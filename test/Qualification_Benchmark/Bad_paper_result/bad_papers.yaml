papers:
- id: on_the_prospects_of_incorporating_large_language_models_llms_in_automated_planning_and_scheduling_aps_on_the_prospects_of_incorporating_large_language_models_llms_in_automated_planning_and_scheduling_aps
  title: "On the Prospects of Incorporating Large Language Models (LLMs) in\n  Automated\
    \ Planning and Scheduling (APS)"
  abstract: 'Automated Planning and Scheduling is among the growing areas in Artificial

    Intelligence (AI) where mention of LLMs has gained popularity. Based on a

    comprehensive review of 126 papers, this paper investigates eight categories

    based on the unique applications of LLMs in addressing various aspects of

    planning problems: language translation, plan generation, model construction,

    multi-agent planning, interactive planning, heuristics optimization, tool

    integration, and brain-inspired planning. For each category, we articulate the

    issues considered and existing gaps. A critical insight resulting from our

    review is that the true potential of LLMs unfolds when they are integrated with

    traditional symbolic planners, pointing towards a promising neuro-symbolic

    approach. This approach effectively combines the generative aspects of LLMs

    with the precision of classical planning methods. By synthesizing insights from

    existing literature, we underline the potential of this integration to address

    complex planning challenges. Our goal is to encourage the ICAPS community to

    recognize the complementary strengths of LLMs and symbolic planners, advocating

    for a direction in automated planning that leverages these synergistic

    capabilities to develop more advanced and intelligent planning systems.'
  url: http://arxiv.org/abs/2401.02500v2
  keywords: ''
  document: "# On the Prospects of Incorporating Large Language Models (LLMs) in Automated\
    \ Planning and Scheduling (APS)\n\nVishal Pallagani<sup>1</sup> , Kaushik Roy<sup>1</sup>\
    \ , Bharath Muppasani<sup>1</sup> , Francesco Fabiano<sup>2</sup> , Andrea Loreggia<sup>3</sup>\
    \ , Keerthiram Murugesan<sup>4</sup> , Biplav Srivastava<sup>1</sup> , Francesca\
    \ Rossi<sup>4</sup> , Lior Horesh<sup>4</sup> , Amit Sheth<sup>1</sup>\n\n> <sup>1</sup>University\
    \ of South Carolina <sup>2</sup>New Mexico State University <sup>3</sup>University\
    \ of Brescia 4 IBM Research\n\n#### Abstract\n\nAutomated Planning and Scheduling\
    \ is among the growing areas in Artificial Intelligence (AI) where mention of\
    \ LLMs has gained popularity. Based on a comprehensive review of 126 papers, this\
    \ paper investigates eight categories based on the unique applications of LLMs\
    \ in addressing various aspects of planning problems: language translation, plan\
    \ generation, model construction, multi-agent planning, interactive planning,\
    \ heuristics optimization, tool integration, and braininspired planning. For each\
    \ category, we articulate the issues considered and existing gaps. A critical\
    \ insight resulting from our review is that the true potential of LLMs unfolds\
    \ when they are integrated with traditional symbolic planners, pointing towards\
    \ a promising neuro-symbolic approach. This approach effectively combines the\
    \ generative aspects of LLMs with the precision of classical planning methods.\
    \ By synthesizing insights from existing literature, we underline the potential\
    \ of this integration to address complex planning challenges. Our goal is to encourage\
    \ the ICAPS community to recognize the complementary strengths of LLMs and symbolic\
    \ planners, advocating for a direction in automated planning that leverages these\
    \ synergistic capabilities to develop more advanced and intelligent planning systems.\n\
    \n# Introduction\n\nAs a sub-field of Artificial Intelligence (Russell and Norvig\
    \ 2003), Automated Planning and Scheduling (Ghallab, Nau, and Traverso 2004) refers\
    \ to developing algorithms and systems to generate plans or sequences of actions\
    \ to achieve specific goals in a given environment or problem domain. APS is a\
    \ valuable tool in domains where there is a need for intelligent decision-making,\
    \ goal achievement, and efficient resource utilization. It enables the automation\
    \ of complex tasks, making systems more capable and adaptable in dynamic environments.\
    \ Over time, APS has evolved from the early development of robust theoretical\
    \ foundations to practical applications in diverse sectors like manufacturing,\
    \ space exploration, and personal scheduling. This evolution underscores the versatility\
    \ and critical significance of APS.\n\nIn parallel with advancements in APS, the\
    \ development and proliferation of LLMs have marked a substantial leap in AI,\
    \ particularly within computational linguistics. Evolving from early efforts in\
    \ natural language processing (NLP), LLMs have undergone significant transformation.\
    \ Initially focused on basic tasks like word prediction and syntax analysis, newer\
    \ models are characterized by their ability to generate coherent, contextually\
    \ relevant text and perform diverse, complex linguistic tasks. Trained on extensive\
    \ text corpora, LLMs have mastered human-like language patterns. Their recent\
    \ success in various NLP tasks has prompted efforts to apply these models in APS.\
    \ There is a notable shift towards using language constructs to specify aspects\
    \ of planning, such as preconditions, effects, and goals, rather than relying\
    \ solely on traditional planning domain languages like PDDL.\n\nThis paper presents\
    \ an exhaustive literature review exploring the integration of LLMs in APS across\
    \ eight categories: Language Translation, Plan Generation, Model Construction,\
    \ Multi-agent Planning, Interactive Planning, Heuristics Optimization, Brain-Inspired\
    \ Planning, and Tool Integration. Table 1 provides the description for the eight\
    \ categories. Our comprehensive analysis of 126 papers not only categorizes LLMs'\
    \ diverse contributions but also identifies significant gaps in each domain. Through\
    \ our review, we put forward the following position:\n\n#### Position Statement\n\
    \nIntegrating LLMs into APS marks a pivotal advancement, bridging the gap between\
    \ the advanced reasoning of traditional APS and the nuanced language understanding\
    \ of LLMs. Traditional APS systems excel in structured, logical planning but often\
    \ lack flexibility and contextual adaptability, a gap readily filled by LLMs.\
    \ Conversely, while LLMs offer unparalleled natural language processing and a\
    \ vast knowledge base, they fail to generate precise, actionable plans where APS\
    \ systems thrive. This integration surpasses the limitations of each standalone\
    \ method, offering a dynamic and context-aware planning approach, while also scaling\
    \ up the traditional use of data and past experiences in the planning process.\n\
    \nIn the forthcoming sections, we delve into the background of LLMs and classical\
    \ planning problem, accompanied by the identification of literature. This sets\
    \ the stage for an indepth exploration of the application of LLMs in APS, where\
    \ we critically examine the strengths and limitations of LLMs. Our position on\
    \ the emerging neuro-symbolic AI paradigm\n\n| Category                | Description\
    \                                                                            \
    \                                                                            \
    \                                                       |\n|-------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Language Translation    | Involves converting natural language into structured\
    \ planning languages or formats like PDDL and<br>vice-versa, enhancing the interface\
    \ between human linguistic input and machine-understandable<br>planning directives.\
    \ |\n| Plan Generation         | Entails the creation of plans or strategies directly\
    \ by LLMs, focusing on generating actionable se<br>quences or decision-making\
    \ processes.                                                                 \
    \              |\n| Model Construction      | Utilizes LLMs to construct or refine\
    \ world and domain models essential for accurate and effective<br>planning.  \
    \                                                                            \
    \                              |\n| Multi-agent Planning    | Focuses on scenarios\
    \ involving multiple agents, where LLMs contribute to coordination and coop<br>erative\
    \ strategy development.                                                      \
    \                                     |\n| Interactive Planning    | Centers on\
    \ scenarios requiring iterative feedback or interactive planning with users, external\
    \ veri<br>fiers, or environment, emphasizing the adaptability of LLMs to dynamic\
    \ inputs.                                     |\n| Heuristics Optimization | Applies\
    \ LLMs in optimizing planning processes through refining existing plans or providing\
    \ heuris<br>tic assistance to symbolic planners.                             \
    \                                                    |\n| Tool Integration   \
    \     | Encompasses studies where LLMs act as central orchestrators or coordinators\
    \ in a tool ecosystem,<br>interfacing with planners, theorem provers, and other\
    \ systems.                                                        |\n| Brain-Inspired\
    \ Planning | Covers research focusing on LLM architectures inspired by neurological\
    \ or cognitive processes,<br>particularly to enhance planning capabilities.  \
    \                                                                        |\n\n\
    Table 1: Comprehensive description of the eight categories utilizing LLMs in APS\n\
    \nis central to our discussion, highlighting its unique advantages over purely\
    \ neural network-based (i.e., statistical AI) or symbolic AI approaches. Finally,\
    \ we will discuss prospective developments, address potential challenges, and\
    \ identify promising opportunities in the field.\n\n# Background\n\n### Large\
    \ Language Models\n\nLarge language models are neural network models with upwards\
    \ of ∼ 3 billion parameters that are trained on extremely large corpora of natural\
    \ language data (trillions of tokens/ words). These models are proficient in interpreting,\
    \ generating, and contextualizing human language, leading to applications ranging\
    \ from text generation to language-driven reasoning tasks. The evolution of LLMs\
    \ in NLP began with rule-based models, progressed through statistical models,\
    \ and achieved a significant breakthrough with the introduction of neural network-based\
    \ models. The shift to sequencebased neural networks, with Recurrent Neural Networks\
    \ (RNNs) and Long Short-Term Memory (LSTM) networks, marked a notable advancement\
    \ due to their capability to process information and context over long sequences.\
    \ Shortcomings in RNNs and LSTMs due to vanishing gradients and, consequently,\
    \ loss of *very long* sequence contexts lead to the transformer model, which introduced\
    \ self-attention (SA) mechanisms. The SA mechanism enabled focus on different\
    \ parts of a long input sequence in parallel, which enhanced understanding of\
    \ contextual nuances in language patterns over extremely long sequences. The SA\
    \ mechanism is also complemented with positional encodings in transformers to\
    \ enable the model to maintain an awareness of word/token order, which is required\
    \ to understand accurate grammar and syntax. The self-attention mechanism, central\
    \ to transformers, uses a query, key, and value system to contextualize dependencies\
    \ in the input sequence. Informally, the SA concept is inspired by classical information\
    \ retrieval systems where the query is the input sequence context, the key refers\
    \ to a \"database\" contained within the parametric memory, and the value is the\
    \ actual value present at that reference. The operation is mathematically expressed\
    \ in Equation 1.\n\n$$\nAttention(Q, K, V) = softmax\\left(\\frac{QK^T}{\\sqrt{d_k}}\\\
    right)V \\qquad (1)\n$$\n\nIn this equation, Q, K, and V denote the query, key,\
    \ and value matrices. The scaling factor <sup>√</sup> dk, where d<sup>k</sup>\
    \ is the dimension of the keys, is employed to standardize the vectors to unit\
    \ variance for ensuring stable softmax gradients during training. Since the introduction\
    \ of LLMs with self-attention, there have been several architectural variants\
    \ depending on the downstream tasks.\n\nCausal Language Modeling (CLMs): CLMs,\
    \ such as GPT-4, are designed for tasks where text generation is sequential and\
    \ dependent on the preceding context. They predict each subsequent word based\
    \ on the preceding words, modeling the probability of a word sequence in a forward\
    \ direction. This process is mathematically formulated as shown in Equation 2.\n\
    \n$$\nP(T) = \\prod_{i=1}^{n} P(t_i | t_{< i})\n$$\n\\n(2)\n\nIn this formulation,\
    \ P(t<sup>i</sup> |t<i) represents the probability of the i-th token given all\
    \ preceding tokens, t<i. This characteristic makes CLMs particularly suitable\
    \ for applications like content generation, where the flow and coherence of the\
    \ text in the forward direction are crucial.\n\nMasked Language Modeling (MLMs):\
    \ Unlike CLMs, MLMs like BERT are trained to understand the bidirectional context\
    \ by predicting words randomly masked in a sentence. This approach allows the\
    \ model to learn both forward and backward dependencies in language structure.\
    \ The MLM prediction process can be represented as Equation 3.\n\n$$\nP(T_{\\\
    text{masked}}|T_{\\text{context}}) = \\prod_{i \\in M} P(t_i|T_{\\text{context}})\n\
    $$\n (3)\n\nHere, Tmasked is the set of masked tokens in the sentence, Tcontext\
    \ represents the unmasked part of the sentence, and M is the set of masked positions.\
    \ MLMs have proven effective in NLP tasks such as sentiment analysis or question\
    \ answering.\n\nSequence-to-Sequence (Seq2Seq) Modeling: Seq2Seq models, like\
    \ T5, are designed to transform an input sequence into a related output sequence.\
    \ They are often employed in tasks that require a mapping between different types\
    \ of sequences, such as language translation or summarization. The Seq2Seq process\
    \ is formulated as Equation 4.\n\n$$\nP(T_{\\text{output}}|T_{\\text{input}})\
    \ = \\prod_{i=1}^{m} P(t_{\\text{output}_i}|T_{\\text{input}}, t_{\\text{output}_{\\\
    lt i}}) \\quad (4)\n$$\n\nIn Equation 4, Tinput is the input sequence, Toutput\
    \ is the output sequence, and P(toutput<sup>i</sup> |Tinput, toutput<i ) calculates\
    \ the probability of generating each token in the output sequence, considering\
    \ both the input sequence and the preceding tokens in the output sequence.\n\n\
    In addition to their architectural variants, the utility of LLMs is further enhanced\
    \ by specific model utilization strategies, enabling their effective adaptation\
    \ to various domains at scale. One key strategy is fine-tuning, which applies\
    \ to pre-trained LLMs. Pre-trained LLMs are models already trained on large datasets\
    \ to understand and generate language, acquiring a broad linguistic knowledge\
    \ base. Fine-tuning involves further training pre-trained LLMs on a smaller, task-specific\
    \ dataset, thereby adjusting the neural network weights for particular applications.\
    \ This process is mathematically represented in Equation 5.\n\n$$\n\\theta_{\\\
    text{fine-tuned}} = \\theta_{\\text{pre-trained}} - \\eta \\cdot \\nabla_{\\theta}\
    \ L(\\theta, D_{\\text{task}})\n$$\n(5)\n\nHere, θfine-tuned are the model parameters\
    \ after fine-tuning, θpre-trained are the parameters obtained from pre-training,\
    \ η is the learning rate, and ∇θL(θ, Dtask) denotes the gradient of the loss function\
    \ L with respect to the parameters θ on the task-specific dataset Dtask.\n\n$$\n\
    P(T|C) = \\prod_{i=1}^{n} P(t_i | t_{< i}, C) \\tag{6}\n$$\n\nComplementing the\
    \ fine-tuning approach is in-context learning, an alternative strategy that is\
    \ particularly characteristic of models like the GPT series. This method diverges\
    \ from fine-tuning by enabling the model to adapt its responses based on immediate\
    \ context or prompts without necessitating further training. The efficacy of in-context\
    \ learning is a direct consequence of the comprehensive pretraining phase, where\
    \ models are exposed to diverse textual datasets, thereby acquiring a nuanced\
    \ understanding of language and context. Given a context C, the model generates\
    \ text T that is contextually relevant, as shown in Equation 6. Here, P(T|C) is\
    \ the probability of generating text T given the context C, and P(t<sup>i</sup>\
    \ |t<i, C) is the probability of generating the i-th token t<sup>i</sup> given\
    \ the preceding tokens t<i and the context C.\n\n![](_page_2_Figure_13.jpeg)\n\
    \nFigure 1: Radar chart showcasing the relative performance of six language models\
    \ (GPT-4, Claude-v1, GPT-3.5-turbo, Vicuna-13B, Alpaca-13B, LLama-13B) across\
    \ key domains: Writing, Roleplay, Reasoning, Math, Coding, Extraction, STEM, and\
    \ Humanities from Zheng et al. (2023a).\n\nThese diverse model types and training\
    \ methodologies under the umbrella of LLMs showcase the flexibility and adaptability\
    \ of language models in handling a wide range of complex tasks. Figure 1 illustrates\
    \ the comparative capabilities of different LLMs across various competency domains,\
    \ such as Writing (evaluating text generation quality), Roleplay (assessing conversational\
    \ interaction), Reasoning (logical problem-solving), Math (numerical problem-solving),\
    \ Coding (programming language understanding and generation), Extraction (information\
    \ retrieval from text), STEM (proficiency in scientific and technical contexts),\
    \ and Humanities (engagement with arts, history, and social sciences content).\
    \ Across these domains, GPT-4 exhibits the strongest performance in the benchmark\
    \ dataset evaluated by Zheng et al. (2023a), indicative of its superior training\
    \ and extensive knowledge base. Expanding LLMs into applications such as code\
    \ generation signifies their adaptability and potential for cross-disciplinary\
    \ innovation. However, fine-tuning and in-context learning methodologies also\
    \ bring challenges, such as potential data overfitting and reliance on the quality\
    \ of input context. LLMs' continuous development and refinement promise to open\
    \ new frontiers in various domains, including automated planning and scheduling,\
    \ by bridging AI with human-like language understanding.\n\n### Automated Planning\
    \ and Scheduling\n\nAPS is a branch of AI that focuses on the creation of strategies\
    \ or action sequences, typically for execution by intelligent agents, autonomous\
    \ robots, and unmanned ve-\n\n![](_page_3_Figure_0.jpeg)\n\nFigure 2: Of the 126\
    \ papers surveyed in this study, 55 were accepted by peer-reviewed conferences.\
    \ This chart illustrates the distribution of these papers across various conferences\
    \ in the fields of LLMs and APS, highlighting the primary forums for scholarly\
    \ contributions in these areas.\n\nhicles. A basic category in APS is a Classical\
    \ Planning Problem (CPP) (Russell and Norvig 2003) which is a tuple M = ⟨D, I,\
    \ G⟩ with domain D = ⟨F, A⟩ - where F is a set of fluents that define a state\
    \ s ⊆ F, and A is a set of actions - and initial and goal states I, G ⊆ F. Action\
    \ a ∈ A is a tuple (ca, *pre*(a), *eff*<sup>±</sup>(a)) where c<sup>a</sup> is\
    \ the cost, and *pre*(a), *eff*<sup>±</sup>(a) ⊆ F are the preconditions and add/delete\
    \ effects, i.e., δM(s, a) |= ⊥s *if* s ̸|= *pre*(a); *else* δM(s, a) |= s ∪ eff<sup>+</sup>(a)\
    \ \\ eff<sup>−</sup>(a) where δM(·) is the transition function. The cumulative\
    \ transition function is δM(s,(a1, a2, . . . , an)) = δM(δM(s, a1),(a2, . . .\
    \ , an)). A plan for a CPP is a sequence of actions ⟨a1, a2, . . . , an⟩ that\
    \ transforms the initial state I into the goal state G using the transition function\
    \ δM. Traditionally, a CPP is encoded using a symbolic representation, where states,\
    \ actions, and transitions are explicitly enumerated. This symbolic approach,\
    \ often implemented using Planning Domain Definition Language or PDDL (McDermott\
    \ et al. 1998), ensures precise and unambiguous descriptions of planning problems.\
    \ This formalism allows for applying search algorithms and heuristic methods to\
    \ find a sequence of actions that lead to the goal state, which is the essence\
    \ of the plan.\n\nThe advent of LLMs has sparked a significant evolution in representation\
    \ methods for CPPs, moving towards leveraging the expressive power of natural\
    \ language (Valmeekam et al. 2023a) and the perceptual capabilities of vision\
    \ (Asai 2018). These novel approaches, inherently more suited for LLM processing,\
    \ use text and vision-based representations, allowing researchers to utilize the\
    \ pre-existing knowledge within LLMs. This shift enables a more humanistic comprehension\
    \ and reasoning about planning tasks, enhancing the flexibility and applicability\
    \ of planning algorithms in complex, dynamic environments. LLMs, while distinct\
    \ in being trained on vast datasets outside the traditional scope of planning,\
    \ loosely connect to previous data-driven methodologies, such as case-based reasoning\
    \ (Xu 1995) applied to planning and Hierarchical Task Network (HTN) (Georgievski\
    \ and Aiello 2015) which make use of task knowledge. It is an open area how LLMs\
    \ may be used synergestically with prior methods.\n\n### LLMs in APS – Literature\
    \ selection\n\nA comprehensive survey of existing literature was conducted to\
    \ explore the application of LLMs for automated planning. This endeavor led to\
    \ identifying 126 pertinent research papers showcasing various methodologies,\
    \ applications, and theoretical insights into utilizing LLMs within this domain.\n\
    \nThe selection of these papers was guided by stringent criteria, focusing primarily\
    \ on their relevance to the core theme of LLMs in automated planning. The search,\
    \ conducted across multiple academic databases and journals, was steered by keywords\
    \ such as \"Large Language Models\", \"Automated Planning\", \"LLMs in Planning\"\
    , and \"LLMs + Robotics\". Figure 2 presents the distribution of these selected\
    \ papers across various peer-reviewed conferences, underlining the breadth and\
    \ diversity of forums addressing the intersection of LLMs and APS. Even if a paper\
    \ originated from a workshop within a conference, only the conference name is\
    \ listed. Out of 126 papers, 71 are under review or available on arXiv. The inclusion\
    \ criteria prioritized the relevance and contribution of papers to automated planning\
    \ with LLMs over the publication date. Nonetheless, all surveyed papers emerged\
    \ from either 2022 or 2023, a trend depicted in Figure 3, underscoring the recent\
    \ surge in LLM research. A word cloud was generated to visually capture the prevalent\
    \ research themes reflected in these papers' titles, illustrated in Figure 4.\
    \ This cloud highlights the frequent use of terms such as \"Language Model\" and\
    \ \"Planning\", which dominate the current discourse. In contrast, the emergence\
    \ of \"Neuro-Symbolic\" reflects a nascent yet growing interest in integrating\
    \ neural and symbolic approaches within the field. This systematic approach ensured\
    \ a comprehensive inclusion of seminal works and recent advancements.\n\nUpon\
    \ the accumulation of these papers, a meticulous manual categorization was undertaken.\
    \ The papers were divided into four piles, each containing approximately 30 papers.\
    \ Each pile was manually categorized by one author,\n\n![](_page_4_Figure_0.jpeg)\n\
    \nFigure 3: Annual distribution of the 126 surveyed papers, indicating a significant\
    \ increase in publications from 12 in 2022 to 114 in 2023, highlighting the rapid\
    \ growth of LLM research within a single year.\n\nwith the final categorization\
    \ being reviewed by all authors. During this process, each paper could belong\
    \ to multiple categories out of the eight established. The maximum number of categories\
    \ assigned to a single paper was three, although the median was typically one\
    \ category per paper. This process was pivotal in distilling the vast information\
    \ into coherent, thematic groups. The categorization was conducted based on the\
    \ specific application of LLMs in planning. This formed eight distinct categories,\
    \ each representing a unique facet of LLM application in automated planning. These\
    \ categories facilitate a structured analysis and highlight LLMs' diverse applications\
    \ and theoretical underpinnings in this field.\n\n![](_page_4_Figure_3.jpeg)\n\
    \nFigure 4: Word cloud of terms from the titles of papers surveyed in this study,\
    \ displaying the prevalence of \"Language Model\" and \"Planning\" as central\
    \ themes. The presence of \"Neuro-Symbolic\" indicates an emergent trend toward\
    \ the fusion of neural and symbolic methodologies in the domain.\n\n# LLMs in\
    \ APS – Literature Discussion\n\nThis section dwelves into the diverse applications\
    \ of LLMs in planning tasks. We have identified eight distinct categories based\
    \ on the utility and application of LLMs in planning, which are concisely summarized\
    \ in Table 1. Figure 5 provides a detailed taxonomy, illustrating the categorization\
    \ of the identified research papers.\n\n### Language Translation\n\nLanguage translation\
    \ in the context of LLMs and planning involves transforming natural language instructions\
    \ into structured planning languages (Wong et al. 2023; Kelly et al. 2023; Yang\
    \ 2023; Pan et al. 2023; Xie et al. 2023; Yang, Ishay, and Lee 2023; Lin et al.\
    \ 2023c; Sakib and Sun 2023; Yang et al. 2023b; Parakh et al. 2023; Yang et al.\
    \ 2023a; Dai et al. 2023; Ding et al. 2023b; Zelikman et al. 2023; Xu et al. 2023b;\
    \ Chen et al. 2023a; You et al. 2023) such as PDDL, and vice versa, utilizing\
    \ in-context learning techniques (Guan et al. 2023). This capability effectively\
    \ bridges the gap between human linguistic expression and machine-understandable\
    \ formats, enhancing intuitive and efficient planning processes. The LLM+P framework\
    \ (Liu et al. 2023) exemplifies this by converting natural language descriptions\
    \ of planning problems into PDDL using GPT-4, leveraging classical planners for\
    \ solution finding, and then translating these solutions back into natural language,\
    \ with a specific focus on robot planning scenarios. Additionally, Graph2NL (Chalvatzaki\
    \ et al. 2023) generates natural language text from scene graphs for long-horizon\
    \ robot reasoning tasks, while (Shirai et al. 2023) introduces a vision-to-language\
    \ interpreter for robot task planning. Further, (Brohan et al. 2023) examines\
    \ the grounding of LLMgenerated natural language utterances in actionable robot\
    \ tasks, and (Yang, Gaglione, and Topcu 2022) utilizes LLMs for creating finite-state\
    \ automatons for sequential decisionmaking problems. Despite these advancements,\
    \ a critical research gap emerges in the autonomous translation capabilities of\
    \ LLMs, particularly in converting natural language to PDDL without external expert\
    \ intervention.\n\nWhile LLMs effectively translate PDDL to natural language,\
    \ a notable gap is evident in their limited understanding of real-world objects\
    \ and the problem of grounding affordances, mainly when translating natural language\
    \ to structured languages like PDDL. Addressing this gap calls for integrating\
    \ neuro-symbolic approaches in LLMs, where the fusion of perceptual experience\
    \ for concrete concept understanding from knowledge graphs complements LLMs' proficiency\
    \ in distributional statistics (Lenat and Marcus 2023).\n\n### Plan Generation\n\
    \nThis category focuses on directly generating plans using LLMs. The research,\
    \ primarily utilizing causal language models through in-context learning (Sermanet\
    \ et al. 2023; Li et al. 2023b; Silver et al. 2023; Parakh et al. 2023; Zelikman\
    \ et al. 2023; Besta et al. 2023; Huang et al. 2023a; Dalal et al. 2023; Wang\
    \ et al. 2023b; Valmeekam et al. 2022; Valmeekam, Marquez, and Kambhampati 2023;\
    \ Gramopadhye and Szafir 2022; Singh et al. 2023)<sup>1</sup> , demonstrates modest\
    \ performance, indicating notable challenges in employing LLMs for effective plan\
    \ generation. Novel in-context learning strategies, such as the Chain-of-Symbol\
    \ and Tree of Thoughts, have been introduced to enhance LLMs' reasoning capabilities\
    \ (Hu et al. 2023b; Yao et al. 2023). Ef-\n\n<sup>1</sup>Due to space constraints,\
    \ only a select number of papers are cited in this section.\n\n![](_page_5_Figure_0.jpeg)\n\
    \nFigure 5: Taxonomy of recent research in the intersection of LLMs and Planning\
    \ into categories (#). Each has scholarly papers based on their unique application\
    \ or customization of LLMs in addressing various aspects of planning problems.\n\
    \nforts to generate multimodal, text, and image-based goalconditioned plans are\
    \ exemplified by (Lu et al. 2023b). Additionally, a subset of studies in this\
    \ survey investigates the fine-tuning of seq2seq, code-based language models (Pallagani\
    \ et al. 2022, 2023b), which are noted for their advanced syntactic encoding.\
    \ These models show promise in improving plan generation within the confines of\
    \ their training datasets (Logeswaran et al. 2023), yet exhibit limitations in\
    \ generalizing to out-of-distribution domains (Pallagani et al. 2023a), highlighting\
    \ a gap in their adaptability across diverse planning contexts.\n\nCausal LLMs\
    \ are predominantly used for plan generation, but their performance is often limited\
    \ due to their design, which is focused on generating text based on preceding\
    \ input. On the other hand, seq2seq LLMs can generate valid plans but struggle\
    \ with generalization across diverse domains. This limitation highlights an opportunity\
    \ for a synergistic approach: integrating even imperfect LLM outputs with symbolic\
    \ planners can expedite heuristic searches, thereby enhancing efficiency and reducing\
    \ search times (Fabiano et al. 2023).\n\n## Model Construction\n\nThis category\
    \ employs LLMs to build or refine world and domain models essential for accurate\
    \ planning. Nottingham et al. (2023); Yuan et al. (2023a) leverage in-context\
    \ learning with LLMs to develop an abstract world model in the Minecraft domain,\
    \ highlighting the challenge of semantic grounding in LLMs. Similarly, Gragera\
    \ and Pozanco (2023) explore the capability of LLMs in completing ill-defined\
    \ PDDL domains. Efforts such as (Huang et al. 2023a; Brohan et al. 2023) delve\
    \ into LLMs' grounding capabilities, with SayCan (Brohan et al. 2023) notably\
    \ achieving 74% executable plans. Hao et al. (2023a); Yoneda et al. (2023) innovatively\
    \ positions LLMs as both world models and reasoning agents, enabling the simulation\
    \ of world states and prediction of action outcomes. Research by (Zhang and Soh\
    \ 2023; Wong et al. 2023; Mandi, Jain, and Song 2023; Hu et al. 2023a; Zhao, Lee,\
    \ and Hsu 2023; Ding et al. 2023b; Huang et al. 2023a; Wu et al. 2023b; Xu et\
    \ al. 2023b; Brohan et al. 2023) shows that LLMs can effectively model highlevel\
    \ human states and behaviors using their commonsense knowledge. Yet, they face\
    \ difficulties accurately processing low-level geometrical or shape features due\
    \ to spatial and numerical reasoning constraints. Additionally, Kelly et al. (2023)\
    \ investigates the potential of LLMs in conjunction with planners to craft narratives\
    \ and logical story models, integrating human-in-the-loop for iterative edits.\n\
    \nLLMs often struggle with detailed spatial reasoning and processing low-level\
    \ environmental features, limiting their effectiveness in model construction.\
    \ Integrating world models presents a viable solution, offering advanced abstractions\
    \ for reasoning that encompass human-like cognitive elements and interactions,\
    \ thereby enhancing LLMs' capabilities in model construction (Hu and Shu 2023).\n\
    \n## Multi-agent Planning\n\nIn multi-agent planning, LLMs play a vital role in\
    \ scenarios involving interaction among multiple agents, typically modeled using\
    \ distinct LLMs. These models enhance coordination and cooperation, leading to\
    \ more complex and effective multi-agent strategies. (Zhang et al. 2023b) introduces\
    \ an innovative framework that employs LLMs to develop cooperative embodied agents.\
    \ AutoGraph (Wei et al. 2023) leverages LLMs to generate autonomous agents adept\
    \ at devising solutions for varied graph-structured data problems. Addressing\
    \ scalability in multi-robot task planning, (Chen et al. 2023d) proposes frameworks\
    \ for the collaborative function of different LLM-based agents. Furthermore, (Abdelnabi\
    \ et al. 2023) and (Hua et al. 2023) collectively demonstrate the effectiveness\
    \ of LLM agents in complex negotiation and decisionmaking environments.\n\nA key\
    \ gap in multi-agent planning with LLMs lies in standardizing inter-agent communication\
    \ and maintaining distinct belief states, including human aspects. Overcoming\
    \ this requires advanced LLM algorithms for dynamic alignment of communication\
    \ and belief states, drawing on epistemic reasoning and knowledge representation\
    \ (de Zarza et al. 2023). `\n\n### Interactive Planning\n\nIn this category, LLMs\
    \ are utilized in dynamic scenarios where real-time adaptability to user feedback\
    \ or iterative planning is essential. The refinement of LLM outputs is typically\
    \ achieved through four primary feedback variants: (a) External verifiers, such\
    \ as VAL(Howey, Long, and Fox 2004) for PDDL or scene descriptors and success\
    \ detectors in robotics (Guan et al. 2023; Arora and Kambhampati 2023; Jha et\
    \ al. 2023; Huang et al. 2022b; Liu, Bahety, and Song 2023; Rana et al. 2023;\
    \ Ren et al. 2023; Kim et al. 2023; Graule and Isler 2023; Driess et al. 2023;\
    \ Zheng et al. 2023b); (b) Online reinforcement learning, which progressively\
    \ updates the LLM about environmental changes (Carta et al. 2023); (c) Self-refinement\
    \ by LLMs, where they provide feedback on their own outputs (Zhou et al. 2023;\
    \ Hu et al. 2023c,b; Ding et al. 2023a; Sun et al. 2023; Naik et al. 2023); (d)\
    \ Input from human experts (Raman et al. 2022; Wu, Ai, and Hsu 2023). Furthermore,\
    \ (Chen et al. 2023b) introduces the \"Action Before Action\" method, enabling\
    \ LLMs to proactively seek relevant information from external sources in natural\
    \ language, thereby improving embodied decision-making in LLMs by 40%.\n\nA key\
    \ gap in interactive planning with LLMs lies in harmonizing the \"fast\" neural\
    \ processing of LLMs with \"slow\" symbolic reasoning, as manifested in feedback\
    \ mechanisms. This integration is key to maintaining the neural speed of LLMs\
    \ while effectively embedding the depth and precision of feedback, which is vital\
    \ for accuracy in dynamic planning scenarios (Zhang et al. 2023a).\n\n### Heuristics\
    \ Optimization\n\nIn the realm of Heuristics Optimization, LLMs are leveraged\
    \ to enhance planning processes, either by refining existing plans or aiding symbolic\
    \ planners with heuristic guidance. Studies like (Hazra, Martires, and De Raedt\
    \ 2023; Hao et al. 2023a; Dai et al. 2023; Feng et al. 2023) have effectively\
    \ coupled LLMs with heuristic searches to identify optimal action sequences. Research\
    \ by (Silver et al. 2022; Shah et al. 2023; Valmeekam et al. 2023b) reveals that\
    \ LLMs' outputs, even if partially correct, can provide valuable direction for\
    \ symbolic planners such as LPG (Gerevini and Serina 2002), especially in problems\
    \ beyond the LLMs' solvable scope. Furthermore, (Raimondo et al. 2023) makes an\
    \ intriguing observation that including workflows and action plans in LLM input\
    \ prompts can notably enhance task-oriented dialogue generalization.\n\nThis category\
    \ marks significant progress towards realizing neuro-symbolic approaches in APS.\
    \ Current methods emphasize plan validity, often at the expense of time efficiency.\
    \ Future research should look at how to continually evolve LLMs for better plan\
    \ generation, with its experience from complimenting symbolic planners (Du et\
    \ al. 2023).\n\n## Tool Integration\n\nIn tool integration, LLMs serve as coordinators\
    \ within a diverse array of planning tools, enhancing functionality in complex\
    \ scenarios. Studies like (Xu et al. 2023a; Lu et al. 2023a; Shen et al. 2023;\
    \ Hao et al. 2023b; Ge et al. 2023) demonstrate that incorporating tools such\
    \ as web search engines, Python functions, and API endpoints enhances LLM reasoning\
    \ abilities. However, (Ruan et al. 2023) notes a tendency for LLMs to over-rely\
    \ on specific tools, potentially prolonging the planning process. (Li et al. 2023a)\
    \ introduces a benchmark for tool-augmented LLMs. While typical approaches involve\
    \ teaching LLMs tool usage via multiple prompts, (Hsieh et al. 2023) suggests\
    \ that leveraging tool documentation offers improved planning capabilities, circumventing\
    \ the need for extensive demonstrations.\n\nLLMs often hallucinate non-existent\
    \ tools, overuse a single tool, and face scaling challenges with multiple tools.\
    \ Overcoming these issues is key to enabling LLMs to effectively select and utilize\
    \ various tools in complex planning scenarios (Elaraby et al. 2023).\n\n### Brain-Inspired\
    \ Planning\n\nThis area explores neurologically and cognitively inspired architectures\
    \ in LLMs (Webb et al. 2023; Sumers et al. 2023; Momennejad et al. 2023; Hu et\
    \ al. 2023d; Lin et al. 2023a), aiming to replicate human-like planning in enhancing\
    \ problem-solving. However, while these methods rely on in-context learning, they\
    \ frequently encounter challenges such as hallucination and grounding, as previously\
    \ discussed, and tend to be more computationally intensive than in-context learning\
    \ alone.\n\nWhile LLMs attempt to mimic symbolic solvers through incontext learning\
    \ for brain-inspired modules, this approach lacks adaptability and is a superficial\
    \ understanding of complex cognitive processes. To overcome these issues, developing\
    \ systems where neural and symbolic components are intrinsically intertwined is\
    \ critical as it would accurately mirror human cognitive capabilities in planning\
    \ (Fabiano et al. 2023).\n\n# Discussion and Conclusion\n\nIn this position paper,\
    \ we comprehensively investigate the role of LLMs within the domain of APS, analyzing\
    \ 126 scholarly articles across eight distinct categories. This extensive survey\
    \ not only provides a detailed landscape of current LLM applications and their\
    \ limitations but also highlights the volume of research in each category: Language\
    \ Translation with 23 papers demonstrates LLMs' proficiency, whereas Plan Generation,\
    \ the most researched category with 53 papers, reveals their shortcomings in optimality,\
    \ completeness, and correctness compared to traditional combinatorial planners.\
    \ Our exploration extends to Model Construction (17 papers), which examines LLMs\
    \ in developing planning models, and the relatively unexplored area of Multiagent\
    \ Planning (4 papers). Interactive Planning is well represented with 21 papers,\
    \ illustrating LLMs' adaptability in feedback-centric scenarios. Despite being\
    \ less researched, Heuristics Optimization and Tool Integration, each with 8 papers,\
    \ provide valuable insights into efficiency enhancement and integration of LLMs\
    \ with symbolic solvers. Lastly, Brain-inspired Planning, although least represented\
    \ with 5 papers, opens innovative avenues for human-like planning processes in\
    \ LLMs. By identifying the research distribution and gaps in these categories,\
    \ our paper proposes how neurosymbolic approaches can address these voids, thereby\
    \ underscoring the varying degrees of LLM applications in APS and guiding future\
    \ research towards enhancing their capabilities in complex planning tasks.\n\n\
    It is important to acknowledge that while LLMs have shown promise, they are not\
    \ a panacea for the inherent complexities of automated planning. The expectation\
    \ that LLMs, operating within polynomial run-time bounds, could supplant the nuanced\
    \ and often non-polynomial complexities of symbolic planners is not yet realizable.\
    \ Indeed, the strengths of LLMs do not currently include generating sequences\
    \ of actions akin to those devised by symbolic planners, which are essential for\
    \ creating a coherent and practical plan for complex problems. However, this does\
    \ not diminish the potential utility of LLMs within this space. When considering\
    \ average-case scenarios, which are typically less complex than worst-case scenarios,\
    \ LLMs could offer substantial efficiencies. They can be seen as akin to meta-heuristic\
    \ approaches, capable of accelerating plan generation in a variety of settings.\
    \ As such, their application, governed by cognitive-inspired frameworks like SOFAI(Fabiano\
    \ et al. 2023), could delineate when and where their use is most advantageous.\n\
    \nFuture research should prioritize three areas: developing new LLM training paradigms\
    \ that ensure coherence and goal alignment in outputs; delving into Henry Kautz's\
    \ neurosymbolic taxonomies (Kautz 2022) to better integrate neural and symbolic\
    \ methods; and establishing clear performance metrics for LLM-assisted planners.\
    \ In conclusion, integrating LLMs into automated planning, while challenging,\
    \ opens avenues for innovation. Embracing a symbiotic approach that combines the\
    \ creative strengths of LLMs with the precision of symbolic planners can lead\
    \ to more effective, sophisticated AI applications in planning.\n\n# References\n\
    \nAbdelnabi, S.; Gomaa, A.; Sivaprasad, S.; Schonherr, L.; ¨ and Fritz, M. 2023.\
    \ Llm-deliberation: Evaluating llms with interactive multi-agent negotiation games.\
    \ *arXiv preprint arXiv:2309.17234*.\n\nArora, D.; and Kambhampati, S. 2023. Learning\
    \ and Leveraging Verifiers to Improve Planning Capabilities of Pre-trained Language\
    \ Models. *arXiv preprint arXiv:2305.17077*.\n\nAsai, M. 2018. Photo-Realistic\
    \ Blocksworld Dataset. *arXiv preprint arXiv:1812.01818*.\n\nBesta, M.; Blach,\
    \ N.; Kubicek, A.; Gerstenberger, R.; Gianinazzi, L.; Gajda, J.; Lehmann, T.;\
    \ Podstawski, M.; Niewiadomski, H.; Nyczyk, P.; et al. 2023. Graph of thoughts:\
    \ Solving elaborate problems with large language models. *arXiv preprint arXiv:2308.09687*.\n\
    \nBrohan, A.; Chebotar, Y.; Finn, C.; Hausman, K.; Herzog, A.; Ho, D.; Ibarz,\
    \ J.; Irpan, A.; Jang, E.; Julian, R.; et al. 2023. Do as i can, not as i say:\
    \ Grounding language in robotic affordances. In *Conference on Robot Learning*,\
    \ 287– 318. PMLR.\n\nCapitanelli, A.; and Mastrogiovanni, F. 2023. A Framework\
    \ to Generate Neurosymbolic PDDL-compliant Planners. *arXiv preprint arXiv:2303.00438*.\n\
    \nCarta, T.; Romac, C.; Wolf, T.; Lamprier, S.; Sigaud, O.; and Oudeyer, P.-Y.\
    \ 2023. Grounding large language models in interactive environments with online\
    \ reinforcement learning. *arXiv preprint arXiv:2302.02662*.\n\nChalvatzaki, G.;\
    \ Younes, A.; Nandha, D.; Le, A. T.; Ribeiro, L. F.; and Gurevych, I. 2023. Learning\
    \ to reason over scene graphs: a case study of finetuning GPT-2 into a robot language\
    \ model for grounded task planning. *Frontiers in Robotics and AI*, 10.\n\nChen,\
    \ B.; Xia, F.; Ichter, B.; Rao, K.; Gopalakrishnan, K.; Ryoo, M. S.; Stone, A.;\
    \ and Kappler, D. 2023a. Openvocabulary queryable scene representations for real\
    \ world planning. In *2023 IEEE International Conference on Robotics and Automation\
    \ (ICRA)*, 11509–11522. IEEE.\n\nChen, X.; Zhang, S.; Zhang, P.; Zhao, L.; and\
    \ Chen, J. 2023b. Asking Before Action: Gather Information in Embodied Decision\
    \ Making with Language Models. *arXiv preprint arXiv:2305.15695*.\n\nChen, Y.;\
    \ Arkin, J.; Zhang, Y.; Roy, N.; and Fan, C. 2023c. AutoTAMP: Autoregressive Task\
    \ and Motion Planning with LLMs as Translators and Checkers. *arXiv preprint arXiv:2306.06531*.\n\
    \nChen, Y.; Arkin, J.; Zhang, Y.; Roy, N.; and Fan, C. 2023d. Scalable Multi-Robot\
    \ Collaboration with Large Language Models: Centralized or Decentralized Systems?\
    \ *arXiv preprint arXiv:2309.15943*.\n\nDagan, G.; Keller, F.; and Lascarides,\
    \ A. 2023. Dynamic Planning with a LLM. *arXiv preprint arXiv:2308.06391*.\n\n\
    Dai, Z.; Asgharivaskasi, A.; Duong, T.; Lin, S.; Tzes, M.-E.; Pappas, G.; and\
    \ Atanasov, N. 2023. Optimal Scene Graph Planning with Large Language Model Guidance.\
    \ *arXiv preprint arXiv:2309.09182*.\n\nDalal, M.; Chiruvolu, T.; Chaplot, D.\
    \ S.; and Salakhutdinov, R. 2023. Plan-Seq-Learn: Language Model Guided RL for\
    \ Solving Long Horizon Robotics Tasks. In *2nd Workshop on Language and Robot\
    \ Learning: Language as Grounding*.\n\nde Zarza, I.; de Curt ` o, J.; Roig, G.;\
    \ Manzoni, P.; and ` Calafate, C. T. 2023. Emergent Cooperation and Strategy Adaptation\
    \ in Multi-Agent Systems: An Extended Coevolutionary Theory with LLMs. *Electronics*,\
    \ 12(12): 2722.\n\nDing, Y.; Zhang, X.; Amiri, S.; Cao, N.; Yang, H.; Kaminski,\
    \ A.; Esselink, C.; and Zhang, S. 2023a. Integrating Action Knowledge and LLMs\
    \ for Task Planning and Situation Handling in Open Worlds. *arXiv preprint arXiv:2305.17590*.\n\
    \nDing, Y.; Zhang, X.; Paxton, C.; and Zhang, S. 2023b. Leveraging Commonsense\
    \ Knowledge from Large Language Models for Task and Motion Planning. In *RSS 2023\
    \ Workshop on Learning for Task and Motion Planning*.\n\nDing, Y.; Zhang, X.;\
    \ Paxton, C.; and Zhang, S. 2023c. Task and motion planning with large language\
    \ models for object rearrangement. *arXiv preprint arXiv:2303.06247*.\n\nDriess,\
    \ D.; Xia, F.; Sajjadi, M. S.; Lynch, C.; Chowdhery, A.; Ichter, B.; Wahid, A.;\
    \ Tompson, J.; Vuong, Q.; Yu, T.; et al. 2023. Palm-e: An embodied multimodal\
    \ language model. *arXiv preprint arXiv:2303.03378*.\n\nDu, M.; Luu, A. T.; Ji,\
    \ B.; and Ng, S.-k. 2023. From Static to Dynamic: A Continual Learning Framework\
    \ for Large Language Models. *arXiv preprint arXiv:2310.14248*.\n\nElaraby, M.;\
    \ Lu, M.; Dunn, J.; Zhang, X.; Wang, Y.; and Liu, S. 2023. Halo: Estimation and\
    \ reduction of hallucinations in open-source weak large language models. *arXiv\
    \ preprint arXiv:2308.11764*.\n\nFabiano, F.; Pallagani, V.; Ganapini, M. B.;\
    \ Horesh, L.; Loreggia, A.; Murugesan, K.; Rossi, F.; and Srivastava, B. 2023.\
    \ Fast and Slow Planning. *arXiv preprint arXiv:2303.04283*.\n\nFeng, X.; Wan,\
    \ Z.; Wen, M.; Wen, Y.; Zhang, W.; and Wang, J. 2023. Alphazero-like tree-search\
    \ can guide large language model decoding and training. *arXiv preprint arXiv:2309.17179*.\n\
    \nGandhi, K.; Sadigh, D.; and Goodman, N. D. 2023. Strategic Reasoning with Language\
    \ Models. *arXiv preprint arXiv:2305.19165*.\n\nGe, Y.; Hua, W.; Ji, J.; Tan,\
    \ J.; Xu, S.; and Zhang, Y. 2023. Openagi: When llm meets domain experts. *arXiv\
    \ preprint arXiv:2304.04370*.\n\nGeorgievski, I.; and Aiello, M. 2015. HTN planning:\
    \ Overview, comparison, and beyond. *Artif. Intell.*, 222: 124– 156.\n\nGerevini,\
    \ A.; and Serina, I. 2002. LPG: A Planner Based on Local Search for Planning Graphs\
    \ with Action Costs. In *Aips*, volume 2, 281–290.\n\nGhallab, M.; Nau, D.; and\
    \ Traverso, P. 2004. *Automated Planning: Theory and Practice*. The Morgan Kaufmann\
    \ Series in Artificial Intelligence. Amsterdam: Morgan Kaufmann. ISBN 978-1-55860-856-6.\n\
    \nGragera, A.; and Pozanco, A. 2023. Exploring the Limitations of using Large\
    \ Language Models to Fix Planning Tasks.\n\nGramopadhye, M.; and Szafir, D. 2022.\
    \ Generating executable action plans with environmentally-aware language models.\
    \ *arXiv preprint arXiv:2210.04964*.\n\nGraule, M. A.; and Isler, V. 2023. GG-LLM:\
    \ Geometrically Grounding Large Language Models for Zero-shot Human Activity Forecasting\
    \ in Human-Aware Task Planning. *arXiv preprint arXiv:2310.20034*.\n\nGu, Q.;\
    \ Kuwajerwala, A.; Morin, S.; Jatavallabhula, K. M.; Sen, B.; Agarwal, A.; Rivera,\
    \ C.; Paul, W.; Ellis, K.; Chellappa, R.; et al. 2023. Conceptgraphs: Open-vocabulary\
    \ 3d scene graphs for perception and planning. *arXiv preprint arXiv:2309.16650*.\n\
    \nGuan, L.; Valmeekam, K.; Sreedharan, S.; and Kambhampati, S. 2023. Leveraging\
    \ Pre-trained Large Language Models to Construct and Utilize World Models for\
    \ Model-based Task Planning. *arXiv preprint arXiv:2305.14909*.\n\nHao, S.; Gu,\
    \ Y.; Ma, H.; Hong, J. J.; Wang, Z.; Wang, D. Z.; and Hu, Z. 2023a. Reasoning\
    \ with language model is planning with world model. *arXiv preprint arXiv:2305.14992*.\n\
    \nHao, S.; Liu, T.; Wang, Z.; and Hu, Z. 2023b. ToolkenGPT: Augmenting Frozen\
    \ Language Models with Massive Tools via Tool Embeddings. *arXiv preprint arXiv:2305.11554*.\n\
    \nHazra, R.; Martires, P. Z. D.; and De Raedt, L. 2023. Say-CanPay: Heuristic\
    \ Planning with Large Language Models using Learnable Domain Knowledge. *arXiv\
    \ preprint arXiv:2308.12682*.\n\nHowey, R.; Long, D.; and Fox, M. 2004. VAL: automatic\
    \ plan validation, continuous effects and mixed initiative planning using PDDL.\
    \ In *16th IEEE International Conference on Tools with Artificial Intelligence*,\
    \ 294–301.\n\nHsieh, C.-Y.; Chen, S.-A.; Li, C.-L.; Fujii, Y.; Ratner, A.; Lee,\
    \ C.-Y.; Krishna, R.; and Pfister, T. 2023. Tool documentation enables zero-shot\
    \ tool-usage with large language models. *arXiv preprint arXiv:2308.00675*.\n\n\
    Hu, B.; Zhao, C.; Zhang, P.; Zhou, Z.; Yang, Y.; Xu, Z.; and Liu, B. 2023a. Enabling\
    \ Efficient Interaction between an Algorithm Agent and an LLM: A Reinforcement\
    \ Learning Approach. *arXiv preprint arXiv:2306.03604*.\n\nHu, H.; Lu, H.; Zhang,\
    \ H.; Lam, W.; and Zhang, Y. 2023b. Chain-of-Symbol Prompting Elicits Planning\
    \ in Large Langauge Models. *arXiv preprint arXiv:2305.10276*.\n\nHu, M.; Mu,\
    \ Y.; Yu, X.; Ding, M.; Wu, S.; Shao, W.; Chen, Q.; Wang, B.; Qiao, Y.; and Luo,\
    \ P. 2023c. Tree-Planner: Efficient Close-loop Task Planning with Large Language\
    \ Models. *arXiv preprint arXiv:2310.08582*.\n\nHu, P.; Qi, J.; Li, X.; Li, H.;\
    \ Wang, X.; Quan, B.; Wang, R.; and Zhou, Y. 2023d. Tree-of-mixed-thought: Combining\
    \ fast and slow thinking for multi-hop visual reasoning. *arXiv preprint arXiv:2308.09658*.\n\
    \nHu, Z.; and Shu, T. 2023. Language Models, Agent Models, and World Models: The\
    \ LAW for Machine Reasoning and Planning. arXiv:2312.05230.\n\nHua, W.; Fan, L.;\
    \ Li, L.; Mei, K.; Ji, J.; Ge, Y.; Hemphill, L.; and Zhang, Y. 2023. War and peace\
    \ (waragent): Large language model-based multi-agent simulation of world wars.\
    \ *arXiv preprint arXiv:2311.17227*.\n\nHuang, W.; Abbeel, P.; Pathak, D.; and\
    \ Mordatch, I. 2022a. Language models as zero-shot planners: Extracting actionable\
    \ knowledge for embodied agents. In *International Conference on Machine Learning*,\
    \ 9118–9147. PMLR.\n\nHuang, W.; Wang, C.; Zhang, R.; Li, Y.; Wu, J.; and Fei-Fei,\
    \ L. 2023a. Voxposer: Composable 3d value maps for robotic manipulation with language\
    \ models. *arXiv preprint arXiv:2307.05973*.\n\nHuang, W.; Xia, F.; Shah, D.;\
    \ Driess, D.; Zeng, A.; Lu, Y.; Florence, P.; Mordatch, I.; Levine, S.; Hausman,\
    \ K.; et al. 2023b. Grounded decoding: Guiding text generation with grounded models\
    \ for robot control. *arXiv preprint arXiv:2303.00855*.\n\nHuang, W.; Xia, F.;\
    \ Xiao, T.; Chan, H.; Liang, J.; Florence, P.; Zeng, A.; Tompson, J.; Mordatch,\
    \ I.; Chebotar, Y.; et al. 2022b. Inner monologue: Embodied reasoning through\
    \ planning with language models. *arXiv preprint arXiv:2207.05608*.\n\nJha, S.\
    \ K.; Jha, S.; Lincoln, P.; Bastian, N. D.; Velasquez, A.; Ewetz, R.; and Neema,\
    \ S. 2023. Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive\
    \ Synthesis using Large Language Models and Satisfiability Solving. *arXiv preprint\
    \ arXiv:2309.16436*.\n\nJoublin, F.; Ceravola, A.; Smirnov, P.; Ocker, F.; Deigmoeller,\
    \ J.; Belardinelli, A.; Wang, C.; Hasler, S.; Tanneberg, D.; and Gienger, M. 2023.\
    \ CoPAL: Corrective Planning of Robot Actions with Large Language Models. *arXiv\
    \ preprint arXiv:2310.07263*.\n\nKannan, S. S.; Venkatesh, V. L.; and Min, B.-C.\
    \ 2023. SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language\
    \ Models. *arXiv preprint arXiv:2309.10062*.\n\nKant, Y.; Ramachandran, A.; Yenamandra,\
    \ S.; Gilitschenski, I.; Batra, D.; Szot, A.; and Agrawal, H. 2022. Housekeep:\
    \ Tidying virtual households using commonsense reasoning. In *European Conference\
    \ on Computer Vision*, 355– 373. Springer.\n\nKautz, H. A. 2022. The third AI\
    \ summer: AAAI Robert S. Engelmore Memorial Lecture. *AI Magazine*, 43(1): 105–\
    \ 125.\n\nKelly, J.; Calderwood, A.; Wardrip-Fruin, N.; and Mateas, M. 2023. There\
    \ and back again: extracting formal domains for controllable neurosymbolic story\
    \ authoring. In *Proceedings of the AAAI Conference on Artificial Intelligence\
    \ and Interactive Digital Entertainment*, volume 19, 64–74.\n\nKim, G.; Kim, T.;\
    \ Kannan, S. S.; Venkatesh, V. L.; Kim, D.; and Min, B.-C. 2023. DynaCon: Dynamic\
    \ Robot Planner with Contextual Awareness via LLMs. *arXiv preprint arXiv:2309.16031*.\n\
    \nKirk, J. R.; Wray, R. E.; and Laird, J. E. 2023. Exploiting Language Models\
    \ as a Source of Knowledge for Cognitive Agents. *arXiv preprint arXiv:2310.06846*.\n\
    \nLenat, D.; and Marcus, G. 2023. Getting from generative ai to trustworthy ai:\
    \ What llms might learn from cyc. *arXiv preprint arXiv:2308.04445*.\n\nLi, M.;\
    \ Song, F.; Yu, B.; Yu, H.; Li, Z.; Huang, F.; and Li, Y. 2023a. Api-bank: A benchmark\
    \ for tool-augmented llms. *arXiv preprint arXiv:2304.08244*.\n\nLi, Y.; Kamra,\
    \ N.; Desai, R.; and Halevy, A. 2023b. Human-Centered Planning. *arXiv preprint\
    \ arXiv:2311.04403*.\n\nLin, B. Y.; Fu, Y.; Yang, K.; Ammanabrolu, P.; Brahman,\
    \ F.; Huang, S.; Bhagavatula, C.; Choi, Y.; and Ren, X. 2023a. SwiftSage: A Generative\
    \ Agent with Fast and Slow Thinking for Complex Interactive Tasks. *arXiv preprint\
    \ arXiv:2305.17390*.\n\nLin, H.; Zala, A.; Cho, J.; and Bansal, M. 2023b. Videodirectorgpt:\
    \ Consistent multi-scene video generation via llmguided planning. *arXiv preprint\
    \ arXiv:2309.15091*.\n\nLin, K.; Agia, C.; Migimatsu, T.; Pavone, M.; and Bohg,\
    \ J. 2023c. Text2motion: From natural language instructions to feasible plans.\
    \ *arXiv preprint arXiv:2303.12153*.\n\nLiu, B.; Jiang, Y.; Zhang, X.; Liu, Q.;\
    \ Zhang, S.; Biswas, J.; and Stone, P. 2023. Llm+ p: Empowering large language\
    \ models with optimal planning proficiency. *arXiv preprint arXiv:2304.11477*.\n\
    \nLiu, Z.; Bahety, A.; and Song, S. 2023. Reflect: Summarizing robot experiences\
    \ for failure explanation and correction. *arXiv preprint arXiv:2306.15724*.\n\
    \nLogeswaran, L.; Sohn, S.; Lyu, Y.; Liu, A. Z.; Kim, D.- K.; Shim, D.; Lee, M.;\
    \ and Lee, H. 2023. Code Models are Zero-shot Precondition Reasoners. *arXiv preprint\
    \ arXiv:2311.09601*.\n\nLu, P.; Peng, B.; Cheng, H.; Galley, M.; Chang, K.-W.;\
    \ Wu, Y. N.; Zhu, S.-C.; and Gao, J. 2023a. Chameleon: Plug-andplay compositional\
    \ reasoning with large language models. *arXiv preprint arXiv:2304.09842*.\n\n\
    Lu, Y.; Feng, W.; Zhu, W.; Xu, W.; Wang, X. E.; Eckstein, M.; and Wang, W. Y.\
    \ 2022. Neuro-symbolic causal language planning with commonsense prompting. *arXiv\
    \ eprints*, arXiv–2206.\n\nLu, Y.; Lu, P.; Chen, Z.; Zhu, W.; Wang, X. E.; and\
    \ Wang, W. Y. 2023b. Multimodal Procedural Planning via Dual Text-Image Prompting.\
    \ *arXiv preprint arXiv:2305.01795*.\n\nLuo, L.; Li, Y.-F.; Haffari, G.; and Pan,\
    \ S. 2023. Reasoning on graphs: Faithful and interpretable large language model\
    \ reasoning. *arXiv preprint arXiv:2310.01061*.\n\nMandi, Z.; Jain, S.; and Song,\
    \ S. 2023. Roco: Dialectic multi-robot collaboration with large language models.\
    \ *arXiv preprint arXiv:2307.04738*.\n\nMcDermott, D.; Ghallab, M.; Howe, A.;\
    \ Knoblock, C.; Ram, A.; Veloso, M.; Weld, D.; and Wilkins, D. 1998. PDDL-the\
    \ planning domain definition language.\n\nMomennejad, I.; Hasanbeig, H.; Vieira,\
    \ F.; Sharma, H.; Ness, R. O.; Jojic, N.; Palangi, H.; and Larson, J. 2023. Evaluating\
    \ Cognitive Maps and Planning in Large Language Models with CogEval. *arXiv preprint\
    \ arXiv:2309.15129*.\n\nNaik, R.; Chandrasekaran, V.; Yuksekgonul, M.; Palangi,\
    \ H.; and Nushi, B. 2023. Diversity of Thought Improves Reasoning Abilities of\
    \ Large Language Models. *arXiv preprint arXiv:2310.07088*.\n\nNottingham, K.;\
    \ Ammanabrolu, P.; Suhr, A.; Choi, Y.; Hajishirzi, H.; Singh, S.; and Fox, R.\
    \ 2023. Do embodied agents dream of pixelated sheep?: Embodied decision making\
    \ using language guided world modelling. *arXiv preprint arXiv:2301.12050*.\n\n\
    Pallagani, V.; Muppasani, B.; Murugesan, K.; Rossi, F.; Horesh, L.; Srivastava,\
    \ B.; Fabiano, F.; and Loreggia, A. 2022. Plansformer: Generating symbolic plans\
    \ using transformers. *arXiv preprint arXiv:2212.08681*.\n\nPallagani, V.; Muppasani,\
    \ B.; Murugesan, K.; Rossi, F.; Srivastava, B.; Horesh, L.; Fabiano, F.; and Loreggia,\
    \ A. 2023a. Understanding the Capabilities of Large Language Models for Automated\
    \ Planning. *arXiv preprint arXiv:2305.16151*.\n\nPallagani, V.; Muppasani, B.;\
    \ Srivastava, B.; Rossi, F.; Horesh, L.; Murugesan, K.; Loreggia, A.; Fabiano,\
    \ F.; Joseph, R.; Kethepalli, Y.; et al. 2023b. Plansformer Tool: Demonstrating\
    \ Generation of Symbolic Plans Using Transformers. In *IJCAI*, volume 2023, 7158–7162.\
    \ International Joint Conferences on Artificial Intelligence.\n\nPan, L.; Albalak,\
    \ A.; Wang, X.; and Wang, W. Y. 2023. Logic-lm: Empowering large language models\
    \ with symbolic solvers for faithful logical reasoning. *arXiv preprint arXiv:2305.12295*.\n\
    \nParakh, M.; Fong, A.; Simeonov, A.; Gupta, A.; Chen, T.; and Agrawal, P. 2023.\
    \ Human-Assisted Continual Robot Learning with Foundation Models. *arXiv preprint\
    \ arXiv:2309.14321*.\n\nRaimondo, S.; Pal, C.; Liu, X.; Vazquez, D.; and Palacios,\
    \ H. 2023. Improving Generalization in Task-oriented Dialogues with Workflows\
    \ and Action Plans. *arXiv preprint arXiv:2306.01729*.\n\nRajvanshi, A.; Sikka,\
    \ K.; Lin, X.; Lee, B.; Chiu, H.-P.; and Velasquez, A. 2023. Saynav: Grounding\
    \ large language models for dynamic planning to navigation in new environments.\
    \ *arXiv preprint arXiv:2309.04077*.\n\nRaman, S. S.; Cohen, V.; Rosen, E.; Idrees,\
    \ I.; Paulius, D.; and Tellex, S. 2022. Planning with large language models via\
    \ corrective re-prompting. In *NeurIPS 2022 Foundation Models for Decision Making\
    \ Workshop*.\n\nRana, K.; Haviland, J.; Garg, S.; Abou-Chakra, J.; Reid, I.; and\
    \ Suenderhauf, N. 2023. Sayplan: Grounding large language models using 3d scene\
    \ graphs for scalable task planning. *arXiv preprint arXiv:2307.06135*.\n\nRen,\
    \ A. Z.; Dixit, A.; Bodrova, A.; Singh, S.; Tu, S.; Brown, N.; Xu, P.; Takayama,\
    \ L.; Xia, F.; Varley, J.; et al. 2023. Robots that ask for help: Uncertainty\
    \ alignment for large language model planners. *arXiv preprint arXiv:2307.01928*.\n\
    \nRuan, J.; Chen, Y.; Zhang, B.; Xu, Z.; Bao, T.; Du, G.; Shi, S.; Mao, H.; Zeng,\
    \ X.; and Zhao, R. 2023. Tptu: Task planning and tool usage of large language\
    \ model-based ai agents. *arXiv preprint arXiv:2308.03427*.\n\nRussell, S.; and\
    \ Norvig, P. 2003. *Artificial Intelligence, A Modern Approach. Second Edition*.\n\
    \nSakib, M. S.; and Sun, Y. 2023. From Cooking Recipes to Robot Task Trees–Improving\
    \ Planning Correctness and Task Efficiency by Leveraging LLMs with a Knowledge\
    \ Network. *arXiv preprint arXiv:2309.09181*.\n\nSarkisyan, C.; Korchemnyi, A.;\
    \ Kovalev, A. K.; and Panov, A. I. 2023. Evaluation of Pretrained Large Language\
    \ Models in Embodied Planning Tasks. In *International Conference on Artificial\
    \ General Intelligence*, 222–232. Springer.\n\nSermanet, P.; Ding, T.; Zhao, J.;\
    \ Xia, F.; Dwibedi, D.; Gopalakrishnan, K.; Chan, C.; Dulac-Arnold, G.; Maddineni,\
    \ S.; Joshi, N. J.; et al. 2023. RoboVQA: Multimodal Long-Horizon Reasoning for\
    \ Robotics. *arXiv preprint arXiv:2311.00899*.\n\nShah, D.; Equi, M.; Osinski,\
    \ B.; Xia, F.; Ichter, B.; and Levine, S. 2023. Navigation with large language\
    \ models: Semantic guesswork as a heuristic for planning. *arXiv preprint arXiv:2310.10103*.\n\
    \nShen, Y.; Song, K.; Tan, X.; Li, D.; Lu, W.; and Zhuang, Y. 2023. Hugginggpt:\
    \ Solving ai tasks with chatgpt and its friends in huggingface. *arXiv preprint\
    \ arXiv:2303.17580*.\n\nShirai, K.; Beltran-Hernandez, C. C.; Hamaya, M.; Hashimoto,\
    \ A.; Tanaka, S.; Kawaharazuka, K.; Tanaka, K.; Ushiku, Y.; and Mori, S. 2023.\
    \ Vision-Language Interpreter for Robot Task Planning. *arXiv preprint arXiv:2311.00967*.\n\
    \nSilver, T.; Dan, S.; Srinivas, K.; Tenenbaum, J. B.; Kaelbling, L. P.; and Katz,\
    \ M. 2023. Generalized Planning in PDDL Domains with Pretrained Large Language\
    \ Models. *arXiv preprint arXiv:2305.11014*.\n\nSilver, T.; Hariprasad, V.; Shuttleworth,\
    \ R. S.; Kumar, N.; Lozano-Perez, T.; and Kaelbling, L. P. 2022. PDDL plan- ´\
    \ ning with pretrained large language models. In *NeurIPS 2022 Foundation Models\
    \ for Decision Making Workshop*.\n\nSingh, I.; Blukis, V.; Mousavian, A.; Goyal,\
    \ A.; Xu, D.; Tremblay, J.; Fox, D.; Thomason, J.; and Garg, A. 2023. ProgPrompt:\
    \ program generation for situated robot task planning using large language models.\
    \ *Autonomous Robots*, 1–14.\n\nSong, C. H.; Wu, J.; Washington, C.; Sadler, B.\
    \ M.; Chao, W.-L.; and Su, Y. 2023. Llm-planner: Few-shot grounded planning for\
    \ embodied agents with large language models. In *Proceedings of the IEEE/CVF\
    \ International Conference on Computer Vision*, 2998–3009.\n\nSumers, T.; Yao,\
    \ S.; Narasimhan, K.; and Griffiths, T. L. 2023. Cognitive architectures for language\
    \ agents. *arXiv preprint arXiv:2309.02427*.\n\nSun, H.; Zhuang, Y.; Kong, L.;\
    \ Dai, B.; and Zhang, C. 2023. AdaPlanner: Adaptive Planning from Feedback with\
    \ Language Models. *arXiv preprint arXiv:2305.16653*.\n\nTang, X.; Zheng, Z.;\
    \ Li, J.; Meng, F.; Zhu, S.-C.; Liang, Y.; and Zhang, M. 2023. Large Language\
    \ Models are In-Context Semantic Reasoners rather than Symbolic Reasoners. *arXiv\
    \ preprint arXiv:2305.14825*.\n\nValmeekam, K.; Marquez, M.; and Kambhampati,\
    \ S. 2023. Can Large Language Models Really Improve by Self-critiquing Their Own\
    \ Plans? *arXiv preprint arXiv:2310.08118*.\n\nValmeekam, K.; Marquez, M.; Olmo,\
    \ A.; Sreedharan, S.; and Kambhampati, S. 2023a. PlanBench: An Extensible Benchmark\
    \ for Evaluating Large Language Models on Planning and Reasoning about Change.\
    \ In *Thirty-seventh Conference on Neural Information Processing Systems Datasets\
    \ and Benchmarks Track*.\n\nValmeekam, K.; Olmo, A.; Sreedharan, S.; and Kambhampati,\
    \ S. 2022. Large Language Models Still Can't Plan (A Benchmark for LLMs on Planning\
    \ and Reasoning about Change). *arXiv preprint arXiv:2206.10498*.\n\nValmeekam,\
    \ K.; Sreedharan, S.; Marquez, M.; Olmo, A.; and Kambhampati, S. 2023b. On the\
    \ planning abilities of large language models (a critical investigation with a\
    \ proposed benchmark). *arXiv preprint arXiv:2302.06706*.\n\nWang, J.; Tong, J.;\
    \ Tan, K.; Vorobeychik, Y.; and Kantaros, Y. 2023a. Conformal Temporal Logic Planning\
    \ using Large Language Models: Knowing When to Do What and When to Ask for Help.\
    \ *arXiv preprint arXiv:2309.10092*.\n\nWang, L.; Xu, W.; Lan, Y.; Hu, Z.; Lan,\
    \ Y.; Lee, R. K.-W.; and Lim, E.-P. 2023b. Plan-and-solve prompting: Improving\
    \ zero-shot chain-of-thought reasoning by large language models. *arXiv preprint\
    \ arXiv:2305.04091*.\n\nWang, X.; Caccia, L.; Ostapenko, O.; Yuan, X.; and Sordoni,\
    \ A. 2023c. Guiding language model reasoning with planning tokens. *arXiv preprint\
    \ arXiv:2310.05707*.\n\nWang, Z.; Cai, S.; Liu, A.; Ma, X.; and Liang, Y. 2023d.\
    \ Describe, explain, plan and select: Interactive planning with large language\
    \ models enables open-world multi-task agents. *arXiv preprint arXiv:2302.01560*.\n\
    \nWebb, T.; Mondal, S. S.; Wang, C.; Krabach, B.; and Momennejad, I. 2023. A Prefrontal\
    \ Cortex-inspired Architecture for Planning in Large Language Models. *arXiv preprint\
    \ arXiv:2310.00194*.\n\nWei, L.; He, Z.; Zhao, H.; and Yao, Q. 2023. Unleashing\
    \ the Power of Graph Learning through LLM-based Autonomous Agents. *arXiv preprint\
    \ arXiv:2309.04565*.\n\nWong, L.; Grand, G.; Lew, A. K.; Goodman, N. D.; Mansinghka,\
    \ V. K.; Andreas, J.; and Tenenbaum, J. B. 2023. From Word Models to World Models:\
    \ Translating from Natural Language to the Probabilistic Language of Thought.\
    \ *arXiv preprint arXiv:2306.12672*.\n\nWu, Y.; Min, S. Y.; Bisk, Y.; Salakhutdinov,\
    \ R.; Azaria, A.; Li, Y.; Mitchell, T.; and Prabhumoye, S. 2023a. Plan, Eliminate,\
    \ and Track–Language Models are Good Teachers for Embodied Agents. *arXiv preprint\
    \ arXiv:2305.02412*.\n\nWu, Z.; Ai, B.; and Hsu, D. 2023. Integrating Common Sense\
    \ and Planning with Large Language Models for Room Tidying. In *RSS 2023 Workshop\
    \ on Learning for Task and Motion Planning*.\n\nWu, Z.; Wang, Z.; Xu, X.; Lu,\
    \ J.; and Yan, H. 2023b. Embodied task planning with large language models. *arXiv\
    \ preprint arXiv:2307.01848*.\n\nXie, Y.; Yu, C.; Zhu, T.; Bai, J.; Gong, Z.;\
    \ and Soh, H. 2023. Translating natural language to planning goals with largelanguage\
    \ models. *arXiv preprint arXiv:2302.05128*.\n\nXu, B.; Liu, X.; Shen, H.; Han,\
    \ Z.; Li, Y.; Yue, M.; Peng, Z.; Liu, Y.; Yao, Z.; and Xu, D. 2023a. Gentopia:\
    \ A collaborative platform for tool-augmented llms. *arXiv preprint arXiv:2308.04030*.\n\
    \nXu, L. 1995. Case based reasoning. *IEEE Potentials*, 13(5): 10–13.\n\nXu, M.;\
    \ Huang, P.; Yu, W.; Liu, S.; Zhang, X.; Niu, Y.; Zhang, T.; Xia, F.; Tan, J.;\
    \ and Zhao, D. 2023b. Creative Robot Tool Use with Large Language Models. *arXiv\
    \ preprint arXiv:2310.13065*.\n\nYang, J.; Chen, X.; Qian, S.; Madaan, N.; Iyengar,\
    \ M.; Fouhey, D. F.; and Chai, J. 2023a. LLM-Grounder: Open-Vocabulary 3D Visual\
    \ Grounding with Large Language Model as an Agent. *arXiv preprint arXiv:2309.12311*.\n\
    \nYang, R.; Hou, M.; Wang, J.; and Zhang, F. 2023b. Ocean-Chat: Piloting Autonomous\
    \ Underwater Vehicles in Natural Language. *arXiv preprint arXiv:2309.16052*.\n\
    \nYang, Y.; Gaglione, J.-R.; and Topcu, U. 2022. Learning Automata-Based Task\
    \ Knowledge Representation from Large-Scale Generative Language Models. *arXiv\
    \ preprint arXiv:2212.01944*.\n\nYang, Y.; and Tomar, A. 2023. On the Planning,\
    \ Search, and Memorization Capabilities of Large Language Models. *arXiv preprint\
    \ arXiv:2309.01868*.\n\nYang, Z. 2023. *Neuro-Symbolic AI Approaches to Enhance\
    \ Deep Neural Networks with Logical Reasoning and Knowledge Integration*. Ph.D.\
    \ thesis, Arizona State University.\n\nYang, Z.; Ishay, A.; and Lee, J. 2023.\
    \ Coupling Large Language Models with Logic Programming for Robust and General\
    \ Reasoning from Text. *arXiv preprint arXiv:2307.07696*.\n\nYao, S.; Yu, D.;\
    \ Zhao, J.; Shafran, I.; Griffiths, T. L.; Cao, Y.; and Narasimhan, K. 2023. Tree\
    \ of thoughts: Deliberate problem solving with large language models. *arXiv preprint\
    \ arXiv:2305.10601*.\n\nYoneda, T.; Fang, J.; Li, P.; Zhang, H.; Jiang, T.; Lin,\
    \ S.; Picker, B.; Yunis, D.; Mei, H.; and Walter, M. R. 2023. Statler: State-maintaining\
    \ language models for embodied reasoning. *arXiv preprint arXiv:2306.17840*.\n\
    \nYou, W.; Wu, W.; Liang, Y.; Mao, S.; Wu, C.; Cao, M.; Cai, Y.; Guo, Y.; Xia,\
    \ Y.; Wei, F.; et al. 2023. EIPE-text: Evaluation-Guided Iterative Plan Extraction\
    \ for Long-Form Narrative Text Generation. *arXiv preprint arXiv:2310.08185*.\n\
    \nYuan, H.; Zhang, C.; Wang, H.; Xie, F.; Cai, P.; Dong, H.; and Lu, Z. 2023a.\
    \ Plan4mc: Skill reinforcement learning and planning for open-world minecraft\
    \ tasks. *arXiv preprint arXiv:2303.16563*.\n\nYuan, S.; Chen, J.; Fu, Z.; Ge,\
    \ X.; Shah, S.; Jankowski, C. R.; Yang, D.; and Xiao, Y. 2023b. Distilling Script\
    \ Knowledge from Large Language Models for Constrained Language Planning. *arXiv\
    \ preprint arXiv:2305.05252*.\n\nZelikman, E.; Huang, Q.; Poesia, G.; Goodman,\
    \ N.; and Haber, N. 2023. Parsel: Algorithmic Reasoning with Language Models by\
    \ Composing Decompositions. In *Thirtyseventh Conference on Neural Information\
    \ Processing Systems*.\n\nZhang, B.; and Soh, H. 2023. Large language models as\
    \ zero-shot human models for human-robot interaction. *arXiv preprint arXiv:2303.03548*.\n\
    \nZhang, C.; Liu, L.; Wang, J.; Wang, C.; Sun, X.; Wang, H.; and Cai, M. 2023a.\
    \ Prefer: Prompt ensemble learning via feedback-reflect-refine. *arXiv preprint\
    \ arXiv:2308.12033*.\n\nZhang, F.; Jin, K.; and Zhuo, H. H. 2023. Planning with\
    \ Logical Graph-based Language Model for Instruction Generation. arXiv:2308.13782.\n\
    \nZhang, H.; Du, W.; Shan, J.; Zhou, Q.; Du, Y.; Tenenbaum, J. B.; Shu, T.; and\
    \ Gan, C. 2023b. Building cooperative embodied agents modularly with large language\
    \ models. *arXiv preprint arXiv:2307.02485*.\n\nZhang, J.; Zhang, J.; Pertsch,\
    \ K.; Liu, Z.; Ren, X.; Chang, M.; Sun, S.-H.; and Lim, J. J. 2023c. Bootstrap\
    \ your own skills: Learning to solve new tasks with large language model guidance.\
    \ *arXiv preprint arXiv:2310.10021*.\n\nZhao, Z.; Lee, W. S.; and Hsu, D. 2023.\
    \ Large Language Models as Commonsense Knowledge for Large-Scale Task Planning.\
    \ *arXiv preprint arXiv:2305.14078*.\n\nZheng, L.; Chiang, W.-L.; Sheng, Y.; Zhuang,\
    \ S.; Wu, Z.; Zhuang, Y.; Lin, Z.; Li, Z.; Li, D.; Xing, E. P.; Zhang, H.; Gonzalez,\
    \ J. E.; and Stoica, I. 2023a. Judging LLM-as-a-judge with MT-Bench and Chatbot\
    \ Arena. arXiv:2306.05685.\n\nZheng, S.; Liu, J.; Feng, Y.; and Lu, Z. 2023b.\
    \ Steve-Eye: Equipping LLM-based Embodied Agents with Visual Perception in Open\
    \ Worlds. *arXiv preprint arXiv:2310.13255*.\n\nZhou, Z.; Song, J.; Yao, K.; Shu,\
    \ Z.; and Ma, L. 2023. ISR-LLM: Iterative Self-Refined Large Language Model for\
    \ Long-Horizon Sequential Task Planning. *arXiv preprint arXiv:2308.13724*."
- id: training_and_serving_system_of_foundation_models_a_comprehensive_survey_school_of_systems_science_and_engineering_sun_yat_sen_university_guangzhou_528406_china_school_of_software_engineering_sun_yat_sen_university_guangzhou_510275_china_department_of_computing_in_the_hong_kong_polytechnic_university_hong_kong_999077_china_peng_cheng_laboratory_shenzhen_518000_china
  title: 'Training and Serving System of Foundation Models: A Comprehensive Survey'
  abstract: 'Foundation models (e.g., ChatGPT, DALL-E, PengCheng Mind, PanGu-$\Sigma$)

    have demonstrated extraordinary performance in key technological areas, such as

    natural language processing and visual recognition, and have become the

    mainstream trend of artificial general intelligence. This has led more and more

    major technology giants to dedicate significant human and financial resources

    to actively develop their foundation model systems, which drives continuous

    growth of these models'' parameters. As a result, the training and serving of

    these models have posed significant challenges, including substantial computing

    power, memory consumption, bandwidth demands, etc. Therefore, employing

    efficient training and serving strategies becomes particularly crucial. Many

    researchers have actively explored and proposed effective methods. So, a

    comprehensive survey of them is essential for system developers and

    researchers. This paper extensively explores the methods employed in training

    and serving foundation models from various perspectives. It provides a detailed

    categorization of these state-of-the-art methods, including finer aspects such

    as network, computing, and storage. Additionally, the paper summarizes the

    challenges and presents a perspective on the future development direction of

    foundation model systems. Through comprehensive discussion and analysis, it

    hopes to provide a solid theoretical basis and practical guidance for future

    research and applications, promoting continuous innovation and development in

    foundation model systems.'
  url: http://arxiv.org/abs/2401.02643v1
  keywords: '* Foundation Model System, Training, Serving, Network, Computing, Storage'
  document: '![](_page_0_Picture_0.jpeg)


    Received XX Month, XXXX; revised XX Month, XXXX; accepted XX Month, XXXX; Date
    of publication XX Month, XXXX; date of current version XX Month, XXXX.


    *Digital Object Identifier 10.1109/OJIM.2022.1234567*


    # **Training and Serving System of Foundation Models: A Comprehensive Survey**


    **JIAHANG ZHOU<sup>1</sup> , YANYU CHEN<sup>1</sup> , ZICONG HONG<sup>3</sup>
    , WUHUI CHEN2, 4, YUE YU<sup>4</sup> , TAO ZHANG<sup>1</sup> , HUI WANG<sup>4</sup>
    , CHUANFU ZHANG<sup>1</sup> , AND ZIBIN ZHENG<sup>2</sup> .**


    > School of Systems Science and Engineering, Sun Yat-sen University, Guangzhou,
    528406, China School of Software Engineering, Sun Yat-sen University, Guangzhou,
    510275, China Department of Computing in The Hong Kong Polytechnic University,
    Hong Kong, 999077, China Peng Cheng Laboratory, Shenzhen, 518000, China


    CORRESPONDING AUTHOR: Wuhui Chen (e-mail: chenwuh@mail.sysu.edu.cn).


    **ABSTRACT** Foundation models (e.g., ChatGPT, DALL-E, PengCheng Mind, PanGu-Σ)
    have demonstrated extraordinary performance in key technological areas, such as
    natural language processing and visual recognition, and have become the mainstream
    trend of artificial general intelligence. This has led more and more major technology
    giants to dedicate significant human and financial resources to actively develop
    their foundation model systems, which drives continuous growth of these models''
    parameters. As a result, the training and serving of these models have posed significant
    challenges, including substantial computing power, memory consumption, bandwidth
    demands, etc. Therefore, employing efficient training and serving strategies becomes
    particularly crucial. Many researchers have actively explored and proposed effective
    methods. So, a comprehensive survey of them is essential for system developers
    and researchers. This paper extensively explores the methods employed in training
    and serving foundation models from various perspectives. It provides a detailed
    categorization of these state-of-the-art methods, including finer aspects such
    as network, computing, and storage. Additionally, the paper summarizes the challenges
    and presents a perspective on the future development direction of foundation model
    systems. Through comprehensive discussion and analysis, it hopes to provide a
    solid theoretical basis and practical guidance for future research and applications,
    promoting continuous innovation and development in foundation model systems.


    **INDEX TERMS** Foundation Model System, Training, Serving, Network, Computing,
    Storage


    #### **I. INTRODUCTION**


    T He combination of deep learning techniques and powerful computational capabilities
    continuously drives the development of artificial general intelligence, ushering
    us into the era of foundation models. However, achieving successful applications
    of foundation models is inseparable from comprehensive support at the system level.
    A foundation model system is built upon extensive training data, state-ofthe-art
    models, high-performance computing resources, and meticulously optimized training
    and serving algorithms. The primary purpose of this system is to handle complex
    tasks with heightened precision, such as GPT3 [\[1\]](#page-10-0), LLaMA [\[2\]](#page-10-1),
    PanGu-Σ [\[3\]](#page-10-2), PengCheng Mind [\[4\]](#page-10-3) etc.


    Foundation models have demonstrated extraordinary performance in many tasks. This
    has led more and more major technology giants to dedicate significant human and
    financial resources to actively develop their foundation model systems, which
    increases the parameter size (Figure [1\)](#page-1-0). However, as the parameter
    size of foundational model systems continues to grow, challenges are posed throughout
    the lifecycle of foundation models, particularly during the training and serving
    phases. In the training phase, the substantial parameter size results in significant
    demands for computation and storage, creating immense pressure on hardware resources
    and computational efficiency. Consequently, training these models usually takes
    a long time and requires efficient utilization of computational resources. In
    the serving phase, with the widespread application of foundation models, the significant
    increase in workload has become an unavoidable challenge. This heightened demand
    may lead to issues for serving systems, such as latency, performance decline,
    or resource bottlenecks. Therefore, employing highly efficient


    ![](_page_1_Figure_1.jpeg)


    <span id="page-1-0"></span>**FIGURE 1. Evolutionary Chart of Model Sizes Over
    Time.**


    <span id="page-1-1"></span>**FIGURE 2. The lifecycle of the foundation model system.**


    training and serving strategies becomes particularly crucial. Many researchers
    have actively explored and proposed effective methods for training and serving.
    However, different approaches have different application scenarios. So, it poses
    a challenge for system developers who struggle to identify the most suitable method
    for their problems. This challenge is precisely why this paper was proposed.


    Although there have been some surveys on foundation models, Most surveys [\[5\]](#page-10-4)–[\[11\]](#page-10-5)
    predominantly focus on model design and downstream task adaptation, with only
    a minority delving into foundation model training. However, there are two notable
    shortcomings in these training-centric surveys [\[12\]](#page-10-6): firstly,
    they lack in-depth exploration from the perspective of updates in network, computing,
    and storage; secondly, their primary emphasis is on the training phase, neglecting
    considerations for the serving phase. Therefore, a comprehensive survey of foundation
    model training and serving methods is essential for system developers and researchers.
    Accordingly, this paper presents an in-depth analysis of the state-of-the-art
    methods in this domain. This paper provides systems developers and researchers
    valuable information through comprehensive analysis and comparison. It assists
    them in making the right decisions when confronted with the challenges associated
    with foundation model systems. evaluation and fine-tuning involve assessing performance
    Training Dataset Foundation model


    ## **II. BASIC CONCEPTS**


    This section comprehensively explains the fundamental concepts in foundation model
    systems.


    #### *A. The lifecycle of the foundation model system*


    The lifecycle of the foundation model system (Figure [2\)](#page-1-1) encompasses
    several crucial stages. ➊ Initially, the collection and preprocessing of data
    ensure the quality and availability required for model training. Subsequently,
    choosing an appropriate model. ➋ Transitioning to the training phase, the model
    undergoes adjustments through the backpropagation algorithm, demanding substantial
    computational resources to enhance its fitting capability to the training data.
    ➌ Model


    with test data and adjusting for improved generalization. Once the model performs
    satisfactorily, it can be deployed into practical applications. ➍ In the serving
    stage, effective deployment and integration are crucial to ensuring harmonious
    collaboration with existing systems. The primary focus in this phase centers on
    performance optimization, aiming to enhance serving speed and reduce latency through
    strategies such as model quantization and hardware acceleration.


    ## *B. Transformer for foundation models*


    Transformer [\[13\]](#page-10-7) is a deep learning model architecture comprised
    of encoders and decoders. Its core innovation lies in the self-attention mechanism,
    an important component widely utilized in foundational models. The main idea is
    to enable the model to focus on dynamic associations between different positions,
    thereby better capturing long-distance interdependent features in a sentence.
    In the current field of deep learning, the Transformer architecture has become
    the preferred choice for numerous foundational models. This architecture stands
    out for its outstanding performance and flexibility, particularly in excelling
    at natural language processing tasks [\[14\]](#page-10-8). Many pivotal foundational
    models, such as GPT, LLaMA, and PengCheng Mind, have adopted the design of the
    Transformer. The successful applications of the Transformer architecture demonstrate
    its universality in foundational models, providing powerful modeling tools for
    various tasks.


    #### **III. MODEL TRAINING**


    In foundation model training, the most significant challenges are the high demands
    for memory and computational power. Therefore, this section explores the implementation
    of optimization strategies in foundation model training from three perspectives,
    network, computing, and storage, to address these challenges, as shown in Table
    [1.](#page-2-0)


    ## *A. Advanced Techniques in Parallel Computing*


    1) Data Parallelism: Accelerating Workloads Effectively


    In data parallelism, each computational node possesses a replica of the model
    and independently processes a subset


    ![](_page_2_Picture_0.jpeg)


    | Parallel Computing                                                                                   |                               |      |                                                                     |                           |               |  |  |

    |------------------------------------------------------------------------------------------------------|-------------------------------|------|---------------------------------------------------------------------|---------------------------|---------------|--|--|

    | Parallelism Type                                                                                     |
    Specific Strategy             | Year | Main Features                                                       |
    Scales (M, B, 10B, 100B+) | Open Resource |  |  |

    | Data Parallelism                                                                                     |
    DDP [15]                      | 2020 | Bucketing gradients, Skipping gradient
    synchronization              | M                         | ✓             |  |  |

    |                                                                                                      |
    Xu et al. [18]                | 2020 | Automatic cross-replica sharding                                    |
    M                         | ×             |  |  |

    |                                                                                                      |
    FSDP [17]                     | 2023 | Fully sharded data parallel                                         |
    100B+                     | ✓             |  |  |

    | Tensor Parallelism                                                                                   |
    Megatron-LM [19]              | 2021 | Weight matrix partitioned                                           |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    Optimus [20]                  | 2023 | Scalable 2D-partition paradigm                                      |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    Tesseract [22]                | 2023 | 2.5-Dimensional Matrix Multiplication                               |
    B                         | ×             |  |  |

    |                                                                                                      |
    3D Tensor Parallelism [24]    | 2021 | 3-dimensional model parallelism, Perfect
    load balance               | M                         | ×             |  |  |

    | Pipeline Parallelism                                                                                 |
    GPipe [25]                    | 2019 | Novel batchsplitting pipelining                                     |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    PipeDream [26]                | 2019 | 1F1B, Weight stashing, Vertical sync                                |
    M                         | ×             |  |  |

    |                                                                                                      |
    Megatron-LM [19]              | 2021 | Schedule with Interleaved Stages                                    |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    Chimera [30]                  | 2021 | Bidirectional pipelines                                             |
    B                         | ✓             |  |  |

    |                                                                                                      |
    PipeDream-2BM [29]            | 2021 | Memory-efficient pipeline parallelism                               |
    B                         | ×             |  |  |

    |                                                                                                      |
    FTPipe [37]                   | 2021 | Mixed-pipe partitioning, Recomputation                              |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    DAPPLE [28]                   | 2022 | Synchronous training                                                |
    B                         | ×             |  |  |

    |                                                                                                      |
    Varuna [27]                   | 2022 | Recomputation                                                       |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    Hanayo [31]                   | 2023 | Wave-like pipeline                                                  |
    100B+                     | ×             |  |  |

    |                                                                                                      |
    Mixpipe [32]                  | 2023 | Mixed scheduling, Flexible bidirectional
    pipeline                   | 10B                       | ×             |  |  |

    |                                                                                                      |
    Avgpipe [33]                  | 2023 | Elastic averaging training method                                   |
    M                         | ×             |  |  |

    |                                                                                                      |
    Bpipe [35]                    | 2023 | Activation balancing                                                |
    100B+                     | ×             |  |  |

    |                                                                                                      |
    Bamboo [36]                   | 2023 | Redundant computation, Use of preemptible
    instances                 | M                         | ×             |  |  |

    |                                                                                                      |
    Dynapipe [34]                 | 2024 | Dynamic micro-batching                                              |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    GShard [38]                   | 2021 | Sparsely-Gated Mixture-of-Experts                                   |
    100B+                     | ×             |  |  |

    |                                                                                                      |
    FastMoE [40]                  | 2021 | Open-source system based on PyTorch                                 |
    100B+                     | ✓             |  |  |

    | Expert Parallelism                                                                                   |
    FasterMoE [42]                | 2022 | Dynamic shadowing method, Novel roofline-like
    model                 | B                         | ✓             |  |  |

    |                                                                                                      |
    Lina [44]                     | 2023 | Tensor partitioning, Two-phase scheduling                           |
    B                         | ×             |  |  |

    |                                                                                                      |
    Janus [45]                    | 2023 | Data-centric paradigm                                               |
    M                         | ×             |  |  |

    |                                                                                                      |
    SmartMoE [43]                 | 2023 | Expert placement strateg                                            |
    10B                       | ×             |  |  |

    |                                                                                                      |
    Alpa [48]                     | 2022 | Two-level parallel execution, ILP Formulation                       |
    100B+                     | ✓             |  |  |

    | Hybrid Parallelism                                                                                   |
    Smith et al. [46]             | 2022 | 3D parallelism methodology                                          |
    100B+                     | ×             |  |  |

    |                                                                                                      |
    Galvatron [49]                | 2022 | Decision tree approach                                              |
    10B                       | ✓             |  |  |

    | GPU Memory Optimization                                                                              |                               |      |                                                                     |                           |               |  |  |

    | Specific Strategy<br>Main Features<br>Scales (M, B, 10B, 100B+)<br>Open Resource<br>Category<br>Year
    |                               |      |                                                                     |                           |               |  |  |

    |                                                                                                      |
    Chen et al. [50]              | 2016 | Checkpointing, Recomputation                                        |
    M                         | ×             |  |  |

    | Checkpointing and Recomputation                                                                      |
    Checkmate [51]                | 2022 | Integer linear program                                              |
    M                         | ✓             |  |  |

    | Mixed Precision Training                                                                             |
    Mixed Precision Training [52] | 2018 | Mixed precision                                                     |
    M                         | ×             |  |  |

    |                                                                                                      |
    Jia et al. [53]               | 2018 | LARS algorithm                                                      |
    M                         | ×             |  |  |

    | Memory Swapping                                                                                      |
    SwapAdvisor [56]              | 2020 | Enetic algorithms                                                   |
    M                         | ×             |  |  |

    |                                                                                                      |
    Autotm [57]                   | 2020 | Integer linear programming                                          |
    M                         | ✓             |  |  |

    |                                                                                                      |
    FlashNeuron [59]              | 2021 | SSDs for data offloading and prefetching                            |
    B                         | ✓             |  |  |

    |                                                                                                      |
    Stronghold [58]               | 2022 | Work window method                                                  |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    Patrickstar [62]              | 2022 | Chunks                                                              |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    G10 [61]                      | 2023 | Amalgamating GPU, host, flash memory into
    a unified memory space    | B                         | ✓             |  |  |

    |                                                                                                      |
    DeepUM [60]                   | 2023 | Enhances Unified Memory by prefetching
    techniques                   | B                         | ×             |  |  |

    | Zero Redundancy Optimization                                                                         |
    ZeRO [63]                     | 2020 | Zero Redundancy                                                     |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    ZeRO-Offload [64]             | 2021 | Parameters is offloaded to CPU memory                               |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    ZeRO-Infinity [66]            | 2021 | Parameters is offloaded to CPU, and NVMe
    memory                     | 100B+                     | ✓             |  |  |

    |                                                                                                      |                               |      |
    Communication Optimization                                          |                           |               |  |  |

    | Category                                                                                             |
    Specific Strategy             | Year | Main Features                                                       |
    Scales (M, B, 10B, 100B+) | Open Resource |  |  |

    | Communication Optimization                                                                           |
    Bagua [67]                    | 2021 | MPI-style communication library                                     |
    M                         | ✓             |  |  |

    |                                                                                                      |
    Out-Of-Order BackProp [70]    | 2022 | Out-Of-Order Computation                                            |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    ZeRO++ [71]                   | 2023 | Weight quantization                                                 |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    Wang et al. [68]              | 2023 | Decomposing the original communication
    and computational operations | 100B+                     | ×             |  |  |

    |                                                                                                      |
    Mobius [69]                   | 2023 | Cross-mapping strategy                                              |
    B                         | ×             |  |  |

    |                                                                                                      |
    Optimus-CC [73]               | 2023 | Compression                                                         |
    B                         | ×             |  |  |

    |                                                                                                      |
    COCKTAILSGD [72]              | 2023 | Communication compression                                           |
    10B                       | ×             |  |  |

    |                                                                                                      |                               |      |                                                                     |                           |               |  |  |


    #### <span id="page-2-0"></span>**TABLE 1. Overview of network, computing, and
    storage optimization strategies in foundation model training.**


    of data assigned to it. As shown in Figure [3a](#page-3-0), each node uses its
    model replica for forward and backward propagation and gradient calculation. So,
    it requires gradient aggregation and synchronization operations to update the
    global model parameters. This distributed approach significantly reduces the computational
    load on individual nodes and speeds up the training process by parallelizing the
    workload.


    Distributed Data Parallel (DDP) [\[15\]](#page-10-9) utilizes gradient bucketing,
    computation-communication overlap, and gradient synchronization skipping to enhance
    the efficiency of distributed data parallelism. The Ring-AllReduce method [\[16\]](#page-10-19)
    effectively addresses the communication load issue in data parallelism with its
    unique design. In this method, worker nodes are organized in a ring topology,
    communicating only with adjacent nodes. In the aforementioned data parallelism
    approach, storing the entire model''s parameters on each node simplifies training
    but significantly increases memory demand, especially for foundation models. To
    solve this problem, several solutions have been proposed. Facebook introduced
    a technique called Fully Sharded Data Parallel


    ![](_page_3_Figure_1.jpeg)


    <span id="page-3-0"></span>**FIGURE 3. Schematic diagram of parallelization strategies
    in foundation model systems. Different color blocks indicate different layers
    in the network.**


    (FSDP) [\[17\]](#page-10-11) to tackle this issue. It divides model parameters
    into smaller units, restoring the complete model parameters through communication
    before computation and discarding them immediately after the calculation. Similarly,
    Xu et al. [\[18\]](#page-10-10) proposed an automatic cross-replica sharding technique
    for weight updates in data-parallel training to optimize memory and communication
    efficiency during model training.


    #### 2) Tensor Parallelism: Scaling Foundation Models


    Tensor parallelism is developed to address the challenges of training foundation
    models that exceed the memory capacity of a single device. In tensor parallelism
    (As shown in Figure [3b](#page-3-0)), the parameters and computations of the model
    are divided (or sliced) across multiple computing devices, effectively reducing
    the memory load on each device.


    Megatron-LM [\[19\]](#page-10-12) introduced an efficient form of 1D tensor parallelism.
    For a given computational task, it involves two GEMM operations and a GeLU non-linearity:
    Y = GeLU(XA), Z = Y B. A can be partitioned into -A1, A<sup>2</sup> . So each
    processor can independently compute the Y<sup>i</sup> :


    $$

    [Y_1, Y_2] = [\text{GeLU}(XA_1), \text{GeLU}(XA_2)].

    $$


    The second weight matrix <sup>B</sup> can be split into B<sup>1</sup> B<sup>2</sup>
    , so Z is equal to -Y1, Y<sup>2</sup> B<sup>1</sup> B<sup>2</sup> . With this
    approach, YiB<sup>i</sup> can be computed separately on individual processors.
    In Transformer models, the method of 1D tensor parallelism is effectively applied
    to the computation of multi-head attention. This allows multiple processing units
    to simultaneously calculate different attention heads without waiting for the
    results of others.


    Optimus [\[20\]](#page-10-13) proposed an efficient and scalable 2D tensor parallelism.
    It is introduced based on the scalable universal matrix multiplication algorithm
    (SUMMA) [\[21\]](#page-10-20). Compared to 1D tensor parallelism, 2D parallelism
    distributes the computational load across more processing units, significantly
    enhancing overall computational efficiency. Although 2D parallelism offers a more
    fine-grained model partitioning approach, it can introduce higher communication
    overhead. To solve this, 2.5D tensor parallelism [\[22\]](#page-10-14) is introduced,
    building upon 2.5D matrix multiplication [\[23\]](#page-10-21), which leverages
    additional devices to minimize communication requirements.


    To balance computation, memory, and communication loads effectively, 3D tensor
    parallelism [\[24\]](#page-10-15) employs a 3-D Parallel Matrix Multiplication
    algorithm to accurately map and execute the computation process of the Transformer
    model. This algorithm optimizes the use of computational resources by intelligently
    distributing and computing different parts of the input and weight matrices on
    designated processors.


    # 3) Pipeline Parallelism: Enhancing Foundation Model Scalability


    In pipeline parallelism (Figure [3c](#page-3-0)), the entire model is divided
    into several stages, with each part allocated to an independent GPU. However,
    a typical issue in pipeline parallel processing is the idle time created due to
    waiting for dependent data or processing results, commonly referred to as the
    bubble phenomenon. Therefore, effectively reducing these bubbles to enhance GPU
    utilization in pipeline parallelism becomes a critical issue.


    GPipe [\[25\]](#page-10-16) is one of the first significant works to apply the
    concept of pipeline parallelism to the training of foundation models. However,
    GPipe requires waiting for each micro-batch to complete forward propagation before
    starting backward propagation, as shown in Figure [4a](#page-4-0). Therefore,
    the intermediate results (activations) produced during the forward computation
    of each micro-batch need to be cached in memory for subsequent backpropagation,
    resulting in increased memory usage. Meanwhile, this approach can also lead to
    the creation of a significant number of bubbles.


    So PipeDream [\[26\]](#page-10-17) utilizes a one-forward-one-backward (1F1B)
    strategy, as shown in Figure [4b](#page-4-0), to solve these problems, in which
    the backward propagation process immediately follows the completion of forward
    propagation for a micro-batch. However, this training mode introduces two types
    of parameter inconsistency. PipeDream utilizes weight stashing and vertical sync
    methods to address these issues. Varuna [\[27\]](#page-10-18) improves upon PipeDream
    by performing


    ![](_page_4_Picture_0.jpeg)


    ![](_page_4_Figure_1.jpeg)


    <span id="page-4-0"></span>**FIGURE 4. Schematic diagram of pipeline parallelization
    and 1F1B pipeline parallelization.**


    recomputation earlier during the backward pass, effectively reducing bubbles and
    memory usage. Meanwhile, similar to PipeDream, DAPPLE [\[28\]](#page-11-3) performs
    synchronization after completing the forward and backward propagation for microbatches.
    This synchronization ensures the consistency of model parameters across micro-batches,
    avoiding parameter inconsistency issues.


    PipeDream utilizes a weight storage scheme to use the same weight version in forward
    and backward propagation for the same input. In the worst case, the number of
    stored weight versions equals the pipeline depth. Therefore, this can result in
    increased memory consumption. PipeDream-2BM [\[29\]](#page-11-1) maintains only
    two versions of model weights within the pipeline. By storing only two versions,
    it significantly reduces memory usage. In Megatron-LM [\[19\]](#page-10-12), pipeline
    parallelism is implemented using an Interleaved Schedule approach. To reduce pipeline
    bubbles, the Interleaved Schedule method assigns each device to two sets of model
    chunks, allowing each device to handle multiple stages. By utilizing the idle
    time of devices that would otherwise be waiting for backward computation, it can
    perform forward computation for the second set of model chunks, effectively reducing
    the size of bubbles in the pipeline. In contrast, Chimera [\[30\]](#page-11-0)
    utilizes a bidirectional pipeline by deploying multiple stages of the model on
    a single GPU. Chimera minimizes idle time and maximizes GPU utilization by interleaving
    the computation of forward and backward propagation across different stages. Different
    from Chimera, Hanayo [\[31\]](#page-11-4) avoids the strategy of model replication.
    Instead, it employed a wave-like pipeline scheme, further reducing bubble rates
    and enhancing performance. Similarly employing a bidirectional pipeline, MixPipe
    [\[32\]](#page-11-5) achieves a better balance between pipeline and device utilization
    by adjusting the number of micro-batches. Additionally, MixPipe designs a hybrid
    scheduling strategy that combines 1F1B and 2F1B to achieve a more balanced memory
    usage, further decreasing bubble rates. To further reduce bubbles, AvgPipe [\[33\]](#page-11-6)
    employs the approach of multiple parallel pipelines, with each pipeline handling
    a batch of data in each iteration. It trains parallel models using an elastic
    averaging training method. By processing more batches, AvgPipe can subdivide each
    batch into finer-grained micro-batches, effectively reducing the generation of
    bubbles.


    In traditional pipelines, feeding a batch of samples with equal lengths into the
    GPU for training is common. In each batch, padding is applied to the input sequences
    to accommodate the length of the longest sequence, leading to evident memory wastage.
    Dynapipe [\[34\]](#page-11-9) introduces a method of dynamic micro-batching, where
    the core idea is to ensure consistent sequence lengths among samples within each
    micro-batch without requiring uniformity across microbatches. This approach reduces
    the padding overhead in micro-batch processing, effectively lowering memory consumption.
    To address memory balancing in the pipeline, Bpipe [\[35\]](#page-11-7) uses an
    activation balancing approach that ensures that all GPUs can fully utilize comparable
    amounts of memory by transferring intermediate activations between different GPUs
    during training. This innovation solves the problem that some GPUs may face high
    memory pressure while others fail to fully utilize the performance.


    The continuous growth of the foundation''s scale has triggered a substantial demand
    for training resources. In addressing this issue, Bamboo [\[36\]](#page-11-8)
    significantly reduces training costs by using preemptible instances optimally.
    When idle, these instances are available at a lower cost but may be preempted
    once users submit priority requests. Bamboo optimizes the training pipeline by
    introducing redundant computations to overcome this challenge. Specifically, each
    node performs computations not only on its layer but also on adjacent layers.
    Bamboo cleverly incorporates these additional computations into redundant layers,
    thus providing greater flexibility at a lower cost. The pipeline methods previously
    discussed primarily involve a simplistic partitioning of a model''s adjacent layers.
    This approach can lead to imbalanced workload distribution across GPUs. As an
    improvement, FTPipe [\[37\]](#page-11-2) introduces mixed-pipe partitioning technology.
    It employs a heuristic algorithm to allocate GPUs based on any computational blocks
    in the computation graph, not just adjacent layers.


    # 4) Expert Parallelism: Enhancing Specialized Computing Capabilities


    Expert parallelism, as depicted in Figure [3d](#page-3-0), involves segmenting
    a specific part of a model into several specialized sub-models, referred to as
    experts, and distributing them across various computational devices. A gating
    network is used to determine how to allocate input data efficiently among these
    different experts.


    Google''s GShard [\[38\]](#page-11-10) introduces the MoE [\[39\]](#page-11-40)
    structure for the first time in training foundation Transformer-based models,
    aiming to address scalability issues in foundation model training. To optimize
    the performance of the MoE model, FastMoE [\[40\]](#page-11-11) was proposed.
    It is the first highperformance MoE open-source system that supports the PyTorch
    [\[41\]](#page-11-41) framework. FastMoE pairs the FFN layer in the Transformer
    and adopts a finer parallelization strategy. This strategy significantly speeds
    up the computation of the FFN part of the Transformer model. During the training
    process of MoE systems, challenges such as dynamic load imbalance and congested
    end-to-end communication need to be addressed. To tackle these challenges, FasterMoE
    [\[42\]](#page-11-12) proposes a dynamic shadowing method to handle load imbalances.
    By dynamically adjusting task allocation and scheduling, system resources are
    utilized more evenly, improving overall efficiency.


    On the other hand, SmartMoE [\[43\]](#page-11-15) system provides comprehensive
    support for distributed training strategies. To address the dynamic computational
    workload of MoE models, the SmartMoE system introduces a unique expert placement
    strategy. Building upon the classic combination of parallel strategies, this strategy
    achieves dynamic load balancing. By intelligently adjusting the deployment positions
    of various experts in the model, the SmartMoE system effectively balances the
    computational workload and improves overall system efficiency. In distributed
    data parallelism, contention may occur between the all-to-all communication among
    MoEs and the all-reduce operations, leading to prolonged training times. Therefore,
    Lina [\[44\]](#page-11-13) integrates tensor partitioning and pipelining to perform
    micro-operation scheduling, reducing blocking periods in distributed training.
    All of the above approaches use an expert-centric paradigm, keeping the expert
    in place and providing information to the expert through an all-to-all process.
    However, Janus [\[45\]](#page-11-14) proposes a new data-centric paradigm: maintaining
    the data in place and moving the experts between GPUs. Janus hides the communication
    time by scheduling the requests of fetching experts in a fine-grained manner,
    thus reducing cross-node traffic. Moreover, Janus develops a topologyaware priority
    strategy, ensuring smooth intra-node expert exchanges without resource contention.


    # 5) Hybrid Parallelism: Combining the Power of Different Parallel Computing Approaches


    Although various parallel technologies have shown significant effects in theoretical
    and experimental research, a single parallel strategy often fails to meet the
    growing computational demands and complexity in actual deep learning model training.
    Therefore, hybrid parallelism becomes critical to addressing this challenge. The
    core of hybrid parallelism lies in its ability to make customized strategy choices
    based on the specific requirements of the task and available hardware resources,
    thereby maximizing training efficiency while ensuring model performance.


    Combining multiple parallelization techniques for enhanced efficiency is common
    when conducting pre-training of foundation models with parameter scales in tens
    to hundreds of billions. Smith et al. [\[46\]](#page-11-17) utilized a combination
    of pipeline and tensor parallelism techniques to parallelize the Transformer block
    in Megatron-Turing NLG during their training using DeepSpeed [\[47\]](#page-11-42)
    and Megatron-LM. They expanded the training scale by incorporating data parallelism,
    allowing for training on more GPUs. To simplify the application and enhance the
    efficiency of parallelization strategies, Alpa [\[48\]](#page-11-16) integrates
    all parallelization strategies into a single framework, establishing a compiler
    that automatically generates optimal parallelization strategies. Similarly, Galvatron
    [\[49\]](#page-11-18) introduces a decision tree approach that leverages logical
    intuition for pruning, thereby significantly cutting down the search space. In
    addition, Galvatron employs a dynamic programming search algorithm to determine
    the most effective hybrid parallelization strategy.


    ## *B. GPU Memory Optimization In Training*


    As the model size increases, the demand for GPU memory grows exponentially. However,
    limited by hardware resources, insufficient GPU memory often becomes a bottleneck,
    restricting the scale and performance of the training. Therefore, developing effective
    GPU memory optimization techniques is essential to reduce memory consumption.
    Subsequent sections will explore various innovative GPU memory optimization techniques
    targeting these overheads.


    1) Checkpointing and Recomputation for Memory Efficiency In foundation model training,
    activation checkpointing technology reduces memory consumption by only saving
    key activation values and uses recomputation technology to regenerate these values
    during backpropagation. This combined approach effectively balances memory usage
    and computational efficiency, enabling the training of foundation models even
    with limited hardware resources.


    It was Chen et al. [\[50\]](#page-11-19) who first proposed the concept of activation
    checkpointing to tackle the high memory consumption in foundation model training.
    By selectively removing unneeded intermediate activations in the forward propagation
    process and reconstructing them during backward propagation through additional
    computations, this method significantly reduces GPU memory usage while allowing
    for the training of more extensive networks. However, recomputation imposes an
    additional time overhead. Therefore, it requires a trade-off between training
    time and memory requirements. To address this problem, Jain et al. proposed the
    Checkmate [\[51\]](#page-11-20), which models the problem to minimize computation
    time while ensuring that task scheduling does not exceed the memory limit of the
    device. The Checkmate effectively manages memory usage by dynamically determining
    when to store activations and recompute them. This enables the training of larger-scale
    networks within the constraints of limited memory resources, providing an effective
    solution to address memory limitations in foundation model training.


    ![](_page_6_Picture_0.jpeg)


    # 2) Optimizing with Mixed Precision Training


    Mixed Precision Training [\[52\]](#page-11-21) is a technique used in foundation
    models that simultaneously employs both low-precision and high-precision data
    types. Representing the training data types as 16-bit floating-point numbers can
    reduce the amount of computation while lowering the memory requirement. However,
    the 16-bit floating-point representation will inevitably impact model convergence.
    Jia et al. [\[53\]](#page-11-22) utilized the LARS algorithm [\[54\]](#page-11-43)
    to solve this problem. The algorithm works by using different learning rates for
    different layers. However, the test found that applying the LARS algorithm to
    the training of half-precision models directly caused a great loss of accuracy.
    This is because after multiplying by the LARS coefficients, many parameters directly
    go to zero due to the small range of the half-precision values, so Jia et al.
    converted the half-precision parameters into single-precision and then combined
    them with the LARS.


    ## 3) Memory Swapping Techniques in Optimization


    The basic idea of memory swapping technology is to offload the computational burden
    from the GPU to other devices, such as CPUs or NVMe. It migrates some model parameters
    and computational tasks from the GPU to other devices. This relieves the GPU''s
    workload and enables it to handle the remaining computational tasks more efficiently.


    This idea was first introduced in vDNN [\[55\]](#page-11-44), which aims to reduce
    the pressure on the GPU memory by moving data that does not require immediate
    access from the GPU to the CPU memory. The implementation of vDNN represents an
    initial application of swapping technology. However, with technological advancements,
    more sophisticated methods have emerged. SwapAdvisor [\[56\]](#page-11-23) employs
    genetic algorithms to automatically search for the best data transfer strategy
    as an alternative to manual judgment-based approaches. The benefit of this automated
    approach is that it reduces the need for human intervention, thereby increasing
    efficiency. In contrast, Autotm [\[57\]](#page-11-24) uses an integer linear programming
    approach to search for suitable transfer strategies.


    Stronghold [\[58\]](#page-11-26) introduces a work window method, which keeps
    only part of the model''s layers and parameters in the GPU. Under this mechanism,
    the GPU processes only the model layers within the work window, transferring the
    rest to the CPU. The corresponding resources are only moved from the CPU to the
    GPU when the work window shifts. Additionally, Stronghold models the window size,
    and leverages computation and communication overlap to hide the communication
    costs between the CPU and GPU effectively. Meanwhile, FlashNeuron [\[59\]](#page-11-25)
    considers that offloading data directly to the CPU might interfere with other
    tasks running on the CPU and thus uses SSDs for data offloading and prefetching.
    DeepUM [\[60\]](#page-11-29) enhances Unified Memory (UM) by incorporating prefetching
    techniques, effectively reducing the additional overhead caused by address translations
    and page faults. Similarly, G10 [\[61\]](#page-11-28) innovatively extends the
    Unified Memory of GPUs, amalgamating GPU memory, host memory, and flash memory
    into a unified memory space. This fusion is achieved by storing flash memory page
    addresses in the UM page table. Consequently, a unified page table can point to
    host, GPU, or flash memory addresses. By preemptively analyzing the lifecycle
    of tensors, G10 enables efficient tensor swapping when needed, maximizing the
    overlap between GPU computation and tensor migration. Furthermore, Patrickstar
    [\[62\]](#page-11-27) proposes a memory management method based on chunks, a series
    of consecutive tensors of the same size. This method is similar to storing files
    in fixed-sized disk blocks in a distributed file system. During training, chunks
    with different lifecycles can share memory, reducing memory usage. Additionally,
    Patrickstar collects memory usage information during the warm-up iteration phase
    to optimize memory management.


    Beyond the methods above, other works like ZeRO-Offload and ZeRO-Infinity have
    also employed Memory Swapping Techniques. To comprehensively introduce the ZeRO
    series of research, this paper includes these additional works in the next section.


    # 4) Zero Redundancy Optimizers


    Microsoft has developed a technology called Zero Redundancy Optimization (ZeRO)
    [\[63\]](#page-11-30) as the core of the DeepSpeed distributed training framework.
    The core idea of ZeRO is to reduce the GPU memory by sacrificing some of the communication
    overhead. ZeRO divides the model parameters, gradients, and optimizer states into
    multiple parts, with each GPU maintaining only a portion of them during training
    and obtaining the rest when needed through an AllGather operation. Building upon
    the foundation laid by ZeRO, ZeRO-Offload [\[64\]](#page-11-31) leverages the
    idea of Heterogeneous DL training [\[65\]](#page-11-45) to alleviate the pressure
    on GPU memory by effectively utilizing CPU memory. It divides the model parameters
    into two parts. One part of the parameters is kept in GPU memory for efficient
    computation during forward and backward propagation. The other part of the parameters
    is offloaded to CPU memory and accessed when needed. Further advancing these concepts,
    ZeRO-Infinity [\[66\]](#page-11-32), similar to ZeRO-Offload, leverages GPU, CPU,
    and NVMe memory to enable the training of foundation models on limited resources
    without the need for code refactoring. With ZeRO-Infinity, the model parameters
    and gradients are still computed on the GPU, while the optimizer state and activations
    are offloaded to more suitable NVMe memory and CPU, respectively.


    ## *C. Communication Optimization*


    As demonstrated in the previous sections, communication overhead is a significant
    bottleneck in the distributed training of foundation deep learning models. This
    issue is especially pronounced when synchronizing model parameters, gradients,
    and optimizer states across multiple GPUs or nodes. The mainstream solutions focus
    on reducing the amount of communication, optimizing communication patterns, and
    enhancing the overlap between computation and communication.


    For instance, Gan et al. developed an MPI-style communication library called Bagua
    [\[67\]](#page-11-33). The library provides a series of flexible and modular primitives
    to support state-of-the-art system relaxation techniques of distributed training.
    Bagua achieves efficient implementation and scalability through this design for
    various cutting-edge distributed learning algorithms. The method proposed by Wang
    et al. [\[68\]](#page-11-36) involves decomposing the original communication and
    computational operations into more fine-grained tasks, thereby achieving an overlap
    between communication and computation that effectively reduces data communication
    overhead. Mobius [\[69\]](#page-11-37) introduces a pipeline strategy for heterogeneous
    memory, which overlaps communication with computation by prefetching data from
    the CPU to the GPU memory for the next stage. Additionally, it employs a Cross-mapping
    strategy to reduce communication contention, further optimizing overall performance.
    Simultaneously, Out-Of-Order Back-Prop [\[70\]](#page-11-34) maximizes the overlap
    between communication and computation by optimizing the sequence of computing
    output gradients, weight gradients, and parameter updates.


    ZeRO achieves parallel computation by distributing model weights, gradients, and
    optimizer states across multiple GPUs, increasing communication volume and frequency.
    As an improvement, ZeRO++ [\[71\]](#page-11-35) employs weight quantization, meaning
    model parameters are compressed into smaller data types (such as INT8) in real-time
    before communication, reducing the required communication bandwidth and time.
    Moreover, ZeRO++ maintains a complete model copy on each machine, enhancing intra-machine
    communication bandwidth. COCKTAILSGD [\[72\]](#page-11-39) integrates various
    communication compression techniques, cleverly overlapping communication with
    local gradient computation. During the communication steps, it combines three
    different compression techniques (random sparsification, top-K sparsification,
    and quantization) to achieve more excellent compression than each method individually.
    Lastly, Optimus-CC [\[73\]](#page-11-38) utilizes three techniques: compression
    of back-propagation gradients, merging of embedding layer synchronization operations,
    and selective phase compression to reduce inter-node communication volume. Optimus-CC
    selectively compresses based on the communication needs of different training
    stages, thus minimizing unnecessary communication overhead and enhancing overall
    training efficiency.


    ## **IV. MODEL SERVING**


    This section discusses five principal areas of optimization in foundation model
    serving systems: batch processing optimization, sparse acceleration techniques,
    resource scheduling optimization, GPU memory optimization, and multi-model inference
    (As shown in Table [2\)](#page-7-0). It presents various innovative techniques
    and technologies designed to enhance pro<span id="page-7-0"></span>**TABLE 2.
    Summary of Optimization Techniques in Foundation Model Serving**


    | Method/Framework                     | Main Features                     | Year
    |  |  |  |  |

    |--------------------------------------|-----------------------------------|------|--|--|--|--|

    | Batch Processing Optimization        |                                   |      |  |  |  |  |

    | DVABatch [74]                        | Dynamic Batching                  | 2022
    |  |  |  |  |

    | Orca [75]                            | Selective Batching                | 2022
    |  |  |  |  |

    | Sparse Acceleration Techniques       |                                   |      |  |  |  |  |

    | SparseAttention [76]                 | Structured sparse attention masks | 2023
    |  |  |  |  |

    | Deja Vu [77]                         | Use MLP to predict sparsity       | 2023
    |  |  |  |  |

    | H2O [78]                             | Sparse KV Cache                   | 2023
    |  |  |  |  |

    | STI [79]                             | Sharded Models                    | 2023
    |  |  |  |  |

    | OliVe [80]                           | Outlier Quantization              | 2023
    |  |  |  |  |

    | Resource Scheduling Optimization     |                                   |      |  |  |  |  |

    | Clockwork [81]                       | Latency Predict                   | 2020
    |  |  |  |  |

    | DeepSpeed Inference [82]             | Integrated Scheduling             | 2022
    |  |  |  |  |

    | REEF [83]                            | Real-Time Preemptive Schedule     | 2022
    |  |  |  |  |

    | AlphaServe [84]                      | Automated Model Parallelism       | 2023
    |  |  |  |  |

    | FastServe [85]                       | Preemptive Scheduling             | 2023
    |  |  |  |  |

    | SHEPHERD [88]                        | Predictive Load Management        | 2023
    |  |  |  |  |

    | OSML [89]                            | Predictive Resource Allocation    | 2023
    |  |  |  |  |

    | GPU Memory Optimization In Inference |                                   |      |  |  |  |  |

    | Gpulet [90]                          | Virtual GPU Partitioning          | 2022
    |  |  |  |  |

    | FlexGen [91]                         | Zig-Zag Block Scheduling          | 2023
    |  |  |  |  |

    | DHA [92]                             | Direct GPU Access                 | 2023
    |  |  |  |  |

    | vLLM [93]                            | PageAttention Mechanism           | 2023
    |  |  |  |  |

    | Multi-Model Inference                |                                   |      |  |  |  |  |

    | PetS [94]                            | Selective Model Sharing           | 2022
    |  |  |  |  |

    | Tabi [97]                            | Multi-Level Model Inference       | 2023
    |  |  |  |  |

    | Speculative Decoding [98]            | Speculative decoding              | 2023
    |  |  |  |  |

    | LLMCad [99]                          | Model collaboration               | 2023
    |  |  |  |  |


    cessing efficiency, minimize latency, and improve memory usage. These strategies
    are categorized within the "networkcomputing-storage" optimization framework.


    - Network optimization is accomplished through efficient batch processing and
    resource scheduling, optimizing data flow and task execution.

    - Computing optimization is characterized by multimodel inference, enabling the
    efficient utilization of computational resources.

    - Storage optimization involves GPU memory management and the application of sparse
    acceleration techniques, collectively reducing memory footprint and computational
    overhead.


    Integrating these "network-computing-storage" principles ensures a comprehensive
    optimization approach, which is crucial for the performance of foundation model
    serving systems.


    #### *A. Batch Processing Optimization*


    Batch processing allows models to handle multiple requests efficiently by grouping
    input data into batches. This method allows for more efficient use of computational
    resources


    ![](_page_8_Picture_0.jpeg)


    by leveraging parallel processing capabilities, significantly improving the throughput
    and reducing the latency of model inferences. DVABatch [\[74\]](#page-11-46) proposes
    a multi-entry and multiexit strategy that employs operations like *new*, *split*,
    and *stretch* to dynamically customize batch sizes for different stages of the
    model, thereby optimizing efficiency, throughput, and reducing latency. In addition
    to this approach, Orca [\[75\]](#page-11-47) introduces a selective batching mechanism
    that strategically applies batch processing and padding to fully connected layers,
    maximizing efficiency. Simultaneously, it refrains from applying this method to
    attention layers, minimizing memory overhead. Furthermore, Orca presents an iterative-level
    scheduling strategy that offers adaptability by enabling batch size adjustments
    after each processing iteration.


    # *B. Sparse Acceleration Techniques*


    Sparse acceleration techniques play a crucial role in optimizing the performance
    of Transformer-based foundation models when faced with limited computational and
    memory resources. These methods leverage the inherent sparsity in model parameters,
    attention mechanisms, and KV Cache to prioritize computation and storage. Transformers
    leverage a KV Cache within the attention mechanism to remember crucial parts of
    the data, which is essential for efficiency, particularly in autoregressive models
    that generate new tokens iteratively and would otherwise require costly recomputation
    of keys and values for each token. By focusing on the most influential components
    of the model and reducing the overhead on less critical areas, sparse acceleration
    approaches enable high model performance while facilitating deployment on edge
    devices and mobile platforms where resources are scarce.


    Addressing the computational intensity of self-attention mechanisms in Transformers,
    Dai et al. [\[76\]](#page-11-48) introduce a method that leverages the intrinsic
    sparsity within selfattention matrices. The method employs structured sparse attention
    masks to allocate computational resources to the most influential attention parameters,
    which are identified by analyzing the attention distribution of the model. These
    parameters shape the initial mask, designed to conform to specific patterns like
    blocks or stripes. Through entropyaware fine-tuning, this mask undergoes further
    refinement by integrating the entropy of the attention matrix''s rows into the
    model''s loss function. Another notable work is Deja Vu [\[77\]](#page-11-49),
    which offers a strategic solution by leveraging the concept of contextual sparsity.
    The proposed approach effectively identifies and activates selective attention
    heads and FFN parameters that are crucial in processing the given input. The Deja
    Vu utilizes an MLP to predict the critical attention heads and FFN parameters
    precisely. In cases where the KV Cache retrieval fails, it triggers a recomputation
    process. Another relevant work is that the H2O [\[78\]](#page-11-50) method suggests
    that in attention blocks, the cumulative attention scores of tokens follow a power-law
    distribution, with only a few tokens playing a pivotal role in generation. To
    conserve memory, H2O retains only the KV Cache for these pivotal tokens, which
    are identified as highly contributive KV Cache based on their elevated cumulative
    attention scores. This approach substantially reduces the memory requirement while
    retaining the essential KV Cache of the attention mechanism.


    In low-resource scenarios on edge devices, both computation and memory are constrained.
    STI [\[79\]](#page-11-51) tackles memory constraints and I/O delays for foundation
    models on edge devices by partitioning the model into manageable shards. A central
    scheduler orchestrates the I/O operations of these shards, considering resource
    availability and the significance of each shard. It stores shards at multiple
    precision levels and dynamically selects the optimal precision for each shard
    based on its importance, thereby optimizing both accuracy and latency. In the
    realm of model quantization acceleration, one prominent contribution is OliVe
    [\[80\]](#page-11-52). This study presents the concept of Outlier-Victim Pair
    (OVP) quantization as a key technique for effectively managing critical outliers
    with minimal reduction in model accuracy. OliVe''s innovative insight lies in
    recognizing the importance of outliers for model accuracy while identifying adjacent
    normal values, termed ''victim values'', that can be pruned without significant
    performance loss. OliVe strategically retains outliers and prunes adjacent normal
    values. This selective pruning approach aligns with hardware design principles.


    ## *C. Resource Scheduling Optimization*


    Effective resource scheduling is essential in optimizing service delivery. DeepSpeed
    Inference [\[82\]](#page-11-54) offers a multi-GPU inference solution designed
    to handle foundation models while adhering to limited GPU memory constraints.
    It introduces an inference pipeline-parallel schedule specifically tailored for
    the autoregressive Decoder in generative models, optimizing prompt processing
    and token generation to minimize latency. Moreover, DeepSpeed Inference leverages
    both GPU and CPU resources, including NVMe storage, to alleviate the burden on
    GPU memory. Furthermore, DeepSpeed Inference incorporates operator fusion within
    Transformer modules, efficiently reducing latency and increasing throughput. In
    the field of model parallelism research, AlphaServe [\[84\]](#page-11-56) enhances
    foundation model inference by employing model parallelism, which distributes models
    across multiple GPUs to overcome the limitations of single GPU memory and reduce
    request latency. AlphaServe incorporates a twolayer placement algorithm that optimizes
    the distribution of model ensembles in clusters, ensuring compliance with Service
    Level Objective (SLO) requirements. Building upon the Alpha framework, it automates
    model parallelism in inference to simplify the management of parallelism. Taking
    optimization further, FastServe [\[85\]](#page-11-57) enhances optimization through
    the careful consideration of service latency. It employs a preemptive scheduling
    mechanism alongside an innovative skip-join Multi-Level Feedback Queue scheduler.
    This combined approach aims to curtail job completion time and diminish both requests
    waiting and processing durations. Moreover, the skip-join mechanism anticipates
    the time required for the initial iteration, thus swiftly delegating the job to
    the most suitable queue. This strategic allocation aids in averting unnecessary
    queue transitions and subsequent delays. However, despite these sophisticated
    approaches, Current methods [\[86\]](#page-11-68), [\[87\]](#page-11-69) that
    make decisions for each request individually often result in GPU overprovisioning
    during short-term high loads, leading to low resource utilization. To address
    this issue, Shepherd [\[88\]](#page-11-58) improves predictability by grouping
    unpredictable individual request streams into medium-sized batches. It employs
    a two-stage scheduling algorithm. In the first stage, it utilizes long-term load
    data to divide the GPU cluster into service groups and allocate GPUs accordingly.
    In the second stage, it introduces preemptive scheduling, prioritizing larger
    batches that align with SLOs to optimize throughput even with reactive scheduling.


    In scenarios with strong latency requirements, some works have addressed the issue.
    Clockwork [\[81\]](#page-11-53) ensures predictable DNN inference times, combating
    tail latency from diverse tasks, hardware, and inputs to satisfy SLOs and minimize
    delays. By limiting options at each computational layer for uniform execution
    times and deploying a central controller that assigns tasks with known durations,
    Clockwork maintains strict timing assurances. REEF [\[83\]](#page-11-55) is a
    system designed for efficient and timely DNN inference on GPUs. It schedules tasks
    in a way that prioritizes real-time tasks, quickly interrupts other tasks if needed,
    and allocates computing units first to real-time kernels, then distributes the
    remaining units to best-effort kernels. In the field of latencysensitive services,
    OSML [\[89\]](#page-11-59) is a machine learning-based scheduler that integrates
    architectural metrics like IPC and cache misses into a predictive model for Quality
    of Service (QoS) changes. It deploys three models: Model A calculates optimal
    resource allocations and detects "resource cliffs"; Model B redistributes resources,
    prioritizing services that are sensitive to QoS degradation; and Model C dynamically
    adjusts resource allocation in real-time based on ongoing QoS assessments to maintain
    service performance.


    ## *D. GPU Memory Optimization In Inference*


    During the process of inference, the weight parameters of a model significantly
    consume GPU memory. Various studies have concentrated on optimizing these model
    parameters. For instance, FlexGen [\[91\]](#page-11-61) is a throughput-oriented
    generative inference system that optimizes offloading strategies. A standout characteristic
    of FlexGen is its zig-zag block scheduling strategy. The zig-zag block scheduling
    strategy explores the computation graph by advancing column-bycolumn and reusing
    weights within each column to minimize loading times. When the memory limits for
    activations are reached, the process transitions to the next column, optimizing
    GPU memory utilization and efficiently processing the model through a zig-zag
    pattern. Additionally, it dynamically loads and unloads activation values and
    KV Cache as required. In another study, Jeong et al. [\[92\]](#page-11-62) utilized
    Direct-Host-Access (DHA) for direct GPU memory access, reducing latency for layers
    like the embedding layer. They also applied Parallel Model Transmission, dividing
    the model per GPU for parallel loading via PCIe. The sections are then quickly
    transferred to the primary GPU using NVLink, optimizing layer execution.


    GPU memory constraints hinder foundation model inference, where the storage of
    the KV Cache is a significant memory overhead. Serving architectures use KV Cache
    to reduce re-computation, but as the token count grows, so does the cache, risking
    GPU memory overflow. To avoid this, frameworks limit iteration length and pre-allocate
    memory for KV Cache, which can lead to memory fragmentation and reduced inference
    performance. Several techniques have been proposed to optimize this aspect. The
    PageAttention mechanism proposed by vLLM [\[93\]](#page-11-63) addresses the issues
    of GPU memory over-allocation and fragmentation. It accomplishes this by emulating
    OS page table mapping and segmenting GPU memory into blocks. A block mapping table
    is then used to ensure logically sequential but physically discrete storage. This
    dynamic approach effectively meets the demand of the KV Cache, reducing memory
    fragmentation and improving inference throughput. Drawing inspiration from the
    virtual nature of operating systems, The gpulet [\[90\]](#page-11-60) concept
    introduces an abstraction for partitioning GPUs, creating virtual GPUs that possess
    a fraction of the physical GPU resources. The proposed multidimensional search-based
    scheduling framework optimizes GPU tasks by considering data batch sizes along
    with the temporal and spatial sharing of resources.


    ## *E. Multi-Model Inference*


    Multi-model inference involves utilizing multiple models for serving. These models
    can be of the same type or different types, often with varying architectures.
    An important research question in this context is how to effectively combine these
    diverse models and optimize resource allocation to achieve optimal performance.
    In the context of multi-task models created through fine-tuning, PetS [\[94\]](#page-11-64)
    introduces an innovative framework for multi-task Parameter Efficient Transformers
    (PET) that processes various tasks in a unified manner. Traditional fine-tuning
    of the entire model for each task incurs substantial memory overhead. PetS circumvents
    this by employing parameter-efficient fine-tuning methods such as Adapters [\[95\]](#page-11-70),
    [\[96\]](#page-11-71), splitting the model into a shared core and task-specific
    small operators. This architecture allows for shared base model usage across tasks,
    reducing memory demands and streamlining model deployment. In the context of hierarchical
    models ranging from small to large, one approach is presented by Tabi [\[97\]](#page-11-65).
    Tabi leverages the observation that smaller models often exhibit predictive capabilities
    similar to larger models by implementing a multi-level inference engine. It employs
    well-calibrated


    ![](_page_10_Picture_0.jpeg)


    confidence scores using temperature scaling to determine whether a query can be
    promptly resolved using the smaller model or if it should be escalated to the
    larger model. For escalated queries, Tabi reduces system overhead by employing
    attention-based word pruning and a weighted ensemble approach. Another technique
    introduced by Google Research is Speculative Decoding [\[98\]](#page-11-66), which
    aims to accelerate the inference process for language models. This method involves
    a smaller model generating tokens sequentially while a larger model simultaneously
    validates the correctness of each token in parallel. The larger model verifies
    the sequence of tokens produced by the smaller model, enabling the generation
    of multiple tokens within a single iteration of the larger model. LLMCad [\[99\]](#page-11-67)
    differs from Google''s Speculative Decoding by employing a tree-based token generation
    approach that facilitates the concurrent evaluation of multiple tokens. To accomplish
    this, LLMCad utilizes a smaller language model to construct a comprehensive vocabulary
    tree comprising various word paths. The larger LLM then efficiently and concurrently
    evaluates these paths.


    ## **V. CHALLENGE AND FUTURE DIRECTIONS**


    ➊ Privacy protection. Regarding privacy protection, the key challenge for foundation
    models lies in the potential unauthorized collection, usage, and inadvertent disclosure
    of personal information. Future efforts should focus on incorporating privacy
    protection mechanisms into the design and application of models to ensure robust
    safeguards for user data, preventing unauthorized use and disclosure threats.
    ➋ Security. Foundation models exhibit a relatively weak ability to defend against
    malicious attacks, making them susceptible to activities such as command injection
    and prompt injection. Particularly in critical domains such as politics, military,
    finance, and healthcare, any form of malicious attack could severely affect the
    stability of national society and the safety of people''s lives and property.
    Therefore, future efforts must focus on enhancing security measures for foundation
    models to ensure their reliable protection in critical domains.


    ➌ Energy sustainability. Foundation systems face a significant challenge in terms
    of energy sustainability during both training and serving. This entails a high
    demand for substantial computational resources, which may result in adverse environmental
    impacts. The key to future efforts lies in enhancing the energy efficiency of
    models and adopting more energy-efficient hardware innovations. Through innovative
    green computing and sustainable development, these efforts aim to make foundation
    model systems more environmentally friendly and efficient, reducing energy dependence
    and mitigating environmental impact.


    # **VI. CONCLUSION**


    This survey delves into the training and serving methods of foundation model systems
    from the perspectives of network, computing, and storage. In the training section,
    it discusses various parallel computing strategies. Each strategy has unique advantages
    and application scenarios. Additionally, it explores GPU memory optimization and
    communication optimization techniques. The serving section discusses key technologies
    such as batch processing, sparse acceleration, resource scheduling, GPU memory
    optimization, and multimodel inference. These strategies are essential for ensuring
    the efficiency and practicality of the foundation model system in real-world scenarios.
    In summary, the training and serving of foundation model systems is an evolving
    field. With the emergence of new technologies, it anticipates solving more challenges
    and further advancing the field of artificial general intelligence.


    ## **REFERENCES**


    - <span id="page-10-0"></span>[1] Brown T, et al. "Language models are few-shot
    learners.", NeurIPS, 2020.

    - <span id="page-10-1"></span>[2] Touvron H, et al. "Llama: Open and efficient
    foundation language models.", arXiv, 2023.

    - <span id="page-10-2"></span>[3] Ren X, et al. "PanGu-Σ: Towards Trillion Parameter
    Language Model with Sparse Heterogeneous Computing.", arXiv, 2023.

    - <span id="page-10-3"></span>[4] https://cloudbrain.pcl.ac.cn/

    - <span id="page-10-4"></span>[5] Chang Y, et al. "A survey on evaluation of large
    language models." arXiv, 2023.

    - [6] Hadi M U, et al. "Large Language Models: A Comprehensive Survey of its Applications,
    Challenges, Limitations, and Future Prospects." arXiv,2023.

    - [7] Zhao H, et al. "Explainability for Large Language Models: A Survey." arXiv,
    2023.

    - [8] Wang X, et al. "Large-scale multi-modal pre-trained models: A comprehensive
    survey." Machine Intelligence Research, 2023.

    - [9] Yin S, Shukang, et al. "A Survey on Multimodal Large Language Models." arXiv,
    2023.

    - [10] Zhou Y, et al. "Vision+ Language Applications: A Survey." CVPR. 2023.

    - <span id="page-10-5"></span>[11] Zhou C, et al. "A comprehensive survey on pretrained
    foundation

    - models: A history from bert to chatgpt.", arXiv, 2023. [12] Zhao W X, et al.
    "A survey of large language models." arXiv ,2023.

    - <span id="page-10-7"></span><span id="page-10-6"></span>[13] Vaswani A, et al.
    "Attention is all you need." NeurIP, 2017.

    - <span id="page-10-8"></span>[14] Devlin, et al. "Bert: Pre-training of deep
    bidirectional transformers for language understanding." NAACL,2018.

    - <span id="page-10-9"></span>[15] Li S, et al. "PyTorch distributed: experiences
    on accelerating data parallel training." VLDB, 2020.

    - <span id="page-10-19"></span>[16] Gibiansky, et al. "Bringing HPC techniques
    to deep learning." Baidu Research, Tech. Rep. (2017).

    - <span id="page-10-11"></span>[17] Zhao Y, et al. "PyTorch FSDP: Experiences
    on Scaling Fully Sharded Data Parallel.",VLDB, 2023.

    - <span id="page-10-10"></span>[18] Xu Y, et al. "Automatic cross-replica sharding
    of weight update in data-parallel training." arXiv, 2020.

    - <span id="page-10-12"></span>[19] Narayanan D, et al. "Efficient large-scale
    language model training on gpu clusters using megatron-lm.", SC, 2021.

    - <span id="page-10-13"></span>[20] Xu Q, et al. "An efficient 2d method for training
    super-large deep learning models.", IPDPS, 2023.

    - <span id="page-10-20"></span>[21] Van De Geijn R A, et al. "SUMMA: Scalable
    universal matrix multiplication algorithm." Concurrency: Practice and Experience,
    1997.

    - <span id="page-10-14"></span>[22] Wang B, et al. "Tesseract: Parallelize the
    Tensor Parallelism Efficiently.", ICPP, 2022

    - <span id="page-10-21"></span>[23] Solomonik E, et al. "Communication-optimal
    parallel 2.5 D matrix multiplication and LU factorization algorithms." European
    Conference on Parallel Processing. Berlin, Heidelberg: Springer Berlin Heidelberg,
    2011.

    - <span id="page-10-15"></span>[24] Bian Z, et al. "Maximizing parallelism in
    distributed training for huge neural networks." arXiv, 2021.

    - <span id="page-10-16"></span>[25] Huang Y, et al. "Gpipe: Efficient training
    of giant neural networks using pipeline parallelism.", NeurIPS, 2019.

    - <span id="page-10-17"></span>[26] Narayanan D, et al. "PipeDream: generalized
    pipeline parallelism for DNN training.", SOSP, 2019.

    - <span id="page-10-18"></span>[27] Athlur S, et al. "Varuna: scalable, low-cost
    training of massive deep learning models.", EuroSys, 2022.

    - <span id="page-11-3"></span>[28] Fan S, et al. "DAPPLE: A pipelined data parallel
    approach for training large models.", PPoPP, 2021.

    - <span id="page-11-1"></span>[29] Narayanan D, et al. "Memory-efficient pipeline-parallel
    dnn training.", ICML, 2021.

    - <span id="page-11-0"></span>[30] Li S, et al. "Chimera: efficiently training
    large-scale neural networks with bidirectional pipelines.", SC, 2021.

    - <span id="page-11-4"></span>[31] Liu Z, et al. "Hanayo: Harnessing Wave-like
    Pipeline Parallelism for Enhanced Large Model Training Efficiency.", SC, 2023.

    - <span id="page-11-5"></span>[32] Zhang W, et al. "MixPipe: Efficient Bidirectional
    Pipeline Parallelism for Training Large-Scale Models." DAC, 2023.

    - <span id="page-11-6"></span>[33] Chen Z, et al. "Elastic Averaging for Efficient
    Pipelined DNN Training.", PPoPP, 2023.

    - <span id="page-11-9"></span>[34] Jiang C, et al. "DynaPipe: Optimizing Multi-task
    Training through Dynamic Pipelines.", EuroSys, 2024.

    - <span id="page-11-7"></span>[35] Kim T, et al. "BPIPE: memory-balanced pipeline
    parallelism for training large language models.", ICML, 2023.

    - <span id="page-11-8"></span>[36] Thorpe J, et al. "Bamboo: Making Preemptible
    Instances Resilient for Affordable Training of Large DNNs.", NSDI, 2023.

    - <span id="page-11-2"></span>[37] Eliad S, et al. "Fine-tuning giant neural networks
    on commodity hardware with automatic pipeline model parallelism.", ATC 2021.

    - <span id="page-11-10"></span>[38] Lepikhin D, et al. "Gshard: Scaling giant
    models with conditional computation and automatic sharding.", ICLR, 2021.

    - <span id="page-11-40"></span>[39] Jacobs R A, et al. "Adaptive mixtures of local
    experts." Neural computation, 1991

    - <span id="page-11-11"></span>[40] He J, et al. "Fastmoe: A fast mixture-of-expert
    training system.", arXiv, 2021.

    - <span id="page-11-41"></span>[41] Paszke A, et al. "Pytorch: An imperative style,
    high-performance deep learning library.", NeurIPS, 2019.

    - <span id="page-11-12"></span>[42] He J, et al. "FasterMoE: modeling and optimizing
    training of largescale dynamic pre-trained models.", PPoPP, 2022.

    - <span id="page-11-15"></span>[43] Zhai M, et al. "SmartMoE: Efficiently Training
    Sparsely-Activated Models through Combining Offline and Online Parallelization.",
    ATC 2023.

    - <span id="page-11-13"></span>[44] Li J, et al. "Accelerating Distributed MoE
    Training and Inference with Lina.", ATC, 2023.

    - <span id="page-11-14"></span>[45] Liu J, et al. "Janus: A Unified Distributed
    Training Framework for Sparse Mixture-of-Experts Models.", SIGCOMM, 2023.

    - <span id="page-11-17"></span>[46] Smith S, et al. "Using deepspeed and megatron
    to train megatronturing nlg 530b, a large-scale generative language model." arXiv,
    2022.

    - <span id="page-11-42"></span>[47] Rasley J, et al. "Deepspeed: System optimizations
    enable training deep learning models with over 100 billion parameters.", KDD,
    2020.

    - <span id="page-11-16"></span>[48] Zheng L, et al. "Alpa: Automating inter-and
    Intra-Operator parallelism for distributed deep learning.", OSDI, 2022.

    - <span id="page-11-18"></span>[49] Miao X, et al. "Galvatron: Efficient Transformer
    Training over Multiple GPUs Using Automatic Parallelism.", VLDB, 2022.

    - <span id="page-11-19"></span>[50] Chen T, et al. "Training deep nets with sublinear
    memory cost." arXiv, 2016.

    - <span id="page-11-20"></span>[51] Jain P, et al. "Checkmate: Breaking the memory
    wall with optimal tensor rematerialization.", MLSys, 2022.

    - <span id="page-11-21"></span>[52] Micikevicius P, et al. "Mixed precision training.",
    ICLR, 2018

    - <span id="page-11-22"></span>[53] Jia X, et al. "Highly scalable deep learning
    training system with mixedprecision: Training imagenet in four minutes." arXiv,
    2018.

    - <span id="page-11-43"></span>[54] You Y, et al. "Imagenet training in minutes.",
    ICPP, 2018.

    - <span id="page-11-44"></span>[55] Rhu M, et al. "vDNN: Virtualized deep neural
    networks for scalable, memory-efficient neural network design.",MICRO, 2016.

    - <span id="page-11-23"></span>[56] Huang C C, et al. "Swapadvisor: Pushing deep
    learning beyond the gpu memory limit via smart swapping.", ASPLOS, 2020.

    - <span id="page-11-24"></span>[57] Hildebrand M, et al. "Autotm: Automatic tensor
    movement in heterogeneous memory systems using integer linear programming.", ASP-LOS,
    2020.

    - <span id="page-11-26"></span>[58] Sun X, et al. "Stronghold: fast and affordable
    billion-scale deep learning model training.", SC, 2022.

    - <span id="page-11-25"></span>[59] Bae J, et al. "FlashNeuron:SSD-Enabled Large-Batch
    Training of Very Deep Neural Networks.", FAST, 2021.

    - <span id="page-11-29"></span>[60] Jung J, et al. "DeepUM: Tensor Migration and
    Prefetching in Unified Memory.", ASPLOS, 2023.

    - <span id="page-11-28"></span>[61] Zhang H, et al. "G10: Enabling An Efficient
    Unified GPU Memory and Storage Architecture with Smart Tensor Migrations.", MICRO,
    2023.

    - <span id="page-11-27"></span>[62] Fang J, et al. "Parallel Training of Pre-Trained
    Models via Chunk-Based Dynamic Memory Management.", TPDS, 2022.

    - <span id="page-11-30"></span>[63] Rajbhandari S, et al. "Zero: Memory optimizations
    toward training trillion parameter models." SC, 2020.

    - <span id="page-11-31"></span>[64] Ren J, et al. "ZeRO-Offload: Democratizing
    Billion-Scale model training.", ATC, 2021.

    - <span id="page-11-45"></span>[65] Huang C C, et al. "Swapadvisor: Pushing deep
    learning beyond the gpu memory limit via smart swapping.", ASPLOS, 2020.

    - <span id="page-11-32"></span>[66] Rajbhandari S, et al. "Zero-infinity: Breaking
    the gpu memory wall for extreme scale deep learning.",SC, 2021.

    - <span id="page-11-33"></span>[67] Gan S, et al. "Bagua: scaling up distributed
    learning with system relaxations.", arXiv,2021.

    - <span id="page-11-36"></span>[68] Wang S, et al. "Overlap communication with
    dependent computation via decomposition in large deep learning models.", ASPLOS,
    2023.

    - <span id="page-11-37"></span>[69] Feng Y, et al. "Mobius: Fine tuning large-scale
    models on commodity gpu servers.",ASPLOS, 2023.

    - <span id="page-11-34"></span>[70] Oh H, et al. "Out-of-order backprop: An effective
    scheduling technique for deep learning.", EuroSys, 2022.

    - <span id="page-11-35"></span>[71] Wang G, et al. "ZeRO++: Extremely Efficient
    Collective Communication for Giant Model Training." arXiv, 2023.

    - <span id="page-11-39"></span>[72] Wang J, et al. "CocktailSGD: Fine-tuning foundation
    models over 500Mbps networks.", ICML, 2023.

    - <span id="page-11-38"></span>[73] Song J, et al. "Optimus-CC: Efficient Large
    NLP Model Training with 3D Parallelism Aware Communication Compression.",ASPLOS,
    2023.

    - <span id="page-11-46"></span>[74] Cui W, et al. "DVABatch: Diversity-aware Multi-Entry
    Multi-Exit Batching for Efficient Processing of DNN Services on GPUs.", ATC, 2022.

    - <span id="page-11-47"></span>[75] Yu G I, et al. "Orca: A distributed serving
    system for Transformer-Based generative models.", OSDI, 2022.

    - <span id="page-11-48"></span>[76] Dai S, et al. "Efficient Transformer Inference
    with Statically Structured Sparse Attention.", DAC, 2023.

    - <span id="page-11-49"></span>[77] Liu Z, et al. "Deja Vu: Contextual Sparsity
    for Efficient LLMs at Inference Time.", ICML, 2023.

    - <span id="page-11-50"></span>[78] Zhang Z, et al. "H2O: Heavy-Hitter Oracle
    for Efficient Generative Inference of Large Language Models", ICML, 2023.

    - <span id="page-11-51"></span>[79] Guo L, et al. "STI: Turbocharge NLP Inference
    at the Edge via Elastic Pipelining.",ASPLOS, 2023.

    - <span id="page-11-52"></span>[80] Guo C, et al. "OliVe: Accelerating Large Language
    Models via Hardware-friendly Outlier-Victim Pair Quantization.", ISCA, 2023.

    - <span id="page-11-53"></span>[81] Gujarati A, et al. "Serving DNNs like Clockwork:
    Performance Predictability from the Bottom Up", OSDI, 2020

    - <span id="page-11-54"></span>[82] Aminabadi R Y, et al. "DeepSpeed-inference:
    enabling efficient inference of transformer models at unprecedented scale." SC,
    2022.

    - <span id="page-11-55"></span>[83] Han M, et al. "Microsecond-scale Preemption
    for Concurrent GPUaccelerated DNN Inferences", OSDI, 2022

    - <span id="page-11-56"></span>[84] Li Z, et al. "AlpaServe: Statistical Multiplexing
    with Model Parallelism for Deep Learning Serving.", OSDI, 2023.

    - <span id="page-11-57"></span>[85] Wu B, et al. "Fast Distributed Inference Serving
    for Large Language Models." arXiv, 2023.

    - <span id="page-11-68"></span>[86] Crankshaw D, et al. "InferLine: latency-aware
    provisioning and scaling for prediction serving pipelines.", SoCC, 2020.

    - <span id="page-11-69"></span>[87] Romero F, et al. "INFaaS: Automated Model-less
    Inference Serving.", ATC, 2021.

    - <span id="page-11-58"></span>[88] Zhang H, et al. "SHEPHERD: Serving DNNs in
    the Wild.", NSDI, 2023.

    - <span id="page-11-59"></span>[89] Liu L, et al. "Intelligent Resource Scheduling
    for Co-located Latencycritical Services: A Multi-Model Collaborative Learning
    Approach.", FAST, 2023.

    - <span id="page-11-60"></span>[90] Choi S, et al. "Serving Heterogeneous Machine
    Learning Models on Multi-GPU Servers with Spatio-Temporal Sharing", ATC, 2022

    - <span id="page-11-61"></span>[91] Sheng Y, et al. "FlexGen: High-Throughput
    Generative Inference of Large Language Models with a Single GPU.", ICML, 2023.

    - <span id="page-11-62"></span>[92] Jeong J, et al. "Fast and Efficient Model
    Serving Using Multi-GPUs with Direct-Host-Access.", EuroSys, 2023.

    - <span id="page-11-63"></span>[93] Kwon W, et al. "Efficient memory management
    for large language model serving with pagedattention.",SOSP, 2023.

    - <span id="page-11-64"></span>[94] Zhou Z, et al. "PetS: A Unified Framework
    for Parameter-Efficient Transformers Serving.", ATC, 2022.

    - <span id="page-11-70"></span>[95] Lin Z, et al. "The adapter-bot: All-in-one
    controllable conversational model.", AAAI, 2021.

    - <span id="page-11-71"></span>[96] Wang R, et al. "K-adapter: Infusing knowledge
    into pre-trained models with adapters." arXiv, 2020.

    - <span id="page-11-65"></span>[97] Wang Y, et al. "Tabi: An Efficient Multi-Level
    Inference System for Large Language Models.", EuroSys, 2023.

    - <span id="page-11-66"></span>[98] Leviathan Y, et al. "Fast Inference from Transformers
    via Speculative Decoding", ICML, 2023

    - <span id="page-11-67"></span>[99] Xu D, et al. "LLMCad: Fast and Scalable On-device
    Large Language Model Inference.", arxiv, 2023.'
- id: a_survey_on_verification_and_validation_testing_and_evaluations_of_neurosymbolic_artificial_intelligence_2024_ieee_personal_use_of_this_material_is_permitted_permission_from_ieee_must_be_obtained_for_all_other_uses_in_any_current_or_future_media_including_reprinting_republishing_this_material_for_advertising_or_promotional_purposes_creating_new_collective_works_for_resale_or_redistribution_to_servers_or_lists_or_reuse_of_any_copyrighted_component_of_this_work_in_other_works_doi_10_1109_tai_2024_3351798_https_www_doi_org_10_1109_tai_2024_3351798_arxiv_2401_03188v2_cs_ai_10_jan_2024
  title: "A Survey on Verification and Validation, Testing and Evaluations of\n  Neurosymbolic\
    \ Artificial Intelligence"
  abstract: 'Neurosymbolic artificial intelligence (AI) is an emerging branch of AI
    that

    combines the strengths of symbolic AI and sub-symbolic AI. A major drawback of

    sub-symbolic AI is that it acts as a "black box", meaning that predictions are

    difficult to explain, making the testing & evaluation (T&E) and validation &

    verification (V&V) processes of a system that uses sub-symbolic AI a challenge.

    Since neurosymbolic AI combines the advantages of both symbolic and

    sub-symbolic AI, this survey explores how neurosymbolic applications can ease

    the V&V process. This survey considers two taxonomies of neurosymbolic AI,

    evaluates them, and analyzes which algorithms are commonly used as the symbolic

    and sub-symbolic components in current applications. Additionally, an overview

    of current techniques for the T&E and V&V processes of these components is

    provided. Furthermore, it is investigated how the symbolic part is used for T&E

    and V&V purposes in current neurosymbolic applications. Our research shows that

    neurosymbolic AI as great potential to ease the T&E and V&V processes of

    sub-symbolic AI by leveraging the possibilities of symbolic AI. Additionally,

    the applicability of current T&E and V&V methods to neurosymbolic AI is

    assessed, and how different neurosymbolic architectures can impact these

    methods is explored. It is found that current T&E and V&V techniques are partly

    sufficient to test, evaluate, verify, or validate the symbolic and sub-symbolic

    part of neurosymbolic applications independently, while some of them use

    approaches where current T&E and V&V methods are not applicable by default, and

    adjustments or even new approaches are needed. Our research shows that there is

    great potential in using symbolic AI to test, evaluate, verify, or validate the

    predictions of a sub-symbolic model, making neurosymbolic AI an interesting

    research direction for safe, secure, and trustworthy AI.'
  url: http://arxiv.org/abs/2401.03188v2
  keywords: Neurosymbolic AI, Validation, Verification, Evaluation, Testing, Deep
    Learning, Safety, Security, Trustworthiness
  document: '© 2024 IEEE. Personal use of this material is permitted. Permission from
    IEEE must be obtained for all other uses, in any current or future media, including
    reprinting/republishing this material for advertising or promotional purposes,
    creating new collective works, for resale or redistribution to servers or lists,
    or reuse of any copyrighted component of this work in other works. DOI: [10.1109/TAI.2024.3351798](https://www.doi.org/10.1109/TAI.2024.3351798)
    arXiv:2401.03188v2 [cs.AI] 10 Jan 2024


    1


    # A Survey on Verification and Validation, Testing and Evaluations of Neurosymbolic
    Artificial Intelligence


    Justus Renkhoff <sup>∗</sup> , Ke Feng <sup>∗</sup> , Marc Meier-Doernberg, Alvaro
    Velasquez, and Houbing Herbert Song, *Fellow, IEEE*


    *Abstract*—Neurosymbolic artificial intelligence (AI) is an emerging branch of
    AI that combines the strengths of symbolic AI and sub-symbolic AI. Symbolic AI
    is based on the idea that intelligence can be represented using semantically meaningful
    symbolic rules and representations, while deep learning (DL), or sometimes called
    sub-symbolic AI, is based on the idea that intelligence emerges from the collective
    behavior of artificial neurons that are connected to each other. A major drawback
    of DL is that it acts as a "black box", meaning that predictions are difficult
    to explain, making the testing & evaluation (T&E) and validation & verification
    (V&V) processes of a system that uses sub-symbolic AI a challenge. Since neurosymbolic
    AI combines the advantages of both symbolic and sub-symbolic AI, this survey explores
    how neurosymbolic applications can ease the V&V process. This survey considers
    two taxonomies of neurosymbolic AI, evaluates them, and analyzes which algorithms
    are commonly used as the symbolic and sub-symbolic components in current applications.
    Additionally, an overview of current techniques for the T&E and V&V processes
    of these components is provided. Furthermore, it is investigated how the symbolic
    part is used for T&E and V&V purposes in current neurosymbolic applications. Our
    research shows that neurosymbolic AI has great potential to ease the T&E and V&V
    processes of sub-symbolic AI by leveraging the possibilities of symbolic AI. Additionally,
    the applicability of current T&E and V&V methods to neurosymbolic AI is assessed,
    and how different neurosymbolic architectures can impact these methods is explored.
    It is found that current T&E and V&V techniques are partly sufficient to test,
    evaluate, verify, or validate the symbolic and sub-symbolic part of neurosymbolic
    applications independently, while some of them use approaches where current T&E
    and V&V methods are not applicable by default, and adjustments or even new approaches
    are needed. Our research shows that there is great potential in using symbolic
    AI to test, evaluate, verify, or validate the predictions of a sub-symbolic model,
    making neurosymbolic AI an interesting research direction for safe, secure, and
    trustworthy AI.


    #### *Impact Statement*—Neurosymbolic AI allows the combination


    Manuscript received January 31, 2023. This work was supported in part by the U.S.
    National Science Foundation under Grant No. 2309760 and Grant No. 2317117.


    Justus Renkhoff and Houbing Herbert Song are with the Security and Optimization
    for Networked Globe Laboratory (SONG Lab), Department of Information Systems,
    University of Maryland, Baltimore County, Baltimore, MD 21250 USA (e-mail: justusr1@umbc.edu;
    h.song@ieee.org).


    Ke Feng is with the Department of Electrical Engineering and Computer Science,
    Embry-Riddle Aeronautical University, Daytona Beach, FL 32114 USA (e-mail: fengk2@my.erau.edu).


    Marc Meier-Doernberg is with the Department of Electrical Engineering and Computer
    Science, Embry-Riddle Aeronautical University, Daytona Beach, FL 32114 USA (e-mail:
    meierdom@my.erau.edu).


    Alvaro Velasquez is with the Department of Computer Science, University of Colorado,
    Boulder, CO 80309 USA (e-mail: alvaro.velasquez@colorado.edu).


    \*Justus Renkhoff and Ke Feng are co-first authors.


    of symbolic representations or knowledge with the abstraction capabilities of
    sub-symbolic AI. This poses new challenges for the AI community, but also offers
    many new opportunities. As neurosymbolic AI is well suited for safety-critical
    domains such as autonomous systems, we aim to connect the two fields T&E/V&V and
    neurosymbolic AI with our survey. Since neurosymbolic AI consists of several components,
    our research provides an overview of individual aspects regarding the T&E/V&V
    of these components. Through this, we influence current research in the field
    of T&E/V&V by highlighting opportunities as well as open challenges that emerge
    from neurosymbolic AI. Our research demonstrates that by combining symbolic and
    sub-symbolic AI, it is possible to test, evaluate, verify and validate predictions
    made by non-transparent sub-symbolic models. Accordingly, we provide an overview
    of current applications leveraging different architectures and combinations of
    symbolic and sub-symbolic AI, aiming to either test and evaluate in order to verify
    and validate predictions or to ease the T&E/V&V processes. In addition, the evaluation
    of current T&E/V&V methods for their applicability to neurosymbolic applications
    revealed a need for testing frameworks that focus on neurosymbolic AI. As a result,
    we provide other researchers with possible directions for future research in the
    field of T&E/V&V of neurosymbolic AI.


    *Index Terms*—Neurosymbolic AI, Validation, Verification, Evaluation, Testing,
    Deep Learning, Safety, Security, Trustworthiness


    ## I. INTRODUCTION


    N EUROSYMBOLIC artificial intelligence (AI) is an increasingly important trend
    in machine learning (ML) and has been referred to as the 3rd wave of artificial
    intelligence [\[1\]](#page-11-0). The word "neuro" in its name implies the use
    of neural networks, especially deep learning (DL), which is sometimes also referred
    to as sub-symbolic AI. This technique is known for its powerful learning and abstraction
    ability, allowing models to find underlying patterns in large datasets or learn
    complex behaviors [\[2\]](#page-11-1). On the other hand, "symbolic" refers to
    symbolic AI. It is based on the idea that intelligence can be represented using
    symbols like rules based on logic or other representations of knowledge [\[3\]](#page-11-2).
    Neurosymbolic AI combines these two approaches to create a hybrid system that
    benefits from the reasoning abilities of symbolic AI and the adaptability of sub-symbolic
    AI, opening new opportunities to improve a variety of different AI branches [\[4\]](#page-11-3),
    [\[5\]](#page-11-4).


    A disadvantage of sub-symbolic AI is its nature of being a "black box". This means
    that predictions made by these systems can be challenging to explain. Therefore,
    when an edge case leads to a system failure, it is often hard to find the reason
    for it. Accordingly, the rigorous testing & evaluation (T&E) and validation &
    verification (V&V) of these "black box" is a relevant topic recognized by governments
    [\[6\]](#page-11-5) and discussed in current literature [\[7\]](#page-11-6), [\[8\]](#page-11-7).
    As neurosymbolic systems incorporate a sub-symbolic component, this work aims
    to provide an overview of current techniques used to validate and verify the symbolic
    as well as sub-symbolic component, and how the architecture of neurosymbolic systems
    affects this process and can be used for V&V purposes.


    In software engineering, common terms are testing & evaluation or T&E and verification
    & validation or V&V. As defined by Wallace and Fujii in [\[9\]](#page-12-0), V&V
    intends to ensure that software performs as intended and meets certain quality
    and reliability standards. T&E are the methods and processes used to carry out
    V&V. Validation refers to the process of ensuring that a system performs as expected
    and delivers the desired result with sufficient accuracy, while verification focuses
    on checking if the design and implementation is correct according to the specified
    requirements [\[10\]](#page-12-1). Usually, verification is a process that takes
    place during development, while validation occurs at the end to evaluate if the
    program "does what it''s supposed to do" [\[11\]](#page-12-2). For reasons of
    readability, we primarily use the term V&V in the following.


    Recent frameworks propose methods to validate and verify symbolic and sub-symbolic
    AI, but discussing how the architecture of neurosymbolic AI can benefit the V&V
    process of the system as a whole has not received enough attention yet. Therefore,
    this paper focuses on two areas. First, the concept of V&V is mapped to symbolic
    and sub-symbolic AI, and an overview of current techniques and procedures used
    during the V&V process is provided. Secondly, it assesses how different neurosymbolic
    applications use the symbolic side to enable V&V of the sub-symbolic component.
    For this purpose, two different taxonomies of neurosymbolic AI are addressed,
    which categorize applications based on their architecture. 1) In 2020, Kautz proposed
    six possible designs of neurosymbolic systems [\[12\]](#page-12-3). 2) An alternative
    taxonomy was introduced by Yu et al. [\[13\]](#page-12-4) in 2021. These taxonomies
    are discussed and compared. Based on this, it is analyzed how current neurosymbolic
    applications leverage these architectures to use the symbolic component to make
    the sub-symbolic part more transparent, accurate, or safe, therefore enabling
    the V&V process through a neurosymbolic system design. The structure of the discussion
    within this paper is visualized in Fig. [1.](#page-2-0)


    Our work demonstrates that some of the current testing methods used for V&V are
    applicable to neurosymbolic AI. In particular, the combination of knowledge graphs
    (KGs) and DL is common, and it would be interesting to design a dedicated testing
    framework based on current techniques to validate neurosymbolic AI as a whole.
    However, there are also neurosymbolic AI applications that are not easy to test
    with current means. With this work, we show that there is much research potential
    in this area, and advocate the awareness of V&V for neurosymbolic AI systems and
    AI in general. Overall, this paper makes the following contributions:


    - Present and compare two current taxonomies of neurosymbolic AI.

    - Map the concepts of V&V as used in software engineer-


    ![](_page_2_Figure_6.jpeg)


    <span id="page-2-0"></span>Fig. 1. Contents of this paper.


    ing to symbolic and sub-symbolic AI.


    - Survey current V&V approaches for symbolic and subsymbolic AI.

    - Analyze the applicability of current V&V methods to neurosymbolic applications.

    - Investigate how symbolic AI can support the V&V process of sub-symbolic AI within
    a neurosymbolic system.

    - Discuss opportunities and challenges of V&V in the domain of neurosymbolic AI.


    The remainder of this paper is structured as follows: In section [II](#page-2-1)
    we analyze the related work. After that, in section [III](#page-3-0) we examine
    and compare two different taxonomies for neurosymbolic AI. Then, in section [IV](#page-5-0)
    and [V](#page-6-0) we survey the most important methods to verify and validate
    symbolic AI and sub-symbolic AI respectively. In section [VI](#page-8-0) we analyze
    if these methods are applicable to current neurosymbolic AI applications and opportunities
    to leverage different neurosymbolic architectures using the symbolic part to verify
    and validate sub-symbolic AI. Afterward, in section [VII](#page-10-0) we explain
    research gaps and problems that might be worth exploring in further research.
    In section [VIII](#page-11-8) we summarize our findings and explain our planned
    future work.


    ## II. RELATED WORK


    <span id="page-2-1"></span>V&V is a crucial process for ensuring the safety and
    reliability of safety-critical systems. Originally, V&V processes were designed
    for conventional software without AI components. With the increasing number of
    modern applications utilizing AI, it becomes crucial to develop approaches for
    the V&V of systems that use AI as a central element.


    ## *A. Surveys on V&V of Machine Learning*


    V&V of ML is an important topic in current research. For this reason, there are
    recent works and surveys that deal with this topic [\[7\]](#page-11-6), [\[8\]](#page-11-7),
    [\[14\]](#page-12-5)–[\[16\]](#page-12-6). Current surveys in this domain either
    deal with a specific area, such as autonomous systems [\[16\]](#page-12-6), in
    which ML is used, or only investigate one aspect like ML testing [\[14\]](#page-12-5),
    [\[15\]](#page-12-7) or formal verification of ML [\[7\]](#page-11-6), which are
    only parts of the entire V&V process.


    In [\[14\]](#page-12-5), testing of ML is surveyed. The survey presents current
    testing workflows, the components of an AI-based application that should be tested
    and provides an overview of properties that require testing as well as the frameworks
    that can be used to test these properties. Additionally, the survey showcases
    applications in safety-critical domains that need to be tested and how the testing
    workflows and frameworks can be applied to these applications.


    Similar, in [\[15\]](#page-12-7) testing approaches and current testing frameworks
    are presented. Compared to [\[14\]](#page-12-5), this survey is not as extensive
    and does not provide background information about topics like ML in general which
    is covered in [\[14\]](#page-12-5), but provides a comprehensive overview of current
    efforts regarding ML testing.


    Huang et al. [\[8\]](#page-11-7) provide a detailed overview of verification,
    testing and the interpretability of DL within their survey. They define the terms
    verification and testing and explain the importance and meaning of properties
    like the robustness or interpretability of DL. They explain differences between
    current approaches for V&V of DL and present a variety of testing frameworks and
    tools to increase the interpretability of DL.


    ## *B. Surveys on Neurosymbolic AI*


    There are multiple recent surveys that cover neurosymbolic AI and its applications
    in general [\[17\]](#page-12-8)–[\[24\]](#page-12-9) and surveys that focus on
    more specific applications such as graph structures [\[25\]](#page-12-10), biomedical
    knowledge graphs [\[26\]](#page-12-11), or natural language processing [\[27\]](#page-12-12).
    None of the just mentioned surveys covers testing, validation or verification
    in the domain of neurosymbolic AI and we could not find any surveys covering this
    topic to this date.


    ## III. TAXONOMIES OF NEUROSYMBOLIC AI


    <span id="page-3-0"></span>Neurosymbolic AI covers a wide range of applications,
    and can be implemented in many different ways. This concerns on the one hand the
    selection of methods used on the symbolic side, and on the other hand how sub-symbolic
    methods are combined with the symbolic ones. Therefore, it is common to divide
    neurosymbolic AI into different categories. Accordingly, multiple taxonomies for
    neurosymbolic AI were proposed [\[12\]](#page-12-3), [\[13\]](#page-12-4), [\[18\]](#page-12-13),
    [\[22\]](#page-12-14). In the following, two current taxonomies are discussed.
    The one from Kautz [\[12\]](#page-12-3) and Yu et al. [\[13\]](#page-12-4) are
    considered. Both taxonomies categorize neurosymbolic AI based on how the sub-symbolic
    and symbolic part interact with each other.


    ## *A. Kautz''s Taxonomy*


    Currently, one of the most common categorizations is that of Kautz, who defines
    six different types of neurosymbolic AI [\[12\]](#page-12-3). All of these types
    represent different system architectures, that try to combine the advantages of
    symbolic AI with those of sub-symbolic AI. Kautz defines the following categories:


    *a) Symbolic Neuro symbolic:* The input of the system is symbolic, then feed into
    a Neural Network, which outputs the symbolic result as well. A typical application
    of Symbolic Neuro Symbolic system is Natural Language Processing (NLP) and has
    become its Standard Operating Procedure (SOP) [\[12\]](#page-12-3). The symbolic
    input are representing embeddings converted from a combination of words extracted
    from the original text document. There are a lot of approaches to perform this
    conversion, such as word2vec [\[28\]](#page-12-15), and Glove [\[29\]](#page-12-16).
    Then those symbolic inputs are fed to a neural network that learns the underlying
    pattern to perform certain tasks, such as translation, semantic classification,
    and chat robot, etc. The output of the neural network is also symbolic in different
    forms based on the tasks. For example, the output is a sequence of words for translation
    tasks or a semantic label for classification tasks.


    *b) Symbolic[Neuro]:* This type of neurosymbolic AI uses a symbolic approach as
    a problem solver in a neural pattern recognition subroutine. It is currently already
    being used in many fields. One of the best-known applications is AlphaGo Zero
    [\[30\]](#page-12-17). Kautz states that most current autonomous vehicles and
    robots utilize this approach, but do not reference any applications from this
    domain.


    *c) Neuro*|*Symbolic:* The Neuro|Symbolic system performs symbolic reasoning based
    on non-symbolic input by leveraging neural networks to transform non-symbolic
    input (for example images) into a symbolic representation. The outputs of neural
    networks are fed into a symbolic representation which is used by a symbolic system
    to perform a complimentary task such as query answering [\[1\]](#page-11-0). All
    building blocks are connected so that learning happens in unison. Garcez and Lamb
    [\[1\]](#page-11-0) name the neuroßsymbolic concept learner [\[31\]](#page-12-18)
    and DeepProbLog [\[32\]](#page-12-19) as examples.


    *d) Neuro: Symbolic* −→ *Neuro:* Kautz describes this category as using the SOP
    which refers to the "Symbolic Neuro symbolic" category. It has a special training
    regime based on symbolic rules. An example for this method is an application by
    Lample and Charton [\[33\]](#page-12-20) which simplifies mathematical expressions.
    The description of this category is very abstract and Kautz refers to a formula
    for the training regime that is not explained further, which makes this category
    rather difficult to grasp.


    *e) Neuro* {*Symbolic*}*:* Within this category, the symbolic part''s purpose
    is to "transform symbolic rules into templates for structures within the neural
    network" [\[12\]](#page-12-3). Kautz references two examples, which are [\[34\]](#page-12-21)
    and [\[35\]](#page-12-22), to show how this concept can be used to integrate abstraction
    and part-of hierarchies into neural networks.


    *f) Neuro[Symbolic]:* Neuro[symbolic] is inspired by the "thinking fast and slow"
    theory from Kahneman [\[36\]](#page-12-23), who explains that the human brain
    has two different systems to make decisions. Neural Networks are similar to system
    1, which operates automatically by instinct without control. The symbolic part
    is similar to system 2, which needs attention and effort to operate. Just like
    a human brain, most of the time system 1 is making decisions until it decides
    to invoke system 2 is necessary. A Neuro[symbolic] system relies on a neural network,
    and the embedded symbolic AI assists if invoked by the neural network. This type
    of neurosymbolic AI is considered to have the highest potential by Kautz [\[12\]](#page-12-3).
    An example is a mouse-maze. Neural Networks recognize this task and invoke the
    symbolic engine, an algorithm to find the shortest path. The symbolic engine output
    the path with marks on the map which show the path. Then the neural network has
    been trained to interpret the marks and follow its guide to find the exit.


    Kautz''s categorization demonstrates how the symbolic part cooperates with the
    sub-symbolic part of the application. This categorization is useful to understand
    how an application as a whole works, but it also brings some problems with it.
    His categorization is very fine, and often it is difficult to clearly determine
    to which category an application belongs. Kautz explains some categories only
    superficially and gives a few examples, which makes it difficult to understand
    certain categories thoroughly. While for other categories, there are no applications
    yet, so it is questionable whether they are at all useful in practice. In addition,
    the names of his category are not well-chosen. The categories, when pronounced,
    are sometimes impossible to tell apart and confusion can quickly arise.


    ## *B. Yu''s Taxonomy*


    Because of the critique on Kautz''s survey, we present another survey by Yu et
    al. [\[13\]](#page-12-4) which provides an overview of current neurosymbolic applications
    and presents an alternative taxonomy. In their paper, current neurosymbolic AI
    applications are studied and divided into three groups: learning for reasoning,
    reasoning for learning, and learningreasoning. Just like Kautz''s taxonomy, the
    categories Yu et al. define represent how the symbolic part interacts with the
    subsymbolic part of the application. In the following paragraphs, the taxonomy
    of Yu et al. will be explained shortly:


    *1) Learning for Reasoning:* This approach integrates subsymbolic processes to
    enhance symbolic problem solving. Essentially, the sub-symbolic component narrows
    the search domain for the symbolic solver, optimizing the problemsolving process.
    This integration is depicted in Fig. [2.](#page-4-0) Another


    ![](_page_4_Figure_4.jpeg)


    <span id="page-4-0"></span>Fig. 2. Flowchart of the Learning for Reasoning type
    of neurosymbolic AI. The sub-symbolic component is used to limit the search space
    for the symbolic part. Therefore, it is accelerating the process [\[13\]](#page-12-4).


    way is that the sub-symbolic part converts unstructured data into symbols, to
    enable efficient symbolic reasoning as shown in Fig. [3.](#page-4-1)


    *2) Reasoning for Learning:* In this model, the roles are reversed: the sub-symbolic
    element primarily solves problems while the symbolic component supplements the
    neural network. This support manifests in two ways: firstly, by directing


    ![](_page_4_Figure_8.jpeg)


    <span id="page-4-1"></span>Fig. 3. Flowchart of the Learning for Reasoning type
    of neurosymbolic AI. In this version of Learning for Reasoning, the sub-symbolic
    part transforms the knowledge that can be obtained from data to symbols [\[13\]](#page-12-4).


    the neural network during its training phase, and secondly, by imposing constraints
    during prediction to prevent unsafe outcomes. Fig. [4](#page-4-2) illustrates
    this architecture.


    ![](_page_4_Figure_11.jpeg)


    <span id="page-4-2"></span>Fig. 4. Flowchart of the Reasoning for Learning type
    of neurosymbolic AI. Here, the symbolic part can guide or constrain the sub-symbolic
    part [\[13\]](#page-12-4).


    *3) Learning-Reasoning:* This variant represents a synergistic combination where
    symbolic and sub-symbolic elements collaborate equally in problem solving. Each
    component''s output directly informs the other''s input, creating a reciprocal
    and dynamic interaction. This bidirectional influence is visualized in Fig. [5.](#page-4-3)


    ![](_page_4_Figure_14.jpeg)


    <span id="page-4-3"></span>Fig. 5. Flowchart of the Learning-Reasoning type of
    neurosymbolic AI. Here, the characteristics of the other architectures are combined
    and the two parts are in constant interaction [\[13\]](#page-12-4).


    *4) Example:* Neurosymbolic approaches that implement safe reinforcement learning
    via shielding [\[37\]](#page-12-24) are great examples to showcase this taxonomy
    as the shielding can be implemented in multiple ways. For a control task, a subsymbolic
    model predicts an action, while a so called, safety shield, synthesized from safety
    specifications specified in temporal logic, ensures that every action is safe.
    If this application is implemented following the Learning for Reasoning or Learning-Reasoning
    design, first, the sub-symbolic part would make a decision based on its inputs
    from the environment. The decision is then given to the safety shield, that checks
    if the predicted action is safe and would then make minimal adjustments, if the
    action is determined to be unsafe. This concept would be categorized as Learning-Reasoning,
    in case feedback is provided to the sub-symbolic part, letting it know, that the
    action was replaced or not. If no feedback is provided, it would be Learning for
    Reasoning. This concept can be seen in Fig. [6.](#page-5-1)


    ![](_page_5_Figure_1.jpeg)


    <span id="page-5-1"></span>Fig. 6. After the agents (sub-symbolic part) predicts
    an action based on the inputs from the environment, a safety shield (symbolic
    part) checks if this decision is safe and replaces it with a safe action if necessary.
    It is optional (indicated in red) to provide the agent with the information that
    the action was replaced or not [\[38\]](#page-12-25).


    The work [\[38\]](#page-12-25) is similar to [\[37\]](#page-12-24), but extends
    the paper by presenting an additional architecture in which the shield is inserted
    before the sub-symbolic part. This allows the shield to limit the action space
    to make sure that every action the sub-symbolic part can choose from is safe.
    This design would be "Reasoning for Learning". This concept can be seen in Fig.
    [7.](#page-5-2)


    ![](_page_5_Figure_4.jpeg)


    <span id="page-5-2"></span>Fig. 7. A safety shield (symbolic part) limits the
    actions the agent (subsymbolic part) is able to choose from. Therefore, the agent
    is only able to choose from a set of safe actions [\[38\]](#page-12-25).


    In their survey, Yu et al. [\[13\]](#page-12-4) examine a wide range of current
    applications and classify them. They show that a variety of symbolic techniques
    can appear in every category of neurosymbolic AI. For example, first-order logic
    is used as a symbolic method in applications of all categories. This shows that
    the selection of the algorithms and methods for the symbolic as well as the sub-symbolic
    part is independent of the associated category. The categories in Yu''s taxonomy
    are only based on the interaction of the symbolic and sub-symbolic component.
    In the following sections, we will analyze which frameworks and methods are currently
    used to test the most common symbolic and sub-symbolic methods and how the symbolic
    part of the application can contribute to the testing of the sub-symbolic component.


    ## IV. V&V OF SYMBOLIC AI


    <span id="page-5-0"></span>As a first step, the V&V process of the two components
    of a neurosymbolic application are considered independently, with this section
    focusing on the symbolic component. Yu et al. [\[13\]](#page-12-4) shows that
    three methods in particular are used frequently as the symbolic part of a neurosymbolic
    AI system. These are propositional logic, first-order logic, and KGs. In the following
    section, the concepts of V&V are mapped to these techniques and the capabilities
    to validate and verify of symbolic AI are assessed.


    ## *A. Mapping V&V to Logical Systems*


    In term of V&V, the following properties are the most relevant: 1) Validity: A
    formula is valid if it is true under every possible interpretation or assignment.
    In logic, this means that if all premises of a statement are true, it is impossible
    that the conclusion is false. 2) Soundness: A logical system is sound if every
    statement that can be derived from the systems is true and an argument is sound
    if it is valid and its premises are true.


    When mapping logical arguments to the V&V process, the validity of a logic argument
    can be analogized to the verification phase. This is because a valid logical argument
    ensures structural correctness given that all premises are true, though it doesn''t
    necessarily affirm the truth of those premises. This is similar to the verification
    process checking if the implementation or design of a system is correct according
    to its specification. On the other hand, soundness aligns with the validation
    phase, as an argument is deemed sound only when all its premises are unequivocally
    true. This is analog to the validation phase, as this ensures that the output
    of a system is as expected and correct.


    ## *B. Verification of Logic*


    If a general algorithm can be found to prove the validity (true/false) of a logic
    argument, it is called decidable. Therefore, the question is: Are propositional
    logic and first-orderlogic decidable?


    1) Propositional logic is decidable. The validity of a statement can be determined
    by a truth table. Truth tables are a fundamental process of computer science.
    As Anellis''s research shows, it appears that this technique was used as early
    as the 19th century [\[39\]](#page-12-26). The complexity of this proof grows
    exponentially with the number of variables. Therefore, truth tables are in practice
    only usable for statements with a small number of propositional variables. Semantic
    tableau also called the truth tree method is an elegant alternative to truth tables
    [\[40\]](#page-12-27). Accordingly, it is possible to validate the symbolic part
    of a neurosymbolic AI application that uses propositional logic using this technique,
    even if current standards are rather inefficient.


    2) There is no general algorithm to check the validity of a first-order logic
    statement. Therefore, first-order logic statements are undecidable. However, this
    does not mean that it is impossible to show the validity of individual statements.
    Truth trees can be used to show the validity of first-order logic statements,
    but if the statement is invalid, the algorithm will run infinitely. To show an
    invalid statement, a countermodel has to be found.


    As described above, algorithms have been found to check the validity of logic
    arguments. Even though first-order logic is not decidable, tools like [\[41\]](#page-12-28),
    can be used to verify it in many cases. However, validity does not depend on whether
    the premises are true. This means that the following statement would be valid
    in terms of logic:


    ## *All animals are birds. All dogs are animals. Therefore, all dogs are birds.*


    The above example shows that a statement can be valid but not sound. Soundness,
    as explained before, describes that not only the syntax but also the semantic
    is valid. Therefore, additional knowledge has to be used, to validate the semantic
    of such an argument. For this purpose, KGs could be used for validation purposes,
    which again have to be validated, too. This problem is considered in more detail
    in the following section.


    ## *C. Validation of Knowledge Graphs*


    KGs are an increasingly important component of current applications. Accordingly,
    there are numerous methods for validating these graphs. The survey "Knowledge
    Graph Validation" by Huaman et al. gives an overview of current methods and tools
    [\[42\]](#page-12-29). Within this survey, several typical error sources which
    frequently occur in KG are described, and an overview is provided of which current
    tools are able to detect and correct such errors in order to create the most valid
    KG possible. A broad variety of tools are available to validate KGs.


    *1) Corroborative Fact Validation (COPAAL) [\[43\]](#page-12-30):* To validate
    KGs or semantic statements, COPAAL computes a socalled mutual information (MI)
    score. The method tries to find alternative sources on the web to validate a statement.
    The paper gives an example of how this method works; a given statement could be:
    "Barack Obama is a US citizen". Using open databases and KGs such as DBpedia 2016-10[1](#page-6-1)
    , the method looks for similar statements that imply or refute that Barack Obama
    is a US citizen. E.g. the data could show that his place of birth is in the USA
    which would make it highly likely that he is a US citizen or if the method finds
    a source that states that he was a US President, it confirms that the original
    statement is very likely to be correct, giving it a high MI score.


    *2) Deep Fact Validation (DeFacto) [\[44\]](#page-12-31):* To validate knowledge,
    DeFacto is an algorithm that tries to find supporting information about a given
    fact in the information as well as supporting information from trustworthy sources.
    Additionally, it provides a score that represents the confidence DeFacto has when
    assessing the validity of a fact.


    *3) Temporal Information Scoping (TISCO) [\[45\]](#page-12-32):* TISCO adds another
    component. This procedure tries to assign times to facts, since many assertions
    are only true at certain times. E.g. athletes regularly change their clubs, people
    may have different professions or live in different places at different points
    in their lives. Therefore, it is important not only to validate the facts, but
    also to link them to points in time in order to establish a timeline.


    In addition to the above-mentioned procedures, there are other similar procedures
    with the same goal. In all procedures, different databases or the web are searched
    based on an assertion in order to confirm and validate statements. Other popular
    methods are FactCheck [\[46\]](#page-12-33), FacTify [\[47\]](#page-12-34), Leopard
    [\[48\]](#page-12-35), Surface [\[49\]](#page-12-36) and S3K [\[50\]](#page-12-37).
    Furthermore, there are already well build KGs available that are tested and highly
    validated, like YAGO [\[51\]](#page-12-38) or Conceptnet [\[52\]](#page-12-39).
    YAGO is used by IBM in their Watson artificial intelligence system [\[53\]](#page-12-40)
    and stores knowledge about people, cities, countries, movies, and organizations.
    It was build with data from Wikipedia[2](#page-6-2) , WordNet [\[54\]](#page-12-41),
    which is also a widely used KG, and GeoNames[3](#page-6-3) . ConceptNet is a knowledge
    graph that links words and phrases with labeled edges. The information comes from
    a variety of sources, including crowdsourcing, expert-generated material, and
    games. Another popular KG is DBpedia[4](#page-6-4) which builds on knowledge from
    Wikipedia documents.


    ## V. V&V OF SUB-SYMBOLIC AI


    <span id="page-6-0"></span>V&V in the context of sub-symbolic AI is an exciting
    topic and also a big challenge, as deep learning is also often referred to as
    a "black box" and is rather opaque in its decisionmaking. Accordingly, it is a
    challenge to validate and verify the behavior of these systems. In order to verify
    a system, it is usually checked whether certain requirements are met. This is
    usually done with the help of formal methods and is a current challenge for systems
    using sub-symbolic AI due to its complexity. For the validation of sub-symbolic
    AI different testing methods are used to check different properties like the correctness
    or robustness of a system.


    ## *A. Verification of Sub-Symbolic AI*


    In the survey of Huang et al. [\[8\]](#page-11-7) various applications to verify
    sub-symbolic AI are presented. They provide a taxonomy for different verification
    approaches and define multiple properties that can be verified. In the following
    these approaches and properties as defined in [\[8\]](#page-11-7) are summarized.


    *1) Properties to Verify:*


    <span id="page-6-5"></span>*a) Robustness:* Robustness can be defined as the ability
    of a model to make a correct decision even in situation when the input is noisy
    or manipulated [\[55\]](#page-12-42).


    <span id="page-6-1"></span><sup>1</sup>https://www.faa.gov/air [traffic/publications/atpubs/atc](https://www.faa.gov/air_traffic/publications/atpubs/atc_html/chap5_section_7.html)
    html/chap5 secti on [7.html,](https://www.faa.gov/air_traffic/publications/atpubs/atc_html/chap5_section_7.html)
    accessed: 01/26/2023


    <span id="page-6-2"></span><sup>2</sup>[https://www.wikipedia.org/,](https://www.wikipedia.org/)
    accessed: 01/29/2023


    <span id="page-6-4"></span><span id="page-6-3"></span><sup>3</sup>[https://www.geonames.org/,](https://www.geonames.org/)
    accessed: 01/29/2023


    <sup>4</sup>[https://www.dbpedia.org/resources/knowledge- graphs/,](https://www.dbpedia.org/resources/knowledge-graphs/)
    accessed: 01/26/2023


    *b) Reachability & Interval:* The reachability and interval are two very similar
    properties, closely connected to each other. Verifying the reachability means,
    that for a certain input the highest possible and lowest possible output is verified.
    Verifying the interval is very similar, as it is an overapproximation of the reachability.


    *c) Lipschitzian:* This property describes how the output changes when small changes
    are made to the input. When verifying this property, the change in output should
    remain below a specified distance.


    *2) Approaches:*


    *a) Search-Based:* Verification algorithms belonging to this type verify the system
    through exhaustive searching. This approach uses algorithms such as the Monte-Carlo
    Tree Search for verification purposes [\[56\]](#page-13-0).


    *b) Constraint Solving:* Algorithms that leverage this approach convert neural
    network into constraints which are easier to verify because they are no longer
    a "black box". For the verification of the resulting constraints, solvers like
    the SAT solver can be used.


    *c) Over-Approximation:* Here, an over-approximation of possible outputs for an
    input is calculated for verification purposes.


    *d) Global Optimization:* As the name suggests, these approaches are based on
    global optimization techniques. An example for this is the tool DeepGo [\[57\]](#page-13-1)
    that uses global optimization techniques for verification in respect to reachability
    and robustness properties.


    An in-depth explanation for the verification of sub-symbolic AI can be found in
    [\[8\]](#page-11-7). Table [I](#page-7-0) provides an overview of current approaches
    that can be used for the verification of sub-symbolic AI.


    <span id="page-7-0"></span>TABLE I APPROACHES TO VERIFY SUB-SYMBOLIC AI AS SURVEYED
    IN [\[8\]](#page-11-7).


    | Approach                                | Publications    |

    |-----------------------------------------|-----------------|

    | Search-Based                            | [56], [58]      |

    | Constraint Solving                      | [59]–[66]       |

    | Over-Approximation                      | [57], [67]–[70] |

    | Search-Based & Constraint Solving       | [71], [72]      |

    | Over-Approximation & Constraint Solving | [73]–[75]       |

    | Global Optimization                     | [57], [70]      |


    ## *B. Validation of Sub-Symbolic AI*


    To validate sub-symbolic AI, a variety of measures can be tested. In [\[14\]](#page-12-5)
    these measures as well as the tools and frameworks to test these in order to validate
    such a system is surveyed. The measures addressed in this survey are the correctness,
    model relevance, efficiency, fairness, interpretability, privacy and robustness
    of the system. In [\[8\]](#page-11-7) especially testing the robustness and increasing
    the interpretability are addressed. Depending on the use case of the application,
    some of these properties are particularly important. Within this survey especially
    the correctness, robustness and interpretability


    <span id="page-7-1"></span>TABLE II WORKS ON TESTING THE CORRECTNESS AS SURVEYED
    IN [\[14\]](#page-12-5)


    | Testing Correctness                 | Publications |

    |-------------------------------------|--------------|

    | Testing Tools                       | [79], [80]   |

    | Testing the Input and Oracle Design | [81]–[86]    |

    | Searching Data Bugs                 | [87], [88]   |


    are considered for validation purposes. In the following, a brief overview of
    these measures and recent frameworks is provided.


    *1) Properties to Validate:*


    *a) Correctness:* Correctness is a fundamental property of a system, representing
    the probability that it completes a task correctly. Popular methods to measure
    the correctness are k-fold cross-validation [\[76\]](#page-13-17) and Bootstrapping
    [\[77\]](#page-13-18). For classification tasks, metrics like accuracy, precision/recall,
    and ROC Curve are commonly used to measure the correctness. Suitability varies
    depending on the situation and data balance. Detailed examples can be found in
    Japkowicz''s workshop [\[78\]](#page-13-19). Regression problems can be evaluated
    using error measurements, such as Mean-Squared-Error (MSE) or Root Mean-Squared-Error
    (RMSE), which provide insights into expected deviations from the system''s predictions.
    In summary, choosing the appropriate measurement is crucial to assess the correctness
    of a sub-symbolic system and should be carefully considered based on the task
    and data distribution. Table [II](#page-7-1) shows a selection of works that focus
    on testing the correctness of sub-symbolic AI. It is based on applications surveyed
    in [\[14\]](#page-12-5).


    *b) Robustness:* The robustness property itself is similar to the one described
    in section [V-A1a.](#page-6-5) The difference is that robustness can not only
    be verified, but also tested and therefore validated. The most common approach
    to test the robustness is to generate adversarial examples or inputs. Frameworks
    such as DeepXplore [\[89\]](#page-13-20), DeepHunter [\[90\]](#page-13-21) or
    DLFuzz [\[91\]](#page-13-22) use adversarial attacks to trigger misbehavior and
    therefore to test the robustness of a neural network. Techniques such as testing
    the code coverage, known from conventional software testing, can be adapted to
    sub-symbolic AI. These approaches maximize a metric called neuron coverage to
    improve the robustness of a sub-symbolic model. Another approach is to detect
    adversarial noise that might cause wrong predictions [\[92\]](#page-14-0), [\[93\]](#page-14-1).
    While these methods focus on images, there are other approaches that focus on
    generating and detecting adversarial attacks for natural language processing [\[94\]](#page-14-2)
    or cybersecurity [\[95\]](#page-14-3), which can be used to test and improve the
    robustness of these models.


    *2) Interpretability:* Neural networks are often considered to be "black boxes",
    because it is a challenge to comprehend the decision-making process of a trained
    model. However, in safety-critical and ethically sensitive domains, it is crucial
    to understand this process to prevent discrimination or system failures. Although
    there is no uniform definition of interpretability, previous work suggests that
    it refers to the degree to which humans can comprehend the reasoning and logic
    behind a deep learning system''s decisions [\[14\]](#page-12-5), [\[96\]](#page-14-4).


    To evaluate interpretability, there are three main categories: Manual assessment,
    automatic assessment, and evaluation of interpretability improvement [\[14\]](#page-12-5).
    Manual assessment involves humans in the loop and is evaluated in real applications.
    Automatic assessment, on the other hand, utilizes proxies to eliminate the need
    for human involvement. Identifying influential instances belongs to this approach,
    which can be achieved through two methods: Deletion Diagnostics and Influence
    Functions [\[97\]](#page-14-5). Both methods detect influential instances by measuring
    the influence of the change to the model when modifying the data sets: Deletion
    Diagnostics remove data points, while Influence Functions up-weight instances
    by differentiating the loss function with respect to its parameters. Notable measures
    of Deletion Diagnostics are DFBETA [\[98\]](#page-14-6) and Cook''s distance [\[99\]](#page-14-7).


    ## VI. OPPORTUNITIES


    <span id="page-8-0"></span>As shown in Fig. [8,](#page-8-1) one solution is to
    verify and validate both sides of a neurosymbolic AI separately. Another solution
    is to leverage the characteristics of the symbolic AI to verify and validate sub-symbolic
    part. In the following, we will consider both approaches and assess whether and
    how current testing and validation methods can be applied to the isolated parts
    of a neurosymbolic application and how current applications leverage the characteristics
    of symbolic policies to validate or improve the properties of the sub-symbolic
    part.


    ![](_page_8_Figure_3.jpeg)


    <span id="page-8-1"></span>Fig. 8. It is possible to either verify and validate
    the parts of a neurosymbolic application independently or the symbolic part can
    be used to either ease or conduct the V&V process of the sub-symbolic part.


    ## *A. Using Neurosymbolic System Architectures for V&V*


    Each of the three different categories of neurosymbolic AI defined by Yu et al.
    [\[13\]](#page-12-4) presented in their paper can affect the V&V process differently.
    For example, in "Reasoning for Learning", the symbolic part can support the sub-symbolic
    AI by providing guidelines and constraints through e.g. logic rules. This means
    that the input is directly applied to the sub-symbolic AI, as shown in Fig. [4.](#page-4-2)
    The symbolic part can therefore improve the robustness and correctness of the
    system by checking, constraining or replacing decisions made by the sub-symbolic
    model. The category "Learning for Reasoning" uses the symbolic part as problem
    solver. This means that the inputs directly go into the sub-symbolic part. It
    is feasible to transform the inputs to the sub-symbolic part to symbolic rules
    that allow to make transparent decisions and therefore increase the interpretability
    of the overall system. Both "Learning for Reasoning" as well as "Reasoning for
    Learning", have the potential to improve the efficiency by accelerating the learning
    process either through guidance by symbolic rules or by limiting the search space
    with the sub-symbolic model. All of these concepts can also be applied to the
    category "Learning-Reasoning". In the following, we give multiple examples based
    on current neurosymbolic applications that leverage these architectures and explain
    the opportunities these techniques provide to increase the safety and trustworthiness
    in AI and especially DL. An overview of selected applications is given in table
    [III.](#page-9-0)


    *1) Safe Reinforcement Learning:* A popular application for neurosymbolic AI is
    safe reinforcement learning for autonomous control tasks. Alshiekh et al. [\[37\]](#page-12-24)
    propose a concept to synthezise a safety shield from formal specifications represented
    in linear temporal logic. As already mentioned in section [III,](#page-3-0) the
    integration of this shield into the neurosymbolic systems is very versatile and
    every architecture according to Yu''s taxonomy is possible. In recent years, several
    similar approaches have been proposed, often using the "Learning for Reasoning"
    or "Learning-Reasoning" architecture to make the minimal needed adjustments to
    guarantee safe actions. One of the more recent works is "Neurosymbolic Reinforcement
    Learning with Formally Verified Exploration" [\[100\]](#page-14-8). The paper
    introduces a reinforcement learning framework called REVEL. Similar to [\[37\]](#page-12-24),
    symbolic rules are used as a verification step within the deep reinforcement learning
    loop providing a safety shield that keeps the agent from executing unsafe actions.
    Therefore, this application can be categorized as "Learning-Reasoning", showing
    how architecture can help to improve the correctness and robustness of a system.
    The paper demonstrates the results using a total of 10 benchmarks and compares
    them with similar state-of-the-art approaches. Compared to Deep Deterministic
    Policy Gradients (DDPG) [\[101\]](#page-14-9), the framework performs better in
    7 out of 10 scenarios. Compared to Constrained policy optimization (CPO) [\[102\]](#page-14-10),
    however, it performs better in only 4 out of 10 cases. The survey "A Review of
    Safe Reinforcement Learning: Methods, Theory and Applications" by Gu et al. [\[103\]](#page-14-11)
    provides an overview of safe reinforcement learning with many different approaches
    often using neurosymbolic AI for verification purposes. Additionally, the authors
    maintain a GitHub repository[5](#page-8-2) listing current works in this domain.


    *2) Verifiable Reinforcement Learning via Policy Extraction [\[104\]](#page-14-12):*
    Another approach to increase the interpretability and transparency of the decisions
    of the sub-symbolic part of a neurosymbolic system is to derive rules from predictions.
    The neurosymbolic framework VIPER, which follows the "Learning for Reasoning"
    architecture, is doing this by deriving rules from predictions of a neural network.
    These rules are represented by a decision tree. This approach helps to make decisions
    easier and more efficient to validate and verify. Furthermore, it makes the decisions
    of the entire system more transparent.


    <span id="page-8-2"></span><sup>5</sup>[https://github.com/chauncygu/Safe-Reinforcement-Learning-Baselines,](https://github.com/chauncygu/Safe-Reinforcement-Learning-Baselines)
    accessed: 12/09/2023


    <span id="page-9-0"></span>TABLE III A SELECTION OF PAPERS THAT USE SYMBOLIC AI
    FOR V&V OF THE SUB-SYMBOLIC PART


    | Paper | Category                                                                                     |
    Summary                                                                                                                       |
    V&V Aspect                                                                                           |

    |-------|----------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|

    | [100] | Learning<br>Reasoning                                                                        |
    Verify<br>predictions<br>using<br>a<br>symbolic<br>"safety policy"                                                            |
    Increasing correct<br>ness and robustness<br>by ensuring a safe<br>output                            |

    | [105] | Non<br>Appli<br>cable                                                                        |
    Convert 3D objects<br>to code which is<br>then<br>converted<br>to<br>3D shapes                                                |
    Improves<br>validity<br>by<br>increasing<br>the<br>interpretability                                  |

    | [104] | Learning for<br>Reasoning                                                                    |
    Learn<br>a<br>provable<br>decision-tree policy                                                                                |
    Improves<br>validity<br>by<br>increasing<br>the<br>interpretability                                  |

    | [106] | Learning for<br>Reasoning                                                                    |
    Learn<br>programmatic<br>policies<br>from<br>tasks<br>that<br>can<br>be<br>described<br>by<br>Markov<br>Decision<br>Processes
    | Improves<br>validity<br>by<br>increasing<br>the<br>interpretability                                  |

    | [38]  | Learning for<br>Reasoning<br>or Learning<br>Reasoning<br>(based<br>on<br>implementa<br>tion)
    | Restrict<br>a<br>DP<br>model or overwrite<br>its decision to allow<br>safe<br>reinforcement<br>learning                       |
    Validate predictions<br>or<br>restrict<br>DL<br>model to improve<br>correctness<br>and<br>robustness
    |

    | [107] | Learning<br>Reasoning                                                                        |
    Learning<br>semantic<br>video<br>representations<br>in<br>a<br>neurosymbolic<br>weak<br>supervised<br>learning
    setup          | Verify<br>learning<br>results by checking<br>against<br>logical<br>specifications                    |


    *3) Learning to Synthesize Programs as Interpretable and Generalizable Policies
    [\[106\]](#page-14-14):* This framework follows a similar approach as "Verifiable
    Reinforcement Learning via Policy Extraction" [\[104\]](#page-14-12). The difference
    is that [\[106\]](#page-14-14) does not use limited policy representations in
    the context of decision trees, but learns to synthesize a program soly on rewards.
    The derived policies can make the decisions more transparent than those of conventional
    DL methods.


    *4) Learning to Infer and Execute 3D Shape Programs [\[105\]](#page-14-13):* This
    application is interesting because unlike the others, it does not quite fit Yu''s
    taxonomy [\[13\]](#page-12-4) because it uses a total of two sub-symbolic parts
    and one symbolic part. Again, the symbolic part gives more accurate results and
    especially increases transparency compared to existing DL methods. The goal of
    the program is to represent a 3D object as 3D shapes. For this, first, an object
    is represented as code by means of a "Neural Program Generator". Then a "Neural
    Program Executor" converts the code to 3D shapes. The code is humanreadable, and
    therefore it is possible to see which shapes of the 3D object have been recognized.
    This increases the interpretability.


    *5) LASER [\[107\]](#page-14-15):* Huang et al. [\[107\]](#page-14-15) present
    a weakly supervised neurosymbolic learning approach to learn semantic video representations.
    The approach receives videos and spatio-temporal specifications in the form of
    linear temporal logic (LTL) as inputs. During the learning process an "alignment
    score" of the specifications and the learned semantic representation is calculated.
    This allows for a verification of the learned representation. The alignment is
    optimized during the learning process.


    ## *B. Assessing the Applicability of Current T&E/V&V Methods to Neurosymbolic
    AI*


    In this section, we address opportunities we have through current V&V methods
    to determine where these approaches reach their limits in neurosymbolic applications.


    *1) Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs [\[108\]](#page-14-16):*
    This method, which according to Yu''s taxonomy [\[13\]](#page-12-4) belongs to
    the category "Reasoning for Learning", deals with zero-shot learning. The approach
    deals with unknown classes by using knowledge about previously learned classes
    and additional semantic embeddings. It uses both semantic embeddings and categorical
    relationships to predict the classes of unknown pictures. The core of the application
    consists of two components: One component is a knowledge graph (KG), and the other
    is a graph convolutional network (GCN). The paper uses multiple configurations
    of datasets for its experiments. In the first one, the KG is based on relationships
    from Never-Ending Language Learning (NELL) [\[109\]](#page-14-17) and images are
    taken from the Never-Ending Image Learning (NEIL) [\[110\]](#page-14-18) dataset.
    In the second configuration, the KG is based on the WordNet [\[54\]](#page-12-41)
    database while the images for the GCN model''s training are taken from the ImageNet
    [\[111\]](#page-14-19) dataset. The KG can be validated with the previously analyzed
    methods. The paper investigates how the method behaves when noise is introduced
    in the KG and when it is completely random. It is shown that the method is quite
    robust even when noise is present in the KG. However, if it is random, then the
    outputs are almost random guesses. Therefore, while it is important that the KG
    is validated by the GCN, which is the problem solver in this procedure, we compensate
    for noise but do not need to validate the KG perfectly and focus on the GCN. There
    are several types of the still rather new GCN. The type used in the paper is based
    on convolutional neural networks (CNNs). This would mean that approaches such
    as [\[112\]](#page-14-20) to find robustness guarantees in GCNs could be used
    for verification and benchmarking tools like [\[113\]](#page-14-21), [\[114\]](#page-14-22)
    for validation purposes. Even though there are some works regarding V&V of GCN
    it is a rather unexplored topic, which would be exciting to further investigate.


    *2) Alpha Go Zero [\[30\]](#page-12-17):* AlphaGo Zero is an application developed
    by DeepMind. It is able to beat the world''s best players in games like Chess
    or Go. This application is not listed in Yu''s [\[13\]](#page-12-4) survey, but
    Kautz''s [\[12\]](#page-12-3) uses it as an example for his category Symbolic[Neuro].
    If this method were included in Yu''s taxonomy, it would belong to the category
    "Learning for Reasoning". A neural network evaluates the state of the game on
    the sub-symbolic part of the application, while a Monte Carlo Tree Search [\[115\]](#page-14-23)
    tries to find the optimal move for the given situation on the symbolic part. Therefore,
    this application has a symbolic problem solver with a neural network supporting
    the decision-making process. AlphaGo Zero is trained by playing against itself
    in an attempt to find better moves and thus better models. AlphaGo Zero''s model
    trains itself and no human-generated data set is needed. This means that the system
    does not need to be protected against noisy or manipulated data. In addition,
    it is not a safetyrelevant application. Therefore, robustness is not necessarily
    in the foreground, since targeted manipulations would be unlikely and futile.
    While the interpretability of AlphaGo Zero''s decisions is interesting, it is
    not the priority when testing or verifying the system. The goal of AlphaGo Zero
    is to develop the strongest possible chess engine that can defeat any opponent.
    For this reason, the main focus in testing the program is on the correctness.
    To validate the Monte Carlo Tree Search, all possible moves for each possible
    game state would have to be evaluated to find the optimal solution. For games
    like TikTakToe, this would not be a problem, but since games like Chess or Go
    have too many different game states, this would not be feasible with current technology.
    To simplify this, the neural network looks at each game situation and evaluates
    it. Since numerous game states are very similar and similar moves would be optimal,
    the DL part tries to identify these relationships between the different situations
    to reduce the possibilities that need to be evaluated. This means that in order
    for the symbolic problem solver to be able to make the correct decision, the sub-symbolic
    part must have assessed the situation correctly beforehand. Thus, a labeled test
    data set would need to be created against which the model could be tested to make
    sure the game states are detected correctly. However, since AlphaGo Zero has never
    been beaten by a human, it is impossible to decide whether the human made a mistake
    in labeling or if AlphaGo Zero made a mistake in evaluating a game situation if
    differences occur. However, as improvements are constantly being made, especially
    in the efficiency of this process, it is clear that even though the models so
    far are very good, there is still room for improvement. The only way to test AlphaGo
    Zero at the moment is to let it play more games against itself to find better
    models, even if this is very inefficient. For this reason, however, optimizing
    the efficiency of AlphaGo Zero''s training is also interesting, since the more
    efficient this is, the faster better results can be obtained and thus the most
    important property in this scenario, correctness, is also improved. To summarize
    this; there is no current test framework that would be applicable to an application
    like AlphaGo Zero.


    *3) DeepProbLog [\[116\]](#page-14-24):* DeepProbLog is a neurosymbolic AI framework
    belonging to the category learning for reasoning according to Yu''s taxonomy.
    The sub-symbolic part is responsible for the low-level perception task, and the
    symbolic part then uses the learning result to perform logical inference. In their
    research, three sets of a total of six experiments are conducted to demonstrate
    the different abilities of DeepProbLog. In five out of six experiments, DeepProbLog
    outperforms the DL model itself, showing better generalization ability, less computational
    complexity and training time, and higher sample efficiency. The tasks in the experiments
    are the addition of single digits and multi-digits, sorting a list of numbers,
    and the coin-ball problem [\[117\]](#page-14-25), where the subsymbolic part is
    used to recognize the numbers or colors in an image, and the symbolic part uses
    the classification results to complete the addition operation or to calculate
    the probability distribution. The sub-symbolic components used in these tasks
    are convolutional neural networks (CNNs) with basic architectures. The experiments
    used the MNIST data set. Input testing could be conducted to expose robusteness
    flaws [\[14\]](#page-12-5). Testing frameworks like DLFuzz could be used to generate
    adversarial samples and improve the robustness of the CNNs [\[118\]](#page-14-26).
    For the sorting task, the sub-symbolic part uses recurrent neural networks (RNNs)
    which are similar as the ones used in the work of Bosnjak et al. [\[119\]](#page-14-27).
    These could be tested by TensorFuzz [\[120\]](#page-14-28), which is used to find
    undesired behaviors of RNNs. Also, cross-validation could be used during the training
    to validate the models performance. The symbolic part of DeepProbLog follows the
    inference process of ProbLog: First, generate the ground instances the query is
    based on; Second, rewrite the ground logic into a propositional logic formula;
    Next, the formula is compiled into a Sentential Decision Diagram (SDD) [\[121\]](#page-14-29)
    for more efficient evaluation; Finally, calculate the probability. Since this
    system is based on propositional logic, the symbolic part is decidable and could
    be verified e.g. using semantic tableau.


    ## VII. OPEN CHALLENGES


    <span id="page-10-0"></span>Examining the current state of neurosymbolic AI and
    current V&V methods, we have revealed numerous open challenges. These open challenges
    address neurosymbolic AI and its applications in general, as well as the V&V methods
    for both symbolic and sub-symbolic AI.


    *a) Investigating New Neurosymbolic Architectures:* The term "neurosymbolic AI"
    is still relatively new at the time this paper was written. As our research has
    shown, it is difficult to find papers on the topic on the well-known platforms
    of ACM and IEEE. However, this is not because no one uses this concept, but because
    the term is not yet widely used in the scientific community. The works by Kautz
    [\[12\]](#page-12-3) and Yu et al. [\[13\]](#page-12-4) make important contributions
    by identifying and categorizing existing applications that use this technique.
    Similar works are published frequently, but there is still no widespread differentiation
    of different categories of neurosymbolic AI and terms as well as clear definitions
    must be established in the future. We have criticized Kautz''s taxonomy for the
    fact that some of his categories are only theoretical with no applications implementing
    them and thus some categories are not practical at the moment. But this also shows
    that there are many opportunities to combine symbolic with sub-symbolic AI that
    have not been explored yet and are worth exploring to find out what potential
    neurosymbolic AI has.


    *b) Efficient Verification of Logic Rules:* Traditional methods like truth tables,
    which can be used to verify propositional logic, are very computationally intensive
    as their run-time depends on the number of parameters. This means that these methods
    do not scale well. However, depending on how the sub-symbolic part is related
    to the symbolic part, it may not be necessary to fully verify the symbolic part.
    Neural networks have the advantage that they can usually deal well with noise
    in the data. That means, if the problem solver is the subsymbolic part and the
    symbolic part has only a supporting function, it would be sufficient to approximate
    a complete verification. This approach could be further investigated and used
    to balance the computational cost and scalability with the need for accuracy and
    logical correctness.


    *c) Testing of Emerging DL Architectures:* Methods for testing the correctness,
    robustness, and other metrics for neural networks are well-researched and are
    constantly being further developed. It happens again and again that new designs
    for neural networks are developed. These new architectures require either new
    testing methods or the adapting of existing ones. In the paper "Zero-shot Recognition
    via Semantic Embedding and Knowledge Graphs" [\[108\]](#page-14-16) a GCN is used
    on the sub-symbolic part of the application. It would be interesting to explore
    whether it is possible to apply methods such as DLFuzz [\[91\]](#page-13-22) here.


    *d) Comparing the Efficiency of Neurosymbolic AI with Comparable Conventional
    Deep Learning Approaches:* Through neurosymbolic AI it is possible to perform
    the training process of a DL model in a more targeted way, since the symbolic
    part can guide and thereby support the sub-symbolic part during training and the
    decision-making process. Therefore, it would be interesting to compare whether
    neurosymbolic AI applications are more efficient in terms of runtime and possibly
    also in terms of energy consumption. Measuring the efficiency of software systems
    and AI are exciting topics that are currently being researched. Since energy-efficient
    training AI can save costs for companies and research institutions as well as
    protect the environment, it is exciting to look at the influence of neurosymbolic
    AI on the efficiency of training. The assessments could be based on existing metrics
    and test procedures for evaluating the resource efficiency of ML [\[122\]](#page-14-30),
    [\[123\]](#page-14-31).


    *e) Apply Current V&V Methods to Common Neurosymbolic Applications:* It could
    be tested whether existing V&V methods can be applied to common neurosymbolic
    applications as explained in the opportunities area. The currently most popular
    neurosymbolic AI applications could be used as examples. This could be extended
    and a testing framework for neurosymbolic AI applications could be developed,
    because there are some configurations that are frequently used. For example, KGs
    are often combined with CNNs. Test frameworks could be developed for these standard
    configurations with respect to the architecture of the application.


    *f) Development of Dedicated Testing Frameworks for Applications using Neurosymbolic
    AI:* At present, there are only a few frameworks for testing neurosymbolic applications,
    as this is still a very new field. While our paper focuses on testing the individual
    components and using symbolic AI to test the sub-symbolic component within the
    system, there are first frameworks that test the whole neurosymbolic system as
    such. These testing frameworks are showing initial success in domain-specific
    applications. For example, Large Language Models (LLMs) are a popular area of
    application for neurosymbolic AI. Accordingly, the paper [\[124\]](#page-14-32)
    introduces a "diversity measure" based on entropy, Gini impurity, and centroid
    distance as a metric to determine the probability of failure of LLMs. Furthermore,
    for the neurosymbolic LASER [\[107\]](#page-14-15) approach for learning semantic
    representations of videos a new model checker was needed. Accordingly, they implemented
    a model checker based on Scallop [\[125\]](#page-14-33) for verification purposes.
    This shows that there is a great need for new model checkers and testing procedures
    for appplications based on neurosymbolic AI.


    ## VIII. CONCLUSION


    <span id="page-11-8"></span>Within this paper, the current state of neurosymbolic
    AI was investigated, as well as the current possibilities to test, evaluate verify
    and validate neurosymbolic AI. Two taxonomies that categorize neurosymbolic applications
    based on the system''s architecture describing how the symbolic and sub-symbolic
    parts of the application interact with each other were assessed. Afterwards, the
    standard procedures to verify and validate common approaches used on the symbolic
    as well as the subsymbolic part were surveyed. Based on this, it was analyzed
    whether it is possible to apply these strategies to popular neurosymbolic applications
    mentioned in recent surveys. It was found that the applicability of current testing
    methods strongly relates to the algorithms used on the symbolic and sub-symbolic
    parts. While there are V&V methods for most approaches used on the symbolic part,
    these are sometimes too computationally expensive for large-scale projects. Therefore,
    it is important to question how thorough the testing on this side has to be, since
    neural networks can handle noisy data well if the symbolic part is only supporting.
    For the subsymbolic side, current testing frameworks can often be used for the
    V&V. These may be modified if necessary, however, this area is still a vivid research
    area, and it may happen that neurosymbolic applications use concepts for which
    no current testing framework exist. Furthermore, some applications demonstrate
    how the symbolic part of the application can be used to make neural networks more
    transparent, robust or accurate. This approach offers many opportunities and is
    still very unexplored, so it is exciting to explore this technique in future works
    including different environments and applications. In addition, it was found that
    there is a growing need for dedicated testing frameworks specialized for domainspecific
    neurosymbolic applications.


    ## REFERENCES


    - <span id="page-11-0"></span>[1] A. d. Garcez and L. C. Lamb, "Neurosymbolic
    ai: The 3 rd wave," *Artificial Intelligence Review*, pp. 1–20, 2023.

    - <span id="page-11-1"></span>[2] C. M. Bishop, "Neural networks and their applications,"
    *Review of scientific instruments*, vol. 65, no. 6, pp. 1803–1832, 1994.

    - <span id="page-11-2"></span>[3] M. Garnelo and M. Shanahan, "Reconciling deep
    learning with symbolic artificial intelligence: representing objects and relations,"
    *Current Opinion in Behavioral Sciences*, vol. 29, pp. 17–23, 2019.

    - <span id="page-11-3"></span>[4] K. Acharya, W. Raza, C. Dourado, A. Velasquez,
    and H. H. Song, "Neurosymbolic reinforcement learning and planning: A survey,"
    *IEEE Transactions on Artificial Intelligence*, pp. 1–14, 2023.

    - <span id="page-11-4"></span>[5] A. Velasquez, "Transfer from imprecise and abstract
    models to autonomous technologies (tiamat)," *Defense Advanced Research Projects
    Agency (DARPA) Program Solicitation*, 2023.

    - <span id="page-11-5"></span>[6] Oct 2023. [Online]. Available: [https://www.whitehouse.gov/briefing-r](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)
    [oom/presidential-actions/2023/10/30/executive-order-on-the-safe-sec](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)
    [ure-and-trustworthy-development-and-use-of-artificial-intelligence/](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)

    - <span id="page-11-6"></span>[7] X. Huang, "Safety and reliability of deep learning:
    (brief overview)," in *Proceedings of the 1st International Workshop on Verification
    of Autonomous & Robotic Systems*, ser. VARS ''21. New York, NY, USA: Association
    for Computing Machinery, 2021. [Online]. Available: <https://doi.org/10.1145/3459086.3459636>

    - <span id="page-11-7"></span>[8] X. Huang, D. Kroening, W. Ruan, J. Sharp, Y.
    Sun, E. Thamo, M. Wu, and X. Yi, "A survey of safety and trustworthiness of deep
    neural networks: Verification, testing, adversarial attack and defence, and interpretability,"
    *Computer Science Review*, vol. 37, p. 100270, 2020. [Online]. Available: [https://www.sciencedirect.com/science/arti](https://www.sciencedirect.com/science/article/pii/S1574013719302527)
    [cle/pii/S1574013719302527](https://www.sciencedirect.com/science/article/pii/S1574013719302527)

    - <span id="page-12-0"></span>[9] D. Wallace and R. Fujii, "Software verification
    and validation: Its role in computer assurance and its relationship with software
    project management standards," 1989-09-05 1989. [Online]. Available: [https://tsapps.nist.gov/publication/get](https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=905731)
    pdf.cfm?pub id=905731

    - <span id="page-12-1"></span>[10] R. G. Sargent, "A tutorial on validation and
    verification of simulation models," in *Proceedings of the 20th conference on
    Winter simulation*, 1988, pp. 33–39.

    - <span id="page-12-2"></span>[11] D. Wallace and R. Fujii, "Software verification
    and validation: an overview," *IEEE Software*, vol. 6, no. 3, pp. 10–17, 1989.

    - <span id="page-12-3"></span>[12] H. Kautz, "The third ai summer: Aaai robert
    s. engelmore memorial lecture," *AI Magazine*, vol. 43, no. 1, pp. 93–104, Mar.
    2022. [Online]. Available: <https://ojs.aaai.org/index.php/aimagazine/article/view/19122>

    - <span id="page-12-4"></span>[13] D. Yu, B. Yang, D. Liu, H. Wang, and S. Pan,
    "A survey on neural-symbolic learning systems," *Neural Networks*, vol. 166, pp.
    105–126, 2023. [Online]. Available: [https://www.sciencedirect.com/sc](https://www.sciencedirect.com/science/article/pii/S0893608023003398)
    [ience/article/pii/S0893608023003398](https://www.sciencedirect.com/science/article/pii/S0893608023003398)

    - <span id="page-12-5"></span>[14] J. M. Zhang, M. Harman, L. Ma, and Y. Liu,
    "Machine learning testing: Survey, landscapes and horizons," *IEEE Transactions
    on Software Engineering*, vol. 48, no. 01, pp. 1–36, 2022.

    - <span id="page-12-7"></span>[15] H. B. Braiek and F. Khomh, "On testing machine
    learning programs," *Journal of Systems and Software*, vol. 164, p. 110542, 2020.
    [Online]. Available: [https://www.sciencedirect.com/science/article/pii/S0164121](https://www.sciencedirect.com/science/article/pii/S0164121220300248)
    [220300248](https://www.sciencedirect.com/science/article/pii/S0164121220300248)

    - <span id="page-12-6"></span>[16] R. C. Cardoso, G. Kourtis, L. A. Dennis, C.
    Dixon, M. Farrell, M. Fisher, and M. Webster, "A review of verification and validation
    for space autonomous systems," *Current Robotics Reports*, vol. 2, no. 3, pp.
    273–283, 2021.

    - <span id="page-12-8"></span>[17] A. d. Garcez, S. Bader, H. Bowman, L. C. Lamb,
    L. de Penning, B. Illuminoo, H. Poon, and C. G. Zaverucha, "Neural-symbolic learning
    and reasoning: A survey and interpretation," *Neuro-Symbolic Artificial Intelligence:
    The State of the Art*, vol. 342, no. 1, p. 327, 2022.

    - <span id="page-12-13"></span>[18] A. Sheth, K. Roy, and M. Gaur, "Neurosymbolic
    artificial intelligence (why, what, and how)," *IEEE Intelligent Systems*, vol.
    38, no. 3, pp. 56–62, 2023.

    - [19] M. Gaur, K. Gunaratna, S. Bhatt, and A. Sheth, "Knowledge-infused learning:
    A sweet spot in neuro-symbolic ai," *IEEE Internet Computing*, vol. 26, no. 4,
    pp. 5–11, 2022.

    - [20] P. Hitzler and M. K. Sarker, *Neuro-Symbolic Artificial Intelligence: The
    state of the art*. IOS Press, 2022.

    - [21] M. K. Sarker, L. Zhou, A. Eberhart, and P. Hitzler, "Neuro-symbolic artificial
    intelligence," *AI Communications*, vol. 34, no. 3, pp. 197–209, 2021.

    - <span id="page-12-14"></span>[22] Z. Susskind, B. Arden, L. K. John, P. Stockton,
    and E. B. John, "Neuro-symbolic ai: An emerging class of ai workloads and their
    characterization," *arXiv preprint arXiv:2109.06133*, 2021.

    - [23] W. Wang and Y. Yang, "Towards data-and knowledge-driven artificial intelligence:
    A survey on neuro-symbolic computing," *arXiv preprint arXiv:2210.15889*, 2022.

    - <span id="page-12-9"></span>[24] W. Gibaut, L. Pereira, F. Grassiotto, A. Osorio,
    E. Gadioli, A. Munoz, S. Gomes, and C. d. Santos, "Neurosymbolic ai and its taxonomy:
    a survey," *arXiv preprint arXiv:2305.08876*, 2023.

    - <span id="page-12-10"></span>[25] L. N. DeLong, R. F. Mir, M. Whyte, Z. Ji,
    and J. D. Fleuriot, "Neurosymbolic ai for reasoning on graph structures: A survey,"
    *arXiv preprint arXiv:2302.07200*, 2023.

    - <span id="page-12-11"></span>[26] L. N. DeLong, R. F. Mir, Z. Ji, F. N. C. Smith,
    and J. D. Fleuriot, "Neurosymbolic ai for reasoning on biomedical knowledge graphs,"
    *arXiv preprint arXiv:2307.08411*, 2023.

    - <span id="page-12-12"></span>[27] K. Hamilton, A. Nayak, B. Boziˇ c, and L.
    Longo, "Is neuro-symbolic ´ ai meeting its promises in natural language processing?
    a structured review," *Semantic Web*, no. Preprint, pp. 1–42, 2022.

    - <span id="page-12-15"></span>[28] K. W. Church, "Word2vec," *Natural Language
    Engineering*, vol. 23, no. 1, pp. 155–162, 2017.

    - <span id="page-12-16"></span>[29] J. Pennington, R. Socher, and C. D. Manning,
    "Glove: Global vectors for word representation," in *Proceedings of the 2014 conference
    on empirical methods in natural language processing (EMNLP)*, 2014, pp. 1532–1543.

    - <span id="page-12-17"></span>[30] D. Silver, J. Schrittwieser, K. Simonyan,
    I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton *et al.*,
    "Mastering the game of go without human knowledge," *nature*, vol. 550, no. 7676,
    pp. 354–359, 2017.

    - <span id="page-12-18"></span>[31] J. Mao, C. Gan, P. Kohli, J. B. Tenenbaum,
    and J. Wu, "The neuro-symbolic concept learner: Interpreting scenes, words, and
    sentences from natural supervision," *CoRR*, vol. abs/1904.12584, 2019. [Online].
    Available: <http://arxiv.org/abs/1904.12584>

    - <span id="page-12-19"></span>[32] R. Manhaeve, S. Dumancic, A. Kimmig, T. Demeester,
    and L. De Raedt, "Deepproblog: Neural probabilistic logic programming," *Advances
    in neural information processing systems*, vol. 31, 2018.

    - <span id="page-12-20"></span>[33] G. Lample and F. Charton, "Deep learning for
    symbolic mathematics," *CoRR*, vol. abs/1912.01412, 2019. [Online]. Available:
    [http://arxiv.or](http://arxiv.org/abs/1912.01412) [g/abs/1912.01412](http://arxiv.org/abs/1912.01412)

    - <span id="page-12-21"></span>[34] L. Serafini, I. Donadello, and A. d. Garcez,
    "Learning and reasoning in logic tensor networks: Theory and application to semantic
    image interpretation," in *Proceedings of the Symposium on Applied Computing*,
    ser. SAC ''17. New York, NY, USA: Association for Computing Machinery, 2017, p.
    125–130. [Online]. Available: <https://doi.org/10.1145/3019612.3019642>

    - <span id="page-12-22"></span>[35] P. Smolensky, M. Lee, X. He, W.-t. Yih, J.
    Gao, and L. Deng, "Basic reasoning with tensor product representations," 2016.
    [Online]. Available: <https://arxiv.org/abs/1601.02745>

    - <span id="page-12-23"></span>[36] D. Kahneman, *Thinking, fast and slow*. New
    York: Farrar, Straus and Giroux, 2011.

    - <span id="page-12-24"></span>[37] M. Alshiekh, R. Bloem, R. Ehlers, B. Konighofer,
    S. Niekum, and ¨ U. Topcu, "Safe reinforcement learning via shielding," in *Proceedings
    of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth
    Innovative Applications of Artificial Intelligence Conference and Eighth AAAI
    Symposium on Educational Advances in Artificial Intelligence*, ser. AAAI''18/IAAI''18/EAAI''18.
    AAAI Press, 2018.

    - <span id="page-12-25"></span>[38] M. Alshiekh, R. Bloem, R. Ehlers, B. Konighofer,
    S. Niekum, and ¨ U. Topcu, "Safe reinforcement learning via shielding," *arXiv
    preprint arXiv:1708.08611*, 2017.

    - <span id="page-12-26"></span>[39] I. H. Anellis, "Peirce''s truth-functional
    analysis and the origin of the truth table," *History and Philosophy of Logic*,
    vol. 33, no. 1, pp. 87–97, 2012.

    - <span id="page-12-27"></span>[40] E. W. Beth, *Semantic Entailment and Formal
    Derivability*. Noord-Hollandsche, 1955.

    - <span id="page-12-28"></span>[41] W. Schwarz, "GitHub - wo/tpg: Tree Proof Generator
    — github.com," [https://github.com/wo/tpg,](https://github.com/wo/tpg) [Accessed
    01-Dec-2022].

    - <span id="page-12-29"></span>[42] E. Huaman, E. Karle, and D. Fensel, "Knowledge
    graph validation," ¨ 2020. [Online]. Available: <https://arxiv.org/abs/2005.01389>

    - <span id="page-12-30"></span>[43] Z. H. Syed, N. Srivastava, M. Roder, and A.-C.
    N. Ngomo, "Copaal- ¨ an interface for explaining facts using corroborative paths."
    in *ISWC (Satellites)*, 2019, pp. 201–204.

    - <span id="page-12-31"></span>[44] J. Lehmann, D. Gerber, M. Morsey, and A.-C.
    Ngonga Ngomo, "Defacto-deep fact validation," in *International semantic web conference*.
    Springer, 2012, pp. 312–327.

    - <span id="page-12-32"></span>[45] A. Rula, M. Palmonari, S. Rubinacci, A.-C.
    Ngonga Ngomo, J. Lehmann, A. Maurino, and D. Esteves, "Tisco: Temporal scoping
    of facts," in *Companion Proceedings of The 2019 World Wide Web Conference*, 2019,
    pp. 959–960.

    - <span id="page-12-33"></span>[46] Z. H. Syed, M. Roder, and A.-C. Ngonga Ngomo,
    "Factcheck: Validat- ¨ ing rdf triples using textual evidence," in *Proceedings
    of the 27th ACM International Conference on Information and Knowledge Management*,
    2018, pp. 1599–1602.

    - <span id="page-12-34"></span>[47] G. Ercan, S. Elbassuoni, and K. Hose, "Retrieving
    textual evidence for knowledge graph facts," in *European Semantic Web Conference*.
    Springer, 2019, pp. 52–67.

    - <span id="page-12-35"></span>[48] R. Speck and A.-C. N. Ngomo, "Leopard—a baseline
    approach to attribute prediction and validation for knowledge graph population,"
    *Journal of Web Semantics*, vol. 55, pp. 102–107, 2019.

    - <span id="page-12-36"></span>[49] A. Padia, F. Ferraro, and T. Finin, "Surface:
    semantically rich fact validation with explanations," *arXiv preprint arXiv:1810.13223*,
    2018.

    - <span id="page-12-37"></span>[50] S. Metzger, S. Elbassuoni, K. Hose, and R.
    Schenkel, "S3k: seeking statement-supporting top-k witnesses," in *Proceedings
    of the 20th ACM international conference on Information and knowledge management*,
    2011, pp. 37–46.

    - <span id="page-12-38"></span>[51] T. Rebele, F. Suchanek, J. Hoffart, J. Biega,
    E. Kuzey, and G. Weikum, "Yago: A multilingual knowledge base from wikipedia,
    wordnet, and geonames," in *The Semantic Web–ISWC 2016: 15th International Semantic
    Web Conference, Kobe, Japan, October 17–21, 2016, Proceedings, Part II 15*. Springer,
    2016, pp. 177–185.

    - <span id="page-12-39"></span>[52] R. Speer, J. Chin, and C. Havasi, "Conceptnet
    5.5: An open multilingual graph of general knowledge," in *Proceedings of the
    AAAI conference on artificial intelligence*, vol. 31, no. 1, 2017.

    - <span id="page-12-40"></span>[53] D. Ferrucci, E. Brown, J. Chu-Carroll, J.
    Fan, D. Gondek, A. A. Kalyanpur, A. Lally, J. W. Murdock, E. Nyberg, J. Prager
    *et al.*, "Building watson: An overview of the deepqa project," *AI magazine*,
    vol. 31, no. 3, pp. 59–79, 2010.

    - <span id="page-12-41"></span>[54] G. A. Miller, "Wordnet: A lexical database
    for english," *Commun. ACM*, vol. 38, no. 11, p. 39–41, nov 1995. [Online]. Available:
    <https://doi.org/10.1145/219717.219748>

    - <span id="page-12-42"></span>[55] N. Drenkow, N. Sani, I. Shpitser, and M. Unberath,
    "A systematic review of robustness in deep learning for computer vision: Mind
    the gap?" 2022.

    - <span id="page-13-0"></span>[56] M. Wicker, X. Huang, and M. Kwiatkowska, "Feature-guided
    blackbox safety testing of deep neural networks," in *Tools and Algorithms for
    the Construction and Analysis of Systems: 24th International Conference, TACAS
    2018, Held as Part of the European Joint Conferences on Theory and Practice of
    Software, ETAPS 2018, Thessaloniki, Greece, April 14-20, 2018, Proceedings, Part
    I 24*. Springer, 2018, pp. 408– 426.

    - <span id="page-13-1"></span>[57] W. Ruan, X. Huang, and M. Kwiatkowska, "Reachability
    analysis of deep neural networks with provable guarantees," in *Proceedings of
    the Twenty-Seventh International Joint Conference on Artificial Intelligence,
    IJCAI-18*. International Joint Conferences on Artificial Intelligence Organization,
    7 2018, pp. 2651–2659. [Online]. Available: <https://doi.org/10.24963/ijcai.2018/368>

    - <span id="page-13-2"></span>[58] M. Wu, M. Wicker, W. Ruan, X. Huang, and M.
    Kwiatkowska, "A game-based approximate verification of deep neural networks with
    provable guarantees," *Theoretical Computer Science*, vol. 807, pp. 298–329, 2020,
    in memory of Maurice Nivat, a founding father of Theoretical Computer Science
    - Part II. [Online]. Available: <https://www.sciencedirect.com/science/article/pii/S0304397519304426>

    - <span id="page-13-3"></span>[59] G. Katz, C. Barrett, D. L. Dill, K. Julian,
    and M. J. Kochenderfer, "Reluplex: An efficient smt solver for verifying deep
    neural networks," in *Computer Aided Verification: 29th International Conference,
    CAV 2017, Heidelberg, Germany, July 24-28, 2017, Proceedings, Part I 30*. Springer,
    2017, pp. 97–117.

    - [60] R. Ehlers, "Formal verification of piece-wise linear feed-forward neural
    networks," in *Automated Technology for Verification and Analysis: 15th International
    Symposium, ATVA 2017, Pune, India, October 3–6, 2017, Proceedings 15*. Springer,
    2017, pp. 269–286.

    - [61] R. R. Bunel, I. Turkaslan, P. Torr, P. Kohli, and P. K. Mudigonda, "A unified
    view of piecewise linear neural network verification," *Advances in Neural Information
    Processing Systems*, vol. 31, 2018.

    - [62] A. Lomuscio and L. Maganti, "An approach to reachability analysis for feed-forward
    relu neural networks," *arXiv preprint arXiv:1706.07351*, 2017.

    - [63] W. Xiang, H.-D. Tran, and T. T. Johnson, "Output reachable set estimation
    and verification for multilayer neural networks," *IEEE Transactions on Neural
    Networks and Learning Systems*, vol. 29, no. 11, pp. 5777–5783, 2018.

    - [64] C.-H. Cheng, G. Nuhrenberg, and H. Ruess, "Maximum resilience of ¨ artificial
    neural networks," in *Automated Technology for Verification and Analysis: 15th
    International Symposium, ATVA 2017, Pune, India, October 3–6, 2017, Proceedings
    15*. Springer, 2017, pp. 251–268.

    - [65] N. Narodytska, S. Kasiviswanathan, L. Ryzhyk, M. Sagiv, and T. Walsh, "Verifying
    properties of binarized deep neural networks," in *Proceedings of the AAAI Conference
    on Artificial Intelligence*, vol. 32, no. 1, 2018.

    - <span id="page-13-4"></span>[66] N. Narodytska, "Formal analysis of deep binarized
    neural networks," in *Proceedings of the Twenty-Seventh International Joint Conference
    on Artificial Intelligence, IJCAI-18*. International Joint Conferences on Artificial
    Intelligence Organization, 7 2018, pp. 5692–5696. [Online]. Available: <https://doi.org/10.24963/ijcai.2018/811>

    - <span id="page-13-5"></span>[67] T. Gehr, M. Mirman, D. Drachsler-Cohen, P.
    Tsankov, S. Chaudhuri, and M. Vechev, "Ai2: Safety and robustness certification
    of neural networks with abstract interpretation [paper presentation]," in *IEEE
    Symposium on Security and Privacy (SP), San Francisco, CA, United States. https://doi.
    org/10.1109/SP*, 2018.

    - [68] S. Wang, K. Pei, J. Whitehouse, J. Yang, and S. Jana, "Formal security
    analysis of neural networks using symbolic intervals," in *27th USENIX Security
    Symposium (USENIX Security 18)*, 2018, pp. 1599–1614.

    - [69] A. Raghunathan, J. Steinhardt, and P. Liang, "Certified defenses against
    adversarial examples," in *International Conference on Learning Representations*,
    2018.

    - <span id="page-13-6"></span>[70] W. Ruan, M. Wu, Y. Sun, X. Huang, D. Kroening,
    and M. Kwiatkowska, "Global robustness evaluation of deep neural networks with
    provable guarantees for the hamming distance," in *Proceedings of the Twenty-Eighth
    International Joint Conference on Artificial Intelligence, IJCAI-19*. International
    Joint Conferences on Artificial Intelligence Organization, 7 2019, pp. 5944–5952.
    [Online]. Available: <https://doi.org/10.24963/ijcai.2019/824>

    - <span id="page-13-7"></span>[71] X. Huang, M. Kwiatkowska, S. Wang, and M. Wu,
    "Safety verification of deep neural networks," in *Computer Aided Verification:
    29th International Conference, CAV 2017, Heidelberg, Germany, July 24-28, 2017,
    Proceedings, Part I 30*. Springer, 2017, pp. 3–29.

    - <span id="page-13-8"></span>[72] S. Dutta, S. Jha, S. Sanakaranarayanan, and
    A. Tiwari, "Output range analysis for deep neural networks," *arXiv preprint arXiv:1709.09130*,
    2017.

    - <span id="page-13-9"></span>[73] L. Pulina and A. Tacchella, "An abstraction-refinement
    approach to verification of artificial neural networks," in *Computer Aided Verification:
    22nd International Conference, CAV 2010, Edinburgh, UK, July 15-19, 2010. Proceedings
    22*. Springer, 2010, pp. 243–257.

    - [74] E. Wong and Z. Kolter, "Provable defenses against adversarial examples
    via the convex outer adversarial polytope," in *International conference on machine
    learning*. PMLR, 2018, pp. 5286–5295.

    - <span id="page-13-10"></span>[75] M. Mirman, T. Gehr, and M. Vechev, "Differentiable
    abstract interpretation for provably robust neural networks," in *International
    Conference on Machine Learning*. PMLR, 2018, pp. 3578–3586.

    - <span id="page-13-17"></span>[76] R. Kohavi *et al.*, "A study of cross-validation
    and bootstrap for accuracy estimation and model selection," in *Ijcai*, vol. 14,
    no. 2. Montreal, Canada, 1995, pp. 1137–1145.

    - <span id="page-13-18"></span>[77] B. Efron and R. J. Tibshirani, *An introduction
    to the bootstrap*. CRC press, 1994.

    - <span id="page-13-19"></span>[78] N. Japkowicz, "Why question machine learning
    evaluation methods," in *AAAI workshop on evaluation methods for machine learning*,
    2006, pp. 6–11.

    - <span id="page-13-11"></span>[79] M. Vartak, J. M. F. da Trindade, S. Madden,
    and M. Zaharia, "Mistique: A system to store and query model intermediates for
    model diagnosis," in *Proceedings of the 2018 International Conference on Management
    of Data*, ser. SIGMOD ''18. New York, NY, USA: Association for Computing Machinery,
    2018, p. 1285–1300. [Online]. Available: <https://doi.org/10.1145/3183713.3196934>

    - <span id="page-13-12"></span>[80] S. Krishnan and E. Wu, "Palm: Machine learning
    explanations for iterative debugging," in *Proceedings of the 2nd Workshop on
    Human-In-the-Loop Data Analytics*, ser. HILDA ''17. New York, NY, USA: Association
    for Computing Machinery, 2017. [Online]. Available: <https://doi.org/10.1145/3077257.3077271>

    - <span id="page-13-13"></span>[81] J. Ding, X. Kang, and X.-H. Hu, "Validating
    a deep learning framework by metamorphic testing," in *Proceedings of the 2nd
    International Workshop on Metamorphic Testing*, ser. MET ''17. IEEE Press, 2017,
    p. 28–34.

    - [82] S. Nakajima, "Generalized oracle for testing machine learning computer
    programs," in *Software Engineering and Formal Methods: SEFM 2017 Collocated Workshops:
    DataMod, FAACS, MSE, CoSim-CPS, and FOCLASA, Trento, Italy, September 4-5, 2017,
    Revised Selected Papers 15*. Springer, 2018, pp. 174–179.

    - [83] A. Dwarakanath, M. Ahuja, S. Sikand, R. M. Rao, R. J. C. Bose, N. Dubash,
    and S. Podder, "Identifying implementation bugs in machine learning based image
    classifiers using metamorphic testing," in *Proceedings of the 27th ACM SIGSOFT
    international symposium on software testing and analysis*, 2018, pp. 118–128.

    - [84] D. Pesu, Z. Q. Zhou, J. Zhen, and D. Towey, "A monte carlo method for metamorphic
    testing of machine translation services," in *Proceedings of the 3rd International
    Workshop on Metamorphic Testing*, ser. MET ''18. New York, NY, USA: Association
    for Computing Machinery, 2018, p. 38–45. [Online]. Available: <https://doi.org/10.1145/3193977.3193980>

    - [85] E. Breck, S. Cai, E. Nielsen, M. Salib, and D. Sculley, "The ml test score:
    A rubric for ml production readiness and technical debt reduction," in *2017 IEEE
    International Conference on Big Data (Big Data)*. IEEE, 2017, pp. 1123–1132.

    - <span id="page-13-14"></span>[86] S. Ma, Y. Liu, W.-C. Lee, X. Zhang, and A.
    Grama, "Mode: automated neural network model debugging via state differential
    analysis and input selection," in *Proceedings of the 2018 26th ACM Joint Meeting
    on European Software Engineering Conference and Symposium on the Foundations of
    Software Engineering*, 2018, pp. 175–186.

    - <span id="page-13-15"></span>[87] N. Hynes, D. Sculley, and M. Terry, "The data
    linter: Lightweight, automated sanity checking for ml data sets," in *NIPS MLSys
    Workshop*, vol. 1, no. 5, 2017.

    - <span id="page-13-16"></span>[88] S. Schelter, D. Lange, P. Schmidt, M. Celikel,
    F. Biessmann, and A. Grafberger, "Automating large-scale data quality verification,"
    *Proceedings of the VLDB Endowment*, vol. 11, no. 12, pp. 1781–1794, 2018.

    - <span id="page-13-20"></span>[89] K. Pei, Y. Cao, J. Yang, and S. Jana, "Deepxplore:
    Automated whitebox testing of deep learning systems," in *proceedings of the 26th
    Symposium on Operating Systems Principles*, 2017, pp. 1–18.

    - <span id="page-13-21"></span>[90] X. Xie, L. Ma, F. Juefei-Xu, M. Xue, H. Chen,
    Y. Liu, J. Zhao, B. Li, J. Yin, and S. See, "Deephunter: a coverage-guided fuzz
    testing framework for deep neural networks," in *Proceedings of the 28th ACM SIGSOFT
    International Symposium on Software Testing and Analysis*, 2019, pp. 146–157.

    - <span id="page-13-22"></span>[91] J. Guo, Y. Zhao, H. Song, and Y. Jiang, "Coverage
    guided differential adversarial testing of deep learning systems," *IEEE Transactions
    on Network Science and Engineering*, vol. 8, no. 2, pp. 933–942, 2020.

    - <span id="page-14-0"></span>[92] D. Meng and H. Chen, "Magnet: A two-pronged
    defense against adversarial examples," in *Proceedings of the 2017 ACM SIGSAC
    Conference on Computer and Communications Security*, ser. CCS ''17. New York,
    NY, USA: Association for Computing Machinery, 2017, p. 135–147. [Online]. Available:
    [https://doi.org/10.1145/3133956.313405](https://doi.org/10.1145/3133956.3134057)
    [7](https://doi.org/10.1145/3133956.3134057)

    - <span id="page-14-1"></span>[93] W. Tan, J. Renkhoff, A. Velasquez, Z. Wang,
    L. Li, J. Wang, S. Niu, F. Yang, Y. Liu, and H. Song, "Noisecam: Explainable ai
    for the boundary between noise and adversarial attacks," *arXiv preprint arXiv:2303.06151*,
    2023.

    - <span id="page-14-2"></span>[94] S. Qiu, Q. Liu, S. Zhou, and W. Huang, "Adversarial
    attack and defense technologies in natural language processing: A survey," *Neurocomputing*,
    vol. 492, pp. 278–307, 2022. [Online]. Available: <https://www.sciencedirect.com/science/article/pii/S0925231222003861>

    - <span id="page-14-3"></span>[95] N. Martins, J. M. Cruz, T. Cruz, and P. Henriques
    Abreu, "Adversarial machine learning applied to intrusion and malware scenarios:
    A systematic review," *IEEE Access*, vol. 8, pp. 35 403–35 419, 2020.

    - <span id="page-14-4"></span>[96] O. Biran and C. Cotton, "Explanation and justification
    in machine learning: A survey," in *IJCAI-17 workshop on explainable AI (XAI)*,
    vol. 8, no. 1, 2017, pp. 8–13.

    - <span id="page-14-5"></span>[97] C. Molnar, *Interpretable Machine Learning*,
    2nd ed., 2022. [Online]. Available: <https://christophm.github.io/interpretable-ml-book>

    - <span id="page-14-6"></span>[98] S. Ruiter and N. D. De Graaf, "National context,
    religiosity, and volunteering: Results from 53 countries," *American Sociological
    Review*, vol. 71, no. 2, pp. 191–210, 2006.

    - <span id="page-14-7"></span>[99] R. D. Cook, "Detection of influential observation
    in linear regression," *Technometrics*, vol. 19, no. 1, pp. 15–18, 1977.

    - <span id="page-14-8"></span>[100] G. Anderson, A. Verma, I. Dillig, and S. Chaudhuri,
    "Neurosymbolic reinforcement learning with formally verified exploration," *Advances
    in neural information processing systems*, vol. 33, pp. 6172–6183, 2020.

    - <span id="page-14-9"></span>[101] T. P. Lillicrap, J. J. Hunt, A. Pritzel, N.
    Heess, T. Erez, Y. Tassa, D. Silver, and D. Wierstra, "Continuous control with
    deep reinforcement learning," *arXiv preprint arXiv:1509.02971*, 2015.

    - <span id="page-14-10"></span>[102] J. Achiam, D. Held, A. Tamar, and P. Abbeel,
    "Constrained policy optimization," in *International conference on machine learning*.
    PMLR, 2017, pp. 22–31.

    - <span id="page-14-11"></span>[103] S. Gu, L. Yang, Y. Du, G. Chen, F. Walter,
    J. Wang, Y. Yang, and A. Knoll, "A review of safe reinforcement learning: Methods,
    theory and applications," *arXiv preprint arXiv:2205.10330*, 2022.

    - <span id="page-14-12"></span>[104] O. Bastani, Y. Pu, and A. Solar-Lezama, "Verifiable
    reinforcement learning via policy extraction," in *Advances in Neural Information
    Processing Systems*, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi,
    and R. Garnett, Eds., vol. 31. Curran Associates, Inc., 2018. [Online]. Available:
    [https://proceedings.neurip](https://proceedings.neurips.cc/paper/2018/file/e6d8545daa42d5ced125a4bf747b3688-Paper.pdf)
    [s.cc/paper/2018/file/e6d8545daa42d5ced125a4bf747b3688-Paper.pdf](https://proceedings.neurips.cc/paper/2018/file/e6d8545daa42d5ced125a4bf747b3688-Paper.pdf)

    - <span id="page-14-13"></span>[105] Y. Tian, A. Luo, X. Sun, K. Ellis, W. T.
    Freeman, J. B. Tenenbaum, and J. Wu, "Learning to infer and execute 3d shape programs,"
    *arXiv preprint arXiv:1901.02875*, 2019.

    - <span id="page-14-14"></span>[106] D. Trivedi, J. Zhang, S.-H. Sun, and J. J.
    Lim, "Learning to synthesize programs as interpretable and generalizable policies,"
    *Advances in neural information processing systems*, vol. 34, pp. 25 146–25 163,
    2021.

    - <span id="page-14-15"></span>[107] J. Huang, Z. Li, D. Jacobs, M. Naik, and
    S.-N. Lim, "Laser: Neurosymbolic learning of semantic video representations,"
    *arXiv preprint arXiv:2304.07647*, 2023.

    - <span id="page-14-16"></span>[108] X. Wang, Y. Ye, and A. Gupta, "Zero-shot
    recognition via semantic embeddings and knowledge graphs," in *Proceedings of
    the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, June 2018.

    - <span id="page-14-17"></span>[109] A. Carlson, J. Betteridge, B. Kisiel, B.
    Settles, E. R. Hruschka, and T. M. Mitchell, "Toward an architecture for never-ending
    language learning," in *Twenty-Fourth AAAI conference on artificial intelligence*,
    2010.

    - <span id="page-14-18"></span>[110] X. Chen, A. Shrivastava, and A. Gupta, "Neil:
    Extracting visual knowledge from web data," in *Proceedings of the IEEE international
    conference on computer vision*, 2013, pp. 1409–1416.

    - <span id="page-14-19"></span>[111] O. Russakovsky, J. Deng, H. Su, J. Krause,
    S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein *et al.*, "Imagenet
    large scale visual recognition challenge," *International journal of computer
    vision*, vol. 115, no. 3, pp. 211–252, 2015.

    - <span id="page-14-20"></span>[112] D. Zugner and S. G ¨ unnemann, "Certifiable
    robustness and robust ¨ training for graph convolutional networks," in *Proceedings
    of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data
    Mining*, 2019, pp. 246–256.

    - <span id="page-14-21"></span>[113] V. P. Dwivedi, C. K. Joshi, A. T. Luu, T.
    Laurent, Y. Bengio, and X. Bresson, "Benchmarking graph neural networks," *Journal
    of Machine Learning Research*, vol. 24, no. 43, pp. 1–48, 2023.

    - <span id="page-14-22"></span>[114] V. Fung, J. Zhang, E. Juarez, and B. G. Sumpter,
    "Benchmarking graph neural networks for materials chemistry," *npj Computational
    Materials*, vol. 7, no. 1, p. 84, 2021.

    - <span id="page-14-23"></span>[115] N. Metropolis and S. Ulam, "The monte carlo
    method," *Journal of the American statistical association*, vol. 44, no. 247,
    pp. 335–341, 1949.

    - <span id="page-14-24"></span>[116] R. Manhaeve, S. Dumancic, A. Kimmig, T. Demeester,
    and L. De Raedt, "Deepproblog: Neural probabilistic logic programming," *Advances
    in Neural Information Processing Systems*, vol. 31, 2018.

    - <span id="page-14-25"></span>[117] A. D. Gordon, T. A. Henzinger, A. V. Nori,
    and S. K. Rajamani, "Probabilistic programming," in *Future of Software Engineering
    Proceedings*, 2014, pp. 167–181.

    - <span id="page-14-26"></span>[118] J. Guo, Y. Jiang, Y. Zhao, Q. Chen, and J.
    Sun, "Dlfuzz: Differential fuzzing testing of deep learning systems," in *Proceedings
    of the 2018 26th ACM Joint Meeting on European Software Engineering Conference
    and Symposium on the Foundations of Software Engineering*, 2018, pp. 739–743.

    - <span id="page-14-27"></span>[119] M. Bosnjak, T. Rockt ˇ aschel, J. Naradowsky,
    and S. Riedel, "Program- ¨ ming with a differentiable forth interpreter," in *International
    conference on machine learning*. PMLR, 2017, pp. 547–556.

    - <span id="page-14-28"></span>[120] A. Odena, C. Olsson, D. Andersen, and I.
    Goodfellow, "Tensorfuzz: Debugging neural networks with coverage-guided fuzzing,"
    in *International Conference on Machine Learning*. PMLR, 2019, pp. 4901– 4911.

    - <span id="page-14-29"></span>[121] A. Darwiche, "Sdd: A new canonical representation
    of propositional knowledge bases," in *Twenty-Second International Joint Conference
    on Artificial Intelligence*, 2011.

    - <span id="page-14-30"></span>[122] E. Kern, L. M. Hilty, A. Guldner, Y. V. Maksimov,
    A. Filler, J. Groger, ¨ and S. Naumann, "Sustainable software products—towards
    assessment criteria for resource and energy efficiency," *Future Generation Computer
    Systems*, vol. 86, pp. 199–210, 2018. [Online]. Available: [ht](https://www.sciencedirect.com/science/article/pii/S0167739X17314188)
    [tps://www.sciencedirect.com/science/article/pii/S0167739X17314188](https://www.sciencedirect.com/science/article/pii/S0167739X17314188)

    - <span id="page-14-31"></span>[123] A. Guldner and J. Murach, "Measuring and
    assessing the resource and energy efficiency of artificial intelligence of things
    devices and algorithms," in *Advances and New Trends in Environmental Informatics:
    Environmental Informatics and the UN Sustainable Development Goals*. Springer,
    2022, pp. 185–199.

    - <span id="page-14-32"></span>[124] N. Ngu, N. Lee, and P. Shakarian, "Diversity
    measures: Domainindependent proxies for failure in language model queries," 2023.

    - <span id="page-14-33"></span>[125] Z. Li, J. Huang, and M. Naik, "Scallop: A
    language for neurosymbolic programming," *Proceedings of the ACM on Programming
    Languages*, vol. 7, no. PLDI, pp. 1463–1487, 2023.


    ![](_page_14_Picture_34.jpeg)


    Justus Renkhoff earned a bachelor''s and master''s degrees in Media and Computer
    Science from Trier University of Applied Sciences, Germany in 2019 and 2021, respectively.
    He is currently pursuing a doctorate degree. Previously, he worked at the Institute
    for Software Systems at Trier University of Applied Sciences, the Security and
    Optimization for Networked Globe Laboratory (SONG Lab) at Embry-Riddle Aeronautical
    University and University of Maryland, Baltimore County and taught as an adjunct
    instructor at St. Bonaventure University,


    New York. His research focuses on explainable and neurosymbolic AI.


    ![](_page_14_Picture_37.jpeg)


    Ke Feng received master''s degree in Electrical and Computer Engineering from
    Embry-Riddle Aeronautical University(ERAU), Daytona Beach, Florida. She is currently
    pursuing a Ph.D. degree in Electrical Engineering and Computer Science at Security
    and Optimization for Networked Globe Laboratory, ERAU. Her major research interests
    include machine learning, deep learning, and the Internet of Things.


    ![](_page_15_Picture_1.jpeg)


    Marc Meier-Doernberg earned his master''s degree in Data Science from Embry-Riddle
    Aeronautical University, Daytona Beach, Florida. He currently works as a Lead
    Analyst for United Airlines where he develops data-driven approaches to air traffic
    management. He previously worked for Lufthansa Group and contributed to various
    analytics projects. He focuses on deep learning, machine learning, and their applications
    in aviation.


    ![](_page_15_Picture_3.jpeg)


    Alvaro Velasquez is a program manager in the Innovation Information Office (I2O)
    of the Defense Advanced Research Projects Agency (DARPA), where he currently leads
    the Assured Neuro-Symbolic Learning and Reasoning (ANSR) program. Before that,
    Alvaro oversaw the machine intelligence portfolio of investments for the Information
    Directorate of the Air Force Research Laboratory (AFRL). Alvaro received his PhD
    in Computer Science from the University of Central Florida and is a recipient
    of the National Science Foundation Graduate Research


    Fellowship Program (NSF GRFP) award, the University of Central Florida 30 Under
    30 award, a distinguished paper award from AAAI, and best paper and patent awards
    from AFRL. He has co-authored 60 papers and two patents and serves as Associate
    Editor of the IEEE Transactions on Artificial Intelligence and his research has
    been funded by the Air Force Office of Scientific Research.


    ![](_page_15_Picture_6.jpeg)


    Houbing Herbert Song (M''12–SM''14-F''23) received the Ph.D. degree in electrical
    engineering from the University of Virginia, Charlottesville, VA, in August 2012.


    He is currently a Professor, the Director of the NSF Center for Aviation Big Data
    Analytics (Planning), the Associate Director for Leadership of the DOT Transportation
    Cybersecurity Center for Advanced Research and Education (Tier 1 Center), and
    the Director of the Security and Optimization for Networked Globe Laboratory (SONG
    Lab,


    www.SONGLab.us), University of Maryland, Baltimore County (UMBC), Baltimore, MD.
    Prior to joining UMBC, he was a Tenured Associate Professor of Electrical Engineering
    and Computer Science at Embry-Riddle Aeronautical University, Daytona Beach, FL.
    He serves as an Associate Editor for IEEE Transactions on Artificial Intelligence
    (TAI) (2023-present), IEEE Internet of Things Journal (2020-present), IEEE Transactions
    on Intelligent Transportation Systems (2021-present), and IEEE Journal on Miniaturization
    for Air and Space Systems (J-MASS) (2020-present). He was an Associate Technical
    Editor for IEEE Communications Magazine (2017-2020). He is the editor of ten books,
    the author of more than 100 articles and the inventor of 2 patents. His research
    interests include cyber-physical systems/internet of things, cybersecurity and
    privacy, and AI/machine learning/big data analytics. His research has been sponsored
    by federal agencies (including National Science Foundation, National Aeronautics
    and Space Administration, US Department of Transportation, and Federal Aviation
    Administration, among others) and industry. His research has been featured by
    popular news media outlets, including IEEE GlobalSpec''s Engineering360, Association
    for Uncrewed Vehicle Systems International (AUVSI), Security Magazine, CXOTech
    Magazine, Fox News, U.S. News & World Report, The Washington Times, and New Atlas.


    Dr. Song is an IEEE Fellow (for contributions to big data analytics and integration
    of AI with Internet of Things), an Asia-Pacific Artificial Intelligence Association
    (AAIA) Fellow, an ACM Distinguished Member (for outstanding scientific contributions
    to computing), and a Full Member of Sigma Xi. Dr. Song has been a Highly Cited
    Researcher identified by Web of Science since 2021. He is an ACM Distinguished
    Speaker (2020 present), an IEEE Vehicular Technology Society (VTS) Distinguished
    Lecturer (2023-present) and an IEEE Systems Council Distinguished Lecturer (2023
    present). Dr. Song received Research.com Rising Star of Science Award in 2022,
    2021 Harry Rowe Mimno Award bestowed by IEEE Aerospace and Electronic Systems
    Society, and 10+ Best Paper Awards from major international conferences, including
    IEEE CPSCom-2019, IEEE ICII 2019, IEEE/AIAA ICNS 2019, IEEE CBDCom 2020, WASA
    2020, AIAA/ IEEE DASC 2021, IEEE GLOBECOM 2021 and IEEE INFOCOM 2022.'
- id: computational_argumentation_based_chatbots_a_survey_brunel_university_london_kingston_lane_london_ub8_3ph_united_kingdom
  title: 'Computational Argumentation-based Chatbots: a Survey'
  abstract: 'Chatbots are conversational software applications designed to interact

    dialectically with users for a plethora of different purposes. Surprisingly,

    these colloquial agents have only recently been coupled with computational

    models of arguments (i.e. computational argumentation), whose aim is to

    formalise, in a machine-readable format, the ordinary exchange of information

    that characterises human communications. Chatbots may employ argumentation with

    different degrees and in a variety of manners. The present survey sifts through

    the literature to review papers concerning this kind of argumentation-based

    bot, drawing conclusions about the benefits and drawbacks that this approach

    entails in comparison with standard chatbots, while also envisaging possible

    future development and integration with the Transformer-based architecture and

    state-of-the-art Large Language models.'
  url: http://arxiv.org/abs/2401.03454v1
  keywords: ''
  document: '# Computational Argumentation-based Chatbots: a Survey


    Brunel University London, Kingston Lane, London, UB8 3PH, United Kingdom


    University of Edinburgh, Crichton St, Edinburgh EH8 9AB, United Kingdom


    Brunel University London, Kingston Lane, London, UB8 3PH, United Kingdom


    University of Lincoln, Brayford Pool, Lincoln, LN6 7TS, United Kingdom


    University of Lincoln, Brayford Pool, Lincoln, LN6 7TS, United Kingdom


    Federico Castagna federico.castagna@brunel.ac.uk


    Nadin K¨okciyan nadin.kokciyan@ed.ac.uk


    Isabel Sassoon isabel.sassoon@brunel.ac.uk


    Simon Parsons sparsons@lincoln.ac.uk


    Elizabeth Sklar esklar@lincoln.ac.uk


    ## Abstract


    Chatbots are conversational software applications designed to interact dialectically
    with users for a plethora of different purposes. Surprisingly, these colloquial
    agents have only recently been coupled with computational models of arguments
    (i.e. computational argumentation), whose aim is to formalise, in a machine-readable
    format, the ordinary exchange of information that characterises human communications.
    Chatbots may employ argumentation with different degrees and in a variety of manners.
    The present survey sifts through the literature to review papers concerning this
    kind of argumentation-based bot, drawing conclusions about the benefits and drawbacks
    that this approach entails in comparison with standard chatbots, while also envisaging
    possible future development and integration with the Transformer-based architecture
    and state-of-the-art Large Language models.


    ## 1. Introduction


    Chatbots are conversational software applications designed to mimic human discourse
    mostly to enable automated online guidance and support (Caldarini et al., 2022).
    These computer programs generate responses based on given inputs, producing replies
    via text or speech format (Sojasingarayar, 2020; Bala et al., 2017). In addition,
    to be defined as such, chatbots must satisfy specific functions. As colloquial
    agents, they need to be able to understand the user (comprehension), have access
    to a knowledge base (competence) and provide an ''anthropomorphic effect'' to
    increase the users'' trust (presence) (Cahn, 2017; Sansonnet et al., 2006). Nowadays,
    these bots represent familiar tools that exist in our lives in the form of virtual
    agents. Their assistance ranges from answering inquiries to e-commerce, from information
    retrieval to educational tasks, and from developing new industrial solutions (Dale,
    2016) to connecting smart objects (Kar & Haldar, 2016). The manifold investments
    of the past decade, the technological advancements (from both software and hardware
    viewpoints), and the development of more efficient Machine Learning (ML) models,
    including the latest Transformer-based architecture (Vaswani et al., 2017), have
    contributed to the steady growth of the research field of chatbot design and implementation.
    Many steps forward have been taken since the release of ELIZA around sixty years
    ago, which is widely considered to be the first conversational agent (Weizenbaum,
    1966).


    The investigation of computational models of arguments in relation to chatbots
    has only recently received attention from researchers. Computational argumentation
    (Rahwan & Simari, 2009) has been applied in Artificial Intelligence (AI) as a
    mechanism for reasoning in which conclusions are drawn from evidence that supports
    the conclusions. Being an intuitive (i.e. closer to everyday human dialectical
    interplay), yet formal, approach for modelling conflicting information occurring
    during exchange of arguments, computational argumentation should be qualified
    as a highly appropriate methodology to enhance current bot behaviours. The benefits
    from such a combination include: more natural discourse, response coherence and
    strategical conveyance of information. Evaluating argumentation semantics would
    also provide the rationale for positing replies in a more transparent way than
    the black-box Large Language models (LLMs) employed in today''s state-of-the-art
    conversational agents. In recent years, cutting-edge technologies have produced
    implementations, such as the various versions of ChatGPT<sup>1</sup> , which currently
    outperform argumentation-based conversational agents. Nonetheless, taking a closer
    look—as we do here—shows that there is plenty of room for improvement for these
    recent advanced models, and integration with the computational argumentation formalism
    may solve their present shortcomings (e.g. lack of explainability), thus potentially
    initiating a new generation of chatbots. To the best of our knowledge, this is
    the first survey that combines computational argumentation and chatbots<sup>2</sup>
    . Our main contribution involves an extensive examination of the relevant literature
    and the subsequent findings that can be drawn from such analysis.


    The paper is structured as follows. We first start by introducing background information
    in Section 2 about the essential theoretical notions involved. In Section 3, we
    then discuss the methodology adopted for reviewing the relevant articles. A thorough
    classification and analysis of conversational agents leveraging computational
    argumentation is given in Section 4. Section 5 illustrates a comprehensive examination
    of the paper''s findings and potential future directions of the argumentation-based
    chatbot research field, and Section 6 concludes the survey with final remarks.


    ## 2. Background


    The following background covers a concise summary of computational argumentation,
    along with a short overview of the history, classification and main features of
    chatbots. The information provided will prove useful for the analysis undertaken
    in the next sections, where each conversational agent will be classified according
    to the specific argumentation employment presented herein.


    <sup>1.</sup> https://chat.openai.com/


    <sup>2.</sup> Notice that, for simplicity, we are often going to prefer the terminology
    ''argumentation-based chatbot'' rather than ''computational argumentation-based
    chatbot'', although the meaning will remain the same.


    ## 2.1 Computational Argumentation


    The term ''computational model of arguments'' encompasses a wide range of different
    approaches, each of which revolves around the notion of arguments and their employment.
    The resulting research field, whose roots can be traced back to Pollock''s and
    Dung''s systematical account of arguments (Pollock, 1987; Dung, 1995), constitutes
    a rich interdisciplinary environment comprising subjects such as philosophy (Walton,
    1990; Mercier & Sperber, 2011), jurisprudence (Bench-Capon et al., 2009), linguistics
    (Lawrence & Reed, 2020), formal logic (Lin & Shoham, 1989) and game theory (Rahwan
    & Larson, 2009). Within the scope of computational argumentation, it is possible
    to identify two main research goals: (a) understand argumentation as a cognitive
    phenomenon via computer program modelling; and (b) support the development of
    human-computer interaction by means of argumentation-related activities (Prakken
    et al., 2020; Dutilh Novaes, 2022). According to Dung''s paradigm (Dung, 1995),
    arguments are considered suitable means to formalise nonmonotonic reasoning, especially
    when showing how humans handle conflicting information in a dialectical way. The
    core notion of such an approach is underpinned by the definition of an argumentation
    framework, where arguments are intended as abstract entities:


    Definition 1 (Abstract AFs (Dung, 1995)) An argumentation framework (AF) is a
    pair: AF = ⟨AR, C⟩ where AR is a set of arguments, and C is the ''attack'' binary
    relation on AR, i.e. C ⊆ AR × AR.


    AFs can be rendered as graphs where each node is an argument, and every directed
    edge connects the conflicting arguments of the framework. The idea conveyed by
    this formalism is that correct reasoning is rendered via the acceptability of
    a statement: an argument is justified only if it is defended against any counterarguments.


    Definition 2 (Semantics for Abstract AFs (Dung, 1995)) Let AF = ⟨AR, C⟩, and let
    S ⊆ AR be a set of arguments. Let also (X,Y) ∈ C denote the conflict existing
    between an argument X and its target Y :


    - S is conflict-free iff ∀X, Y ∈ S: (X, Y ) ∈ C / ;

    - X ∈ AR is acceptable w.r.t. S iff ∀Y ∈ AR such that (Y, X) ∈ C: ∃Z ∈ S such
    that (Z, Y ) ∈ C;

    - A conflict-free extension S is an admissible extension iff X ∈ S implies X is
    acceptable w.r.t. S;

    - An admissible extension S is a complete extension iff ∀X ∈ AR: X is acceptable
    w.r.t. S implies X ∈ S. The minimal complete extension (with respect to set inclusion)
    is called the grounded extension, whereas a maximal complete extension (with respect
    to set inclusion) is called a preferred extension;

    - A stable extension S is such that iff ∀Y ∈ AR, if Y /∈ S, then ∃X ∈ S such that
    (X, Y ) ∈ C.


    Furthermore, AFs can be instantiated by the formulae of some logical language.
    These instantiations paved the way for a plethora of different studies (e.g.,
    (Besnard & Hunter, 2008; Modgil & Prakken, 2013; Toni, 2014)) concerning the so-called
    structured argumentation, as opposed to the previously introduced abstract approach.
    The internal structure of an argument is usually composed of (one or more) premises,
    a conclusion and a set of inference rules (e.g. strict or defeasible) connecting
    premises to the conclusion. The same semantics described above can then be used
    to evaluate structured argumentation frameworks and compute justified arguments.


    Example 1 Let us consider the abstract AF depicted in Figure 1. Then, according
    to the semantics described in Definition 2, we can identify the following extensions:


    admissible = ∅, {a}, {b}, {e}, {a, e}, {b, e}; complete = {e}, {a, e}, {b, e};
    grounded = {e}; preferred = {a, e}, {b, e}; stable = {a, e}, {b, e}.


    ![](_page_3_Figure_4.jpeg)


    Figure 1: An abstract argumentation framework.


    # 2.1.1 Argument Mining


    Argument(ation) mining has been defined as "the general task of analyzing discourse
    on the pragmatics level and applying a certain argumentation theory to model and
    automatically analyze the data at hand" (Habernal & Gurevych, 2017). Argument
    mining (AM) can be considered the research area aimed at detecting natural language
    arguments and their relations in text, with the final goal of providing machine-processable
    structured data for computational models of argument (Cabrio & Villata, 2018).
    As depicted in Figure 5, an AM pipeline consists of two main stages: arguments''
    extraction and relations'' prediction. We could delineate the AM framework by
    listing the tasks, in increasing order of complexity, that constitute such a framework.
    In short, moving from a preliminary textual segmentation and a classification
    of such elements as argumentative or not, it will then be possible to identify
    the single argument components (such as premises, claim, major claim, evidence,
    etc. (Mayer et al., 2020)). The following steps envisage the recognition of clausal
    properties and relational properties with respect to the previously detected argument
    components (Lawrence & Reed, 2020). In particular, Saadat-Yazdi, Pan and K¨okciyan
    show how the use of external commonsense knowledge helps in identifying relations
    among arguments by uncovering implicit inferences (Saadat-Yazdi et al., 2023).
    Some of the models proposed in the literature include Long-Short Term Memory (LSTM)
    models (Cocarascu & Toni, 2017), pre-trained transformers (Ruiz-Dolz et al., 2021;
    Saadat-Yazdi et al., 2023) and logical rulebased systems (Jo et al., 2021). Overall,
    AM is useful in enabling the generation of an argumentation framework, or graph,
    from the mined corpus of texts. We now provide a more concrete analysis of the
    arguments'' extraction stage within the AM pipeline.


    Example 2 Inspired by the political debate example illustrated in (Cabrio & Villata,
    2018), we introduce an example to show how one can identify single arguments by
    following two distinct steps: (S1) the detection of argument components, such
    as premises and claims, and (S2) the recognition of their specific textual boundaries
    via the exclusion of any irrelevant words. In the following, we show how S1 and
    S2 could be applied to an example about the use of solar energy to extract an
    argument (Arg). Note that (C) and (P) distinguish conclusion from premises, whereas
    the bold and underlined fonts identify their respective boundaries.


    - (S1) "She talks about solar panels. We invested in a solar company, our country.
    That was a disaster (C). They lost plenty of money on that one (P). Now, look,
    I''m a great believer in all forms of energy (P), but we''re putting a lot of
    people out of work (P)."

    - (S2) "She talks about solar panels. We invested in a solar company, our country.
    That was a disaster. They lost plenty of money on that one. Now, look, I''m a
    great believer in all forms of energy, but we''re putting a lot of people out
    of work."

    - (Arg) [Since] they lost plenty of money on that one, [even though] I''m a great
    believer in all forms of energy, we''re [nonetheless] putting a lot of people
    out of work. [We can then conclude] that was a disaster.


    ![](_page_4_Figure_6.jpeg)


    Figure 2: Example of an argumentation mining pipeline.


    # 2.1.2 Argument Schemes


    Argument schemes (AS) have been extensively investigated and employed in the AI
    literature as a way to directly convey presumptive reasoning in multi-agent interactions
    (e.g. (Atkinson et al., 2006; Tolchinsky et al., 2012; Grando et al., 2013; K¨okciyan
    et al., 2018, 2021)). Each AS is characterized by a unique set of critical questions
    (CQs), rendered as attacking arguments, whose purpose is to establish the validity
    of the scheme instantiations (which can then be evaluated by semantically computing
    their acceptability). Although the literature presents diverse classification
    systems for argument schemes (e.g. (Walton et al., 2008; Walton & Macagno, 2015;
    Wagemans, 2016)), they all share the idea that such schemes constitute reasoning
    patterns that may be harnessed to structure natural language text into rational
    and coherent arguments, thus generating systematic elements of dialogue.


    Example 3 As an example of AS in the healthcare domain, consider the argument
    scheme for proposed treatment (ASPT), as rendered in (Sassoon et al., 2021), and
    the respective critical questions: the validity of any potential ASPT instantiation
    depends upon the answers given to each critical question.


    | ASPT                                                                                                                   |

    |------------------------------------------------------------------------------------------------------------------------|

    | Premise : Given the patient''s fact Ft<br>Premise : In order to realise goal
    G<br>Premise : Treatment T promotes goal G |

    | Conclusion : Treatment T should be considered                                                                          |


    CQ1: Has treatment T been unsuccessfully used on the patient in the past?


    CQ2: Has treatment T caused side effects for the patient?


    CQ3: Given the patient''s fact Ft, are there counter-indications to treatment
    T?


    CQ4: Are there alternative Actions to achieve the same goal G?


    Finally, although the concept was developed for different purposes, the importance
    of argument schemes has found uptake within the computational argumentation community
    (Visser et al., 2018) also for textual mining tasks (Walton, 2012).


    # 2.1.3 Argumentation Reasoning Engine


    One of the main purposes of computational argumentation is to enable the resolution
    of conflicting knowledge, thus allowing for a selection of the most appropriate
    (i.e. justified) pieces of information. "A decision is a choice between competing
    beliefs about the world or between alternative courses of action. [...] Inference
    processes generate arguments for and against each candidate [belief or action].
    Decision making then ranks and evaluates candidates based on the underlying arguments
    and selects one candidate as the final decision. Finally, the decision commits
    to a new belief about a situation, or an intention to act in a particular way."
    (Fox et al., 2007). Decision-making processes can be encoded as problems whose
    solutions are rendered by the computation and evaluation of AFs: an argumentation
    engine is essentially a reasoning tool driven by the same logic. The resulting
    acceptable entities provide a compelling rationale for and against a given choice,
    while also leaving space for further deliberations (Dix et al., 2009). Such an
    argumentative decisionmaking apparatus can be a useful addition to any real-world
    software application concerning defeasible reasoning, as advocated by the comprehensive
    study of Bryant and Krause (2008). We can distinguish two kinds of reasoning engines
    based on computational argumentation:


    - ''Solvers'', i.e. specialized pieces of software that encode and provide answers
    to distinct algorithmic problems. In particular, they address computational argumentationrelated
    reasoning challenges according to a chosen semantics σ: for example, the enumeration
    of σ-extensions in the AF and the credulous and sceptical membership of a specific
    argument to at least one (credulous) or each (sceptical) σ-extensions (e.g. AFGCN
    (Malmqvist, 2021), A-Folio DPDB (Fichte et al., 2021), ASPARTIX-V21 (Dvor´ak et
    al., 2021), ConArg (Bistarelli et al., 2021a), FUDGE (Thimm et al., 2021), HARPER++
    (Thimm, 2021), MatrixX (Heinrich, 2021), µ-toksia (Niskanen & J¨arvisalo, 2021),
    PYGLAF (Alviano, 2021)).

    - ''Panoptic Engines'', i.e. solvers designed to implement additional functionalities
    and customisation tools (e.g. ArguLab (Podlaszewski et al., 2011), ArgTrust (Tang
    et al., 2012), Argue tuProlog (Bryant et al., 2006), IACAS (Vreeswijk, 1994),
    CaSAPI (Gartner & Toni, 2007), Prengine (Hung, 2017), PyArg (Borg et al., 2022),
    NEXAS (Dachselt et al., 2022)).


    Example 4 The ASP-Solver ASPARTIX is an example of such an argumentation-driven
    reasoning engine. Starting from an AF as input, the Answer-Set-Programming solver
    will output the result of the specified reasoning task given a particular semantic
    (both encoded as ASP rules).


    ![](_page_6_Figure_5.jpeg)


    Figure 3: Example of an argumentation reasoning engine architecture (Dvoˇr´ak
    et al., 2020).


    It is worth mentioning that most of these engines also embed a planning component,
    which derives from their underlying employment of the AF formalism. Indeed, computing
    acceptable arguments enables ''argumentative paths'' that lead to the achievement
    of the predetermined goal by deciding among (possibly) multiple options. Following
    edges that connect justified nodes in an AF will exclude any potential rebuttals,
    thus ensuring a successful strategy. That is to say, each reasoning step, enclosed
    and rendered as an argument, is performed whilst having in mind the overall plan
    required for reaching a consistent decision.


    # 2.1.4 Argumentation-based Dialogues


    The view of computation as distributed cognition and interaction contributed to
    the rise of the multi-agent systems paradigm, where agents are intended as software
    entities capable of flexible autonomous action in dynamic and unpredictable domains
    (Luck et al., 2005). As a means of communication between such intelligent agents,
    formal dialogues were chosen due to their potential expressivity despite still
    being subject to specific restrictions (McBurney & Parsons, 2009). Argumentation-based
    dialogues are rule-governed interactions among participants (i.e. agents with
    their own beliefs, goals, desires and a limited amount of information regarding
    the other players) that take turns in making utterances. As shown in Table 1,
    these dialogues are usually categorized according to elements such as information
    possessed by the participants at the commencement of the interaction, their individual
    goals, and the knowledge and goals they share with other agents (Walton & Krabbe,
    1995).


    | Dialogue type    | Description                                                        |
    Example                    |

    |------------------|--------------------------------------------------------------------|----------------------------|

    |                  | Information-seeking X seeks the answer to some question(s)
    from Y. | (Hulstijn, 2000)           |

    | Inquiry          | X and Y collaborate to answer some question(s).                    |
    (Black & Hunter, 2007)     |

    | Persuasion       | X seeks to persuade Y to accept a proposition.                     |
    (Prakken, 2006)            |

    | Negotiation      | X and Y bargain over the division of some scarce resources.        |
    (McBurney et al., 2003)    |

    | Deliberation     | X and Y collaborate to decide what actions should be adopted.      |
    (McBurney et al., 2007)    |

    | Eristic          | X and Y quarrel verbally to vent perceived grievances.             |
    /                          |

    | Verification     | X wants to verify the beliefs of Y.                                |
    (Cogan et al., 2005)       |

    | Query            | X challenges Y since it is interested in Y''s arguments.            |
    (Cogan et al., 2005)       |

    | Command          | X tells Y what to do.                                              |
    (Girle, 1996)              |

    | Education        | X wants to teach Y something.                                      |
    (Sklar & Parsons, 2004)    |

    | Chance discovery | Ideas arise out of exchanges between X and Y.                      |
    (McBurney & Parsons, 2001) |


    Table 1: Description of existing dialogue types


    The selection and transitions between different dialogues can instead be rendered
    via a Control Layer (McBurney & Parsons, 2002; Sklar & Azhar, 2015), defined in
    terms of atomic dialogue types and control dialogues. The latter are meta-structures
    that have as their topics other dialogues and contribute to the management of
    the protocols combinations and their transitions.


    In general, the main components of argumentation-based dialogues can be identified
    as: (i) syntax, which handles the availability of and interaction between utterances;
    (ii) semantics, which differs according to the specific focus and final deployment
    of the dialogue; and (iii) pragmatics, which accounts for those aspects of the
    language that do not involve considerations about truth and falsity (e.g. the
    illocutionary force of the utterances) (McBurney & Parsons, 2013).


    ### 2.2 Chatbots


    A chatbot must be able to parse the user input and interpret what it means before
    providing an appropriate response or output (and thus starting a ''chat''). The
    way in which the bot elaborates the replies to be delivered depends upon its response
    architecture model. Following the studies conducted in (Adamopoulou & Moussiades,
    2020; Singh & Thakur, 2020; Klopfenstein et al., 2017; Codecademy, 2022), we can
    classify such models as:


    - Rule-based chatbots employ the simplest response architecture structure. The
    bots'' replies are entirely predefined and returned to the user according to a
    series of rules. The internal model of such rule-based software can be thought
    of as a decision tree that has a clear set of possible outputs defined for each
    step in the dialogue. Usually, this category of conversational agents handles
    those kinds of interactions where the user has a number of pre-compiled options
    to choose from. As an example of rule-based colloquial agents, we can consider
    ELIZA (Weizenbaum, 1966): deemed by scholars as the first implementation of a
    chatbot, it operates by harnessing linguistic rules in combination with recognized
    keywords from the users'' inputs. Further development in the area resulted in
    PARRY (Colby et al., 1971), a chatbot that improved ELIZA via a conversational
    strategy embedded to simulate a person with paranoia. Jabberwacky (Carpenter,
    1982) is also an instance of a rule-based bot that interacts through contextual
    pattern matching. It steadily expands its database by collecting tokens from previous
    conversations that occurred with different users.

    - Retrieval-based chatbots represent a more complex response architecture structure.
    The bots'' replies are pulled from an existing corpus of stored sentences. Machine
    Learning and Natural Language Processing (NLP) models are used to interpret the
    user input (operation divided into intent classification and entity recognition)
    and determine the most fitting response to retrieve. As an example of retrieval-based
    colloquial agents, we can consider A.L.I.C.E. (Wallace, 2009) developed using
    the Artificial Intelligence Markup Language (AIML) (Wallace, 2003). Such a language
    comprises a class of data objects and partially describes the behaviour of computer
    programs that process them via stimulus-response templates. Furthermore, also
    IBM''s Watson Assistant (IBM, 2006) and Microsoft''s Cortana (Microsoft, 2014)
    represent other instances of the retrieval-based model. The first parses input
    to find statistically relevant replies in its database by means of parallel algorithms.
    The second instead leverages the natural language processing capabilities of Tellme''s
    Network (owned by Microsoft from 2007) and the Satori knowledge repository to
    provide responses (Marshall, 2014).

    - Generative chatbots represent the most convoluted response architecture structure.
    These bots are capable of formulating their own original responses based on the
    user input rather than relying on existing text. The deployment of Deep Learning
    models allows returning the appropriate response by calculating the likelihood
    of the next element(s) in a word sequence. However, training such models requires
    time, and it is not always clear what is used to produce replies, which may be
    repetitive or nonsensical. In addition, generative bots are not generally capable
    of accessing data other than what is embedded in their model parameters. One common
    approach to mitigate these problems is to combine both retrieval and generative
    operations in the chatbot (Roller et al., 2020). As an example of such a hybrid
    type of virtual assistant, we can consider Apple''s Siri (Apple, 2011) and Amazon''s
    Alexa (Amazon, 2014; Lopatovska et al., 2019). Both provide replies to users''
    questions (along with an additional wide


    array of possible functions) via Deep Learning procedures or delegating requests
    to a set of external providers (e.g. WolframAlpha (Heater, 2018)).


    Generative-LLMs. Generative chatbots that hinge upon Large Language models (LLMs)
    deserve special mention, given recent interest in such models. The design and
    deployment of the Transformer architecture (Vaswani et al., 2017) determined a
    paradigm shift towards ''pre-training'' and ''fine-tuning'' learnings (Zhao et
    al., 2023): scaling up pre-trained models led to the discovery of LLMs and their
    impressive capabilities (Brown et al., 2020; Touvron et al., 2023a; Anil et al.,
    2023). Leveraging these new technologies, conversational agents such as the famous
    ChatGPT<sup>3</sup> prove to outperform most of the previous benchmarks and predecessors
    in information extraction tasks (Li et al., 2023), natural language inference,
    question answering, dialogue tasks (Qin et al., 2023) and machine translation
    (Jiao et al., 2023). That being said, LLMs and the chatbots based on them also
    suffer from a number of downsides including: faulty reasoning, inexplicable appearance
    of previously unknown abilities (phenomenon denoted as emergent abilities<sup>4</sup>
    ), nonsensical or unfaithful replies (i.e. hallucination), biased and toxic communications,
    expensive training costs and high carbon footprint<sup>5</sup> . Finally, it has
    also been shown how underlying models such as GPT-3 (Brown et al., 2020) fall
    short of producing adequate and compelling arguments (Hinton & Wagemans, 2022).
    However the outputs of such models may prove particularly suited to support argument
    mining operations, given carefully conditioned (or an increased number of) inputs
    (de Wynter & Yuan, 2023; Chen et al., 2023).


    The different response architecture models and the corresponding high-level operations
    that characterise them are depicted in Figure 4. Notice, as previously anticipated,
    that is quite common for conversational agents to use a combination of different
    response models in order to produce optimal results. Furthermore, chatbots can
    be classified based on the conversation topics they are able to cover. Closed
    domain ones (e.g. bots focused on customer assistance or e-commerce) are restricted
    to providing responses within a particular matter. Due to their specific area
    of competence, usually, these agents are very efficient in delivering good-quality
    discourses. On the other hand, open domain chatbots (e.g. the previously referenced
    Apple''s Siri, Amazon''s Alexa, Meta''s Llama 2-Chat, Google''s Bard and OpenAI''s
    ChatGPT, as well as Meena (Adiwardana et al., 2020), Mitsuku (Worswick, 2018)
    and Microsoft''s XiaoIce (Zhou et al., 2020)) should be able to explore any range
    of conversation topics, similar to how a real-world human-to-human interaction
    would be. However, it is not straightforward to implement such bots, and they
    prove to be more prone


    <sup>3.</sup> Other remarkable examples are DialoGPT (Zhang et al., 2019), BlenderBot
    3x (Xu et al., 2023), Bard (https://bard.google.com/), Claude (https://claude.ai/),
    Llama 2-Chat (Touvron et al., 2023b), Mistral-7b-Instruct (Jiang et al., 2023),
    and Zephyr-7b (Tunstall et al., 2023).


    <sup>4.</sup> Emergent abilities constitute a controversial topic and some studies
    even argue against their existence (Schaeffer et al., 2023).


    <sup>5.</sup> Although it has been argued that the adoption of best practices
    in model training should reduce carbon dioxide emissions by 2030 (Patterson et
    al., 2022).


    ![](_page_10_Figure_1.jpeg)


    Figure 4: Comparisons of different response architecture models


    to errors, incoherent responses<sup>6</sup> or other issues similar to the aforementioned
    generative-LLMs.


    # 2.2.1 The Knowledge Base Acquisition


    Chatbots cannot automatically generate responses unless they are provided with
    a specific knowledge base from which those replies can be retrieved. This limitation
    involves every type of conversational agent and not only the retrieval-based,
    as one may think. Indeed, rule-based architecture requires hard coding of data
    into the scripts of the chatbot, whereas generative models necessitate a corpus
    of information to be trained upon. However, plenty of data collection is needed
    to obtain such knowledge bases and, usually, these datasets allow the chatbots
    to interact only on a restricted range of topics. In particular, anticipating
    a topic covered in the next sections, some argumentation-based chatbots are characterized
    by a knowledge base consisting of a set of arguments (alternatively, an argument
    graph) to collect which current approaches include argument mining from documents
    (e.g. (Cocarascu et al., 2019; Trautmann et al., 2020)) or hand coding of texts
    by researchers (e.g. (Cerutti et al., 2016; Rosenfeld & Kraus, 2016)). Nevertheless,
    these operations can be complicated tasks to achieve, especially if we need to
    handle only real-world arguments rather than artificial (i.e. computed) ones.
    That is to say, it may be difficult to retrieve high-quality arguments concerning
    a specific topic on the web, or it may also be problematic to distinguish between
    the person (and, thus, account for her attributes) who posited a specific claim.
    Questionnaires or personal interviews may provide a solution, although such solutions
    are expensive and require a large amount of human effort. Interestingly, studies
    such as (Chalaguine & Hunter, 2018; Chalaguine et al., 2018) proposed an alternative
    method to face this potential issue. The results of their research show how a
    chatbot, with little


    <sup>6.</sup> Notice these errors can have extreme and harmful consequences, such
    as a medical chatbot suggesting a patient to kill themselves. (Daws, 2020)


    to no domain expertise, may elicit arguments and counterarguments from different
    users, thus automating the process of argument acquisition. This procedure, called
    argument harvesting by the authors, allows for the generation of AFs that incorporate
    the knowledge base information over the required domain. Another alternative approach
    is provided by the work conducted in (Chalaguine & Hunter, 2019) that describes
    how to acquire a large number of (high-quality) arguments in a graph structure
    using crowd-sourcing.


    # 3. Methodology


    This survey hinges upon the collection and review of papers concerning argumentationbased
    chatbots. Before delving into the examination of our findings, it may be helpful
    to provide an uncontroversial definition of the subject of our investigation:


    Definition 3 (Computational Argumentation-based chatbots) We consider computational
    argumentation-based chatbots those conversational agents that employ argumentative
    models to: (i) extract textual data via argument mining tools, (ii) structure
    information by means of argumentative templates, (iii) reason with argument semantics
    and/or (iv) deliver replies to users through argumentation-based dialogues.


    A schematic representation of the argumentation employment types within a conversational
    agent architecture is provided in Figure 5. Here it is specified the level at
    which each aspect operates in the overall chatbot design. Argument mining enables
    the construction of a database for model training or a knowledge base (KB) by
    extracting information from texts. KB data can be structured into argumentative
    patterns, which may then be delivered as argumentation-based dialogue replies
    to the interacting end-user after being selected through a reasoning step (that
    usually involves argument semantics computation). Notice that we strictly selected
    only papers involving such aspects, avoiding any other articles pertaining to
    chatbots or meanings of argumentation that differ from those introduced in Section
    2. For example, we did not consider the work of (Toniuc & Groza, 2017) among the
    surveyed papers since it does not account for computational argumentation as described
    herein (albeit the presented textual entailments relationship may be transformed
    into a sort of premises-conclusion argument dependency). A similar issue can be
    observed in (Altay et al., 2022; Kulatska, 2019) where, although there is a reference
    to a general notion of arguments and counterarguments, it does not correspond
    to the one provided in Section 2. On the other hand, we also excluded research
    such as (Chalaguine et al., 2018; Chalaguine & Hunter, 2018) since their focus
    is more on the automated collection of a corpus of arguments and counterarguments
    rather than the implementation of a conversational agent that delivers argumentation-based
    dialogues. Furthermore, the interactive recommender system of (Rago et al., 2018,
    2020), which clarifies its recommendations through explanations, does not qualify
    as an argumentation-based chatbot either. That is because, although it makes use
    of a Bipolar/Tripolar AF<sup>7</sup> to embed its underlying knowledge base, no
    reasoning, extraction, structure or delivery via computational models of argument
    (as interpreted in this paper) occurs.


    <sup>7.</sup> Bipolar Argumentation Frameworks, or Bipolar AFs, have been extensively
    introduced in (Cayrol & Lagasquie-Schiex, 2005). Tripolar Argumentation Frameworks
    may instead be seen as (using the same words that appear in (Rago et al., 2018)):
    "instances of ''tripolar frameworks'' as defined in (Gabbay, 2016) and of ''generalised
    argumentation frameworks'' as defined in (Baroni et al., 2017)."


    ![](_page_12_Figure_1.jpeg)


    Figure 5: Schematic argumentation employment within chatbots architecture.


    To clarify, in our survey, we did not restrict the search according to particular
    chatbot types, or their final scope, nor did we distinguish between different
    bot denominations (e.g. ''argumentative dialogical agent'', ''dialogue manager'',
    ''automated persuasion system'') or maturity of implementation, (e.g. fully-fledged
    or just sketched). Also, we did not account for specific time ranges and gathered
    articles independently of the year of publication. We have then analysed and organized
    the results in one concise comparative table (Table 2) that displays the classifications
    and main features of each conversational agent. In particular, we listed all the
    reviewed chatbots and distinguished between each bot''s final purpose (e.g. persuade,
    explain, inform), response architecture model (the prevalent one is recorded in
    case of multiple models), and conversation domain (for which we mostly considered
    the topic specified in the corresponding paper examples). Additional data comprise
    also the way in which computational argumentation has been employed within the
    chatbot architecture (i.e. extraction, structure, reason, deliver). Finally, we
    inspected the arranged information and discussed our main findings.


    | Paper(s)                      | Final       | Response        | Conversation        |
    Argumentation      |

    |-------------------------------|-------------|-----------------|---------------------|--------------------|

    |                               | Purpose     | Architecture    | Domain              |
    Employment         |

    | (Cocarascu et al., 2019)      | Explain     | Rule-based      | Movies reviews      |
    Extract, Reason    |

    | (Slonim et al., 2021)         | Debate      | Retrieval-based | Unspecified         |
    Extract            |

    |                               |             |                 | (semi-open domain)  |                    |

    | (Galitsky, 2019)              |             |                 |                     |                    |

    | (Galitsky, 2018)              | Unspecified | Retrieval-based | Unspecified         |
    Extract            |

    | (Galitsky, 2020)              |             |                 | (closed domain)     |                    |

    | (Dignum & Bex, 2017)          | Converse    | Retrieval-based | Healthcare          |
    Reason, Deliver    |

    | (Bistarelli et al., 2021)     | Converse    | Retrieval-based | Unspecified         |
    Reason             |

    |                               |             |                 | (closed domain)     |                    |

    | (Castagna et al., 2022, 2023) | Explain     | Retrieval-based | Healthcare          |
    Reason, Structure  |

    | (Sassoon et al., 2019)        | Explain     | Retrieval-based | Healthcare          |
    Reason, Structure, |

    |                               |             |                 |                     |
    Deliver            |

    | (Fazzinga et al., 2021)       | Inform      | Retrieval-based | COVID-19 vaccine    |
    Reason, Deliver    |

    | (Bex et al., 2016)            | Inform      | Retrieval-based | Fraud report        |
    Reason, Deliver    |

    | (Sklar & Azhar, 2015)         | Explain     | Retrieval-based | Treasure Hunt       |
    Deliver            |

    | (Sklar & Azhar, 2018)         |             |                 | Game                |                    |

    | (Rosenfeld & Kraus, 2016)     | Persuade    | Retrieval-based | Benefits of
    holding | Reason, Deliver    |

    |                               |             |                 | a Master''s
    Degree   |                    |

    | (Chalaguine et al., 2019)     | Persuade    | Retrieval-based | Meat consumption    |
    Deliver            |

    | (Chalaguine & Hunter, 2020)   | Persuade    | Retrieval-based | UK university
    fees  | Deliver            |

    | (Chalaguine & Hunter, 2021)   | Persuade    | Retrieval-based | COVID-19 vaccine    |
    Deliver            |

    | (Hadoux & Hunter, 2019)       | Persuade    | Retrieval-based | Cycling in the
    city | Deliver            |

    | (Hadoux et al., 2021)         | Persuade    | Retrieval-based | UK university
    fees  | Deliver            |

    | (Andrews et al., 2008)        | Persuade    | Retrieval-based | Desert survival     |
    Deliver            |

    | (Guo et al., 2022)            | Persuade    | Retrieval-based | Nuclear energy      |
    Deliver            |

    | (Wambsganss et al., 2021)     | Explain     | Unspecified     | Unspecified         |
    Extract            |

    |                               |             |                 | (closed domain)     |                    |


    Table 2: Argumentation-based chatbots specifics


    # 4. Argumentation-based Chatbots


    This section covers a concise description of all the reviewed chatbots according
    to their specific argumentation employment. We first outline each argumentation-based
    category before providing an account of the conversational agents pertinent to
    the class. Note that it may be the case for a bot to present components that fulfil
    specific tasks (e.g. extract, structure, reasoning, and deliver) without exploiting
    computational argumentation. The fact that we are not detailing such components
    does not undermine their presence or effectiveness but reflects the choice of
    strictly conferring an argumentative scope to the survey. We conclude by highlighting
    the evaluations of such chatbots (if any) as presented in their respective papers.


    ### 4.1 Argumentation-based Extraction


    Starting from a corpus of natural language texts, argument mining procedures allow
    for the extraction of arguments, and the classification of their relations, within
    such documents. The mined data can then be further processed and organized in
    AFs<sup>8</sup> , or simply be employed as replies according to the user''s input.
    Unlike the latter, the former choice may lead to a reasoning operation upon the
    framework that will elicit specific output depending on the evaluation criteria
    of the captured semantics. For example, ADA, the argumentative dialogical agent
    introduced in (Cocarascu et al., 2019), extracts arguments from movie review snippets
    and mines the relations subsisting among them. The acquired data is then utilized
    to construct a Quantitative Bipolar argumentation framework, QBAF (experimentally
    evaluated against three gradual semantics for QBAF: QuAD (Baroni et al., 2015),
    DF-QUAD (Rago et al., 2016) and the Restricted Euler-based semantics (REB) (Amgoud
    & Ben-Naim, 2018)) upon which the conversational agent will instantiate the reply
    templates stored within its system. Those replies will thus be delivered to the
    interacting user when prompted for explanations about the selected movie recommendation.


    Another example of an argumentation-based extraction chatbot is rendered by the
    conversational agent developed in (Slonim et al., 2021) whose purpose is to challenge
    humans with competitive debates. After having preprocessed a corpus of 400 million
    newspaper articles in order to create an index of meaningful concepts, the bot
    mines for arguments thus obtaining claims and evidence related to the selected
    dispute. In this process, the agent identifies the relations occurring between
    the mined arguments and takes advantage of these data to prepare counterarguments
    against different stances on the debate topic. The replies posited by the bot
    will then be retrieved among the mined arguments, or the ones stored in a more
    general knowledge base, via a neural model. Notably, the interaction with the
    user occurs on a speech base and the speech-to-text conversion is performed by
    IBM''s Watson<sup>9</sup> .


    A borderline case is constituted by the ArgueBot conversational agent (Wambsganss
    et al., 2021). Developed as a learning tool for providing adaptive feedback on
    students'' logic argumentation, ArgueBot (a bot deployed within the Slack platform10)
    hinges on a BERT (Devlin et al., 2018) classifier to perform AM operations on
    the user''s textual input before providing tailored comments on their argumentative
    writing. Although the chatbot may be equipped with specific reply templates, its
    exact response architecture is unclear and remains unspecified by the authors.


    Finally, on a more abstract level, the research discussed in (Galitsky, 2020,
    2019, 2018) describes the deployment of specific argument mining approaches to
    chatbots. Here, the conversational agent constructs a communicative discourse
    tree from a subset of text by matching each fragment of the subset that has a
    verb to a verb signature. The subsequent application of classification models
    allows the bot to detect arguments and their relations


    <sup>8.</sup> We stipulate that constructing an AF from the utterances of an argumentation-based
    dialogue does not qualify as an ''argumentation-based extraction''. That is because
    the arguments and the attacks (respectively supports) are already given and do
    not require further parsing.


    <sup>9.</sup> Once again, recall that we are emphasising the elements leveraging
    computational argumentation. Project Debater (Slonim et al., 2021) is a fully-fledged
    debating system, nonetheless, its employment of AM procedures is the only argumentation-related
    component, and this is why it is the one described.


    <sup>10.</sup> https://slack.com/


    and then leverage that information to provide replies according to the user input.
    In a nutshell, by resorting to in-depth rhetorical analysis, the chatbot accounts
    for multiple features of the argument (e.g. embedded affective aspects, consistency
    with the domain clauses, etc.), which results in more precise user-bot replies
    matches.


    ### 4.2 Argumentation-based Reply Structures


    Chatbot replies can be structured according to the traditional argumentative format:
    a claim derived from a set of premises by means of particular inference rules.
    This approach includes argument schemes and general frameworks for structured
    argumentation (e.g. ASPIC+, ABA, etc.). In general, the organization of data within
    such an argumentative pattern occurs before the generation of an AF and the computation
    of its semantics. However, it may also be convenient to arrange the bot responses
    using specific templates, regardless of a further semantic evaluation. Indeed,
    providing replies with a precise structure serves to highlight the rationale underpinning
    the argument claim and enhance the overall clarity of the discourse. As an example,
    we can consider the conversational agent presented in (Castagna et al., 2022,
    2023), which may be seen as the final implementation of previous versions described
    in (Essers et al., 2018; K¨okciyan et al., 2019; Balatsoukas et al., 2019; Chapman
    et al., 2019; Balatsoukas et al., 2020; Sassoon et al., 2020; K¨okciyan et al.,
    2021; Drake et al., 2022). Harnessing the novel Explanation-Question-Response,
    or EQR, argument scheme (first envisaged as a dialogue protocol and sketched in
    (McBurney, Parsons, et al., 2021)), this bot delivers tailored justified recommendations
    within the healthcare domain, helping users self-manage their conditions. These
    recommendations embed an additional layer of information: the rationale behind
    the instantiated scheme acceptability (i.e. its evaluation, automated via the
    ASPARTIX (Egly et al., 2008) engine, according to the considered argumentation
    framework). Additional replies provided by the chatbot will be structured by harnessing
    the argument scheme (and respective CQ) templates instantiated by the bot knowledge
    base.


    ### 4.3 Argumentation-based Reasoning


    As previously discussed, an argumentation engine can be employed as the underlying
    tool that drives a chatbot''s reasoning operations. In such a circumstance, regardless
    of the chosen framework (e.g. Abstract AFs (Dung, 1995), Bipolar AFs (Cayrol &
    Lagasquie-Schiex, 2005), Weighted Bipolar AFs (Rosenfeld & Kraus, 2016), Quantitative
    Bipolar AFs (Cocarascu et al., 2019), Metalevel AFs (K¨okciyan et al., 2021),
    etc.), most of the decisionmaking processes involve the computation and semantic
    evaluation of the AF. Intuitively, starting from a knowledge base embedded in
    a set of arguments, the bot executes a reasoning procedure that usually results
    in a selection of acceptable arguments (which changes depending on the chosen
    semantics). When interacting with the user, the conversational agent will retrieve
    its replies, based upon the received input from its interlocutor, from the computed
    acceptable arguments. As such, we can generally assume that argumentation-based
    reasoning engines are intertwined with retrieval-based response architectures
    or hybrid models that include retrieval-based operations. For example, ArguBot
    (Bistarelli et al., 2021b), developed using Google DialogFlow11, employs ASPARTIX
    (Egly et al., 2008) to compute arguments from an underlying Bipolar AF, to support
    (pro-bot) or challenge (con-bot) the user''s opinion about the topic of dialogue.


    The conversational agent presented in (Fazzinga et al., 2021)<sup>12</sup> retrieves
    its arguments from an underlying Bipolar AF as well, although it follows the semantics
    illustrated in (Fazzinga et al., 2018). The selected reply is then an argument
    acceptable with respect to an admissible extension computed over the overall framework,
    thus providing a strategy that also accounts for future developments of the chat.
    In addition, the bot is capable of formulating on-demand explanations about a
    particular reply, i.e. a sequence of natural language sentences that describes
    the facts supporting it, along with motivations against other possible conflicting
    arguments that the system discarded.


    In contrast, the chatbot outlined in (Dignum & Bex, 2017) deploys computational
    argumentation as a means of evaluating completed phases of the ongoing dialogue,
    rather than starting with a previously generated AF. More precisely, an argument
    graph is constructed by incorporating the facts that emerge during the dialectical
    interaction with the user. Then, a formal assessment occurs by checking if those
    facts are members of acceptable extensions of the graph. Interestingly, this conversational
    agent harnesses social practices theory (Reckwitz, 2002; Shove et al., 2012) to
    contextualise the conversation and provide useful background information that
    facilitates the user''s input interpretation. A similar deployment of computational
    argumentation is envisaged in (Bex et al., 2016), where an AI system that enhances
    the online report of trade frauds is outlined. A chatbot (the ''dialogue manager'')
    exchanges arguments with the user parties (both fraud victims and police) eliciting,
    if needed, more information about the ongoing case whilst building a knowledge
    graph. The acquired data will then enable the matching of the graph with a typical
    criminal scenario known by the police. Subsequently, formal argumentation semantics
    will drive the reasoning with scenarios and pieces of evidence (i.e. the ''hybrid
    theory'' (Bex et al., 2010; Bex, 2015)).


    Finally, the conversational agent (SPA) envisaged in (Rosenfeld & Kraus, 2016)
    also employs an argumentation-based reasoning engine. In particular, it embeds
    its knowledge base into a Weighted Bipolar AF (WBAF) and computes the argument
    that maximizes the framework evaluation function according to the user input.
    The score returned by the valuation function represents the reasoner''s ability
    to support that argument and defend it against potential attacks. The dialectical
    interaction with the user follows a strategical persuasion dialogue protocol (optimized
    via Monte Carlo Planning (Silver & Veness, 2010)) that might involve updating
    the argumentation frameworks of both the persuader and the persuadee.


    ### 4.4 Argumentation-based Reply Delivery


    Chatbots may handle and deliver their responses to the user interacting with them
    by leveraging the protocols of argumentation-based dialogues. Harnessing the dialogue
    logic, the conversational agent can optimize its strategy and utter only the arguments
    that prove to be necessary for achieving its final goal. In a way, we could identify
    the delivery phase


    <sup>11.</sup> https://cloud.google.com/dialogflow/docs/


    <sup>12.</sup> Subsequently embedded into a privacy-preserving dialogue system
    (Fazzinga et al., 2022).


    as a ''secondary reasoning step'' where the bot chooses which arguments to move
    (strictly following the involved dialogue protocol instructions) among the ones
    available (possibly previously computed by the ''primary engine'' described by
    the reasoning phase). Notice that the arguments licensed in a dialogue protocol
    follow a more flexible definition than the standard ones provided in the abstract
    or structure argumentation approach: " [. . .] it is the idea of dialogue as an
    exchange between two or more individuals, an exchange which captures features
    of what would be informally called an "argument". That is, dialogue as the exchange
    of reasons [i.e. arguments] for or against some matter"(Black et al., 2021).


    As an example, we could examine the work introduced in (Hadoux et al., 2021),
    which expands upon (Hadoux & Hunter, 2019; Hunter, 2018; Hunter et al., 2019)
    and depicts an overall framework for modelling beliefs and concerns in a persuasion
    dialogue. An implementation of such a framework is then envisaged via an automated
    persuasion system (APS), a software application aiming at convincing the interacting
    agent to accept some arguments. Following the asymmetric persuasion dialogue protocol
    illustrated therein (i.e. unlike the system, the user is restricted in choosing
    replies among the provided options), the proposed chatbot proves to be capable
    of identifying, within its knowledge base embedded in an argument graph, the most
    appropriate argument to posit. Essentially, the APS performs a Monte Carlo Tree
    Search coupled with a reward function to maximize the addressing of concerns (paired
    with the arguments of the graph) and the user''s beliefs.


    Similarly, the bot presented in (Chalaguine & Hunter, 2020) aims at persuading
    the interlocutor via a free-text interaction where the user''s inputs are matched
    (by vector rendering and cosine similarity) with the (crowdsourced) arguments
    of the graph representing the knowledge base. The chatbot trains a classifier
    to detect the most common concerns of the persuadee and employs it to select counterarguments
    that will produce a result more compelling than a random choice. If no argument
    similarity is detected, the conversational agent will resort to a default reply
    based on the user''s concerns. Furthermore, the same authors presented an analogous
    architecture for a persuasion bot in (Chalaguine & Hunter, 2021), with the addition
    of a particular concern-argument graph. By incorporating the knowledge base within
    such a small graph, it can be proved that no large amount of data is needed to
    generate effective persuasive dialogues. Interestingly, a preliminary analysis
    of the impact (appeal) of arguments addressing the users'' concerns in a persuasion
    dialogue performed by a chatbot has also been conducted by the same authors in
    (Chalaguine et al., 2019). Another example of such a concern-based approach may
    be represented by Argumate, a chatbot designed to facilitate students'' production
    of persuasive statements (Guo et al., 2022). To provide appropriate suggestions,
    the bot retrieves its replies from an underlying argument graph, whose edges denote
    attack and support relations, via a concern identification method. Notice that
    the interactions between Argumate and the users occur both by typing and selecting
    predefined options.


    A common trait amongst all of the above argumentation-based conversational agents
    is that, although the corpus from which they extract their replies is organized
    as an argument graph, there is no interest in any particular acceptable semantics.
    That is to say, the knowledge base is organized and considered as a plain AF,
    where arguments and attacks are the only relevant features. In addition, most
    of these studies also account for a baseline chatbot which exploits a random strategy
    for selecting counterarguments from the available choices within the underlying
    knowledge base. The reason for this is to provide a means for comparing the developed
    bots which employ more fine-grained strategies for choosing their replies.


    Finally, one last conversational agent that focuses on the delivery of persuasion
    dialogues is the chatbot designed in (Andrews et al., 2008). Implemented harnessing
    the AIML markup language (Wallace, 2003), the bot comprises a planning component
    that searches over an argumentation model for the optimal dialectical path to
    pursue in order to persuade the user. The agent records the user''s beliefs and
    updates this information whenever its interlocutor agrees/disagrees during the
    interaction. Such belief revision plays an important role in the strategic view
    of the chatbot. Moving towards different topics, the conversational agent implemented
    in (Sassoon et al., 2019), within the context of explanation for wellness consultation,
    exploits multiple dialogue protocols (i.e. persuasion, deliberation and information
    seeking) whilst exchanging instantiations of acceptable argument schemes with
    its interlocutor. The adoption of diversified dialogue protocols (i.e. persuasion,
    inquiry and information seeking) characterises also the chatbot-equipped robot
    proposed in (Sklar & Azhar, 2015) and demonstrated in (Azhar & Sklar, 2017). Retrieving
    the most appropriate argument constructed from its beliefs, an operation facilitated
    by the restricted options available to the user, the robot communicates with its
    human interlocutor in order to strategize about a treasure-hunting game.


    ### 4.5 Evaluation of the Chatbots


    Thus far, we have described the reviewed argumentation-based chatbots, primarily
    focusing on their features in relation to argumentation employment. However, some
    of those conversational agents have also been evaluated via specifically designed
    user studies<sup>13</sup> whose results will be reported herein. For example,
    the virtual debater devised in (Slonim et al., 2021) exhibits a higher discussion
    quality than the compared artificial competitors, although it still fails to achieve
    a human-like level. Furthermore, (Balatsoukas et al., 2020) reported on the findings
    ensuing from the pilot study designed to assess a former version of the CON-SULT
    system and the comprised chatbot. The outcome was a criticism concerning a lack
    of a more natural conversation flow when interacting with the bot. User studies
    have also been conducted to test the human-robot interaction presented within
    the ArgHRI system of (Sklar & Azhar, 2015; Azhar & Sklar, 2017). The results showed
    how argumentation-based dialogues contribute to enhancing trust towards the robots.
    Nonetheless, analysis of the


    <sup>13.</sup> A different (and outdated) way of evaluating the capability of
    a conversational agent would be through a discussion with a human end-user: the
    more natural and seamless the interaction, the more effective the chatbot. The
    Turing Test (or Imitation Game) is a proposal advanced by Alan Turing (Turing
    & Haugeland, 1950) whose idea was to present some sort of test of a machine''s
    ability to exhibit intelligent behaviour equivalent to, or indistinguishable from,
    that of a human. Hinging on the Imitation Game, the Loebner Prize is a contest
    started in 1980 to award computer programs that are the most humanlike, i.e. that
    perform the best in the Turing Test. The winner of the contest is the one that
    tricks a judge the highest percentage of the time, and Mitsuku is the chatbot
    that won the largest number of such prizes (Worswick, 2013). The Loebner competition
    (considered defunct since 2020) has been subjected to a long list of criticisms.
    Among these, there was the alleged idea that entrants do not aim at understanding
    humans since deception and pretence are highly rewarded in this contest. Another
    criticism leveled against the Loebner Prize is that it confuses the Imitation
    Game with proof of humanlike intelligence. However, machines cannot reason like
    humans, as claimed by Searle in 1980 with his famous ''Chinese Room experiment''
    (Searle, 1980; Cole, 2020).


    dialogues themselves (Sklar & Azhar, 2018) highlighted how the possibility of
    interrogating the bot to obtain explanations did not lead to a significant increase
    in performance from the human-robot team, nor a boost in user satisfaction.


    On the other hand, the SPA conversational agent introduced in (Rosenfeld & Kraus,
    2016) outplayed the baseline chatbot (which harnessed a different, heuristic,
    strategy) when tested in its persuasion task, thus proving capable of delivering
    human-like level conversations. Similarly outperforming the baseline agent is
    the bot presented in (Chalaguine et al., 2019). Indeed, the paper includes an
    experiment that shows how such a chatbot, by positing arguments that address the
    users'' concerns, is more likely to positively change the users'' attitude in
    comparison with another agent that does not employ such a strategy. An analogous
    interest in users'' concerns is encompassed in the study implemented in (Chalaguine
    & Hunter, 2020). The results (conjointly supported by the experiments in (Hadoux
    & Hunter, 2019) and confirmed by (Hadoux et al., 2021)) conclude that a strategic
    chatbot accounting for concerns is more likely to provide relevant and cogent
    arguments. Moreover, it is also worth mentioning the evaluation outcome of the
    other two persuasive agents presented in (Andrews et al., 2008; Chalaguine & Hunter,
    2021). The former bot provides fluent conversations with its interlocutors performing
    generally better than a purely task-oriented system. The latter, instead, shows
    how an interactive chatbot yields more compelling information than a static webpage.


    Lastly, the ArgueBot conversational agent underwent both quantitative and qualitative
    assessments (Wambsganss et al., 2021). The data collected from detailed feedback
    and Likert scale post-experiment forms yielded positive results. In particular,
    the participants perceived the chatbot as helpful, useful and easy to interact
    with.


    ## 5. Discussion


    Table 2 depicts an overview of our findings, with a quantitative summary of the
    sampled chatbots'' features shown in Figure 6. As a first remark, it is surprising
    that only a few argumentation-based chatbots appear in the literature. Indeed,
    the formal characterisation of real-world dialectical interactions provided by
    computational argumentation seems to be well-suited for agents whose role concerns
    conversing with users. This, however, may follow from the fact that the computational
    argumentation research field is still in an early stage of dissemination (especially
    outside of Europe), rather than deriving from the unsuitability of the argumentation
    formalism. Another possible explanation may be due to the fact that there has
    been an explosive interest in model-free methods in computer science in the last
    decades (Bringsjord & Govindarajulu, 2022), ignoring model-based methods (like
    computational argumentation), which are only now gaining favour again, for example,
    as a way of ''interpreting'' the model-free output. Nevertheless, a number of
    considerations can be drawn from the outcome of our analysis. Persuade and Explain
    prove to be the most common goals of the examined chatbots. The latter stems from
    the recent interest in explainable AI and its link with computational models of
    arguments (Vassiliades et al., 2021; McBurney et al., 2021; Cyras et al., 2021).
    Persuasion dialogues, instead, have been ˇ studied in papers such as (Hunter,
    2015; Murphy et al., 2016), whose findings show how the use of argumentation-based
    formalisms may provide compelling strategies to induce belief change. One reason
    for such a number of persuasion-focused chatbots could indeed


    ![](_page_20_Figure_1.jpeg)


    Figure 6: Percentage of sampled systems characterised by the argumentation employment
    type (top left), response architecture (top right), final purpose (bottom left)
    and conversation domain (bottom right) as described from the data of Table 2.


    be related to the effectiveness of argumentation in delivering replies in such
    an area, as also advocated by the results of several user studies. To corroborate
    this, it can be noticed how persuasive conversational agents employ computational
    argumentation in such a way that falls under the (dialogical) Deliver category
    (which, as expected, turns out to be the most common class listed in Table 2).
    Observe also that the main features of such bots include the account of beliefs
    and concerns when positing cogent (argumentative) replies. Continuing our analysis
    of different typologies of argumentation employment, it is worth emphasizing that
    Structure always appears together with Reason (though not vice versa), meaning
    that they are closely intertwined. That is because, in the considered papers,
    the instantiated scheme templates that structure the arguments work as input for
    the evaluating algorithm operated by the reasoning engine.


    In general, it is less common that an argumentation-based chatbot employs argumentation
    solely for its reasoning engine. Indeed, after the semantics of the underlying
    AF have been computed, the bot usually requires a dialogue protocol that handles
    the replies delivery. Speaking of the underlying argumentation framework, we realized
    that, when embedding a knowledge base into an AF, the Bipolar framework (and its
    variants QBAF and WBAF) turns out to be the most common option. This choice is
    related to the additional information provided by BAFs which encompass support
    relations rather than just attacks, allowing for an intuitive formalisation of
    both endorsements and conflicts between pieces of data.


    Within our survey, we identified several conversation domains contemplated by
    the bots, ranging from Healthcare to Nuclear energy, with the former representing
    the prevailing domain (and also subsuming others). Notice that ''unspecified domain''
    could mean either that no conversational topic has been specified or that a sketched
    list of multiple topics has been presented. Interestingly, there is no argumentation-based
    chatbot eligible to be considered as open domain, although we might regard as
    ''semi-open domain'' the agent discussed in (Slonim et al., 2021). Indeed, despite
    the absence of topic limitations in its debate delivery (due to a huge corpus
    upon which arguments are retrieved), the bot is not capable of handling small
    talk or other analogous trivial interactions. This also affects its discussions,
    each of which is modelled as a challenge towards opposite stances. Another peculiarity
    of the agent engineered in (Slonim et al., 2021) is that it allows for unconstrained
    speech in user input, whereas most chatbots only allow for free-text input (and
    the bots envisaged in (Bex et al., 2016) and (Guo et al., 2022) combines both
    free and limited textual prompts). Nonetheless, the proficiency in managing and
    processing unrestricted natural language sentences shows how argumentation-based
    chatbots can aptly mimic realworld-like discussions.


    Finally, observe that almost every examined bot is equipped with a retrieval-based
    response model with the only exception envisaged in (Cocarascu et al., 2019).
    Indeed, the hybrid conversational agent proposed therein handles its dialogues
    mostly via a few tailored textual templates, hence harnessing its rule-based component.
    However, it may also resort to its retrieval-based model when the user questions
    the provided explanations. In general, it is also worth noticing that, unlike
    standard conversational agents, the surveyed literature revealed no generative-type
    argumentation-based chatbots14. Per se, this is not a major drawback, since generative
    response architecture may suffer from various issues such as lack of transparency
    about the origins of the produced replies, biased output, or creation of nonsensical
    responses. Nevertheless, this outlines a current limitation of argumentationbased
    bots, mostly due to an absence of studies on the matter. A possible solution to
    such a shortcoming may be provided, once again, by resorting to a hybrid approach
    that leverages state-of-the-art Transformer technologies. For example, embedding
    argumentation methodologies into current LLMs-based conversational agents would
    produce generative argumentation-based chatbots while also proving useful in mitigating
    those models'' downsides.


    <sup>14.</sup> Recall, however, that we have no explicit information regarding
    the response architecture of ArgueBot (Wambsganss et al., 2021).


    # 5.1 Benefits of Leveraging Computational Argumentation Approaches in Generative-LLMs
    Chatbots Design


    In the literature, the class of generative-LLMs chatbots (e.g. ChatGPT, Llama
    2-Chat, Bard, Claude) is considered to be the present cutting-edge category of
    conversational agents. Having already listed the shortcomings that affect those
    models, we have not yet discussed potential solutions on how to address such limitations.
    We argue that computational argumentation may prove to be an effective means capable
    of successfully handling and amending most of these weaknesses, especially (but
    not limited to) when they originate from the black-box nature of LLMs. Indeed,
    the thriving research field of eXplainable AI (XAI), which studies ways to improve
    the interpretability of AI-driven systems, proposes also argumentative strategies
    as adequate forms of explanations to address the lack of models'' transparency
    (Cyras et al., 2021; Vassiliades et al., 2021). These intuitions are backed ˇ
    by studies such as (McBurney et al., 2021; Castagna, 2022), where it is suggested
    that AI systems should adopt an argumentation-based approach to explanations consisting
    of dialogue protocols characterising the interactions between an explainer and
    an explainee. Embedded into LLMs, such a dialectical interplay would provide an
    informative post hoc method to deliver deliberated explanations to end-users while
    also ensuring detailed replies to follow-on queries.


    On this matter, it is worth noticing that Microsoft conducted an analysis of the
    capability of GPT-4 (one of the latest released GPT models (OpenAI, 2023)) to
    provide clarifications regarding its output (Bubeck et al., 2023). Although it
    outperforms the ChatGPT version based on GPT-3.5, even GPT-4 has its drawbacks
    when dealing with the process consistency of its explanations: it provides a plausible
    account of the rationale behind the generation of its output, but it often fails
    in representing a more general justification able to predict the outcome of the
    model given similar inputs. An argumentative dialogue (such as EQR (McBurney et
    al., 2021; Castagna, 2022)) designed for explanation purposes would solve the
    process-consistency issues by providing conversations where more information can
    be retrieved and thus eschewing the limited explanation length and language constraints
    deemed to be the leading causes of the problem (Bubeck et al., 2023).


    Drawing from the usability of the aforementioned dialogue-based XAI, let us now
    delve into the possible ways in which computational argumentation may provide
    solutions (summarized in Table 3) to the current shortcomings of LLMs:


    Emergent abilities. The puzzling appearance of such an unpredictable phenomenon
    consists of the sudden occurrence of specific competencies in large-scale models
    that do not manifest in smaller ones. Thus, it is not possible to anticipate the
    ''emergence'' of these abilities (e.g. improved arithmetic, multi-task understanding,
    enhanced multi-lingual operations) by simply analysing smaller-scale models (Wei
    et al., 2022a). Among these capabilities, we can also identify Theory of Mind
    (ToM), i.e. the aptitude to impute mental state to others. Considered to be uniquely
    human, ToM may have spontaneously occurred in LLMs as a byproduct of their training
    (Kosinski, 2023). All of the aforementioned aspects contribute to the general
    mystery surrounding Transformer-based technology, which leads to mistrust among
    the general public. Argumentative XAI could indirectly help as a post hoc solution:
    although it cannot identify the reasons why emergent abilities originate, it could
    nonetheless provide explanations that would clarify their functioning.


    Hallucination. Defined as ''the generated content that is nonsensical or unfaithful
    to the provided source content'' (Ji et al., 2023) the phenomenon of hallucination
    in natural language generation can be divided into intrinsic and extrinsic. The
    former refers to generated output that contradicts the source upon which the model
    was trained. The second, instead, represents an output that cannot be verified.
    The employment of an argumentation reasoning engine can reduce the intrinsic hallucination
    kind by stipulating that only grounded arguments (hence, members of conflict-free
    sceptical extensions) will be output by the chatbot. On the other hand, extrinsic
    hallucinations can be probed by argumentative XAI methods, thus ensuring, in the
    worst-case scenario, the retrieval of additional information over the produced
    content.


    Reasoning. Different scholars argue that, although LLMs provide a good representation
    of language generation, they lack reasoning skills and logical thinking (Mahowald
    et al., 2023; Bang et al., 2023; Frieder et al., 2023; Thorp, 2023). In an attempt
    to provide effective solutions, Chain and Tree of Thoughts (respectively, CoT
    and ToT) have been introduced to address such weaknesses. CoT consists of a prompting
    strategy that details a series of intermediate reasoning steps in order to achieve
    better performance in arithmetic, symbolic and commonsense inferences (Wei et
    al., 2022b). The limitations of this approach mostly concern the absence of a
    procedure to plan or analyse multiple reasoning paths before generating the output
    and this is exactly the enhancement yielded by ToT. Indeed, Tree of Thoughts frames
    each problem as a search over a tree, where each node is a partial solution (Yao
    et al., 2023). Against these two options, we argue that endowing generative-LLM-based
    chatbots with a reasoning engine driven by computational argumentation may provide
    a more intuitive and cheaper alternative (e.g. it does not require expensive resources
    to be implemented, unlike ToT). Argumentative reasoning is particularly suited
    for models that parse, work and generate natural language. Recall that AFs are
    graphs whose edges represent paths determining the status of each node. Then,
    semantically computing an argumentation framework allows planning the most appropriate
    sequence of ''thoughts'' (arguments) to achieve the desired result. Such sequences
    account for divergent information, thus also mimicking and (potentially) outperforming
    the recent CCoT (Contrastive Chain of Thought) prompting technique, which mostly
    handles only one contrastive sample at a time (Chia et al., 2023).


    Biased and Toxic Output. Models have a tendency to reflect their training data,
    thus reproducing biased or toxic content that can harm the interacting user (Brown
    et al., 2020). This translates into the critical necessity of aligning LLMs towards
    human moral values, and even in this case, computational argumentation may prove
    useful to mitigate the problem. Indeed, a recent study investigates the use of
    computational argumentation as a tool for detecting unwanted bias in tabular data-driven
    binary classification decision-making systems (Waller, 2023). The proposed method
    is model-agnostic and does not require access to labelled data or the specification
    of protected characteristics. Notice also that the steadfast progress in the field
    of argument mining could ensure the provision of algorithms capable of precisely
    detecting biased and toxic arguments in the underlying dataset and filtering them
    out. This would allow for the reduction of harmful data upon which generative
    models will be trained. Another potential solution envisages leveraging argument
    schemes and their taxonomies. Specifically, the instantiation of AS from AI systems
    enables a semantically richer approach capable of enhancing and leading LLMs-generated
    text into more realistic and ethically constructive debates (Bezou-Vrakatseli,
    2023).


    | Generative LLMs Chatbot | Potential Solutions |            |               |  |

    |-------------------------|---------------------|------------|---------------|--|

    | Shortcomings            | Arg XAI             | Arg Engine | AM<br>&<br>AS |  |

    | Emergent Abilities      | ✓                   |            |               |  |

    | Hallucination           | ✓                   | ✓          |               |  |

    | Reasoning               |                     | ✓          |               |  |

    | Biased and Toxic Output |                     |            | ✓             |  |


    Table 3: Computational argumentation means for addressing LLMs chatbots'' downsides.
    Arg XAI (Argumentative XAI) refers to explanation procedures based on computational
    argumentation strategies and tools. Arg Engine (Argumentative Engine) concerns
    the reasoning capabilities of engines driven by computational argumentation (Section
    2.1.3). Finally, AM indicates the Argument Mining operations of Section 2.1.1,
    whereas AS denotes the Argument Schemes structure of Section 2.1.2.


    ## 6. Conclusion


    Conversational agents and computational argumentation are intrinsically connected
    by their shared focus on dialectical interactions. Combining both subjects, in
    this paper, we have sifted through the literature to review and analyse the existing
    argumentation-based chatbots. Around 70% of the bots we examined (recalling our
    constrained selection, as explained in Section 3) employ computational models
    of arguments as a way of delivering their replies to interacting users, following
    specific dialogue protocols. This implies that argumentative formalism proves
    to be particularly effective when handling exchanges of information in natural
    language, especially if a persuasion goal is involved. In addition, reasoning
    engines prove to be quite a common feature too. Harnessing argumentation extensions,
    those engines provide the rationale for selecting the most appropriate response
    to output, depending on the chosen semantics. Finally, unlike standard bots (i.e.
    non-argumentative ones), we discovered that there is no generative argumentation-based
    chatbot, nor an open-domain one, although there might be some ways of implementing
    such agents by embedding argumentation methodologies within LLM-driven conversational
    agents. Entangled with computational argumentation, chatbot design and their respective
    forthcoming progress, the research field of argumentation-based chatbots appears
    to have promising options to pursue in the coming years, including an interesting
    role to play in the recent Transformer-based turn of AI studies.


    ## References


    - Adamopoulou, E., & Moussiades, L. (2020). Chatbots: History, technology, and
    applications. Machine Learning with Applications, 2, 100006.

    - Adiwardana, D., Luong, M.-T., So, D. R., Hall, J., Fiedel, N., Thoppilan, R.,
    Yang, Z., Kulshreshtha, A., Nemade, G., Lu, Y., et al. (2020). Towards a human-like
    opendomain chatbot. arXiv preprint arXiv:2001.09977.

    - Altay, S., Schwartz, M., Hacquin, A.-S., Allard, A., Blancke, S., & Mercier,
    H. (2022). Scaling up interactive argumentation by providing counterarguments
    with a chatbot. Nature Human Behaviour, 6 (4), 579–592.

    - Alviano, M. (2021). The PYGLAF argumentation reasoner (ICCMA2021).. http: //argumentationcompetition.org/2021/downloads/pyglaf.pdf.

    - Amazon (2014). Alexa.. https://developer.amazon.com/en-US/alexa, (last accessed
    11/10/2022).

    - Amgoud, L., & Ben-Naim, J. (2018). Evaluation of arguments in weighted bipolar
    graphs. International Journal of Approximate Reasoning, 99, 39–55.

    - Andrews, P., Manandhar, S., & De Boni, M. (2008). Argumentative human computer
    dialogue for automated persuasion. In Proceedings of the 9th SIGdial Workshop
    on Discourse and Dialogue, pp. 138–147.

    - Anil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri,
    S., Taropa, E., Bailey, P., Chen, Z., et al. (2023). Palm 2 technical report.
    arXiv preprint arXiv:2305.10403.

    - Apple (2011). Siri.. https://www.apple.com/siri/, (last accessed 11/10/2022).

    - Atkinson, K., Bench-Capon, T., & Modgil, S. (2006). Argumentation for decision
    support. In International Conference on Database and Expert Systems Applications,
    pp. 822– 831. Springer.

    - Azhar, M. Q., & Sklar, E. I. (2017). A study measuring the impact of shared
    decision making in a human-robot team. International Journal of Robotics Research
    (IJRR), 36, 461–482.

    - Bala, K., Kumar, M., Hulawale, S., & Pandita, S. (2017). Chat-bot for college
    management system using ai. International Research Journal of Engineering and
    Technology, 4 (11), 2030–2033.

    - Balatsoukas, P., Sassoon, I., Chapman, M., Kokciyan, N., Drake, A., Modgil,
    S., Ashworth, M., Curcin, V., Sklar, E., & Parsons, S. (2020). In the wild pilot
    usability assessment of a connected health system for stroke self management.
    In 2020 IEEE International Conference on Healthcare Informatics (ICHI), pp. 1–3.
    IEEE.

    - Balatsoukas, P., Porat, T., Sassoon, I., Essers, K., K¨okciyan, N., Chapman,
    M., Drake, A., Modgil, S., Ashworth, M., Sklar, E., et al. (2019). User involvement
    in the design of a data-driven self-management decision support tool for stroke
    survivors. In IEEE EU-ROCON 2019-18th International Conference on Smart Technologies,
    pp. 1–6. IEEE.

    - Bang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H.,
    Ji, Z., Yu, T., Chung, W., et al. (2023). A multitask, multilingual, multimodal
    evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint
    arXiv:2302.04023.

    - Baroni, P., Comini, G., Rago, A., & Toni, F. (2017). Abstract games of argumentation
    strategy and game-theoretical argument strength. In PRIMA 2017: Principles and
    Practice of Multi-Agent Systems: 20th International Conference, Nice, France,
    October 30–November 3, 2017, Proceedings 20, pp. 403–419. Springer.

    - Baroni, P., Romano, M., Toni, F., Aurisicchio, M., & Bertanza, G. (2015). Automatic
    evaluation of design alternatives with quantitative argumentation. Argument &
    Computation, 6 (1), 24–49.

    - Bench-Capon, T., Prakken, H., & Sartor, G. (2009). Argumentation in legal reasoning.
    Springer.

    - Besnard, P., & Hunter, A. (2008). Elements of argumentation, Vol. 47. MIT press
    Cambridge.

    - Bex, F. (2015). An integrated theory of causal stories and evidential arguments.
    In Proceedings of the 15th international conference on artificial intelligence
    and law, pp. 13–22.

    - Bex, F., Peters, J., & Testerink, B. (2016). A.I. for online criminal complaints:
    From natural dialogues to structured scenarios..

    - Bex, F. J., Van Koppen, P. J., Prakken, H., & Verheij, B. (2010). A hybrid formal
    theory of arguments, stories and criminal evidence. Artificial Intelligence and
    Law, 18 (2), 123–152.

    - Bezou-Vrakatseli, E. (2023). Evaluation of llm reasoning via argument schemes.
    In Online Handbook of Argumentation for AI, Vol. 4.

    - Bistarelli, S., Rossi, F., Santini, F., & Carlo, T. (2021a). CONARG: A constraint-programming
    solver for abstract argumentation problems.. http:// argumentationcompetition.org/2021/downloads/conarg.pdf.

    - Bistarelli, S., Taticchi, C., & Santini, F. (2021b). A chatbot extended with
    argumentation.. In AI3@ AI\* IA.

    - Black, E., & Hunter, A. (2007). A generative inquiry dialogue system. In Proceedings
    of the 6th international joint conference on Autonomous agents and multiagent
    systems, pp. 1–8. Association for Computing Machinery.

    - Black, E., Maudet, N., & Parsons, S. (2021). Argumentation-based dialogue. In
    Handbook of Formal Argumentation, Volume 2, p. 511. College Publications.

    - Borg, A., Odekerken, D., et al. (2022). PyArg for solving and explaining argumentation
    in python..

    - Bringsjord, S., & Govindarajulu, N. S. (2022). Artificial Intelligence. In Zalta,
    E. N., & Nodelman, U. (Eds.), The Stanford Encyclopedia of Philosophy (Fall 2022
    edition). Metaphysics Research Lab, Stanford University.

    - Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan,
    A., Shyam, P., Sastry, G., Askell, A., et al. (2020). Language models are few-shot
    learners. Advances in neural information processing systems, 33, 1877–1901.

    - Bryant, D., & Krause, P. (2008). A review of current defeasible reasoning implementations.
    The Knowledge Engineering Review, 23 (3), 227–260.

    - Bryant, D., Krause, P. J., & Vreeswijk, G. (2006). Argue tuProlog: A lightweight
    argumentation engine for agent applications. COMMA, 144, 27–32.

    - Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E.,
    Lee, P., Lee, Y. T., Li, Y., Lundberg, S., et al. (2023). Sparks of artificial
    general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712.

    - Cabrio, E., & Villata, S. (2018). Five years of argument mining: a data-driven
    analysis.. In IJCAI, Vol. 18, pp. 5427–5433.

    - Cahn, J. (2017). Chatbot: Architecture, design, & development. University of
    Pennsylvania School of Engineering and Applied Science Department of Computer
    and Information Science.

    - Caldarini, G., Jaf, S., & McGarry, K. (2022). A literature survey of recent
    advances in chatbots. Information, 13 (1), 41.

    - Carpenter, R. (1982). Jabberwacky.. https://web.archive.org/web/20050411013547/
    http://chat.jabberwacky.com/ (last accessed 18/10/2022).

    - Castagna, F. (2022). Towards a fully-fledged formal protocol for the Explanation-Question-Response
    dialogue. In Online Handbook of Argumentation for AI, pp. 17–21.

    - Castagna, F., Garton, A., McBurney, P., Parsons, S., Sassoon, I., & Sklar, E.
    I. (2023). EQRbot: A chatbot delivering EQR argument-based explanations. Frontiers
    in Artificial Intelligence, 6.

    - Castagna, F., Parsons, S., Sassoon, I., & Sklar, E. I. (2022). Providing explanations
    via the EQR argument scheme. In Computational Models of Argument: Proceedings
    of COMMA 2022.

    - Cayrol, C., & Lagasquie-Schiex, M.-C. (2005). On the acceptability of arguments
    in bipolar argumentation frameworks. In European Conference on Symbolic and Quantitative
    Approaches to Reasoning and Uncertainty, pp. 378–389. Springer.

    - Cerutti, F., Palmer, A., Rosenfeld, A., Snajder, J., & Toni, F. (2016). A pilot
    study in ˇ using argumentation frameworks for online debates..

    - Chalaguine, L. A., Hamilton, F. L., Hunter, A., & Potts, H. W. W. (2018). Argument
    harvesting using chatbots. Proceedings of COMMA, 149.

    - Chalaguine, L. A., & Hunter, A. (2018). Chatbot design for argument harvesting.
    Computational Models of Argument: Proceedings of COMMA 2018, 305, 457.

    - Chalaguine, L. A., & Hunter, A. (2019). Knowledge acquisition and corpus for
    argumentation-based chatbots. In CEUR Workshop Proceedings, Vol. 2528, pp. 1–
    14. CEUR Workshop Proceedings.

    - Chalaguine, L. A., & Hunter, A. (2020). A persuasive chatbot using a crowd-sourced
    argument graph and concerns. Computational Models of Argument: Proceedings of
    COMMA 2020, 326, 9.

    - Chalaguine, L. A., & Hunter, A. (2021). Addressing popular concerns regarding
    COVID-19 vaccination with natural language argumentation dialogues. In European
    Conference on Symbolic and Quantitative Approaches with Uncertainty, pp. 59–73.
    Springer.

    - Chalaguine, L. A., Hunter, A., Potts, H., & Hamilton, F. (2019). Impact of argument
    type and concerns in argumentation with a chatbot. In 2019 IEEE 31st International
    Conference on Tools with Artificial Intelligence (ICTAI), pp. 1557–1562. IEEE.

    - Chapman, M., Balatsoukas, P., K¨okciyan, N., Essers, K., Sassoon, I., Ashworth,
    M., Curcin, V., Modgil, S., Parsons, S., & Sklar, E. I. (2019). Computational
    argumentation-based clinical decision support. In 18th International Conference
    on Autonomous Agents and Multiagent Systems, AAMAS 2019, pp. 2345–2347. International
    Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS).

    - Chen, G., Cheng, L., Tuan, L. A., & Bing, L. (2023). Exploring the potential
    of large language models in computational argumentation. arXiv preprint arXiv:2311.09022.

    - Chia, Y. K., Chen, G., Tuan, L. A., Poria, S., & Bing, L. (2023). Contrastive
    chain-ofthought prompting. arXiv preprint arXiv:2311.09277.

    - Cocarascu, O., Rago, A., & Toni, F. (2019). Extracting dialogical explanations
    for review aggregations with argumentative dialogical agents. In Proceedings of
    the 18th International Conference on Autonomous Agents and MultiAgent Systems,
    pp. 1261–1269. Association for Computing Machinery.

    - Cocarascu, O., & Toni, F. (2017). Identifying attack and support argumentative
    relations using deep learning. In Proceedings of the 2017 Conference on Empirical
    Methods in Natural Language Processing, pp. 1374–1379, Copenhagen, Denmark. Association
    for Computational Linguistics.

    - Codecademy (2022). What are chatbots.. https://www.codecademy.com/article/ what-are-chatbots
    (last accessed 11/10/2022).

    - Cogan, E., Parsons, S., & McBurney, P. (2005). New types of inter-agent dialogues.
    In International Workshop on Argumentation in Multi-Agent Systems, pp. 154–168.
    Springer.

    - Colby, K. M., Weber, S., & Hilf, F. D. (1971). Artificial paranoia. Artificial
    Intelligence, 2 (1), 1–25.

    - Cole, D. (2020). The Chinese Room Argument. In Zalta, E. N. (Ed.), The Stanford
    Encyclopedia of Philosophy (Winter 2020 edition). Metaphysics Research Lab, Stanford
    University.

    - Cyras, K., Rago, A., Albini, E., Baroni, P., & Toni, F. (2021). Argumentative
    xai: a survey. ˇ In Proceedings of the Thirtieth International Joint Conference
    on Artificial Intelligence (IJCAI-21) Survey Track. International Joint Conferences
    on Artificial Intelligence.

    - Dachselt, R., Gaggl, S. A., Kr¨otzsch, M., Mendez, J., Rusovac, D., & Yang,
    M. (2022). NEXAS: A visual tool for navigating and exploring argumentation solution
    spaces. Computational Models of Argument: Proceedings of COMMA 2022, 353, 116.


    Dale, R. (2016). The return of the chatbots. Natural Language Engineering, 22
    (5), 811–817.


    - Daws, R. (2020). Medical chatbot using openai''s gpt-3 told a fake patient to
    kill themselves.. https://www.artificialintelligence-news.com/2020/ 10/28/medical-chatbot-openai-gpt3-patient-kill-themselves/
    (last accessed 30/1/2023).

    - de Wynter, A., & Yuan, T. (2023). I wish to have an argument: Argumentative
    reasoning in large language models. arXiv preprint arXiv:2309.16938.

    - Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training
    of deep bidirectional transformers for language understanding. arXiv preprint
    arXiv:1810.04805.

    - Dignum, F., & Bex, F. (2017). Creating dialogues using argumentation and social
    practices. In International Conference on Internet Science, pp. 223–235. Springer.

    - Dix, J., Parsons, S., Prakken, H., & Simari, G. R. (2009). Research challenges
    for argumentation.. Comput. Sci. Res. Dev., 23 (1), 27–34.

    - Drake, A., Sassoon, I., Balatsoukas, P., Porat, T., Ashworth, M., Wright, E.,
    Curcin, V., Chapman, M., Kokciyan, N., Sanjay, M., et al. (2022). The relationship
    of sociodemographic factors and patient attitudes to connected health technologies:
    a survey of stroke survivors.. Health Informatics Journal.

    - Dung, P. M. (1995). On the acceptability of arguments and its fundamental role
    in nonmonotonic reasoning, logic programming and n-person games. Artificial intelligence,
    77 (2), 321–357.

    - Dutilh Novaes, C. (2022). Argument and Argumentation. In Zalta, E. N., & Nodelman,
    U. (Eds.), The Stanford Encyclopedia of Philosophy (Fall 2022 edition). Metaphysics
    Research Lab, Stanford University.

    - Dvoˇr´ak, W., Rapberger, A., Wallner, J. P., & Woltran, S. (2020). Aspartix-v19-an
    answer-set programming based system for abstract argumentation. In International
    Symposium on Foundations of Information and Knowledge Systems, pp. 79–89. Springer.

    - Dvor´ak, W., K¨onig, M., Wallner, J. P., & Woltran, S. (2021). ASPARTIX-V21..
    http: //argumentationcompetition.org/2021/downloads/aspartix-v21.pdf.

    - Egly, U., Gaggl, S. A., & Woltran, S. (2008). Aspartix: Implementing argumentation
    frameworks using answer-set programming. In International Conference on Logic
    Programming, pp. 734–738. Springer.

    - Essers, K., Chapman, M., Kokciyan, N., Sassoon, I., Porat, T., Balatsoukas,
    P., Young, P., Ashworth, M., Curcin, V., Modgil, S., et al. (2018). The CONSULT
    system. In Proceedings of the 6th International Conference on Human-Agent Interaction,
    pp. 385–386.

    - Fazzinga, B., Flesca, S., & Furfaro, F. (2018). Probabilistic bipolar abstract
    argumentation frameworks: complexity results. In Proceedings of the Twenty-Seventh
    International Joint Conference on Artificial Intelligence, IJCAI-18, pp. 1803–1809.
    International Joint Conferences on Artificial Intelligence Organization.

    - Fazzinga, B., Galassi, A., & Torroni, P. (2021). An argumentative dialogue system
    for covid-19 vaccine information. In International Conference on Logic and Argumentation,
    pp. 477–485. Springer.

    - Fazzinga, B., Galassi, A., & Torroni, P. (2022). A privacy-preserving dialogue
    system based on argumentation. Intelligent Systems with Applications, 16, 200113.

    - Fichte, J. K., Hecher, M., Gorczyca, P., & Dewoprabowo, R. (2021). A-folio DPDB
    system description for ICCMA 2021.. http://argumentationcompetition.org/2021/
    downloads/a-folio-dpdb.pdf.

    - Fox, J., Glasspool, D., Grecu, D., Modgil, S., South, M., & Patkar, V. (2007).
    Argumentation-based inference and decision making–a medical perspective. IEEE
    intelligent systems, 22 (6), 34–41.

    - Frieder, S., Pinchetti, L., Griffiths, R.-R., Salvatori, T., Lukasiewicz, T.,
    Petersen, P. C., Chevalier, A., & Berner, J. (2023). Mathematical capabilities
    of chatgpt. arXiv preprint arXiv:2301.13867.

    - Gabbay, D. M. (2016). Logical foundations for bipolar and tripolar argumentation
    networks: preliminary results. Journal of Logic and Computation, 26 (1), 247–292.

    - Galitsky, B. (2018). Enabling chatbots by detecting and supporting argumentation..
    https: //patents.google.com/patent/US10679011B2/en.

    - Galitsky, B. (2019). Enabling chatbots by detecting and supporting affective
    argumentation.. https://patents.google.com/patent/US20190138595A1/en.

    - Galitsky, B. (2020). Enabling chatbots by validating argumentation.. https://patents.
    google.com/patent/US10817670B2/en.

    - Gartner, D., & Toni, F. (2007). CaSAPI: a system for credulous and sceptical
    argumentation. Proc. of ArgNMR, 80–95.

    - Girle, R. A. (1996). Commands in dialogue logic. In International Conference
    on Formal and Applied Practical Reasoning, pp. 246–260. Springer.

    - Grando, M. A., Moss, L., Sleeman, D., & Kinsella, J. (2013). Argumentation-logic
    for creating and explaining medical hypotheses. Artificial intelligence in medicine,
    58 (1), 1–13.

    - Guo, K., Wang, J., & Chu, S. K. W. (2022). Using chatbots to scaffold efl students''
    argumentative writing. Assessing Writing, 54, 100666.

    - Habernal, I., & Gurevych, I. (2017). Argumentation mining in user-generated
    web discourse. Computational Linguistics, 43 (1), 125–179.

    - Hadoux, E., & Hunter, A. (2019). Comfort or safety? gathering and using the
    concerns of a participant for better persuasion. Argument & Computation, 10 (2),
    113–147.

    - Hadoux, E., Hunter, A., & Polberg, S. (2021). Strategic argumentation dialogues
    for persuasion: Framework and experiments based on modelling the beliefs and concerns
    of the persuadee. arXiv preprint arXiv:2101.11870.

    - Heater, B. (2018). Alexa gets access to Wolfram Alpha''s knowledge engine..
    https://techcrunch.com/2018/12/20/


    alexa-gets-access-to-wolfram-alphas-knowledge-engine/, (last accessed 29/1/2023).


    - Heinrich, M. (2021). The matrixx solver for argumentation frameworks.. http://
    argumentationcompetition.org/2021/downloads/matrixx.pdf.

    - Hinton, M., & Wagemans, J. H. (2022). How persuasive is ai-generated argumentation?
    an analysis of the quality of an argumentative text produced by the GPT-3 AI text
    generator. Argument & Computation, pp. 1–16.

    - Hulstijn, J. (2000). Dialogue models for inquiry and transaction.. PhD thesis,
    Universiteit Twente, Enschede, The Netherlands.

    - Hung, N. D. (2017). Inference procedures and engine for probabilistic argumentation.
    International Journal of Approximate Reasoning, 90, 163–191.

    - Hunter, A. (2015). Modelling the persuadee in asymmetric argumentation dialogues
    for persuasion. In Twenty-Fourth International Joint Conference on Artificial
    Intelligence.

    - Hunter, A. (2018). Towards a framework for computational persuasion with applications
    in behaviour change. Argument & Computation, 9 (1), 15–40.

    - Hunter, A., Chalaguine, L., Czernuszenko, T., Hadoux, E., & Polberg, S. (2019).
    Towards computational persuasion via natural language argumentation dialogues.
    In Joint German/Austrian Conference on Artificial Intelligence (K¨unstliche Intelligenz),
    pp. 18–33. Springer.

    - IBM (2006). Watson.. https://www.ibm.com/products/watson-assistant (last accessed
    11/10/2022).

    - Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y. J.,
    Madotto, A., & Fung, P. (2023). Survey of hallucination in natural language generation.
    ACM Comput. Surv., 55 (12).

    - Jiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., de
    las Casas, D., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., Lavaud, L.
    R., Lachaux, M.-A., Stock, P., Scao, T. L., Lavril, T., Wang, T., Lacroix, T.,
    & Sayed, W. E. (2023). Mistral 7b..

    - Jiao, W., Wang, W., Huang, J., Wang, X., & Tu, Z. (2023). Is chatgpt a good
    translator? yes with gpt-4 as the engine. arXiv preprint arXiv:2301.08745.

    - Jo, Y., Bang, S., Reed, C., & Hovy, E. (2021). Classifying Argumentative Relations
    Using Logical Mechanisms and Argumentation Schemes. Transactions of the Association
    for Computational Linguistics, 9, 721–739.

    - Kar, R., & Haldar, R. (2016). Applying chatbots to the internet of things: Opportunities
    and architectural elements. International Journal of Advanced Computer Science
    and Applications, 7 (11).

    - Klopfenstein, L. C., Delpriori, S., Malatini, S., & Bogliolo, A. (2017). The
    rise of bots: A survey of conversational interfaces, patterns, and paradigms.
    In Proceedings of the 2017 conference on designing interactive systems, pp. 555–565.

    - K¨okciyan, N., Chapman, M., Balatsoukas, P., Sassoon, I., Essers, K., Ashworth,
    M., Curcin, V., Modgil, S., Parsons, S., & Sklar, E. I. (2019). A collaborative
    decision support tool for managing chronic conditions. In The 17th World Congress
    of Medical and Health Informatics.

    - K¨okciyan, N., Sassoon, I., Sklar, E., Modgil, S., & Parsons, S. (2021). Applying
    metalevel argumentation frameworks to support medical decision making. IEEE Intelligent
    Systems, 36 (2), 64–71.

    - K¨okciyan, N., Sassoon, I., Young, A., Chapman, M., Porat, T., Ashworth, M.,
    Curcin, V., Modgil, S., Parsons, S., & Sklar, E. (2018). Towards an argumentation
    system for supporting patients in self-managing their chronic conditions. In AAAI
    Joint Workshop on Health Intelligence (W3PHIAI).

    - Kosinski, M. (2023). Theory of mind may have spontaneously emerged in large
    language models. arXiv preprint arXiv:2302.02083.

    - Kulatska, I. (2019). Arguebot: Enabling debates through a hybrid retrieval-generation-based
    chatbot. Master''s thesis, University of Twente.

    - Lawrence, J., & Reed, C. (2020). Argument mining: A survey. Computational Linguistics,
    45 (4), 765–818.

    - Li, B., Fang, G., Yang, Y., Wang, Q., Ye, W., Zhao, W., & Zhang, S. (2023).
    Evaluating chatgpt''s information extraction capabilities: An assessment of performance,
    explainability, calibration, and faithfulness. arXiv preprint arXiv:2304.11633.

    - Lin, F., & Shoham, Y. (1989). Argument systems: A uniform basis for nonmonotonic
    reasoning.. KR, 89, 245–255.

    - Lopatovska, I., Rink, K., Knight, I., Raines, K., Cosenza, K., Williams, H.,
    Sorsche, P., Hirsch, D., Li, Q., & Martinez, A. (2019). Talk to me: Exploring
    user interactions with the amazon alexa. Journal of Librarianship and Information
    Science, 51 (4), 984–997.

    - Luck, M., McBurney, P., Shehory, O., & Willmott, S. (2005). Agent technology:
    computing as interaction (a roadmap for agent based computing)..

    - Mahowald, K., Ivanova, A. A., Blank, I. A., Kanwisher, N., Tenenbaum, J. B.,
    & Fedorenko, E. (2023). Dissociating language and thought in large language models:
    a cognitive perspective. arXiv preprint arXiv:2301.06627.

    - Malmqvist, L. (2021). AFGCN: An approximate abstract argumentation solver..
    http: //argumentationcompetition.org/2021/downloads/afgcn.pdf.

    - Marshall, C. (2014). Cortana: everything you need to know about Microsoft''s
    Siri rival.. https://www.techradar.com/news/phone-and-communications/mobile-phones/
    cortana-everything-you-need-to-know-about-microsoft-s-siri-rival-1183607) (last
    accessed 23/08/2023).

    - Mayer, T., Cabrio, E., & Villata, S. (2020). Transformer-based argument mining
    for healthcare applications. In ECAI 2020, pp. 2108–2115. IOS Press.

    - McBurney, P., Hitchcock, D., & Parsons, S. (2007). The eightfold way of deliberation
    dialogue. In International Journal of Intelligent Systems, Vol. 22, pp. 95–132.
    Wiley Online Library.

    - McBurney, P., & Parsons, S. (2001). Chance discovery using dialectical argumentation.
    In Annual Conference of the Japanese Society for Artificial Intelligence, pp.
    414–424. Springer.

    - McBurney, P., & Parsons, S. (2002). Games that agents play: A formal framework
    for dialogues between autonomous agents. Journal of logic, language and information,
    11 (3), 315–334.

    - McBurney, P., & Parsons, S. (2009). Dialogue games for agent argumentation.
    In Argumentation in artificial intelligence, pp. 261–280. Springer.

    - McBurney, P., & Parsons, S. (2013). Talking about doing. From Knowledge Representation
    to Argumentation in AI, Law and Policy Making, 151–166.

    - McBurney, P., Parsons, S., et al. (2021). Argument schemes and dialogue protocols:
    Doug walton''s legacy in artificial intelligence. Journal of Applied Logics, 8
    (1), 263–286.

    - McBurney, P., Van Eijk, R. M., Parsons, S., & Amgoud, L. (2003). A dialogue
    game protocol for agent purchase negotiations. In Autonomous Agents and Multi-Agent
    Systems, Vol. 7, pp. 235–273. Springer.

    - Mercier, H., & Sperber, D. (2011). Why do humans reason? arguments for an argumentative
    theory. Behavioral and brain sciences, 34 (2), 57–74.

    - Microsoft (2014). Cortana.. https://www.microsoft.com/en-us/cortana (last accessed
    11/10/2022).

    - Modgil, S., & Prakken, H. (2013). A general account of argumentation with preferences.
    Artificial Intelligence, 195, 361–397.

    - Murphy, J., Black, E., & Luck, M. M. (2016). A heuristic strategy for persuasion
    dialogues. In Computational Models of Argument: Proceedings of COMMA 2016, pp.
    411–418. IOS Press.

    - Niskanen, A., & J¨arvisalo, M. (2021). µ–toksia at ICCMA''21.. http:// argumentationcompetition.org/2021/downloads/mu-toksia.pdf.

    - OpenAI (2023). Gpt-4 technical report.. arXiv.

    - Patterson, D., Gonzalez, J., H¨olzle, U., Le, Q., Liang, C., Munguia, L.-M.,
    Rothchild, D., So, D. R., Texier, M., & Dean, J. (2022). The carbon footprint
    of machine learning training will plateau, then shrink. Computer, 55 (7), 18–28.

    - Podlaszewski, M., Caminada, M., & Pigozzi, G. (2011). An implementation of basic
    argumentation components. In The 10th International Conference on Autonomous Agents
    and Multiagent Systems-Volume 3, pp. 1307–1308.

    - Pollock, J. L. (1987). Defeasible reasoning. Cognitive science, 11 (4), 481–518.

    - Prakken, H. (2006). Formal systems for persuasion dialogue. In The knowledge
    engineering review, Vol. 21, pp. 163–188. Cambridge University Press.

    - Prakken, H., Bistarelli, S., & Santini, F. (2020). Computational Models of Argument:
    Proceedings of COMMA 2020, Vol. 326. IOS Press.

    - Qin, C., Zhang, A., Zhang, Z., Chen, J., Yasunaga, M., & Yang, D. (2023). Is
    chatgpt a general-purpose natural language processing task solver?. arXiv preprint
    arXiv:2302.06476.

    - Rago, A., Cocarascu, O., Bechlivanidis, C., & Toni, F. (2020). Argumentation
    as a framework for interactive explanations for recommendations. In Proceedings
    of the International Conference on Principles of Knowledge Representation and
    Reasoning, Vol. 17, pp. 805–815.

    - Rago, A., Cocarascu, O., & Toni, F. (2018). Argumentation-based recommendations:
    Fantastic explanations and how to find them. In Proceedings of the Twenty-Seventh
    International Joint Conference on Artificial Intelligence, pp. 1949–1955.

    - Rago, A., Toni, F., Aurisicchio, M., & Baroni, P. (2016). Discontinuity-free
    decision support with quantitative argumentation debates. In Fifteenth International
    Conference on the Principles of Knowledge Representation and Reasoning.

    - Rahwan, I., & Larson, K. (2009). Argumentation and game theory. Argumentation
    in artificial intelligence, 321–339.

    - Rahwan, I., & Simari, G. R. (2009). Argumentation in Artificial Intelligence.
    Springer.

    - Reckwitz, A. (2002). Toward a theory of social practices: A development in culturalist
    theorizing. European journal of social theory, 5 (2), 243–263.

    - Roller, S., Dinan, E., Goyal, N., Ju, D., Williamson, M., Liu, Y., Xu, J., Ott,
    M., Shuster, K., Smith, E. M., et al. (2020). Recipes for building an open-domain
    chatbot. arXiv preprint arXiv:2004.13637.

    - Rosenfeld, A., & Kraus, S. (2016). Strategical argumentative agent for human
    persuasion. In ECAI 2016, pp. 320–328. IOS Press.

    - Ruiz-Dolz, R., Alemany, J., Barbera, S., & Garcia-Fornes, A. (2021). Transformer-based
    models for automatic identification of argument relations: A cross-domain evaluation.
    IEEE Intelligent Systems, 36 (06), 62–70.

    - Saadat-Yazdi, A., Pan, J., & K¨okciyan, N. (2023). Uncovering implicit inferences
    for improved relational argument mining. In Proceedings of the 17th Conference
    of the European Chapter of the Association for Computational Linguistics, pp.
    2476–2487.

    - Sansonnet, J.-P., Leray, D., & Martin, J.-C. (2006). Architecture of a framework
    for generic assisting conversational agents. In International Workshop on Intelligent
    Virtual Agents, pp. 145–156. Springer.

    - Sassoon, I., K¨okciyan, N., Chapman, M., Sklar, E., Curcin, V., Modgil, S.,
    & Parsons, S. (2020). Implementing argument and explanation schemes in dialogue.
    Computational Models of Argument: Proceedings of COMMA 2020, 326, 471.

    - Sassoon, I., K¨okciyan, N., Modgil, S., & Parsons, S. (2021). Argumentation
    schemes for clinical decision support. Argument & Computation, pp. 1–27.

    - Sassoon, I., K¨okciyan, N., Sklar, E., & Parsons, S. (2019). Explainable argumentation
    for wellness consultation. In International Workshop on Explainable, Transparent
    Autonomous Agents and Multi-Agent Systems, pp. 186–202. Springer.

    - Schaeffer, R., Miranda, B., & Koyejo, S. (2023). Are emergent abilities of large
    language models a mirage?. arXiv preprint arXiv:2304.15004.

    - Searle, J. R. (1980). Minds, brains, and programs. Behavioral and brain sciences,
    3 (3), 417–424.

    - Shove, E., Pantzar, M., & Watson, M. (2012). The Dynamics of Social Practice:
    Everyday Life and how it Changes. SAGE.

    - Silver, D., & Veness, J. (2010). Monte-carlo planning in large pomdps. Advances
    in neural information processing systems, 23.

    - Singh, S., & Thakur, H. K. (2020). Survey of various AI Chatbots based on technology
    used. In 2020 8th International Conference on Reliability, Infocom Technologies
    and Optimization (Trends and Future Directions)(ICRITO), pp. 1074–1079. IEEE.

    - Sklar, E., & Parsons, S. (2004). Towards the application of argumentation-based
    dialogues for education. In Autonomous Agents and Multiagent Systems, International
    Joint Conference on, Vol. 4, pp. 1420–1421. IEEE Computer Society.

    - Sklar, E. I., & Azhar, M. Q. (2015). Argumentation-based dialogue games for
    shared control in human-robot systems. Journal of Human-Robot Interaction, 4 (3),
    120–148.

    - Sklar, E. I., & Azhar, M. Q. (2018). Explanation through argumentation. In Proceedings
    of the 6th International Conference on Human-Agent Interaction, pp. 277–285.

    - Slonim, N., Bilu, Y., Alzate, C., Bar-Haim, R., Bogin, B., Bonin, F., Choshen,
    L., Cohen-Karlik, E., Dankin, L., Edelstein, L., et al. (2021). An autonomous
    debating system. Nature, 591 (7850), 379–384.

    - Sojasingarayar, A. (2020). Seq2seq ai chatbot with attention mechanism. arXiv
    preprint arXiv:2006.02767.

    - Tang, Y., Sklar, E., & Parsons, S. (2012). An argumentation engine: Argtrust.
    In Ninth International Workshop on Argumentation in Multiagent Systems.

    - Thimm, M. (2021). Harper+: Using grounded semantics for approximate reasoning
    in abstract argumentation.. http://argumentationcompetition.org/2021/downloads/
    harper++.pdf.

    - Thimm, M., Cerutti, F., & Vallati, M. (2021). FUDGE: A light-weight solver for
    abstract argumentation based on sat reductions.. http://argumentationcompetition.org/
    2021/downloads/fudge.pdf.

    - Thorp, H. H. (2023). Chatgpt is fun, but not an author. Science, 379 (6630),
    313–313.

    - Tolchinsky, P., Modgil, S., Atkinson, K., McBurney, P., & Cort´es, U. (2012).
    Deliberation dialogues for reasoning about safety critical actions. Autonomous
    Agents and Multi-Agent Systems, 25 (2), 209–259.

    - Toni, F. (2014). A tutorial on assumption-based argumentation. Argument & Computation,
    5 (1), 89–117.

    - Toniuc, D., & Groza, A. (2017). Climebot: An argumentative agent for climate
    change. In 2017 13th IEEE International Conference on Intelligent Computer Communication
    and Processing (ICCP), pp. 63–70. IEEE.

    - Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,
    T., Rozi`ere, B., Goyal, N., Hambro, E., Azhar, F., et al. (2023a). Llama: Open
    and efficient foundation language models. arXiv preprint arXiv:2302.13971.

    - Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov,
    N., Batra, S., Bhargava, P., Bhosale, S., et al. (2023b). Llama 2: Open foundation
    and fine-tuned chat models. arXiv preprint arXiv:2307.09288.

    - Trautmann, D., Daxenberger, J., Stab, C., Sch¨utze, H., & Gurevych, I. (2020).
    Fine-grained argument unit recognition and classification. In Proceedings of the
    AAAI Conference on Artificial Intelligence, Vol. 34, pp. 9048–9056.

    - Tunstall, L., Beeching, E., Lambert, N., Rajani, N., Rasul, K., Belkada, Y.,
    Huang, S., von Werra, L., Fourrier, C., Habib, N., Sarrazin, N., Sanseviero, O.,
    Rush, A. M., & Wolf, T. (2023). Zephyr: Direct distillation of lm alignment..

    - Turing, A. M., & Haugeland, J. (1950). Computing machinery and intelligence.
    The Turing Test: Verbal Behavior as the Hallmark of Intelligence, 29–56.

    - Vassiliades, A., Bassiliades, N., & Patkos, T. (2021). Argumentation and explainable
    artificial intelligence: a survey. The Knowledge Engineering Review, 36.

    - Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
    Kaiser, L., & Polosukhin, I. (2017). Attention is all you need. Advances in neural
    information processing systems, 30.

    - Visser, J., Lawrence, J., Wagemans, J., & Reed, C. (2018). Revisiting computational
    models of argument schemes: Classification, annotation, comparison. In 7th International
    Conference on Computational Models of Argument, COMMA 2018, pp. 313–324. ios Press.

    - Vreeswijk, G. (1994). IACAS: An interactive argumentation system. Rapport technique
    CS, 94 (03).

    - Wagemans, J. (2016). Constructing a periodic table of arguments. In Argumentation,
    objectivity, and bias: Proceedings of the 11th international conference of the
    Ontario Society for the Study of Argumentation (OSSA), Windsor, ON: OSSA, pp.
    1–12.

    - Wallace, R. (2003). The elements of AIML style. Alice AI Foundation, 139.

    - Wallace, R. S. (2009). The anatomy of A.L.I.C.E.. In Parsing the turing test,
    pp. 181–210. Springer.

    - Waller, M. (2023). An argumentation-based approach to bias detection in automated
    decision-making systems. In Online Handbook of Argumentation for AI, Vol. 4.

    - Walton, D. (2012). Argument mining by applying argumentation schemes. Studies
    in Logic, 4 (1), 2011.

    - Walton, D., & Krabbe, E. C. (1995). Commitment in dialogue: Basic concepts of
    interpersonal reasoning. SUNY press.

    - Walton, D., & Macagno, F. (2015). A classification system for argumentation
    schemes. Argument & Computation, 6 (3), 219–245.

    - Walton, D., Reed, C., & Macagno, F. (2008). Argumentation schemes. Cambridge
    University Press.

    - Walton, D. N. (1990). What is reasoning? What is an argument?. The journal of
    Philosophy, 87 (8), 399–419.

    - Wambsganss, T., Guggisberg, S., & S¨ollner, M. (2021). Arguebot: A conversational
    agent for adaptive argumentation feedback. In Innovation Through Information Systems:
    Volume II: A Collection of Latest Research on Technology Issues, pp. 267–282.
    Springer.

    - Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama,
    D., Bosma, M., Zhou, D., Metzler, D., et al. (2022a). Emergent abilities of large
    language models. arXiv preprint arXiv:2206.07682.

    - Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou,
    D., et al. (2022b). Chain-of-thought prompting elicits reasoning in large language
    models. Advances in Neural Information Processing Systems, 35, 24824–24837.

    - Weizenbaum, J. (1966). ELIZA-a computer program for the study of natural language
    communication between man and machine. Communications of the ACM, 9 (1), 36– 45.

    - Worswick, S. (2013). Interview Loebner 2013 winner.. https://aidreams.co.uk/
    forum/index.php?page=Steve\_Worswick\_Interview\_-\_Loebner\_2013\_winner# .Y0IfoHZBxPY
    (last accessed 11/10/2022).

    - Worswick, S. (2018). Mitsuku wins Loebner Prize 2018!.. https://medium.com/
    pandorabots-blog/mitsuku-wins-loebner-prize-2018-3e8d98c5f2a7 (last accessed 18/06/2023).

    - Xu, J., Ju, D., Lane, J., Komeili, M., Smith, E. M., Ung, M., Behrooz, M., Ngan,
    W., Moritz, R., Sukhbaatar, S., Boureau, Y.-L., Weston, J., & Shuster, K. (2023).
    Improving open language models by learning from organic interactions..

    - Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y., & Narasimhan,
    K. (2023). Tree of thoughts: Deliberate problem solving with large language models.
    arXiv preprint arXiv:2305.10601.

    - Zhang, Y., Sun, S., Galley, M., Chen, Y.-C., Brockett, C., Gao, X., Gao, J.,
    Liu, J., & Dolan, B. (2019). Dialogpt: Large-scale generative pre-training for
    conversational response generation. arXiv preprint arXiv:1911.00536.

    - Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang,
    B., Zhang, J., Dong, Z., et al. (2023). A survey of large language models. arXiv
    preprint arXiv:2303.18223.

    - Zhou, L., Gao, J., Li, D., & Shum, H.-Y. (2020). The Design and Implementation
    of XiaoIce, an Empathetic Social Chatbot. Computational Linguistics, 46 (1), 53–93.'
- id: a_universal_knowledge_model_and_cognitive_architecture_for_prototyping_agi_a_universal_knowledge_model_and_cognitive_architecture_for_prototyping_agi
  title: "A Universal Knowledge Model and Cognitive Architecture for Prototyping\n\
    \  AGI"
  abstract: 'The article identified 42 cognitive architectures for creating general

    artificial intelligence (AGI) and proposed a set of interrelated functional

    blocks that an agent approaching AGI in its capabilities should possess. Since

    the required set of blocks is not found in any of the existing architectures,

    the article proposes a new cognitive architecture for intelligent systems

    approaching AGI in their capabilities. As one of the key solutions within the

    framework of the architecture, a universal method of knowledge representation

    is proposed, which allows combining various non-formalized, partially and fully

    formalized methods of knowledge representation in a single knowledge base, such

    as texts in natural languages, images, audio and video recordings, graphs,

    algorithms, databases, neural networks, knowledge graphs, ontologies, frames,

    essence-property-relation models, production systems, predicate calculus

    models, conceptual models, and others. To combine and structure various

    fragments of knowledge, archigraph models are used, constructed as a

    development of annotated metagraphs. As components, the cognitive architecture

    being developed includes machine consciousness, machine subconsciousness,

    blocks of interaction with the external environment, a goal management block,

    an emotional control system, a block of social interaction, a block of

    reflection, an ethics block and a worldview block, a learning block, a

    monitoring block, blocks of statement and solving problems, self-organization

    and meta learning block.'
  url: http://arxiv.org/abs/2401.06256v3
  keywords: ''
  document: "# **A Universal Knowledge Model and Cognitive Architecture for Prototyping\
    \ AGI**\n\nArtem Sukhobokov1[0000-0002-1370-6905] , Evgeny Belousov2[0009-0002-5335-9167]\
    \ , Danila Gromozdov2[0009-0007-2342-6046] , Anna Zenger3[0009-0007-9909-755X]\
    \ , and Ilya Popov2\\*[0009-0007-2226-9640]\n\n SAP America, Inc. 3999 West Chester\
    \ Pike, Newtown Square, PA 19073, USA Bauman Moscow State Technical University,\
    \ 2-nd Baumanskaya 5, Moscow 105005, Russian Federation OZON Marketplace Kazakhstan\
    \ LLP, Al-Farabi avenue 77/7, Bostandyk district, Almaty\n\n050040, Kazakhstan\n\
    \nlink.s.twink@gmail.com\n\n**Abstract.** The article identified 42 cognitive\
    \ architectures for creating general artificial intelligence (AGI) and proposed\
    \ a set of interrelated functional blocks that an agent approaching AGI in its\
    \ capabilities should possess. Since the required set of blocks is not found in\
    \ any of the existing architectures, the article proposes a new cognitive architecture\
    \ for intelligent systems approaching AGI in their capabilities. As one of the\
    \ key solutions within the framework of the architecture, a universal method of\
    \ knowledge representation is proposed, which allows combining various non-formalized,\
    \ partially and fully formalized methods of knowledge representation in a single\
    \ knowledge base, such as texts in natural languages, images, audio and video\
    \ recordings, graphs, algorithms, databases, neural networks, knowledge graphs,\
    \ ontologies, frames, essence-property-relation models, production systems, predicate\
    \ calculus models, conceptual models, and others. To combine and structure various\
    \ fragments of knowledge, archigraph models are used, constructed as a development\
    \ of annotated metagraphs. As components, the cognitive architecture being developed\
    \ includes machine consciousness, machine subconsciousness, blocks of interaction\
    \ with the external environment, a goal management block, an emotional control\
    \ system, a block of social interaction, a block of reflection, an ethics block\
    \ and a worldview block, a learning block, a monitoring block, blocks of statement\
    \ and solving problems, self-organization and meta learning block.\n\n**Keywords:**\
    \ Cognitive architecture, AGI, Metagraph, Archigraph, Universal knowledge model,\
    \ Machine consciousness, Machine subconsciousness, Machine reflection, Machine\
    \ worldview.\n\n## **1 Introduction**\n\nIn recent years, there has been a rapid\
    \ and multidirectional development of intelligent information systems developed\
    \ by people [1]. In [2], it was assumed that a relatively distant extrapolation\
    \ of the functionality of these developments would be the creation of a general\
    \ artificial intelligence comparable to human intelligence (in current terminology\
    \ – AGI). The main capabilities of an intelligent information system, such as\
    \ perceptual abilities, attention mechanisms, choice of actions, learning, memory,\
    \ reasoning and their practical application are determined by the cognitive architecture\
    \ used in the system [3]. If we consider the basic principles of functioning,\
    \ then cognitive architectures are the opposite of expert systems. Expert systems\
    \ provide solutions to intellectual tasks in a narrowly defined context, in the\
    \ segment of activity for which they have knowledge, in contrast, cognitive architectures\
    \ aim to providing a wide coverage, solving a diverse set of tasks in different\
    \ fields. More importantly, cognitive architectures provide intelligent behavior\
    \ at the system level, rather than at the level of methods of individual components\
    \ designed to solve specialized tasks [3].\n\nIn 2016-18, after a relatively long\
    \ break, two reviews of cognitive architectures were published [4, 5] (the third\
    \ version of the publication [4], like the publication [5], appeared in 1918).\
    \ After that, no systematic reviews were published until preparation of this article.\
    \ Only brief reviews were published as part of the justification for the need\
    \ to develop new architectures. In these two reviews, which cover about 140 architectures,\
    \ we identified cognitive architectures designed to create AGI, and supplemented\
    \ the list with the results of a bibliographic search.\n\nUnlike the reviews in\
    \ [6,7], the authors of which considered cognitive architectures for creating\
    \ AGI, including architectures that were not intended for this purpose in the\
    \ review, we consider it important to analyze precisely cognitive architectures\
    \ that are declared as architectures intended for creating AGI, since additional\
    \ requirements are imposed on them [8]. Other cognitive architectures could be\
    \ developed to test some technical solutions or to solve more utilitarian tasks,\
    \ for example, for image processing or controlling a transport robot transporting\
    \ workpieces in the workshop.\n\nIn the list of cognitive architectures, if the\
    \ architecture does not have a name, it will be presented simply with a link to\
    \ the publication. The final list of cognitive architectures for analysis includes\
    \ 42 architectures, presented in Table 1. For each architecture, this table contains\
    \ citations indicating that the architecture is intended to enable AGI. For some\
    \ architectures, publications do not explicitly mention AGI as a target. In these\
    \ cases, the decision to include in the list is determined by the goals of the\
    \ architecture to model human-like behavior or by focusing on the complex of functions\
    \ inherent with humans.\n\n| # | Name  | Link(s) | Citations about purpose of\
    \ cognitive architecture                                                     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                              |\n|---|-------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | 1 | Soar  | [9]     | Soar … have used … to build complex integrated AI agents,\
    \ and to create<br>detailed models of human behavior. … We have found that combining\
    \ what<br>is known in psychology, in neuroscience, and in AI is an effective approach<br>to\
    \ building a comprehensive cognitive architecture. … Our bet is that achiev<br>ing\
    \ human-level intelligence is a long path of incremental experiments, dis<br>coveries,\
    \ tests, reformulations and refinements. |\n| 2 | ACT-R | [10]    | This paper\
    \ explores requirements on cognitive architectures for artificial gen<br>eral\
    \ intelligence. The goal of the analysis is to determine the requirements for<br>cognitive\
    \ architectures that support the full-range of human-level intelligent<br>behavior.\
    \                                                                            \
    \                                                                            \
    \                           |\n\n**Table 1.** Cognitive architectures aimed to\
    \ create AGI, and author citations confirming this.\n\n| 3  | NARS           \
    \                       | [11]    | … system aimed at the realization of Artificial\
    \ General Intelligence (AGI).                                                \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                        |\n|----|---------------------------------------|---------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | 4  | LIDA                                  | [12]    | … we  argue that Learning\
    \ Intelligent Distribution Agent (LIDA) … may<br>be suitable as an underlying\
    \ cognitive architecture on which others might<br>build an AGI.              \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                              |\n| 5  | Haikonen<br>cognitive<br>architecture\
    \ | [13]    | The author visions autonomous robots that perceive and understand\
    \ the world<br>and act in it in a natural way, without programs and numerical\
    \ representation<br>of information. This approach considers the cognitive machine\
    \ as a system<br>that is seamlessly interactive, both internally and externally,\
    \ in respect to its<br>environment and experience. This approach should result\
    \ in robots that know<br>and understand what they are doing and why, robots that\
    \ can plan and imagine<br>their actions and the possible outcome of these. Robots\
    \ that exhibit properties<br>like these are said to possess machine consciousness,\
    \ which may or may not<br>have common deeper properties with animal and human\
    \ consciousness.                                                             \
    \                                                              |\n| 6  | SiMA<br>(previously<br>ARS)\
    \           | [14]    | … most of humans' behaviour is covered by every-day capabilities.\
    \ … our<br>experience with the cognitive architecture SiMA showed that – especially<br>when\
    \ the foundations of the human mind are at stake – every-day behaviour<br>is more\
    \ suitable to analyse the basic functions of the human mind.                 \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                |\n| 7  | Sigma\
    \                                 | [15]    | We … expect that a system capable\
    \ of artificial general intelligence (AGI)<br>would provide natural support for\
    \ Theory of Mind. We are interested here in<br>how Theory of Mind capabilities\
    \ may be realized within Sigma (Σ), a nascent<br>cognitive system—an integrated\
    \ computational model of intelligent behav<br>ior— that is grounded in a cognitive\
    \ architecture, a model of the fixed struc<br>ture underlying a cognitive system.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                        |\n| 8  |                                       | [16]\
    \    | The platform used as an specific domain for the initial experiments is\
    \ the iCub<br>humanoid robot simulator, but the architecture is built so it can\
    \ be applied to<br>different platforms and applications. This platform was chosen\
    \ because it pro<br>vides a \"Human-Like\" architectural level …             \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                         |\n\
    | 9  | CogPrime                              | [17,18] | Part 1 of the book …\
    \ sketches the broad outlines of a novel, integrative archi<br>tecture for Artificial\
    \ General Intelligence (AGI) called CogPrime …<br>Part 2 of the book concludes\
    \ with a chapter summarizing the argument that<br>CogPrime can lead to human-level\
    \ (and eventually perhaps greater) AGI …                                     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                     |\n|    | 10 Ikon Flux                 \
    \         | [19,20] | Ikon Flux is a fully implemented prototypical architecture\
    \ for self-program<br>ming systems - a prototype being an abstract type to be\
    \ instantiated in a con<br>crete domain. … A system continuously modeling its\
    \ own operation has to do<br>so at multiple levels of abstraction, from the program\
    \ rewriting up to the level<br>of global processes (e.g. the utility function),\
    \ thus turning eventually into a<br>fully self-modeling system. ,,, We believe\
    \ peewee granularity is a promising<br>way to simplify operational semantics and\
    \ reach a computational homogene<br>ity that can enable automated architectural\
    \ growth – which in itself is a nec<br>essary step towards scaling of cognitive\
    \ skills exhibited by current state-of<br>the-art architectures. Only this way\
    \ will we move more quickly towards arti<br>ficial general intelligence. |\n|\
    \ 11 | eBICA                                 | [21,22] | This work continues the\
    \ effort to design and test the cognitive architecture<br>eBICA: a general model\
    \ of emotionally biased behavior control and decision<br>making, with the focus\
    \ on social emotional relationships. … We also pre<br>sented the study of an implemented\
    \ Virtual Actor based on the eBICA model.<br>… The overall conclusion is that\
    \ the implemented Virtual Actor performs at<br>a human level.                \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                |\n| 12 | D-LANCA                           \
    \    | [7]     | This work suggests a novel approach to autonomous systems development<br>linking\
    \ autonomous technology to an integrated cognitive architecture with<br>the aim\
    \ of supporting a common artificial general intelligence (AGI) devel<br>opment.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                               |\n| 13 | ICOM\
    \                                  | [23]    | This paper articulates the methodology\
    \ and reasoning for how biasing in the<br>Independent Core Observer Model (ICOM)\
    \ Cognitive Architecture for Arti<br>ficial General Intelligence (AGI) is done.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                            |\n\n| 14 |          | [24]    | We consider a task-oriented\
    \ approach to AGI, when any cognitive problem,<br>perhaps superior to human ability,\
    \ has sense given a criterion of its solution.                               \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                             |\n|----|----------|---------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | 15 | LIS      | [25]    | … the LIS Framework … provides a way to approach AGI\
    \ learning in a flex<br>ible and easy-to-use manner by combining multiple, interchangeable\
    \ compo<br>nents. The framework allows AGI workers including beginners to combine<br>pre-installed\
    \ LIS Framework components and begin AGI development with<br>ease.           \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                     |\n| 16 |          | [26]\
    \    | This paper is concerned with artificial general intelligence (AGI). Our\
    \ ulti<br>mate goal is to create a computational model that may operate in any\
    \ environ<br>ment and develop intelligence adapted to that environment in a fully\
    \ auto<br>matic fashion.                                                     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                               |\n| 17 | MBCA\
    \     | [27]    | The biologically inspired Meaningful-Based Cognitive Architecture\
    \ (MBCA)<br>integrates the sensory processing abilities found in neural networks\
    \ with many<br>of the symbolic logical abilities found in human cognition. … MBCA\
    \ can<br>functionally produce a variety of behaviors which can help to better\
    \ hypothe<br>size and understand mammalian cortical function, and provide insight\
    \ into<br>possible mechanisms which link such mesoscopic functioning to the causal<br>and\
    \ symbolic behavior seen in humans.                                          \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                   |\n| 18 |          | [28]\
    \    | We introduce an AGI, in the form of cognitive architecture, which is based\
    \ on<br>Global Workspace Theory (GWT).                                       \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                 |\n| 19 | PySigma\
    \  | [29]    | The Sigma cognitive architecture is the beginning of an integrated\
    \ computa<br>tional model of intelligent behavior aimed at the grand goal of artificial\
    \ gen<br>eral intelligence (AGI). However, whereas it has been proven to be capable<br>of\
    \ modeling a wide range of intelligent behaviors, the existing implementation<br>of\
    \ Sigma has suffered from several significant limitations.  In this article,<br>we\
    \ propose solutions for this limitation  The resulting design changes con<br>verge\
    \ on a more capable version of the architecture called PySigma.              \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                   |\n| 20 |          | [30]    | In general,\
    \ neuromorphic computing and cognitive modeling are two promis<br>ing approaches\
    \ to achieve AGI. … Our motivation is to provide a generic<br>methodology bridging\
    \ the computation theory with the underlying implemen<br>tation at the algorithm\
    \ level.                                                                     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                         |\n| 21 | GLAIR    | [31]    | GLAIR\
    \ (Grounded Layered Architecture with Integrated Reasoning) is a mul<br>tilayered\
    \ cognitive architecture for embodied agents operating in real, virtual,<br>or\
    \ simulated environments containing other agents. … The motivation for the<br>development\
    \ of GLAIR has been \"Computational Philosophy\", the computa<br>tional understanding\
    \ and implementation of human-level intelligent behavior<br>without necessarily\
    \ being bound by the actual implementation of the human<br>mind.             \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                 |\n| 22 |          | [32,33] | I'll be using\
    \ the term my cognitive system, cognitive architecture, artificial<br>general\
    \ intelligence, and AGI interchangeably.                                     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                  |\n| 23 | H-CogAff | [34] \
    \   | H-CogAff, a special case of CogAff, is postulated as a minimal architecture<br>specification\
    \ for a human-like system.                                                   \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                               |\n| 24 |          | [35]    |\
    \ Our approach is to use a functional core to simulate the development of cog<br>nitive\
    \ functions of autonomous agents. … The most important goal in the field<br>of\
    \ AGI is the development of control systems for cognitive agents, which, in<br>terms\
    \ of their intellectual performance, are not inferior, and perhaps even sur<br>pass\
    \ humans. Developmental psychology studies show that the most signifi<br>cant\
    \ changes in Innenwelt occur at the sensorimotor stage, which is the first<br>in\
    \ the postnatal ontogenesis. … . According to Piaget, this period of develop<br>ment\
    \ is one of the most important in the creation of human mental abilities.<br>The\
    \ proposed architecture makes it possible to simulate the process of evolu<br>tion\
    \ of cognitive abilities, including the stage of sensorimotor development of<br>autonomous\
    \ agents. |\n| 25 | EM-ONE   | [36]    | The design of EM-ONE draws heavily on\
    \ Minsky's Emotion Machine archi<br>tecture hence the name EM-ONE … I have also\
    \ drawn ideas from Sloman's                                                  \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                        |\n\n|    |           |      | H-CogAff architecture,\
    \ which resembles Minsky's architecture in many re<br>spects … Both Minsky and\
    \ Sloman developed their architectures to provide<br>rich frameworks with which\
    \ to explain the diversity of complex and subtle<br>aspects of human cognition,\
    \ especially our capacity for common sense and<br>our variety of emotions. … My\
    \ goal with EM-ONE is primarily to support<br>more intricate forms of reflective\
    \ commonsense thinking, although in the long<br>run I hope it will help to explain\
    \ a broader array of types of thinking including<br>such feelings as love, confusion,\
    \ anger, and hope.                                                           \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                          |\n\
    |----|-----------|------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | 26 |           | [37] | The article describes the author's proposal on cognitive\
    \ architecture for the<br>development of a general-level artificial intelligent\
    \ agent («strong» artificial<br>intelligence).                               \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                             |\n| 27 | CAMAL\
    \     | [38] | With the distributed model specific agents can change The distributed\
    \ agent<br>requests those elements of itself (i.e. its component agents) that\
    \ are associated<br>with the current learning task to modify themselves.  Currently\
    \ we are look<br>ing at the nature of communication between agents with shared\
    \ motivations<br>and are using distributed blackboards.  We have designed and\
    \ implemented<br>agents that display motivational qualities and address important\
    \ questions<br>about the nature of emotion and autonomy.  We have demonstrated\
    \ emotive<br>qualities in our research agents.  compromises can lead to the design\
    \ of<br>agent systems with inherent conflicts.  By designing agents with the quali<br>ties\
    \ described in this chapter an agent is given the means to represent and<br>reason\
    \ about these conflicts when they do arise. This research continues to<br>raises\
    \ questions about what agent is, what a mind is, and what are emotion<br>and motivation.\
    \ |\n| 28 | SMCA      | [39] | Artificial Intelligence originated with the desire\
    \ to develop artificial minds<br>capable of performing or behaving like an animal\
    \ or person.  Cognitive ar<br>chitectures are designed to be capable of performing\
    \ certain behaviours and<br>functions based on our understanding of human and\
    \ non human minds.  de<br>veloping SMCA (Society of Mind Cognitive Architecture)\
    \ can be viewed<br>from the perspective of Minsky, which leads to the development\
    \ of many dif<br>ferent types of simple agents, with different behaviours. Metacognition\
    \ is use<br>ful for framing the constraints for this swarm intelligence. Swarm\
    \ intelligence<br>requires the inclusion of a mathematical theory of how the group\
    \ of agents<br>work together to achieve a common goal. Swarm intelligence uses\
    \ different<br>mathematical algorithms so as to cover all processing and functioning\
    \ associ<br>ated with the adopted architecture or mind model.                \
    \                            |\n| 29 | MicroPSI  | [40] | This book is completely\
    \ dedicated to understanding the functional workings<br>of intelligence and the\
    \ mechanisms that underlie human behavior by creating<br>a new cognitive architecture.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \         |\n| 30 | LISA      | [41] | Human mental representations are both flexible\
    \ and structured – properties<br>that, together, present challenging design requirements\
    \ for a model of human<br>thinking. The Learning and Inference with Schemas and\
    \ Analogies (LISA)<br>model of analogical reasoning aims to achieve these properties\
    \ within a neural<br>network.                                                \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                     |\n| 31 | CIT       | [42]\
    \ | The paper proposes a novel cognitive architecture that combines cognitive<br>computing\
    \ and cognitive agent technologies for performing human-like func<br>tionality.\
    \ The system architecture is known as CIT (Cognitive Information<br>Technology).\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                            |\n| 32 | Companion | [43] | The Companion cognitive\
    \ architecture is aimed at reaching human-level AI<br>by creating software social\
    \ organisms – systems that interact with people us<br>ing natural modalities,\
    \ working and learning over extended periods of time as<br>collaborators rather\
    \ than tools.                                                                \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \              |\n| 33 |           | [44] | The paper proposes a novel cognitive\
    \ architecture for computational creativ<br>ity based on the Psi model and on\
    \ the mechanisms inspired by dual process<br>theories of reasoning and rationality.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \ |\n\n| 34 | Polyscheme [45] |      | This thesis describes a new framework for\
    \ understanding and creating human<br>level intelligence by integrating multiple\
    \ representation and inference<br>schemes.                                   \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \  |\n|----|-----------------|------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | 35 |                 | [46] | We present a three level Cognitive architecture\
    \ for the simulation of human<br>behaviour based on Stanovich's tripartite framework.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                   |\n| 36 |\
    \ Clarion         | [47] | The goal of this work is to develop a unified framework\
    \ for understanding the<br>human mind, and within the unified framework to develop\
    \ process-based,<br>mechanistic explanations of a substantial variety of psychological\
    \ phenom<br>ena.                                                             \
    \                                                                            \
    \                                                                            \
    \                                                     |\n| 37 | Oscar        \
    \   | [48] | The basic observation that motivates the OSCAR architecture is that\
    \ agents<br>of human-level intelligence operating in an environment of real-world\
    \ com<br>plexity (henceforth, GIAs — \"generally intelligent agents\") must be\
    \ able to<br>form beliefs and make decisions against a background of pervasive\
    \ ignorance.                                                                 \
    \                                                                            \
    \                                                   |\n| 38 | OntoAgent      \
    \ | [49] | This paper presents an overview of a cognitive architecture, OntoAgent,\
    \ that<br>supports the creation and deployment of intelligent agents capable of\
    \ simulat<br>ing human-like abilities.                                       \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                 |\n| 39 | INKA            |\
    \ [50] | Artificial intelligence research is now flourishing which aims at achieving<br>general,\
    \ human-level intelligence. Accordingly, cognitive architectures are<br>increasingly\
    \ employed as blueprints for building intelligent agents to be en<br>dowed with\
    \ various perceptive and cognitive abilities. This paper presents a<br>novel integrated\
    \ neuro-cognitive architecture (INCA) which emulate the pu<br>tative functional\
    \ aspects of various salient brain sub-systems via a learning<br>memory modeling\
    \ approach. |\n| 40 | ISAAC           | [51] | A foundational component of an\
    \ ISAAC processing framework is the concept<br>of \"mixture of experts\" architecture\
    \ and methodology, similar to a human<br>brain.                              \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \          |\n| 41 |                 | [52] | This article provides an analytical\
    \ framework for how to simulate human-like<br>thought processes within a computer.\
    \  Iterative updating is conceptualized<br>here as an information processing strategy,\
    \ a model of working memory, a<br>theory of consciousness, and an algorithm for\
    \ designing and programming<br>artificial general intelligence.              \
    \                                                                            \
    \                                                                       |\n| 42\
    \ | Aigo            | [53] | Here we outline an architecture and development plan,\
    \ together with some<br>preliminary results, that offers a much more direct path\
    \ to full Human-Level<br>AI (HLAI) / AGI.                                    \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                  |\n\nWhen analyzing\
    \ the architectures, the following functional components were identified:\n\n\
    - Consciousness for agent management in real time;\n- Subconscious mind for performing\
    \ routine operations;\n- Goal management;\n- Emotional management;\n- Formation\
    \ and application of ethical assessments;\n- Monitoring;\n- Training;\n- Social\
    \ interaction;\n- Reflection;\n- Setting tasks;\n- Problem solving;\n- Self-development\
    \ and meta-learning;\n- Formation and use of a worldview;\n- Multimodal receipt\
    \ of information from the external environment;\n- Multimodal delivery of information\
    \ to the external environment;\n- Control of movement organs and manipulators.\n\
    \nThe listed set of functions is an extension of the set used in [53], however,\
    \ such an extension is justified, since a deeper understanding of many aspects\
    \ has emerged over the past time. If we really want to see artificial intelligence\
    \ comparable to human intelligence, all these functions are necessary for it.\
    \ As ten years ago, in a study by Alexey Samsonovich [54], all existing cognitive\
    \ architectures were acclaimed as limited, we could not find more than 60% of\
    \ the necessary functions anywhere. This served as a prerequisite for the development\
    \ of a new cognitive architecture, which will have the necessary functionality.\n\
    \nIn 2019, a cognitive architecture was proposed, which is a very general sketch\
    \ of the AGI structure [55], annotated metagraphs were used to represent knowledge\
    \ in the architecture [56]. Later in [57], an approach was proposed on how to\
    \ create intelligent information systems based on this architecture, including\
    \ individual components from the AGI composition. Due to the rapid progress of\
    \ research in areas such as metagraphs, machine ethics, machine emotions, machine\
    \ thinking, there is a need to reconsider this previously developed cognitive\
    \ architecture. The need to develop a new cognitive architecture was the reason\
    \ to reflect all the necessary functionality in the second version of this architecture.\n\
    \n### **2 Material and Methods**\n\nDuring the work, materials from several hundred\
    \ scientific publications were used, the most significant of which are listed\
    \ in the list of references. We often discussed which of several publications\
    \ on the same topic to indicate in the link, and tried to bring the one that most\
    \ fully reflects the information or more clearly sets out the material. Two publications\
    \ in the same link were listed together under different numbers if they significantly\
    \ complement each other.\n\nAnother important source of materials for the article\
    \ was our own activities. After all, we are designing AGI, and it should be able\
    \ to do a lot of things that a human can. Therefore, we analyzed our daily actions\
    \ and listened to ourselves sensitively, trying to understand how we work with\
    \ knowledge, and what functional components should be present as part of the cognitive\
    \ architecture of AGI.\n\n### **3 Results**\n\nIn the process of the research,\
    \ a preliminary design of a knowledge base has been developed that will be able\
    \ to operate with any forms of knowledge representation. Using it, a preliminary\
    \ design of a cognitive architecture has been developed, based on which AGI prototypes\
    \ can be created.\n\n### **3.1 The Universal Knowledge Model**\n\n#### **3.1.1\
    \ Archigraph as the Foundation of a Universal Model of Knowledge**\n\nThe basis\
    \ of cognitive architecture is the representation of knowledge. Like a human,\
    \ an agent must be able to work with different forms of knowledge and switch from\
    \ one to another. In [58], a universal data model was proposed that allows storing\
    \ data in a data lake structured according to different data models: relational,\
    \ multidimensional, graph, and others. For this purpose, the metagraph data model\
    \ based on annotated metagraphs has been expanded through the use of protographs\
    \ and archigraphs [59,60]. The annotated metagraph proposed in [61,62], but at\
    \ first did not have such a name, is characterized by the following properties:\n\
    \n- The structure of the metagraph includes, in addition to the usual edges and\
    \ vertices, metaedges and metavertices;\n- Each vertex, edge, metavertex and metaedge\
    \ is characterized by a set of attributes that have a name and value;\n- Metavertices\
    \ and metaedges differ from ordinary edges and vertices in that they can contain\
    \ fragments of a metagraph inside themselves, which by their properties also represent\
    \ metagraphs;\n- The contents of various metavertices and metaedges can overlap\
    \ up to complete equivalence (that is why the term annotated metagraph is used,\
    \ that some meta-objects can annotate others [63]);\n- The boundaries of the metavertices\
    \ and metaedges are permeable to edges and metaedges to any nesting depth.\n\n\
    A protograph can be considered as a graph that has no edges. The role of edges\
    \ is performed by the adjacent vertices to each other. The protograph P is defined\
    \ by the set of elements {pi}, i = 1, n and the neighborhood matrix Mn×n consisting\
    \ of 0 and 1, where 1 means the neighborhood (adjacency) of element a to element\
    \ b. Examples of protographs are: stack, queue, table, figures of the game \"\
    Life\". An example of an infinite protograph is the tape of a Turing machine.\
    \ Ordinary graphs are protographs in which elements are divided into two classes\
    \ of elements and the rule applies that elements of the same class cannot be adjacent.\n\
    \nIn the archigraphs, the elements belong to more than two classes. The number\
    \ of classes into which the elements are divided is the most important characteristic\
    \ of an archigraph. The concept of an archigraph makes it possible to systematize\
    \ various definitions of metagraphs. Annotated metagraphs are archigraphs with\
    \ five classes of elements: vertices, metavertices, edges, metaedges, and attributes.\n\
    \nTo make it convenient to work with knowledge, we propose to expand the annotated\
    \ metagraph model as shown in Fig. 1.\n\n![](_page_8_Figure_0.jpeg)\n\n**Fig.\
    \ 1.** An expansion of annotated metagraph.\n\nThis expansion of capabilities\
    \ will be done through the following steps:\n\n- 1. Add by analogy with pseudographs\
    \ by A. Burdakov [64]:\n- ─ the ability to have edges and metaedges as in hypergraphs,\
    \ which can connect more than 2 objects (can start on several objects and can\
    \ end on several objects);\n- ─ the possibility that an edge or a metaedge can\
    \ start not only from a vertices or a metavertices, but also from another edges\
    \ or a metaedges, and can also end not only with a vertices or a metavertices,\
    \ but also with another edges or a metaedges.\n\nThe term \"pseudograph\" used\
    \ by A. Burdakov to describe the way knowledge is represented is not very successful,\
    \ since there are at least two other interpretations of this term [65], [66].\n\
    \n- 2. Add features for working with implicitly and explicitly defined sets:\n\
    - ─ to provide an opportunity to group vertices, metavertices , edges and metaedges\
    \ into groups with similar ones due to their direct proximity to each other as\
    \ in protographs. For any element of such groups, operations are possible: find\
    \ out the number of elements in the group, get a link to the next member of the\
    \ group;\n- ─ provide an opportunity for any metavertex or metaedge to indicate\
    \ that the objects of the first level included in them form a finite set. For\
    \ such sets, operations are\n\npossible: find out the number of elements of the\
    \ set, get a link to the first nearest element of the set, get a link to the next\
    \ element of the set;\n\n- ─ provide an opportunity for any metavertex or metaedge\
    \ to indicate that the objects included in them form a countable set. For such\
    \ metavertices or metaedges, two metavertices are created inside sets: one contains\
    \ a finite set of object types, and the second contains a countable set of objects\
    \ (further, when designing the knowledge base, various ways of representing countable\
    \ sets will be proposed). For objects of a countable set, operations are possible:\
    \ get a reference to the first nearest element of the set, get a reference to\
    \ the next element of the set;\n- ─ provide an opportunity to create metavertices\
    \ that implement operations on sets: union, intersection, subtraction, despite\
    \ the fact that the internal elements of the first level of such metavertices\
    \ can only be metavertices and metaedges that form sets.\n- 3. Add logical data\
    \ processing capabilities:\n- ─ to provide the possibility of operators = and\
    \ above the objects in two versions: structurally (according to the internal structure\
    \ and composition of attributes) and by value (in addition to the structure, the\
    \ attribute values must match);\n- ─ provide the ability to use standard operations\
    \ =, , >, <, , for operations on attributes;\n- ─ provide the ability to specify\
    \ predicates in the attributes of vertices, edges, metavertices and metaedges;\n\
    - ─ provide the ability to perform logical operations (&, V, ¬) over the attributes\
    \ of vertices, edges, metavertices and metaedges;\n- ─ provide an opportunity\
    \ to create metavertices that implement quantifiers and over sets, despite the\
    \ fact that the only internal element of the first level of such meta-vertices\
    \ can only be metavertices and metaedges forming sets;\n- ─ provide the ability\
    \ to create metavertices that implement logical inference operations on objects,\
    \ specifying a set of source objects and their attributes with predicates, as\
    \ well as the object and its attribute to which the result will be assigned;\n\
    - ─ create meta-vertices that implement a wide range of modal operators (aletic,\
    \ epistemic, deontic, axiological, temporal) by specifying one or more objects\
    \ and their attributes with predicates.\n\nMetagraphs with such extensions can\
    \ be used to implement first, second and higher order logic, as well as various\
    \ modal logics, they only lack functions. Let's call them generalized logical\
    \ metagraphs. To implement functions, we will move from metagraphs to archigraphs\
    \ and in addition to vertices, edges, meta-vertices, and meta-edges, we will add\
    \ another type of object - a function. The resulting generalized logical archigraphs\
    \ can become the basis for the presentation of knowledge.\n\nIn order for the\
    \ model to combine any forms of knowledge and ensure work with them, it is necessary,\
    \ by analogy with the universal data model [58], to add several dozen types of\
    \ elements corresponding to different forms of knowledge representation to the\
    \ archigraph. Then it will be possible to build archigraphs in which all knowledge\
    \ from a certain subject area will be combined, regardless of the form of their\
    \ representation. The edges and meta-edges of such an archigraph will correspond\
    \ to the relationship between entities. Meta-edges will be used when these relationships\
    \ are complex and need to be detailed with additional entities. In addition to\
    \ edges and metaedges reflecting the content of knowledge, the archigraph will\
    \ also contain edges and metaedges reflecting the history of which object was\
    \ obtained from or based on which. For example, that this text is an abstract\
    \ of that text. The appearance of such seemingly technical connections in the\
    \ archigraph is completely justified – this is also knowledge. The use of metaedges\
    \ in such technical cases may be due to the complexity of the conversion process.\n\
    \nAs a storage environment for the proposed archigraphs, it is necessary to develop\
    \ a specialized DBMS that supports the archigraph data model. Its design and development\
    \ can be considered as a further development of the work on the development of\
    \ metagraph databases, approaches to the creation of which were considered in\
    \ [67,68].\n\nAll the knowledge presented in the archigraph can be divided into\
    \ three large groups: unformalized, partially formalized and formalized.\n\n####\
    \ **3.1.2 Storage and Processing of Non-Formalized Knowledge**\n\nThe informal\
    \ knowledge processed in computers can be classified as:\n\n- Texts in natural\
    \ languages, including technical, legal, prose, poetry, etc.;\n- Various graph\
    \ schemes and drawings developed outside the automation systems of their development;\n\
    - Maps made outside GIS;\n- Speech audio recordings;\n- Music, sound effects;\n\
    - Images (photographs, paintings, portraits);\n- Videos and movies, including\
    \ those with audio accompaniment.\n\nThere are many technologies for converting\
    \ informal knowledge into formalized knowledge. For example, let's first consider\
    \ the transition from natural language texts to formalized knowledge. In order\
    \ not to delve too much into history, you can take as a starting point the popular\
    \ and quite functionally complete NLTK library for Python [69]. During further\
    \ development, neural networks and knowledge graphs began to be widely used for\
    \ these purposes [70,71]. In addition to technologies for converting texts into\
    \ semantic networks or into knowledge graphs (the latter provide opportunities\
    \ for logical inference based on the knowledge contained in them), there are well-developed\
    \ technologies for reverse conversion from graphs to texts [72]. One of the recent\
    \ works in this field is devoted to the bidirectional transformation of texts\
    \ into semantically loaded metagraphs and vice versa [73].\n\nTo formalize images,\
    \ their representations are used in the form of scene graphs, which are structured\
    \ representations of images in the form of graphs containing objects, their attributes\
    \ and defining relationships between objects in the scene. There are currently\
    \ two main approaches to scene graph generation (SGG):\n\n- The first is to find\
    \ objects, and then to find paired relationships between the found objects [74].\n\
    - The second is the simultaneous detection of objects and the relationships between\
    \ them [75].\n\nAs a rule, SGG tasks are solved by using various types of neural\
    \ networks: convolutional (CNN) [76], recurrent (RNN) [77], graph (GNN) [78].\
    \ [79,80] provides a detailed overview of existing methods for generating scene\
    \ graphs. The reverse transformation – the generation of images from scene graphs,\
    \ as well as from other images or from text descriptions is also performed using\
    \ neural networks. Generative adversarial networks (GAN) are mainly used [81].\
    \ A separate major area is the generation of images and related descriptions based\
    \ on the results of medical diagnostic procedures such as MRI and PET [82]. In\
    \ these cases, the image acts as an external representation of the data processing\
    \ results coming from the diagnostic equipment, masking the formalized representation\
    \ of the semantics of the received data.\n\nThe task of formalizing video is relatively\
    \ new. One of the solutions to this problem is based on the development of the\
    \ idea of constructing a graph of image scenes – the construction of a graph of\
    \ video scenes [83]. Another approach used in [84] involves the generation of\
    \ knowledge graphs based on language annotations to videos. In the same article,\
    \ the authors propose a model for generating knowledge graphs directly from video\
    \ based on neural networks, trained on the dataset obtained in the first part\
    \ of the work. Neural networks are also used for reverse conversion – generation\
    \ of videos from knowledge graphs, sets of images or text descriptions. This topic\
    \ attracts the attention of many researchers. Only in the preprint archive arxiv.org\
    \ A search for the phrase \"video generation\" in the headlines of publications\
    \ yields a list containing more than 380 articles. Some of the works on this topic\
    \ are considered in the reviews [85], [86].\n\nThe formalization of audio recordings\
    \ of speech is usually performed in two stages. Based on the spectral characteristics\
    \ of speech, it is quite difficult to immediately build a knowledge graph. In\
    \ order not to form it directly from the spectral pattern of human speech sound\
    \ waves, an intermediate stage of speech recognition is performed, for example,\
    \ using voice assistants [87]. After that, the problem is reduced to the task\
    \ of formalizing texts in natural languages, which was considered earlier. Neural\
    \ networks are widely used as speech-to-text translation tools: convolutional\
    \ (CNN) [88], transformers [89] and, more recently, graph neural networks (GNN)\
    \ [90]. About a dozen different methods have been developed for synthesizing speech\
    \ from text [91]. Currently, neural network–based methods are also the most promising:\
    \ convolutional networks that do not have autoregression provide the highest speed\
    \ of speech formation [92], and networks with feedback - transformers [92] and\
    \ generative-adversarial (GAN) [93] are characterized by high acoustic speech\
    \ quality, can generate speech with several voices and give it an emotional coloring.\n\
    \nTo formalize musical works, their fragments and the sounds of musical instruments\
    \ stored in musical databases [94,95], as well as sound effects stored in special\
    \ databases [96], special formalization methods based on Markov processes [97]\
    \ and algebraic methods [98,99] are used.\n\nA separate major area of formalization\
    \ of non-formalized knowledge is the formalization of multimodal representations\
    \ combining two or more non-formalized streams of knowledge, such as those related\
    \ to the main ones: text, image, video, audio, as well as various auxiliary ones:\
    \ context, pose, intonation, facial expressions, smell, taste, touch. The knowledge\
    \ graph obtained as a result of multimodal synchronous processing of several parallel\
    \ streams of unformalized knowledge is not a simple combination and combination\
    \ of knowledge graphs obtained by processing individual streams, additional knowledge\
    \ may appear in it due to a deeper understanding of the subject area [100]. In\
    \ addition, knowledge from different streams fills in gaps and corrects errors\
    \ in individual streams. It is shown that the connection of several modalities\
    \ makes it possible to improve the formation and processing of knowledge graphs\
    \ created on the basis of information selected from social networks [101]. Interactive\
    \ immersive generative multimodal interaction between a person and an agent in\
    \ the form of a steady smooth exciting conversation accompanied by the display\
    \ of images is considered as a prospect for the development of technologies of\
    \ multimodal interaction with agents in [102].\n\n#### **3.1.3 Storage and Processing\
    \ of Partially Formalized Knowledge**\n\nThe first group of partially formalized\
    \ knowledge is data that has a structure, but there is no intensional that allows\
    \ them to be used and interpreted. And there is also no understanding of the place\
    \ of specific data in the metric of the relevant semantic space. Partially formalized\
    \ knowledge can include:\n\n- Data located in files organized using various access\
    \ methods (sequential, direct, index-sequential, etc.);\n- Data stored in files\
    \ created without specifying access methods in various local, distributed and\
    \ cloud file systems;\n- Data in databases organized according to various data\
    \ models (network, hierarchical, multivalue, multidimensional, relational, object,\
    \ vector, XML, key-value, wide column, documentary, tabular, time series, event,\
    \ spatial, etc., as well as RDF used without describing semantics) [103], including:\
    \ data from various modules and subsystems of enterprise management, data from\
    \ document management and content management systems, data from electronic trading\
    \ platforms, test questions and training material from automated learning systems,\
    \ data from library systems and scientific citation systems, data from research\
    \ automation systems, etc.;\n- Data from search engines indexes, both on the internet\
    \ scale [104] and corporate ones [105];\n- Data from blockchain frameworks;\n\
    - CAD data on the products being designed;\n- Neural network structures;\n- Cartographic\
    \ data in GIS;\n- Tables and diagrams prepared in desktop and cloud applications,\
    \ with the exception of diagrams describing certain sequences of actions (program\
    \ flowcharts, business process diagrams, project plans, production flowcharts,\
    \ etc.).\n\nThe second group of partially formalized knowledge is mathematical\
    \ models that are not context–bound:\n\n- Linear and nonlinear equations and systems\
    \ of such equations;\n- Differential equations and systems of such equations;\n\
    - Partial differential equations and systems of such equations;\n- Probabilistic\
    \ equations and systems of such equations;\n- Logical equations of propositional\
    \ calculus and systems of such equations;\n- Tensor operators and equations;\n\
    - Infinite-dimensional topological vector spaces and their mappings [106];\n-\
    \ Algebras, groups, rings, fields, lattices, modules [107].\n\nFor both groups,\
    \ the lists are clearly not exhaustive. However, they provide an understanding\
    \ that allows you to assign similar cases, that are not included, in each group.\n\
    \nTo turn data or abstract mathematical models into formalized knowledge, it is\
    \ necessary to add connections that allow them to be used and interpreted, to\
    \ correlate these objects with other ones.\n\n#### **3.1.4 Storage and Processing\
    \ of Formalized Knowledge**\n\nThe ways of presenting formalized knowledge are\
    \ very diverse:\n\n- Computer programs in traditional programming languages (programs\
    \ that have source code, architecture, or algorithm descriptions available will\
    \ have internal granularity);\n- Computer programs in languages that implement\
    \ logical programming based on a subset of first-order predicate logic or implement\
    \ it along with other features (Prolog, Visual Prolog, Mercury, Oz, Strand, KL0,\
    \ KL1, Datalog, etc.) [108];\n- Diagrams describing some sequences of actions\
    \ (program flowcharts, business process diagrams, project execution plans, production\
    \ flowcharts, etc.) Prepared using specialized tools;\n- Semantic networks [109];\n\
    - Trained neural networks;\n- Frames (during the first 15 years of their development,\
    \ frame systems and languages were used for the structural representation of knowledge\
    \ [110], but since the late 1980s, logical inference tools based on stored information\
    \ have appeared in them [111] and with subsequent development, the role of logic\
    \ tools increases significantly [112]);\n- Knowledge graphs [113];\n- Descriptions\
    \ using first-order predicate logic (in the languages of general logic [114],\
    \ as well as in the languages CycL [115], FO[‧] [116], KIF [117,118], etc.);\n\
    - Descriptions using language families for the semantic web: RDF [119] and OWL\
    \ [120] or simpler ones like SHOE [121];\n- Description in ontology description\
    \ languages and/or in systems such as UFO [122], OntoUML [123], DOGMA [124], Ontologua\
    \ [125], LOOM [126], etc.;\n- Production systems (in simple cases, they can be\
    \ implemented using traditional programming languages, with professional implementation\
    \ specialized development languages [127,128] or special systems for working with\
    \ production rules [129] are used, they can be divided by type into clock and\
    \ stream ones [130]);\n- Formal grammars [131];\n- Formal systems of concepts\
    \ [132];\n- Conceptual models of knowledge [133];\n- Interconnected points in\
    \ the Elements-Attributes-Relations space [134,135];\n- Complex networks [136];\n\
    - Petri nets [137];\n- Finite state machines [138];\n- Simulation models [139].\n\
    \nTraditionally, when listing ways to represent formalized knowledge, objects\
    \ such as computer programs, neural networks, finite state machines, simulation\
    \ models and complex networks are not considered. This is due, among other things,\
    \ to the fact that in the absence of additional information, and sometimes even\
    \ if it is available, it is impossible to explain the results obtained by accessing\
    \ such objects. However, when creating a broad-purpose knowledge base for a projected\
    \ AGI, the lack of detailed explanations of how the final result was obtained,\
    \ as well as for a person, is not a reason to discard such objects. We can say\
    \ that they contain \"canned\" knowledge, and when entering the initial data,\
    \ they produce a result.\n\nThe above list of types of formalized knowledge is\
    \ also not comprehensive, as is the composition of other groups, but it gives\
    \ an intuitive understanding of what objects, not yet listed, could be included\
    \ in this group.\n\n#### **3.1.5 An Alternative Version of the Knowledge Base\
    \ Organization, which was Abandoned**\n\nIt was possible to avoid applying the\
    \ concept of an archigraph with several dozen types of objects for different types\
    \ of knowledge, but instead to focus on the model of a generalized logical metagraph,\
    \ to which only functions could be added and a \"Type\" attribute could be introduced\
    \ for each vertex, with which the type of knowledge contained in it could be determined.\
    \ But for each type of knowledge, its own group of functions working with it will\
    \ be used, which may overlap or not overlap with the functions of the other types\
    \ of knowledge. In addition, technical edges or metaedges related to knowledge\
    \ transformation would come into or out of each object. And for all these functions,\
    \ edges and metaedges in this case, one would also need a special \"Type\" attribute.\
    \ This would complicate the structure. Therefore, this option was abandoned.\n\
    \n### **3.2 A Preliminary Design of the Cognitive Architecture on the Basis of\
    \ which AGI Prototypes Can Be Developed**\n\n#### **3.2.1 Common Description of\
    \ Cognitive Architecture**\n\nBased on the suggested universal knowledge model,\
    \ a cognitive architecture is proposed, shown in Fig. 2, which can be used to\
    \ develop AGI prototypes.\n\n![](_page_15_Figure_3.jpeg)\n\n**Fig. 2.** A diagram\
    \ of the cognitive architecture that can be used to develop AGI prototypes.\n\n\
    All functional modules included in the cognitive architecture, except for modules\
    \ interacting with the external environment, work with the knowledge base, which\
    \ is the agent's memory. Each module interacting with the knowledge base has a\
    \ separate section there, in which it stores the knowledge it needs, and can change\
    \ them as it sees fit. If some knowledge is important for several modules, to\
    \ eliminate duplication, they can be stored in a common section accessible to\
    \ all of them. But then, to make changes to such knowledge, consent must be obtained\
    \ from all modules that have access to them.\n\nAll functional modules of the\
    \ cognitive architecture are integrated using a common knowledge bus. The knowledge\
    \ sent to the common bus gets to all modules connected to the bus, then each module\
    \ individually decides how to deal with them, save them in its knowledge base\
    \ area and somehow use or ignore them. In addition, the shared bus can be used\
    \ by modules to request knowledge from other modules. The response to the request\
    \ also comes via a common bus. Knowledge on the common bus can be transmitted\
    \ in all forms in which it can be stored in the knowledge base.\n\nUsing a shared\
    \ knowledge bus is an alternative used in many cognitive architectures to the\
    \ concept of working memory ([9], [11], [12], [15] and others). These options\
    \ are comparable to the integration methods used in the architecture of software\
    \ systems: integration over a common bus and integration over data. The advantages\
    \ of using a common knowledge bus are that all modules are forced to process the\
    \ incoming knowledge stream in parallel, except in situations where knowledge\
    \ is sent to a specific module in response to its request. This is a mechanism\
    \ that requires much more resources (both processor and memory), but this mechanism\
    \ is based on active actions, it involves individual modules in knowledge processing\
    \ and provides an up-to-date context for all of them. Unlike the general knowledge\
    \ bus, when using working memory, in case of any situation, the module must look\
    \ at what lies in the workspace. This is a passive mechanism. What if the necessary\
    \ knowledge has already been removed from the workspace and replaced with something\
    \ else?\n\nThe modules of consciousness and subconsciousness play a major role\
    \ in interacting with interface modules that provide interaction with the external\
    \ environment. The consciousness module is a control system that controls the\
    \ movement of an agent in a complex space, which is a combination of ordinary\
    \ three-dimensional space, time and any other spaces in which the agent operates\
    \ (for example, media spaces, consumer goods spaces, scientific research spaces,\
    \ etc.), with all the limitations inherent in these spaces (for example, you can\
    \ only move from one floor to another by stairs or by elevator). The subconscious\
    \ module allows you to implement ready-made routine sequences of actions stored\
    \ in the knowledge base without connecting or with minimal connection of a relatively\
    \ slow control system implemented by consciousness. Often the same sequences of\
    \ actions performed by consciousness move over time into the subconscious.\n\n\
    Consciousness controls movement, focusing on the goals generated by the goal management\
    \ module, and on the situation developing in the external environment. Knowledge\
    \ about the situation in the external environment from the multimodal data and\
    \ knowledge conversion module is transmitted not only to the modules of consciousness\
    \ and subconsciousness, which are the main consumers this data, but also after\
    \ being cleared of unnecessary details, it is transmitted to the common bus, from\
    \ where all other modules receive them, including: monitoring module, goal management\
    \ module, emotional management module. And the same in the opposite direction\
    \ (but not symmetrically): the modules interacting with the external environment\
    \ receive knowledge from the common bus, for example, emotions from the emotional\
    \ management module, although the bulk of knowledge is transferred there from\
    \ consciousness and subconsciousness.\n\nThe emotional control module is another\
    \ control system besides consciousness, which does not act as precisely as consciousness\
    \ can, but on all modules at once. The emotions generated are not some single\
    \ objects with the meanings \"sad\", \"joyful\", \"anxious\", \"ashamed\", etc.,\
    \ but more complex knowledge structures where there are reasons, some previous\
    \ history, perhaps: participants in the event and something else.\n\nThe ethical\
    \ assessment module generates ethical assessments of all events and actions, including\
    \ possible actions. These assessments can both encourage and deter these actions,\
    \ and the level of support or deterrence may vary. If the actions and events have\
    \ already taken place, then their ethical assessments are added to their characteristics.\
    \ Just like emotions, ethical assessments are complex structures in which reasons\
    \ may be present, justifying artifacts or chains of events, etc. Ethical assessments\
    \ are formed on the basis of ethical principles stored in the knowledge base and\
    \ amenable to modification either with human participation or as a result of repeated\
    \ occurrence of sequences of events that reveal contradictions in these principles.\n\
    \nThe reflection module is somewhat similar to the ethics module, it also generates\
    \ assessments of actions and events, but only past ones, and not from the perspective\
    \ of some ethical norms established by culture, religion or some authorities,\
    \ but from the perspective of achieving the final result, side effects that arise,\
    \ influencing one's own and others' plans, and etc. At the same time, very often,\
    \ during the work of the reflection module, events that have occurred are modeled\
    \ from the positions of other participants, their assumed (or confirmed by some\
    \ facts) estimates of these events are formed, and their own estimates are adjusted\
    \ from these positions.\n\nThe social interaction module takes into account relationships\
    \ with people and other agents, existing and possible roles in these interactions,\
    \ emotions towards other agents, the course of processes and the results of previous\
    \ interactions with them and, based on all of this, adjusts action plans that\
    \ are somehow related to other agents. In addition to plans, the module influences\
    \ actions and dialogues when interacting with people and other agents, forming\
    \ additional knowledge for modules of interaction with the external environment.\n\
    \nThe worldview module provides the formation and support of a special section\
    \ in the knowledge base, which contains a picture of the agent's world and determines\
    \ his place in it, the main goals of the agent's existence are formulated. This\
    \ section is based on a scientific picture of the world, but to understand many\
    \ aspects of history, art, and social relationships, other pictures of the world\
    \ (mythological, several religious, and alternative scientific) are also stored\
    \ in the section with explanations why they are not correct. The scientific picture\
    \ of the world is modified as new scientific knowledge becomes available. Stored\
    \ worldviews are used to gain new knowledge from different fields and compare\
    \ them with those available in the database. In case of contradictions, various\
    \ reactions are possible, both the re-clarification of the received knowledge\
    \ and the assignment of assessments that they are false.\n\nThe monitoring module\
    \ allows for various types of monitoring in a wide range of processes occurring\
    \ in the external environment and in the modules of the agent's cognitive system.\
    \ The occurrence of some events, changes in the values of the characteristics\
    \ of some objects can be controlled, and both the achievement of some expected\
    \ value and the finding of this value within some acceptable limits can be controlled.\
    \ The initiation of monitoring processes is carried out by other modules of the\
    \ cognitive architecture.\n\nThe learning module generates new knowledge in the\
    \ knowledge base. This can happen both through the direct transfer of knowledge\
    \ coming from the external environment with their subsequent comparison with existing\
    \ knowledge and binding in the absence of contradictions, and through the formation\
    \ of models based on the results of the agent's own actions. Both externally received\
    \ and independently created models are tested and checked for compliance with\
    \ the knowledge already available in the knowledge base. If there are inconsistencies,\
    \ new knowledge can be discarded (if it strongly contradicts the worldview, ethical\
    \ assessments, or already existing knowledge) or recorded in the knowledge base\
    \ with the mark indicating the presence of contradictions. The formation of new\
    \ knowledge can occur in all modules of the cognitive architecture working with\
    \ the knowledge base, while access to the learning module is performed to replenish\
    \ and/or adjust the knowledge base.\n\nThe task setting and solution modules carry\
    \ out the formulation and solution of tasks. Requests to them are initiated from\
    \ any module of the cognitive architecture, including the learning module for\
    \ building new models and the setting and solving problems modules themselves\
    \ for setting and solving problems when a complex task is divided into subtasks.\n\
    \nWith the help of the self-organization and meta-learning module, the agent should\
    \ be able to rebuild and improve his activities, find and switch to using new\
    \ more productive ways of learning. Decisions on the reorganization of activities\
    \ or on the transition to new forms of activity, as well as decisions on the transition\
    \ to new forms of education should be made based on the results of a purposeful\
    \ search, modeling and subsequent practical testing. For the first time, the need\
    \ for such a functional component as part of the cognitive architecture for AGI\
    \ was shown in [140].\n\nThe presented description of the cognitive architecture\
    \ in the light of [141] can be considered as a top-level specification that can\
    \ be used to further detail the cognitive architecture and develop an intelligent\
    \ agent, however, we will not delve into this process due to its resource intensity.\
    \ Our following descriptions of the individual modules will be related to an overview\
    \ of the implementation of the corresponding mechanisms in other cognitive architectures.\n\
    \n#### **3.2.2 Consciousness**\n\nOf the 42 cognitive architectures considered\
    \ by us, only four have an explicitly highlighted \"Consciousness\" component\
    \ for building AGI: LIDA [12], Haikonen cognitive architecture [13], [16], ICOM\
    \ [23] and MBCA [27], Clarion [47], OntoAgent [49], ISAAC [51], [52]. And GLAIR\
    \ [31] also talks about the Knowledge Layer in which conscious reasoning, planning,\
    \ and act selection is performed. There are much more cognitive architectures\
    \ for simpler robots that have consciousness embedded in them, or architectures\
    \ being developed as part of research projects on the realization of consciousness:\
    \ [142], [143], [144], MECA [145], [146], [147], [148], [149], RoboErgoSum [150],\
    \ [151], COCOCA [152], MLECOG [153], [154], [155], CELTS [156], [157], [158],\
    \ [159], [160], [161]. In these works, as a rule, a lot of attention is paid to\
    \ the technical implementation of consciousness and its integration into the cognitive\
    \ architecture, while its functionality is not worked out deeply enough, but only\
    \ at a general level.\n\nThe key features of the modern understanding of machine\
    \ consciousness were formulated in [162,163]. Consciousness is considered as a\
    \ control system for the agent's current actions. To have minimal consciousness,\
    \ it is necessary that the agent has the following capabilities:\n\n- self-knowledge:\
    \ Agent has complete knowledge of its current cognitive state as well as of the\
    \ data produced by all its interfaces, sensor, and motor units.\n- self-monitoring:\
    \ Agent is completely informed about the performance and status of its sensory\
    \ and motor units over time (including the quality of the sensations and the reports\
    \ from all of them) and of its embedding in the environment as it is.\n- self-awareness\
    \ (or self-reflection): Agent behaves in a way that unambiguously reflects, respectively\
    \ is determined by its current cognitive state and the information gained by its\
    \ self-knowledge and self-monitoring abilities, and that is 'aware' of the internal\
    \ and external changes that it causes.\n- self-informing: Agent globally broadcasts\
    \ its cognitive state, to all modules of the system and whenever changes of state\
    \ occur.\n\nIt can be expected that the further development of this theory from\
    \ a minimal to a more advanced consciousness will make it possible to realize\
    \ consciousness as a system of parallel control processes taking place in multidimensional,\
    \ partially intersecting virtual spaces in which spatial and temporal constraints\
    \ are set. If the actions that need to be performed based on the results of parallel\
    \ management processes in the real space in which the agent operates contradict\
    \ each other, they are checked for consistency in time distribution, ranked and\
    \ queued. In the process of functioning, the consciousness module intensively\
    \ interacts with all other AGI modules, receiving plans for further actions, applying\
    \ for statements and solutions to problems of modeling possible situations, considering\
    \ ethical assessments, checking with the worldview, etc.\n\n#### **3.2.3 Subconscious**\n\
    \nThe machine subconscious contains ready-made models and algorithms that can\
    \ be quickly activated when corresponding situations arise. Unlike human memory,\
    \ the volume of the machine subconscious can be quite large, and stored models\
    \ can cover a wide range of fields of knowledge and activities. Among the architectures\
    \ designed to create AGI, the following architectures have the subconscious: ACT-R\
    \ [10], LIDA [12], CogPrime [17, 18], ICOM [23], GLAIR [31], MicroPSI [40], Clarion\
    \ [47], OntoAgent [49], ISAAC [51], [52]. Some cognitive architectures, which\
    \ do not have the immediate goal of creating AGI, are claimed to have both consciousness\
    \ and subconsciousness: COCOCA [152], MLECOG [153], [154], [155], CELTS [156],\
    \ [157], [158], [159], [160], [161]. At the same time, there are cognitive architectures\
    \ of this class, which have only subconsciousness without consciousness: IFORs\
    \ [164], [165], [166], [167], DIARC [168], NCCA [169], [170].\n\nThe existence\
    \ of the subconscious in the cognitive architecture is evidenced not only by the\
    \ explicit indication of its presence. As was rightly noted in [35], all reactive\
    \ cognitive architectures such as Soar [9], ICARUS [171], SW-CASPAR [172] or individual\
    \ reactive levels in complex combined architectures, such as the reactive layer\
    \ in CogAff [34], contain a certain set of behaviors for different situations\
    \ and, in fact, act as a subconscious.\n\nThe perception of subconsciousness,\
    \ that has developed among some researchers, as some kind of auxiliary system\
    \ that helps consciousness (which is not entirely true) leads to the fact that\
    \ the specific functionality of the subconscious in cognitive architectures\n\n\
    is often left behind the scenes or distorted. So, in [155] and [157] they take\
    \ as a basis Kahneman's idea [173] about the dual nature of thinking processes\
    \ and distinguish a fast subconscious mind that processes large amounts of incoming\
    \ information and a slow consciousness that processes significantly less information.\
    \ This is true, but with this approach, the functionality of the subconscious\
    \ mind for the accumulation, storage and use of ready-made algorithms and models\
    \ remains undisclosed.\n\nAlong with the fact that the functionality of the subconscious\
    \ mind is not revealed, it can also be distorted. So, the article [174] begins\
    \ with the correct statements that the subconscious can handle tasks in the high\
    \ dimensional problem solving space while the consciousness can operate only in\
    \ the low dimensional space. But then the author considers a way to transfer information\
    \ from the subconscious mind to consciousness using emotions. The same idea is\
    \ expressed in [175]. In our opinion, this is wrong, emotions are not signals\
    \ of the subconscious mind. The emotional management system is a separate functional\
    \ component of the cognitive architecture. In the architecture shown in the figure\
    \ above, the subconscious mind can directly interact with the modules of interaction\
    \ with the external environment. Consciousness, receiving information about these\
    \ interactions, can suppress or correct them.\n\nSimilarly, attaching the functions\
    \ of interaction with the external environment to the subconscious mind [161],\
    \ in our opinion, is also a distortion of its functionality; for this purpose,\
    \ separate modules should be allocated in the cognitive architecture. The restriction\
    \ on the methods of realization of the subconscious mind caused by this distortion\
    \ (the use of neural networks and fuzzy logic) immediately becomes invalid after\
    \ the distortion is eliminated. This is confirmed by a number of examples of the\
    \ inclusion of the subconscious mind in the symbolist cognitive architectures\
    \ presented in this section, based on the use of production rules.\n\n#### **3.2.4\
    \ Worldview**\n\nOf the 42 cognitive architectures we have considered for building\
    \ AGI, the worldview module is present in NARS [11], Sigma [15], MBCA [27], GLAIR\
    \ [31], H-CogAff [34], EM-ONE [36], CAMAL [38], SMCA [39], Clarion [47] and Oscar\
    \ [48], as well as in cognitive architectures developed for research purposes\
    \ that did not consider all aspects of human activity: CogAff [34], [145], ICARUS\
    \ [171], SW-CASPAR [172], CRIBB [176], A-CRIBB [177], [178], SACA [179], [180],\
    \ CoJACK [181], [182], [183], MAMID [184], CogToM [185], Scruff [186], CASPAR\
    \ [187], [188] and InnovA [189]. All these cases provide for the presence and\
    \ use of many elements of worldviews. All these elements are either intuitive\
    \ (laid down initially when creating an agent), or formed as a result of training,\
    \ and they are all related to some operational aspects of the activity. Conflicting\
    \ worldviews such as scientific, religious, and mythological are not considered.\n\
    \nIn [190], a method for the coordinated use of several contradictory worldviews\
    \ is proposed, but it is quite primitive and not suitable for AGI: the agent acts\
    \ as a character in a game journey full of challenges and mysteries that underlie\
    \ myths. In [191] and [192], a fragmented worldview is considered. The fundamental\
    \ basis for dealing with\n\nworldviews is the theory of Belief revision [193],\
    \ [194], [195]. For effective coordinated use of different worldviews, it is necessary,\
    \ depending on the context, to ensure dynamic switching between different independent\
    \ worldview models and to have knowledge (on a deeper layer of worldview common\
    \ to all models) about the relevance of each model and the conditions of its application.\n\
    \n#### **3.2.5 Reflection**\n\nThe reflection module builds models of this agent,\
    \ reflecting its various aspects: activities, plans, knowledge, appearance, etc.\
    \ At the same time, these models can be built in parallel and from different perspectives:\n\
    \n- From the point of view of some theoretical concepts: cost, safety, environmental\
    \ protection, technical condition, etc.;\n- From the point of view of some real\
    \ or abstract individuals and/or organizations. In the process of building a reflexive\
    \ model, an agent model is used, from which position this reflexive model is built.\
    \ In this case, not one, but a small sequence of reflexive models can be built\
    \ from the position of a particular agent and several of its models: In particular,\
    \ the second reflexive model is built on the assumption that the external agent\
    \ knows that the main agent understands what the external agent thinks about him.\
    \ This is considered in the second external agent model. According to the same\
    \ principle of multiple reflection, third and subsequent reflexive models and\
    \ models of an external agent can be constructed.\n\nIn both variants, emotional\
    \ assessments of concepts and subjects can be considered, from the point of view\
    \ of which reflexive models are built.\n\nThe created reflexive models can be\
    \ partial models of a given agent (reflect only one or several of its sides) and\
    \ differ from the model of a given agent available in consciousness. They are\
    \ used for self-assessment and adjustment of modelled aspects.\n\nReflection functionality\
    \ is available in the following cognitive architectures designed to create AGI:\
    \ Soar [9], Sigma [15], eBICA [21.22], H-CogAff [34], EM-ONE [36], CAMAL [38],\
    \ SMCA [39], MicroPSI [40], [44], Polyscheme [45], [46], Clarion [47]. In addition,\
    \ it is used in the cognitive architecture of strong human-machine intelligence\
    \ [196], as well as in cognitive architectures designed for simpler robots and\
    \ research in the field of cognitive architectures: CogAff [34], DIARC [168],\
    \ CRIBB [176], A-CRIBB [177], SACA [179], [180], MAMID [184], [197], EM1 [198],\
    \ Cognitive Architecture for Human-Robot Interaction [199], [200], [201], [202].\n\
    \n### **4 Conclusions**\n\nThe article proposes a model of knowledge representation\
    \ that allows the upcoming AGI to work with different representations of knowledge\
    \ and freely move from one to another. This model is used in the proposed AGI\
    \ cognitive architecture, which identifies functional blocks for all types of\
    \ cognitive activity that the authors considered inherent in humans.\n\nWe hope\
    \ that the proposed cognitive architecture and knowledge representation model\
    \ will solve the problem formulated in the introduction, as well as allow us to\
    \ answer some of the challenges that faced the theory of cognitive architectures\
    \ according to [203,204], in particular:\n\n- The need for robust integration\
    \ of mechanisms involving planning, acting, monitoring and goal reasoning.\n-\
    \ [The limited size](http://www.ieee-coro.org/) and the homogeneous typology of\
    \ knowledge that is encoded and processed by systems based on cognitive architectures.\n\
    \nIn the first prototypes being developed, not all types of knowledge and not\
    \ all functional blocks of the cognitive architecture may be supported. At the\
    \ same time, the prototyping process and future theoretical research may reveal\
    \ the need to expand the composition of blocks of cognitive architecture, to include\
    \ blocks not provided for in this article.\n\n### **5 Discussion**\n\nThe article\
    \ considers in detail only 5 functional modules of the proposed cognitive architecture\
    \ out of 17 including Knowledge base. Of course, it is necessary to describe them\
    \ all. Obstacles to this:\n\n- the text of the article is already quite large\
    \ then will increase significantly in size;\n- a lot of additional time is required\
    \ to perform a significant additional amount of work on the analysis of cognitive\
    \ architectures and text preparation.\n\nThe authors plan to prepare a continuation\
    \ of this article in the future with a description of the remaining functional\
    \ modules.\n\n### **6 Organizational Snippets**\n\n### **6.1 Author Contributions**\n\
    \n**Artem Sukhobokov**: Conceptualization, Writing - Original Draft, Supervision.\
    \ **Evgeny Belousov**: Resources, Writing - Original Draft. **Danila Gromozdov**:\
    \ Writing - Original Draft, Validation. **Anna Zenger**: Writing - Original Draft,\
    \ Writing - Review & Editing. **Ilya Popov**: Methodology, Writing - Original\
    \ Draft.\n\n### **6.2 Declaration of Competing Interest**\n\nThe authors declare\
    \ that they have no known competing financial interests or personal relationships\
    \ that could have appeared to influence the work reported in this paper.\n\n###\
    \ **6.3 Funding**\n\nThis research did not receive any specific grant from funding\
    \ agencies in the public, commercial, or not-for-profit sectors.\n\n### **References**\n\
    \n- 1. Ghosh, S., & Singh, A. (2020, May). The scope of Artificial Intelligence\
    \ in mankind: A detailed review. *Journal of Physics: Conference Series 1531*,\
    \ Article 012045. IOP Publishing. https://doi.org/10.1088/1742-6596/1531/1/012045\n\
    - 2. Newell, А. (1990). *Unified Theories of Cognition (The William James lectures:\
    \ 1987)* Harvard University Press.\n- 3. Langley, P., Laird, J. E., & Rogers,\
    \ S. (2009). Cognitive architectures: Research issues and challenges. *Cognitive\
    \ Systems Research*, *10*(2), 141-160. <https://doi.org/10.1016/j.cogsys.2006.07.004>\n\
    - 4. Kotseruba. I., & Tsotsos, J. K. (2018) A review of 40 years in cognitive\
    \ architecture research: core cognitive abilities and practical applications.\
    \ *arXiv*:1610.08602v3 [cs.AI]. <https://doi.org/10.48550/arXiv.1610.08602>\n\
    - 5. Ye, P., Wang, T., & Wang, F. -Y. (2018). A Survey of Cognitive Architectures\
    \ in the Past 20 Years. *IEEE Transactions on Cybernetics*, *48*(12), 3280-3290.\
    \ <https://doi.org/10.1109/TCYB.2018.2857704>\n- 6. Duch, W., Oentaryo, R. J.,\
    \ & Pasquier, M. (2008, March). Cognitive architectures: Where do we go from here?.\
    \ In: Wang, P., Gorzel, B., & Franklin, S. (eds) *Artificial General Intelligence\
    \ 2008: Proceedings of the First AGI Conference* (pp. 122-136) IOS Press. <https://ebooks.iospress.nl/volumearticle/4075>\n\
    - 7. Panella, I., Fragonara, L. Z., & Tsourdos, A. (2021). A deep learning cognitive\
    \ architecture: Towards a unified theory of cognition. In: [Arai,](https://link.springer.com/book/10.1007/978-3-030-55180-3#author-1-0)\
    \ K.[, Kapoor,](https://link.springer.com/book/10.1007/978-3-030-55180-3#author-1-1)\
    \ S., [& Bhatia](https://link.springer.com/book/10.1007/978-3-030-55180-3#author-1-2)\
    \ R. (eds) *Intelligent Systems and Applications: Proceedings of the 2020 Intelligent\
    \ Systems Conference (IntelliSys)* Vol 1 (pp. 566-582) Advances in Intelligent\
    \ Systems and Computing, vol 1250. Springer, Cham. https://doi.org/10.1007/978-3-030-55180-3\\\
    _42\n- 8. Laird, J. E., & Wray III, R. E. (2010, June). Cognitive architecture\
    \ requirements for achieving AGI. In: *3d Conference on Artificial General Intelligence\
    \ (AGI-2010)* (pp. 3-8) Atlantis Press. https://doi.or[g/10.2991/agi.2010.2](https://doi.org/10.2991/agi.2010.2)\n\
    - 9. Laird, J. E. (2019). *The Soar cognitive architecture.* MIT press. <https://doi.org/10.7551/mitpress/7688.001.0001>\n\
    - 10. Lebiere, C., Pirolli, P., Thomson, R., Paik, J., Rutledge-Taylor, M., Staszewski,\
    \ J., & Anderson, J. R. (2013). A functional model of sensemaking in a neurocognitive\
    \ architecture. *Computational intelligence and neuroscience*, *2013*, Article\
    \ 921695. <https://doi.org/10.1155/2013/921695>\n- 11. Wang, P. (2013). Natural\
    \ language processing by reasoning and learning. In: Kühnberger, K,-U., Rudolph,\
    \ S., & Wang, P. (eds) *Artificial General Intelligence: 6th International Conference,\
    \ AGI 2013*. (pp. 160-169) Lecture Notes in Computer Science, vol 7999. Springer,\
    \ Berlin, Heidelberg. [https://doi.org/10.1007/978-3-642-39521-5\\\\_17](https://doi.org/10.1007/978-3-642-39521-5_17)\n\
    - 12. Faghihi, U., & Franklin, S. (2012). The LIDA model as a foundational architecture\
    \ for AGI. In: Wang, P., & Goertzel, B. (eds) *Theoretical foundations of artificial\
    \ general intelligence* (pp. 103-121) Atlantis Press, Paris. [https://link.springer.com/content/pdf/10.2991/978-94-91216-62-6\\\
    \\_7.pdf](https://link.springer.com/content/pdf/10.2991/978-94-91216-62-6_7.pdf)\n\
    - 13. Haikonen, P. O. (2007). *Robot brains: circuits and systems for conscious\
    \ machines.* Wiley-Interscience, York, NY, United States.\n\n- 14. Schaat, S.,\
    \ Wendt, A., Kollmann, S., Gelbard, F., & Jakubec, M. (2015). Interdisciplinary\
    \ Development and Evaluation of Cognitive Architectures Exemplified with the SiMA\
    \ Approach. In: Airenti, G., Bara, B. G., & Sandini, G. (eds) *EuroAsianPacific\
    \ Joint Conference on Cognitive Science* (pp. 515-520) EAPCogSci 2015*.* CEUR\
    \ WORKSHOP PROCEEDINGS. vol 1419.<https://ceur-ws.org/Vol-1419/paper0084.pdf>\n\
    - 15. Pynadath, D. V., Rosenbloom, P. S., & Marsella, S. C. (2014). Reinforcement\
    \ learning for adaptive theory of mind in the sigma cognitive architecture. In:\
    \ Goertzel, B., Orseau, L., & Snaider, J. (eds.) *Artificial General Intelligence:\
    \ 7th International Conference*, *AGI 2014* (pp. 143-154) Lecture Notes in Computer\
    \ Science, vol 8598. Springer, Cham. [https://doi.org/10.1007/978-3-319-09274-4\\\
    \\_14](https://doi.org/10.1007/978-3-319-09274-4_14)\n- 16. Raizer, K., Paraense,\
    \ A. L., & Gudwin, R. R. (2012). A cognitive architecture with incremental levels\
    \ of machine consciousness inspired by cognitive neuroscience. *International\
    \ Journal of Machine Consciousness*, *4*(02), 335-352. <https://doi.org/10.1142/S1793843012400197>\n\
    - 17. Goertzel, B.. Pennachin, C., & Geisweiller, N. (2014). *Engineering General\
    \ Intelligence, Part 1: A Path to Advanced AGI via Embodied Learning and Cognitive\
    \ Synergy*. Atlantis Press, Paris, France.<https://doi.org/10.2991/978-94-6239-027-0>\n\
    - 18. Goertzel, B.. Pennachin, C., & Geisweiller, N. (2014). *Engineering General\
    \ Intelligence, Part 2: The CogPrime Architecture for Integrative, Embodied AGI.*\
    \ Atlantis Press, Paris, France. <https://doi.org/10.2991/978-94-6239-030-0>\n\
    - 19. Thórisson, K. R., & Nivel, E. (2009, June). Achieving artificial general\
    \ intelligence through peewee granularity. In: *2nd Conference on Artificial General\
    \ Intelligence (2009)* (pp. 198-199). Atlantis Press. https://doi.or[g/10.2991/agi.2009.42](https://doi.org/10.2991/agi.2009.42)\n\
    - 20. Nivel, E., & Thórisson, K. R. (2009, June). Self-programming: Operationalizing\
    \ autonomy. In: *2nd Conference on Artificial General Intelligence (2009)* (pp.\
    \ 212-217) Atlantis Press. https://doi.or[g/10.2991/agi.2009.45](https://doi.org/10.2991/agi.2009.45)\n\
    - 21. Azarnov, D. A., Chubarov, A. A., & Samsonovich, A. V. (2018). Virtual actor\
    \ with socialemotional intelligence. *Procedia computer science*, *123*, 76-85.\
    \ https://doi.org/10.1016/j.procs.2018.01.013\n- 22. Samsonovich, A. V. (2020).\
    \ Socially emotional brain-inspired cognitive architecture framework for artificial\
    \ intelligence. *Cognitive Systems Research*, *60*, 57-76. <https://doi.org/10.1016/j.cogsys.2019.12.002>\n\
    - 23. Kelley, D., & Twyman, M. (2020). Biasing in an independent core observer\
    \ model artificial general intelligence cognitive architecture. *Procedia Computer\
    \ Science*, *169*, 535-541. <https://doi.org/10.1016/j.procs.2020.02.213>\n- 24.\
    \ Vityaev, E. E., Demin, A. V., & Kolonin, Y. A. (2020). Logical Probabilistic\
    \ Biologically Inspired Cognitive Architecture. In: Goertzel, B., Panov, A., Potapov,\
    \ A., & Yampolskiy, R. (eds) *Artificial General Intelligence, AGI 2020* (pp.\
    \ 337–346) Lecture Notes in Computer Science, vol 12177. Springer, Cham[. https://doi.org/10.1007/978-3-030-52152-3\\\
    \\_36](https://doi.org/10.1007/978-3-030-52152-3_36)\n- 25. Nakamura, M., & Yamakawa,\
    \ H. (2016). A Game-Engine-Based Learning Environment Framework for Artificial\
    \ General Intelligence. In: Hirose, A., Ozawa, S., Doya, K., Ikeda, K., Lee, M.,\
    \ & Liu, D. (eds) *Neural Information Processing* ICONIP 2016 (pp. 351-356) Lecture\
    \ Notes in Computer Science, vol 9947. Springer, Cham. https://doi.org/10.1007/978-3-319-46687-3\\\
    _39\n- 26. Strannegård, C., von Haugwitz, R., Wessberg, J., & Balkenius, C. (2013).\
    \ A cognitive architecture based on dual process theory. In: Kühnberger, K,-U.,\
    \ Rudolph, S., & Wang, P. (eds) *Artificial General Intelligence: 6th International\
    \ Conference, AGI 2013* (pp. 140- 149) Lecture Notes in Computer Science, vol\
    \ 7999. Springer, Berlin, Heidelberg. [https://doi.org/10.1007/978-3-642-39521-5\\\
    \\_15](https://doi.org/10.1007/978-3-642-39521-5_15)\n- 27. Schneider, H. (2020).\
    \ Subsymbolic Versus Symbolic Data Flow in the Meaningful-Based Cognitive Architecture.\
    \ In: Samsonovich, A. (eds) *Biologically Inspired Cognitive Architectures 2019*\
    \ BICA 2019 (pp. 465–474) Advances in Intelligent Systems and Computing, vol 948.\
    \ Springer, Cham[. https://doi.org/10.1007/978-3-030-25719-4\\\\_61](https://doi.org/10.1007/978-3-030-25719-4_61)\n\
    - 28. Komarovsky, S. (2022). Dynamic and Evolving Neural Network as a Basis for\
    \ AGI (No. 7922). *EasyChair*[. https://easychair.org/publications/preprint\\\\\
    _download/bCjT](https://easychair.org/publications/preprint_download/bCjT)\n-\
    \ 29. Zhou, J., & Ustun, V. (2022). PySigma: Towards Enhanced Grand Unification\
    \ for the Sigma Cognitive Architecture. In: Goertzel, B., Iklé, M., & Potapov,\
    \ A. (eds) *Artificial General Intelligence. AGI 2021* (pp. 355-366) Lecture Notes\
    \ in Computer Science, vol 13154. Springer, Cham. https://doi.org/10.1007/978-3-030-93758-4\\\
    _36\n- 30. Xu, M., Zheng, H., Pei, J., & Deng, L. (2023). A Unified Structured\
    \ Framework for AGI: Bridging Cognition and Neuromorphic Computing. In: Hammer,\
    \ P., Alirezaie, M., & Strannegård, C. (eds) *Artificial General Intelligence.\
    \ AGI 2023* (pp. 345-356) Lecture Notes in Computer Science, vol 13921. Springer,\
    \ Cham. [https://doi.org/10.1007/978-3-031-33469-6\\\\_35](https://doi.org/10.1007/978-3-031-33469-6_35)\n\
    - 31. Shapiro S. C., & Bona J. P. (2010). The GLAIR Cognitive Architecture. *International\
    \ Journal of Machine Consciousness*, *2*(2), 307-332. <https://doi.org/10.1142/S1793843010000515>\n\
    - 32. Miller, M. S. P. (2019). Building Minds with Patterns. *10th Annual International\
    \ Conference on Biologically Inspired Cognitive Architectures BICA 2019*, August\
    \ 16-18, Redmond, WA, USA. <https://www.youtube.com/watch?reload=9&v=kqicbyONxO8>\n\
    - 33. Miller, M. S. P. (2020). *Coding Artificial Minds*. Michael S. P. Miller.\n\
    - 34. Sloman, A., & Chrisley, R. L. (2005). More things than are dreamt of in\
    \ your biology: Information-processing in biologically inspired robots. *Cognitive\
    \ Systems Research*, *6*(2), 145-174. <https://doi.org/10.1016/j.cogsys.2004.06.004>\n\
    - 35. Serov, A. (2022). Evolution of a cognitive architecture on the basis of\
    \ a functional core. *SN Applied Sciences*, *4*, Article 306. https://doi.org/10.1007/s42452-022-05195-6\n\
    - 36. Singh, P. (2005). *EM-ONE: an architecture for reflective commonsense thinking*\
    \ (Doctoral dissertation, Massachusetts Institute of Technology). <https://dspace.mit.edu/bitstream/handle/1721.1/33926/67297587-MIT.pdf>\n\
    - 37. Dushkin, R. V. (2022). Towards AGI: Cognitive Architecture Based on Hybrid\
    \ and Bionic Principles. In: Arai, K. (eds) *Intelligent Computing* (pp. 337-345)\
    \ Lecture Notes in Networks and Systems, vol 283. Springer, Cham. [https://doi.org/10.1007/978-3-030-80119-9\\\
    \\_19](https://doi.org/10.1007/978-3-030-80119-9_19)\n- 38. Davis, D. N. (2003).\
    \ Architectures for cognitive and a-life agents. In: Plekhanova V.(eds) *Intelligent\
    \ agent software engineering* (pp. 27-48). IGI Global. <https://doi.org/10.4018/978-1-59140-046-2.ch002>\n\
    - 39. Venkatamuni, V. M. (2008). *A society of mind approach to cognition and\
    \ metacognition in a cognitive architecture* (Doctoral dissertation, University\
    \ of Hull). <https://hull-repository.worktribe.com/output/4213883>\n- 40. Bach,\
    \ J. (2009). *Principles of synthetic intelligence PSI: an architecture of motivated\
    \ cognition*. Oxford University Press, Inc.\n- 41. Hummel, J. E., & Holyoak, K.\
    \ J. (2003). Relational reasoning in a neurally-plausible cognitive architecture:\
    \ An overview of the LISA project. *Cognitive Studies: Bulletin of the Japanese\
    \ Cognitive Science Society, 10*, 58-75. https://doi.org/10.11225/jcss.10.58\n\
    - 42. Chandiok, A., & Chaturvedi, D. K. (2018). CIT: Integrated cognitive computing\
    \ and cognitive agent technologies based cognitive architecture for human-like\
    \ functionality in artificial systems. *Biologically inspired cognitive architectures,\
    \ 26*, 55-79. <https://doi.org/10.1016/j.bica.2018.07.020>\n- 43. Forbus, K. D.,\
    \ & Hinrich, T. (2017). Analogy and relational representations in the companion\
    \ cognitive architecture. *AI Magazine, 38*(4), 34-42. <https://doi.org/10.1609/aimag.v38i4.2743>\n\
    \n- 44. Augello, A., Infantino, I., Lieto, A., Pilato, G., Rizzo, R., Vella, F.\
    \ (2016). Artwork creation by a cognitive architecture integrating computational\
    \ creativity and dual process approaches. *Biologically inspired cognitive architectures*,\
    \ *15*, 74-86. <https://doi.org/10.1016/j.bica.2015.09.007>\n- 45. Cassimatis,\
    \ N. L. (2001). *Polyscheme: a cognitive architecture for intergrating multiple\
    \ representation and inference schemes* (Doctoral dissertation, Massachusetts\
    \ Institute of Technology). <https://dspace.mit.edu/bitstream/handle/1721.1/8325/50491511-MIT.pdf>\n\
    - 46. Larue, O., Poirier, P., Nkambou, R. (2012). A Three-Level Cognitive Architecture\
    \ for the Simulation of Human Behaviour. In: Kosseim, L., Inkpen, D. (eds) *Advances\
    \ in Artificial Intelligence. Canadian AI 2012* (pp. 337-342). Lecture Notes in\
    \ Computer Science, vol 7310. Springer, Berlin, Heidelberg[. https://doi.org/10.1007/978-3-642-30353-1\\\
    \\_33](https://doi.org/10.1007/978-3-642-30353-1_33)\n- 47. Sun, R. (2016). *Anatomy\
    \ of the mind: exploring psychological mechanisms and processes with the Clarion\
    \ cognitive architecture.* Oxford University Press.\n- 48. Pollock, J. L. (2008).\
    \ Oscar: An architecture for generally intelligent agents. *Frontiers in Artificial\
    \ Intelligence and Applications, 171*, Wang, P., Goertzel, B. & Franklin, S. (eds.)\
    \ Artificial General Intelligence 2008: Proceedings of the First AGI Conference.\
    \ IOS Press, pp. 275-286. <https://www.johnpollock.us/ftp/PAPERS/General%20Intelligence.pdf>\n\
    - 49. Nirenburg, S., McShane, M., Beale, S., & Catizone, R. (2011). A cognitive\
    \ architecture for simulating bodies and minds. In *AMIA Annual Symposium Proceedings*\
    \ (Vol. 2011, pp. 905-914). American Medical Informatics Association. <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3243225/>\n\
    - 50. Oentaryo, R. J., & Pasquier, M. (2008, June). Towards a novel integrated\
    \ neuro-cognitive architecture (INCA). In *2008 IEEE International Joint Conference\
    \ on Neural Networks (IEEE World Congress on Computational Intelligence)* (pp.\
    \ 1902-1909). IEEE. <https://doi.org/10.1109/IJCNN.2008.4634058>\n- 51. Crowder,\
    \ J.A., Carbone, J.N., Friess, S.A. (2014). Artificial Cognitive System Architectures.\
    \ In: *Artificial Cognition Architectures* (pp. 229-242). Springer, New York,\
    \ NY. [https://doi.org/10.1007/978-1-4614-8072-3\\\\_9](https://doi.org/10.1007/978-1-4614-8072-3_9)\n\
    - 52. Reser, J. E. (2022). A Cognitive Architecture for Machine Consciousness\
    \ and Artificial Superintelligence: Updating Working Memory Iteratively. *arXiv\
    \ preprint arXiv:2203.17255*. <https://doi.org/10.48550/arXiv.2203.17255>\n- 53.\
    \ Voss, P., & Jovanovic, M. (2023). Concepts is All You Need: A More Direct Path\
    \ to AGI. *arXiv preprint arXiv:2309.01622*. <https://doi.org/10.48550/arXiv.2309.01622>\n\
    - 54. Samsonovich, A. V. (2013). Extending Cognitive Architectures. In: Chella,\
    \ A., Pirrone, R., Sorbello, R., & Jóhannsdóttir, K. (eds) *Biologically Inspired\
    \ Cognitive Architectures 2012* (pp. 41-49) Advances in Intelligent Systems and\
    \ Computing, vol 196. Springer, Berlin, Heidelberg. [https://doi.org/10.1007/978-3-642-34274-5\\\
    \\_11](https://doi.org/10.1007/978-3-642-34274-5_11)\n- 55. Sukhobokov, A. A.,\
    \ Gapanyuk, Y. E., & Chernenkiy, V. M. (2020). Consciousness and Subconsciousness\
    \ as a Means of AGI's and Narrow AI's Integration. In: Samsonovich, A. (eds) *Biologically\
    \ Inspired Cognitive Architectures 2019* BICA 2019 (pp. 515-520) Advances in Intelligent\
    \ Systems and Computing, vol 948. Springer, Cham. [https://doi.org/10.1007/978-3-030-25719-4\\\
    \\_66](https://doi.org/10.1007/978-3-030-25719-4_66)\n- 56. Tarassov, V. B., &\
    \ Gapanyuk, Y. E. (2020). Complex Graphs in the Modeling of Multiagent Systems:\
    \ From Goal-Resource Networks to Fuzzy Metagraphs. In: Kuznetsov, S. O., Panov,\
    \ A. I., & Yakovlev, K. S. (eds) *Artificial Intelligence* RCAI 2020 (pp. 177-198)\
    \ Lecture Notes in Computer Science, vol 12412. Springer, Cham. [https://doi.org/10.1007/978-3-030-59535-7\\\
    \\_13](https://doi.org/10.1007/978-3-030-59535-7_13)\n- 57. Sukhobokov, A. A.,\
    \ & Lavrinova, L. I. (2021). AGI Components for Enterprise Management Systems.\
    \ In: Samsonovich, A.V., Gudwin, R.R., & Simões, A.d.S. (eds) *Brain-Inspired\
    \ Cognitive Architectures for Artificial Intelligence: BICA\\*AI 2020* BICA 2020\
    \ (pp. 495-500) Advances in Intelligent Systems and Computing, vol 1310. Springer,\
    \ Cham. [https://doi.org/10.1007/978-3-030-65596-9\\\\_60](https://doi.org/10.1007/978-3-030-65596-9_60)\n\
    - 58. Sukhobokov, A. A., Gapanyuk, Y. E., Zenger, A. S. & Tsvetkova, A. K. (2022).\
    \ The concept of an intelligent data lake management system: machine consciousness\
    \ and a universal data model. *Procedia Computer Science*. *213*, 407-414. <https://doi.org/10.1016/j.procs.2022.11.085>\n\
    - 59. Kruchinin, S. V. (2017). Protogaphs and Archigraphs as a Graphs Generalization.\
    \ *Journal of Scientific Research Publications*, (3(41)), 23-33.\n- [https://www.elibrary.ru/download/elibrary\\\
    \\_30637766\\\\_39362008.pdf](https://www.elibrary.ru/download/elibrary_30637766_39362008.pdf)\
    \ 60. Kruchinin, S. V. (2017). On some generalizations of graphs: multigraphs,\
    \ hypergraphs, metagraphs, flow and port graphs, protographs, archigraphs. *Science\
    \ issues,* (3), 48-67.\n- [https://elibrary.ru/download/elibrary\\\\_32627955\\\
    \\_58725411.pdf](https://elibrary.ru/download/elibrary_32627955_58725411.pdf)\
    \ 61. Samokhvalov, E. N., Revunkov, G. I., & Gapanyuk, Y. E. (2015). Metagraphs\
    \ for Information Systems Semantics and Pragmatics Definition. *Herald of the\
    \ Bauman Moscow State Technical University. Series Instrument Engineering,* (1),\
    \ 83-99. [https://elibrary.ru/download/elibrary\\\\_22978780\\\\_19587991.pdf](https://elibrary.ru/download/elibrary_22978780_19587991.pdf)\n\
    - 62. Chernenkiy, V. M, Gapanyuk, Y. E., Revunkov, G. I., Kaganov, Y. T., Fedorenko,\
    \ Y. S., & Minakova, S. V. (2017). Using metagraph approach for complex domains\
    \ description. In: L. Kalinichenko, Y. Manolopoulos, N. Skvortsov, & V. Sukhomlin\
    \ (eds) *Selected Papers of the 19th International Conference on Data Analytics\
    \ and Management in Data Intensive Domains* DAMDID/RCDL'2017 (pp. 342-349) CEUR\
    \ WORKSHOP PROCEEDINGS. vol 2022.<https://ceur-ws.org/Vol-2022/paper52.pdf>\n\
    - 63. Gapanyuk, Y. (2021). The development of the metagraph data and knowledge\
    \ model. In: Tarassov, V. B., Borisov, V. V., & Kobrinskii B. A. (eds) *Advances\
    \ in Fuzzy Systems and Soft Computing: Selected Contributions to the 10th International\
    \ Conference on \"Integrated Models and Soft Computing in Artificial Intelligence*\
    \ IMSC-2021 (pp. 1-7) CEUR WORKSHOP PROCEEDINGS. vol 2965[. https://ceur-ws.org/Vol-2965/paper01.pdf](https://ceur-ws.org/Vol-2965/paper01.pdf)\n\
    - 64. Burdakov A. (1922). *What is a pseudograph. Definition of a pseudograph.*\
    \ Retrieved from <https://deep-econom.livejournal.com/1042208.html> . Accessed\
    \ August 28, 2023\n- 65. Nlab (1922). *pseudograph.* Retrieved from<https://ncatlab.org/nlab/show/pseudograph>\
    \ . Accessed August 28, 2023\n- 66. Ajzerman, М. А., Vol'skij, V. I., & Litvakov,\
    \ B. М. (1993). Pseudographs and Pseudograph-Based Choice. *Automation and Remote\
    \ Control*, *54*(7), 138-149. <https://www.mathnet.ru/links/7490edc8620d5fb77a071a16db2561e3/at2988.pdf>\n\
    - 67. Chernenkiy, V. M., Gapanyuk, Y. E., Kaganov, Y., Dunin, I., Lyaskovsky,\
    \ M., & Larionov, V. (2018, October). Storing Metagraph Model in Relational, Document-Oriented,\
    \ and Graph Databases. In: [Kalinichenko,](http://synthesis.ipi.ac.ru/synthesis/staff/lak.html)\
    \ L., [Manolopoulos,](http://delab.csd.auth.gr/~manolopo/yannis.html) Y., [Stupnikov,](http://synthesis.ipi.ac.ru/synthesis/staff/ssa.html)\
    \ S., [Skvortsov,](http://synthesis.ipi.ac.ru/synthesis/staff/nskv.html) N., [Sukhomlin,](http://www.sukhomlin.ru/)\
    \ V. (eds) *Selected Papers of the XX International Conference on Data Analytics\
    \ and Management in Data Intensive Domains* DAMDID/RCDL 2018 (pp. 82-89) CEUR\
    \ WORKSHOP PROCEEDINGS. vol 2277[. https://ceur-ws.org/Vol-2277/paper17.pdf](https://ceur-ws.org/Vol-2277/paper17.pdf)\n\
    - 68. Sukhobokov, А. А., Trufanov, V. А., Stolyarov, Yu. А., Sadykov, М. R., &\
    \ Elizarov, О. О. (2021). Distributed Metagraph DBMS Based on Blockchain Technology.\
    \ *Natural and Technical Sciences,* (7), 201-209. <https://doi.org/10.25633/ETN.2021.07.15>\n\
    - 69. Hardeniya, N. (2015). *NLTK essentials*. Packt Publishing. <https://dl.acm.org/doi/abs/10.5555/2846245>\n\
    - 70. Gomez-Perez, J. M., Denaux, R., & Garcia-Silva, A. (2020). *A Practical\
    \ Guide to Hybrid Natural Language Processing: Combining Neural Models and Knowledge\
    \ Graphs for NLP*. Springer. <https://link.springer.com/book/10.1007/978-3-030-44830-1>\n\
    - 71. Liu, Z., Lin, Y., & Sun, M. (2020). *Representation learning for natural\
    \ language processing*. Springer Nature. <https://doi.org/10.1007/978-981-15-5573-2>\n\
    - 72. Gatt, A., & Krahmer, E. (2018). Survey of the state of the art in natural\
    \ language generation: Core tasks, applications and evaluation. *Journal of Artificial\
    \ Intelligence Research*, *61*, 65-170. <https://doi.org/10.1613/jair.5477>\n\n\
    - 73. Todosiev, N., Yankovskiy, V., Andreev, A., & Gapanyuk, Y. (2023). The Conceptual\
    \ Modeling System Based on Metagraph Approach. *Proceedings of the Institute for\
    \ Systems Analysis Russian Academy of Sciences, 73*(1), 176-184. <https://doi.org/10.14357/20790279230120>\n\
    - 74. Liao, W., Rosenhahn, B., Shuai, L., & Yang, M. Y. (2019). Natural language\
    \ guided visual relationship detection. In: *2019 IEEE/CVF Conference on Computer\
    \ Vision and Pattern Recognition Workshops (CVPRW)* (pp. 444-453). IEEE. <https://doi.org/10.1109/CVPRW.2019.00058>\n\
    - 75. Li, Y., Ouyang, W., Zhou, B., Wang, K., & Wang, X. (2017). Scene graph generation\
    \ from objects, phrases and region captions. In: *2017 IEEE International Conference\
    \ on Computer Vision (ICCV)* (pp. 1270-1279). IEEE.<https://doi.org/10.1109/ICCV.2017.142>\n\
    - 76. Dai, B., Zhang, Y., & Lin, D. (2017). Detecting visual relationships with\
    \ deep relational networks. In: *2017 IEEE Conference on Computer Vision and Pattern\
    \ Recognition (CVPR)* (pp. 3298-3308). IEEE.<https://doi.org/10.1109/CVPR.2017.352>\n\
    - 77. Xu, D., Zhu, Y., Choy, C. B., & Fei-Fei, L. (2017). Scene graph generation\
    \ by iterative message passing. In: *2017 IEEE Conference on Computer Vision and\
    \ Pattern Recognition (CVPR)* (pp. 3097-3106). IEEE[. https://doi.org/10.1109/CVPR.2017.330](https://doi.org/10.1109/CVPR.2017.330)\n\
    - 78. Li, Y., Ouyang, W., Zhou, B., Shi, J., Zhang, C., & Wang, X. (2018). Factorizable\
    \ Net: An Efficient Subgraph-Based Framework for Scene Graph Generation. In: Ferrari,\
    \ V., Hebert, M., Sminchisescu, C., & Weiss, Y. (eds) *Computer Vision – ECCV\
    \ 2018*. ECCV 2018 (pp. 346-363) *Lecture Notes in Computer Science*, vol 11205.\
    \ Springer, Cham. [https://doi.org/10.1007/978-3-030-01246-5\\\\_21](https://doi.org/10.1007/978-3-030-01246-5_21)\n\
    - 79. Xu, P., Chang, X., Guo, L., Huang, P. Y., Chen, X., & Hauptmann, A. G. (2020).\
    \ A survey of scene graph: Generation and application. (No 3385) *EasyChair.*\
    \ [https://easychair.org/publications/preprint\\\\_download/SrPK](https://easychair.org/publications/preprint_download/SrPK)\n\
    - 80. Chang, X., Ren, P., Xu, P., Li, Z., Chen, X., & Hauptmann, A. (2023). A\
    \ comprehensive survey of scene graphs: Generation and application. *IEEE Transactions\
    \ on Pattern Analysis and Machine Intelligence*, *45*(1), 1-26[. https://doi.org/10.1109/TPAMI.2021.3137605](https://doi.org/10.1109/TPAMI.2021.3137605)\n\
    - 81. Elasri, M., Elharrouss, O., Al-Maadeed, S., & Tairi, H. (2022). Image generation:\
    \ A review. *Neural Processing Letters*, *54*(5), 4609-4646. <https://doi.org/10.1007/s11063-022-10777-x>\n\
    - 82. Singh, N.K., Raza, K. (2021). Medical Image Generation Using Generative\
    \ Adversarial Networks: A Review. In: Patgiri, R., Biswas, A., Roy, P. (eds) *Health\
    \ Informatics: A Computational Perspective in Healthcare. Studies in Computational\
    \ Intelligence*, vol 932, pp. 77-96. Springer, Singapore. [https://doi.org/10.1007/978-981-15-9735-0\\\
    \\_5](https://doi.org/10.1007/978-981-15-9735-0_5)\n- 83. Wang, W., Luo, Y., Chen,\
    \ Z., Jiang, T., Chen, L., Yang, Y., & Xiao, J. (2023). Taking A Closer Look at\
    \ Visual Relation: Unbiased Video Scene Graph Generation with Decoupled Label\
    \ Learning. *arXiv preprint arXiv*: *2303.13209v1 [cs.CV].* <https://doi.org/10.48550/arXiv.2303.13209>\n\
    - 84. Mahon, L., Giunchiglia, E., Li, B., Lukasiewicz, T. (2020, December). Knowledge\
    \ graph extraction from videos. In: *2020 19th IEEE International Conference on\
    \ Machine Learning and Applications (ICMLA)* (pp. 25-32). IEEE. <https://doi.org/10.1109/ICMLA51294.2020.00014>\n\
    - 85. Liu, C., & Yu, H. (2023). Ai-empowered persuasive video generation: A survey.\
    \ *ACM Computing Surveys, 55*(13s), Article 285, pp. 1-31[. https://doi.org/10.1145/3588764](https://doi.org/10.1145/3588764)\n\
    - 86. Aldausari, N., Sowmya, A., Marcus, N., & Mohammadi, G. (2022). Video generative\
    \ adversarial networks: a review. *ACM Computing Surveys (CSUR)*, *55*(2), Article\
    \ 30, pp. 1- 25. <https://doi.org/10.1145/3487891>\n- 87. Karim, M. R., Ali, H.,\
    \ Das, P., Abdelwaheb, M., & Decker, S. (2022). Question Answering Over Biological\
    \ Knowledge Graph via Amazon Alexa. *arXiv preprint arXiv:2210.06040v1 [cs.AI].*\
    \ <https://doi.org/10.48550/arXiv.2210.06040>\n- 88. Kiranyaz, S., Avci, O., Abdeljaber,\
    \ O., Ince, T., Gabbouj, M., & Inman, D. J. (2021). 1D convolutional neural networks\
    \ and applications: A survey. *Mechanical systems and signal processing*, *151*,\
    \ Article 107398[. https://doi.org/10.1016/j.ymssp.2020.107398](https://doi.org/10.1016/j.ymssp.2020.107398)\n\
    - 89. Dong, L., Xu, S., & Xu, B. (2018, April). Speech-transformer: a no-recurrence\
    \ sequenceto-sequence model for speech recognition. In: *2018 IEEE international\
    \ conference on acoustics, speech and signal processing (ICASSP)* (pp. 5884-5888).\
    \ IEEE. <https://doi.org/10.1109/ICASSP.2018.8462506>\n- 90. Kwon, Y., Heo, H.\
    \ S., Jung, J. W., Kim, Y. J., Lee, B. J., & Chung, J. S. (2022, May). Multi-scale\
    \ speaker embedding-based graph attention networks for speaker diarisation. In:\
    \ *ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal\
    \ Processing (ICASSP)* (pp. 8367-8371). IEEE. <https://doi.org/10.1109/ICASSP43922.2022.9747450>\n\
    - 91. Tan, X., Qin, T., Soong, F., & Liu, T. Y. (2021). A survey on neural speech\
    \ synthesis. *arXiv preprint arXiv:2106.15561v3 [eess.AS].* <https://doi.org/10.48550/arXiv.2106.15561>\n\
    - 92. Kaur, N., & Singh, P. (2023). Conventional and contemporary approaches used\
    \ in text to speech synthesis: a review. *Artificial Intelligence Review 56*(7),\
    \ 5837–5880. <https://doi.org/10.1007/s10462-022-10315-0>\n- 93. Wali, A., Alamgir,\
    \ Z., Karim, S., Fawaz, A., Ali, M. B., Adan, M., & Mujtaba, M. (2022). Generative\
    \ adversarial networks for speech processing: A review. *Computer Speech & Language*,\
    \ *72*, Article 101308[. https://doi.org/10.1016/j.csl.2021.101308](https://doi.org/10.1016/j.csl.2021.101308)\n\
    - 94. Goto, M., Hashiguchi, H., Nishimura, T., & Oka, R. (2003). RWC music database:\
    \ Music genre database and musical instrument sound database. In: *Proceedings\
    \ of the 4th International Conference on Music Information Retrieval*, pp. 229-230.\
    \ <https://archives.ismir.net/ismir2003/paper/000013.pdf>\n- 95. Hashida, M.,\
    \ Nakamura, E., & Katayose, H. (2017, July). Constructing PEDB 2nd Edition: a\
    \ music performance database with phrase information. In *Proceedings of the 14th\
    \ Sound and Music Computing Conference (SMC 2017)* (pp. 359-364). [http://smc2017.aalto.fi/media/materials/proceedings/SMC17\\\
    \\_p359.pdf](http://smc2017.aalto.fi/media/materials/proceedings/SMC17_p359.pdf)\n\
    - 96. Gygi, B., & Shafiro, V. (2010). Development of the database for environmental\
    \ sound research and application (DESRA): Design, functionality, and retrieval\
    \ considerations. *EURASIP Journal on Audio, Speech, and Music Processing*, *2010*,\
    \ Article 654914, pp. 1-12[. https://link.springer.com/content/pdf/10.1155/2010/654914.pdf](https://link.springer.com/content/pdf/10.1155/2010/654914.pdf)\n\
    - 97. Xenakis, I. (1992). *Formalized music: thought and mathematics in composition*\
    \ (No. 6). Pendragon Press.\n- 98. Andreatta, M. (2004). On group-theoretical\
    \ methods applied to music: some compositional and implementational aspects. In:\
    \ G. Mazzola, T. Noll, and E. Puebla (Eds). *Perspectives in Mathematical and\
    \ Computational Music Theory,* EpOs, Osnabr¨uck, pp. 122-162. <http://recherche.ircam.fr/equipes/repmus/moreno/01AndreattaEpos2004.pdf>\n\
    - 99. Papadopoulos, A. (2014). Mathematics and group theory in music. *arXiv preprint\
    \ arXiv:1407.5757 [math.HO].* <https://doi.org/10.48550/arXiv.1407.5757>\n- 100.\
    \ Peng, J., Hu, X., Huang, W., & Yang, J. (2023). What Is a Multi-Modal Knowledge\
    \ Graph: A Survey. *Big Data Research*, Article 100380. <https://doi.org/10.1016/j.bdr.2023.100380>\n\
    - 101. Wilcke, W. X., Bloem, P., de Boer, V., van t Veer, R. H., & van Harmelen,\
    \ F. A. H. (2020). End-to-end entity classification on multimodal knowledge graphs.\
    \ *arXiv preprint arXiv:2003.1238[3v1](https://arxiv.org/abs/2003.12383v1) [cs.AI].*\
    \ <https://doi.org/10.48550/arXiv.2003.12383>\n- 102. Park, S. M., & Kim, Y. G.\
    \ (2023). Visual language integration: A survey and open challenges. *Computer\
    \ Science Review*, *48*, Article 100548. <https://doi.org/10.1016/j.cosrev.2023.100548>\n\
    - 103. DB-Engines. (2023). *DBMS popularity broken down by database model Number\
    \ of systems per category, August 2023*. Retrieved fro[m https://db-engines.com/en/ranking\\\
    \\_categories](https://db-engines.com/en/ranking_categories) . Accessed August\
    \ 8, 2023\n\n- 104. Cambazoglu, B. B., & Baeza-Yates, R. (2022). Scalability challenges\
    \ in web search engines. Springer Nature. https://doi.org/10.1007/978-3-031-02298-2\n\
    - 105. Hilger, J., & Wahl, Z. (2022). Enterprise Search. In: *Making Knowledge\
    \ Management Clickable*. (pp. 163-179). Springer, Cham[. https://doi.org/10.1007/978-3-030-92385-3\\\
    \\_9](https://doi.org/10.1007/978-3-030-92385-3_9)\n- 106. Bowers, A., & Kalton,\
    \ N. J. (2014). *An introductory course in functional analysis.* Springer. <https://doi.org/10.1007/978-1-4939-1945-1>\n\
    - 107. Lee, G. T. (2018). *Abstract algebra: An introductory course.* Springer.\
    \ https://doi.org/10.1007/978-3-319-77649-1\n- 108. Körner, P., Leuschel, M.,\
    \ Barbosa, J., Costa, V. S., Dahl, V., Hermenegildo, M. V., ... , & Ciatto, G.\
    \ (2022). Fifty years of Prolog and beyond. *Theory and Practice of Logic Programming*,\
    \ *22*(6), 776-858. <https://doi.org/10.1017/S1471068422000102>\n- 109. Sowa,\
    \ J. F. (1992). Semantic networks. Encyclopedia of artificial intelligence, 2,\
    \ 1493- 1511. <http://www.jfsowa.com/pubs/semnet.pdf>\n- 110. Karp, P. D. (1992).\
    \ *The design space of frame knowledge representation systems.* SRI International.\
    \ <https://redirect.cs.umbc.edu/courses/771/spring04/papers/karp-freview.pdf>\n\
    - 111. Weaver, M. T., France, R. K., Chen, Q. F., & Fox, E. A. (1989). Using a\
    \ frame‐based language for information retrieval. *International Journal of Intelligent\
    \ Systems*, *4*(3), 223- 257.<https://doi.org/10.1002/int.4550040303>\n- 112.\
    \ Hernandez, G. B. (2017). The languages of relevant logic: a model-theoretic\
    \ perspective. The thesis for the degree of Doctor of Philosophy at the University\
    \ of Otago, Dunedin, New Zealand [https://ourarchive.otago.ac.nz/bitstream/handle/10523/7068/BadiaHernan](https://ourarchive.otago.ac.nz/bitstream/handle/10523/7068/BadiaHernandezGuillermo2016PhD.pdf?sequence=1&isAllowed=y)[dezGuillermo2016PhD.pdf?sequence=1&isAllowed=y](https://ourarchive.otago.ac.nz/bitstream/handle/10523/7068/BadiaHernandezGuillermo2016PhD.pdf?sequence=1&isAllowed=y)\n\
    - 113. Ehrlinger, L., & Wöß, W. (2016). Towards a definition of knowledge graphs.\
    \ In: [Martin,](http://aksw.org/MichaelMartin.html)  М., [Cuquet,](http://mcuquet.github.io/)\
    \ М., & Folmer, E. (eds) *Posters&Demos@SEMANTiCS 2016 and SuC-CESS'16 Workshop*\
    \ (pp. 1-4). SEMANTiCS 2016. CEUR WORKSHOP PROCEEDINGS. vol 1695[. https://ceur-ws.org/Vol-1695/paper4.pdf](https://ceur-ws.org/Vol-1695/paper4.pdf)\n\
    - 114. ISO. (2018). *INTERNATIONAL STANDARD ISO/IEC 24707:2018 Information technology\
    \ — Common Logic (CL) — A framework for a family of logic-based languages.* Retrieved\
    \ fro[m https://www.iso.org/standard/66249.html](https://www.iso.org/standard/66249.html)\
    \ . Accessed August 12, 2023\n- 115. Guha, R. V., & Lenat, D. B. (1991). CYC:\
    \ A mid-term report. *Applied Artificial Intelligence an International Journal*,\
    \ *5*(1), 45-86. <https://doi.org/10.1080/08839519108927917>\n- 116. De Cat, B.,\
    \ Bogaerts, B., Bruynooghe, M., Janssens, G., & Denecker, M. (2018). Predicate\
    \ logic as a modeling language: the IDP system. In: Kifer, M., & Liu, Y. A. (Eds.).\
    \ *Declarative Logic Programming: Theory, Systems, and Applications* (pp. 279-323).\
    \ Machinery and Morgan & Claypool. <https://doi.org/10.1145/3191315.3191321>\n\
    - 117. KSL.Stanford (1992). *Knowledge Interchange Format (KIF).* Retrieved from\
    \ [https://web.archive.org/web/20070212094221/http://www.ksl.stanford.edu/knowledge](https://web.archive.org/web/20070212094221/http:/www.ksl.stanford.edu/knowledge-sharing/kif/)[sharing/kif/](https://web.archive.org/web/20070212094221/http:/www.ksl.stanford.edu/knowledge-sharing/kif/)\
    \ Accessed August 13, 2023\n- 118. Genesereth, M. R., & Fikes R. E. (1992). *Knowledge\
    \ Interchange Format. Version 3.0. Reference Manual.* Computer Science Department\
    \ at Stanford University <https://www.cs.auckland.ac.nz/courses/compsci367s2c/resources/kif.pdf>\n\
    - 119. W3C. (2014). RDF 1.1 *Concepts and Abstract Syntax.* Retrieved from <https://www.w3.org/TR/rdf11-concepts/>.\
    \ Accessed August 12, 2023\n- 120. W3C. (2012). *OWL 2 Web Ontology Language Document\
    \ Overview (Second Edition)* Retrieved from <https://www.w3.org/TR/2012/REC-owl2-overview-20121211/>\
    \ . Accessed August 12, 2023\n- 121. Heflin, J., & Hendler, J. (2001). A portrait\
    \ of the Semantic Web in action. *IEEE Intelligent Systems*, *16*(2), 54-59. https://doi.org/\
    \ [10.1109/5254.920600](https://doi.org/10.1109/5254.920600)\n- 122. Guizzardi,\
    \ G., Botti Benevides, A., Fonseca, C. M., Porello, D., Almeida, J. P. A., & Sales,\
    \ T. P. (2022). UFO: Unified foundational ontology. *Applied ontology*, *17*(1),\
    \ 167-210. <https://doi.org/10.3233/AO-210256>\n- 123. Guizzardi, G., & Wagner,\
    \ G. (2012, December). Conceptual simulation modeling with Onto-UML advanced tutorial.\
    \ In: *Proceedings of the 2012 Winter Simulation Conference* (WSC) (pp. 1-15).\
    \ IEEE. <https://doi.org/10.1109/WSC.2012.6465133>\n- 124. Jarrar, M., & Meersman,\
    \ R. (2008). Ontology Engineering The DOGMA Approach. In: Dillon, T.S., Chang,\
    \ E., Meersman, R., & Sycara, K. (eds) *Advances in Web Semantics I: Ontologies,\
    \ Web Services and Applied Semantic Web*, 7-34. Lecture Notes in Computer Science,\
    \ vol 4891. Springer[. https://doi.org/10.1007/978-3-540-89784-2\\\\_2](https://doi.org/10.1007/978-3-540-89784-2_2)\n\
    - 125. Farquhar, A., Fikes, R., & Rice, J. (1997). Tools for assembling modular\
    \ ontologies in Ontolingua. In: [Kuipers,](https://dblp.org/pid/k/BenjaminKuipers.html)\
    \ B., & [Webber,](https://dblp.org/pid/95/4733.html) B. L. (eds). *Proceedings\
    \ of the Fourteenth National Conference on Artificial Intelligence and Ninth Innovative\
    \ Applications of Artificial Intelligence Conference, AAAI 97*, 454-459.\n- <https://redirect.cs.umbc.edu/courses/771/current/papers/KSL-97-03.pdf>\
    \ 126. MacGregor, R., & Burstein, M. H. (1991). Using a description classifier\
    \ to enhance knowledge representation. *IEEE Expert*, *6*(3), 41-46[. https://doi.org/10.1109/64.87683](https://doi.org/10.1109/64.87683)\n\
    - 127. Rattanasawad, T., Saikaew, K. R., Buranarach, M., & Supnithi, T. (2013,\
    \ September). A review and comparison of rule languages and rule-based inference\
    \ engines for the Semantic Web. In: *2013 International Computer Science and Engineering\
    \ Conference (ICSEC)* (pp. 1-6). IEEE[. https://doi.org/10.1109/ICSEC.2013.6694743](https://doi.org/10.1109/ICSEC.2013.6694743)\n\
    - 128. Riley, G., & Giarratano, J. C. (2005). *Expert systems: principles and\
    \ programming.* Thomson Course Technology.\n- 129. Varlamov, O. O. (2018). Wi!\
    \ Mi expert system shell as the novel tool for building knowledge-based systems\
    \ with linear computational complexity. *International Review of Automatic Control*,\
    \ *11*(6), 314-325. <https://doi.org/10.15866/ireaco.v11i6.15855>\n- 130. Popov,\
    \ I. A., Erokhin, I. A., Sukhobokov, A. A., Gromozdov, D. R., & Belousov, E. A.\
    \ (2022). An implementation of different minimal consciousness's variants for\
    \ a cyber-physical system. *Procedia Computer Science*, *213*, 370-376. <http://doi.org/10.1016/j.procs.2022.11.080>\n\
    - 131. Gross, M., & Lentin, A. (2012). *Introduction to formal grammars.* Springer\
    \ Science & Business Media.\n- 132. Poelmans, J., Kuznetsov, S. O., Ignatov, D.\
    \ I., & Dedene, G. (2013). Formal concept analysis in knowledge processing: A\
    \ survey on models and techniques. *Expert systems with applications*, *40*(16),\
    \ 6601-6623. <https://doi.org/10.1016/j.eswa.2013.05.007>\n- 133. Vykhovanets,\
    \ V. S. (2021, May). The notional model of knowledge representation. *Journal\
    \ of physics: conference series 1864*, Article 012058. IOP Publishing. <https://doi.org/10.1088/1742-6596/1864/1/012058>\n\
    - 134. Chuvikov, D. A., & Nazarov, K. V. (2016). Designing algorithms for solving\
    \ physics problems on the basis of mivar approach. *International Journal of Advanced\
    \ Studies*, *6*(3), 31- 50. <https://doi.org/10.12731/2227-930X-2016-3-31-50>\n\
    - 135. Varlamov, O. O. (2002). *Evolutionary databases and knowledge for adaptive\
    \ synthesis of intelligent systems. Mivar information space.* Radio and communications,\
    \ Moscow. [https://elibrary.ru/download/elibrary\\\\_21237254\\\\_68431832.pdf](https://elibrary.ru/download/elibrary_21237254_68431832.pdf)\n\
    - 136. Boccaletti, S., Latora, V., Moreno, Y., Chavez, M., & Hwang, D.-U. (2006).\
    \ Complex networks: Structure and dynamics. *Physics Reports*, *424*(4–5), 175-308.\
    \ <https://doi.org/10.1016/j.physrep.2005.10.009>\n- 137. Reisig, W. (2012). *Petri\
    \ nets: an introduction.* Springer. [https://doi.org/10.1007/978-3-](https://doi.org/10.1007/978-3-642-69968-9)\
    \ [642-69968-9](https://doi.org/10.1007/978-3-642-69968-9)\n- 138. Hadjicostis,\
    \ C. N. (2020). *Estimation and inference in discrete event systems: A Model-Based\
    \ Approach with Finite Automata.* Springer International Publishing. <https://doi.org/10.1007/978-3-030-30821-6>\n\
    - 139. Choi, B. K., & Kang, D. (2013). *Modeling and simulation of discrete event\
    \ systems*. John Wiley & Sons.\n\n- 140. Samsonovich, A. V. (2009, October). The\
    \ Constructor metacognitive architecture. In *2009 AAAI Fall Symposium Series*[.\
    \ https://cdn.aaai.org/ocs/999/999-4272-1-PB.pdf](https://cdn.aaai.org/ocs/999/999-4272-1-PB.pdf)\n\
    - 141. Osawa, M., Omori, T., Takahashi, K., Arakawa, N., Sakai, N., Imai, M.,\
    \ & Yamakawa, H. (2019). Function Map-Driven Development for AGI. In: Samsonovich,\
    \ A. (eds) *Biologically Inspired Cognitive Architectures 2018* BICA 2018 (pp.\
    \ 239–244) Advances in Intelligent Systems and Computing, vol 848. Springer, Cham.\
    \ https://doi.org/10.1007/978-3-319-99316-4\\_32\n- 142. Shanahan, M. (2006).\
    \ A cognitive architecture that combines internal simulation with a global workspace.\
    \ *Consciousness and cognition*, *15*(2), 433-449. <https://doi.org/10.1016/j.concog.2005.11.005>\n\
    - 143. Chella, A., Frixione, M., & Gaglio, S. (2008). A cognitive architecture\
    \ for robot self-consciousness. *Artificial intelligence in medicine*, *44*(2),\
    \ 147-154. <https://doi.org/10.1016/j.artmed.2008.07.003>\n- 144. Becker, T.,\
    \ Fabro, J. A., Oliveira, A. S. D., & Reis, L. P. (2015), Adding Conscious Aspects\
    \ in Virtual Robot Navigation through Baars-Franklin's Cognitive Architecture.\
    \ In: *2015 IEEE International Conference on Autonomous Robot Systems and Competitions*.\
    \ (pp. 204- 209). IEEE. <https://doi.org/10.1109/ICARSC.2015.34>\n- 145. Gudwin,\
    \ R., Paraense, A., de Paula, S. M., Fróes, E., Gibaut, W., Castro, E., Figueiredo,\
    \ V,, & Raizer, K. (2017). The multipurpose enhanced cognitive architecture (MECA).\
    \ *Biologically Inspired Cognitive Architectures*, *22*, 20-34. <https://doi.org/10.1016/j.bica.2017.09.006>\n\
    - 146. Dyachenko, Y., Nenkov, N., Petrova, M., Skarga-Bandurova, I., & Soloviov,\
    \ O. (2018). Approaches to cognitive architecture of autonomous intelligent agent.\
    \ *Biologically Inspired Cognitive Architectures*, *26*, 130-135.<https://doi.org/10.1016/j.bica.2018.10.004>\n\
    - 147. Chella, A., & Pipitone, A. (2020). A cognitive architecture for inner speech.\
    \ *Cognitive Systems Research*, 59, 287-292. <https://doi.org/10.1016/j.cogsys.2019.09.010>\n\
    - 148. Burrafato, M., & Florio, L. (2012). *A cognitive architecture based on\
    \ an amygdala-thalamo-cortical model for developing new goals and behaviors: application\
    \ in humanoid robotics.* Artificial Intelligence and Robotics Laboratory of the\
    \ Polytechnic of Milan. [https://www.politesi.polimi.it/retrieve/a81cb05a-32b0-616b-e053-](https://www.politesi.polimi.it/retrieve/a81cb05a-32b0-616b-e053-1605fe0a889a/2012_10_Burrafato_Florio.pdf)\
    \ [1605fe0a889a/2012\\\\_10\\\\_Burrafato\\\\_Florio.pdf](https://www.politesi.polimi.it/retrieve/a81cb05a-32b0-616b-e053-1605fe0a889a/2012_10_Burrafato_Florio.pdf)\n\
    - 149. Lanza, F. (2021). *Human-Robot Teaming Interaction: a Cognitive Architecture\
    \ Solution.* University of Palermo. Ph.D. Thesis.\n- [https://iris.unipa.it/retrieve/handle/10447/479089/1105689/Tesi\\\
    \\_di\\\\_Dottorato\\\\_lanza.pdf](https://iris.unipa.it/retrieve/handle/10447/479089/1105689/Tesi_di_Dottorato_lanza.pdf)\
    \ 150. Chatila, R., Renaudo, E., Andries, M., Chavez-Garcia, R. O., Luce-Vayrac,\
    \ P., Gottstein,\n- R., ... & Khamassi, M. (2018). Toward self-aware robots. *Frontiers\
    \ in Robotics and AI, 5*, Article 88. <https://doi.org/10.3389/frobt.2018.00088>\n\
    - 151. Augello, A., Gaglio, S., Infantino, I., Maniscalco, U., Pilato, G., & Vella,\
    \ F. (2023). Roboception and adaptation in a cognitive robot. *Robotics and Autonomous\
    \ Systems, 164*, Article 104400. <https://doi.org/10.1016/j.robot.2023.104400>\n\
    - 152. Shylaja, K. R., Vijayakumar, M. V., Davis, D. N., & Prasad, E. V. (2013).\
    \ Cognitive Architecture to Evolve Conscious Cognitive Tasks into Common Sense\
    \ Actions on Agents. In: *Proceedings of the World Congress on Engineering and\
    \ Computer Science* (Vol. 1, pp. 383-388)[. https://www.iaeng.org/publication/WCECS2013/WCECS2013\\\
    \\_pp383-388.pdf](https://www.iaeng.org/publication/WCECS2013/WCECS2013_pp383-388.pdf)\n\
    - 153. Starzyk, J. A., & Graham, J. (2017). MLECOG: Motivated learning embodied\
    \ cognitive architecture. *IEEE Systems Journal*, *11*(3), 1272-1283. <https://doi.org/10.1109/JSYST.2015.2442995>\n\
    - 154. Chatterjee, S. (December 14, 2012). The Cognitive Architecture for Artificial\
    \ Consciousness: Machine Mental States. *Social Science Research Network*. <http://doi.org/10.2139/ssrn.2189382>\n\
    - 155. Huyck, C. R. (2017, October). The neural cognitive architecture. In *2017\
    \ AAAI Fall Symposium Series*[. https://cdn.aaai.org/ocs/15954/15954-69912-1-PB.pdf](https://cdn.aaai.org/ocs/15954/15954-69912-1-PB.pdf)\n\
    - 156. Faghihi, U., Fournier-Viger, P., Nkambou, R. (2013). CELTS: A Cognitive\
    \ Tutoring Agent with Human-Like Learning Capabilities and Emotions. In: Peña-Ayala,\
    \ A. (eds) *Intelligent and Adaptive Educational-Learning Systems. Smart Innovation,\
    \ Systems and Technologies*, vol 17, pp. 339-365. Springer, Berlin, Heidelberg.\
    \ [https://doi.org/10.1007/978-3-642-30171-1\\\\_14](https://doi.org/10.1007/978-3-642-30171-1_14)\n\
    - 157. Augello, A., Infantino, I., Lieto, A., Pilato, G., Rizzo, R., & Vella,\
    \ F. (2016). Artwork creation by a cognitive architecture integrating computational\
    \ creativity and dual process approaches. *Biologically inspired cognitive architectures*,\
    \ *15*, 74-86. <https://doi.org/10.1016/j.bica.2015.09.007>\n- 158. Cerone, A.\
    \ (2018). Towards a Cognitive Architecture for the Formal Analysis of Human Behaviour\
    \ and Learning. In: Mazzara, M., Ober, I., Salaün, G. (eds) *Software Technologies:\
    \ Applications and Foundations.* STAF 2018. Lecture Notes in Computer Science\
    \ (pp. 216-232), vol 11176. Springer, Cham[. https://doi.org/10.1007/978-3-030-04771-9\\\
    \\_17](https://doi.org/10.1007/978-3-030-04771-9_17)\n- 159. Garrido-Mercháin,\
    \ E. C., Molina, M., & Mendoza-Soto, F. M. (2022). A global workspace model implementation\
    \ and its relations with philosophy of mind. *Journal of Artificial Intelligence\
    \ and Consciousness*, *9*(01), 1-28. <http://dx.doi.org/10.1142/S270507852150020X>\n\
    - 160. Graham, J., & Starzyk, J. A. (2013, April). Transitioning from motivated\
    \ to cognitive agent model. In: *2013 IEEE Symposium on Computational Intelligence\
    \ for Human-like Intelligence (CIHLI)* (pp. 9-16). IEEE. <https://doi.org/10.1109/CIHLI.2013.6613259>\n\
    - 161. Chernenkiy, V., Gapanyuk, Y., Terekhov, V., Revunkov, G., & Kaganov, Y.\
    \ (2018). The hybrid intelligent information system approach as the basis for\
    \ cognitive architecture. *Procedia computer science*, *145*, 143-152. <https://doi.org/10.1016/j.procs.2018.11.022>\n\
    - 162. Wiedermann, J., & Leeuwen, J. V. (2019, July). Finite state machines with\
    \ feedback: an architecture supporting minimal machine consciousness. In: *Conference\
    \ on Computability in Europe* (pp. 286-297). Springer, Cham[. https://doi.org/10.1007/978-3-319-59740-9\\\
    \\_2](https://doi.org/10.1007/978-3-319-59740-9_2)\n- 163. Wiedermann, J., & Leeuwen,\
    \ J. V. (2021, January). Towards Minimally Conscious Cyber-Physical Systems: A\
    \ Manifesto. In: *International Conference on Current Trends in Theory and Practice\
    \ of Informatics* (pp. 43-55). Springer, Cham. [https://doi.org/10.1007/978-3-030-67731-2\\\
    \\_4](https://doi.org/10.1007/978-3-030-67731-2_4)\n- 164. Henninger, A. E., Jones,\
    \ R. M., & Chown, E. (2003, July). Behaviors that emerge from emotion and cognition:\
    \ implementation and evaluation of a symbolic-connectionist architecture. In:\
    \ *Proceedings of the second international joint conference on Autonomous agents\
    \ and multiagent systems* (pp. 321-328)[. https://doi.org/10.1145/860575.860627](https://doi.org/10.1145/860575.860627)\n\
    - 165. Ekanayake, H., Karunarathna, D. D., & Hewagamage, K. P. (2006). Behavior-based\
    \ Cognitive Architecture for Meditative E-Learning. *Innovations for a Knowledge\
    \ Economy*. Proceedings of the 8th International Information Technology Conference\
    \ IITC2006, pp. 80-88. Colombo Sri Lanka: Infotel Lanka Society Ltd, 2008. [https://citeseerx.ist.psu.edu/docu](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=0fa059b2640e113348d8fc126095142ed9dd04f9#page=87)[ment?repid=rep1&type=pdf&doi=0fa059b2640e113348d8fc126095142ed9dd04f9#page](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=0fa059b2640e113348d8fc126095142ed9dd04f9#page=87)\
    \ [=87](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=0fa059b2640e113348d8fc126095142ed9dd04f9#page=87)\n\
    - 166. van Ments, L., Treur, J. (2022). Dynamics, Adaptation and Control for Mental\
    \ Models: A Cognitive Architecture. In: Treur, J., Van Ments, L. (eds) *Mental\
    \ Models and Their Dynamics, Adaptation, and Control.* Studies in Systems, Decision\
    \ and Control, vol 394, pp. 3-26. Springer, Cham[. https://doi.org/10.1007/978-3-030-85821-6\\\
    \\_1](https://doi.org/10.1007/978-3-030-85821-6_1)\n- 167. Burger, J. R. (2008).\
    \ Cognitive Architecture for Direction of Attention Founded on Subliminal Memory\
    \ Searches, Pseudorandom and Nonstop. *arXiv preprint arXiv:0805.3126*. <https://doi.org/10.48550/arXiv.0805.3126>\n\
    - 168. Scheutz, M., Williams, T., Krause, E., Oosterveld, B., Sarathy, V., Frasca,\
    \ T. (2019). An Overview of the Distributed Integrated Cognition Affect and Reflection\
    \ DIARC Architecture. In: Aldinhas Ferreira, M., Silva Sequeira, J., Ventura,\
    \ R. (eds) *Cognitive Architectures. Intelligent Systems, Control and Automation:\
    \ Science and Engineering*, vol 94, pp. 165-193. Springer, Cham. [https://doi.org/10.1007/978-3-319-97550-4\\\
    \\_11](https://doi.org/10.1007/978-3-319-97550-4_11)\n\n- 169. Chernavskaya, O.\
    \ To the Problem of Digital Immortality. *Social Science Research Network*. <https://doi.org/10.2139/ssrn.4593718>\n\
    - 170. Nagoev, Z., Nagoeva, O., & Gurtueva, I. (2020). Multi-agent neurocognitive\
    \ models of semantics of spatial localization of events. *Cognitive Systems Research*,\
    \ *59*, 91-102. https://doi.org/10.1016/j.cogsys.2019.09.015\n- 171. Langley,\
    \ P., & Choi, D. (2006, July). A unified cognitive architecture for physical agents.\
    \ In: *AAAI'06 Proceedings of the National Conference on Artificial Intelligence*\
    \ (Vol. 2, pp. 1469-1474). AAAI Pres[s.http://www.isle.org/~langley/papers/icarus.aaai06.pdf](http://www.isle.org/~langley/papers/icarus.aaai06.pdf)\n\
    - 172. Longo, C. F., Santoro, C., Asmundo, M. N., Santamaria, D. F., & Cantone,\
    \ D. (2021). SW-CASPAR: Reactive-Cognitive Architecture based on Natural Language\
    \ Processing for the task of Decision-Making in the Open-World Assumption. In:\
    \ [Calegari,](https://www.unibo.it/sitoweb/roberta.calegari/en) R., [Ciatto,](https://www.unibo.it/sitoweb/giovanni.ciatto/en)\
    \ G., [Denti,](https://www.unibo.it/sitoweb/enrico.denti/en) E., [Omicini,](https://www.unibo.it/sitoweb/andrea.omicini/en)\
    \ A., [& Sartor,](https://www.unibo.it/sitoweb/giovanni.sartor/en) G. (eds) 22nd\
    \ Workshop \"From Objects to Agents\" (pp. 178-193). WOA 2021. CEUR WORKSHOP PROCEEDINGS.\
    \ vol 2963. <https://ceur-ws.org/Vol-2963/paper10.pdf>\n- 173. Kahneman, D. 2011.\
    \ Thinking, fast and slow. Macmillan. <http://www.math.chalmers.se/~ulfp/Review/fastslow.pdf>\n\
    - 174. Rauterberg, M. (2010). Emotions: The Voice of the Unconscious. In: Yang,\
    \ H.S., Malaka, R., Hoshino, J., Han, J.H. (eds) *Entertainment Computing - ICEC\
    \ 2010*. ICEC 2010. (pp. 205-215). Lecture Notes in Computer Science, vol 6243.\
    \ Springer, Berlin, Heidelberg. [https://doi.org/10.1007/978-3-642-15399-0\\\\\
    _19](https://doi.org/10.1007/978-3-642-15399-0_19)\n- 175. Henninger, A. E., Chown,\
    \ E., & Jones, R. (2004). *Emotional synthetic forces*. US Army Research Institute\
    \ for the Behavioral and Social Sciences. [https://citeseerx.ist.psu.edu/docu](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=7b26c84c3240cc00c14c4ed4393c093874d13a9f)[ment?repid=rep1&type=pdf&doi=7b26c84c3240cc00c14c4ed4393c093874d13a9f](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=7b26c84c3240cc00c14c4ed4393c093874d13a9f)\n\
    - 176. Wahl, S., & Spada, H. (2000). Children IS Reasoning about Intentions, Beliefs\
    \ and Behaviour. *Cognitive Science Quarterly, 1*(1), 3–32. <https://psycnet.apa.org/record/2002-18784-001>\n\
    - 177. Lewis, S. C. (2004). *Computational Models of Emotion and Affect*, PhD\
    \ Thesis, Computer Science, University of Hull.\n\t- <https://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.417166>\n\
    - 178. Low, J., Apperly, I. A., Butterfill, S. A., & Rakoczy, H. (2016). Cognitive\
    \ architecture of belief reasoning in children and adults: A primer on the two‐systems\
    \ account*. Child Development Perspectives, 10*(3), 184*-189.* <https://doi.org/10.1111/cdep.12183>\n\
    - 179. Kodipalli, A. (2018). Cognitive architecture to analyze the effect of intrinsic\
    \ motivation with metacognition over extrinsic motivation on swarm agents. *International\
    \ Journal of Electrical and Computer Engineering*, *8*(5), 3984-3990. <https://doi.org/10.11591/ijece.v8i5.pp3984-3990>\n\
    - 180. Foltyn, L., Tozicka, J., Rollo, M., Pechoucek, M., & Jisl, P. (2006, June).\
    \ Reflective-cognitive architecture: From abstract concept to self-adapting agent.\
    \ In: *IEEE Workshop on Distributed Intelligent Systems: Collective Intelligence\
    \ and Its Applications (DIS'06)* (pp. 326-334). IEEE. https://doi.org/10.1109/DIS.2006.62\n\
    - 181. Ritter, F. E., Bittner, J. L., Kase, S. E., Evertsz, R., Pedrotti, M.,\
    \ & Busetta, P. (2012). CoJACK: A high-level cognitive architecture with demonstrations\
    \ of moderators, variability, and implications for situation awareness. *Biologically\
    \ Inspired Cognitive Architectures, 1*, 2-13[. https://doi.org/10.1016/j.bica.2012.04.004](https://doi.org/10.1016/j.bica.2012.04.004)\n\
    - 182. Patacchiola, M., & Cangelosi, A. (2020). A developmental cognitive architecture\
    \ for trust and theory of mind in humanoid robots. *IEEE Transactions on Cybernetics,\
    \ 52*(3), 1947- 1959*.* https://doi.org[/10.1109/TCYB.2020.3002892](https://doi.org/10.1109/TCYB.2020.3002892)\n\
    - 183. Baskar, J., & Lindgren, H. (2014). Cognitive Architecture of an Agent for\
    \ Human-Agent Dialogues. In: Corchado, J.M., et al. (eds) *Highlights of Practical\
    \ Applications of Hetero-*\n\n*geneous Multi-Agent Systems.* The *PAAMS Collection.\
    \ PAAMS 2014 International Workshops*. (pp. 89-100). Communications in Computer\
    \ and Information Science, vol 430. Springer, Cham[. https://doi.org/10.1007/978-3-319-07767-3\\\
    \\_9](https://doi.org/10.1007/978-3-319-07767-3_9)\n\n- 184. Hudlicka, E. (2002).\
    \ This time with feeling: Integrated model of trait and state effects on cognition\
    \ and behavior. *Applied Artificial Intelligence*, *16*(7-8), 611-641. <https://doi.org/10.1080/08339510290030417>\n\
    - 185. Grassiotto, F., Costa, P. D. P. (2021). CogToM: A Cognitive Architecture\
    \ Implementation of the Theory of Mind. In: *Proceedings of the 13th International\
    \ Conference on Agents and Artificial Intelligence (ICAART 2021).* Vol 2 (pp.\
    \ 546-553). <https://doi.org/10.5220/0010194205460553>\n- 186. Pfeffer, A., &\
    \ Lynn, S.K. (2019). Scruff: A Deep Probabilistic Cognitive Architecture for Predictive\
    \ Processing. In: Samsonovich, A. (eds) *Biologically Inspired Cognitive Architectures\
    \ 2018*. BICA 2018. (pp. 245-259). Advances in Intelligent Systems and Computing,\
    \ vol 848. Springer, Cham[. https://doi.org/10.1007/978-3-319-99316-4\\\\_33](https://doi.org/10.1007/978-3-319-99316-4_33)\n\
    - 187. Longo, C. F., Longo, F., & Santoro, C. (2021). Caspar: Towards decision\
    \ making helpers agents for IoT, based on natural language and first order logic\
    \ reasoning. Engineering Applications of Artificial Intelligence, 104, Article\
    \ 104269. <https://doi.org/10.1016/j.engappai.2021.104269>\n- 188. Gnaneswari,\
    \ G., & Vijayakumar, M. V. (2017). Building a Conversational Agent based on the\
    \ principles of Cognitive Pragmatics using Cognitive Architecture. *International\
    \ Journal of Engineering Research & Technology*, *6*(2), 200-206[. https://www.re](https://www.researchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369_Building_a_Conversational_Agent_based_on_the_principles_of_Cognitive_Pragmatics_using_Cognitive_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent-based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf)[searchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369\\\
    \\_Building\\\\_a\\\\_Con](https://www.researchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369_Building_a_Conversational_Agent_based_on_the_principles_of_Cognitive_Pragmatics_using_Cognitive_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent-based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf)[versational\\\
    \\_Agent\\\\_based\\\\_on\\\\_the\\\\_principles\\\\_of\\\\_Cognitive\\\\_Pragmatics\\\
    \\_using\\\\_Cogni](https://www.researchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369_Building_a_Conversational_Agent_based_on_the_principles_of_Cognitive_Pragmatics_using_Cognitive_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent-based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf)[tive\\\
    \\_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent](https://www.researchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369_Building_a_Conversational_Agent_based_on_the_principles_of_Cognitive_Pragmatics_using_Cognitive_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent-based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf)[based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf](https://www.researchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369_Building_a_Conversational_Agent_based_on_the_principles_of_Cognitive_Pragmatics_using_Cognitive_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent-based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf)\n\
    - 189. Li, H., Liu, X., Jiao, F., Doboli, A., & Doboli, S. (2017). InnovA: a cognitive\
    \ architecture for computational innovation through robust divergence and its\
    \ application for analog circuit design. *IEEE Transactions on Computer-Aided\
    \ Design of Integrated Circuits and Systems, 37*(10), 1943-1956. https://doi.org/10.1109/TCAD.2017.2783344.\n\
    - 190. Heylighen, F. (2011). Life is an Adventure! An Agent-Based Reconciliation\
    \ of Narrative and Scientific Worldviews. *Social Science Research Network*. <http://doi.org/10.2139/ssrn.3075423>\n\
    - 191. Bendaña, J., & Mandelbaum, E. (2021). The fragmentation of belief. In:\
    \ Borgoni, C., Kindermann, D., Onofri, A. (eds.) *The Fragmented Mind* (pp. 78-107)\
    \ Oxford University Press, UK.<https://doi.org/10.1093/oso/9780198850670.003.0004>\n\
    - 192. Egan, A. (2021). Fragmented models of belief. In: Borgoni, C., Kindermann,\
    \ D., Onofri, A. (eds.) *The Fragmented Mind* (pp. 108-134) Oxford University\
    \ Press, UK. <https://doi.org/10.1093/oso/9780198850670.003.0005>\n- 193. Peppas,\
    \ P. (2008). Belief revision. In: van Harmelen, F., Lifschitz, V., & Porter, B.\
    \ (eds). *Handbook of Knowledge Representation* (pp. 317-359). Elsevier. [http://doi.org/10.1016/S1574-6526\\\
    (07\\)03008-8](http://doi.org/10.1016/S1574-6526(07)03008-8)\n- 194. Olsson, E.\
    \ J., & Enqvist, S. (Eds.). (2011). *Belief revision meets philosophy of science.*\
    \ Springer. http://doi.org/10.1007/978-90-481-9609-8\n- 195. Ribeiro, M. M. (2012).\
    \ *Belief revision in non-classical logics.* Springer. <http://doi.org/10.1007/978-1-4471-4186-0>\n\
    - 196. Krinkin, K., Shichkina, Y. (2023). Cognitive Architecture for Co-evolutionary\
    \ Hybrid Intelligence. In: Goertzel, B., Iklé, M., Potapov, A., Ponomaryov, D.\
    \ (eds) *Artificial General Intelligence.* AGI 2022. Lecture Notes in Computer\
    \ Science, vol 13539. (pp. 293-303). Springer, Cham[. https://doi.org/10.1007/978-3-031-19907-3\\\
    \\_28](https://doi.org/10.1007/978-3-031-19907-3_28)\n- 197. van Ments, L., Treur,\
    \ J. (2021). Reflections on dynamics, adaptation and control: a cognitive architecture\
    \ for mental models. *Cognitive Systems Research*, 70, 1-9. <https://doi.org/10.1016/j.cogsys.2021.06.004>\n\
    - 198. Morgan, B. (2010, September). Funk2: a distributed processing language\
    \ for reflective tracing of a large critic-selector cognitive architecture. In:\
    \ *2010 Fourth IEEE International Conference on Self-Adaptive and Self-Organizing\
    \ Systems Workshop* (pp. 269-274). IEEE. <https://doi.org/10.1109/SASOW.2010.56>\n\
    - 199. Jung, Y., Choi, Y., Park, H., Shin, W., & Myaeng, S. H. (2007, August).\
    \ Integrating robot task scripts with a cognitive architecture for cognitive human-robot\
    \ interactions. In: *2007 IEEE International Conference on Information Reuse and\
    \ Integration* (pp. 152-157). IEEE.<https://doi.org/10.1109/IRI.2007.4296613>\n\
    - 200. Larue, O., Poirier, P., Nkambou, R. (2012). A Cognitive Architecture Based\
    \ on Cognitive/Neurological Dual-System Theories. In: Zanzotto, F.M., Tsumoto,\
    \ S., Taatgen, N., Yao, Y. (eds) *Brain Informatics. BI 2012* (pp. 288-299). Lecture\
    \ Notes in Computer Science, vol 7670. Springer, Berlin, Heidelberg. [https://doi.org/10.1007/978-3-642-35139-6\\\
    \\_27](https://doi.org/10.1007/978-3-642-35139-6_27)\n- 201. Liew, P. S., Chin,\
    \ C. L., & Huang, Z. (2009). Development of a computational cognitive architecture\
    \ for intelligent virtual character. *Computer Animation and Virtual Worlds, 20*(2‐3),\
    \ 257-266[. https://doi.org/10.1002/cav.316](https://doi.org/10.1002/cav.316)\n\
    - 202. Treur, J., & Glas, G. (2021). A multi-level cognitive architecture for\
    \ self-referencing, selfawareness and self-interpretation. *Cognitive Systems\
    \ Research, 68*, 125-142. <https://doi.org/10.1016/j.cogsys.2020.10.019>\n- 203.\
    \ Lieto, A., Bhatt, M., Oltramari, A., & Vernon, D. (2018). The role of cognitive\
    \ architectures in general artificial intelligence. *Cognitive Systems Research*,\
    \ *48*, 1-3. <https://doi.org/10.1016/j.cogsys.2017.08.003>\n- 204. Lieto, A.\
    \ (2021). Cognitive design for artificial minds. Routledge, London, New York."
- id: cognitive_bpm_as_an_equalizer_improving_access_and_efficiency_for_employees_with_and_without_cognitive_disabilities_cognitive_bpm_as_an_equalizer_improving_access_and_efficiency_for_employees_with_and_without_cognitive_disabilities
  title: "Cognitive BPM as an Equalizer: Improving Access and Efficiency for\n  Employees\
    \ with (and without) Cognitive Disabilities"
  abstract: 'We examine ProcessGPT, an AI model designed to automate, augment, and
    improve

    business processes, to study the challenges of managing business processes

    within the cognitive limitations of the human workforce, particularly

    individuals with cognitive disabilities. ProcessGPT provides a blueprint for

    designing efficient business processes that take into account human cognitive

    limitations. By viewing this through the lens of cognitive disabilities, we

    show that ProcessGPT improves process usability for individuals with and

    without cognitive disabilities. We also demonstrate that organizations

    implementing ProcessGPT-like capabilities will realize increased productivity,

    morale, and inclusion.'
  url: http://arxiv.org/abs/2401.06375v1
  keywords: '* Knowledge-based systems, Management, Organizations, Organizational
    aspects, Disabilities'
  document: "# **Cognitive BPM as an Equalizer: Improving Access and Efficiency for\
    \ Employees with (and without) Cognitive Disabilities**\n\n#### **Gordon Banks<sup>1</sup>\
    \ , Gates Bierhuizen<sup>2</sup> , Katherine McCrum<sup>3</sup> , and Ellen Wengert<sup>4</sup>**\n\
    \n1,2,4 Systems Engineering Program, George Mason University, Fairfax, VA 22030\
    \ USA\n\n3 Operations Research Program, George Mason University, Fairfax, VA 22030\
    \ USA\n\nCorresponding author: Gordon Banks (e-mail: gbanks7@gmu.edu).\n\n**ABSTRACT**\
    \ We examine ProcessGPT, an AI model designed to automate, augment, and improve\
    \ business processes, to study the challenges of managing business processes within\
    \ the cognitive limitations of the human workforce, particularly individuals with\
    \ cognitive disabilities. ProcessGPT provides a blueprint for designing efficient\
    \ business processes that take into account human cognitive limitations. By viewing\
    \ this through the lens of cognitive disabilities, we show that ProcessGPT improves\
    \ process usability for individuals with and without cognitive disabilities. We\
    \ also demonstrate that organizations implementing ProcessGPT-like capabilities\
    \ will realize increased productivity, morale, and inclusion.\n\n**INDEX TERMS**\
    \ Knowledge-based systems, Management, Organizations, Organizational aspects,\
    \ Disabilities\n\n# **I. INTRODUCTION**\n\nHuman cognitive factors such as perception,\
    \ attention, memory, language, reasoning, processing speed, and executive functions\
    \ [1] have known limitations. [2][3][4][5] In contrast, Artificial intelligence\
    \ (AI) systems transcend many boundaries of human cognition, particularly for\
    \ memory, attention, and executive function. [6][7] Large language models such\
    \ as GPT-4 already outperform humans in language areas such as lexical knowledge,\
    \ grammatical sensitivity, communication ability, naming facility, and fluency.\
    \ [\\[1\\]](#page-0-0)[8]\n\nExploration of AI's cognitive capabilities in the\
    \ context of business process management (BPM) offers insights into knowledge-intensive\
    \ processes that are predominantly driven by human activities. [9] Knowledge-intensive\
    \ processes can only be partially mapped to a process model and commonly vary\
    \ due to circumstances and administrative discretion. [10] Facilitation of these\
    \ processes is within the domain of Cognitive BPM, which manages business processes\
    \ using cognitive computing technologies. [11] We reference other researchers'\
    \ AI model, ProcessGPT, as a practical representation of a Cognitive BPM solution\
    \ (Fig. 1). ProcessGPT is an AI model whose goal is to suggest the best next step\
    \ in a process based on a Process Knowledge Graph and extensive supporting elements.\
    \ [12] While ProcessGPT is capable of process augmentation, automation, and improvement,\
    \ we highlight the challenges faced by employees with cognitive disabilities by\
    \ considering how ProcessGPT can augment their experience.\n\n<span id=\"page-0-0\"\
    ></span>![](_page_0_Figure_10.jpeg)\n\n**FIGURE 1. Relationships between AI, BPM,\
    \ and ProcessGPT elements.**\n\n<span id=\"page-0-1\"></span>Through the use of\
    \ AI-intensive systems, like ProcessGPT, organizations can decrease the administrative\
    \ burden and cognitive load on their employees leading to increased organizational\
    \ productivity (Fig. 2). ProcessGPT's potential as a facilitator for process users\
    \ is profound, particularly in the context of knowledge-intensive processes, which\
    \ rely heavily on human cognitive resources by their nature. Knowledge-intensive\
    \ processes can prove particularly challenging for employees with cognitive disabilities,\
    \ which include autism, ADHD, dyslexia, aphasia, and mild cognitive impairment.\
    \ Cognitive disabilities limit the functional learning, memory, attention, and\
    \ executive functions needed to perform the tasks that comprise knowledgeintensive\
    \ processes. Knowing this, we establish two research questions to investigate\
    \ the nexus of business processes, AI, and cognitive disabilities: 1) How can\
    \ AI-intensive technology be applied to business processes to accommodate individuals\
    \ with cognitive disabilities? and 2) What benefits are likely to be seen from\
    \ accommodating individuals with cognitive disabilities in business processes?\
    \ Through our results we aim to motivate organizations to accommodate people with\
    \ cognitive disabilities in their business processes with the use of AI, which\
    \ will benefit the entire organization, not just personnel with cognitive disabilities.\n\
    \n![](_page_1_Figure_1.jpeg)\n\n**FIGURE 2. Mapping how AI can lead to improved\
    \ organizational productivity**\n\n# **II. BACKGROUND**\n\n## A. *Cognitive Disabilities\
    \ in the Workplace*\n\nAccording to the CDC, approximately 13% of the US population\
    \ has some form of cognitive disability. [13] Individuals with cognitive disabilities\
    \ have significant difficulties relating to:\n\n- 1) learning, communication,\
    \ reading, writing, or math,\n- 2) the ability to understand or process new or\
    \ complex information and learn new skills, with a reduced ability to cope independently,\
    \ and / or\n- <span id=\"page-1-1\"></span>3) memory and attention or visual,\
    \ language, or numerical thinking. [14]\n\nThese individuals face unique challenges\
    \ in the workplace that depend on the cognitive resources required to properly\
    \ execute their tasks. By nature, business processes shift administrative burdens\
    \ to users–and their limited cognitive resources. [15] Navigating many business\
    \ processes involves understanding multi-step procedures, remembering to follow\
    \ up on paperwork, reading dense process documentation, or completing forms with\
    \ ambiguous language and jargon. These tasks require attention to detail, adherence\
    \ to procedures, and effective communication with various parties involved in\
    \ the process. Doing so places demands on users' cognitive functions, reducing\
    \ the time and cognitive resources they have available for other tasks.\n\nGenerally,\
    \ a user's performance decreases as their cognitive load increases, and is a function\
    \ of task complexity, task support, and user capabilities. User capabilities depend\
    \ on cognitive factors such as attention, memory, and processing speed, in addition\
    \ to non-cognitive factors such as experience, training, environmental conditions,\
    \ enthusiasm, organizational culture, fatigue, and stress. [16] For any user of\
    \ a business process, there exists some level of process complexity that will\
    \ exceed their cognitive resources, resulting in cognitive overload. [17][\\[15\\\
    ]](#page-1-0) It follows that this threshold will be lower for a user with a cognitive\
    \ disability performing a task that depends on cognitive factors limited by their\
    \ disability.\n\nThe World Wide Web Consortium (W3C) drafted detailed guidelines\
    \ for making content usable for people with cognitive and learning disabilities.\
    \ [\\[14\\]](#page-1-1) These guidelines are organized by nine key objectives\
    \ that designers should target:\n\n- 1) Help users understand what things are\
    \ and how to use them\n- 2) Help users find what they need\n- 3) Use clear content\
    \ (text, images, and media)\n- 4) Help users avoid mistakes\n- 5) Help users focus\n\
    - 6) Ensure processes do not rely on memory\n- 7) Provide help and support\n-\
    \ 8) Support adaptation and personalization\n- 9) Test with real users\n\nEach\
    \ objective is decomposed into specific guidelines and design patterns. Background\
    \ information is also given. For instance, within \"*Objective 1: Help Users Understand\
    \ What Things are and How to Use Them*,\" the guidelines familiarize the reader\
    \ with the issues that inform this objective:\n\n*Users with cognitive and learning\
    \ disabilities may have trouble with orientation and learning. This can mean people\
    \ get disoriented in a site.*\n\n*Learning new things and remembering new information\
    \ is especially difficult for people with cognitive and learning disabilities.\
    \ They can also struggle or be unable to learn new design patterns. Make controls,\
    \ icons and elements simple and conventional to help.*\n\nDesign patterns that\
    \ support this objective are then given:\n\n- *1) Make the Purpose of Your Page\
    \ Clear*\n- *2) Use a Familiar Hierarchy and Design*\n- *3) Use a Consistent Visual\
    \ Design*\n- *4) Make Each Step Clear*\n- *5) Clearly Identify Controls and Their\
    \ Use*\n- <span id=\"page-1-0\"></span>*6) Make the Relationship Clear Between\
    \ Controls and the Content They Affect*\n- *7) Use Icons that Help the User*\n\
    \nEach design pattern details user needs, what to do to meet those needs, how\
    \ it helps, and provides examples. Overall, the W3C guidelines emphasize using\
    \ familiar design patterns with easily understood content presented in manageable\
    \ chunks, as well as supporting users by anticipating cognitive shortcomings.\n\
    \n#### *B. Knowledge-Intensive Processes*\n\nBPM seeks continuous improvement\
    \ of business processes, [18] and refers to poorly performing or otherwise troublesome\
    \ business processes as unmanaged, [19][20] unstructured, *ad hoc*, or knowledge-intensive\
    \ processes. [21][\\[10\\]](#page-0-1) We adopt the *knowledge-intensive* descriptor\
    \ used to initially describe ProcessGPT.\n\nIn general, business processes require\
    \ users to perform administrative tasks in pursuit of an organizational goal.\
    \ Knowledge-intensive business processes often lack the consistent, clear, and\
    \ complete definition necessary for timely execution toward a goal. [\\[10\\]](#page-0-1)\
    \ As a result, users are required to either remember idiosyncrasies about a process\
    \ or maintain information outside of the very systems intended to manage that\
    \ process. Knowledge-intensive processes thus grow to encompass additional unmanaged\
    \ elements via these mechanisms. [15] Unmanaged elements contribute to a large\
    \ \"digital exhaust\" signature (emails, spreadsheets, documents, forms, chats,\
    \ etc. that contain critical process guidelines, best practices, and policies)\
    \ typical of knowledge-intensive processes. [22] This emergent complexity not\
    \ only constitutes a continual drain on the cognitive resources of all workers,\
    \ reducing overall productivity and morale, its unmanaged nature places the most\
    \ burden on users with cognitive disabilities. Users with limited cognition will\
    \ be the first to experience cognitive overload, with no recourse for accommodation.\n\
    \nThe better users understand these processes, the better their output and, hence,\
    \ their morale. The rules and procedures associated with knowledge-intensive processes\
    \ are frequently associated with negative perceptions that affect both morale\
    \ and output, regardless of whether those perceptions are accurate. [23] Another\
    \ important factor related to employee morale and efficiency is emphasis on high-value\
    \ work. Often when employees are asked about the most frustrating part of their\
    \ jobs, they will mention the amount of time spent on low-value tasks that detracts\
    \ from their primary work. These tasks are in many cases manual, repetitive, and\
    \ can consume a lot of time. [24] Simplifying steps, eliminating confusion, and\
    \ adding transparency to business processes are the key to a more efficient and\
    \ satisfied workforce.\n\nMany have already tried to address these challenges\
    \ through Robotic Process Automation (RPA). RPA typically leverages commercial\
    \ software to automate routine tasks, copying human actions. RPA is a growing\
    \ area that has been proven to save employee time on low-value work. The Federal\
    \ RPA Community of Practice estimates that as of 2021, over 1.4M hours of work\
    \ have been saved due to the implementation of RPA. [25] Industry leaders such\
    \ as Microsoft have been working to facilitate this type of automation by digitizing\
    \ contracts. Microsoft Azure has taken physical paperwork into the cloud which\
    \ opens the door for contract processes to be integrated into more efficient workflows.\
    \ AI is the next logical area where contract processing should and will go. [26]\n\
    \nAI changes the way many industries operate. In contracting, AI can sift through\
    \ an enormous amount of paperwork and understand what the content of each is.\
    \ AI allows organizations an \"all-knowing\" power where information can be queried\
    \ and analytics can be reported, all without the intervention of a human. Additionally,\
    \ it can review contract content for consistency across an organization and assess\
    \ risk by identifying terms that are suboptimal. Ultimately it can perform these\
    \ tasks in a way that is faster and more accurate than a human. [27] This has\
    \ major implications for law firms, as well as innumerable other industries.\n\
    \nProcessGPT can decrease the amount of time spent on knowledge-intensive tasks\
    \ by training it on a large set of business process data. The model can be further\
    \ refined by user input and decisions. The goal is to automate repetitive tasks\
    \ that would otherwise be conducted by human workers. This has potential to greatly\
    \ improve how employees with cognitive disabilities complete their work and provide\
    \ benefit to an organization.\n\n# **III. RELEVANT WORK**\n\nAI technologies already\
    \ demonstrate their effectiveness in assisting individuals with cognitive disabilities,\
    \ improving administrative tasks, and ensuring compliance with accessibility regulations.\n\
    \nOne relevant study [28] focuses on assistive technology for cognitive impairment\
    \ in older individuals, highlighting the importance of compensation systems. These\
    \ systems employ AI planning techniques to introduce flexibility into tasks like\
    \ schedule management, personalized reminders, and guidance for routine tasks\
    \ that improve daily life for these individuals. The system takes on the cognitive\
    \ load associated with internalizing routine but crucial tasks, reducing the need\
    \ for external monitoring and instances of compliance failure. Implementing AI\
    \ in the workplace can enable design principles to assist process users with cognitive\
    \ disabilities by offering timely reminders, tracking tasks to ensure follow-up,\
    \ learning routines, and guiding them through tasks.\n\nA UK study [29] explores\
    \ the use of AI, machine learning (ML), and deep learning (DL) to address regulatory\
    \ compliance challenges faced by financial institutions. These technologies automate\
    \ tasks, process complex information, and reduce cognitive load for users. For\
    \ example, AI-powered voice assistants aid in administrative tasks, scheduling,\
    \ and accessing information, simplifying work responsibilities. DL algorithms\
    \ analyze and interpret data, providing insights and recommendations for informed\
    \ decision-making. These AI technologies empower individuals with cognitive disabilities\
    \ to overcome challenges related to information processing, memory, and task completion,\
    \ leading to increased efficiency and effectiveness. In addition, the use of AI,\
    \ ML, and DL can contribute to compliance with regulations such as Section 508\
    \ by facilitating the development of inclusive interfaces and adaptive technologies.\
    \ Natural language processing capabilities enable voice-controlled interfaces\
    \ that alleviate the need for complex navigation or manual input, while AI algorithms\
    \ accommodate different communication styles and preferences, ensuring information\
    \ accessibility for individuals with cognitive disabilities.\n\n<span id=\"page-2-0\"\
    ></span>A collection of case studies provide compelling evidence for the positive\
    \ impact of reducing administrative work on job satisfaction. Research on U.S.\
    \ physicians [30] revealed that spending less time on administrative tasks is\
    \ associated with higher career satisfaction. Similarly, a study on general practitioners\
    \ [31] highlights how excessive paperwork and bureaucratic interference contributed\
    \ to reduced job satisfaction and increased stress levels. Social workers [32]\
    \ also reported job dissatisfaction linked to paperwork. Additionally, studies\
    \ on public sector employees in Switzerland [33] and China [34] emphasized the\
    \ detrimental effects of red tape on work outcomes, including increased resignation\
    \ rates, decreased job satisfaction, and heightened procrastination behavior.\
    \ A study in Australia makes a case for finding ways to support those with dyslexia\
    \ to prevent job-burnout. The study finds that \"excessive job demands, in the\
    \ absence of supportive job resources and personal resources, leads to poor mental\
    \ health and wellbeing…results seem to suggest that employees with dyslexia face\
    \ challenges in the workplace related to their disability including excessive\
    \ mental exhaustion, and fatigue, leaving them vulnerable to workplace stress\
    \ and job burnout. Improving psycho-social workplace environments, increasing\
    \ job resources, decreasing job demands, and critically influencing work engagement,\
    \ will reduce job burnout and reduce apparent difficulties for individuals with\
    \ dyslexia in the workplace.\" [35] By leveraging AI technologies to automate\
    \ and streamline administrative processes, individuals with cognitive disabilities\
    \ can experience a significant reduction in paperwork, bureaucratic complexities,\
    \ and associated stress. This can lead to improved job satisfaction, allowing\
    \ them to focus more on their core tasks and enhance their overall well-being.\n\
    \nThe findings from a South Korean study [36] highlight the importance of individual-level\
    \ factors, such as job satisfaction and organizational citizenship behavior, in\
    \ predicting organizational performance in both the United States and Korea. This\
    \ suggests that addressing these individual-level factors can lead to improved\
    \ organizational performance. Job satisfaction has been shown to positively influence\
    \ performance outcomes. By improving job satisfaction, organizations can enhance\
    \ employee motivation, commitment, and overall engagement, resulting in improved\
    \ performance. For individuals with cognitive disabilities, AI can play a crucial\
    \ role in improving job satisfaction by accommodating their specific needs and\
    \ providing support tailored to their abilities. AI solutions can be developed\
    \ to streamline administrative tasks, reduce barriers, and enhance accessibility,\
    \ thereby creating a more inclusive and accommodating work environment. This,\
    \ in turn, can improve job satisfaction for individuals with cognitive disabilities,\
    \ leading to enhanced performance for both individuals and organizations.\n\n\
    Organizations like Microsoft are actively working to improve the workplace for\
    \ individuals with cognitive disabilities, exemplifying the significance of applying\
    \ AI to business process management. Microsoft's collaboration with Clover Technologies,\
    \ Concurrency, and Gigi's Playhouse Down syndrome development centers resulted\
    \ in a mixed-reality platform and Azure-based solution that enables individuals\
    \ with cognitive disabilities to engage in meaningful warehouse work. [37] This\
    \ real-world example demonstrates the potential of AI to transform business operations,\
    \ broaden employment opportunities, and empower individuals with cognitive disabilities.\
    \ The progress made by Microsoft and its partners underscores the value and potential\
    \ of AI to foster inclusivity, increase job satisfaction, and enhance performance\
    \ for individuals with cognitive disabilities.\n\nCognitive and learning disabilities\
    \ encompass a wide range of difficulties in cognitive functions, including learning,\
    \ communication, reading, writing, math, understanding complex information, learning\
    \ new skills, coping independently, memory, attention, and specific types of thinking.\
    \ [\\[14\\]](#page-1-1) AI solutions exhibit remarkable capabilities such as perfect\
    \ recall, extensive knowledge, understanding of process-specific language, access\
    \ to historical process data, awareness of task statuses, and identification of\
    \ non-compliant tasks. When comparing human cognition to AI cognition, it is important\
    \ to note that even individuals without cognitive disabilities experience limitations\
    \ in attention, short-term and long-term memory, recall speed, and executive function.\
    \ AI solutions specifically designed to enhance accessibility can alleviate the\
    \ physical and mental burdens for individuals with cognitive disabilities, and\
    \ even have a positive impact on those without such disabilities as a second-order\
    \ effect. This reduction in cognitive load and improved accessibility has the\
    \ potential to increase job satisfaction and ultimately enhance performance, while\
    \ ensuring compliance with regulatory standards.\n\n# **IV. PROCESSGPT CAPABILITIES**\n\
    \nThe architecture proposed in [12] rigorously outlines textual capabilities of\
    \ ProcessGPT and additionally introduces multimodal capabilities that would leverage\
    \ voice, imagery, and video sources to augment and automate business processes.\
    \ Designed as an adaptable AI system and trained using existing organizational\
    \ processes, ProcessGPT would seamlessly integrate into various industries and\
    \ business processes. Here, we study ProcessGPT's functions in a variety of applications\
    \ to better understand the benefits it brings to users with cognitive disabilities.\n\
    \n**Filling Out Forms.** Automatically fills out forms at the request of users.\n\
    \n*Example Process:* Employee onboarding. A form with business jargon confuses\
    \ a new employee. ProcessGPT, understanding the context, recommends the correct\
    \ field value to the user.\n\n*Cognitive Support:* Simplifies the process by filling\
    \ out forms, reducing cognitive load and confusion caused by business jargon.\n\
    \n**Answering Process Questions.** Provides guidance on the next steps in a process.\n\
    \n*Example Process:* Project management. A project management system requires\
    \ a user to manually coordinate tasks outside of the system but does not provide\
    \ guidance. ProcessGPT provides clear, step-by-step guidance when needed.\n\n\
    *Cognitive Support:* Provides clear, step-by-step instructions, aiding individuals\
    \ who may struggle with complex instructions.\n\n**Reminders and Follow-ups.**\
    \ Reminds users to follow up on requests.\n\n*Example Process:* Sales process.\
    \ A CRM system does not provide reminders for follow-ups. ProcessGPT reminds a\
    \ salesperson to follow up with a potential client.\n\n*Cognitive Support:* Provides\
    \ reminders, assisting individuals who may have difficulties with memory or attention.\n\
    \n**Resource Planning.** Analyzes structured data to perform resource planning.\n\
    \n*Example Process:* Team scheduling. A scheduling system is complex and time-consuming.\
    \ ProcessGPT analyzes team members' schedules and skills to assign tasks efficiently.\n\
    \n*Cognitive Support:* Automates complex tasks like resource planning, reducing\
    \ cognitive load and the need for multitasking.\n\n**Email Processing.** Processes\
    \ emails, reducing non-productive time spent on replying, searching, and organizing\
    \ emails.\n\n*Example Process:* Customer service. An email system lacks efficient\
    \ sorting and replying features. ProcessGPT helps a customer service rep respond\
    \ to customer inquiries quickly and effectively.\n\n*Cognitive Support:* Simplifies\
    \ email processing, aiding individuals who may struggle with organization and\
    \ prioritization.\n\n**Voice Transcription.** Transcribes calls and meetings.\n\
    \n*Example Process:* Meeting transcription. A transcription system is slow and\
    \ inaccurate. ProcessGPT accurately transcribes a team meeting and shares the\
    \ notes with all participants.\n\n*Cognitive Support:* Provides transcription\
    \ services, aiding individuals who may have difficulties with auditory processing\
    \ or note-taking.\n\n**Onboarding Assistance.** Assists with onboarding new employees.\n\
    \n*Example Process:* New employee orientation. An orientation system is confusing\
    \ for new employees. ProcessGPT answers a new employee's questions about company\
    \ policies in a clear and understandable way.\n\n*Cognitive Support:* Provides\
    \ clear and understandable answers to questions, aiding individuals who may struggle\
    \ with complex information.\n\n**Task Management.** Helps manage tasks, extract\
    \ data, highlight specific items of interest, and review legal agreements.\n\n\
    *Example Process:* Contract management. A contract management system is complex\
    \ and hard to navigate. ProcessGPT extracts key terms from a contract for review\
    \ in a user-friendly format.\n\n*Cognitive Support:* Simplifies task management,\
    \ aiding individuals who may struggle with organization and prioritization.\n\n\
    **Data Interpretation.** Interprets user data, answers queries, and expedites\
    \ project progress.\n\n*Example Process:* Data analysis. A data analysis system\
    \ is complex and requires advanced skills. ProcessGPT interprets sales data and\
    \ provides a forecast for the next quarter in a simple, understandable format.\n\
    \n*Cognitive Support:* Presents data in a simple, understandable format, aiding\
    \ individuals who may struggle with complex data or numerical thinking.\n\n**Automating\
    \ Repetitive Tasks.** Automates repetitive and generic tasks.\n\n*Example Process:*\
    \ Travel claims. A travel system requires manual data entry. ProcessGPT automatically\
    \ associates credit card charges with travel expenses, creates expenses from receipt\
    \ images, and enables conversational creation of vouchers, saving time and reducing\
    \ errors.\n\n*Cognitive Support:* Automates repetitive tasks, reducing cognitive\
    \ load and the potential for errors.\n\n**User-Centric Guidance.** Provides straightforward,\
    \ comprehensible guidance and process support tailored to the cognitive capabilities\
    \ and needs of each individual process user.\n\n*Example Process:* Onboarding.\
    \ An organization's onboarding process is unclear because it consists of multiple\
    \ independent sub-processes. ProcessGPT provides a user with step-by-step guidance\
    \ that bridges sub-processes.\n\n*Cognitive Support:* Provides clear, step-by-step\
    \ guidance, aiding individuals with limited executive function.\n\n**Intermediary\
    \ for Internal Systems.** Acts as an intermediary between users and internal systems.\n\
    \n*Example Process:* Timekeeping system. A timekeeping system has substantial\
    \ latency. ProcessGPT acts as a responsive front end where the user can input\
    \ their working hours without delays. ProcessGPT then interfaces with the organization's\
    \ timekeeping system in the background.\n\n*Cognitive Support:* Acts as an intermediary\
    \ for complex systems, aiding individuals who have limited attention.\n\n**Drafting\
    \ Email Responses.** Drafts email responses based on user's needs.\n\n*Example\
    \ Process:* Email communication. A user needs to follow up with a colleague. ProcessGPT\
    \ drafts an email for the user based on the context of the follow-up.\n\n*Cognitive\
    \ Support:* Reduces cognitive load by drafting emails, aiding individuals who\
    \ may struggle with written communication.\n\n**Searching Multiple Data Sources.**\
    \ Searches multiple data sources based on conversational guidance from the user.\n\
    \n*Example Process:* Data retrieval. A user needs to find a document but can only\
    \ recall general information about it. ProcessGPT searches through emails, enterprise\
    \ storage, and local storage based on conversational input to find the document.\n\
    \n*Cognitive Support:* Simplifies the process of searching through multiple data\
    \ sources, aiding individuals with limited memory.\n\n**Compiling Data from Disparate\
    \ Sources.** Automatically compiles data from disparate data sources without the\
    \ user having to search and open each one.\n\n*Example Process:* Data compilation.\
    \ A user needs to compile data from different sources for a report. ProcessGPT\
    \ automatically compiles the necessary data, saving the user time and effort.\n\
    \n*Cognitive Support:* Automates the task of compiling data from different sources,\
    \ reducing cognitive load and the potential for errors.\n\n**ProcessGPT Self-Assessment.**\
    \ Automatic evaluation of user experience and response quality based on conversation\
    \ content.\n\n*Example Process:* Procurement. A user needs a procurement form\
    \ drafted to buy a piece of hardware for a project. ProcessGPT automatically drafts\
    \ the form but requires correction.\n\n*Cognitive Support:* Enables seamless testing\
    \ with real users by identifying and implementing corrective feedback. This eliminates\
    \ typical burdens created by process administrators such as surveys and suggestion\
    \ boxes.\n\nWhile this is not an exhaustive list, the table below demonstrates\
    \ a surjective mapping of ProcessGPT capabilities to the key areas established\
    \ by the W3C to make content usable for individuals with cognitive disabilities.\
    \ This demonstrates that ProcessGPT enables knowledge-intensive business processes\
    \ to accommodate a broad range of cognitive disabilities without altering the\
    \ underlying systems.\n\n| CORRELATION OF PROCESSGPT FUNCTIONS WITH COGNITIVE\
    \ DISABILITY<br>ACCOMMODATIONS |                                             \
    \                    |                                                       \
    \                                             |  |  |\n|---------------------------------------------------------------------------------|-----------------------------------------------------------------|----------------------------------------------------------------------------------------------------|--|--|\n\
    | Accommodation                                                              \
    \     |                                                                 | ProcessGPT\
    \ Functions Enabling<br>the Accommodation                                    \
    \             |  |  |\n|                                                     \
    \                            | Help users understand<br>what things are and how\
    \ to<br>use them | Filling Out Forms, Answering<br>Process Questions, Onboarding<br>Assistance,\
    \ User-Centric Guidance |  |  |\n|                                           \
    \                                      | Help users find what they<br>need   \
    \                            | Searching Multiple Data Sources,<br>Compiling Data\
    \ from Disparate<br>Sources                       |  |  |\n|                 \
    \                                                                | Use clear content\
    \ (text,<br>images and media)                   | Intermediary for Internal Systems\
    \                                                                  |  |  |\n|\
    \                                                                            \
    \     | Help users avoid mistakes                                       | Reminders\
    \ and Follow-ups, Task<br>Management, Automating<br>Repetitive Tasks         \
    \              |  |  |\n|                                                    \
    \                             | Help users focus                             \
    \                   | Email Processing, Drafting Email<br>Responses, Resource\
    \ Planning,<br>Data Interpretation           |  |  |\n|                      \
    \                                                           | Ensure processes\
    \ do not<br>rely on memory                       | Reminders and Follow-ups,<br>Searching\
    \ Multiple Data Sources,<br>Voice Transcription               |  |  |\n|     \
    \                                                                            |\
    \ Provide help and support                                        | Answering\
    \ Process Questions,<br>Onboarding Assistance, User<br>Centric Guidance      \
    \              |  |  |\n|                                                    \
    \                             | Support adaptation and<br>personalization    \
    \                   | User-Centric Guidance,<br>Intermediary for Internal Systems\
    \                                        |  |  |\n|                          \
    \                                                       | Test with real users\
    \                                            | ProcessGPT Self-Assessment    \
    \                                                                     |  |  |\n\
    \nTABLE 1 CORRELATION OF PROCESSGPT FUNCTIONS WITH COGNITIVE DISABILITY\n\n# **V.\
    \ QUANTIFYING BENEFITS**\n\nAccommodating individuals with cognitive disabilities\
    \ in knowledge-intensive business processes directly affects process usability,\
    \ which is a quality attribute associated with the user interface of a system.\
    \ [38] Business process usability is captured by quality attributes that fall\
    \ into four categories: quality of function, quality of input & output objects,\
    \ quality of non-human resources, and quality of human resources. Each category\
    \ has numerous dimensions, as defined in [39] and shown in the table below.\n\n\
    | TABLE 2                                  |  |\n|------------------------------------------|--|\n\
    | QUALITY DIMENSIONS OF BUSINESS PROCESSES |  |\n\n| Function          | Input/Output\
    \  | Non-Human<br>Resource | Human<br>Resource |\n|-------------------|---------------|-----------------------|-------------------|\n\
    | Suitability       | Accuracy      | Suitability           | Domain         \
    \   |\n| Accuracy          | Objectivity   | Accuracy              | Knowledge\
    \         |\n| Security          | Believability | Security              | Qualification\
    \     |\n| Reliability       | Reputation    | Reliability           | Certification\
    \     |\n| Understandability | Accessibility | Time                  | Experience\
    \        |\n| Learnability      | Security      | Efficiency            | Time\
    \              |\n| Time Efficiency   | Relevancy     | Resource             \
    \ | Management        |\n| Resource          | Value-added   | Utilization   \
    \        | Communication     |\n| Utilization       | Timeliness    | Effectiveness\
    \         | Skills            |\n| Effectiveness     | Completeness  | Safety\
    \                |                   |\n| Productivity      | Amount of     |\
    \ User                  |                   |\n| Safety            | Data    \
    \      | Satisfaction          |                   |\n| User Satisfaction |  \
    \             | Robustness            |                   |\n| Robustness    \
    \    |               | Availability          |                   |\n\nApplying\
    \ ProcessGPT to a knowledge-intensive business process will improve quality dimensions\
    \ within the Function and Input/Output categories. Similarly, it reduces the performance\
    \ requirements of human and non-human resources while delivering the same or better\
    \ quality in those areas. The improved function and input/output quality provided\
    \ by ProcessGPT translate directly to a better user experience. Likewise, reducing\
    \ the performance requirements of non-human and human resources opens up the same\
    \ user experience to a broader range of users. This collectively demonstrates\
    \ that ProcessGPT improves usability for all process users–not just those with\
    \ cognitive disabilities.\n\n<span id=\"page-5-2\"></span><span id=\"page-5-1\"\
    ></span><span id=\"page-5-0\"></span>The benefits of improving business process\
    \ usability are well characterized and overwhelmingly positive. Cost savings from\
    \ users spending less time on a process are most evident; however, second-order\
    \ savings accrue in areas such as development, support, training, documentation,\
    \ and maintenance. [40][41] Conventional usability improvements have a near-term\
    \ costbenefit ratio ranging from 1:2 for low-volume processes to more than 1:100\
    \ for high volume processes. [42][43][44] Usability savings accrue continually\
    \ such that cost-benefit ratio only improves over time. It is important to note\
    \ the converse: the costs of poor usability accrue continuously. This is true\
    \ regardless of whether usability issues are known by process administrators.\
    \ Ultimately, the users' cognitive factors serve as the testing grounds for process\
    \ usability.\n\nProcessGPT can also relieve the administrative burden put onto\
    \ employees by external organizations. For example, government-mandated forms\
    \ and processes often have poor usability, which impacts the users and the government\
    \ (and taxpayers). Government contracts are particularly egregious, with up to\
    \ 9% of a contract's value spent on administering the contract itself. That means\
    \ for every dollar spent on services, an organization is spending nine cents on\
    \ non-value-added activity. [45] Implementing an AI system like ProcessGPT has\
    \ the potential to significantly reduce the time spent on these nonvalue-added\
    \ tasks. Augmenting existing functions such as prioritizing inboxes and automatically\
    \ drafting basic emails can also have large impacts. Using email accounts for\
    \ 28% of an employee's time at work. [46] Reducing the time spent searching past\
    \ emails or documents gives employees more time to focus on the tasks at hand.\n\
    \nGains from usability improvements are so broad that they are difficult to characterize\
    \ entirely, yet their impact is undeniable and impossible to overlook. [47] Numerous\
    \ methods exist to quantify usability benefits, and there is no shortage of relevant\
    \ case studies. [\\[40\\]](#page-5-0)[\\[41\\]](#page-5-1) It is common to see\
    \ process time and costs reduced by half as well as absolute savings in the millions\
    \ of dollars. Usability improvements sometimes pay for themselves within the first\
    \ day of implementation. [\\[41\\]](#page-5-1) In fact, the authors found no research\
    \ that showed a negative return on usability investments.\n\nImproved usability\
    \ of business processes also leads to increased productivity and associated cost\
    \ savings. The same work can be done by less people, or the same people can do\
    \ more (and more relevant) work. [\\[43\\]](#page-5-2) Usable processes reduce\
    \ the upfront costs needed for documentation and training. Likewise, continuous\
    \ cost savings are realized in these same areas because usable processes enable\
    \ process users to be more self-sufficient.\n\nEmpowering users to reach a goal\
    \ via an intuitive, responsive process pays additional dividends in the form of\
    \ improved employee morale and increased self-directed work. People naturally\
    \ avoid tasks they don't like, resulting in procrastination behaviors, poor work\
    \ quality, and increased risk of turnover. [\\[34\\]](#page-2-0) These again impact\
    \ the bottom line of an organization. [\\[43\\]](#page-5-2)\n\n## **VI. POTENTIAL\
    \ CHALLENGES**\n\nThe use of an AI system to help ease bureaucratic burden within\
    \ an organization is not without challenges. Anytime government or commercial\
    \ information systems are storing and collating data, there is concern of data\
    \ security. An all-knowing AI system could have the potential to create proprietary\
    \ information or even impact the classification of data. Following guidance on\
    \ AI development and implementation will be central to mitigating these issues.\
    \ [48] In addition to data security risk, the access to employee correspondence\
    \ (e.g. email, chats, personal data) could pose a threat to program integrity\
    \ if there is no human manager to make ethical/tactical decisions on what should\
    \ be shared.\n\nBeyond its application for ProcessGPT, there is general apprehension\
    \ about adopting AI technologies. A Gallup poll from 2018 indicated that most\
    \ people think AI will destroy more jobs than it creates. [49] There is uncertainty\
    \ around the future of AI's impact on society that can cause anxiety for many.\
    \ There is also the question of achievability – when will the technology exist\
    \ to create a working system like ProcessGPT? Additionally, as AI technology is\
    \ developed, it is imperative to keep humans' emotions at the center. Following\
    \ best practices such as those laid out in the HAX Toolkit [50] developed by Microsoft\
    \ will be crucial to making AI an accepted part of organizations. This kind of\
    \ \"human-centric\" design will ensure that people using the technology are confident\
    \ in the benefits they bring and trust that those benefits outweigh the costs.\n\
    \n## **VII. CONCLUSIONS**\n\nWe drew upon an analysis of a proposed Cognitive\
    \ BPM architecture, ProcessGPT, to understand the potential role of AI in enhancing\
    \ workplace inclusivity and efficiency, particularly for individuals with cognitive\
    \ disabilities. We viewed these capabilities through the lens of human cognitive\
    \ factors and their limitations to address our initial research questions.\n\n\
    **RQ1:** How can AI-intensive technology be applied to business processes to accommodate\
    \ individuals with cognitive disabilities?\n\nWe studied ProcessGPT's functions\
    \ in hypothetical applications to better understand how it can accommodate users\
    \ with cognitive disabilities. The functions consisted of:\n\n- \n- Filling out\
    \ forms Answering process questions\n- Onboarding assistance User-centric guidance\n\
    - Task management Reminders and follow-ups\n- Email processing Automating repetitive\
    \ tasks\n- Resource planning Drafting email responses\n- ProcessGPT Self-Assessment\
    \ Voice transcription\n- Intermediary for internal systems\n- \n- \n- Compiling\
    \ data from\n- disparate sources • Data interpretation\n- Searching multiple data\
    \ sources\n\nWe logically demonstrated that ProcessGPT enables knowledge-intensive\
    \ business processes to accommodate a broad range of cognitive disabilities by\
    \ correlating these functions with the W3C guidelines for *Making Content Usable\
    \ for People with Cognitive and Learning Disabilities*.\n\n**RQ2:** What are the\
    \ benefits of accommodating individuals with cognitive disabilities in business\
    \ processes?\n\nWe correlated ProcessGPT disability accommodations with cognition-agnostic\
    \ BPM quality attributes to demonstrate that ProcessGPT improves usability for\
    \ all process users. Generalizing these usability improvements also enables ProcessGPT\
    \ benefits to be compared to the well-studied and universally positive impacts\
    \ of usability engineering. Ultimately, usability of a process is correlated with\
    \ the cognitive demand it places on its users, and no user has unlimited cognitive\
    \ resources. ProcessGPT and similar AI-intensive systems would improve usability\
    \ of knowledge-intensive processes for everyone by accommodating individuals with\
    \ limited cognitive factors, resulting in increased productivity and employee\
    \ morale across the workforce.\n\nIn this work, we address a critical need that\
    \ affects a significant portion of the workforce by focusing on accommodating\
    \ individuals with cognitive disabilities. Simultaneously, we illuminate a novel\
    \ approach to reduce administrative burdens across the workforce. While users\
    \ without cognitive disabilities must endure cumbersome knowledge-intensive business\
    \ processes with little recourse, many organizations are legally obligated to\
    \ accommodate individuals with disabilities. This is comparable to automatic door\
    \ openers, which benefit all users despite being installed to fulfill legal requirements\
    \ to accommodate individuals with physical disabilities. Users without physical\
    \ disabilities benefit from automatic door openers when their arms are full or\
    \ they are part of a large group, for instance. If a door has poor usability because\
    \ it is heavy or poorly positioned, automatic openers rectify these issues for\
    \ everyone. In these instances, disability accommodations rectify flaws in systems\
    \ that were not properly designed or validated by the original designer. ProcessGPT\
    \ would perform this function within knowledge-intensive processes across a wide\
    \ range of use cases. Organizations that are legally obligated to accommodate\
    \ individuals with disabilities may achieve compliance by applying ProcessGPT\
    \ or similar AI-intensive systems to their knowledgeintensive business processes.\
    \ Additional benefits in the form of reduced costs, increased productivity, and\
    \ improved morale only strengthen this argument\n\n- 1. Alfredo Ardila and Byron\
    \ Bernal. \"What Can Be Localized in the Brain? Toward a 'Factor' Theory on Brain\
    \ Organization of Cognition,\" International Journal of Neuroscience, vol. 117,\
    \ no. 7, pp. 935–969, Jan. 2007, doi: 10.1080/00207450600912222.\n- 2. George\
    \ A. Miller, \"'The magical number seven, plus or minus two: Some limits on our\
    \ capacity for processing information,' (Miller 1956),\" 1956, Accessed: Jul.\
    \ 11, 2023. [Online]. Available: http://archive.org/details/miller1956\\_202204\n\
    - 3. Derek M. Jones, \"The 7±2 urban legend,\" MISRA C Conference 2002, October\
    \ 2002. [Online]. Available: http://www.knosof.co.uk/cbook/misart.pdf\n- 4. J.\
    \ M. J. Murre and J. Dros, \"Replication and Analysis of Ebbinghaus' Forgetting\
    \ Curve,\" PLOS ONE, vol. 10, no. 7, p. e0120644, Jul. 2015, doi: 10.1371/journal.pone.0120644.\n\
    - 5. F. Paas, A. Renkl, and J. Sweller, \"Cognitive Load Theory and Instructional\
    \ Design: Recent Developments,\" Educational Psychologist, vol. 38, pp. 1–4, Jun.\
    \ 2010, doi: 10.1207/S15326985EP3801\\_1.\n- 6. M. Boudry, M. Vlerick, and T.\
    \ Edis, \"The end of science? On human cognitive limitations and how to overcome\
    \ them,\" Biology & Philosophy, vol. 35, Jan. 2020, doi: 10.1007/s10539-020-9734-7.\n\
    - 7. I. Kotseruba and J. K. Tsotsos, \"40 years of cognitive architectures: core\
    \ cognitive abilities and practical applications,\" Artif Intell Rev, vol. 53,\
    \ no. 1, pp. 17– 94, Jan. 2020, doi: 10.1007/s10462-018-9646-y.\n- 8. OpenAI,\
    \ \"GPT-4 Technical Report.\" arXiv, Mar. 27, 2023. doi: 10.48550/arXiv.2303.08774.\n\
    - 9. V. Keith and S. Farris, \"Human-Centered Business Process Management,\" Fujitsu\
    \ scientific & technical journal, vol. 45, Apr. 2009.\n- 10. C. Di Ciccio, A.\
    \ Marrella, and A. Russo, \"Knowledge-Intensive Processes: Characteristics, Requirements\
    \ and Analysis of Contemporary Approaches,\" J Data Semant, vol. 4, no. 1, pp.\
    \ 29–57, Mar. 2015, doi: 10.1007/s13740-014-0038-4.\n- 11. Hull, Richard, and\
    \ Hamid R. Motahari Nezhad. \"Rethinking BPM in a Cognitive World: Transforming\
    \ How We Learn and Perform Business Processes,\" 3– 19, 2016. https://doi.org/10.1007/978-3-319-45348-4\\\
    _1.\n- 12. Beheshti, Amin, Jian Yang, Quan Z. Sheng, Boualem Benatallah, Fabio\
    \ Casati, Schahram Dustdar, Hamid Reza Motahari Nezhad, Xuyun Zhang, and Shan\
    \ Xue. \"ProcessGPT: Transforming Business Process Management with Generative\
    \ Artificial Intelligence.\" arXiv, May 28, 2023. https://doi.org/10.48550/arXiv.2306.01771.\n\
    - 13. Centers for Disease Control and Prevention, National Center on Birth Defects\
    \ and Developmental Disabilities, Division of Human Development and Disability.\
    \ Disability and Health Data System (DHDS) Data [online]. [accessed Jul 15, 2023].\
    \ URL: https://dhds.cdc.gov\n- 14. \"Making Content Usable for People with Cognitive\
    \ and Learning Disabilities.\" https://www.w3.org/TR/coga-usable/ (accessed Jul.\
    \ 15, 2023).\n- 15. B. Bozeman, J. Youtie, and J. Jung, \"Robotic Bureaucracy\
    \ and Administrative Burden: What Are the Effects of Universities' Computer Automated\
    \ Research Grants Management Systems?,\" Research Policy, vol. 49, no. 6, p. 103980,\
    \ Jul. 2020, doi: 10.1016/j.respol.2020.103980.\n- 16. A. Gregoriades and A. Sutcliffe,\
    \ \"A socio-technical approach to business process simulation,\" Decision Support\
    \ Systems, vol. 45, no. 4, pp. 1017–1030, Nov. 2008.\n- 17. Sweller, John. \"\
    Cognitive Load During Problem Solving: Effects on Learning.\" Cognitive Science\
    \ 12, no. 2 (1988): 257–85. https://doi.org/10.1207/s15516709cog1202\\_4.\n- 18.\
    \ Workflow Management Coalition, \"Workflow Management Coalition Terminology &\
    \ Glossary.\" Lighthouse Point, Florida: Future Strategies Inc.,1999.\n- 19. Y.\
    \ Doganata, \"Detecting Compliance Failures in Un-managed Processes,\" in Strategic\
    \ and Practical Approaches for Information Security Governance: Technologies and\
    \ Applied Solutions, 2012, pp. 385–404. doi: 10.4018/978-1-4666-0197-0.ch022.\n\
    - 20. Mukhi, N.K. (2010). Monitoring Unmanaged Business Processes. In: Meersman,\
    \ R., Dillon, T., Herrero, P. (eds) On the Move to Meaningful Internet Systems:\
    \ OTM 2010. OTM 2010. Lecture Notes in Computer Science, vol 6426. Springer, Berlin,\
    \ Heidelberg. https://doi.org/10.1007/978-3-642-16934-2\\_7\n- 21. J. Gonçalves,\
    \ F. Baião, F. Santoro, and G. Guizzardi, \"A cognitive BPM theory for knowledge-intensive\
    \ processes,\" Business Process Management Journal, vol. 29, pp. 465–488, Feb.\
    \ 2023, doi: 10.1108/BPMJ-11-2021-0746.\n- 22. Hamid R. Motahari Nezhad, Rama\
    \ Akkiraju, \"Towards Cognitive BPM as the Next Generation BPM Platform for Analytics-Driven\
    \ Business Processes,\" in Business Process Management Workshops, F. Fournier\
    \ and J. Mendling, Eds., in Lecture Notes in Business Information Processing,\
    \ vol 202, 2015, doi: 10.1007/978-3-319-15895-2\\_14.\n- 23. F. Hattke, D. Hensel,\
    \ and J. Kalucza, \"Emotional Responses to Bureaucratic Red Tape,\" Public Administration\
    \ Review, vol. 80, no. 1, pp. 53–63, 2020, doi: 10.1111/puar.13116.\n- 24. \"\
    The Liberation of Federal Employees from Low-Value Work is Underway,\" Sep. 09,\
    \ 2020. https://www.performance.gov/liberating-fed-employees-fromlow-value-work-underway//#liberating\
    \ (accessed Jul. 10, 2023).\n- 25. \"'The State of Federal RPA,' Federal RPA Community\
    \ of Practice (CoP), December 29, 2021, [Online]. Available[:](https://s3.amazonaws.com/digitalgov/static/state-of-federal-rpa-report-12-2021.pdf)\
    \ https://s3.amazonaws.com/digitalgov/static/state-of-federal-rpa-report-12-2021.pdf\
    \ [Accessed: 16-Jul-2023].\n- 26. I. T. stories, \"Digitizing contract management\
    \ with microservices on Azure,\" Inside Track Blog, Dec. 17, 2019. https://www.microsoft.com/insidetrack/blog/digitizing-contract-management-using-micro-services-on-azure/\
    \ (accessed Aug. 02, 2023).\n- 27. B. Rich, \"How AI Is Changing Contracts,\"\
    \ Harvard Business Review, Feb. 12, 2018. Accessed: Aug. 02, 2023. [Online]. Available:\
    \ https://hbr.org/2018/02/how-ai-is-changing-contracts\n- 28. Pollack, Martha\
    \ E. \"Intelligent Technology for an Aging Population: The Use of AI to Assist\
    \ Elders with Cognitive Impairment.\" *AI Magazine*, 15 June 2005, ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/1810.\n\
    - 29. Singh, Charanjit. \"Artificial Intelligence and Deep Learning: Considerations\
    \ for Financial Institutions for Compliance with the Regulatory Burden in the\
    \ United Kingdom.\" *Journal of Financial Crime*, 14 Apr. 2023, www.emerald.com/insight/content/doi/10.1108/JFC-01-2023-0011/full/pdf?title=artificialintelligence-and-deep-learning-considerations-for-financial-institutions-for-compliance-with-the-regulatory-burden-in-the-united-kingdom.\n\
    - 30. Woolhandler , Steffie, and David Himmelstein . *Administrative Work Consumes\
    \ One-Sixth of U.S ... - Sage Journals*, 1 Oct. 2014, journals.sagepub.com/doi/pdf/10.2190/HS.44.4.a.\n\
    - 31. Dowell, A. C., Hamilton, S., & McLeod, D. K. (2000). Job satisfaction, psychological\
    \ morbidity and job stress among New Zealand general practitioners. *New Zealand\
    \ Medical Journal, 113*(1113), 269-272. http://mutex.gmu.edu/login?url=https://www.proquest.com/scholarly-journals/job-satisfactionpsychological-morbidity-stress/docview/1140265594/se-2\n\
    - 32. Deborah B. Smith & Joel Shields (2013) Factors Related to Social Service\
    \ Workers' Job Satisfaction: Revisiting Herzberg's Motivation to Work, Administration\
    \ in Social Work, 37:2, 189-198, DOI[: 10.1080/03643107.2012.673217.](https://doi.org/10.1080/03643107.2012.673217)\n\
    - 33. Giauque, David & Ritz, Adrian & Varone, Frédéric & Anderfuhren-Biget, Simon.\
    \ (2012). Resigned But Satisfied: The Negative Impact of Public Service Motivation\
    \ and Red Tape on Work Satisfaction. Public Administration. 90. 10.1111/j.1467-9299.2011.01953.x.\n\
    - 34. Huang, Q., Zhang, K., Bodla, A. A., & Wang, Y. (2022). The Influence of\
    \ Perceived Red Tape on Public Employees' Procrastination: The Conservation of\
    \ Resource Theory Perspective. *International journal of environmental research\
    \ and public health*, *19*(7), 4368. https://doi.org/10.3390/ijerph19074368\n\
    - 35. S. Wissell, L. Karimi, T. Serry, L. Furlong, and J. Hudson, \"'You Don't\
    \ Look Dyslexic': Using the Job Demands-Resource Model of Burnout to Explore Employment\
    \ Experiences of Australian Adults with Dyslexia,\" International Journal of Environmental\
    \ Research and Public Health, vol. 19, no. 17, Art. no. 17, Jan. 2022, doi: 10.3390/ijerph191710719.\n\
    - 36. Sangmook Kim, Individual-Level Factors and Organizational Performance in\
    \ Government Organizations, *Journal of Public Administration Research and Theory*,\
    \ Volume 15, Issue 2, April 2005, Pages 245–261[, https://doi.org/10.1093/jopart/mui013](https://doi.org/10.1093/jopart/mui013)\n\
    - 37. Lasnoski, Nathan. \"AI Enables Employment for Individuals with Cognitive\
    \ Disabilities.\" *Humans of IT Blog*, 21 Sept. 2020, techcommunity.microsoft.com/t5/humans-of-it-blog/ai-enables-employment-for-individuals-with-cognitive/ba-p/1681812.\n\
    - 38. Jakob Nielsen, \"Usability 101: Introduction to Usability,\" Nielsen Norman\
    \ Group. https://www.nngroup.com/articles/usability-101-introduction-to-usability/\
    \ (accessed Jul. 30, 2023).\n- 39. M. Heravizadeh, J. Mendling, and M. Rosemann,\
    \ \"Dimensions of Business Processes Quality (QoBP),\" in Business Process Management\
    \ Workshops, D. Ardagna, M. Mecella, and J. Yang, Eds., in Lecture Notes in Business\
    \ Information Processing. Berlin, Heidelberg: Springer, 2009, pp. 80–91. doi:\
    \ 10.1007/978-3-642-00328-8\\_8.\n- 40. G. M. Donahue, \"Usability and the bottom\
    \ line,\" Software, IEEE, vol. 18, pp. 31–37, Feb. 2001.\n- 41. Bevan, N. (2005).\
    \ Cost benefits evidence and case studies. Cost-justifying usability: An update\
    \ for the internet age. San Francisco: Morgan Kaufmann.\n- 42. C.-M. Karat, \"\
    Cost-Benefit Analysis of Usability Engineering Techniques,\" Proceedings of the\
    \ Human Factors Society Annual Meeting, vol. 34, no. 12, pp. 839–843, Oct. 1990,\
    \ doi: 10.1177/154193129003401203.\n- 43. Weinschenk, Susan. \"Usability: A Business\
    \ Case,\" White Paper Human Factors International 30 (2005).\n- 44. C.-M. Karat,\
    \ \"4 Chapter A Business Case Approach to Usability Cost Justification for the\
    \ Web,\" in Cost-Justifying Usability (Second Edition), R. G. Bias and D. J. Mayhew,\
    \ Eds., in Interactive Technologies. San Francisco: Morgan Kaufmann, 2005, pp.\
    \ 103–141. doi: 10.1016/B978-012095811-5/50004-3.\n- 45. O. H. Petersen, J. R.\
    \ Hansen, and K. Houlberg, \"The administrative burden of doing business with\
    \ the government: Learning and compliance costs in Business-Government interactions,\"\
    \ Public Administration, vol. n/a, no. n/a, doi: 10.1111/padm.12904.\n- 46. Sokolov,\
    \ D. (2023, May 3). How much time do your employees spend on checking emails?\
    \ PPM Express. https://ppm.express/blog/how-much-time-youremployees-spend-on-checking-emails/#:~:text=According%20to%20the%20McKinsey%20Global,in%20the%20background%20while%20working.\n\
    - 47. A. Bruseberg, \"Presenting the value of Human Factors Integration: guidance,\
    \ arguments and evidence,\" Cogn Tech Work, vol. 10, no. 3, pp. 181–189, Jul.\
    \ 2008, doi: 10.1007/s10111-007-0100-1.\n- 48. Government Accountability Office,\
    \ \"Title of the Report or Webpage,\" U.S. Government Accountability Office, Publication\
    \ Date (if available), UR[L:](https://www.gao.gov/products/gao-21-519sp) [https://www.gao.gov/products/gao-21-519sp.](https://www.gao.gov/products/gao-21-519sp)\n\
    - 49. Cognitive World, \"Is AI a Job Killer or Job Creator?,\" Forbes, November\
    \ 24, 2019, URL[:](https://www.forbes.com/sites/cognitiveworld/2019/11/24/is-ai-a-job-killer-or-job-creator/?sh=1b20b10337e8)\
    \ [https://www.forbes.com/sites/cognitiveworld/2019/11/24/is-ai-a](https://www.forbes.com/sites/cognitiveworld/2019/11/24/is-ai-a-job-killer-or-job-creator/?sh=1b20b10337e8)[job-killer-or-job-creator/?sh=1b20b10337e8.](https://www.forbes.com/sites/cognitiveworld/2019/11/24/is-ai-a-job-killer-or-job-creator/?sh=1b20b10337e8)\n\
    - 50. Microsoft, \"AI Guidelines Hax Toolkit,\" Microsoft, UR[L:](https://www.microsoft.com/en-us/haxtoolkit/ai-guidelines/)\
    \ [https://www.microsoft.com/en-us/haxtoolkit/ai-guidelines/.](https://www.microsoft.com/en-us/haxtoolkit/ai-guidelines/)"
- id: greedy_algorithm_for_inference_of_decision_trees_from_decision_rule_systems_greedy_algorithm_for_inference_of_decision_trees_from_decision_rule_systems
  title: "Greedy Algorithm for Inference of Decision Trees from Decision Rule\n  Systems"
  abstract: 'Decision trees and decision rule systems play important roles as classifiers,

    knowledge representation tools, and algorithms. They are easily interpretable

    models for data analysis, making them widely used and studied in computer

    science. Understanding the relationships between these two models is an

    important task in this field. There are well-known methods for converting

    decision trees into systems of decision rules. In this paper, we consider the

    inverse transformation problem, which is not so simple. Instead of constructing

    an entire decision tree, our study focuses on a greedy polynomial time

    algorithm that simulates the operation of a decision tree on a given tuple of

    attribute values.'
  url: http://arxiv.org/abs/2401.06793v1
  keywords: ': decision rule systems, decision trees.'
  document: '# Greedy Algorithm for Inference of Decision Trees from Decision Rule
    Systems


    Kerven Durdymyradov and Mikhail Moshkov Computer, Electrical and Mathematical
    Sciences & Engineering Division and Computational Bioscience Research Center King
    Abdullah University of Science and Technology (KAUST) Thuwal 23955-6900, Saudi
    Arabia {kerven.durdymyradov,mikhail.moshkov}@kaust.edu.sa


    ### Abstract


    Decision trees and decision rule systems play important roles as classifiers,
    knowledge representation tools, and algorithms. They are easily interpretable
    models for data analysis, making them widely used and studied in computer science.
    Understanding the relationships between these two models is an important task
    in this field. There are well-known methods for converting decision trees into
    systems of decision rules. In this paper, we consider the inverse transformation
    problem, which is not so simple. Instead of constructing an entire decision tree,
    our study focuses on a greedy polynomial time algorithm that simulates the operation
    of a decision tree on a given tuple of attribute values.


    *Keywords*: decision rule systems, decision trees.


    # 1 Introduction


    Decision trees [\[3,](#page-7-0) [4,](#page-7-1) [8,](#page-7-2) [31,](#page-9-0)
    [34,](#page-10-0) [40\]](#page-10-1) and systems of decision rules [\[6,](#page-7-3)
    [7,](#page-7-4) [11,](#page-8-0) [14,](#page-8-1) [33,](#page-10-2) [34,](#page-10-0)
    [35,](#page-10-3) [36\]](#page-10-4) are widely used as classifiers, knowledge
    representation tools, and algorithms. They are known for their interpretability
    in data analysis [\[10,](#page-8-2) [15,](#page-8-3) [23,](#page-9-1) [41\]](#page-10-5).


    Investigating the relationship between these two models is an important task in
    computer science. Converting decision trees into decision rule systems is a well-known
    and simple process [\[37,](#page-10-6) [38,](#page-10-7) [39\]](#page-10-8). This
    paper focuses on the inverse transformation problem, which is not trivial.


    The research related to this problem encompasses several directions:


    • Two-stage construction of decision trees. This approach involves building decision
    rules based on input data, followed by the construction of decision trees or decision
    structures (which are generalizations of decision trees) using the generated rules.
    The benefits of this two-stage construction method are explained in [\[1,](#page-7-5)
    [2,](#page-7-6) [17,](#page-8-4) [18,](#page-8-5) [19,](#page-8-6) [20,](#page-9-2)
    [21,](#page-9-3) [22,](#page-9-4) [42\]](#page-10-9).


    - Relationships between the depth of deterministic and nondeterministic decision
    trees for computing Boolean functions [\[5,](#page-7-7) [16,](#page-8-7) [24,](#page-9-5)
    [43\]](#page-10-10). Note that the nondeterministic decision trees can be interpreted
    as decision rule systems. Note also that the minimum depth of a nondeterministic
    decision tree for a Boolean function is equal to its certificate complexity [\[9\]](#page-8-8).

    - Relationships between the depth of deterministic and nondeterministic decision
    trees for problems over finite and infinite information systems [\[25,](#page-9-6)
    [27,](#page-9-7) [29,](#page-9-8) [30,](#page-9-9) [32\]](#page-10-11). These
    systems consist of a universe and a set of attributes defined on it [\[35\]](#page-10-3).


    This paper builds upon the syntactic approach proposed in previous works [\[26,](#page-9-10)
    [28\]](#page-9-11). The approach assumes that we have a system of decision rules
    but lack knowledge of the input data, and our objective is to transform these
    rules into a decision tree.


    Let us consider a system of decision rules S, which consists of rules of the form


    $$

    (a_{i_1} = \delta_1) \wedge \cdots \wedge (a_{i_m} = \delta_m) \rightarrow \sigma,

    $$


    where ai<sup>1</sup> , . . . , ai<sup>m</sup> represent attributes, δ1, . . .
    , δ<sup>m</sup> are the corresponding attribute values, and σ is the decision.


    The problem associated with this system is to determine, for a given input (a
    tuple of values of attributes included in S), all the realizable rules, i.e.,
    rules with a true left-hand side. It is important to note that any attribute in
    the input can take any value.


    The objective of this paper is to minimize the number of queries required to determine
    the attribute values. To achieve this, decision trees are explored as algorithms
    for solving the problem at hand.


    In our previous work [\[12\]](#page-8-9), we investigated the minimum depth of
    decision trees for the considered problem and established both upper and lower
    bounds. These bounds depend on three parameters of the decision rule system: the
    total number of distinct attributes, the maximum length of a decision rule, and
    the maximum number of attribute values. We demonstrated that there exist systems
    of decision rules where the minimum depth of the decision trees is significantly
    smaller than the total number of attributes in the rule system. This finding shows
    that decision trees are a reasonable choice for such systems of decision rules.


    In another study [\[13\]](#page-8-10), we examined the complexity of constructing
    decision trees and acyclic decision graphs that represent decision trees. We found
    that in many cases, the minimum number of nodes in decision trees can grow as
    a superpolynomial function depending on the size of the decision rule systems.
    To address this issue, we introduced two types of acyclic decision graphs as representations
    of decision trees. However, simultaneously minimizing the depth and the number
    of nodes in these graphs poses a challenging bi-criteria optimization problem.


    We left this problem for future research and pursued an alternative approach:
    instead of constructing the entire decision tree, we developed a polynomial time
    algorithm that models the behavior of the decision tree for a given tuple of attribute
    values. This algorithm is based on an auxiliary algorithm for the construction
    of a node cover for a hypergraph corresponding to a decision rule system: nodes
    of this hypergraph correspond to attributes and edges – to rules from the rule
    system. The auxiliary algorithm is not greedy: at each step, this algorithm adds
    to the cover being constructed all the attributes belonging to a rule that has
    not yet been covered.


    In this paper, we develop a new algorithm with polynomial time complexity, which
    models the behavior of a decision tree solving the considered problem for a given
    tuple of attribute values. The auxiliary algorithm for it is a standard greedy
    algorithm for the set cover problem. Therefore we talk about the entire algorithm
    for describing the operation of decision trees as greedy. We study the accuracy
    of this algorithm, i.e., we compare the depth of the decision tree described by
    it and the minimum depth of a decision tree. The obtained bound is a bit worse
    in the comparison with the bound for the algorithm considered in [\[13\]](#page-8-10).
    However, we expect that the considered algorithms are mutually complementary:
    the old one will work better for systems with short decision rules and the new
    one will work better for systems with long decision rules. In the future, we are
    planning to do computer experiments to explore this hypothesis.


    In this paper, we repeat the main definitions from [\[12\]](#page-8-9) and give
    some lemmas from [\[12\]](#page-8-9) without proofs.


    This paper consists of five sections. Section [2](#page-2-0) considers the main
    definitions and notation. Section [3](#page-4-0) contains auxiliary statements.
    Section [4](#page-5-0) discusses the greedy algorithm, which models the behavior
    of a decision tree. Section [5](#page-6-0) contains short conclusions.


    # <span id="page-2-0"></span>2 Main Definitions and Notation


    In this section, we consider the main definitions and notation related to decision
    rule systems and decision trees. In fact, we repeat corresponding definitions
    and notation from [\[12\]](#page-8-9).


    ## 2.1 Decision Rule Systems


    Let ω = {0, 1, 2, . . .} and A = {a<sup>i</sup> : i ∈ ω}. Elements of the set
    A will be called *attributes*. A *decision rule* is an expression of the form


    $$

    (a_{i_1} = \delta_1) \wedge \cdots \wedge (a_{i_m} = \delta_m) \rightarrow \sigma,

    $$


    where m ∈ ω, ai<sup>1</sup> , . . . , ai<sup>m</sup> are pairwise different attributes
    from A and δ1, . . . , δm, σ ∈ ω.


    We denote this decision rule by r. The expression (ai<sup>1</sup> = δ1) ∧ · ·
    · ∧ (ai<sup>m</sup> = δm) will be called the *left-hand side*, and the number
    σ will be called the *right-hand side* of the rule r. The number m will be called
    the *length* of the decision rule r. Denote A(r) = {ai<sup>1</sup> , . . . , aim}
    and K(r) = {ai<sup>1</sup> = δ1, . . . , ai<sup>m</sup> = δm}. If m = 0, then
    A(r) = K(r) = ∅.


    A *system of decision rules* S is a finite nonempty set of decision rules. Denote
    A(S) = S <sup>r</sup>∈<sup>S</sup> A(r), n(S) = |A(S)|, and d(S) the maximum length
    of a decision rule from S. Let n(S) > 0. For a<sup>i</sup> ∈ A(S), let VS(ai)
    = {δ : a<sup>i</sup> = δ ∈ S <sup>r</sup>∈<sup>S</sup> K(r)} and EVS(ai) = VS(ai)
    ∪ {∗}, where the symbol ∗ is interpreted as a number from ω that does not belong
    to the set VS(ai). Letter E here and later means *extended*: we consider not only
    values of attributes occurring in S but arbitrary values from ω. Denote k(S) =
    max{|VS(ai)| : a<sup>i</sup> ∈ A(S)}. If n(S) = 0, then k(S) = 0. We denote by
    Σ the set of systems of decision rules.


    Let S ∈ Σ, n(S) > 0, and A(S) = {aj<sup>1</sup> , . . . , aj<sup>n</sup> }, where
    j<sup>1</sup> < · · · < jn. Denote EV (S) = EVS(aj<sup>1</sup> ) × · · · × EVS(aj<sup>n</sup>
    ). For ¯δ = (δ1, . . . , δn) ∈ EV (S), denote K(S, ¯δ) = {aj<sup>1</sup> = δ1,
    . . . , aj<sup>n</sup> = δn}. We will say that a decision rule r from S is *realizable*
    for a tuple ¯δ ∈ EV (S) if K(r) ⊆ K(S, ¯δ). It is clear that any rule with the
    empty left-hand side is realizable for the tuple ¯δ.


    We now define a problem related to the rule system S.


    Problem *Extended All Rules*: for a given tuple ¯δ ∈ EV (S), it is required to
    find the set of rules from S that are realizable for the tuple ¯δ. We denote this
    problem EAR(S). In the special case, when n(S) = 0, all rules from S have the
    empty left-hand side. In this case, it is natural to consider the set S as the
    solution to the problem EAR(S).


    ### 2.2 Decision Trees


    A *finite directed tree with root* is a finite directed tree in which only one
    node has no entering edges. This node is called the *root*. The nodes without
    leaving edges are called *terminal* nodes. The nodes that are not terminal will
    be called *working* nodes. A *complete path* in a finite directed tree with root
    is a sequence ξ = v1, d1, . . . , vm, dm, vm+1 of nodes and edges of this tree
    in which v<sup>1</sup> is the root, vm+1 is a terminal node and, for i = 1, .
    . . , m, the edge d<sup>i</sup> leaves the node v<sup>i</sup> and enters the node
    vi+1.


    An *extended decision tree over a decision rule system* S is a labeled finite
    directed tree with root Γ satisfying the following conditions:


    - Each working node of the tree Γ is labeled with an attribute from the set A(S).

    - Let a working node v of the tree Γ be labeled with an attribute a<sup>i</sup>
    . Then exactly |EVS(ai)| edges leave the node v and these edges are labeled with
    pairwise different elements from the set EVS(ai).

    - Each terminal node of the tree Γ is labeled with a subset of the set S.


    Let Γ be an extended decision tree over the decision rule system S. We denote
    by CP(Γ) the set of complete paths in the tree Γ. Let ξ = v1, d1, . . . , vm,
    dm, vm+1 be a complete path in Γ. We correspond to this path a set of attributes
    A(ξ) and an equation system K(ξ). If m = 0 and ξ = v1, then A(ξ) = ∅ and K(ξ)
    = ∅. Let m > 0 and, for j = 1, . . . , m, the node v<sup>j</sup> be labeled with
    the attribute ai<sup>j</sup> and the edge d<sup>j</sup> be labeled with the element
    δ<sup>j</sup> ∈ ω ∪ {∗}. Then A(ξ) = {ai<sup>1</sup> , . . . , aim} and K(ξ) =
    {ai<sup>1</sup> = δ1, . . . , ai<sup>m</sup> = δm}. We denote by τ (ξ) the set
    of decision rules attached to the node vm+1.


    A system of equations {ai<sup>1</sup> = δ1, . . . , ai<sup>m</sup> = δm}, where
    ai<sup>1</sup> , . . . , ai<sup>m</sup> ∈ A and δ1, . . . , δ<sup>m</sup> ∈ ω
    ∪ {∗}, will be called *inconsistent* if there exist l, k ∈ {1, . . . , m} such
    that l 6= k, i<sup>l</sup> = ik, and δ<sup>l</sup> 6= δk. If the system of equations
    is not inconsistent, then it will be called *consistent*.


    Let S be a decision rule system and Γ be an extended decision tree over S.


    We will say that Γ *solves* the problem EAR(S) if any path ξ ∈ CP(Γ) with consistent
    system of equations K(ξ) satisfies the following conditions:


    • For any decision rule r ∈ τ (ξ), the relation K(r) ⊆ K(ξ) holds.


    • For any decision rule r ∈ S \ τ (ξ), the system of equations K(r) ∪ K(ξ) is
    inconsistent.


    For any complete path ξ ∈ CP(Γ), we denote by h(ξ) the number of working nodes
    in ξ. The value h(Γ) = max{h(ξ) : ξ ∈ CP(Γ)} is called the *depth* of the decision
    tree Γ.


    Let S be a decision rule system. We denote by hEAR(S) the minimum depth of a decision
    tree over S, which solves the problem EAR(S).


    If n(S) = 0, then there is only one decision tree solving the problem EAR(S).
    This tree consists of one node labeled with the set of rules S. Therefore if n(S)
    = 0, then hEAR(S) = 0.


    # <span id="page-4-0"></span>3 Auxiliary Statements


    In this section, we first give some statements from [\[12\]](#page-8-9) and then
    we prove a new one.


    Let S be a decision rule system and α = {ai<sup>1</sup> = δ1, . . . , ai<sup>m</sup>
    = δm} be a consistent equation system such that ai<sup>1</sup> , . . . , ai<sup>m</sup>
    ∈ A and δ1, . . . , δ<sup>m</sup> ∈ ω ∪ {∗}. We now define a decision rule system
    Sα. Let r be a decision rule for which the equation system K(r) ∪ α is consistent.
    We denote by r<sup>α</sup> the decision rule obtained from r by the removal from
    the left-hand side of r all equations that belong to α. Then S<sup>α</sup> is
    the set of decision rules r<sup>α</sup> such that r ∈ S and the equation system
    K(r) ∪ α is consistent.


    <span id="page-4-2"></span>Lemma 1. *(follows from Lemma 6 [\[12\]](#page-8-9))
    Let* S *be a decision rule system with* n(S) > 0*,* α = {ai<sup>1</sup> = δ1,
    . . . , ai<sup>m</sup> = δm} *be a consistent equation system such that* ai<sup>1</sup>
    , . . . , ai<sup>m</sup> ∈ A(S) *and, for* j = 1, . . . , m*,* δ<sup>j</sup> ∈
    EVS(ai<sup>j</sup> )*. Then* hEAR(S) ≥ hEAR(Sα)*.*


    We correspond to a decision rule system S a hypergraph G(S) with the set of nodes
    A(S) and the set of edges {A(r) : r ∈ S}. A *node cover* of the hypergraph G(S)
    is a subset B of the set of nodes A(S) such that A(r) ∩ B 6= ∅ for any rule r
    ∈ S such that A(r) 6= ∅. If A(S) = ∅, then the empty set is the only node cover
    of the hypergraph G(S). Denote by β(S) the minimum cardinality of a node cover
    of the hypergraph G(S).


    <span id="page-4-3"></span>Lemma 2. *(follows from Lemma 7 [\[12\]](#page-8-9))
    Let* S *be a decision rule system. Then* hEAR(S) ≥ β(S)*.*


    <span id="page-4-1"></span>Lemma 3. *(follows from Lemma 8 [\[12\]](#page-8-9))
    Let* S *be a decision rule system. Then* hEAR(S) ≥ d(S)*.*


    Let S be a decision rule system and S ′ be the set of rules of the length d(S)
    from S. Two decision rules r<sup>1</sup> and r<sup>2</sup> from S ′ are called
    *equivalent* if K(r1) = K(r2). This equivalence relation provides a partition
    of the set S ′ into equivalence classes. We denote by S max the set of rules that
    contains exactly one representative from each equivalence class and does not contain
    any other rules.


    <span id="page-4-4"></span>Lemma 4. *Let* S *be a decision rule system with* n(S)
    > 0*. Then*


    $$

    h_{EAR}(S) \ge \ln |S^{\max}| / \ln(k(S) + 1).

    $$


    *Proof.* Let r ∈ S max and the rule r is equal to (ai<sup>1</sup> = δ1) ∧ · ·
    · ∧ (ai<sup>m</sup> = δm) → σ. We now define a tuple ¯δ(r) ∈ EV (S). For j = 1,
    . . . , m, the tuple ¯δ(r) in the position corresponding to the attribute ai<sup>j</sup>
    contains the number δ<sup>j</sup> . All other positions of the tuple ¯δ(r) are
    filled with the symbol ∗. We denote by S max( ¯δ(r)) the set of rules from S max
    that are realizable for the tuple ¯δ(r). One can show that S max( ¯δ(r)) = {r}.
    From here it follows that the problem EAR(S) has at least |S max| pairwise different
    solutions.


    Let Γ be a decision tree, which solves the problem EAR(S) and for which h(Γ) =
    hEAR(S). Then the number of terminal nodes in Γ should be at least |S max|. It
    is easy to show that the number of terminal nodes in Γ is at most (k(S) + 1)h(Γ).
    Therefore (k(S) + 1)h(Γ) ≥ |S max| and h(Γ) ≥ ln |S max|/ ln(k(S) + 1). Thus,
    hEAR(S) ≥ ln |S max|/ ln(k(S) + 1).


    # <span id="page-5-0"></span>4 Algorithms


    In this section, we consider an auxiliary algorithm Agreedy that constructs a
    node cover for the hypergraph corresponding to a decision rule system and an algorithm
    AEAR that describes the work of a decision tree solving the problem EAR(S) for
    a decision rule system S with n(S) > 0.


    ## 4.1 Auxiliary Algorithm Agreedy


    Let S be a decision rule system with n(S) > 0. First, we describe a polynomial
    time algorithm Agreedy for the construction of a node cover B for the hypergraph
    G(S max) such that |B| ≤ β(S max) ln |S max| + 1.


    ### *Algorithm* Agreedy


    During each step, this algorithm chooses an attribute a<sup>i</sup> ∈ A(S max)
    with the minimum index i, which covers the maximum number of rules from S max
    uncovered during previous steps and add it to the set B (an attribute a<sup>i</sup>
    covers a rule r ∈ S max if a<sup>i</sup> ∈ A(r)). The algorithm will finish the
    work when all rules from S max are covered.


    The considered algorithm is essentially a well-known greedy algorithm for the
    set cover problem – see Sect. 4.1.1 of the book [\[34\]](#page-10-0).


    <span id="page-5-1"></span>Lemma 5. *(follows from Theorem 4.1 [\[34\]](#page-10-0))
    Let* S *be a decision rule system with* n(S) > 0*. The algorithm* Agreedy *constructs
    a node cover* B *for the hypergraph* G(S max) *such that* |B| ≤ β(S max) ln |S
    max| + 1*.*


    ## 4.2 Greedy Algorithm AEAR


    Let S be a decision rule system with n(S) > 0. We now describe a polynomial time
    algorithm AEAR that, for a given tuple of attribute values from the set EV (S),
    describes the work on this tuple of a decision tree Γ, which solves the problem
    AER(S). Note that this algorithm is similar to the algorithm considered in [\[13\]](#page-8-10).


    ## *Algorithm* AEAR


    The work of the decision tree Γ consists of rounds.


    *First round*. Using the algorithm Agreedy, we construct a node cover B<sup>1</sup>
    of the hypergraph G(S max) with |B1| ≤ β(S max) ln |S max|+ 1. The decision tree
    Γ sequentially computes values of the attributes from B1. As a result, we obtain
    a system α<sup>1</sup> consisting of |B1| equations of the form ai<sup>j</sup>
    = δ<sup>j</sup> , where ai<sup>j</sup> ∈ B<sup>1</sup> and δ<sup>j</sup> is the
    computed value of the attribute ai<sup>j</sup> . If Sα<sup>1</sup> = ∅ or all
    rules from Sα<sup>1</sup> have the empty left-hand side, then the tree Γ finishes
    its work. The result of this work is the set of decision rules r from S for which
    the system of equations K(r) ∪ α<sup>1</sup> is consistent. These rules correspond
    to rules from Sα<sup>1</sup> with the empty left-hand side. Otherwise, we move
    on to the second round of the decision tree Γ work.


    *Second round*. Using the algorithm Agreedy, we construct a node cover B<sup>2</sup>
    of the hypergraph G((Sα<sup>1</sup> ) max) with |B2| ≤ β((Sα<sup>1</sup> ) max)
    ln |(Sα<sup>1</sup> ) max|+1. The decision tree Γ sequentially computes values
    of the attributes from B2. As a result, we obtain a system α<sup>2</sup> consisting
    of |B2| equations. If Sα1∪α<sup>2</sup> = ∅ or all rules from Sα1∪α<sup>2</sup>
    have the empty left-hand side, then the tree Γ finishes its work. The result of
    this work is the set of decision rules r from S for which the system of equations
    K(r) ∪ α<sup>1</sup> ∪ α<sup>2</sup> is consistent. These rules correspond to
    rules from Sα1∪α<sup>2</sup> with the empty left-hand side. Otherwise, we move
    on to the third round of the decision tree Γ work, etc., until we obtain empty
    system of rules or system in which all rules have empty left-hand side.


    Theorem 1. *Let* S *be a decision rule system with* n(S) > 0*. The algorithm*
    AEAR *describes the work of a decision tree* Γ*, which solves the problem* EAR(S)
    *and for which* h(Γ) ≤ hEAR(S) 3 ln(k(S) + 1) + hEAR(S)*.*


    *Proof.* It is clear that d(S) > d(Sα<sup>1</sup> ) > d(Sα1∪α<sup>2</sup> ) >
    · · · . Therefore the number of rounds is at most d(S). By Lemma [3,](#page-4-1)
    d(S) ≤ hEAR(S). We now show that the number of attributes values of which are
    computed by Γ during each round is at most hEAR(S) 2 ln(k(S) + 1) + 1. We consider
    only the second round: the proofs for other rounds are similar. From Lemma [5](#page-5-1)
    it follows that the number of attributes values of which are computed by Γ during
    the second round is at most β((Sα<sup>1</sup> ) max) ln |(Sα<sup>1</sup> ) max|
    + 1. Evidently, β((Sα<sup>1</sup> ) max) ≤ β(Sα<sup>1</sup> ). By Lemmas [1](#page-4-2)
    and [2,](#page-4-3) β(Sα<sup>1</sup> ) ≤ hEAR(Sα<sup>1</sup> ) ≤ hEAR(S). Therefore
    β((Sα<sup>1</sup> ) max) ≤ hEAR(S). By Lemmas [1](#page-4-2) and [4,](#page-4-4)
    ln |(Sα<sup>1</sup> ) max| ≤ hEAR(Sα<sup>1</sup> ) ln(k(S) + 1) ≤ hEAR(S) ln(k(S)
    + 1). Therefore the number of attributes values of which are computed by Γ during
    the second round is at most hEAR(S) 2 ln(k(S) + 1) + 1. This bound is true for
    each round. The number of rounds is at most hEAR(S). Thus, the depth of the decision
    tree Γ is at most hEAR(S) 3 ln(k(S) + 1) + hEAR(S).


    # <span id="page-6-0"></span>5 Conclusions


    In this paper, we considered a new algorithm with polynomial time complexity,
    which models the behavior of a decision tree solving the problem EAR(S) for a
    given tuple of attribute values. We studied the accuracy of this algorithm: we
    compared the depth of the decision tree described by it and the minimum depth
    of a decision tree. The obtained bound is a bit worse in the comparison with the
    bound for the algorithm considered in [\[13\]](#page-8-10). However, we expect
    that these two algorithms are mutually complementary: the old one will work better
    for systems with short decision rules and the new one will work better for systems
    with long decision rules. In the future, we are planning to do computer experiments
    to explore this hypothesis. We are also planning to develop a dynamic programming
    algorithm for the minimization of the depth of decision trees and to compare experimentally
    the depth of decision trees constructed by the two considered algorithms with
    the minimum depth.


    ### Acknowledgements


    Research reported in this publication was supported by King Abdullah University
    of Science and Technology (KAUST).


    # <span id="page-7-5"></span>References


    - <span id="page-7-6"></span>[1] Abdelhalim, A., Traor´e, I., Nakkabi, Y.: Creating
    decision trees from rules using RBDT-1. Comput. Intell. 32(2), 216–239 (2016)

    - [2] Abdelhalim, A., Traor´e, I., Sayed, B.: RBDT-1: A new rule-based decision
    tree generation technique. In: G. Governatori, J. Hall, A. Paschke (eds.) Rule
    Interchange and Applications, International Symposium, RuleML 2009, Las Vegas,
    Nevada, USA, November 5-7, 2009. Proceedings, *Lecture Notes in Computer Science*,
    vol. 5858, pp. 108–121. Springer (2009)

    - <span id="page-7-0"></span>[3] AbouEisha, H., Amin, T., Chikalov, I., Hussain,
    S., Moshkov, M.: Extensions of Dynamic Programming for Combinatorial Optimization
    and Data Mining, *Intelligent Systems Reference Library*, vol. 146. Springer (2019)

    - <span id="page-7-1"></span>[4] Alsolami, F., Azad, M., Chikalov, I., Moshkov,
    M.: Decision and Inhibitory Trees and Rules for Decision Tables with Many-valued
    Decisions, *Intelligent Systems Reference Library*, vol. 156. Springer (2020)

    - <span id="page-7-7"></span>[5] Blum, M., Impagliazzo, R.: Generic oracles and
    oracle classes (extended abstract). In: 28th Annual Symposium on Foundations of
    Computer Science, Los Angeles, California, USA, 27-29 October 1987, pp. 118–126.
    IEEE Computer Society (1987)

    - <span id="page-7-4"></span><span id="page-7-3"></span>[6] Boros, E., Hammer,
    P.L., Ibaraki, T., Kogan, A.: Logical analysis of numerical data. Math. Program.
    79, 163–190 (1997)

    - [7] Boros, E., Hammer, P.L., Ibaraki, T., Kogan, A., Mayoraz, E., Muchnik, I.B.:
    An implementation of logical analysis of data. IEEE Trans. Knowl. Data Eng. 12(2),
    292– 306 (2000)

    - <span id="page-7-2"></span>[8] Breiman, L., Friedman, J.H., Olshen, R.A., Stone,
    C.J.: Classification and Regression Trees. Wadsworth and Brooks (1984)

    - <span id="page-8-8"></span><span id="page-8-2"></span>[9] Buhrman, H., de Wolf,
    R.: Complexity measures and decision tree complexity: a survey. Theor. Comput.
    Sci. 288(1), 21–43 (2002)

    - <span id="page-8-0"></span>[10] Cao, H.E.C., Sarlin, R., Jung, A.: Learning
    explainable decision rules via maximum satisfiability. IEEE Access 8, 218180–218185
    (2020)

    - [11] Chikalov, I., Lozin, V.V., Lozina, I., Moshkov, M., Nguyen, H.S., Skowron,
    A., Zielosko, B.: Three Approaches to Data Analysis - Test Theory, Rough Sets
    and Logical Analysis of Data, *Intelligent Systems Reference Library*, vol. 41.
    Springer (2013)

    - <span id="page-8-9"></span>[12] Durdymyradov, K., Moshkov, M.: Bounds on depth
    of decision trees derived from decision rule systems. arXiv:2302.07063 [cs.CC]
    (2023). URL <https://doi.org/10.48550/arXiv.2302.07063>

    - <span id="page-8-10"></span>[13] Durdymyradov, K., Moshkov, M.: Construction
    of decision trees and acyclic decision graphs from decision rule systems. arXiv:2305.01721
    [cs.AI] (2023). URL <https://doi.org/10.48550/arXiv.2305.01721>

    - <span id="page-8-3"></span><span id="page-8-1"></span>[14] F¨urnkranz, J., Gamberger,
    D., Lavrac, N.: Foundations of Rule Learning. Cognitive Technologies. Springer
    (2012)

    - [15] Gilmore, E., Estivill-Castro, V., Hexel, R.: More interpretable decision
    trees. In: H. Sanjurjo-Gonz´alez, I. Pastor-L´opez, P.G. Bringas, H. Quinti´an,
    E. Corchado (eds.) Hybrid Artificial Intelligent Systems - 16th International
    Conference, HAIS 2021, Bilbao, Spain, September 22-24, 2021, Proceedings, *Lecture
    Notes in Computer Science*, vol. 12886, pp. 280–292. Springer (2021)

    - <span id="page-8-7"></span>[16] Hartmanis, J., Hemachandra, L.A.: One-way functions,
    robustness, and the nonisomorphism of NP-complete sets. In: Proceedings of the
    Second Annual Conference on Structure in Complexity Theory, Cornell University,
    Ithaca, New York, USA, June 16-19, 1987. IEEE Computer Society (1987)

    - <span id="page-8-5"></span><span id="page-8-4"></span>[17] Imam, I.F., Michalski,
    R.S.: Learning decision trees from decision rules: A method and initial results
    from a comparative study. J. Intell. Inf. Syst. 2(3), 279–304 (1993)

    - [18] Imam, I.F., Michalski, R.S.: Should decision trees be learned from examples
    of from decision rules? In: H.J. Komorowski, Z.W. Ras (eds.) Methodologies for
    Intelligent Systems, 7th International Symposium, ISMIS ''93, Trondheim, Norway,
    June 15-18, 1993, Proceedings, *Lecture Notes in Computer Science*, vol. 689,
    pp. 395–404. Springer (1993)

    - <span id="page-8-6"></span>[19] Imam, I.F., Michalski, R.S.: Learning for decision
    making: the FRD approach and a comparative study. In: Z.W. Ras, M. Michalewicz
    (eds.) Foundations of Intelligent Systems, 9th International Symposium, ISMIS
    ''96, Zakopane, Poland, June 9-13, 1996, Proceedings, *Lecture Notes in Computer
    Science*, vol. 1079, pp. 428–437. Springer (1996)

    - <span id="page-9-2"></span>[20] Kaufman, K.A., Michalski, R.S., Pietrzykowski,
    J., Wojtusiak, J.: An integrated multitask inductive database VINLEN: initial
    implementation and early results. In: S. Dzeroski, J. Struyf (eds.) Knowledge
    Discovery in Inductive Databases, 5th International Workshop, KDID 2006, Berlin,
    Germany, September 18, 2006, Revised Selected and Invited Papers, *Lecture Notes
    in Computer Science*, vol. 4747, pp. 116–133. Springer (2006)

    - <span id="page-9-3"></span>[21] Michalski, R.S., Imam, I.F.: Learning problem-oriented
    decision structures from decision rules: The AQDT-2 system. In: Z.W. Ras, M. Zemankova
    (eds.) Methodologies for Intelligent Systems, 8th International Symposium, ISMIS
    ''94, Charlotte, North Carolina, USA, October 16-19, 1994, Proceedings, *Lecture
    Notes in Computer Science*, vol. 869, pp. 416–426. Springer (1994)

    - <span id="page-9-4"></span><span id="page-9-1"></span>[22] Michalski, R.S.,
    Imam, I.F.: On learning decision structures. Fundam. Informaticae 31(1), 49–64
    (1997)

    - <span id="page-9-5"></span>[23] Molnar, C.: Interpretable Machine Learning.
    A Guide for Making Black Box Models Explainable, 2 edn. (2022). URL <christophm.github.io/interpretable-ml-book/>

    - <span id="page-9-6"></span>[24] Moshkov, M.: About the depth of decision trees
    computing Boolean functions. Fundam. Informaticae 22(3), 203–215 (1995)

    - <span id="page-9-10"></span>[25] Moshkov, M.: Comparative analysis of deterministic
    and nondeterministic decision tree complexity. Global approach. Fundam. Informaticae
    25(2), 201–214 (1996)

    - [26] Moshkov, M.: Some relationships between decision trees and decision rule
    systems. In: L. Polkowski, A. Skowron (eds.) Rough Sets and Current Trends in
    Computing, First International Conference, RSCTC''98, Warsaw, Poland, June 22-26,
    1998, Proceedings, *Lecture Notes in Computer Science*, vol. 1424, pp. 499–505.
    Springer (1998)

    - <span id="page-9-11"></span><span id="page-9-7"></span>[27] Moshkov, M.: Deterministic
    and nondeterministic decision trees for rough computing. Fundam. Informaticae
    41(3), 301–311 (2000)

    - [28] Moshkov, M.: On transformation of decision rule systems into decision trees
    (in Russian). In: Proceedings of the Seventh International Workshop Discrete Mathematics
    and its Applications, Moscow, Russia, January 29 – February 2, 2001, Part 1, pp.
    21–26. Center for Applied Investigations of Faculty of Mathematics and Mechanics,
    Moscow State University (2001)

    - <span id="page-9-8"></span>[29] Moshkov, M.: Classification of infinite information
    systems depending on complexity of decision trees and decision rule systems. Fundam.
    Informaticae 54(4), 345–368 (2003)

    - <span id="page-9-9"></span>[30] Moshkov, M.: Comparative analysis of deterministic
    and nondeterministic decision tree complexity. Local approach. In: J.F. Peters,
    A. Skowron (eds.) Trans. Rough Sets IV, *Lecture Notes in Computer Science*, vol.
    3700, pp. 125–143. Springer (2005)

    - <span id="page-9-0"></span>[31] Moshkov, M.: Time complexity of decision trees.
    In: J.F. Peters, A. Skowron (eds.) Trans. Rough Sets III, *Lecture Notes in Computer
    Science*, vol. 3400, pp. 244–459. Springer (2005)

    - <span id="page-10-11"></span><span id="page-10-2"></span>[32] Moshkov, M.: Comparative
    Analysis of Deterministic and Nondeterministic Decision Trees, *Intelligent Systems
    Reference Library*, vol. 179. Springer (2020)

    - [33] Moshkov, M., Piliszczuk, M., Zielosko, B.: Partial Covers, Reducts and
    Decision Rules in Rough Sets - Theory and Applications, *Studies in Computational
    Intelligence*, vol. 145. Springer (2008)

    - <span id="page-10-3"></span><span id="page-10-0"></span>[34] Moshkov, M., Zielosko,
    B.: Combinatorial Machine Learning - A Rough Set Approach, *Studies in Computational
    Intelligence*, vol. 360. Springer (2011)

    - [35] Pawlak, Z.: Rough Sets Theoretical Aspects of Reasoning about Data, *Theory
    and Decision Library: Series D*, vol. 9. Kluwer (1991)

    - <span id="page-10-6"></span><span id="page-10-4"></span>[36] Pawlak, Z., Skowron,
    A.: Rudiments of rough sets. Inf. Sci. 177(1), 3–27 (2007)

    - [37] Quinlan, J.R.: Generating production rules from decision trees. In: J.P.
    McDermott (ed.) Proceedings of the 10th International Joint Conference on Artificial
    Intelligence. Milan, Italy, August 23-28, 1987, pp. 304–307. Morgan Kaufmann (1987)

    - <span id="page-10-8"></span><span id="page-10-7"></span>[38] Quinlan, J.R.:
    C4.5: Programs for Machine Learning. Morgan Kaufmann (1993)

    - [39] Quinlan, J.R.: Simplifying decision trees. Int. J. Hum. Comput. Stud. 51(2),
    497–510 (1999)

    - <span id="page-10-5"></span><span id="page-10-1"></span>[40] Rokach, L., Maimon,
    O.: Data Mining with Decision Trees - Theory and Applications, *Series in Machine
    Perception and Artificial Intelligence*, vol. 69. World Scientific (2007)

    - [41] Silva, A., Gombolay, M.C., Killian, T.W., Jimenez, I.D.J., Son, S.: Optimization
    methods for interpretable differentiable decision trees applied to reinforcement
    learning. In: S. Chiappa, R. Calandra (eds.) The 23rd International Conference
    on Artificial Intelligence and Statistics, AISTATS 2020, 26-28 August 2020, Online
    [Palermo, Sicily, Italy], *Proceedings of Machine Learning Research*, vol. 108,
    pp. 1855–1865. PMLR (2020)

    - <span id="page-10-9"></span>[42] Szydlo, T., Sniezynski, B., Michalski, R.S.:
    A rules-to-trees conversion in the inductive database system VINLEN. In: M.A.
    Klopotek, S.T. Wierzchon, K. Trojanowski (eds.) Intelligent Information Processing
    and Web Mining, Proceedings of the International IIS: IIPWM''05 Conference held
    in Gdansk, Poland, June 13-16, 2005, *Advances in Soft Computing*, vol. 31, pp.
    496–500. Springer (2005)

    - <span id="page-10-10"></span>[43] Tardos, G.: Query complexity, or why is it
    difficult to separate NP <sup>A</sup> ∩ coNP <sup>A</sup> from P A by random oracles
    A? Comb. 9(4), 385–392 (1989)'
- id: automated_test_production_complement_to_ad_hoc_testing_automated_test_production_complement_to_ad_hoc_testing
  title: Automated Test Production -- Complement to "Ad-hoc" Testing
  abstract: 'A view on software testing, taken in a broad sense and considered a important

    activity is presented. We discuss the methods and techniques for applying tests

    and the reasons we recognize make it difficult for industry to adopt the

    advances observed in academia. We discuss some advances in the area and briefly

    point out the approach we intend to follow in the search for a solution.'
  url: http://arxiv.org/abs/2401.02230v1
  keywords: ''
  document: '# Automated Test Production Complement to "Ad-hoc" Testing


    Gomes, J.M.<sup>1</sup> and Dias, L.A.V.<sup>1</sup>


    1 Instituto Tecnol´ogico de Aeron´autica - ITA


    January 5, 2024


    #### Abstract


    A view on software testing, taken in a broad sense and considered a important
    activity is presented. We discuss the methods and techniques for applying tests
    and the reasons we recognize make it difficult for industry to adopt the advances
    observed in academia. We discuss some advances in the area and briefly point out
    the approach we intend to follow in the search for a solution.


    # 1 Motivation


    Accepting that tests are important, but are not always implemented or kept up
    to date during the lifetime of a program, we conclude that nothing has changed
    since the introduction of the Agile Manifesto earlier this century [\[1\]](#page-13-0)
    which we reproduce below and from which we highlight the passage "Software that
    works rather than complete documentation"[\[1\]](#page-13-0).


    - "Individuals and interactions over processes and tools"

    - "Working software over comprehensive documentation"

    - "Customer collaboration over contract negotiation"

    - "Responding to change over following a plan"


    This view has come to become an important industry trend [\[2\]](#page-13-1)[1](#page-0-0)
    , where face-to-face interactions are preferable to formal communication processes
    and working programs are preferable to comprehensive documentation, leaving the
    interpretation of the term "comprehensive" to each agile development team to decide
    [\[4](#page-13-2)]. In fact the agile method suggests that all documentation can
    be replaced by informal communication with an emphasis on tacit rather than explicit
    knowledge [\[5\]](#page-14-0).


    <span id="page-0-0"></span><sup>1</sup>The 14<sup>o</sup> annual report STATEofAGILE
    from 2020 points out that 95% of organizations practice agile software development
    methods. [\[3](#page-13-3)].


    On the other hand, the adoption of continuous integration and continuous delivery
    processes and tools has been steadily and unequivocally growing in both industry
    [\[6](#page-14-1), [7](#page-14-2)] and open source projects [\[8\]](#page-14-3),
    which can to some extent be interpreted as a denial of one of the principles of
    the Agile Manifesto: "Individuals and interactions over processes and tools",
    yet this does not come as a relief to the fact that many see benefits in building
    and maintaining formal models, but are not content to build them as they believe
    they consume too much time and resources, even believing in the slim chances of
    success of projects that do not use some modeling [\[9\]](#page-14-4).


    The implications of this view for the construction and maintenance of programs
    and the use and application of development methods and tools are discussed.


    # 2 Test Production Methods


    The present discussion is a contribution to the understanding of how software
    testing fits into the present realities perceived by both industry and academia,
    even if these realities, as we shall see, do not correspond and will not converge.
    The TDD (Test Driven Development) technique is widely cited and recommended by
    the signers of the Agile Manifesto [\[10\]](#page-14-5), even though it is not
    part of the manifesto or its twelve principles [\[1\]](#page-13-0), so we can
    conclude that the IT (Information Technology) industry at least recognizes the
    importance of testing programs. The academia, on the other hand, perceives program
    testing based on formal specifications as inevitable in pioneering studies since
    the 1970s [\[11,](#page-14-6) [12\]](#page-14-7), the foundations for combining
    formal methods and program testing being established and accepted, and it is up
    to the community to put them into practice, optimize and extend them.


    In general, we classify the tests in Formal: verifiable by theoretical means or
    pure logic; and Empirical: verifiable through observation or direct experience[2](#page-1-0)
    .


    ### 2.1 Formal Testing


    Hoare and Floyd introduced formal methods by introducing the "Hoare calculus"
    for proving the correctness of a program as well as the notions of pre and postconditions,
    invariants and assertions. His ideas were gradually developed into the current
    formal software engineering tools and techniques, such as the OCL (Object Constraint
    Language) [\[15](#page-14-8)] used to specify constraints in UML (Unified Modelling
    Language) diagrams.


    According to Gaudel, for each and every specification method, there is a notation
    [\[16](#page-14-9)]. Depending on the method, specifications can include expressions
    in various logical forms, used to write pre and postconditions, axioms of data
    types, constraints, temporal properties. They can represent definitions of process
    states, such as:


    <span id="page-1-0"></span><sup>2</sup>We take into account the formality of the
    test and not the conduct of the test, as it is perfectly possible to conduct empirical
    tests by adopting formal practices in their execution.


    - CSP (Communicating Sequential Processes) [\[17\]](#page-14-10)

    - CCS (Calculus of Communicating Systems) [\[18](#page-14-11)]

    - LOTOS (Language Of Temporal Ordering Specification) [\[19](#page-14-12)]

    - Circus [\[20\]](#page-14-13)


    Or they can have annotated diagrams, such as:


    - FSM (Finite State Machine) [\[21\]](#page-15-0)

    - LTS (Labelled Transition Systems) [\[22](#page-15-1)]

    - Petri Networks [\[23\]](#page-15-2)

    - etc.


    But there is more than a syntax. First, there is a formal semantics, in terms
    of mathematical notions such as:


    - Predicate transformers for pre and post conditions

    - Classified sets and algebras for axiomatic definitions

    - Various types of automata, traces, faults, divergences, for process algebras


    Second, there is a formal deduction system, making it possible to perform proofs,
    or other checks (such as model checking), or both. Thus, formal specifications
    can be analyzed to guide the identification of appropriate test cases.


    In addition to syntax, semantics, and the deduction system, formal methods come
    with some relations between specifications that formalize equivalence or correct
    step-by-step development. Depending on the context, such relations are called:
    refinement, conformance, or, in the case of formulas, satisfiability, and are
    fundamental to test methods [\[16\]](#page-14-9).


    Gaudel concludes that model-based tests are tests of the black-box [3](#page-2-0)
    type, where the internal organization of the program under test is ignored and
    the strategy is based on a description of the desired properties and behavior
    of the program[4](#page-2-1) , which may be formal or not, or in other words,
    these methods target certain classes of faults and assume that the program is
    exempt from other types and classes of faults [\[16\]](#page-14-9).


    <span id="page-2-0"></span><sup>3</sup>Method of validating functional and external
    aspects of a computer application.


    <span id="page-2-1"></span><sup>4</sup>We separate these tests into a category
    - that of Formal Tests - that is, tests with a formal basis and that originate
    from models.


    ### 2.2 Empirical Tests


    Without formal defined specifications a priori, which as we have seen in "Motivation"
    is a trend in the industry, we are left only with informal and empirical practice[5](#page-3-0)
    for the verification and validation of the correctness of computer program implementation[6](#page-3-1)
    . One of the practices advocated by supporters of agile methods is TDD, where
    tests are written even before the program itself, but it does not show clear benefits[7](#page-3-2)
    compared to the option of implementing the tests after the program is ready [\[25](#page-15-3),
    [26](#page-15-4), [27](#page-15-5)], or it may be linked to the fact that processes
    like TDD encourage stable and refined steps of continuous improvement [\[28\]](#page-15-6).


    In the informal test, we have a relation of the hypothesis to an observation statement,
    which is nothing more than a proposition about the perceptible properties of some
    entity, set of entities, or system, followed by a rule transmission where, if
    the observation statement directly confirms the hypothesis, then indirectly it
    confirms any of its logical consequences [\[29](#page-15-7)].


    We can state that formal tests are cases of inductive inference[8](#page-3-3)
    , and that in empirical tests we have a direct confirmation of the hypothesis,
    but without the soundness and precision that formal methods[9](#page-3-4) guarantee
    [\[30\]](#page-15-8) as a consequence of the ad hoc attitude with which the informality
    of design[10](#page-3-5) of empirical testing is practiced.


    Just as using only Formal Methods we are unable to judge all the possibilities
    of flaws that a program may present[\[31\]](#page-15-9), we can state that Empirical
    Methods are also so, and for the same reasons, with the aggravating factor of
    introducing a certain randomness[11](#page-3-6) to the process.


    ### 2.3 Static and Dynamic Analysis


    This is a case where the test can either be defined a priori (as in TDD or modelbased)
    or a posteriori (as most informal tests are done), and which according to Gaudel,
    would be the answer to the lack of coverage of Formal Tests, but which as we will
    see below, also present problems of application in practice.


    Static analysis was introduced in 1980 with the work "Methods to ensure the standardization
    of FORTRAN software. [PFORT, DAVE, POLISH, and BRNANL, for analysis and editing
    of codes, in FORTRAN for PDP-10 and IBM 360 and 370]" by Gaffney and Wooten [\[32](#page-15-10)].
    The nature of verification


    <span id="page-3-0"></span><sup>5</sup>Which generally means: verifiable by direct
    observation or experience rather than by theory or pure logic, even though it
    is possible to adopt formal practices during an empirical procedure.


    <sup>6</sup>Nothing prevents that, even starting from a basis of formal specifications,
    empirical tests be adopted in the verification of the implementation.


    <span id="page-3-1"></span><sup>7</sup>The practice of TDD is advocated mainly
    because the alternative is to have no tests at all after the program is ready[\[24\]](#page-15-11).


    <span id="page-3-3"></span><span id="page-3-2"></span><sup>8</sup>We cannot call
    "formal tests" a case of "indirect confirmation".


    <span id="page-3-4"></span><sup>9</sup>Formal methods pursue qualitative and quantitative
    metrics of the soundness and precision of the method itself.


    <sup>10</sup>And as we said earlier, not necessarily of the actual conduct, which
    can be perfectly formal.


    <span id="page-3-6"></span><span id="page-3-5"></span><sup>11</sup>The observer''s
    objectivity and his judgment.


    performed by static parsers include [\[33,](#page-15-12) [34\]](#page-15-13) (but
    not limited to only these) the following analyses:


    - Layout and source code formatting

    - Identifying language constructs known to be non-portable

    - Identifying algorithm constructs known to be unsafe

    - Use of variables or constants with suspect names and contents (for example:
    PASSWORD = ''SECRET'')

    - Detection of faults not considered by compilers

    - Control flow analysis (detection of loops)

    - Detect data usage in variables before a value has been entered

    - Detect value overloading in variables (assign a very large value to a variable
    that only supports small values - in some languages assign a DOUBLE value to a
    simple INT variable)

    - Detect memory overflow (leak) or the non-validation of may memory overflow (assigning
    a very long constant to a variable that supports a small memory size)

    - Detect leakage of handles (the reference to the control structure) of files
    and accesses to communication resources

    - Check permission to perform certain operations

    - Ensuring the termination of a processing (or ensuring indications that it will
    not terminate)

    - Ensure the order in which processing is performed and terminated in a way that
    maintains the integrity of the information (or ensure that it gives indications
    that the information is not intact)

    - Ensure that the process can be observed as deterministic[12](#page-4-0) (or
    ensure that there are indications that the process cannot be observed as deterministic)


    Many of these validations can be (and most often are) done by compilers (when
    the language is compiled)[\[35\]](#page-15-14). Since the purpose of the compiler
    is to generate executable code and not to check for programming faults, and other
    classes of faults can only be determined at runtime, such as memory overflow,
    which only occurs if a very long constant is supplied during program use,[13](#page-4-1)
    ,


    <span id="page-4-0"></span><sup>12</sup>If an action is visible to the environment
    (i.e. if it performs data retrieval or changes data), then we say it is observable.
    The order of execution of non-priority rules will make a difference in the order
    of appearance of observable actions.


    <span id="page-4-1"></span><sup>13</sup>Although it is possible, as we can see
    later, to predict overflow using one of the many static analysis methods available.


    | Classe                      | Descri¸c˜ao                                                                                                                                                         |

    |-----------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|

    | Lexical Analysis            | Lexical analysis is based on the grammatical structure
    of the language. It divides the                                                                              |

    |                             | program into small parts that are compared to
    known fault libraries. Disregarding                                                                                   |

    |                             | syntax, semantics and interaction between subroutines,
    the incidence of false posi                                                                                  |

    |                             | tives is high [42].                                                                                                                                                 |

    | Type Inference              | It infers the type of variables and functions
    by the compiler or interpreter, and checks                                                                            |

    |                             | that accesses to these variables and functions
    conform to predefined rules for the type                                                                             |

    | Data Flow                   | [43].<br>Refers to collecting semantic information
    from source code, and using algebraic                                                                            |

    | Analysis                    | method determines the definition and use of variables
    at compile time.<br>Starting                                                                                  |

    |                             | from the execution flow graph, a data flow analysis
    determines whether values in a                                                                                  |

    |                             | program are flagged as potentially vulnerable
    variables [44].                                                                                                       |

    | Rule Checking               | Checks the security of a program using pre-set
    rules [45]. Some rules, such as re                                                                                   |

    |                             | quiring execution under elevated privilege, carry
    security implications [42] and are                                                                                |

    |                             | detected.                                                                                                                                                           |

    | Constraints                 | Divided between constraint generation and constraint
    resolution during the analysis                                                                                 |

    | Analysis                    | process. Constraint generation sets variable types
    or analyzes the constraint system                                                                                |

    |                             | between different states of execution using predetermined
    rules; constraint resolution                                                                              |

    |                             | applies and resolves the generated constraints
    [42].                                                                                                                |

    | Comparison of<br>Correction | Comparison of source or binary code snippets changed
    during the process of fixing                                                                                   |

    | Snippets                    | flaws is used to find known implementation gaps.
    After patches have been applied<br>to a program, the comparison serves to determine
    the location and causes of the |

    |                             | vulnerability to which they apply [42].                                                                                                                             |

    | Symbolic                    | It represents program inputs as symbols instead
    of the actual data, and produces al                                                                                 |

    | Execution                   | gebraic expressions over the symbol in the implementation
    process. By the constraint                                                                                |

    |                             | solving method symbolic execution can detect possible
    failures [46, 47, 48, 49].                                                                                    |

    | Abstract<br>Interpretation  | It is a formal description of program analysis,
    which maps the program to abstract                                                                                  |

    |                             | domains. The technique requires completeness,
    which makes it impractical for very                                                                                   |

    |                             | large programs, but proves correct for all possible
    inputs [50, 51].                                                                                                |

    | Proof of<br>Theorems        | Semantic analysis of the program, which can solve
    infinite state system problems [52,                                                                               |

    |                             | 53]. First convert the program into a logical
    formula, then prove that the program is                                                                               |

    |                             | a valid theorem using axioms and rules [42].                                                                                                                        |

    | Model<br>Verification       | Starting from formal models, such as state machines
    or directed graphs, it runs<br>through them and compares the model with the implementation
    to see if it matches |

    |                             | the characteristics predefined by the first [54].                                                                                                                   |

    |                             |                                                                                                                                                                     |


    <span id="page-5-0"></span>Table 1: Classification of Static Analyzers


    then specialized checkers such as Linters[\[36\]](#page-16-9) are adopted. Capable
    of detecting a wide range of faults, including style (layout of source code),
    some use source code annotations to achieve better problem detection, at the expense
    of extra developer work [\[37,](#page-16-10) [38,](#page-16-11) [39,](#page-16-12)
    [40,](#page-16-13) [41\]](#page-16-14).


    Static analyzers can then be classified (see Table [1\)](#page-5-0) into various
    types and capabilities, covering the detection of several possible fault categories,
    from implementation to vulnerability and security related.


    The problem with static analyzers is the high false positive rate (alerts that
    are not real problems), low understandability of alerts and lack of automation
    in quick fixes for the large number of identified problems [\[55\]](#page-17-4),
    such as: [\[56](#page-17-5)] code structure and [\[57](#page-17-6)] coding patterns,
    which could easily be fixed using automatic refactoring techniques [\[58](#page-17-7)],
    but as we will see below, the available tools are not in line with the latest
    advances made by the scientific community.


    Dynamic analysis, on the other hand, is in contrast to static analysis and contemplates
    the forms best known and adopted by the industry in the appli-


    | Classe           | Descri¸c˜ao                                                                            |

    |------------------|----------------------------------------------------------------------------------------|

    | Unit Test        | The process of testing subprograms, subroutines, classes,
    or functional units within   |

    |                  | a program to verify that there are no programming flaws [60,
    p. 486].                  |

    | Integration Test | Testing phase where the functional units are combined and
    tested as a group to assess  |

    |                  | whether they worked properly in the complete system [60,
    p. 235].                      |

    | System Testing   | Test conducted on multiple integrated systems to evaluate
    their ability to communi     |

    |                  | cate with each other and achieve general and specific integration
    requirements [60,    |

    |                  | p. 545].                                                                               |

    | Acceptance Test  | Testing of a system or functional unit generally performed
    by the buyer or user on     |

    |                  | site after installation of the software to make sure that
    the contractual requirements |

    |                  | have been met [60, p. 5].                                                              |


    <span id="page-6-0"></span>Table 2: Classification of Dynamic Tests


    cation of software testing [\[59\]](#page-17-9) (see Table [2\)](#page-6-0).


    # 3 The Challenge of Testing


    ### 3.1 Software Quality


    C. A. R. Hoare in the research "How did software get so reliable without proof?"
    conducted in 1996 states that it was reasonable to predict that the size and ambition
    of software products would be severely limited by the lack of reliability in their
    components. Estimates suggested, in its study, that professionally written programs
    may contain between one and ten correctable faults for every thousand lines of
    code; and any one software fault, in principle, can have a spectacular effect
    (or worse: a subtly misleading effect) on the behavior of the entire system [\[61\]](#page-17-10).


    Hoare found at the time that the software patch problem turned out to be far less
    serious than anticipated. An analysis by Mackenzie [\[62\]](#page-17-11) showed
    that of several thousand deaths attributed to computer applications, only ten
    or so could be explained by software crashes: most due to a few cases of incorrect
    dosage calculations in radiation cancer treatment. Similarly, predictions of collapse
    due to the size of computer programs have been falsified by the continuous operation
    of real-time software systems now measured in tens of millions of lines of code
    and subject to thousands of updates per year.


    In his review Hoare concludes that, despite appearances, modern software engineering
    practice owes much to the theoretical concepts and ideals of early research in
    this field; and that formalization and proof techniques have played an essential
    role in the validation and progress of research.


    Hoare concludes that the main factors for the apparent success of the software
    are:


    • Management - The most dramatic advances in the delivery of reliable software
    are directly attributable to a wider recognition of the fact that the process
    of program development can be predicted, planned, managed, and controlled just
    as in any other branch of engineering.


    - Test Thorough testing is the cornerstone of reliability in quality assurance
    and control in modern production engineering. Tests are applied as early as possible
    throughout the production line. They are rigorously designed to maximize the probability
    of detecting failures and as quickly as possible.

    - Debugging The secret of successful testing is that it checks the quality of
    the process and methods by which the code was produced. But there is an entirely
    different and very common response to the discovery of a flaw by testing: simply
    fix it and get on with the job. This is known as debugging, by analogy with trying
    to get rid of a mosquito infestation by killing the ones that bite - much faster,
    cheaper and more satisfying than draining the swamps in which they breed.

    - Excess Engineering The concept of safety factor is very widespread in engineering.
    After calculating the worst case load on a beam, the civil engineer will try to
    build it at least twice as strong. In computing, a continuous drop in the price
    of storage and increased processing power has made it acceptable to add redundancies
    to reduce the risk of software failures and a smaller scale of damage. This leads
    to the same kind of over-engineering required by law for bridge construction;
    and it is extremely effective, although there is no clear way to measure it by
    a numerical factor.

    - Programming Methodologies Most of the measures described so far for achieving
    reliability in software are the same ones that have been proven equally effective
    in all engineering disciplines. But the best general techniques for management,
    quality control, and safety would be totally useless by themselves; they are only
    effective when there is a general understanding, a common conceptual framework
    and terminology for discussing the relationship between cause and effect, between
    action and consequence. Research in programming methodology has this goal: to
    establish a conceptual framework and a theoretical basis to assist in the systematic
    derivation and justification of each design decision by a rational and explicable
    line of reasoning.


    ### 3.2 Perceived Quality when Using Software


    According to the NIST (National Institute of Standards and Technology) report,
    the estimated impact (in the United States) of inadequate software testing infrastructure
    is 859 billions dollars and the potential cost savings from feasible improvements
    is 822 billions dollars. Software users account for a larger share of the total
    costs of inadequate infrastructure (64 percent) compared to "viable" cost reductions
    (52 percent) because a large share of user costs are due to prevention activities.
    Whereas mitigation activities decrease proportionally to the decrease in the number
    of failures, prevention costs (such as redundant systems and investigating purchasing
    decisions) are likely to persist, even if only a few errors are expected. For
    software developers, the feasible cost savings are


    |            | Testers /<br>Employees<br>(millions) | Cost of inadequate<br>testing
    infrastructure |                              | Potential cost reduction<br>with
    feasible improvements |                              |

    |------------|--------------------------------------|----------------------------------------------|------------------------------|--------------------------------------------------------|------------------------------|

    |            |                                      | Unit cost                                    |
    Total cost<br>(million US\$) | Unit cost<br>(million US\$)                            |
    Total Cost<br>(million US\$) |

    | Developers | 0,302                                | 69.945                                       |
    21.155                       | 34.964                                                 |
    10.575                       |

    | Users      |                                      |                                              |                              |                                                        |                              |

    | Industry   | 25,0                                 | 459                                          |
    11.463                       | 135                                                    |
    3.375                        |

    | Services   | 74,1                                 | 362                                          |
    26.858                       | 112                                                    |
    8.299                        |

    | Total      |                                      |                                              |
    59.477                       |                                                        |
    22.249                       |


    Table 3: Estimated national impact in the US (adapted from [\[63\]](#page-17-12))


    approximately 50 percent of the total costs of inadequate infrastructure. This
    reflects a more proportional decrease in testing effort as testing resources and
    tools improve [\[63\]](#page-17-12).


    If we add up everything from minor inconveniences in our daily lives to incalculable
    human and social damage from software failures, the perception we have may be
    quite different from that of Hoare in his study. This is because today the penetration
    of computerized systems in our lives, with its own challenges and opportunities
    due to the great convergence of connected systems, interoperability and massive
    distribution of information, can make the most insignificant failure from a mere
    annoyance (such as losing access to your favorite music playlist) to a catastrophe
    of global proportions (such as a widespread failure in a worldwide satellite communications
    system).


    ### 3.3 The Gap Between Industry and Scientific Advances


    In 1996 Hoare noted that academic research gains in programming methodologies
    took up to 20 years to be adopted by industry as a sign of maturity and sanity
    - only in very specific areas and for a brief period would it be justified to
    apply the latest pure research advances to people''s everyday lives [\[61\]](#page-17-10).
    This mismatch also has the benefit of providing adequate planning of research
    and education as well as adequacy of the installed park in the industry. The result
    of not following this step is to adopt immature technologies and practices, with
    unpredictable and undesirable results, with no skilled labor available to apply
    it and make the necessary corrections when failures occur[14](#page-8-0) .


    Another consequence of not observing the maturity of cutting-edge research before
    its adoption in practice is the fact that, paradoxically, mature and effective
    technologies have not yet been adopted by industry, or when they are, they are
    isolated cases that cause astonishment when they present better results than those
    obtained with "state-of-the-art technologies". As an example we cite the adoption
    of the pairwise technique for test generation. The mathematical theory behind
    this technique has been around since the 1960s (see DESIGN, TESTING AND ESTIMATION
    IN COMPLEX EXPERIMENTATION. I. EXPANSIBLE AND CONTRACTIBLE FACTORIAL DESIGNS AND
    THE APPLICATION


    <span id="page-8-0"></span><sup>14</sup>If this scenario sounds like something
    that is happening in your industry, then maybe this is the reason.


    | Research                                               | Type      | Tests  |
    Time | Defects |

    |--------------------------------------------------------|-----------|--------|------|---------|

    | "A case study on pairwise testing application"<br>[66] | Ad<br>hoc | 14,041
    | 20h  | 10      |

    |                                                        | Pairwise  | 68     |
    4h   | 10      |

    | "A case study using testing technique for soft         | Manual    | 159    |
    6h   | 3       |

    | ware as a service (SaaS)" [67]                         | Pairwise  | 17     |
    1h   | 3       |


    <span id="page-9-0"></span>Table 4: Pairwise Application Research Results


    OF LINEAR PROGRAMMING TO COMBINATORIAL PROBLEMS publishied in 1965 [\[64](#page-17-13)]),
    the application in software testing using pairwise was presented earlier this
    century (see Combinatorial group testing and its applications published in 2000
    [\[65](#page-17-14)]). Recent research using these techniques (see Table [4\)](#page-9-0)
    shows promising numbers[15](#page-9-1):


    With results like this, it was expected that the adoption of the Pairwise technique
    to tests production in a cost-effective way would be more welcomed by the industry[16](#page-9-2)
    .


    # 4 Promises of Formal Development


    ### 4.1 Model Driven Development


    One of the most promising approaches to computer program development was MDD (Model
    Drive Development) and MDA (Model Drive Architecture), where models are the primary
    artifacts and the others, such as code, are generated from them [\[68\]](#page-18-2).
    The goal is to raise the level of abstraction, making software development closer
    to solving the requirements and problems outlined by its future users and making
    the developer''s life simpler and easier [\[69](#page-18-3)] and providing mainly
    automation of the process [\[70](#page-18-4)]. According to Yusuf et al. and Swithinbank
    et al., the advantages of using MDD are:


    - Increased developer productivity because of automation and focus on requirements
    analysis

    - Ease of maintenance many software was developed by specialists who left the
    organization at some point, and the technique would facilitate the evolution by
    retaining the knowledge of these specialists

    - Legacy reuse can make it easy and feasible to migrate old applications to new
    systems by applying the technique


    <span id="page-9-1"></span><sup>15</sup>We are aware that this sampling is neither
    meaningful nor representative, but only illustrative from our point of view.


    <span id="page-9-2"></span><sup>16</sup>Informally, in our contacts with software
    development practitioners and testing experts and discussions about the practice
    of Pairwise have ranged from ignorance of its existence to negative concepts and
    objections to its use as ineffective.


    - Adaptability adding or modifying is made easy given the automation already in
    place

    - Consistency every application will strictly follow the pattern established by
    the tools

    - Repetition great return on investment if applied throughout an organization

    - Improved communication with sponsors models are easier to interpret than code

    - Improved project communication templates help to understand the system design
    and assist in the discussion about the system itself

    - Domain knowledge capture if there is sufficient documentation of the system,
    the organization''s knowledge is maintained

    - Long-term asset high-level models and abstractions of business solutions are
    immune to technological change

    - Ability to postpone technology decisions focus on solving business problems
    allows decisions on non-functional problems to be left for a more opportune time


    #### 4.1.1 Problems with models


    The biggest problem with using models as the only source for software production
    is that trying to solve an organizational problem from conceptual abstractions
    larger than the machine languages used by computers to run programs implies a
    reduction of information [\[72](#page-18-5), p. 90]. This information has to be
    supplanted by the MDD tool itself by means of ready-made patterns, or from the
    developer by means of extensions, and that leads, according to Hailpern and Tarr
    [\[69\]](#page-18-3) to other problems:


    - Redundancy because of the widespread use of ready-made code examples

    - Unbridled back and forth problems to adjust the model to conform to another
    system or module

    - Moving complexity elsewhere rather than reducing it, requiring even more specialization


    #### 4.1.2 Future of MDD


    Standardization around UML and tool interoperability around the XMI (XML Metadata
    Interchange)[\[73\]](#page-18-6) standard can lead the open source community to
    produce products that can leverage development using MDD. Tools such as the Eclipse
    Modeling Framework (see <https://www.eclipse.org/modeling/emf/>) is an example
    of technology with this kind of potential, however this leads us to another conclusion.


    #### 4.1.3 Prospects


    Our view is that, the main barrier to the adoption of technologies like MDD, is
    how quickly this kind of solution becomes irrelevant.


    This irrelevance happens as the application and use of information technologies
    and platforms evolve.


    In the 1970s and 1980s, the adoption of CASE (Computer Aided Software Engineering)
    tools, which we can say were the precursors of MDD and MDA, was seen as a solution
    to the same problems we have listed above. At that time software development took
    place mainly on large computers, the Mainframes. But at the same time personal
    computers emerged, which at first were not seen as business tools, this soon became
    an untruth with the release of the IBM PC in 1981[\[74\]](#page-18-7) and since
    then software development has moved from the older and more expensive platform
    (Mainframes) to the more modern and cheaper (PCs (Personal Computers)), and this
    became increasingly true with the adoption of local networks like Novell in 1979
    [\[75](#page-18-8)] with over 500.000 computers installed in the world [\[76\]](#page-18-9)
    at the time. This movement continued, but once again changed focus. In 1989 Tim
    Berners-Lee invented the World Wide Web, in 1993 we had the release of the Mosaic
    browser by NCSA (National Center for Supercomputing Applications), and in 1994
    we had Netscape Navigator created by the same developers, now in a private company
    of the same name. Since then the development has been turning to applications
    presented by the browsers but running on corporate servers on the Internet. In
    early 2007 Apple introduces the iPhone, and at the end of the following year Google
    introduces Android. Still supported by the basic Internet infrastructure, application
    development shifts focus once again to the new mobile platform. And these days,
    some technologies are on the threshold, or at least promise to be, of creating
    new platforms, and among them we can mention Bitcoin (announced in 2009), virtual
    reality (as used in airplane pilot training and introduced as a consumer product
    in the 1990s by computer game companies like Sega in 1991) and augmented reality
    (made popular in games like Pok´emon Go in 2016) and finally the renaissance of
    Artificial Intelligence with the adoption of Machine Learning techniques.


    This rapid evolution and shift of focus to different platforms, with different
    approaches that decisively impact the architecture of the systems, databases,
    operating systems, programming languages, forms of presentation, number of application
    layers, and different APIs (Application Programming Interfaces) employed to mediate
    an increasingly large and complex network of interconnected products and services
    makes it practically impossible to develop, train personnel, and make them productive
    in the employment of any technology with the nature of the MDDs tools, which end
    up being relegated only to the role of modeling, right at the initial requirements
    gathering phase, within a longer development life cycle and without fulfilling
    the promise of covering it completely that has been made since the 1970s and 1980s
    by the CASE[\[77](#page-18-10)] tools, and which, as we saw earlier in this introduction,
    often does not motivate software development professionals and decision makers
    to bear the cost and time required in their absortion and deployment.


    # 5 Conclusions and Future Work


    If in one hand we have the promise of great advances and improvements in the quality
    of software products by applying techniques and tools developed by both academia
    and industry, despite the expected (and even desirable) delay between the development
    and adoption of these new technologies, we also have on the other hand the adoption
    of practices by the industry that make it difficult to incorporate certain mature
    technologies, or even to put them to the test, due to the lack of formalization
    that these practices prescribe in the name of agility in producing products quickly
    and meeting the desires of their customers.


    Without the adoption of formal software development methods, it is not possible
    to continue and progress with the advanced quality methods and methodologies developed
    in academia.


    The solution to this would be a back-and-forth approach, whereby by reverse engineering
    and starting from the source code of the computer programs, formal models are
    deduced and then complemented by the developers in order to produce the artifacts
    and inputs necessary for formal methods of quality verification and validation.
    Automation and adoption of standards are key to keeping costs within acceptable
    parameters for the industry.


    This approach has its pros and cons. Using reverse engineering to produce formal
    models will cause loss of information [17](#page-12-0), and this and other problems
    to come are what we set out to address.


    We intend to continue these studies with an analysis of the State of the Art in
    the conception and production of computer program tests, followed by ways of bringing
    together the methods and practices adopted by industry and the techniques developed
    by academia.


    <span id="page-12-0"></span><sup>17</sup>In general, models should have less information
    than the finished products that originated from them


    # Acronyms


    | API                | Application Programming Interface 12                                                                                  |  |  |

    |--------------------|-----------------------------------------------------------------------------------------------------------------------|--|--|

    | CASE<br>CCS<br>CSP | Computer Aided Software Engineering 12<br>Calculus of Communicating
    Systems 3<br>Communicating Sequential Processes 3 |  |  |

    | FSM                | Finite State Machine 3                                                                                                |  |  |

    | IT                 | Information Technology 2                                                                                              |  |  |

    | LOTOS<br>LTS       | Language Of Temporal Ordering Specification 3<br>Labelled
    Transition Systems 3                                        |  |  |

    | MDA<br>MDD         | Model Drive Architecture 10, 12<br>Model Drive Development
    10–12                                                      |  |  |

    | NCSA<br>NIST       | National Center for Supercomputing Applications 12<br>National
    Institute of Standards and Technology 8                |  |  |

    | OCL                | Object Constraint Language 2                                                                                          |  |  |

    | PC                 | Personal Computer 12                                                                                                  |  |  |

    | TDD                | Test Driven Development 2, 4                                                                                          |  |  |

    | UML                | Unified Modelling Language 2, 11                                                                                      |  |  |

    | XMI<br>XML         | XML Metadata Interchange 11<br>Extensible Markup Language
    11                                                          |  |  |


    # <span id="page-13-0"></span>References


    - <span id="page-13-1"></span>[1] K. Beck et al., "Manifesto for agile software
    development," 2001.

    - [2] B. Ramesh, L. Cao, K. Mohan, and P. Xu, "Can distributed software development
    be agile?" Communications of the ACM, vol. 49, no. 10, pp. 41–46, 2006.

    - <span id="page-13-3"></span>[3] V. One, "14th annual state of agile report,"
    Online: https://stateofagile.com, 2020.

    - <span id="page-13-2"></span>[4] R. Hoda, J. Noble, and S. Marshall, "How much
    is just enough? some documentation patterns on agile projects," in Proceedings
    of the 15th European Conference on Pattern Languages of Programs, 2010, pp. 1–13.

    - <span id="page-14-0"></span>[5] A. Cockburn and J. Highsmith, "Agile software
    development, the people factor," Computer, vol. 34, no. 11, pp. 131–133, 2001.

    - <span id="page-14-1"></span>[6] D. G. Feitelson, E. Frachtenberg, and K. L.
    Beck, "Development and deployment at facebook," IEEE Internet Computing, vol.
    17, no. 4, pp. 8–17, 2013.

    - <span id="page-14-2"></span>[7] G. G. Claps, R. B. Svensson, and A. Aurum, "On
    the journey to continuous deployment: Technical and social challenges along the
    way," Information and Software technology, vol. 57, pp. 21–31, 2015.

    - <span id="page-14-3"></span>[8] M. Hilton, T. Tunnell, K. Huang, D. Marinov,
    and D. Dig, "Usage, costs, and benefits of continuous integration in open-source
    projects," in 2016 31st IEEE/ACM International Conference on Automated Software
    Engineering (ASE), IEEE, 2016, pp. 426–437.

    - <span id="page-14-4"></span>[9] M. Canat, N. P. Catal`a, A. Jourkovski, S. Petrov,
    M. Wellme, and R. Lagerstr¨om, "Enterprise architecture and agile development:
    Friends or foes?" In 2018 IEEE 22nd International Enterprise Distributed Object
    Computing Workshop (EDOCW), IEEE, 2018, pp. 176–183.

    - <span id="page-14-5"></span>[10] K. Beck, "Aim, fire [test-first coding]," IEEE
    Software, vol. 18, no. 5, pp. 87–89, 2001.

    - <span id="page-14-6"></span>[11] J. B. Goodenough and S. L. Gerhart, "Toward
    a theory of test data selection," IEEE Transactions on software Engineering, no.
    2, pp. 156–173, 1975.

    - <span id="page-14-7"></span>[12] T. S. Chow, "Testing software design modeled
    by finite-state machines," IEEE transactions on software engineering, no. 3, pp.
    178–187, 1978.

    - [13] C. A. R. Hoare, "An axiomatic basis for computer programming," Communications
    of the ACM, vol. 12, no. 10, pp. 576–580, 1969.

    - [14] R. W. Floyd, "Toward interactive design of correct programs," in Readings
    in artificial intelligence and software engineering, Elsevier, 1986, pp. 331–
    334.

    - <span id="page-14-8"></span>[15] J. B. Warmer and A. G. Kleppe, The Object Constraint
    Language: Precise Modeling with UML. Addison Wesley, 1999.

    - <span id="page-14-9"></span>[16] M.-C. Gaudel, "Formal methods for software
    testing," in 2017 International Symposium on Theoretical Aspects of Software Engineering
    (TASE), IEEE, 2017, pp. 1–3.

    - <span id="page-14-11"></span><span id="page-14-10"></span>[17] B. Roscoe, "The
    theory and practice of concurrency," 1998.

    - [18] R. Milner, "Lectures on a calculus for communicating systems," in International
    Conference on Concurrency, Springer, 1984, pp. 197–220.

    - <span id="page-14-12"></span>[19] E. Brinksma, "An algebraic language for the
    specification of the temporal order of events in services and protocols," in Proc.
    of the European Teleinformatics Conference, Varese, Italy, 1983, pp. 533–542.

    - <span id="page-14-13"></span>[20] M. de Almeida Xavier, "Defini¸c˜ao e implementa¸c˜ao
    do sistema de tipos da linguagem circus," M.S. thesis, Universidade Federal de
    Pernambuco, 2006.

    - <span id="page-15-1"></span><span id="page-15-0"></span>[21] M. L. Minsky, Computation.
    Prentice-Hall Englewood Cliffs, 1967.

    - [22] E. M. Clarke, E. A. Emerson, and A. P. Sistla, "Automatic verification
    of finite-state concurrent systems using temporal logic specifications," ACM Transactions
    on Programming Languages and Systems (TOPLAS), vol. 8, no. 2, pp. 244–263, 1986.

    - <span id="page-15-11"></span><span id="page-15-2"></span>[23] C. A. Petri and
    W. Reisig, "Petri net," Scholarpedia, vol. 3, no. 4, p. 6477, 2008.

    - [24] B. George and L. Williams, "A structured experiment of test-driven development,"
    Information and software Technology, vol. 46, no. 5, pp. 337– 342, 2004.

    - <span id="page-15-3"></span>[25] F. Shull, G. Melnik, B. Turhan, L. Layman,
    M. Diep, and H. Erdogmus, "What do we know about test-driven development?" IEEE
    software, vol. 27, no. 6, pp. 16–19, 2010.

    - <span id="page-15-4"></span>[26] M. Josefsson, "Making architectural design
    phase obsolete-tdd as a design method," in Seminar course on SQA in Agile Software
    Development Helsinki University of Technology, 2004.

    - <span id="page-15-5"></span>[27] L. Madeyski, "The impact of test-first programming
    on branch coverage and mutation score indicator of unit tests: An experiment,"
    Information and Software Technology, vol. 52, no. 2, pp. 169–184, 2010.

    - <span id="page-15-6"></span>[28] D. Fucci, H. Erdogmus, B. Turhan, M. Oivo,
    and N. Juristo, "A dissection of the test-driven development process: Does it
    really matter to test-first or to test-last?" IEEE Transactions on Software Engineering,
    vol. 43, no. 7, pp. 597–614, 2016.

    - <span id="page-15-7"></span>[29] C. G. Hempel, "Studies in the logic of confirmation
    (i.)," Mind, vol. 54, no. 213, pp. 1–26, 1945.

    - <span id="page-15-8"></span>[30] G. ISO, "Information technology, open systems
    interconnection, conformance testing methodology and framework," International
    Standard IS, vol. 9646, 1991.

    - <span id="page-15-9"></span>[31] E. Dijkstra, "Structured programming," in Classics
    in software engineering, 1979, pp. 41–48.

    - <span id="page-15-10"></span>[32] P. W. Gaffney and J. W. Wooten, "Methods to
    ensure the standardization of fortran software. [pfort, dave, polish, and brnanl,
    for analysis and editing of codes, in fortran for pdp-10 and ibm 360 and 370],"
    May 1980.

    - <span id="page-15-12"></span>[33] A. Aiken, J. M. Hellerstein, and J. Widom,
    "Static analysis techniques for predicting the behavior of active database rules,"
    ACM Transactions on Database Systems (TODS), vol. 20, no. 1, pp. 3–41, 1995.

    - <span id="page-15-13"></span>[34] N. Ayewah, W. Pugh, D. Hovemeyer, J. D. Morgenthaler,
    and J. Penix, "Using static analysis to find bugs," IEEE software, vol. 25, no.
    5, pp. 22– 29, 2008.

    - <span id="page-15-14"></span>[35] R. P. Wilson and M. S. Lam, "Efficient context-sensitive
    pointer analysis for c programs," ACM Sigplan Notices, vol. 30, no. 6, pp. 1–12,
    1995.

    - <span id="page-16-10"></span><span id="page-16-9"></span>[36] I. F. Darwin,
    Checking C Programs with lint. " O''Reilly Media, Inc.", 1988.

    - [37] D. Evans, "Static detection of dynamic memory errors," ACM SIGPLAN Notices,
    vol. 31, no. 5, pp. 44–53, 1996.

    - <span id="page-16-11"></span>[38] D. Jackson, "Aspect: Detecting bugs with abstract
    dependences," ACM Transactions on Software Engineering and Methodology (TOSEM),
    vol. 4, no. 2, pp. 109–145, 1995.

    - <span id="page-16-12"></span>[39] D. L. Detlefs, "An overview of the extended
    static checking system," in Proceedings of The First Workshop on Formal Methods
    in Software Practice, Citeseer, 1996, pp. 1–9.

    - <span id="page-16-13"></span>[40] D. L. Detlefs, K. R. M. Leino, G. Nelson,
    and J. B. Saxe, "Extended static checking," 1998.

    - <span id="page-16-14"></span>[41] J. L. Jensen, M. E. Jørgensen, M. I. Schwartzbach,
    and N. Klarlund, "Automatic verification of pointer programs using monadic second-order
    logic," in Proceedings of the ACM SIGPLAN 1997 conference on Programming language
    design and implementation, 1997, pp. 226–234.

    - <span id="page-16-0"></span>[42] P. Li and B. Cui, "A comparative study on software
    vulnerability static analysis techniques and tools," in 2010 IEEE international
    conference on information theory and information security, IEEE, 2010, pp. 521–524.

    - <span id="page-16-1"></span>[43] C. Hankin and D. Le M´etayer, "Deriving algorithms
    from type inference systems: Application to strictness analysis," in Proceedings
    of the 21st ACM SIGPLAN-SIGACT symposium on Principles of programming languages,
    1994, pp. 202–212.

    - <span id="page-16-2"></span>[44] L. D. Fosdick and L. J. Osterweil, "Data flow
    analysis in software reliability," ACM Computing Surveys (CSUR), vol. 8, no. 3,
    pp. 305–330, 1976.

    - <span id="page-16-3"></span>[45] F. Hayes-Roth, "Rule-based systems," Communications
    of the ACM, vol. 28, no. 9, pp. 921–932, 1985.

    - <span id="page-16-4"></span>[46] R. S. Boyer, B. Elspas, and K. N. Levitt, "Select—a
    formal system for testing and debugging programs by symbolic execution," ACM SigPlan
    Notices, vol. 10, no. 6, pp. 234–245, 1975.

    - <span id="page-16-5"></span>[47] J. C. King, "Symbolic execution and program
    testing," Communications of the ACM, vol. 19, no. 7, pp. 385–394, 1976.

    - <span id="page-16-6"></span>[48] W. E. Howden, "Experiments with a symbolic
    evaluation system," in Proceedings of the June 7-10, 1976, national computer conference
    and exposition, 1976, pp. 899–908.

    - <span id="page-16-7"></span>[49] L. A. Clarke, "A program testing system," in
    Proceedings of the 1976 annual conference, 1976, pp. 488–491.

    - <span id="page-16-8"></span>[50] S. Abramsky and C. Hankin, Abstract interpretation
    of declarative languages. Prentice Hall Professional Technical Reference, 1987.

    - <span id="page-17-0"></span>[51] F. Nielson and N. Jones, "Abstract interpretation:
    A semantics-based tool for program analysis," Handbook of logic in computer science,
    vol. 4, pp. 527–636, 1994.

    - <span id="page-17-1"></span>[52] M. Davis, "The early history of automated deduction:
    Dedicated to the memory of hao wang," in Handbook of Automated Reasoning, Elsevier,
    2001, pp. 3–15.

    - <span id="page-17-2"></span>[53] W. Bibel, "Early history and perspectives of
    automated deduction," in Annual Conference on Artificial Intelligence, Springer,
    2007, pp. 2–18.

    - <span id="page-17-3"></span>[54] E. M. Clarke Jr, O. Grumberg, D. Kroening,
    D. Peled, and H. Veith, Model checking. MIT press, 2018.

    - <span id="page-17-4"></span>[55] B. Johnson, Y. Song, E. Murphy-Hill, and R.
    Bowdidge, "Why don''t software developers use static analysis tools to find bugs?"
    In 2013 35th International Conference on Software Engineering (ICSE), IEEE, 2013,
    pp. 672–681.

    - <span id="page-17-5"></span>[56] S. Panichella, V. Arnaoudova, M. Di Penta,
    and G. Antoniol, "Would static analysis tools help developers with code reviews?"
    In 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and
    Reengineering (SANER), IEEE, 2015, pp. 161–170.

    - <span id="page-17-6"></span>[57] F. Zampetti, S. Scalabrino, R. Oliveto, G.
    Canfora, and M. Di Penta, "How open source projects use static code analysis tools
    in continuous integration pipelines," in 2017 IEEE/ACM 14th International Conference
    on Mining Software Repositories (MSR), IEEE, 2017, pp. 334–344.

    - <span id="page-17-7"></span>[58] M. Agnihotri and A. Chug, "A systematic literature
    survey of software metrics, code smells and refactoring techniques," Journal of
    Information Processing Systems, vol. 16, no. 4, pp. 915–934, 2020.

    - <span id="page-17-9"></span>[59] G. J. Myers, T. Badgett, T. M. Thomas, and
    C. Sandler, The art of software testing. Wiley Online Library, 2004, vol. 2.

    - <span id="page-17-8"></span>[60] I. ( O. for Standardization), Iso/iec/ieee
    24765: 2017 systems and software engineering-vocabulary, 2017.

    - <span id="page-17-10"></span>[61] C. A. R. Hoare, "How did software get so reliable
    without proof?" In International Symposium of Formal Methods Europe, Springer,
    1996, pp. 1– 17.

    - <span id="page-17-11"></span>[62] D. MacKenzie, "Computer-related accidental
    death: An empirical exploration," Science and Public Policy, vol. 21, no. 4, pp.
    233–248, 1994.

    - <span id="page-17-12"></span>[63] S. Planning, "The economic impacts of inadequate
    infrastructure for software testing," National Institute of Standards and Technology,
    2002.

    - <span id="page-17-13"></span>[64] S. R. Webb, "Design, testing and estimation
    in complex experimentation. i. expansible and contractible factorial designs and
    the application of linear programming to combinatorial problems," ROCKETDYNE CANOGA
    PARK CA, Tech. Rep., 1965.

    - <span id="page-17-14"></span>[65] D. Du, F. K. Hwang, and F. Hwang, Combinatorial
    group testing and its applications. World Scientific, 2000, vol. 12.

    - <span id="page-18-0"></span>[66] C. B. Monteiro, L. A. V. Dias, and A. M. da
    Cunha, "A case study on pairwise testing application," in 2014 11th International
    Conference on Information Technology: New Generations, IEEE, 2014, pp. 639–640.

    - <span id="page-18-1"></span>[67] A. C. da Silva, L. R. Correa, L. A. V. Dias,
    and A. M. da Cunha, "A case study using testing technique for software as a service
    (saas)," in 2015 12th International Conference on Information Technology-New Generations,
    IEEE, 2015, pp. 761–762.

    - <span id="page-18-2"></span>[68] L. Yusuf, M. Chessel, and T. Gardner, "Implement
    model-driven development to increase the business value of your it system," Retrieved
    January, vol. 29, p. 2008, 2006.

    - <span id="page-18-3"></span>[69] B. Hailpern and P. Tarr, "Model-driven development:
    The good, the bad, and the ugly," IBM systems journal, vol. 45, no. 3, pp. 451–461,
    2006.

    - <span id="page-18-4"></span>[70] R. Jacobs, ARCast with Ron Jacobs, English.
    [Online]. Available: [https://channel9.msdn.com/Shows/AR](https://channel9.msdn.com/Shows/ARCast+with+Ron+Jacobs/ARCast-5)
    (visited on 11/19/2020).

    - [71] P. Swithinbank et al., Patterns: Model-Driven Development Using IBM Rational
    Software Architect. IBM, International Technical Support Organization, 2005.

    - <span id="page-18-6"></span><span id="page-18-5"></span>[72] S. K. Langer, Feeling
    and form. Routledge and Kegan Paul London, 1953, vol. 3.

    - [73] O. M. Group, XML Metadata Interchange, English, Technology Standards Consortium,
    Jun. 2015. [Online]. Available: <https://www.omg.org/spec/XMI/About-XMI/>.

    - <span id="page-18-7"></span>[74] M. J. Miller, Why the IBM PC had an Open Architecture,
    English, News Site, publisher: Ziff Davis, Aug. 2011. [Online]. Available: [https://www.pcmag.com/archive/why-the-ib](https://www.pcmag.com/archive/why-the-ibm-pc-had-an-open-architecture-286065)

    - <span id="page-18-8"></span>[75] L. Proven, How the clammy claws of Novell NetWare
    were torn from today''s networks, English, News Site, publisher: Situation Publishing,
    Jul. 2013. [Online]. Available: [https://www.theregister.com/2013/07/16/netware\\_4\\_anniversary/](https://www.theregister.com/2013/07/16/netware_4_anniversary/).

    - <span id="page-18-9"></span>[76] R. Payne and K. Manweiler, CCIE: Cisco Certified
    Internetwork Expert Study Guide: Routing and Switching. John Wiley & Sons, 2006.

    - <span id="page-18-10"></span>[77] V. J. Mercurio, B. F. Meyers, A. M. Nisbet,
    and G. Radin, "Ad/cycle strategy and architecture," IBM Systems Journal, vol.
    29, no. 2, pp. 170– 188, 1990.'
- id: automated_test_production_systematic_literature_mapping_automated_test_production_systematic_literature_mapping
  title: Automated Test Production -- Systematic Literature Mapping
  abstract: 'The broader goal of this research, on the one hand, is to obtain the
    State of

    the Art in Automated Test Production (ATP), to find the open questions and

    related problems and to track the progress of researchers in the field, and on

    the other hand is to list and categorize the methods, techniques and tools of

    ATP that meet the needs of practitioners who produce computerized business

    applications for internal use in their corporations - eventually it can be

    extended to the needs of practitioners in companies that specialize in

    producing computer applications for generic use.'
  url: http://arxiv.org/abs/2401.01430v1
  keywords: ''
  document: "# Automated Test Production Systematic Literature Mapping\n\nGomes, J.M.\
    \ <sup>1</sup> and Dias, L.A.V. 1\n\n1 Instituto Tecnol´ogico de Aeron´autica\
    \ - ITA\n\nJanuary 4, 2024\n\n# 1 Objectives\n\nThe broader goal of this research,\
    \ on the one hand, is to obtain the State of the Art in ATP (Automated Test Production),\
    \ to find the open questions and related problems and to track the progress of\
    \ researchers in the field, and on the other hand is to list and categorize the\
    \ methods, techniques and tools of ATP that meet the needs of practitioners who\
    \ produce computerized business applications for internal use in their corporations\
    \ - eventually it can be extended to the needs of practitioners in companies that\
    \ specialize in producing computer applications for generic use.\n\n# 2 Literature\
    \ Systematic Mapping\n\n### 2.1 Planning\n\nIn order to obtain an overview of\
    \ the research on ATP, an SLM (Systematic Literature Mapping) is conducted here\
    \ so that from this study we can perform an SLR (Systematic Literature Review)\
    \ in order to investigate it further. We apply the method proposed by Petersen\
    \ et al. and which we present in the Figure [1](#page-1-0) to conduct this SLM[\\\
    [1\\]](#page-16-0).\n\nWe sought with this study to identify the amount and types\
    \ of research and its results under the topic ATP. As important secondary results,\
    \ we also sought to identify the discussion forums on the subject.\n\nThe question\
    \ QP1 is a filter for narrowing the scope of the research. The question QP2 aims\
    \ to identify the main discussion forums where researchers related to ATP publish\
    \ their work or meet to present advances and update their knowledge in the area.\
    \ In the question QP3 we propose to classify the search results and identify the\
    \ main types of studies related to ATP and categorize their contributions.\n\n\
    <span id=\"page-1-0\"></span>![](_page_1_Figure_0.jpeg)\n\nFigure 1: Steps do\
    \ execute the research for an SLM (adapted from [\\[1\\]](#page-16-0))\n\nThe\
    \ search term was generated from keywords and their synonyms as presented in the\
    \ Table [2.](#page-1-1) In Keele et al. it is pointed out that Petticrew and Roberts\
    \ suggest the use of PICOC (Population, Intervention, Comparison, Outcome, Context)\
    \ to formulate the search term in scientific publication databases [\\[2,](#page-16-1)\
    \ [3\\]](#page-16-2).\n\nTwo of the main considerations in designing the search\
    \ protocol are that, first, we are neglecting \"comparison\", and are therefore\
    \ using the PIOC (Population, Intervention, Outcome, Context) variation, because\
    \ it is not part of our goal to compare different solutions to the same problem,\
    \ and second, we avoid considering specific results, i.e., studies that are not\
    \ aimed at the production of general-purpose computer applications, or use within\
    \ an enterprise and business world context.\n\n<span id=\"page-1-2\"></span>\n\
    \n| #   | Question                                         |\n|-----|--------------------------------------------------|\n\
    | QP1 | Is the study?                                    |\n|     | Recently published\
    \ (within the last five years)? |\n| QP2 | Which \"journals\" include studies\
    \ in \"ATP?        |\n|     | Or Annals of Congresses, Events, Authors, etc. \
    \  |\n| QP3 | What kinds of studies are published in ATP?      |\n|     | Categorized\
    \ as listed in Figure 5                |\n\n<span id=\"page-1-1\"></span>\n\n\
    | Term       | Synonyms                                        | Related to  \
    \ |\n|------------|-------------------------------------------------|--------------|\n\
    | software   | program                                         | Population  \
    \ |\n| test       | check<br>checking<br>validation<br>verification | Population\
    \   |\n| generation | creation<br>inception<br>production             | Intervention\
    \ |\n| method     | methodology<br>model<br>process<br>standard     | Outcome\
    \      |\n| tool       | environment<br>framework<br>software<br>suite   | Outcome\
    \      |\n\nTable 1: Research questions for SLM\n\nTable 2: Search terms for the\
    \ SLM\n\nThe Context is an extended view of the population, where we say whether\
    \ the study is conducted in Academy or Industry, in which Industry segment [\\\
    [4\\]](#page-16-3). In our case we were indifferent with regard to this aspect.\n\
    \nFinally we applied the search criteria of the Section [2.1](#page-2-0) to the\
    \ scientific publication databases listed in the Table [3.](#page-2-1)\n\n```\n\
    (\"software\" OR \"program\" OR \"test\" OR \"check\" OR \"checking\" OR \"\n\
    \   ,→ validation\" OR \"verification\") AND (\"generation\" OR \"\n   ,→ creation\"\
    \ OR \"inception\" OR \"production\") AND (\"method\" OR\n   ,→ \"methodology\"\
    \ OR \"model\" OR \"process\" OR \"standard\" OR \"\n   ,→ tool\" OR \"environment\"\
    \ OR \"framework\" OR \"software\" OR \"\n   ,→ suite\")\n```\nListing 1: Search\
    \ criteria for the SLM\n\n### 2.2 Conduction\n\n<span id=\"page-2-1\"></span>The\
    \ scientific publication sources, listed in Table [3,](#page-2-1) are, according\
    \ to Brereton et al., the most relevant for Software Engineering [\\[5\\]](#page-16-4).\n\
    \n| Name                |  |\n|---------------------|--|\n| IEEE Xplore      \
    \   |  |\n| ACM Digital Library |  |\n| Google Scholar      |  |\n| CiteSeerX\
    \           |  |\n| Inspec              |  |\n| ScienceDirect       |  |\n| EI\
    \ Compendex        |  |\n| Springer Link       |  |\n\nTable 3: Scientific publishing\
    \ databases\n\nThe choice of primary research sources was based on simple and\
    \ practical premises:\n\n- use of structured search terms (using \"AND\", \"OR\"\
    , \"NOT\" and parentheses);\n- filters to search for more recent documents; and\n\
    - filters to list relevant documents in the desired area of expertise.\n\nBased\
    \ on these criteria, the ScienceDirect and ISI Web of Science publication bases\
    \ were discarded for not presenting satisfactory results for this research [1](#page-2-2)\
    \ and both Google Scholar and CiteSeerX by not providing additional\n\n<span id=\"\
    page-2-2\"></span><sup>1</sup>The ScienceDirect of Elsevier for example restricts\
    \ the search to only 8 terms, and in one exercise returned only 11 studies. Of\
    \ these only one could be read in full and was still not relevant to the present\
    \ study.\n\nfilters by area or subarea of knowledge and finally EI Compendex and\
    \ Inspec also did not allow access. As an alternative we used the Periodical Portal\
    \ of CAPES (Coordena¸c˜ao de Aperfei¸coamento de Pessoal de N´ıvel Superior do\
    \ Brasil) [2](#page-3-0) with the exception that the search criteria had to be\
    \ adapted because of restrictions in the platform as can be seen in the Section\
    \ [2.2](#page-3-1) (as in the other platforms, additional filters were applied\
    \ - see Table [7\\)](#page-4-0).\n\n```\n(software OR program OR test OR check\
    \ OR checking OR\n   ,→ validation OR verification) AND\n(generation OR creation\
    \ OR inception OR production)\n```\nListing 2: Search criteria for the SLM used\
    \ at CAPES\n\n<span id=\"page-3-2\"></span>Then, within each publication base,\
    \ filters were applied to improve the quality of the results obtained. In general,\
    \ we selected only recent documents (2015 to 2020 - up to the date of the survey:\
    \ April 2020). The particular criteria for each base are listed in the Tables\
    \ [4](#page-3-2) to [7.](#page-4-0)\n\n| Filter            | Value           \
    \                                                                            \
    \                                                                            \
    \                              |\n|-------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Publication title | IEEE Access<br>IEEE Systems Journal<br>IEEE Latin America<br>Transactions\
    \                                                                            \
    \                                                 |\n|                   | IEEE\
    \ Transactions on<br>Software Engineering                                    \
    \                                                                            \
    \                                          |\n| Indexation terms  | learning (artificial<br>intelligence)<br>optimisation<br>neural\
    \ nets<br>cloud computing<br>genetic algorithms<br>probability<br>program testing<br>search\
    \ problems<br>Internet<br>resource allocation |\n\nTable 4: IEEE Xplore filters\n\
    \n| Filter                   | Value                   |\n|--------------------------|-------------------------|\n\
    | ACM Full-Text Collection | All journals collection |\n| Publication Title  \
    \      | Search title only       |\n\nTable 5: ACM Digital Library filters\n\n\
    <span id=\"page-3-0\"></span><sup>2</sup>See <http://www.periodicos.capes.gov.br>.\n\
    \n| Filter        | Value                                                    \
    \                                                                            \
    \                                                                            \
    \                                                        |\n|---------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Content Type  | Article<br>Chapter<br>Conference Paper                     \
    \                                                                            \
    \                                                                            \
    \                                                      |\n| Discipline    | Computer\
    \ Science                                                                    \
    \                                                                            \
    \                                                                            \
    \                             |\n| Subdiscipline | Computer Science,<br>general<br>Computer\
    \ Systems<br>Organizations and<br>Communications<br>Networks<br>Data Structures\
    \ and<br>Information Theory<br>Information Systems<br>and Communication<br>Service<br>Software\
    \ Engineer<br>ing/Programming and<br>Operating Systems |\n\n<span id=\"page-4-0\"\
    ></span>\n\n| Filter                          | Value                        \
    \                        |\n|---------------------------------|------------------------------------------------------|\n\
    | Type of<br>source               | Studies                                  \
    \            |\n| Language<br>Refinement<br>Topic | English<br>Pair revised journals<br>Computer\
    \ Science |\n\n| Table 7: \"Peri´odicos da CAPES\" filters |\n|-----------------------------------------|\n\
    |-----------------------------------------|\n\n<span id=\"page-4-1\"></span>After\
    \ running the search using the Section [2.1](#page-2-0) criteria and applying\
    \ the filters listed in the Tables [4](#page-3-2) to [7](#page-4-0) we obtained\
    \ the results listed in the Table [8](#page-4-1) (in number of documents).\n\n\
    | Name                 | Qty. | %     |\n|----------------------|------|-------|\n\
    | IEEE Xplore          | 715  | 33.10 |\n| ACM Digital Library  | 308  | 14.26\
    \ |\n| Springer Link        | 709  | 32.82 |\n| Peri´odicos da CAPES | 428  |\
    \ 19.81 |\n| TOTAL                | 2160 |       |\n\nTable 8: Total documents\
    \ retrieved from each publishing databases for the SLM\n\nThe selection of documents\
    \ was based on Inclusion and Exclusion criteria defined iteratively during the\
    \ reading of the documents found and served to determine the suitability of each\
    \ one to the objectives of this work. The Inclusion Criteria are those presented\
    \ in the Table [9,](#page-5-0) and in the Table [10](#page-5-1) we have the Exclusion\
    \ Criteria.\n\n<span id=\"page-5-0\"></span>\n\n| #   | Description          \
    \                                                                        |\n|-----|----------------------------------------------------------------------------------------------|\n\
    | CI1 | Document types:<br>books (book excerpts), technical re<br>ports;     \
    \                        |\n| CI2 | If several have reported the same study, only\
    \ the most<br>recent one will be considered; and |\n| CI3 | From the abstract\
    \ the researcher can deduce that the ar<br>ticle is about ATP.               |\n\
    \nTable 9: Inclusion criteria for the SLM\n\n<span id=\"page-5-1\"></span>\n\n\
    | #   | Description                                                |\n|-----|------------------------------------------------------------|\n\
    | CE1 | The article strays from the main topic of this study which |\n|     |\
    \ deals with ATP for general applications;                   |\n| CE2 | The topic\
    \ ATP is not part of the article's contribution or |\n|     | the topic is only\
    \ mentioned; and                           |\n| CE3 | No empirical findings or\
    \ current available literature are  |\n|     | reported.                     \
    \                             |\n\nTable 10: Exclusion criteria for the SLM\n\n\
    Given the large number of studies (see Table [8\\)](#page-4-1) found we organized\
    \ our work into iterative steps:\n\n- 1. Reading the summary and conclusion; and\n\
    - 2. Selection and classification by reading the entire document.\n\nA pre-selection\
    \ was based only on the title of the document found because, as already noted\
    \ by Keele et al., searches of electronic databases bring a very large number\
    \ of irrelevant results. During the review, other studies were rejected as being\
    \ outside the scope of this study [\\[2\\]](#page-16-1).\n\n| Name           \
    \      | Qty. | %     |\n|----------------------|------|-------|\n| IEEE Xplore\
    \          | 33   | 14.73 |\n| ACM Digital Library  | 66   | 29.46 |\n| Springer\
    \ Link        | 11   | 4.91  |\n| Peri´odicos da CAPES | 114  | 50.89 |\n| Sub-total\
    \            | 224  |       |\n| Duplicate studies    | 7    | 4.24  |\n| Rejected\
    \ studies     | 52   | 31.52 |\n| TOTAL                | 165  |       |\n|   \
    \                   |      |       |\n\nTable 11: Primary studies selction result\
    \ for the SLM\n\n<span id=\"page-6-0\"></span>\n\n| #     | Description      \
    \                                  |\n|-------|----------------------------------------------------|\n\
    | CE1.1 | Applied to hardware;                               |\n| CE1.2 | Applied\
    \ to embedded software;                      |\n| CE1.3 | Language-specific; \
    \                                |\n| CE1.4 | Does not deal with tests for general\
    \ applications; |\n| CE1.5 | Not intended for general applications;          \
    \   |\n| CE2.1 | Does not deal with test generation;                |\n| CE3.1\
    \ | No contribution to this study;                     |\n| CE3.2 | This is not\
    \ scientific research; and               |\n| CE3.3 | Survey with old data.  \
    \                            |\n\nTable 12: Refining exclusion criteria for the\
    \ SLM\n\nThe studies were rejected in the second selection based on a refinement\
    \ of the exclusion criteria listed in the Table [10](#page-5-1) and that we list\
    \ in the Table [12.](#page-6-0) Our motivation behind these criteria, as explained\
    \ in the \"Objectives\", is to find solutions that meet the needs of professionals\
    \ who produce computerized business applications for internal use in their corporations\
    \ - eventually extending to the needs of professionals in companies specializing\
    \ in the production of generic computer applications.\n\n<span id=\"page-6-1\"\
    ></span>![](_page_6_Figure_3.jpeg)\n\nFigure 2: Classification scheme (adapted\
    \ from [\\[1\\]](#page-16-0))\n\nFor documents classification we adopted the Petersen\
    \ et al. as can be seen in the Figure [2,](#page-6-1) and in the same way we adopted\
    \ facets analyzing the abstracts of the studies found. We started by analyzing\
    \ two main facets to classify the documents. The research type facet was based\
    \ on the classification proposed by Wieringa et al. and summarized in the Table\
    \ [13.](#page-7-0) The type of contribution is based on the interpretation of\
    \ the abstracts and listed in the Table [14](#page-8-0) [\\[1,](#page-16-0) [6\\\
    ]](#page-16-5).\n\n<span id=\"page-7-0\"></span>\n\n| Category      | Description\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                             |\n|---------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Validation    | The techniques investigated are new and have not<br>been implemented\
    \ in practice. Techniques used<br>are from experimental examples and done in the<br>laboratory.\
    \                                                                            \
    \                                              |\n| Avaliation    | The technique\
    \ was implemented in practice and<br>the evaluation was conducted.<br>Demonstrated<br>how\
    \ the technique was implemented in practice<br>and what the consequences were\
    \ in terms of ben<br>efits and disadvantages. Also includes identifica<br>tion\
    \ of problems in the industry. |\n| Proposal      | A solution to a problem has\
    \ been proposed, ei<br>ther new or a significant extension of an existing<br>technique.\
    \ The potential benefits and applicabil<br>ity of the solution is shown by a short\
    \ example or<br>a good line of argument.                                     \
    \              |\n| Philosophical | These studies outlined a new approach to pre<br>existing\
    \ knowledge and structured the field in the<br>form of a taxonomy or conceptual\
    \ work.                                                                      \
    \                                                                          |\n\
    | Opinion       | These studies express someone's personal opinion<br>about a\
    \ particular technique, whether it is good<br>or not, or how things are done.<br>They\
    \ are not<br>supported by related work or research methods.                  \
    \                                                                 |\n| Practice\
    \      | They explain in what and how something was<br>done in practice. It has\
    \ to be the author's per<br>sonal experience.                                \
    \                                                                            \
    \                                                              |\n\nTable 13:\
    \ Researches types\n\n<span id=\"page-8-0\"></span>\n\n| Category     | Description\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \   |\n|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Metric       | A system or standard of measures or measure<br>ments taken using\
    \ an existing standard.                                                      \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                          |\n| Tool         | A device or implementation, used\
    \ to perform a<br>certain function.                                          \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                          |\n| Model        |\
    \ A comprehensive and systematic approach that<br>includes theoretical principles,\
    \ benefits and draw<br>backs, objectives, methodological guidelines and<br>specifications,\
    \ and the characteristic use of cer<br>tain sets of methods and techniques.  \
    \                                                                            \
    \                                                                         |\n\
    | Method       | No particular theoretical orientation is inferred<br>in a method.\
    \ Researchers impose their own par<br>ticular theoretical beliefs on an experiment\
    \ when<br>they design and implement it by applying one or<br>more techniques.\
    \                                                                            \
    \                                                                            \
    \                    |\n| Technique    | A single operation or interaction in\
    \ which a re<br>searcher uses one or more procedures to elicit an<br>immediate\
    \ reaction from the object of study or to<br>shape the experiment and obtain results.\
    \                                                                            \
    \                                                                            \
    \                                             |\n| Procedure    | An organized\
    \ sequence of operations and interac<br>tions that a researcher uses to conduct\
    \ an exper<br>iment.                                                         \
    \                                                                            \
    \                                                                            \
    \                                                                            |\n\
    | Intervention | Purposefully interferes with or mitigates various<br>aspects\
    \ of the object of study and that affect the<br>outcome by applying procedure,\
    \ technique. The<br>elements acting on the industry during a partic<br>ular intervention\
    \ are most often computer appli<br>cations, the researcher, or both.         \
    \                                                                            \
    \                  |\n| Approach     | A broad way of addressing an industry concern\
    \ or<br>problem. A specific methods is not implied, but<br>a specific set of techniques\
    \ will likely come into<br>play when trying to intervene in the industry and<br>the\
    \ problem that is the subject of the research.<br>The procedures to be used will\
    \ be determined by<br>the delimitations of the methodological variant in<br>which\
    \ we design the study. |\n| Strategy     | An action plan designed to achieve\
    \ an overall<br>goal.                                                        \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                        |\n\nTable 14: Contributions\
    \ types\n\n### 2.3 Analysis of Results\n\n<span id=\"page-8-1\"></span>Based on\
    \ the criteria listed in the Table [10](#page-5-1) and expanded in the Table [12](#page-6-0)\
    \ we selected 165 and rejected 52 documents categorized according to the Table\
    \ [15.](#page-8-1)\n\n| Motive                                            | Qty.\
    \ |\n|---------------------------------------------------|------|\n| Applied to\
    \ hardware                               | 9    |\n| Applied to embedded software\
    \                      | 2    |\n| Language-specific                         \
    \        | 2    |\n| No contribution to this study                     | 5   \
    \ |\n| This is not scientific research                   | 1    |\n| Does not\
    \ deal with test generation                | 22   |\n| Does not deal with tests\
    \ for general applications | 3    |\n| Not intended for general applications \
    \            | 7    |\n| Survey with old data                              | 1\
    \    |\n| TOTAL                                             | 52   |\n\nTable\
    \ 15: Rejection motives\n\nThe research questions listed in Table [1](#page-1-2)\
    \ were applied to the selected studies and we obtained the results that we list\
    \ below.\n\n#### QP1 - Is the study current?\n\n<span id=\"page-9-1\"></span>Recently\
    \ published (within the last five years)?\n\n| Tipo  | criteria |\n|-------|----------|\n\
    | 2015  | 34       |\n| 2016  | 32       |\n| 2017  | 20       |\n| 2018  | 26\
    \       |\n| 2019  | 38       |\n| 2020  | 15       |\n| TOTAL | 165      |\n\n\
    Table 16: Publications / Year\n\n| Tipo        | Qty. | %     |\n|-------------|------|-------|\n\
    | Books       | 3    | 1.82  |\n| Conferences | 51   | 30.91 |\n| Journals   \
    \ | 111  | 67.27 |\n| TOTAL       | 165  |       |\n\nTable 17: Studies / Channel\n\
    \n<span id=\"page-9-0\"></span>We can observe a relative constancy of studies\
    \ published on the topic in recent years, indicating that the topic is of interest\
    \ and there is potential progress to be explored.\n\n#### QP2 - Which \"journals\"\
    \ include studies in \"ATP\"?\n\nOr Annals of Congresses, Events, Authors, etc.\n\
    \nWe classified how the studies were published (see Table [17\\)](#page-9-0) and\
    \ then sought to identify where they were published to get an idea of the best\
    \ Journals and Events where to look for information on the topic. Unfortunately,\
    \ as can be seen in the Table [18](#page-10-0) there is no specific event for\
    \ this topic. In the Figure [3](#page-10-1) and Table [19](#page-11-0) we obtained\
    \ a more satisfactory result in identifying the most relevant publications for\
    \ our research.\n\n<span id=\"page-10-1\"></span>![](_page_10_Figure_0.jpeg)\n\
    \nFigure 3: Participation of ATP Studies in Congresses\n\n<span id=\"page-10-0\"\
    ></span>\n\n| Conference                                                     \
    \                                                         | Qty. |\n|-------------------------------------------------------------------------------------------------------------------------|------|\n\
    | The Search-Based Software Testing (SBST) Workshop (co-located<br>in ICSE)  \
    \                                             | 7    |\n| ACM ESEC/FSE Joint European\
    \ Software Engineering Conference<br>and Symposium on the Foundations of Software\
    \ Engineering | 6    |\n| Internation Conference on Software Engineering     \
    \                                                                     | 6    |\n\
    | IEEE/ACM International Conference on Automated Software En<br>gineering    \
    \                                             | 5    |\n| ACM ICSCA Software and\
    \ Computer Applications                                                      \
    \                      | 3    |\n| ACM SIGSOFT ISSTA International Symposium on\
    \ Software<br>Testing and Analysis                                           |\
    \ 3    |\n| ACM/IEEE International Conference on Automation of Software<br>Test\
    \                                                     | 2    |\n| ACM ESEC/FSE\
    \ Joint European Software Engineering Conference                             \
    \                                | 2    |\n| and Symposium on the Foundations\
    \ of Software Engineering                                                    \
    \            |      |\n| ACM SBES Brazilian Symposium on Software Engineering\
    \                                                                    | 2    |\n\
    | Symposium on Information and Communication Technology                      \
    \                                             | 2    |\n\nTable 18: Major conferences\
    \ addressing ATP\n\nIn the graph from Figure [3](#page-10-1) we have a look at\
    \ the interest in the topic over the course of the surveyed period in the main\
    \ congresses listed.\n\nIn Journals we identify in the Table [19](#page-11-0)\
    \ where the topic is most frequently addressed.\n\n![](_page_11_Figure_0.jpeg)\n\
    \nParticipation of ATP Studies in Publications\n\n<span id=\"page-11-0\"></span>Figure\
    \ 4: Participation of ATP Studies in Publications\n\n| Publication           \
    \                                         | Qty. |\n|----------------------------------------------------------------|------|\n\
    | IEEE Trans. Software Eng.                                      | 20   |\n| IEEE\
    \ Access                                                    | 9    |\n| The Journal\
    \ of Systems & Software                              | 6    |\n| Science of Computer\
    \ Programming                                | 5    |\n| IET Software        \
    \                                           | 4    |\n| International Journal\
    \ of Software Engineering and Knowledge En | 4    |\n| gineering             \
    \                                         |      |\n| Journal of King Saud University\
    \ - Computer and Information Sci | 4    |\n| ences                           \
    \                               |      |\n| ACM Trans. Softw. Eng. Methodol. \
    \                              | 3    |\n| Applied Soft Computing            \
    \                             | 3    |\n| Autom Softw Eng                    \
    \                            | 3    |\n| Empir Software Eng                  \
    \                           | 3    |\n| J Softw Eng Res Dev                  \
    \                          | 3    |\n| Software Testing, Verification and Reliability\
    \                 | 3    |\n| The Computer Journal                           \
    \                | 3    |\n\nTable 19: Major Publications Addressing ATP\n\nOnce\
    \ again we present in a graph at Figure [3](#page-10-1) a view of the interest\
    \ in the topic over the surveyed period in the main Journals listed.\n\nWe also\
    \ sought to identify the main authors on the subject, regardless of the medium\
    \ of publication. In the Table [20](#page-12-1) we list those who presented the\
    \ highest production within this research and their H-Index [\\[7\\]](#page-16-6).\n\
    \n<span id=\"page-12-1\"></span>\n\n| Author                    | Institution\
    \                                | Qty. | h-idx3 |\n|---------------------------|--------------------------------------------|------|--------|\n\
    | Harman, Mark              | University College Lon<br>don              | 3 \
    \   | 68     |\n| Arcuri, Andrea            | Kristiania<br>University<br>College\
    \        | 9    | 39     |\n| Fraser, Gordon            | University of Passau\
    \                       | 8    | 39     |\n| McMinn, Phil              | University\
    \ of Sheffield                    | 4    | 27     |\n| Zamli,<br>Kamal<br>Z. \
    \    | University<br>Malaysia<br>Pahang           | 8    | 23     |\n| Panichella,\
    \ An<br>nibale  | Delft<br>University<br>of<br>Technology    | 3    | 27     |\n\
    | Gargantini,<br>Angelo     | University of Bergamo                      | 3 \
    \   | 18     |\n| Vergilio,<br>Silvia<br>R. | Federal<br>University<br>of<br>Paran´a\
    \     | 4    | 17     |\n| Riccobene,<br>Elvinia     | Universit`a di Milano \
    \                     | 3    | 16     |\n| Arcaini, Paolo            | National<br>Institute<br>of<br>Informatics\
    \ | 3    | 15     |\n| Staats, Matt4             | University<br>of<br>Luxem<br>bourg\
    \         | 3    | 15     |\n| Gay, Gregory              | Chalmers, University\
    \ of<br>Gothenburg      | 6    | 12     |\n| Rojas,<br>Jos´e<br>Miguel | University\
    \ of Leicester                    | 3    | 13     |\n\nTable 20: Main Authors\
    \ in ATP of this Study\n\nThe Table [20](#page-12-1) seeks to order the authors\
    \ by weighting their H-Index and the number of publications found within the search.\n\
    \n### QP3 - What kinds of studies are published in ATP?\n\nCategorized as listed\
    \ in Figure [5](#page-12-0)\n\nWe first build on the classification proposed by\
    \ Wieringa et al. and quantify the Facet of Study Types in Figure [5](#page-12-0)\
    \ [\\[6\\]](#page-16-5). This categorization will be useful in performing a SLR\
    \ as we qualify the studies with the desired bias for this research.\n\n<span\
    \ id=\"page-12-0\"></span>![](_page_12_Figure_6.jpeg)\n\nFigure 5: Types of Artifacts\
    \ Generated\n\n<span id=\"page-12-3\"></span><span id=\"page-12-2\"></span><sup>3</sup>Data\
    \ obtained via Google Scholar and calculated since 2015.\n\n<sup>4</sup>See Scopus\
    \ [https://www.scopus.com/results/authorNamesList.uri?sort=count-f&](https://www.scopus.com/results/authorNamesList.uri?sort=count-f&src=al&affilName=University+of+Luxembourg&s=AUTHLASTNAME%28Staats%29+AND+AUTHFIRST%28Matt%29+AND+AFFIL%28University+of+Luxembourg%29&st1=Staats&st2=Matt)\
    \ [src=al&affilName=University+of+Luxembourg&s=AUTHLASTNAME%28Staats%29+AND+](https://www.scopus.com/results/authorNamesList.uri?sort=count-f&src=al&affilName=University+of+Luxembourg&s=AUTHLASTNAME%28Staats%29+AND+AUTHFIRST%28Matt%29+AND+AFFIL%28University+of+Luxembourg%29&st1=Staats&st2=Matt)\n\
    \n[AUTHFIRST%28Matt%29+AND+AFFIL%28University+of+Luxembourg%29&st1=Staats&st2=Matt](https://www.scopus.com/results/authorNamesList.uri?sort=count-f&src=al&affilName=University+of+Luxembourg&s=AUTHLASTNAME%28Staats%29+AND+AUTHFIRST%28Matt%29+AND+AFFIL%28University+of+Luxembourg%29&st1=Staats&st2=Matt).\n\
    \n<span id=\"page-13-0\"></span>![](_page_13_Figure_0.jpeg)\n\nFigure 6: Types\
    \ of Test Generators\n\nIn Figure [6](#page-13-0) we categorize studies also with\
    \ respect to the level of access to the source code of the program object of testing\
    \ in the Verification and Validation language, where white-box [5](#page-13-1)\
    \ tests are applied in verification (i.e., was the correct program built?) and\
    \ black-box [6](#page-13-2) tests are applied in validation (i.e., was the program\
    \ built correctly?). For the purposes of this research, we consider any access\
    \ to the source code to mean white-box testing and neglect so-called graybox [7](#page-13-3)\
    \ testing. We classify as white-box or black-box tests those tests that apply\
    \ verification techniques through observation or direct experience.\n\nWe consider\
    \ as Formal tests verifiable by theoretical means or pure logic, whose specifications\
    \ may include expressions in various logical forms, used to write pre and post\
    \ conditions, axioms of data types, constraints, temporal properties. They can\
    \ represent definitions of process states, and there is a formal deduction system,\
    \ enabling proofs, or other verifications (such as model checking), or both. Thus,\
    \ formal specifications can be analyzed to guide the identification of appropriate\
    \ test cases. According to Gaudel, these are black-box type tests, where the internal\
    \ organization of the program under test is ignored and the strategy is based\
    \ on a description of the desired properties and program behavior, grouped here\
    \ by those that meet these [\\[8\\]](#page-16-7) characteristics.\n\nAlso following\
    \ the methodology proposed by Wieringa et al., we quantified the documents by\
    \ the Facet of the Artifact Type generated by the study, taking as a basis the\
    \ approach presented by each and which we list in the Figure [7](#page-14-0) [\\\
    [6\\]](#page-16-5). In a future SLR we can apply qualitative aspects that will\
    \ determine whether for the purposes of this research specialized (generate only\
    \ the code or the test data) or general (generate both the code and the test data)\
    \ approaches are the most relevant.\n\n<span id=\"page-13-2\"></span><span id=\"\
    page-13-1\"></span><sup>5</sup>Validating non-functional, internal aspects of\
    \ a computer application.\n\n<sup>6</sup>Validating functional and external aspects\
    \ of a computer application.\n\n<span id=\"page-13-3\"></span><sup>7</sup>The\
    \ combination of white-box and black-box testing methods.\n\n<span id=\"page-14-0\"\
    ></span>![](_page_14_Figure_0.jpeg)\n\nFigure 7: Types of Artifacts Generated\n\
    \n<span id=\"page-14-1\"></span>![](_page_14_Figure_2.jpeg)\n\nFigure 8: Contributions\
    \ of the Studies\n\nThe quantification of the studies by the Contribution Type\
    \ Facet (see Figure [7\\)](#page-14-0) was important for the qualification and\
    \ selection of the most relevant studies to meet the objectives of the present\
    \ research and the quantified can be observed in the Figure [8.](#page-14-1)\n\
    \n# 3 Results\n\nWas presented the elementary results of a SLM applied to finding\
    \ relevant studies in ATP. This review applied the methodology of Petersen et\
    \ al. with elements of Keele et al., Brereton et al. [\\[1,](#page-16-0) [2,](#page-16-1)\
    \ [5\\]](#page-16-4)\n\n### 3.1 Conclusions\n\nBased on the research questions\
    \ developed in the Table [1](#page-1-2) the conclusions is:\n\n#### 3.1.1 Is the\
    \ study current?\n\nWas ensured that the studies were recent by restricting our\
    \ search to the last 5 years and we can observe in the Table [16](#page-9-1) an\
    \ even distribution of studies across the surveyed period.\n\n#### 3.1.2 Which\
    \ \"journals\" include studies in ATP?\n\nIn the Table [17](#page-9-0) it can\
    \ be seen the large concentration of studies published in conferences and \"Journals\"\
    \ and this led us to list the main conferences (see Table [18\\)](#page-10-0)\
    \ and the main publications (see Table [19\\)](#page-11-0). The relatively small\
    \ number of books on the subject, in our view, is due to the innovative characteristics\
    \ under which the fields of engineering and computer science live today.\n\n####\
    \ 3.1.3 What categories of studies are published in ATP?\n\nOf particular interest\
    \ to our research on ATP, the types of studies that stood out the most can be\
    \ seen in Figure [8.](#page-14-1) The concentration in practical aspects, as tools,\
    \ methods, models and metrics leads us to conclude that the maturity the subject\
    \ is now in Academy. The generation of both code and data is addressed by the\
    \ studies, and this is a guarantee that we're covering all aspects of the subject.\n\
    \n### 3.2 Future Work\n\nThis work aims to prepare ground for a SLR where it will\
    \ determine the challenges in applying generative testing techniques and evaluate\
    \ the solutions intended to be applied in future work.\n\n# Acronyms\n\nATP Automated\
    \ Test Production - pages: 1, 2, 6, 10, 13, 15, 16\n\nCAPES Coordena¸c˜ao de Aperfei¸coamento\
    \ de Pessoal de N´ıvel Superior do Brasil - page: 4\n\nPICOC Population, Intervention,\
    \ Comparison, Outcome, Context - page: 2\n\nPIOC Population, Intervention, Outcome,\
    \ Context - page: 2\n\nSLM Systematic Literature Mapping - pages: 1, 15\n\nSLR\
    \ Systematic Literature Review - pages: 1, 13, 14, 16\n\n# References\n\n- <span\
    \ id=\"page-16-0\"></span>[1] K. Petersen, R. Feldt, S. Mujtaba, and M. Mattsson,\
    \ \"Systematic mapping studies in software engineering,\" in 12th International\
    \ Conference on Evaluation and Assessment in Software Engineering (EASE) 12, 2008,\
    \ pp. 1– 10.\n- <span id=\"page-16-1\"></span>[2] S. Keele et al., \"Guidelines\
    \ for performing systematic literature reviews in software engineering,\" Technical\
    \ report, Ver. 2.3 EBSE Technical Report. EBSE, Tech. Rep., 2007.\n- <span id=\"\
    page-16-2\"></span>[3] M. Petticrew and H. Roberts, Systematic reviews in the\
    \ social sciences: A practical guide. John Wiley & Sons, 2008.\n- <span id=\"\
    page-16-3\"></span>[4] C. Wohlin, P. Runeson, M. H¨ost, M. C. Ohlsson, B. Regnell,\
    \ and A. Wessl´en, Experimentation in software engineering. Springer Science &\
    \ Business Media, 2012.\n- <span id=\"page-16-4\"></span>[5] P. Brereton, B. A.\
    \ Kitchenham, D. Budgen, M. Turner, and M. Khalil, \"Lessons from applying the\
    \ systematic literature review process within the software engineering domain,\"\
    \ Journal of systems and software, vol. 80, no. 4, pp. 571–583, 2007.\n- <span\
    \ id=\"page-16-5\"></span>[6] R. Wieringa, N. Maiden, N. Mead, and C. Rolland,\
    \ \"Requirements engineering paper classification and evaluation criteria: A proposal\
    \ and a discussion,\" Requirements engineering, vol. 11, no. 1, pp. 102–107, 2006.\n\
    - <span id=\"page-16-6\"></span>[7] J. E. Hirsch, \"An index to quantify an individual's\
    \ scientific research output,\" Proceedings of the National academy of Sciences,\
    \ vol. 102, no. 46, pp. 16 569–16 572, 2005.\n- <span id=\"page-16-7\"></span>[8]\
    \ M.-C. Gaudel, \"Formal methods for software testing,\" in 2017 International\
    \ Symposium on Theoretical Aspects of Software Engineering (TASE), IEEE, 2017,\
    \ pp. 1–3."
- id: automated_test_production_systematic_literature_review_automated_test_production_systematic_literature_review
  title: Automated Test Production -- Systematic Literature Review
  abstract: 'Identifying the main contributions related to the Automated Test Production

    (ATP) of Computer Programs and providing an overview about models,

    methodologies and tools used for this purpose is the aim of this Systematic

    Literature Review (SLR). The results will enable a comprehensive analysis and

    insight to evaluate their applicability. A previously produced Systematic

    Literature Mapping (SLM) contributed to the formulation of the ``Research

    Questions'''' and parameters for the definition of the qualitative analysis

    protocol of this review.'
  url: http://arxiv.org/abs/2401.02033v1
  keywords: ''
  document: "## Automated Test Production Systematic Literature Review\n\nGomes, J.M.\
    \ <sup>1</sup> and Dias, L.A.V. 1\n\n1 Instituto Tecnol´ogico de Aeron´autica\
    \ - ITA\n\nJanuary 5, 2024\n\n#### Abstract\n\nIdentifying the main contributions\
    \ related to the Automated Test Production of Computer Programs and providing\
    \ an overview about models, methodologies and tools used for this purpose is the\
    \ aim of this Systematic Literature Review. The results will enable a comprehensive\
    \ analysis and insight to evaluate their applicability. A previously produced\
    \ SLM (Systematic Literature Mapping) contributed to the formulation of the \"\
    Research Questions\" and parameters for the definition of the qualitative analysis\
    \ protocol of this review.\n\n## 1 Objectives\n\nThe broader goal of this research,\
    \ while on the one hand is to obtain the State of the Art in ATP (Automated Test\
    \ Production), find the problems faced and track the progress of researchers in\
    \ the field, on the other hand we also intend to list and categorize the ATP methods,\
    \ techniques and tools that meet the needs of professionals producing specialized\
    \ business applications for internal use within their corporations - eventually\
    \ extending to the needs of professionals in companies specializing in the production\
    \ of generic or even academic computer applications.\n\nProviding the scientific\
    \ and technological community with an overview of models, methodologies and tools\
    \ used for this purpose is the goal of this SLR (Systematic Literature Review).\
    \ The results will allow a comprehensive analysis and insight to evaluate their\
    \ applicability.\n\n## <span id=\"page-0-0\"></span>2 Systematic Literature Review\n\
    \n### 2.1 Planning\n\nIn order to analyze, evaluate and interpret the available\
    \ research for the matter of ATP of Computer Programs, we applied the method proposed\
    \ by Brereton et\n\n![](_page_1_Figure_0.jpeg)\n\n<span id=\"page-1-0\"></span>Figure\
    \ 1: Steps to perform an SLR (adaptedo from [\\[1\\]](#page-13-0))\n\nal. and\
    \ presented in the Figure [1.](#page-1-0) Whereas the Systematic Literature Mapping[\\\
    [2\\]](#page-13-1) survey gave us an overview and insight into what represents\
    \ current research in ATP, with the present SLR we aim to identify the effort\
    \ needed to answer our research questions[\\[1\\]](#page-13-0).\n\nSeveral adjustments\
    \ suggested by Kitchenham et al. led us to consider the methodologies of Basili\
    \ and Weiss for formulating the research questions, of Chen and Babar for classifying\
    \ the type of study, of Keele et al. for conducting a quality assessment of each\
    \ proposal, and of Kitchenham et al., Dyba et al. for gauging the scientific rigor\
    \ of the studies obtained and in accordance with criteria of interest to our research\
    \ [\\[3,](#page-13-2) [4,](#page-13-3) [5,](#page-13-4) [6,](#page-14-0) [7,](#page-14-1)\
    \ [8\\]](#page-14-2).\n\nWe defined the questions that this research intends to\
    \ answer by following the Basili and Weiss Basili and Weiss - a systematic method\
    \ for organizing measurements. The method begins by specifying an objective (purpose,\
    \ object, problem, point of view). The goal is refined into several questions,\
    \ each of which in turn is refined into Basili and Weiss metrics. Providing the\
    \ answers to the questions, the data can be analyzed to identify whether or not\
    \ the objectives were met [\\[4\\]](#page-13-3).\n\nThus, the goal of this SLR\
    \ is:\n\n- Purpose Understand and characterize ...\n\t- Problem ... the solutions\
    \ in ATP ...\n\t\t- ∗ Object ... of Computer Program Testing ...\n\t\t\t- · Point\
    \ of view ... used by researchers and informatics professionals.\n\nBased on the\
    \ above stated goal, we derive the questions to be answered (see Table [1\\)](#page-2-0).\n\
    \n| #     | Question                                           |  |\n|-------|----------------------------------------------------|--|\n\
    | QP1   | What is the model, process, framework or tool      |  |\n|       | used\
    \ for test production?                          |  |\n| QP1.1 | What type of test\
    \ is generated?                    |  |\n| QP1.2 | What test production techniques\
    \ were applied?      |  |\n| QP1.3 | What tools does the study employ?       \
    \           |  |\n| QP1.4 | What are the prerequisites for its application?  \
    \  |  |\n| QP1.5 | What types of studies or evaluations have been con |  |\n|\
    \       | ducted?                                            |  |\n\n<span id=\"\
    page-2-0\"></span>Table 1: Research questions from SLR\n\nThe question QP1 allows\
    \ us to categorize the approaches and learn about the applicability of the study\
    \ proposal and meets the requirement of identifying solutions to the problem.\n\
    \n| Name                                                                     \
    \                                    |  |  |  |\n|--------------------------------------------------------------------------------------------------------------|--|--|--|\n\
    | IEEE Xplore<br>ACM Digital Library<br>Google Scholar<br>CiteSeerX<br>Inspec<br>ScienceDirect<br>EI\
    \ Compendex |  |  |  |\n| Springer Link                                      \
    \                                                          |  |  |  |\n\n<span\
    \ id=\"page-2-1\"></span>Table 2: Scientific publication bases\n\n### 2.2 Conduction\n\
    \nThe studies obtained for conducting this SLR were obtained from the scientific\
    \ publication sources listed in the Table [2](#page-2-1) and selected in our SLM[\\\
    [2\\]](#page-13-1).\n\nThe selection of documents was based on Inclusion and Exclusion\
    \ Criteria defined iteratively during the reading of the documents found and provided\
    \ to determine the suitability of each to the objectives of this work. The Inclusion\
    \ Criteria are those presented in the Table [3,](#page-2-2) and in the Table [4](#page-3-0)\
    \ we have the Exclusion Criteria.\n\n| #   | Descri¸c˜ao                     \
    \                                                      |\n|-----|---------------------------------------------------------------------------------------|\n\
    | CI1 | The Study is a review of current<br>models/processes/frameworks      \
    \                 |\n| CI2 | The study is useful for a better understanding of\
    \ the<br>problem                      |\n| CI3 | The study discusses one or more\
    \ tools within a process<br>applicable to this research |\n| CI4 | The study proposes\
    \ a<br>model/process/framework/methodology                           |\n\n<span\
    \ id=\"page-2-2\"></span>Table 3: Inclusion criteria for the SLR\n\n| CE1<br>The\
    \ study presents some<br>model/process/framework/methodology but does not<br>provide\
    \ enough information about its use<br>CE2<br>The study does not contain any kind\
    \ of evaluation for<br>the demonstration of results, such as case studies,<br>experiments,\
    \ or examples of use<br>CE3<br>The study is not directly related to this research\
    \ | # | Descri¸c˜ao |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---|-------------|\n\
    |                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                       |   |             |\n|               \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                        |   |             |\n|                              \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \         |   |             |\n|                                             \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                      |   | \
    \            |\n|                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                       |   |             |\n\
    |                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                       |   |             |\n|               \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                        |   |             |\n\n<span id=\"page-3-0\"></span>Table\
    \ 4: Exclusion criteria from SLR\n\nGiven the large number of studies[\\[2\\]](#page-13-1)\
    \ found we organized our work into iterative steps:\n\n- 1. Reading the summary\
    \ and conclusion; and\n- 2. Selection by reading the entire document.\n\n| Name\
    \                 | Qty. | %     |\n|----------------------|------|-------|\n\
    | IEEE Xplore          | 33   | 14.73 |\n| ACM Digital Library  | 66   | 29.46\
    \ |\n| Springer Link        | 11   | 4.91  |\n| Peri´odicos da CAPES | 114  |\
    \ 50.89 |\n| Sub-total            | 224  |       |\n| Duplicate studies    | 7\
    \    | 4.24  |\n| Rejected studies     | 52   | 31.52 |\n| TOTAL             \
    \   | 165  |       |\n\n<span id=\"page-3-1\"></span>Table 5: Result of the selection\
    \ of primary studies for the SLR\n\nAfter reading the abstract of the pre-selected\
    \ publications, if they are interesting, we also read the conclusion, and if the\
    \ paper remains promising to our expectation it is then selected (see Figure [1](#page-1-0)\
    \ and Table [5\\[](#page-3-1)[2\\]](#page-13-1)). The selection criteria at this\
    \ stage become slightly stricter and we are now looking for model-oriented papers,\
    \ methods, techniques and tools that generate tests for general-purpose computer\
    \ applications and we avoid for example:\n\n- Texts that deal with test generation\
    \ but never in an automated or semiautomated way;\n- Tests applied to computing\
    \ devices or equipment of specific use such as those of industrial, embedded and\
    \ specialized use such as automotive and so on;\n- Tests related to a specific\
    \ or particular application such as a database manager or a commercial application,\
    \ etc;\n- Tests aimed at a specific use of a technology or facility, such as geo-location\
    \ or the use of gestures on touch screens, etc;\n- Testing targeted at a particular\
    \ industry or segment of the economy or society, such as healthcare, banking and\
    \ finance, trade, etc.; and\n\n• Tests oriented to the detection of non-functional\
    \ flaws, such as security, performance, etc.\n\nOf course, despite the rigor we\
    \ seek to conduct this research, exceptions will be made for the sake of completeness\
    \ and common sense, and we may include studies, which applied to the technologies\
    \ or segments listed above, are part of a case study within a larger context.\n\
    \nA difficult decision to make at this point is whether or not to discriminate\
    \ the application of tests on a given platform. Nowadays we see the proliferation\
    \ of the use of computing resources in a pervasive way, and we have computing\
    \ devices on our desks, in our pockets, like jewelry on our wrists, and even in\
    \ our home appliances [\\[9\\]](#page-14-3). And this is just one of the aspects\
    \ we observe directly, since the computing itself can take place inside the device\
    \ locally, or remotely on servers connected to the Internet, or even in hybrid\
    \ mode. Following the criteria listed above, we will discriminate particular or\
    \ niche or proprietary uses of certain manufacturers and not consider them, but\
    \ we must include the cases where these platforms are extremely widespread and\
    \ have a wide range of applications developed on them, such as those used in cell\
    \ phone handsets for example.\n\nAfter this preliminary selection we will proceed\
    \ with a more careful reading of the complete document that will generate notes\
    \ that will be useful in this work.\n\nIn the full reading of the documents obtained\
    \ after the first and second search criteria, the selection becomes a qualitative\
    \ analysis where each document is evaluated according to quality criteria and\
    \ scored, a method proposed by Keele et al. and which we used to evaluate quality\
    \ of studies for this review [\\[6\\]](#page-14-0). These new criteria, which\
    \ we call Quality Criteria, are based on the research questions listed in the\
    \ Table [1](#page-2-0) and whose answers will be mapped into points. The sum of\
    \ the points obtained by each document will give us a score, within which we define\
    \ a cut-off value that will select or eliminate the document.\n\nThe questions\
    \ defined for this selection phase are those listed in the Table [6.](#page-4-0)\n\
    \n| #     | Description                  | Questions    |\n|-------|------------------------------|--------------|\n\
    | CQ1   | Describe the model, process, |              |\n|       | framework or\
    \ tool used or    |              |\n|       | created?                     | \
    \             |\n| CQ1.1 | Does it show the types       | QP1.1        |\n|  \
    \     | of tests generated?          |              |\n| CQ1.2 | Does it present\
    \ the test     | QP1.2        |\n|       | generation techniques used?  |    \
    \          |\n| CQ2   | List the prerequisites?      | QP1.3, QP1.4 |\n| CQ2.1\
    \ | Does it list technologies    |              |\n|       | and knowledge required\
    \ for   |              |\n|       | proper use?                  |           \
    \   |\n| CQ2.2 | List situations for which    |              |\n|       | its\
    \ use is recommended?      |              |\n| CQ2.3 | List situations for which\
    \    |              |\n|       | the use is not recommended?  |              |\n\
    \n<span id=\"page-4-0\"></span>Table 6: Quality criteria of the SLR\n\nThe possible\
    \ answers to the questions presented in the Table [6](#page-4-0) are listed in\
    \ the Table [7.](#page-5-0) With the quality assessment we answered most of the\
    \ research questions proposed in the Table [1](#page-2-0) with the exception of\
    \ the question \"QP1.4 - What types of studies or evaluations have been conducted\"\
    , for which we adopted the classification into six categories proposed by Chen\
    \ and Babar and listed in the Table [9](#page-6-0) [\\[5\\]](#page-13-4).\n\n\
    | Answer    | Value |\n|-----------|-------|\n| Yes       | 1.0   |\n| Partially\
    \ | 0.5   |\n| No        | 0.0   |\n\n<span id=\"page-5-0\"></span>Table 7: Quality\
    \ criteria values\n\nBased on the questions in the Table [6](#page-4-0) and the\
    \ answer values listed in the Table [7](#page-5-0) we have a Max Score of 10 points\
    \ (only elementary questions count towards the maximum score). We set the cutoff\
    \ score at cutoffScore points, i.e. documents that do not get at least this score\
    \ in the Qualitative Analysis phase will be discarded.\n\n| Criteria | Weight\
    \ |  |\n|----------|--------|--|\n| CQ1      | 7      |  |\n| CQ2      | 3   \
    \   |  |\n\n<span id=\"page-5-1\"></span>Table 8: Quality criteria weights\n\n\
    We apply the weights listed in the \"Table [8](#page-5-1) and thus a description\
    \ of the requirements in the studies (\"CQ1\") of the models or tools presented\
    \ have higher objective value than the description (\"CQ2\") or the listing of\
    \ their prerequisites.\n\n| Description                                      \
    \                                 |\n|-----------------------------------------------------------------------------------|\n\
    | Rigorous Analysis                                                          \
    \       |\n| Rigorous derivation and proof suitable for formal model         \
    \                  |\n| Case Study                                           \
    \                             |\n| An empirical investigation of a current phenomenon\
    \ in its actual context;         |\n| when the boundaries between phenomenon and\
    \ context are not clearly evident;       |\n| and in which multiple sources of\
    \ evidence are used                                |\n| Discussion           \
    \                                                             |\n| Qualitative\
    \ and textual opinion                                                   |\n| Example\
    \                                                                           |\n\
    | The authors describe an application and provide an example to help in the  \
    \       |\n| description, but the example is \"used to validate\" or \"evaluate\"\
    \ to the extent    |\n| that the authors suggest                             \
    \                             |\n| Experience Report                         \
    \                                        |\n| The result has been used in real\
    \ examples, but not in the form of case studies or |\n| controlled experiments,\
    \ evidence of its use is collected informally or formally   |\n| Field Study \
    \                                                                      |\n| Controlled\
    \ experiment conducted in industry settings                              |\n|\
    \ Laboratory Experiment with Human Subjects                                  \
    \       |\n| Identifying precise relationships between variables in a controlled\
    \ environment   |\n| using humans and applying quantitative techniques       \
    \                          |\n| Laboratory Experiment with Software Subjects \
    \                                     |\n| A laboratory experiment to compare\
    \ the performance of the proposed model or       |\n| tool with existing ones\
    \                                                           |\n| Simulation  \
    \                                                                      |\n| Running\
    \ with stochastic data and using a real model or tool                       |\n\
    |                                                                            \
    \       |\n\n<span id=\"page-6-0\"></span>Table 9: Categories of studies evaluated\
    \ in the SLR\n\nWith the adoption of the categorization of studies that we have\
    \ listed in Table [9,](#page-6-0) it only remains to quantify these categories\
    \ so that we can properly score the studies and select those of interest to us.\
    \ For this Galster et al. suggests an analysis in three dimensions[\\[10\\]](#page-14-4).\n\
    \n- C Context, which refers to the environment in which conducted, includes the\
    \ experience of the personnel involved, processes used, and illustrates the feasibility\
    \ of applying a particular technology\n- D Design, which describes the products,\
    \ resources and processes used in the study\n- V Validity, that is, a discussion\
    \ of the validity of the results obtained, their limitations, and what threatens\
    \ this validity\n\nWe capture the value of each dimension as proposed in Ivarsson\
    \ and Gorschek in three levels [\\[11\\]](#page-14-5):\n\n- 1 weak;\n- 2 regular;\
    \ and\n- 3 strong.\n\nThis rigor is appropriate for empirical studies and meets\
    \ the ideas presented by Kitchenham et al. and elaborated on in Dyba et al. Cross-referencing\
    \ the\n\n|                                                              | Value\
    \                                                                            \
    \                      |                                                     \
    \                                                                            \
    \                                                                            \
    \         |                                                                  \
    \                                                                            \
    \                                                                            \
    \                                        |\n|--------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Dimension                                                    | Weak (1)    \
    \                                                                            \
    \               | Regular (2)                                                \
    \                                                                            \
    \                                                                            \
    \  | Strong (3)                                                              \
    \                                                                            \
    \                                                                            \
    \                                 |\n| Context<br>of<br>the<br>study<br>(C)  \
    \                       | There seems to<br>be no<br>description of<br>the context\
    \ in<br>which the<br>evaluation is<br>conducted | The context in<br>which the\
    \ study<br>is conducted is<br>mentioned or<br>briefly<br>presented, but is<br>not\
    \ described in<br>a way that the<br>reader can<br>understand it<br>and compare\
    \ it<br>to another<br>context | The context is<br>described in a<br>way that the<br>reader\
    \ can<br>understand it<br>and compare it<br>to another<br>context            \
    \                                                                            \
    \                                               |\n| Study design<br>(D)     \
    \                                     | There seems to<br>be no<br>description\
    \ of<br>the evaluation<br>design presented                        | The study\
    \ design<br>is described<br>briefly, e.g., \"10<br>students turned<br>in assignments<br>1,\
    \ 2, and 3 on<br>time\"                                                      \
    \                                         | The study design<br>is described in\
    \ a<br>way that a<br>reader can<br>understand,<br>among other<br>things, the<br>variables<br>measured,\
    \ the<br>control used, the<br>treatments, the<br>selection and<br>sampling used,<br>and\
    \ other<br>pertinent<br>information |\n| Validity<br>of<br>the<br>dis<br>cussion<br>of<br>results\
    \ (V) | There seems to<br>be no<br>description of<br>any threats to<br>the validity\
    \ of<br>the evaluation       | The validity of<br>the study is<br>mentioned, but<br>not\
    \ described in<br>detail                                                     \
    \                                                                            \
    \     | The validity of<br>the evaluation is<br>discussed in<br>detail where<br>threats\
    \ are<br>described and<br>measures to<br>limit them are<br>detailed          \
    \                                                                            \
    \                          |\n\ndimensions with the values we arrive at the Table\
    \ [10](#page-7-0) with the classification of rigor [\\[7,](#page-14-1) [8\\]](#page-14-2).\n\
    \n<span id=\"page-7-0\"></span>Table 10: Classification of rigor applied to studies\
    \ in the SLR\n\n## 2.3 Qualitative Analysis\n\nBased on the parameters set in\
    \ the Tables [6,](#page-4-0) [7](#page-5-0) and [10](#page-7-0) the selected studies\
    \ (see Table [5\\)](#page-3-1) were qualified and the result can be seen in the\
    \ \"Selected Primary Studies\".\n\n![](_page_7_Figure_5.jpeg)\n\n<span id=\"page-7-2\"\
    ></span><span id=\"page-7-1\"></span>Figure 2: Qualified studies\n\nIn the Figure\
    \ [2](#page-7-1) and Table [11](#page-7-2) we list the totals of studies that\
    \ have qualified based on the cutoff score (7 points).\n\n## 2.4 Analysis of Results\n\
    \nBased on the criteria listed in the Table [3](#page-2-2) 165 were selected and\
    \ 52[\\[2\\]](#page-13-1) rejected.\n\nThe research questions listed in Table\
    \ [1](#page-2-0) were applied to the selected studies and we obtained the results\
    \ that we list further below.\n\n#### 2.4.1 Models, processes, frameworks or tools\
    \ used for test production (QP1)\n\nIn the SLM[\\[2\\]](#page-13-1) we applied\
    \ the Petersen et al. systematics to classify the obtained documents as seen in\
    \ the Figure [3](#page-8-0) and evaluated the type of contribution based on interpretation\
    \ of the abstracts and listed in the Figure [4](#page-8-1) and Table [17](#page-11-0)\
    \ [\\[12,](#page-14-6) [13\\]](#page-14-7).\n\n![](_page_8_Figure_6.jpeg)\n\n\
    <span id=\"page-8-0\"></span>Figure 3: Classification Scheme (adapted from [\\\
    [12\\]](#page-14-6))\n\nWhat types of tests are produced (QP1.1)? In the Figure\
    \ [4](#page-8-1) we list the types of generators addressed by the studies, and\
    \ in the Figure [5](#page-8-2) the types of tests produced.\n\n![](_page_8_Figure_9.jpeg)\n\
    \n<span id=\"page-8-2\"></span><span id=\"page-8-1\"></span>Figure 4: Artifact\
    \ Types\n\n| Artifact Type | %   | Qty.  |\n|---------------|-----|-------|\n\
    | Both          | 32  | 6.67  |\n| Code          | 5   | 57.58 |\n| Data     \
    \     | 124 | 32.73 |\n| N/A           | 4   | 3.03  |\n\n| Generator Type | %\
    \   | Qty.  |\n|----------------|-----|-------|\n| Formal         | 33  | 20.00\
    \ |\n| White-box      | 130 | 78.79 |\n| Black-box      | 2   | 1.21  |\n\nTable\
    \ 12: Types of Artifacts Produced\n\nTable 13: Types of Generators\n\nWhat test\
    \ generation techniques were applied (QP1.2)? The most used techniques found in\
    \ the studies can be seen in Figure [6.](#page-9-0)\n\n![](_page_9_Figure_5.jpeg)\n\
    \n<span id=\"page-9-0\"></span>Figure 6: Models, methods, processes and techniques\
    \ applied in ATP\n\nWhat tools does the study employ (QP1.3)? In Figure [7](#page-9-1)\
    \ we list the tools employed by the studies.\n\n![](_page_9_Figure_8.jpeg)\n\n\
    <span id=\"page-9-1\"></span>Figure 7: Tools used in the studies\n\n<span id=\"\
    page-9-2\"></span>Table 14: Tools used in the studies\n\nWe classified as \"Proof\
    \ of concept\" the studies that used some program to present their approach but\
    \ did not use or produce a tool that can be considered ready for use by industry\
    \ and in some even for other studies.\n\nWhat are the prerequisites for its application\
    \ (QP1.4)? What artificats we observed that are required to perform the analysis\
    \ according to the study.\n\n![](_page_10_Figure_0.jpeg)\n\n<span id=\"page-10-0\"\
    ></span>Figure 8: Study Requirements\n\n| Study type          | %     | Qty. |\n\
    |---------------------|-------|------|\n| Source code         | 52.12 | 86   |\n\
    | Model               | 9.09  | 15   |\n| Model + Source code | 0.61  | 1    |\n\
    | Tool + Source code  | 30.30 | 50   |\n| Tool + Model        | 7.88  | 13   |\n\
    \n<span id=\"page-10-1\"></span>Table 15: Study Requirements\n\nWhat types of\
    \ studies or evaluations have been conducted (QP1.5)? The types of studies were\
    \ classified according to Table [16](#page-11-1) and the results listed in Figure\
    \ [9](#page-11-2) and Table [17.](#page-11-0)\n\n| Category     | Description\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \   |\n|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Metric       | A system or standard of measures or measure<br>ments taken using\
    \ an existing standard.                                                      \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                          |\n| Tool         | A device or implementation, used\
    \ to perform a<br>certain function.                                          \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                          |\n| Model        |\
    \ A comprehensive and systematic approach that<br>includes theoretical principles,\
    \ benefits and draw<br>backs, objectives, methodological guidelines and<br>specifications,\
    \ and the characteristic use of cer<br>tain sets of methods and techniques.  \
    \                                                                            \
    \                                                                         |\n\
    | Method       | No particular theoretical orientation is inferred<br>in a method.\
    \ Researchers impose their own par<br>ticular theoretical beliefs on an experiment\
    \ when<br>they design and implement it by applying one or<br>more techniques.\
    \                                                                            \
    \                                                                            \
    \                    |\n| Technique    | A single operation or interaction in\
    \ which a re<br>searcher uses one or more procedures to elicit an<br>immediate\
    \ reaction from the object of study or to<br>shape the experiment and obtain results.\
    \                                                                            \
    \                                                                            \
    \                                             |\n| Procedure    | An organized\
    \ sequence of operations and interac<br>tions that a researcher uses to conduct\
    \ an exper<br>iment.                                                         \
    \                                                                            \
    \                                                                            \
    \                                                                            |\n\
    | Intervention | Purposefully interferes with or mitigates various<br>aspects\
    \ of the object of study and that affect the<br>outcome by applying procedure,\
    \ technique. The<br>elements acting on the industry during a partic<br>ular intervention\
    \ are most often computer appli<br>cations, the researcher, or both.         \
    \                                                                            \
    \                  |\n| Approach     | A broad way of addressing an industry concern\
    \ or<br>problem. A specific methods is not implied, but<br>a specific set of techniques\
    \ will likely come into<br>play when trying to intervene in the industry and<br>the\
    \ problem that is the subject of the research.<br>The procedures to be used will\
    \ be determined by<br>the delimitations of the methodological variant in<br>which\
    \ we design the study. |\n| Strategy     | An action plan designed to achieve\
    \ an overall<br>goal.                                                        \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                        |\n\n<span id=\"page-11-1\"\
    ></span>Table 16: Type of contribution\n\n![](_page_11_Figure_2.jpeg)\n\n<span\
    \ id=\"page-11-0\"></span>Table 17: Contributions of the Studies\n\n<span id=\"\
    page-11-2\"></span>Figure 9: Contributions of the Studies\n\n## 3 Results\n\n\
    We present the results of a SLR employed to find relevant studies on ATP. This\
    \ review applied the methodology of Petersen et al. with elements of Basili and\
    \ Weiss, Keele et al., Brereton et al. The results obtained list different models,\
    \ processes, frameworks and tools used with diverse approaches and results.\n\n\
    ### 3.1 Conclusions\n\nBased on the research questions developed in Section [2](#page-0-0)\
    \ we conclude that:\n\n#### 3.1.1 Models, processes, frameworks or tools applied\
    \ to test production\n\nTypes of tests produced As we can see from the Figures\
    \ [4](#page-8-1) and [5](#page-8-2) much of the studies have been devoted to producing\
    \ test verification of white-box [1](#page-12-0) . We also observe significant\
    \ concern with the Oracle problem (determining the correct outputs for given inputs)\
    \ and there are a significant number of approaches that produce data for program\
    \ verification.\n\nGiven the aspect of this research and the questions we address,\
    \ black-box tests[2](#page-12-1) were not representative in our results, however\
    \ according to Gaudel formal methods were a highlight and these can be considered\
    \ to be black-box tests.\n\nTechniques applyed to test production Several techniques\
    \ were employed in test production, and among them we highlight Search Methods\
    \ (see Figure [6\\)](#page-9-0). Secondly we note the application of Specification\
    \ Extraction[3](#page-12-2) as an important approach employed by the studies.\n\
    \nHighlighted we can also observe: Symbolic Execution, Combinatorial Methods and\
    \ Model Notation.\n\nTools applyed by the studies In the Figure [7](#page-9-1)\
    \ and Table [14](#page-9-2) we observed a great diversity of tools used and none\
    \ in particular stood out in our study, highlighting the use of UML (Unified Modelling\
    \ Language) by a significant percentage (if compared to other approaches) of studies.\
    \ This fragmentation demonstrates, on the one hand, a great wealth of available\
    \ solutions and approaches, but it may also be indicative of a lack of maturity\
    \ of the solutions presented, which can be observed by the opinion of some authors\
    \ [\\[15,](#page-14-8) [16\\]](#page-14-9).\n\nPre-requisites to the proposed\
    \ approaches For even obvious reasons (related to white-box testing - see Figure\
    \ [5\\)](#page-8-2), the vast majority of studies require access to the source\
    \ code of the applications (see Figure [8](#page-10-0) and Table [15\\)](#page-10-1).\
    \ Many\n\n<span id=\"page-12-0\"></span><sup>1</sup>Method of validating non-functional,\
    \ internal aspects of a computer application.\n\n<span id=\"page-12-1\"></span><sup>2</sup>Method\
    \ of validating functional and external aspects of a computer application\n\n\
    <span id=\"page-12-2\"></span><sup>3</sup>Comparative studies do not present particular\
    \ techniques or methods\n\nstudies are conducted using tools (none in particular\
    \ as we have noted - see Figure [7\\)](#page-9-1), but an important number have\
    \ been conducted from models (previously produced by a development process or\
    \ ad hoc).\n\nTypes of studies or evaluations conducted In the Figure [9](#page-11-2)\
    \ and Table [17](#page-11-0) we list the main contributions of the studies, and\
    \ note a rather encouraging number of concrete contributions (in the form of methods,\
    \ tools, metrics, and models) that can be leveraged and extended by the industry.\n\
    \n### 3.2 Future work\n\nThis work aimed to prepare the ground for further research\
    \ on ATP where we will determine the challenges in applying generative testing\
    \ techniques and evaluate the solutions we intend to address.\n\n## Acronyms\n\
    \n| ATP        | Automated Test Production<br>- pages: 1, 2, 13, 14          \
    \                                          |\n|------------|-------------------------------------------------------------------------------------------------------|\n\
    | SLM<br>SLR | Systematic Literature Mapping<br>- pages: 1, 3, 9<br>Systematic\
    \ Literature Review<br>- pages: 1–3, 13 |\n\nUML Unified Modelling Language -\
    \ page: 13\n\n## References\n\n- <span id=\"page-13-0\"></span>[1] P. Brereton,\
    \ B. A. Kitchenham, D. Budgen, M. Turner, and M. Khalil, \"Lessons from applying\
    \ the systematic literature review process within the software engineering domain,\"\
    \ Journal of systems and software, vol. 80, no. 4, pp. 571–583, 2007.\n- <span\
    \ id=\"page-13-1\"></span>[2] J. M. Gomes and L. A. V. Dias, \"Automated test\
    \ production – systematic literature mapping,\" 2024. arXiv: [2401.01430 \\[cs.SE\\\
    ]](https://arxiv.org/abs/2401.01430).\n- <span id=\"page-13-2\"></span>[3] B.\
    \ Kitchenham, O. P. Brereton, D. Budgen, M. Turner, J. Bailey, and S. Linkman,\
    \ \"Systematic literature reviews in software engineering–a systematic literature\
    \ review,\" Information and software technology, vol. 51, no. 1, pp. 7–15, 2009.\n\
    - <span id=\"page-13-3\"></span>[4] V. R. Basili and D. M. Weiss, \"A methodology\
    \ for collecting valid software engineering data,\" IEEE Transactions on software\
    \ engineering, no. 6, pp. 728–738, 1984.\n- <span id=\"page-13-4\"></span>[5]\
    \ L. Chen and M. A. Babar, \"A systematic review of evaluation of variability\
    \ management approaches in software product lines,\" Information and Software\
    \ Technology, vol. 53, no. 4, pp. 344–362, 2011.\n- <span id=\"page-14-0\"></span>[6]\
    \ S. Keele et al., \"Guidelines for performing systematic literature reviews in\
    \ software engineering,\" Technical report, Ver. 2.3 EBSE Technical Report. EBSE,\
    \ Tech. Rep., 2007.\n- <span id=\"page-14-1\"></span>[7] B. A. Kitchenham, T.\
    \ Dyba, and M. Jorgensen, \"Evidence-based software engineering,\" in Proceedings.\
    \ 26th International Conference on Software Engineering, IEEE, 2004, pp. 273–281.\n\
    - <span id=\"page-14-2\"></span>[8] T. Dyba, B. A. Kitchenham, and M. Jorgensen,\
    \ \"Evidence-based software engineering for practitioners,\" IEEE software, vol.\
    \ 22, no. 1, pp. 58–65, 2005.\n- <span id=\"page-14-3\"></span>[9] R. M. Davis,\
    \ \"Evolution of computers and computing,\" Science, vol. 195, no. 4283, pp. 1096–1102,\
    \ 1977.\n- <span id=\"page-14-4\"></span>[10] M. Galster, D. Weyns, D. Tofan,\
    \ B. Michalik, and P. Avgeriou, \"Variability in software systems—a systematic\
    \ literature review,\" IEEE Transactions on Software Engineering, vol. 40, no.\
    \ 3, pp. 282–306, 2013.\n- <span id=\"page-14-5\"></span>[11] M. Ivarsson and\
    \ T. Gorschek, \"A method for evaluating rigor and industrial relevance of technology\
    \ evaluations,\" Empirical Software Engineering, vol. 16, no. 3, pp. 365–395,\
    \ 2011.\n- <span id=\"page-14-6\"></span>[12] K. Petersen, R. Feldt, S. Mujtaba,\
    \ and M. Mattsson, \"Systematic mapping studies in software engineering,\" in\
    \ 12th International Conference on Evaluation and Assessment in Software Engineering\
    \ (EASE) 12, 2008, pp. 1–10.\n- <span id=\"page-14-7\"></span>[13] R. Wieringa,\
    \ N. Maiden, N. Mead, and C. Rolland, \"Requirements engineering paper classification\
    \ and evaluation criteria: A proposal and a discussion,\" Requirements engineering,\
    \ vol. 11, no. 1, pp. 102–107, 2006.\n- [14] M.-C. Gaudel, \"Formal methods for\
    \ software testing,\" in 2017 International Symposium on Theoretical Aspects of\
    \ Software Engineering (TASE), IEEE, 2017, pp. 1–3.\n- <span id=\"page-14-8\"\
    ></span>[15] U. Rueda, F. Kifetew, and X. Devroey, \"Towards automated test case\
    \ generation maturity,\" in Proceedings of the 12th International Workshop on\
    \ Search-Based Software Testing, ser. SBST '19, ZSCC: 0000000, IEEE Press, 2019,\
    \ pp. 9–10. doi: [10.1109/SBST.2019.00011](https://doi.org/10.1109/SBST.2019.00011).\
    \ [Online]. Available: <https://doi.org/10.1109/SBST.2019.00011>.\n- <span id=\"\
    page-14-9\"></span>[16] A. Arcuri, \"An experience report on applying software\
    \ testing academic results in industry: We need usable automated test generation,\"\
    \ Empir Software Eng, vol. 23, no. 4, pp. 1959–1981, 2018, issn: 1382-3256. doi:\
    \ [10.1007/s10664-017-9570-9](https://doi.org/10.1007/s10664-017-9570-9).\n\n\
    | #        | Title                                                           \
    \                                                                            \
    \                                      | Author                              \
    \                                                                            \
    \      |\n|----------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n\
    | 1<br>2   | Support<br>Software<br>and<br>Primary<br>Evolving<br>Using<br>for<br>Generation<br>Generation<br>Suite<br>Test<br>Test<br>Unit<br>Multifaceted<br>Automated\
    \                       | Sina<br>Shamshiri,<br>Gay,                         \
    \                                                                   |\n|     \
    \     | Functions<br>Fitness<br>ing                                          \
    \                                                                            \
    \                                 | Gregory                                  \
    \                                                                            \
    \ |\n| 3        | Improving Model-Based Test Generation by Model Decomposition\
    \                                                                            \
    \                                          | Riccobene,<br>Angelo;<br>Gargantini,<br>Paolo;<br>Arcaini,\
    \                                                            |\n| 4        | to\
    \ the<br>Algorithms Applied<br>Automatic Generation of Search-Based          \
    \                                                                            \
    \                        | A.<br>Jackson<br>Lima,<br>Jakubovski;<br>L.<br>Helson<br>Elvinia<br>Filho,\
    \                                            |\n| 5        | Lines<br>Product<br>of\
    \ Software<br>Adaptive<br>Testing<br>Feature                                 \
    \                                                                            \
    \    | Kamal<br>R.<br>Silvia<br>Vergilio,<br>Prado;                          \
    \                                                |\n|          | Strategy<br>Optimization<br>Generation<br>Learning-Based<br>Cases<br>Teaching<br>Test<br>Functional<br>GUI<br>Fuzzy<br>for\
    \                                                        | Z.<br>Zamli,<br>Fakhrud;<br>Din,\
    \                                                                            \
    \          |\n| 6        | Context<br>Using<br>Generation<br>Test<br>Improving<br>One-Size-Fits-None?<br>Fitness<br>Optimized\
    \                                                                            \
    \    | Gregory<br>Gay,                                                       \
    \                                                |\n| 7        | Optimisa<br>a\
    \ Many-Objective<br>as<br>Generation<br>Functions<br>Case<br>Test<br>Automated\
    \                                                                            \
    \            | Meshesha;<br>Fitsum<br>Kifetew,<br>Annibale;<br>Panichella,   \
    \                                                        |\n| 8        | Generation<br>Test<br>Targets<br>Approach\
    \ for Model-Based<br>of the<br>Selection<br>Dynamic<br>Decomposition-Based<br>with<br>Problem<br>tion\
    \                                     | Riccobene,<br>Angelo;<br>Gargantini,<br>Paolo;<br>Paolo<br>Tonella,<br>Arcaini,\
    \                                       |\n| 9        | for<br>Suites<br>Test<br>Controllable\
    \                                                                            \
    \                                                                 | Robert<br>Elvinia\
    \                                                                            \
    \                         |\n|          | Distributed<br>Complete<br>Generating<br>Testing\
    \                                                                            \
    \                                                      | M.<br>Hierons,      \
    \                                                                            \
    \                      |\n| 10<br>11 | Mo<br>for<br>Strategy<br>Testing<br>Generation<br>Event-Based<br>Model<br>for<br>Morphology<br>Static-Dynamic<br>Model<br>A<br>Exploiting<br>AMOGA:\
    \                               | Ahmed,<br>Rosziati;<br>Ibrahim,<br>Mutlu<br>Ibrahim-Anka;<br>Beyazit,<br>Fevzi;<br>Salihu,<br>Belli,\
    \                  |\n|          | Testing<br>Apps<br>bile                   \
    \                                                                            \
    \                                                            | Asmau<br>Usman,<br>Z.;<br>Kamal<br>Zamli,<br>S.;<br>Bestoun\
    \                                                           |\n| 12       | Optimisa<br>Compiler<br>via<br>Equivalences<br>Mutant<br>Trivial<br>Detecting<br>tions\
    \                                                                            \
    \                | Yue;<br>Jia,<br>Harman,<br>Mike;<br>Yves;<br>Papadakis,<br>Traon,<br>Le<br>Marinos;<br>Nicos;<br>Malevris,<br>Kintis,\
    \ |\n| 13       | to<br>Proofs<br>Pen-and-Paper<br>From<br>Verification:<br>Software<br>Deductive\
    \                                                                            \
    \                       | Mark<br>Marieke<br>Huisman,<br>Reiner;<br>H¨ahnle, \
    \                                                                   |\n| 14  \
    \     | A multi-objective test data generation approach for mutation test<br>Tools<br>Industrial\
    \                                                                            \
    \              | R.<br>Silvia<br>Vergilio,<br>A.;<br>Rui<br>Filho,<br>Matnei \
    \                                                          |\n|          | models<br>of\
    \ feature<br>ing                                                             \
    \                                                                            \
    \              |                                                             \
    \                                                          |\n| 15       | val<br>string<br>expressions<br>for<br>data<br>regular<br>test<br>invalid<br>and<br>searches<br>and<br>of\
    \ valid<br>web<br>using<br>generation<br>routines<br>Automatic<br>idation | Stevenson,<br>Phil;<br>McMinn,<br>Muzammil;<br>Shahbaz,\
    \                                                               |\n| 16      \
    \ | suites<br>test<br>of whole<br>generation<br>mutation-based<br>scalable<br>Achieving\
    \                                                                            \
    \                   | Andrea<br>Arcuri,<br>Gordon;<br>Fraser,<br>Mark        \
    \                                                               |\n| 17      \
    \ | T<br>ON LATE AC<br>CONSTRAINTS<br>WAY TEST GENERATION STRATEGY BASED<br>OF<br>BENCHMARKING<br>COMPARATIVE\
    \                                                                         | Alsewari;<br>Rahman<br>Abdul<br>Z.;<br>Al-Kazemi<br>Kamal<br>Basem<br>Zamli,\
    \                                          |\n|          | ALGORITHM<br>CLIMBING<br>HILL<br>CEPTANCE\
    \                                                                            \
    \                                                             |              \
    \                                                                            \
    \                             |\n| 18       | An experimental study of hyper-heuristic\
    \ selection and acceptance                                                   \
    \                                                              | Gra<br>Kendall,<br>Fakhrud;<br>Din,<br>Z.;<br>Kamal<br>Zamli,\
    \                                                         |\n| 19       | for<br>flow\
    \ graph<br>generation<br>control<br>suite<br>multiple condition<br>test<br>t-way<br>combinatorial<br>MOF-based<br>for<br>an<br>mechanism<br>MCCFG:\
    \                      | R.<br>Kim,<br>S.<br>Young;<br>Bestoun<br>Park,<br>Ahmed,<br>Hyun;<br>ham;<br>Son,\
    \                                     |\n|          | generation<br>case<br>test<br>automatic\
    \                                                                            \
    \                                                               |            \
    \                                                                            \
    \                               |\n| 20       | gen<br>suite<br>test<br>t-way<br>for<br>strategy<br>hyper-heuristic<br>Search<br>Tabu<br>A\
    \                                                                            \
    \            | Kendall,<br>Y;<br>Basem<br>Alkazemi,<br>Z.;<br>Kamal<br>Graham<br>Zamli,\
    \                                              |\n| 21       | specification<br>evolved<br>for<br>generation<br>case<br>test<br>based<br>net<br>eration<br>Petri\
    \                                                                            \
    \     | Jin,<br>Haibo;<br>Chen,<br>Mingyue;<br>Jiang,<br>Zuohua;<br>Ding,    \
    \                                                 |\n| 22       | Reduc<br>of\
    \ Mutant<br>Generation<br>the<br>for<br>Hyper-Heuristic<br>A<br>Sentinel:    \
    \                                                                            \
    \               | Krinke,<br>Federica;<br>Sarro,<br>Mengchu<br>Giovani;<br>Zhou,<br>Guizzo,<br>Zhi;\
    \                                     |\n|          | Strategies<br>tion     \
    \                                                                            \
    \                                                                            \
    \   | Jens;<br>R.<br>Silvia<br>Vergilio,                                     \
    \                                               |\n| 23       | debug<br>and<br>testing<br>for<br>oracles<br>(F)LTL<br>of<br>generation<br>Automated\
    \                                                                            \
    \                  | Franz<br>Wotawa,<br>Ingo;<br>Pill,                      \
    \                                                              |\n| 24       |\
    \ Gen<br>Test<br>for<br>Solvers<br>SMT<br>and<br>of SAT<br>Use<br>the<br>Optimize<br>to<br>How<br>ging\
    \                                                                            \
    \  | Riccobene,<br>Angelo;<br>Gargantini,<br>Paolo;<br>Arcaini,              \
    \                                              |\n| 25       | Automated<br>the<br>for<br>Expressions<br>function<br>fitness<br>of\
    \ Boolean<br>the<br>Choosing<br>eration                                      \
    \                                   | Gre<br>Gay,<br>Almulla,<br>Alireza;<br>Salahirad,<br>Elvinia\
    \                                                          |\n|          | generation<br>job:<br>faults<br>real<br>detect<br>that<br>suites<br>of\
    \ test                                                                       \
    \                                | Hussein;<br>gory                          \
    \                                                                            |\n\
    | 26       | Gen<br>Case<br>Test<br>Automatic<br>for<br>Tool<br>and<br>Process<br>TDD<br>A<br>MoFQA:\
    \                                                                            \
    \               | Nathalie<br>Gonz´alez;<br>Magal´ı<br>Riquelme;<br>Linda    \
    \                                                           |\n| 27       | models<br>process<br>business<br>from<br>generation<br>Models<br>cases<br>MDD<br>test<br>from<br>Automatic<br>eration\
    \                                                             | Mohammad;<br>Amiri,<br>Arezoo;<br>Cernuzzi<br>Seqerloo,<br>Luca<br>Yazdani<br>Aquino;\
    \                                 |\n| 28       | Cell<br>Boolean<br>for<br>Generation<br>Case<br>Test\
    \                                                                            \
    \                                                  | Mahnaz<br>Koupaee,<br>Wei-Tek<br>Saeed;<br>Parsa,<br>Lian\
    \                                                             |\n| 29       |\
    \ chart<br>Covering<br>state<br>from<br>by<br>generation<br>Expressions<br>case<br>test<br>based<br>coverage<br>Transition\
    \                                                          | S.K.<br>Swain,<br>Mitrabinda;<br>Tsai<br>Ray,<br>S.;<br>Pradhan,<br>Yu;\
    \                                               |\n| 30       | generation<br>suite<br>test<br>whole<br>for<br>Algorithm<br>Memetic<br>diagram<br>A\
    \                                                                            \
    \                   | Phil<br>McMinn,<br>Andrea;<br>Arcuri,<br>Gordon;<br>Fraser,\
    \                                                           |\n| 31       | algo<br>pollination<br>flower<br>on<br>based<br>generation<br>data<br>test<br>Pairwise\
    \                                                                            \
    \                | Tairan,<br>A.A.;<br>Alsewari,<br>B.;<br>Abdullah<br>Nasser,\
    \                                                           |\n| 32       | Isabelle<br>in<br>diagrams<br>for\
    \ invariant<br>code generation<br>and<br>Verification<br>rithm               \
    \                                                                     | J<br>Eriksson,<br>Rj;<br>Z.<br>Kamal<br>Back,<br>V;<br>Zamli,<br>Preoteasa,<br>N.M.;\
    \                                  |\n| 33       | generation<br>test<br>for<br>under-approximation<br>Tri-modal\
    \                                                                            \
    \                                         | Masson,<br>Jacques;<br>Julliand,<br>Hadrien;<br>Bride,\
    \                                                                |\n| 34     \
    \  | strength<br>variable<br>for<br>algorithm<br>greedy<br>on<br>elitism<br>the<br>Adapting\
    \                                                                            \
    \                | Kamal<br>Zamli,<br>A.A.;<br>Alsewari,<br>A.A.B.A.;<br>Pierre-Alain<br>Homaid,\
    \                                         |\n\n# Appendices\n\n## Appendix A Selected\
    \ Primary Studies\n\ncombinatorial test cases generation\n\nZ.; Alsariera, Y.A.\n\
    \n35 Model Learning and Test Generation Using Cover Automata Ipate, Florentin;\
    \ Stefanescu, Alin; Dinca, Ionut"
- id: exception_aware_lifecycle_model_construction_for_framework_apis_yan_ji_wei1_2_huang_jin_hao3_yang_heng_qin2_4_yan_jun1_2
  title: Exception-aware Lifecycle Model Construction for Framework APIs
  abstract: 'The implementation of complex software systems usually depends on low-level

    frameworks or third-party libraries. During their evolution, the APIs adding

    and removing behaviors may cause unexpected compatibility problems. So,

    precisely analyzing and constructing the framework/ library''s API lifecycle

    model is of great importance. Existing works have proposed the API

    existence-changing model for defect detection, while not considering the

    influence of semantic changes in APIs. In some cases, developers will not

    remove or deprecate APIs but modify their semantics by adding, removing, or

    modifying their exception-thrown code, which may bring potential defects to

    upper-level code. Therefore, besides the API existence model, it is also

    necessary for developers to be concerned with the exception-related code

    evolution in APIs, which requires the construction of exception-aware API

    lifecycle models for framework/library projects. To achieve automatic

    exception-aware API lifecycle model construction, this paper adopts a static

    analysis technique to extract exception summary information in the framework

    API code and adopts a multi-step matching strategy to obtain the changing

    process of exceptions. Then, it generates exception-aware API lifecycle models

    for the given framework/library project. With this approach, the API lifecycle

    extraction tool, JavaExP, is implemented, which is based on Java bytecode

    analysis. Compared to the state-of-the-art tool, JavaExP achieves both a higher

    F1 score (+60%) and efficiency (+7x), whose precision of exception matching and

    changing results is 98%. Compared to the exception-unaware API lifecycle

    modeling on 60 versions, JavaExp can identify 18% times more API changes. Among

    the 75,433 APIs under analysis, 20% of APIs have changed their

    exception-throwing behavior at least once after API introduction, which may

    bring many hidden compatibility issues.'
  url: http://arxiv.org/abs/2401.02660v1
  keywords: '* static analysis; program evolution; Java exception summary; API lifecycle'
  document: "# 异常信息敏感的框架 API 生命周期模型构造\\*\n\n燕季薇 1) ,2) 黄进豪 3) 杨恒钦 2),4) 严俊 1),2) \\\
    *\n\n1) (中国科学院软件研究所 软件工程技术研究开发中心 北京 100190)\n\n> 2) (中国科学院大学 北京 100049)\n\n(北京工业大学\
    \ 北京 100124)\n\n3)\n\n4) (国科大杭州高等研究院 杭州 310024)\n\n摘 要 大型软件系统的实现通常依赖于底层框架或第三方库。这些框架/库代码数量繁多、实现复杂,但它们的演化升级\
    \ 往往独立于其调用者,为上层软件的质量保障带来挑战。例如,框架/库代码升级时 API 的新增和删除行为可能引发上层软 件的兼容性问题。准确分析并提取框架/库代码\
    \ API 生命周期模型可以有效辅助对这类代码演化情况的理解,支撑上层的分 析与测试。现有工作中的 API 生命周期模型主要关注 API 的存在性变动,而未考虑特定代码语义变更对开发者的影响。在\
    \ 某些情况下,开发者没有删除或废弃特定的 API,而是更改其代码语义,例如增加、删除或修改用于外部数据校验的异常抛 出相关代码。如果新版本框架/库中的异常抛出行为发生变更而调用者不知情,可能给上层软件系统带来隐患。因此,除了\
    \ API 的存在性,开发者还应特别关注异常相关代码的变更情况,即为框架/库代码构建异常信息敏感的 API 生命周期模型。\n\n为实现异常信息敏感的 API\
    \ 生命周期模型构造,本文采用面向 Java 字节码的静态分析方法,首先提取框架 API 中的异 常抛出行为,生成异常摘要信息,然后通过多轮流式匹配策略获取异常信息的变更情况,构造异常信息敏感的\
    \ API 生命周期 模型。该方法:1)通过控制依赖语句切片提取异常抛出语句的关键触发条件,采用参数推断策略将局部变量的约束条件转 换为仅与外部输入参数相关的异常前断言,并基于自底向上的摘要传递实现跨过程异常摘要提取;2)通过关键信息精准匹\
    \ 配和自适应模糊匹配策略,分析异常摘要信息的新增、删除和修改情况,最终得到异常敏感的 API 生命周期模型,共包含七 种 API 变更形式。基于该方法,实现了基于\
    \ Java 字节码分析的 API 生命周期提取工具 JavaExP。与最新的 Java 异常分析工 具相比,在异常摘要信息提取方面,JavaExP 在大幅提高分析效率(+7x)的同时实现了更高的\
    \ F1 分数(+60%)。通过人工确 认 Apache common-io 项目在 19 个版本上的演化报告,发现异常级别的演化分析准确率达到 98%。对六个真实框架/库项目\
    \ 在 60 个版本上的 API 生命周期分析表明,与异常不敏感的 API 生命周期相比,采用异常敏感的分析时,API 发生变动的比 例提高了 18%。在\
    \ 75,433 个被分析的 API 中,约有 20% API 的异常抛出行为至少发生过一次改变,这些 API 共涉及超过七 千多处独立的异常变更。在多个项目上的分析结果表明,异常敏感的模型构造能够更加精准地描述\
    \ API 的演化过程。\n\n关键词 静态分析;代码演化;Java 异常摘要;API 生命周期 中图法分类号 TP311 DOI 号 xxx\n\n# **Exception-aware\
    \ Lifecycle Model Construction for Framework APIs**\n\nYAN Ji-Wei1),2) HUANG Jin-Hao3)\
    \ Yang Heng-Qin2),4) YAN Jun1),2)\\*\n\n1)(Technology Center of Software Engineering,\
    \ Institute of Software, Chinese Academy of Sciences Beijing, 100190)\n\n2)(University\
    \ of Chinese Academy of Sciences, Beijing, 100049)\n\n3)(Beijing University of\
    \ Technology, Beijing, 100124)\n\n4)(Hangzhou Institute for Advanced Study, Hangzhou,\
    \ 310024)\n\n#### **Abstract**\n\nThe implementation of complex software systems\
    \ usually depends on low-level frameworks or third-party libraries. However, the\
    \ evolution of these frameworks or libraries is independent of the upper-level\
    \ applications, which brings challenges in upper-level code quality assurance.\
    \ For example, during code evolution, the APIs adding and removing behaviors may\
    \ cause unexpected compatibility problems. Precisely analyzing and constructing\
    \ the framework/ library's API lifecycle model is of great importance, which could\
    \ help in understanding changes in APIs as well as supporting the analysis and\
    \ testing of upper-level code. Nowadays, existing works propose the API existencechanging\
    \ model for defect detection, while not considering the influence of semantic\
    \ changes in APIs. In some cases, developers will not remove or deprecate APIs\
    \ but modify their semantics by adding, removing, or modifying their exception-thrown\
    \ code, which is used to verify the users' inputs. It may bring potential defects\
    \ to upper-level code if the exception-related behaviors in newer versions are\
    \ changed silently. Therefore, besides the API existence model, it is also necessary\
    \ for developers to be concerned with the exception-related code evolution in\
    \ APIs, which requires the construction of exception-aware API lifecycle models\
    \ for framework/library projects.\n\nTo achieve automatic exception-aware API\
    \ lifecycle model construction, this paper adopts static analysis technique to\
    \ extract exception summary information in the framework API code and adopts a\
    \ multi-step matching strategy to obtain the changing process of exceptions. Then,\
    \ it generates exception-aware API lifecycle models for the given framework/library\
    \ project. Our approach: 1) adopts control-dependency slicing analysis to extract\
    \ the conditions of the exception-thrown statements; uses a parameter tracing\
    \ strategy to transform exception-throwing conditions into external-variable-related\
    \ preconditions; and performs inter-procedure precondition construction by a bottom-up\
    \ summary-based analysis. 2) proposes the exact-matching and adaptive-matching\
    \ strategies to analyze the addition, deletion, and modification changes based\
    \ on the summarized exception summaries; generates exception-aware API lifecycle\
    \ model which covers seven API changing types. With this approach, the API lifecycle\
    \ extraction tool, JavaExP, is implemented, which is based on Java bytecode analysis.\
    \ Compared to the state-of-the-art tool, JavaExP achieves both higher F1-score\
    \ (+60%) and efficiency (+7x). By manually confirming the exception changing reports\
    \ on 19 versions of Apache common-io project, we found that the precision of exception\
    \ matching and changing results is 98%. The evaluation of 60 versions of six projects\
    \ shows that, compared to the exception-unaware API lifecycle modeling, JavaExp\
    \ can identify 18% times more API changes. Among the 75,433 APIs under analysis,\
    \ 20% of APIs have changed their exception-throwing behavior at least once after\
    \ API introduction. These APIs involve a total of more than 7k independent exception\
    \ changes, which shows that the exception-aware lifecycle modeling can describe\
    \ the evolution process of APIs more accurately.\n\n**Key words** static analysis;\
    \ program evolution; Java exception summary; API lifecycle\n\n# 1. 引言\n\n具有复杂功能的大型软件系统往往由多个模\
    \ 块组成,其实现依赖于底层编程框架和种类繁多的 第三方库。这些框架/库代码通过持续的版本更新修 改代码缺陷或完善代码功能,其演化过程独立于调 用它们的上层软件系统。在上层应用的开发过程\
    \ 中,软件供应链安全分析中的依赖安全检测工具会 帮助开发者识别项目依赖中的漏洞,并提醒应用开 发者尽快更新版本以保障代码质量安全。例如,当 GitHub\
    \ 检测到项目代码中使用易受攻击的依赖项 或恶意软件时,会向开发者发送 Dependabot 警报 [\\[1\\]](#page-16-0)。如果上层应用开发者在不熟悉框架/库代码\
    \ API 演化过程的情况下变更版本,可能会引入其他问 题,如使用了过时/被移除的 API 或未及时捕获处理 新抛出的异常,进而导致程序错误或引发兼容性问\
    \ 题等。\n\n框架/库代码中 API 的变更导致用户在迁移上 层软件系统时花费较多精力,间接增加了使用特定 框架/库的开发难度[\\[2\\]\\[3\\\
    ]](#page-16-1)[\\[4\\]](#page-16-2)。为保障这些依赖于底 层框架/库函数的软件系统质量,一种解决方案是预 先分析不同框架/库代码版本下的\
    \ API 调用规约,并 检测调用代码的正确性。针对这一问题,现有工作 提出了 API 级别的生命周期模型[\\[18\\]](#page-16-3),并通过分析\
    \ 框架更新时提供的 API 变更文本文件[\\[5\\]](#page-16-4)或通过轻 量级框架代码分析扫描其 API 列表[\\[6\\]\\[7\\\
    ]](#page-16-5)等方法来 构建 API 级别的生命周期模型。虽然这些工作考虑 了 API 的存在性变更,但忽略了 API 中关键代码语 义变更的影响。在某些情况下,开发者没有删除或\
    \ 废弃特定的 API,而是更改其代码语义。对于框架 /库的使用人员,除了 API 的存在性变更外,语义信 息变更也是 API 调用时以及 API 调用合规性检测中\
    \ 需要考虑的一项关键信息。\n\n基于API完整代码的差异分析可以准确反映代 码的变更情况,但完整的代码变更结果数据量庞大 且复杂,对于上层应用的分析和测试,并非所有变\
    \ 更都会对用户的使用产生影响。我们发现,在 API 演化过程中,同一 API 的基本功能往往保持一致, 即代码升级不应影响现有 API 的基本功能实现,这\
    \ 类变化应是对用户透明的,但 API 对外部输入数据 的校验过程和校验结果的反馈方式是可变的,它们 会影响 API 的上层调用。在 Java 代码中,当\
    \ API 接 收到非预期的外部输入时,通常会抛出异常来应对 这一非预期行为,而上层用户应该及时捕获并处理\n\n这些异常行为[\\[41\\]](#page-17-0)。Mostafa\
    \ 等人对 Java 库代码兼 容性错误的统计[\\[55\\]](#page-17-1)表明,由异常导致的兼容性问 题占比超过 1/3(105/296)。葛等人在文献[\\\
    [58\\]](#page-17-2)中指 出,框架/库代码中存在的错误或漏洞可能会被攻击 者利用, 从而损害软件供应链安全,这些错误或漏 洞往往与框架/库代码中存在的异常有关。由此可\
    \ 见,API 异常抛出行为的变化会对用户调用方式产 生重要影响,在软件快速演化背景下,其变更行为 对于软件的健壮性与安全性息息相关。\n\n| 1. public\
    \ int getCount() {                                 |  |  |  |  |\n|------------------------------------------------------------|--|--|--|--|\n\
    | 2. -<br>return (int) getByteCount();                       |  |  |  |  |\n|\
    \ 3. +<br>long result = getByteCount();                      |  |  |  |  |\n|\
    \ 4. +<br>if (result > Integer.MAX_VALUE) {                  |  |  |  |  |\n|\
    \ 5. +<br>throw new ArithmeticException(\"The byte count      |  |  |  |  |\n\
    | \" + result + \" is too large to be converted to an int\"); } |  |  |  |  |\n\
    | 6. +<br>return (int) result;<br>//修改返回空值为抛出异常              |  |  |  |  |\n|\
    \ 7. }                                                       |  |  |  |  |\n|\
    \ (a)新增异常实例                                                  |  |  |  |  |\n\n\
    | 1. public static void moveFile(File srcFile, File destFile) |  |  |\n|-------------------------------------------------------------|--|--|\n\
    | throws IOException {                                        |  |  |\n| 2.<br>if\
    \ (destFile.exists())                                |  |  |\n| 3. -<br>throw\
    \ new IOException(\"Destination '\" + destFile +  |  |  |\n| \"' already exists\"\
    );                                        |  |  |\n| 8. +<br>throw new FileExistsException(\"\
    Destination '\" +     |  |  |\n| destFile + \"' already exists\"); //修改异常类型  \
    \                  |  |  |\n| 4. }                                           \
    \             |  |  |\n| (b)修改抛出异常类型                                         \
    \        |  |  |\n\n| 1. public void forceDelete(File file) throws IOException\
    \ { |  |  |  |\n|------------------------------------------------------------|--|--|--|\n\
    | 2. +<br>boolean filePresent = file.exists();               |  |  |  |\n| 3.\
    \ +<br>if (!file.delete()) { //增加文件删除判断条件                 |  |  |  |\n| 4. +<br>if\
    \ (!filePresent) {                                |  |  |  |\n| 5. -<br>if (!file.exists())\
    \ {                              |  |  |  |\n| throw new FileNotFoundException(\"\
    File does<br>6.           |  |  |  |\n| not exist: \" + file); }             \
    \                       |  |  |  |\n| 7. +<br>}                              \
    \                    |  |  |  |\n| 8. }                                      \
    \                 |  |  |  |\n| (c)修改异常抛出条件                                  \
    \              |  |  |  |\n\n#### 图 **1** 不同版本 **API** 中异常相关代码变更示例\n\n图 1 给出了真实项目中的异常相关变更代码片\
    \ 段示例,其变更形式多种多样,包括新增或删除异 常实例[\\[12\\]\\[13\\]](#page-16-6)、修改异常实例的类型、描述或抛出 条件[\\\
    [14\\]](#page-16-7) [\\[15\\]](#page-16-8) [\\[16\\]](#page-16-9)等。在代码演化过程中,同一异常\
    \ 可能发生多次不同类型的变更[\\[14\\]\\[17\\]](#page-16-7)(参见图 3)。 这些变更可能对 API 的外部使用产生影响,即改变\n\
    \nAPI 使用规约。因此,为了正确理解框架 API 的生 命周期行为,需在考虑 API 增删变化之外,结合 API 中异常的变更情况,为其构造异常信息敏感的生命\
    \ 周期模型。该模型的构建依赖于对异常摘要信息的 准确提取与匹配分析。其中的关键挑战是:1)应提 取哪些关键信息表征API中的异常实例并尽量减少 数据中影响匹配的噪音;2)当一个方法中存在多个\
    \ 同类型的异常实例时,如何准确地在多个版本中匹 配到同一实例并识别变更内容,从而准确构建 API 及其异常集合的生命周期。\n\n针对这些挑战,本文首先设计了一种面向演化\
    \ 分析的异常摘要形式,包括异常类型、描述文本、 前断言三类核心信息。为了减少匹配时的数据噪 音,本文在异常抛出条件分析中,通过控制依赖约 束分析去除了与异常抛出无关的条件约束;通过数\
    \ 据流分析将所有中间局部变量约束转换为外部输 入变量约束;通过跨过程异常传递分析避免函数级 代码重构导致的函数内异常变更。此外,为准确识 别不同版本代码中的异常实例,本文共设计了基于\
    \ 类型、描述、前断言、关键前断言四类信息的过滤 器,对于无法完全匹配的异常实例,采用多轮流式 匹配策略识别变更实例、分析变更过程,最终生成 涵盖七类变更行为的异常敏感\
    \ API 生命周期报告。\n\n基于该方法,本文实现了异常信息敏感的 Java API 分析工具 JavaExP (Java Exception-aware\
    \ API analyzer[\\)\\[46\\]](#page-17-3)。其框架图如图 2 所示,对于任意两个\n\n(或多个)版本的 Java 框架/库的\
    \ jar 包/class 文件, JavaExP 先通过异常摘要提取模块获取每个版本的 异常摘要报告。其次,将这些摘要被输入到生命周 期构造模块,对不同版本中\
    \ API 异常语义摘要执行 自适应匹配和异常变更分析。分析后,可以获取 API 的新增、删除情况和 API 中异常的新增、删除和修 改情况,从而得到目标版本区间上异常信息敏感的\
    \ API 生命周期模型。\n\n![](_page_3_Figure_5.jpeg)\n\n#### 图 **2 JavaExP** 方法框架图\n\n\
    多组对比实验验证了本文方法的有效性。对于 异常摘要提取模块,与最新的 Java 异常分析工具 WI[T \\[26\\]](#page-16-10)相比,JavaExP\
    \ 使用更短的时间 (-87%) 提 取到了大量 WIT 无法分析的异常信息,并显著提高 F1 分数(相对提升 60%)。应用 JavaExP 分析了六 个项目的\
    \ 60 个版本,并为其生成 API 生命周期报 告,演化分析的准确率达到 98%;找到了 API 中大 量的异常变更行为,在 75,433 个 API 中,在异常敏\
    \ 感的 API 生命周期模型中,约 20%的 API 在首次引 入后,异常信息发生过至少一次变动;与异常不敏 感的 API 生命周期相比,异常敏感的 API\
    \ 发生变动 的比例提高了 18%。本文的工具和实验数据均已开 源到 GitHub [\\[46\\]](#page-17-3)。\n\n本文的章节结构设计如下:第\
    \ 1 章概述异常信 息敏感的 API 生命周期模型构造方法;第 2 章介 绍本文所需的基础知识和概念定义;第 3 章介绍面 向 Java 程序的异常摘要提取方法;第\
    \ 4 章介绍基于 异常摘要分析 API 生命周期构造方法;第 5 章给出 实验设计和结果分析,评估所提方法的有效性;第 6 章介绍本文的相关工作;最后一章为总结与展望。\n\
    \n# 2. 基础知识与示例应用\n\n### **2.1. Java**异常\n\n异常是在程序执行过程中出现的问题或错误 的一种表示。在 Java 语言中,异常被定义为派生\
    \ 自 java.lang.Throwable 类的对象,在 Java 类库、用 户方法及运行时故障中都可能会抛出异常。Java 提 供了很多内置的异常类\
    \ [\\[42\\]](#page-17-4),如 IOException、 IllegalArgumentException 等,此外,开发人员还可 以自定义异常类以便更好地适应特定需求。一部分\
    \ 异常会被 Java 虚拟机自动的抛出,在运行时不需要 显式处理,但它们可能会导致程序的异常终止,这 类异常也被称为非受检异常或运行时异常;还有一 类异常需在编译时显式地处理,否则会导致编译错\
    \ 误,它们又叫受检异常或编译时异常[\\[43\\]](#page-17-5)。在方法内 部检测到不符合预期条件或无法处理的情况时,开 发者可以通过 throw\
    \ 语句声明主动抛出异常提供有 关特定问题或错误的信息,并将控制权交给调用者 或上层代码来处理(try-catch 行为)。对于框架/库 API 的调用者,API\
    \ 中抛出的异常类型、抛出条件 等与API调用过程的中数据输入规约和异常捕获方 式息息相关。因此,这类变更应被及时传递给开发 人员。\n\n### **2.2.\
    \ API** 演化和生命周期\n\n 应用程序接口(API)是框架/库代码对外提供服 务的调用接口。随着代码功能的演化升级,旧版本 API 在新版中可能被删除,新版代码中也会增加\
    \ API 以提供更丰富的功能。除了 API 的增加与删除, API 中代码的实现方式、数据校验方式等均可能发 生变化。API 的生命周期指 API 在不同的框架/库版\
    \ 本中的存在范围,如 Li 等人提取了安卓框架代码中 API 的生命周期模型[\\[5\\]](#page-16-4),虽然 API 的变动较为频 繁,但在\
    \ API 持续存在的生命周期中,其中包含的 异常实例可能是持续演化的,这类变化在异常不敏 感的 API 级别生命周期模型中无法体现。\n\n### **2.3.**\
    \ 概念定义\n\n针对 API、异常及生命周期等概念,我们分别 给出如下定义。\n\n定义 **1**(应用程序接口方法): API = (id, version,\
    \ class, method, S\\_Exp) 为一个应用程序接口方法,它 包含 API 的签名、版本号、所在的类名称、方法名 称以及包含的异常集合 S\\\
    _Exp。\n\n定义 **2**(异常摘要):Summay(exp) = (API.id, type, message, condition, precondition),\
    \ exp∈API.S\\_Exp 为一个异常摘要,它包含异常所在的 API、异常的 类型、异常抛出时的描述文本信息、异常抛出语句 的控制依赖条件以及与异常抛出相关的外部参数\
    \ 前断言。\n\n定义 **3**(**API/**异常存在性生命周期)API 的存在性 生命周期为该 API 从引入到删除的版本区间的并 集。对于其中包含的异常实例\
    \ Exp∈S\\_Exp,异常的 存在性生命周期为该异常在该API中从引入到删除 的版本区间的并集。\n\n定义 **4**(异常敏感的 **API**\
    \ 生命周期)API 中所有异 常对象 exp∈API.S\\_Exp 摘要信息 Summay(exp)的 集合为 S\\_Summay(S\\_Exp)\
    \ ,在不同的版本中,当 且仅当两个异常摘要信息集合中任何异常摘要信 息均相同时,可认为异常摘要信息的取值在不同版 本上保持不变。对于异常摘要信息集合的特定取\
    \ 值,如果其出现的最早版本为 Vi,最末版本为 V<sup>j</sup> (i<=j),则其生命周期为[Vi, Vj]。对于异常敏感的 API 生命周期,它给出了摘要信息集合\
    \ S\\_Summay 在目标版本中所有不同取值到其生命周期的映射 关系。导致 API 中异常摘要信息取值变更的操作被 称为异常敏感的 API 操作,包括:API\
    \ 新增、API 删除、API 修改-异常新增、API 修改-异常删除、API 修改-异常类型变更、API 修改-异常描述变更和 API 修改-异常断言变更七类。\n\
    \n### **2.4.** 示例代码\n\n图 3 为 Apache commons-io [\\[14\\]\\[17\\]](#page-16-7)项目中\
    \ API moveFile()的部分代码,给出了其异常 e 在不同版本 中的变更情况,+表示新增代码,-表示删除代码。 该异常为针对 API 第 2 个参数变量\
    \ destFile 的文件 存在性校验。在版本号 1.4 的代码中,类型为 IOException 的异常实例 e 被引入,而在 2.0 版本 中,异常实例\
    \ e 的类型被更改为 FileExistsException 类。随后,在版本 2.7 中,该方法被重构,但实际 异常 e 的抛出条件未发生变化。在版本\
    \ 2.9 中,该 方法被再次重构,异常 e 的抛出位置发生变化,其 描述文本和异常前断言也发生改变。因此,对于图 5 中的异常 e,其演化过程为一次新增,一次异常类\
    \ 型更改,一次异常描述文本和前断言更改,其中经 历了两次方法重构。在这种情况下,上层开发者很 难快速评估不同版本中API包含的异常是否变动以 及变动的过程。为提取目标\
    \ API 的生命周期,首先 需准确获取每一个异常实例的关键信息,判定不同 版本中的多个异常信息是否指向同一个异常实例, 如是同一实例,则记录其变更过程,在此基础上,\
    \ 生成完整的 API 生命周期报告。\n\n```\n1. public static void moveFile(File srcFile, File\
    \ destFile) ...{\n2. if (srcFile == null) {\n3. throw new NullPointerException(\"\
    Source must not \nbe null\");\n4. if (destFile == null) {\n5. throw new NullPointerException(\"\
    Destination \nmust not be null\");\n6. if (!srcFile.exists()) {\n7. throw new\
    \ FileNotFoundException(\"Source '\" + \nsrcFile + \"' does not exist\");\n8.\
    \ if (srcFile.isDirectory()) {\n9. throw new IOException(\"Source '\" + srcFile\
    \ + \"' is \na directory\");\n10. if (destFile.exists()) \n11. - throw new IOException(\"\
    Destination '\" + destFile \n+ \"' already exists\"); //在 1.4 版本引入\n12. + throw\
    \ new FileExistsException(\"Destination '\" + \ndestFile + \"' already exists\"\
    ); //在 2.0 版本变更类型\n13. }\n                (a) 版本变更 V1.4 V2.0\n```\n\n| 1. public\
    \ static void moveFile(File srcFile, File destFile) {   |\n|-----------------------------------------------------------------|\n\
    | 2. +<br>validateMoveParameters(srcFile, destFile);// //throw    |\n| other three\
    \ exceptions //在 2.7 版本移动其他异常的位置                      |\n| 3.<br>if (srcFile.isDirectory())\
    \ {                              |\n| 4.<br>throw new IOException(\"Source '\"\
    \ + srcFile + \"' is        |\n| a directory\");                             \
    \                     |\n| 5.<br>if (destFile.exists())                      \
    \              |\n| 6.<br>throw new FileExistsException(\"Destination '\" +  \
    \         |\n| destFile + \"' already exists\");                             \
    \    |\n| 7. }                                                            |\n\
    | (b)版本变更 V2.0  V2.7                                             |\n| 1. public\
    \ static void moveFile(File srcFile, File destFile) {   |\n| 2. -<br>validateMoveParameters(srcFile,\
    \ destFile);// //throw    |\n| other two exceptions                          \
    \                  |\n| 3. -<br>if (srcFile.isDirectory()) {                 \
    \           |\n| 4. -<br>throw new IOException(\"Source '\" + srcFile + \"'  \
    \       |\n| is a directory\");                                              \
    \ |\n| 5. -<br>if (destFile.exists())                                  |\n| 6.\
    \ -<br>throw new FileExistsException(\"Destination '\" +         |\n| destFile\
    \ + \"' already exists\"); //在 2.9 版本整体重构                  |\n| 7. + moveFile(srcFile,\
    \ destFile,                                |\n| StandardCopyOption.COPY_ ATTRIBUTES);\
    \                           |\n| 8. }                                        \
    \                    |\n| 9.                                                 \
    \             |\n| 10. + public static void moveFile(File srcFile, File destFile,\
    \  |\n| CopyOption copyOptions) throws IOException {                    |\n| 11.\
    \ +<br>validateMoveParameters(srcFile, destFile); //throw     |\n| other three\
    \ exceptions                                          |\n| 12. +<br>requireFile(srcFile,\
    \ \"srcFile\"); //throw other two     |\n| exceptions                        \
    \                              |\n| 13. +<br>requireAbsent(destFile, null);  \
    \                       |\n| 14. + }                                         \
    \                |\n| 15.                                                    \
    \         |\n| 16. + private static File requireFile(File file, String name) {\
    \ |\n| 17. +<br>Objects.requireNonNull(file, name);                    |\n| 18.\
    \ +<br>if (!file.isFile())                                    |\n| 19. +<br>throw\
    \ new                                              |\n| IllegalArgumentException(\"\
    Parameter '\" + name + \"' is not       |\n| a file: \" + file);             \
    \                                 |\n| 20. +<br>return file;                 \
    \                          |\n| 21. +<br>}                                   \
    \                   |\n| 22.                                                 \
    \            |\n| 23. + private static void requireAbsent(File file, String  \
    \     |\n| name) throws FileExistsException {                              |\n\
    \n24. + if (file.exists())\n\n25. + throw new FileExistsException(String.format\
    \ (\"File element in parameter '%s' already exists: '%s'\", name, file));\n\n\
    26. +}\n\n#### (**c**)版本变更 **V2.7 V2.9**\n\n#### 图 **3 Apache Commons-IO** 异常变更示例代码\n\
    \n# 3. Java 程序异常摘要提取方法\n\n本章介绍异常摘要提取模块的主要方法。\n\n## **3.1.** 异常摘要提取模块概览\n\nJavaExP\
    \ 的异常摘要提取模块主要包含基本信 息分析和异常前断言分析两个部分。如图 4 所示, 基本信息分析部分以 jar 包或 class 文件为输入,负 责构建程序的控制流图、函数调用图等数据结构,\
    \ 并提取每个方法中抛出异常的基本信息,获得方法 到异常的映射。异常前断言分析部分首先通过构建 方法的控制依赖图,去除判定结果与异常抛出行为 无关的非控制依赖条件,提高了断言分析结果的精\
    \ 准性。获取依赖条件后,再通过参数约束推断将异 常触发条件关联到外部输入参数,获取单个方法的 前断言。此外,通过函数调用关系和参数传递关系 追踪进一步构造了跨过程的异常抛出前断言。最\
    \ 后,形成异常信息摘要报告。\n\n![](_page_5_Figure_11.jpeg)\n\n### 图 4 Java 程序异常摘要提取模块流程图\n\
    \n# **3.2.** 基本信息分析\n\n基本信息提取部分基于静态分析框架 Soot [\\[44\\]](#page-17-6) 对输入代码进行预处理,为每个程序方法构建控制\
    \ 流图(Control Flow Graph,CFG),并生成全局的 函数调用图(Call Graph,CG)。接着,通过遍历 所有的语句,可以定位到显式抛出异常的\
    \ throw() 语句(称为异常抛出点),分析在每个异常抛出点 抛出的异常类型和描述文本等异常基本信息。对于 异常类型,我们分析异常变量的定义语句,并分析\
    \ 对应实例的类型;对于描述分析,我们从异常抛出\n\n点的描述文本变量反向追踪,通过字符串函数建模 还原完整的文本字符串,考虑到部分变量取值无法 直接获取,这里将异常拼接后的文本信息转换为正\
    \ 则表达式形式。\n\n获取基本信息后,JavaExP 记录方法名称和方 法中显示抛出异常的映射关系,并生成方法-异常映 射表,其中一个方法可以对应多个异常。对于图\
    \ 3(c) 的示例应用,可以得到一条映射边{ requireAbsent () FileExistsException @loc25}。由于方法 moveFile\
    \ 的参数会影响 requireAbsent 的异常抛出,因此对 moveFile 也应生成异常前断言。在后续分析中,该 断言可通过为requireAbsent方法构建异常行为摘要\
    \ 和追踪跨过程参数关系得到。\n\n# **3.3.** 前断言分析\n\n除了基本信息,异常摘要中的另一类重要元素 是前断言信息。前断言分析包括控制依赖条件分\
    \ 析、外部输入参数约束推断和跨过程参数约束推断 三个部分。\n\n### **3.3.1.** 控制依赖条件分析\n\n为了生成异常的前断言,首先需要准确提取异\
    \ 常的控制依赖条件。控制依赖条件一定在异常触发 的前置路径上,即在异常被触发时经过的程序路径 上。该路径可以从异常抛出点通过后向路径遍历得 到,而该路径上的全部条件被称为为异常触发的前\
    \ 置路径条件。\n\n定义 **5**(异常前置路径):PrePath (m,e) = (S0,…,Si, Si+1,..,Se) 为异常触发的一条前置路径,其\
    \ 中 S<sup>0</sup> 为方法 m 的入口语句,S<sup>e</sup> 为异常 e 的抛出语 句,程序语句 Si+1 是语句 Si的一个后继节点。异常\
    \ e 对应的多个异常前置路径形成了异常前置路径集 合 PrePathSet (m, e)。\n\n定义 **6**(异常前置路径条件): CondInPath\
    \ (m, e, prePath) 为异常前置路径上的条件语句的集合, 每个元素 cond ∈ CondInPath均是一个条件语句。\n\n对于图 3(a)中的\
    \ moveFile () 方法,第 2-9 行分 别抛出四个异常,如果他们的异常条件被满足,第 12 行异常 e 不会被抛出,因此,异常 e 依赖于这些\
    \ 控制条件。但如果将 2-9 行中的 throw 语句更改为 非终止语句,如输出、日志、数据处理等语句,则 其所属的条件将与第 12 行的异常无关。所有与异\
    \ 常抛出无关的路径前置条件语句无需被作为最终 异常断言的一部分。\n\n定义 **7**(异常控制依赖条件):ControlCond InPath (m,\
    \ e, prePath) 为异常前置路径上控制依赖 条 件 的 集 合 , 其 中 每 个 元 素 controlCond ∈ ControlCondInPath\
    \ 是一条和异常 e 之间存在控制依 赖关系的条件语句。即对于条件 controlCond 的多 个后继节点,存在至少一个后继节点不存在于异常 e 的任何异常前置路径中。\n\
    \n定义 **8**(异常控制依赖约束):ControlConstraint InPath (m, e, prePath)为异常前置路径上的异常控制 依 赖\
    \ 约 束 集 合 , 每 个 异 常 控 制 依 赖 约 束 (controlCond, isCondTrue) ∈ ControlConstraintInPath包\
    \ 括一个控制依赖条件语句及其条件判定结果。\n\n算法 1(extractConstraint)给出了异常控制依赖 条件的提取算法。第 2 行首先获取方法\
    \ m 的控制流 图 cfg,其中节点代表语句,边代表语句之间的控制 流向关系。第 3 行提取控制依赖图 cdg [\\[32\\]\\[33\\]](#page-16-11),其\
    \ 中节点代表语句,边代表语句之间的控制依赖关 系。通过搜索 cdg,可以得到异常抛出语句 Se对应 的异常控制依赖约束集合 controlConstraintSet。接着,\
    \ 第 5 行通过在 cfg 上后向路径遍历得到异常前置路 径集合 prePathSet。对于 prePathSet 中的每条异常前 置路径 prePath,第\
    \ 7-13 行负责构建仅包含异常控 制依赖条件切片的集合 controlConstraintInPath,并 在第 14 行将其加入输出集合 controlConstraintSet\
    \ 中。在这一过程中,第 8 行遍历 prePath 中的每一 个节点,如果一个节点是条件语句,且存在于 Se的 控制依赖节点集合 controlNodeSet\
    \ 中,将记录该节 点 node(第 9 行)。第 10 行分析 node 在 prePath 上的后继节点 node.succ,判定当前路径上 if 条件的\
    \ 判定结果为 true 或为 false(在字节码中,if 语句会 指明当 if 条件为真时的 goto 语句的位置,因此,可 通过下一语句 succ 是否为\
    \ goto 的目标语句判定条 件是否取值为真)。随后在第 11 行,该节点 node 与条件判定结果 isCondTrue 形成的约束条件 constraint\
    \ 会被加入当前路径的异常控制依赖约束 集合 controlConstraintInPath 中。最后,第 16 行将 返 回 方 法 m 的 异 常 控\
    \ 制 依 赖 约 束 集 合 controlConstraintSet,其中每个元素为一条路径上的 一组控制依赖约束。\n\n| 算法<br>1 | 控制依赖条件分析<br>extractConstraint\
    \                                          |\n|---------|------------------------------------------------------------------------|\n\
    | 输入:方法   | m, 异常<br>e(异常抛出语句为<br>Se)                                        \
    \      |\n|         | 输出:异常控制依赖约束集合<br>controlConstraintSet                  \
    \                |\n|         | 1 Set <set<constraint>&gt; controlConstraintSet\
    \ = new</set<constraint> |\n\nHashSet (); //初始化\n\n- 2 Graph cfg = constructCFG\
    \ (m); //构建控制流图 cfg\n- 3 Graph cdg = constructCDG (cfg, m); //构建控制依赖图 cdg\n- 4\
    \ Set <Node> controlNodeSet= getControlNodesOfExp (cdg, Se); //在 cdg 中找到 S<sup>e</sup>\
    \ 的控制依赖节点\n- 5 Set <Path> prePathSet = backTraverseFromExp (cfg, Se); //从 S<sup>e</sup>\
    \ 后向路径遍历得到异常前置路径\n- 6 for (Path prePath : prePathSet){\n- 7 Set <Constraint> controlConstraintInPath=\
    \ new HashSet ();\n- 8 for (node : prePath) {·\n- 9 if (node.isCondition () and\
    \ controlNodeSet.contains (node)) {\n- 10 Boolean isCondTrue =getCondJudgeRes\
    \ (node, node.succ); //获取分支条件的判定结果\n- 11 controlConstraintInPath.add (new Constraint\
    \ (node, isCondTrue)); //新增控制依赖条件\n- 12 }\n- 13 }\n- 14 controlConstraintSet.add\
    \ (controlConstraintInPath) //增加一条路径上的一组控制依赖条件\n- 15 }\n\n16 Return controlConstraintSet\n\
    \n例如,对于图 3(a)中的 moveFile() 方法,第 2- 11 行的 5 个控制条件均存在一个后继节点不在任 何一条异常前置路径中,因此异常控制依赖条件为\
    \ ControlCondInPath ={2,4,6,8,10}。接着,通过分析异 常控制依赖条件在异常前置路径中的后继语句,即 条件为真或为假时的后继语句在异常前置路径中,\
    \ 可以得到每个异常控制依赖条件取值结果,即 controlConstraintInPath = {(srcFile == null, false), (destFile\
    \ == null, false), (srcFile.exists(), true), (srcFile.isDirectory(), false), (destFile.exists(),\
    \ true)}。 这里仅为方便展示,在实际的字节码分析过程中, 可被获取的是中间变量约束,如(\\$z0==0, false)。\n\n# **3.3.2.**\
    \ 外部输入参数约束推断\n\n经过上一节的分析,可以获取异常的控制依赖 约束。但字节码中没有变量名称信息,仅有按序编 号的内部变量,如 r0,z1,而这些变量在不同版本\
    \ 中不存在关联关系,难以被直接用于匹配和比较。 因此,应将约束的主体转换为语义固定的对象,如 API 的参数,提取异常前断言时通过数据流追踪获 取的内部变量约束归约为参数相关约束,从而准确\
    \ 分析异常前断言的变更情况。\n\n算法 2(refineAnalysis)对于异常控制依赖条件 集合中每条路径上的每个 控制依赖约束条件 controlConstraint\
    \ 进行分析,通过参数推断得到仅 与外部输入参数相关的 refinedConstraint。算法第 1 行提取语句中的所有变量并将它们放入集合 dataRelatedVars。第\
    \ 2-4 行中,对于变量集合中非输 入参数相关的内部变量,通过数据流分析获取其最 近的变量赋值语句,其中方法 getDefUse 通过数据 流分析获取方法\
    \ m 的定义-使用链 [\\[45\\]](#page-17-7)。第 5 行根 据数据分析结果更改原约束条件 controlConstraint, 即依次使用内部变量的赋值结果替换该变量,并将\
    \ 更新后的约束条件递归地传入 refineAnalysis 方法 继续分析,直至 refinedConstraint 中不再包含内部 变量时,迭代终止。这里,中间码预先被转换为\
    \ SSA 格式。此外,JavaExP 还通过启发式策略调整优化 了输出形式,增强断言的用户可读性。该算法最后 返回推断后的约束条件 refinedConstraint。\n\
    \n| 算法<br>参数约束推断分析<br>2<br>refineAnalysis                  |\n|--------------------------------------------------------|\n\
    | 输入:方法 m, 异常 e(异常抛出语句为 Se),异常                           |\n| 控制依赖条件 controlConstraint\
    \                               |\n| 输出:推断后的约束条件 refinedConstraint           \
    \               |\n| 1 Set <value> dataRelatedVars= getVarFromStmts</value> |\n\
    | (constraint.getStmt ()); //提取语句中的变量                    |\n|                \
    \                                        |\n\n- 2 For (Value: value dataRelatedVars){\n\
    - 3 if(isOutsideValue(value)) continue;\n- 4 Stmt assignStmt= getAssignStmtofValue\
    \ (getDefUse(m), value); //后向数据流分析获取最近 的变量赋值语句\n- 5 refinedConstraint = replaceValueInConstraint\
    \ (constraint.getStmt (), value, assignStmt. getRightValue()) //将约束语句中的 value\
    \ 替换为 value 的赋值内容\n- 6 refineAnalysis(m, e, refinedConstraint)\n- 7 }\n- 8 Return\
    \ refinedConstraint\n\n据流追踪,得到该方法内的控制依赖条件为 (\\$z0==0, false)}。表 1 (a) 中给出了通过数据流分析\
    \ 反向推断外部数据约束 parameter0.exists()的过程。\n\n# 表 **1(a)** 过程内追踪约束条件 **(requireAbsent)**\n\
    \n| 控制依赖      | 数据流追踪后推断的约束条件                              |  |  |\n|-----------|--------------------------------------------|--|--|\n\
    |           | \\$z0 is true + \\$z0 is-invoke r0.exists()  |  |  |\n| (\\$z0==0,\
    \ |  r0.exists() is true                      |  |  |\n| false)    | r0.exists()\
    \ is true + r0 denote parameter0 |  |  |\n|           |  parameter0.exists()\
    \ is true              |  |  |\n\n### **3.3.3.** 跨过程参数约束推断\n\n在 API 的演化过程中,异常的抛出位置可能发\
    \ 生移动,如将异常抛出语句移动到另一方法并调用 它[\\[17\\]](#page-16-12)。如采用过程间分析,这类代码重构会被识别 为异常的删除,从而引发\
    \ API 演化分析中的误报。 如图 3 对应的异常实例,在版本 1.4 中,异常抛出 代码仅在 moveFile()本身中出现,但在最新的 2.13 版本中,该异常需要至少联合分析六个函数的才能\
    \ 被准确获取。为了增加异常匹配分析的准确度, JavaExP 在为过程内所有异常实例构造摘要信息的 基础上,通过函数调用关系分析和参数映射关系分 析,生成跨过程的异常摘要信息。\n\
    \n具体的跨过程参数约束推断的过程为:首先构 造应用程序的函数调用图,并对函数调用关系进行 拓扑排序。再按照拓扑序的逆序自底向上的分析每 个方法,其中被调用的方法\
    \ callee 一定会比调用它 的方法 caller 更早被分析。当定位到当前方法 caller 中的一个调用语句 stmt 时,可得到被调用的方法 callee。如果被调用方法\
    \ callee 的参数与异常的抛出 有关,则会根据调用方法 caller 和被调用方法 callee 中参数位置的映射关系,更新从被调用方法 callee\
    \ 中获取的参数相关约束 cons1。此外,还应提取 caller 方法中调用 callee 语句前的程序路径上需要满足的 参数相关约束,包含路径上的控制依赖约束\
    \ cons2, 和路径上被调用函数中的其他异常抛出约束的取 反 cons3。约束 cons1、cons2、cons<sup>3</sup> 均更新到调用方\
    \ 法 caller 的参数约束中后,可得到关于方法 caller 的 异常前断言。对于函数内直接抛出的异常,类似的, 也应使用异常抛出前置路径的函数调用中使得异\
    \ 常不被抛出的条约束 cons<sup>3</sup> 更新其直接约束。按照 拓扑逆序分析,从而可以依次更新每个方法的前断 言信息,由于底层的约束会向上传递更新,每个方\
    \ 法仅需被分析一次。\n\n对于图 3(c)中的 moveFile 方法,其第 1 个参数\n\n对应方法 requireAbsent 中的第 0 个参数,根据这一\
    \ 参数映射关系可以更新 requireAbsent 中的前断言 信息得到 moveFile 的约束。此外,在 moveFile 中 调用 requireAbsent\
    \ 方法时,执行到该方法调用点时 应满足来自前置方法 validateMoveParameters 和 requireFile 中的其他约束,最终得到由 5\
    \ 个约束组 成的完整前置条件。结果见表 1(b)。\n\n| 表<br>跨过程追踪约束条件<br>1 (b)<br>(moveFile) |      \
    \                                                                 |  |  |  | \
    \ |\n|---------------------------------------|-----------------------------------------------------------------------|--|--|--|--|\n\
    | 控制依赖                                  | 数据流追踪后推断的约束条件                      \
    \                                   |  |  |  |  |\n|                         \
    \              | requireAbsent@parameter0.exists() is true<br>+ requireAbsent(r1,null)\
    \ |  |  |  |  |\n|                                       |  r1.exists() is true\
    \                                                 |  |  |  |  |\n| constraint\
    \ in                         | r1.exists() is true + r1 denote parameter1    \
    \                        |  |  |  |  |\n| requireAbsent                      \
    \   |  parameter1.exists() is true                                         |\
    \  |  |  |  |\n| + constraints                         | merge constraints from\
    \ related methods                                |  |  |  |  |\n| in moveFile\
    \                           | parameter0 is not null + parameterl is not     \
    \                       |  |  |  |  |\n|                                     \
    \  | null + parameter0.exists() is true +                                  | \
    \ |  |  |  |\n|                                       | parameter0. isFile() is\
    \ true +                                        |  |  |  |  |\n|             \
    \                          | parameterl.exists() is true                     \
    \                      |  |  |  |  |\n\n# 4. 基于异常提取的 API 生命周期构造\n\n本章介绍 API 生命周期构造模块的主要方法。\n\
    \n# **4.1. API**生命周期构造模块概览\n\nJavaExP 的生命周期构造模块主要包含 API 匹 配与变更分析、生命周期模型构造两个部分。如图\
    \ 5 所示,异常匹配与变更分析部分以异常摘要文件 为输入,先采用完全匹配策略获取 API 异常实例的 匹配关系,再通过自适应匹配策略识别其他异常实 例的映射和局部变更情况,生成异常敏感的\
    \ API 变 更报告;生命周期模型构造部分则以多个版本的 API 变更分析报告为输入,分析同一 API 方法或同 一异常实例在不同版本中的变更过程,最后生成相\
    \ 应的生命周期模型。\n\n![](_page_8_Figure_14.jpeg)\n\n图 5 API 生命周期构造模块流程图\n\n# **4.2.**\
    \ 异常信息敏感的**API**匹配与变更分析\n\n基于提取的异常摘要信息,接下来,我们采用 完全匹配和自适应匹配相结合的异常匹配方式对 不同版本中的异常进行匹配。在异常匹配过程,API\
    \ 签名、异常类型、描述和断言信息是四个关键信息, 这里仅考虑签名相同的 API 中异常的匹配,如果 API 签名变更,则认为发生方法级改变。如表 2 所\
    \ 示,异常类型、描述和断言信息的不同组合共有 8 种。如果两个异常符合规则 R1,三个信息可完全匹 配,则表明该异常未发生改变。如不能完全匹配, 则需根据规则\
    \ R2-R8 进行自适应匹配。在这些规则 中,我们将根据对符合该类别特征代码实例的经验 分析和意图理解,判定不同变更特征下的异常代码 是否可匹配。对于 R2-R4,仅有单一信息变更,这\
    \ 类变化更有可能是同一异常的正常演化导致的,而 非两个高度相似的异常。而如果多个信息变更,其 匹配情况将相对复杂,如果两个异常摘要中有至少 两类信息不一致(R5-R8),通常可认定两个异常指\
    \ 向不同的实例。但考虑到异常类型这一信息指向性 较为稳定,在代码重构中有可能出现类型不变但是 异常描述和断言发生改变的情况,因此规则 R5 下 的匹配结果将视情况而定,具体参见以下异常匹配\
    \ 的详细流程。\n\n|    | API | 异常摘要 |             |    |         |  |\n|----|-----|------|-------------|----|---------|--|\n\
    | 规则 | 签名  | 类型   | 描述          | 断言 | 匹配结果    |  |\n| R1 | √   | √    | √   \
    \        | √  | 匹配-未变更  |  |\n| R2 | √   | X    | √           | √  | 匹配-类型变更 |\
    \  |\n| R3 | √   | √    | X           | √  | 匹配-描述变更 |  |\n| R4 | √   | √    |\
    \ √           | X  | 匹配-断言变更 |  |\n|    |     |      |             |    | 可能匹配-断言\
    \ |  |\n| R5 | √   |      | √<br>X<br>X |    | 和描述变更   |  |\n| R6 | √   | X  \
    \  | √           | x  | 不匹配     |  |\n| R7 | √   | X    | X           | √  | 不匹配\
    \     |  |\n| R8 | √   | X    | X           | X  | 不匹配     |  |\n\n表 **2** 异常实例匹配规则\n\
    \n- 1) 对于所有待分析 API,采用规则 R1 对 API 在相 邻版本中的异常进行完全匹配,如果匹配成功则 将匹配到的一对异常分别从各自版本下的匹配\
    \ 队列中移除。\n- 2) 采用异常类型变更 R2、异常描述变更 R3、和异 常断言变更 R4 规则对应的三个规则进行匹配。 这里将择依次使用各个信息过滤器,比较异常类\n\
    \n型、描述、前断言信息是否一致。过滤器接受一 组异常,根据过滤器类型返回过滤后的一组异 常。如旧版本中的异常 e<sup>1</sup> 经过第一个过滤器之\
    \ 后匹配到多个异常,那么所有被匹配的异常会被 作为候选对象传递给下一个过滤器;如 e<sup>1</sup> 未匹 配到任何异常,则将当前过滤器接受到的全部异\
    \ 常将被作为候选对象传递给下一个过滤器。如果 在过滤过程中,e<sup>1</sup> 在新版本中唯一匹配到异常 e2,则表明 e<sup>1</sup>\
    \ 和 e<sup>2</sup> 指向同一个异常,e<sup>1</sup> 和 e<sup>2</sup> 将 被记录并从各自的匹配队列中移除。\n\n\
    - 3) 经过步骤 2 后未找到唯一匹配的异常,将继续采 用规则 R5 进行匹配。满足这种情况的可匹配异 常往往是由于代码重构造成的,由于前置方法、 代码位置变更导致了异常前断言不完全相同,但\
    \ 这种情况下异常最近最直接的抛出条件通常不 会改变,因此,可提取距离异常抛出点最近的直 接条件对应的前断言(关键前断言)信息用于匹 配。对于异常 e1,如果能够唯一找到异常\
    \ e2,它 们的异常类型和异常关键前断言均相同,即使断 言和描述信息不同,e1和 e<sup>2</sup> 也会被匹配,记录后 从各自的匹配队列中移除。\n\
    - 4) 经过步骤 3 后,待匹配异常集合规模可能减小, 使得之前一对多匹配的异常变更为唯一匹配。因 此,可再次重复过程 2)和 3),直至匹配结果不 变,即达到不动点。\n\
    - 5) 如果多轮匹配结束后异常仍未被匹配,那么旧版 本中的未匹配异常将被标记为异常删除,新版本 中的未匹配异常将被标记为异常新增。\n\n在图 3 代码中,JavaExP\
    \ 根据规则 R2 匹配到 V1.4-V2.0 的变化,根据规则 R1 完全匹配了 V2.0- V2.7,最后根据规则 R5 匹配到 V2.7-V2.9 的变化,\
    \ 从而完整刻画了该 API 中异常的变化情况。\n\n### **4.3.** 异常敏感的**API**生命周期模型构造\n\n经过异常匹配与变更分析后,可得到\
    \ API 在相 邻版本中异常的变更结果。变更类型包含定义 **4** 中 声明的七类操作:API 新增、API 删除、异常新增、 异常删除、异常类型变更、异常描述变更和异常断\
    \ 言变更。为了生成完整的生命周期报告,我们从初 始版本开始,不断使用相邻版本的异常摘要构造更 完整的生命周期报告,直至最新版本。\n\n图 6 给出对图\
    \ 3 示例中异常实例的生命周期报 告。该报告包含异常所在的 API 的信息,如引入和 删除版本;包括异常的基本信息,如异常的引入、 删除版本;以及在不同版本区间上异常摘要信息的\n\
    \n变更情况,如异常类型变更。在这个实例中,异常 所在的 API moveFile(), 在 1.4 版本引入,在最新的 2.13 版本中依然存在。其中目标异常\
    \ e 共发生了三 次变更,分别是:2.0 版本变更了异常类型;2.9 版 本中更改了异常的描述文本;2.9 版本中更改了异 常前断言中涉及到的方法调用。值得注意的是,在\
    \ 2.7 版本中,虽然相关代码被开发者重构,但异常信 息分析表明,其异常抛出行为未发生任何改变,因 此,该版本未出现在变更报告中。\n\n![](_page_10_Figure_2.jpeg)\n\
    \n图 6 图 3 中 **API moveFile()**的生命周期模型\n\n# 5. 工具实现与实验分析\n\n基于本文提出的方法,我们实现了一种基于静\
    \ 态分析的 Java 程序 API 生命周期模型自动分析工 具 JavaExP [\\[46\\]](#page-17-3)。该工具包含约 10k 行 Java\
    \ 代码和 1.4k 行 Python 代码,依赖于底层分析框架 Soot [\\[44\\]](#page-17-6) 完成中间码提取、控制流图、函数调用图和控制依\
    \ 赖图[\\[32\\]](#page-16-11)等数据结构的构建。为了评估本文方法的 有效性和效率,本章在多个基准数据集上对工具 JavaExP 开展了一系列实验,主要研究问题如下:\n\
    \n- **RQ1**:在手工构造和真实 Java 项目上,JavaExP 能否准确高效地提取异常摘要信息?\n- **RQ2**:在真实框架/库项目上,JavaExP\
    \ 能否正 确构造异常信息敏感的API的生命周期模型?\n- **RQ3**:在真实框架/库项目上,异常信息敏感的 API 的生命周期模型有何特征?\n\n\
    ### **5.1.** 实验设置\n\n为回答 RQ1,我们手工构造了一个包含常见异常抛 出方式的基准测试集 ExceptionBench [\\[51\\\
    ]](#page-17-8),涉及到 多种常见的 Java 特性。数据集中的六个类分别为: 基本场景 Basic 类,其中包含无条件抛出、判空条 件抛出、字符串取值条件抛出、字符串操作条件抛\
    \ 出、逻辑与/或条件抛出等;跨函数调用场景 MultipleCall 类,包括多种跨函数调用场景;多路径 场景 MultiplePath 类,包含 if-else\
    \ 分支路径和 for 循 环路径;多个异常场景 MultipleThrow 类,包含同 一函数内多个异常和跨过程调用导致的多个异常; 类字段变量使用场景\
    \ FieldValue 类;和一个融合了 多种场景的综合场景 Motivation 类;共包含 40 个 异常。此外,本实验复用了 Nassif 等人构造的面向\
    \ Apache Commons IO [\\[49\\]](#page-17-9)的异常断言标注集合[\\[34\\]](#page-17-10)。 为保证对比的公平性,本实验仅将目标项目的源文\
    \ 件和对应 Jar 包作为输入,而未将任何项目外的第 三方库、JDK 等代码作为分析目标,排除未显式抛 出的异常和代码实现不在项目中的异常后,该数据 集共包含\
    \ 392 个独立异常。此外,本实验还选取了 六个广泛使用的 Java 项目来评估工具在这些真实 项目上的分析性能。评估标准包括异常摘要数量和 运行时间等。这里对每个项目的分析时间上限均被\
    \ 设置为 2 小时。为回答 RQ2 和 RQ3,我们以 RQ1 中六个真实项目为演化分析目标,根据这些项目在 Maven 仓库[\\[53\\]](#page-17-11)中的代码发布情况,收集了共计\
    \ 60 个历史版本 jar 包。随后,我们在这些版本上对真 实项目中API的演化情况进行分析。对于同一项目, 演化分析时仅考虑同级别变更版本。\n\n在实验有效性评估的对比工具选择方面,由于\
    \ 尚没有对于异常信息敏感的API演化分析的直接对 比工具,我们首先选择 Java 异常信息提取工具,对 异常分析这一重要模块的精度进行评估,再人工检 验\
    \ API 演化分析结果的有效性。经调研,工作 [\\[21\\]\\[22\\]](#page-16-13)可通过自然语言处理方式从 JavaDoc 文档\
    \ 或注释中提取异常信息,但由于文档/注释信息和代 码信息常存在偏差,不能将文档信息中提取的异常 信息作为演化分析的对象。工作[\\[34\\]](#page-17-10)\
    \ [\\[54\\]](#page-17-12)通过机器 翻译方法为异常抛出代码生成文档或通过自然语 言处理技术自动生成测试用例,但其异常信息分析 结果无法直接用于异常演化分析。基于此,本文选\
    \ 择了最新 SOTA 的 Java 异常前断言提取自动化工 具 WIT [\\[26\\]](#page-16-10),评估该工具与 JavaExP 在异常提取方\
    \ 面的能力差异。WIT 工具通过静态分析解析目标 Java 项目源代码,构造控制流图并提取跨过程路径 约束,结合约束求解技术获得异常相关的变量约束 信息,最终提取出\
    \ Java 异常的类型、前断言、描述 等信息,且其工具是公开可获取的。\n\n### **5.2.** 实验结果与分析\n\n### **5.2.1.**\
    \ 异常摘要报告有效性评估 **(RQ1)**\n\n对于异常分析提取,分析工具提取到的异常都 是真实存在的,其错误结果分为两种:未识别到真 实的异常,对应为漏报\
    \ FN;识别到真实异常,提取 了错误的异常摘要信息,而遗漏了正确的异常摘要 信息,可被认为既属于误报,也属于漏报信息。\n\n|  |  |  |  |\
    \  |  | 表 3 工具在 ExceptionBench 数据集上的有效性 |\n|--|--|--|--|--|--|---------------------------------|\n\
    |--|--|--|--|--|--|---------------------------------|\n\n| 工具      | TP | FP |\
    \ FN | Precision | Recall | F1-Score |\n|---------|----|----|----|-----------|--------|----------|\n\
    | JavaExP | 39 | 1  | 0  | 0.98      | 0.98   | 0.98     |\n| WIT     | 30 | 5\
    \  | 10 | 0.86      | 0.75   | 0.80     |\n\n表 3 分别给出本文 JavaExP 工具和异常提取工 具 WIT\
    \ 工具在 ExceptionBench 数据集上的有效性 评估结果,包括 TP、FP、FN 数值,和根据公式 Precision=TP/(TP+FP),\
    \ Recall=TP/(TP+FN), F1- Score=2×Precision×Recall/(Precision+Recall)计算 出的精确度、召回率和\
    \ F1 分数的结果。可以看到, JavaExP成功为其中的39个异常生成了正确的异常 摘要报告,其中 1 个误报是由于异常涉及复杂的数 据值变更,导致前断言分析不准确。在\
    \ WIT 不能处 理的 10(5+5)个异常中,5 个由于包含冗余且错误 的约束或涉及复杂的数据值变更导致异常前断言 提取结果有误,5 个涉及不支持的语法特性导致异\
    \ 常摘要未成功提取。在精确度、召回率和 F1 分数 三个度量指标上,JavaExP 均优于 WIT 工具。\n\n| 工具      | TP  | FP\
    \ | FN  | Precision | Recall | F1-Score |  |\n|---------|-----|----|-----|-----------|--------|----------|--|\n\
    | JavaExP | 300 | 56 | 36  | 0.84      | 0.77   | 0.80     |  |\n| WIT     | 137\
    \ | 17 | 255 | 0.89      | 0.35   | 0.50     |  |\n\n表 4 给出了工具 WIT 和 JavaExP 在公开基准\
    \ 测试集 DScrib[e\\[34\\]](#page-17-10)中异常上的有效性分析结果。在 该数据集上,WIT 正确生成的异常摘要数量为 137。\
    \ WIT 不 能 正 确 生 成 摘 要 的 异 常 数 量 为 255 (238+17),其中有 238 个异常的摘要为空,17 个 异常的摘要信息不准确。与之相比,JavaExP\
    \ 成功 生成了 300 个正确的异常摘要报告。JavaExP 不能 正确生成摘要的异常数量为 92(36+56),其中有 36 个异常的摘要为空,56 个异常的摘要信息不准\
    \ 确。虽然 WIT 的分析精确度略高于 JavaExP,但其\n\n召回率显著下降。与 WIT 相比,JavaExP 同时实现 了较高的精确度和召回率,F1\
    \ 分数与 WIT 比相对 提升了 60%。\n\n通过对 JavaExP 错误结果的分类分析,我们发 现对于 56 个摘要信息不准确的异常,其中的 22\
    \ 个 异常受限于循环条件展开次数,11 个异常存在无法 正确分析的复杂关系,10 个异常缺少部分正确路 径,8 个异常中被调用函数 callee 中的前断言约束\
    \ 无法正确映射到调用函数 caller 的参数,3 个异常 没有正确处理 try 语句中的异常抛出,2 个异常的前 断言条件自相冲突。对于另外 36 个摘要结果为空\
    \ 的异常,导致精度损失的一个原因是复杂跨函数参 数传递增加了分析难度。如图 3 所示,随着版本更 新,框架/库开发者在重构的过程中倾向于将异常抛 出代码进行包装以便复用,这间接增加了分析的复\
    \ 杂性。在 Apache Commons IO 项目 V2.13 版本中, 调用链长度不少于 5 的共有 578 处,调用链长度不 少于 10 的共有 50\
    \ 处,而调用链中任意一处异常摘 要信息误差均可能影响最终的匹配情况。此外, JavaExP 对字节码的静态分析能力也影响了分析结 果,如在处理位运算代码的断言条件时尚存在偏\
    \ 差、对静态变量的取值使用初始赋值,循环条件仅 展开 0 次和 1 次等,这些分析影响了前断言中部分 条件的准确性。\n\n|             |\
    \       |         |       | WIT          | JavaExP |        |       |  |\n|-------------|-------|---------|-------|--------------|---------|--------|-------|--|\n\
    | 项目名         | 版本    | LOC     | 总摘    | 时间           | 独立摘     | 总摘     | 时间\
    \    |  |\n|             |       |         | 要数    | /秒           | 要数      |\
    \ 要数     | /秒    |  |\n| Commons IO  | 2.6   | 9,984   | 297   | 3,903       \
    \ | 268     | 1,285  | 44    |  |\n| JGraphT     | 0.9.2 | 15,660  | 142   | 119\
    \          | 176     | 4,17   | 52    |  |\n| GraphStream | 1.3   | 48,535  |\
    \ 142   | 431          | 342     | 2,087  | 160   |  |\n| Guava       | 19.0 \
    \ | 70,250  | 2,347 | 6,133        | 221     | 3,891  | 112   |  |\n| Nashorn\
    \     | 1.8   | 83,728  | 177   | 1,759        | 949     | 3,446  | 355   |  |\n\
    | Android     | 10.0  | 546,655 | 524*  | 7,200        | 7,906   | 51,915 | 1743\
    \  |  |\n| 合计/平均       |       | 129,135 |       | 3,692 19,545 | 9,862   | 62,624\
    \ | 2,466 |  |\n\n表 **5** 工具在真实项目上的分析结果\n\n进一步,我们在六个真实项目上进行分析性能 的评估。表 5 给出了所选项目的名称、版本和大小,\
    \ 其中大小为不含注释的 Java 源码行数。后五列对比 了两个工具的结果中异常摘要数量和分析时间。其 中,对于大型的 Android 框架代码,WIT 超时导致\
    \ 未完成分析,因此,仅统计其在两小时内生成的结 果,并计算其中包含的异常摘要数量。对于六个被 测项目,WIT 用时约 5.5 小时,提取的总异常摘要\n\n\
    数量为 3,692。与之相比,JavaExP 用时仅 0.7 小时, 提取的独立摘要数量为 9,862,总摘要数量为 62,624,分析效率提高约 7 倍,提取数量显著增加。\
    \ 基于这一结果,我们进一步分析了异常数量的增加 是由于 JavaExP 分析到了更多的独立异常,还是由 于独立异常在跨函数调用过程中在不同调用路径 中重复出现导致的。我们根据异常抛出方法、异常\
    \ 抛出语句位置信息进行去重后的异常数量计为独 立异常的数量,独立摘要的数量少于总摘要数量。 据统计, WIT 的总摘要数量 (3,692)显著少于 JavaExP\
    \ 的独立摘要数量(9,862),由此可知,与 WIT 相比,JavaExP 不仅提取出更多的异常摘要结果, 且成功分析了更多的独立异常。\n\n实验表明,JavaExP\
    \ 提取的异常摘要数量显著 多于 WIT,且用时更短,带来这一优势的主要原因 有以下三个方面。首先,JavaExP 基于字节码分析, 不受限于新的 Java\
    \ 语法特性,分析范围更广,能够 正确处理 Java 的各种复杂语法特性支持,其分析能 力不受到代码形式的影响。其次,JavaExP 对分析 规模的限制更少,该方法并没有对每条路径上的节\
    \ 点数、函数内联后的节点数量等做严格限制[26],而 是在遍历控制流路径时先提取终止于异常抛出的 语句,仅分析异常抛出行为相关的代码切片,分析 范围更为聚焦。此外,JavaExP\
    \ 采用自底向上构建 函数摘要的方式,对每个函数不会被重复分析,带 来了明显的效率优势。除了效率优势,JavaExP 的 分析准确度也较高。JavaExP\
    \ 通过提取异常的类型、 描述文本、前断言三类核心信息对异常进行刻画, 在异常前断言分析时主动忽略了与当前异常抛出 无关的非控制依赖条件,但沿着函数调用链追踪异\
    \ 常抛出必要的关键前置条件,提高了异常分析的准 确性,这也为后续在不同版本中匹配异常的演化信 息打下了良好的基础。\n\n**RQ1** 结论:相比于现有的异常分析工具,JavaExP\
    \ 能够更加准确地提取异常的摘要信息,在现有数 据集上,将分析精度提高了约 60%;通过跨函数 摘要合并策略,将分析效率提高了 7 倍,并显著 增加了成功提取的异常摘要数量。\n\
    \n# **5.2.2. API** 生命周期模型构造正确性 **(RQ2)**\n\n在 RQ2 中,我们选取六个项目中发布历史版本 数量最多(19 个)的\
    \ Apache Commons IO 项目,人 工确认 JavaExP 在该项目上 API 演化分析结果的有 效性。对于 API 和异常增删修改的七种形式,为了\
    \ 保证公平性,本实验选取对象具体的方法为:对于 每个变更类别,首先根据变更实例数量对所在的 Java 类(class)文件进行排序。对于各个变更类型, 根据其变更总数,从所有变更实例中按照均匀分布\
    \ 采样间隔地选择实例。考虑到异常前断言的数量相 对较多,在选择时容易选择到因方法封装在不同上 层方法被重复调用的异常实例,为增加多样性,避 免确认相似的异常,该类别下会对异常调用链进行\
    \ 过滤,仅收集未包含相同异常抛出方法的实例。我 们对每种类别均收集 10 个实例(不足 10 时按实际 数量)。最终,对于 7 种变更类型,共收集了 63\
    \ 个 变更实例,结果见表 6,详细的人工确认报告见[\\[46\\]](#page-17-3)。\n\n对于过程内的分析,大量跨过程调用引入的异 常均无法被分析,占异常总数的\
    \ 94%;对于在当前 方法中抛出的可被分析的异常,异常抛出之前的跨 过程调用也会对前断言产生影响。在表 6 中,过程 内分析评估时仅选择在当前方法中抛出的异常,如\
    \ 果只考虑当前方法内出现的约束条件,分析结果 均正确,但如考虑其他方法调用带来的隐式约束, 有 5 个断言信息变更行为正确,其中 3 个异常摘要 前断言信息提取结果完全正确。\n\
    \n表 **6 API** 演化分析的正确性\n\n|        | 统计 API |    | API | 异常 | 异常 | 异常文 | 异常类 |\
    \ 异常条      |\n|--------|--------|----|-----|----|----|-----|-----|----------|\n\
    |        |        | 新增 | 删除  | 新增 | 删除 | 本修改 | 型修改 | 件修改      |\n| 过程内 数量 |  \
    \      | 10 | 10  | 10 | 10 | 10  | 3   | 10       |\n|        | 正确     | 10 |\
    \ 10  | 10 | 10 | 10  | 3   | 10[5/3]  |\n| 跨过程 数量 |        | 10 | 10  | 10 |\
    \ 10 | 10  | 10  | 10       |\n|        | 正确     | 10 | 10  | 10 | 10 | 9   |\
    \ 10  | 10[10/5] |\n\n与之相比,跨过程的分析则可以分析被调用函 数中抛出的深层异常和前置函数中的隐式约束。受 限于字节码静态分析,在异常条件修改变更结果\
    \ 中,5 个异常摘要前断言信息提取结果完全正确。5 个异常摘要提取结果不完全准确,但它们不影响对 断言变更检测结果的正确性,如循环展开有限次和 位运算约束结果不完全准确,但变更前后能够显著\
    \ 区分。在异常描述变更结果中,有一处错误的异常 匹配。这是因为版本 2.9 中的代码被大幅重构,原 异常的类型、消息、前断言均发生了改变,但函数 中刚好存在另一个与原异常类型和关键前断言均\
    \ 相同的异常,从而导致它们被错误匹配。总体来看, 跨过程策略下,演化分析的整体准确率达到 98%, 跨过程分析能够捕获到其他函数内存在的异常及 其断言条件,变更分析结果整体较为准确。后续\
    \ RQ3 中异常演化分析默认采用跨过程分析策略。\n\n经人工总结,影响 API 中异常匹配的可能因素 包括:1)在跨过程传递分析中,异常断言分析的精 度和过程间参数约束的分析可能传递影响最终的\
    \ 匹配结果;2)开发者可能同时修改同一个异常的多 个信息,导致难以通过单一变化严格限制匹配规 则,需在尽量避免错误匹配的前提下,尽可能识别 出存在差异的同一异常。3)目前仅能匹配文本相等\
    \ 和逻辑相等,如果开发者换用语义相同的不同 API, 如!isFile()和 isDirectory()语义相同,因无法自动判 断前后是否一致,会识别其为异常条件变更。如需\
    \ 判断语义一致性,需在后续研究中引入语义分析。\n\n**RQ2** 结论: JavaExP 能够基于提取的异常摘要, 准确构建 API 的生命周期模型,其中跨过程分析\
    \ 策略更为准确。部分异常的前断言信息存在精度 损失,但对 API 演化分析的影响不大。\n\n### **5.2.3. API** 生命周期变更结果分析\
    \ **(RQ3)**\n\n对于 RQ2 中的六个项目,我们在 Maven 仓库 中收集了各项目的共计 60 个历史发布版本,并在 表 7 中统计了各个项目的\
    \ API 变更情况。所有版本 的分析时间共计 30 分钟。对于 API 本身的变更, 新增 API 数量较多,随着版本演化,API 的数量整 体趋向于一直增加,但也有部分\
    \ API 会被删除。当 发生大版本重构时,API 变化较为明显。除了 API 的新增删除,JavaExP 还识别出了大量的异常变更 行为。在所有的 75,433\
    \ 个 API 中,约 14.3%的 API 新增过异常抛出行为,13.9% 删除过原有的异常, 6.5%更改过抛出条件,1.9%更改过异常描述文本, 0.1%变更过异常类型。在异常敏感的\
    \ API 生命周期 模型中,约 20%的 API 在被引入后,异常信息在后 续版本中发生过调整,这说明 API 中异常相关代码 的调整是十分常见的,异常敏感的\
    \ API 生命周期构 造能够更加精准的描述 API 的实际变更情况。\n\n| 项目名         | #分析 | #总     | #新增    |\
    \ #删除    | #异常摘要        |\n|-------------|-----|--------|--------|--------|--------------|\n\
    |             | 版本  | API    | API    | API    | 改变 API       |\n| Commons IO\
    \  | 19  | 1,880  | 1,665  | 36     | 548 (29%)    |\n| JGraphT     | 7   | 2,493\
    \  | 1,859  | 740    | 665 (27%)    |\n| GraphStream | 5   | 3,345  | 1,607  |\
    \ 1,460  | 194 (6%)     |\n| Guava       | 14  | 3,772  | 1,868  | 666    | 848\
    \ (22%)    |\n| Nashorn     | 5   | 4,340  | 8      | 11     | 739 (17%)    |\n\
    | Android     | 10  | 59,603 | 32,331 | 8,260  | 11,512 (19%) |\n| Total     \
    \  | /   | 75,433 | 39,338 | 11,173 | 14,506 (20%) |\n\n表 **7 API** 变更情况统计分析\n\
    \n进一步的,我们在图 7 和表 8 中展示了六个项 目中异常实例的变更情况。图 7(a)中统计了每个 API 中的发生变更的全部异常实例,当一个异常被 封装并多次调用时会多次统计。可以看到,当考虑\
    \ 重复异常时,新增异常的数量占比最高,其次删除 异常的数量。实际上部分新增异常是被重复调用 的。图 7(b)以独立异常为关注对象,异常多次调 用时仅统计一次,表\
    \ 8 给出了对应图 7(b)中独立 异常变更的数量统计,与图 7(a)相比,新增删除 异常的数量占比有所下降。在异常语义行为的不同 变更中,异常类型变更整体数量最少,主要包括子\
    \ 类到父类的变更,父类到子类变更,原生异常类到 自定义异常类的变更,代码重构复用功能相似代码 导致的类型变更等。描述信息变更其次,其原因包 括修正文字错误、增加描述信息、代码重构导致使\
    \ 用封装代码的描述文字等。而异常前断言更改的数 量相对较多,包括增删路径上的前置异常导致条件 变化,代码重构导致的条件变更等。\n\n![](_page_13_Figure_8.jpeg)\n\
    \n(**a**)异常实例变更类型统计\n\n![](_page_13_Figure_10.jpeg)\n\n# (**b**)独立异常实例变更类型统计 图\
    \ **7** 异常变更情况统计\n\n| 项目名         | #异常    | #异常<br>新增 | #异常<br>删除 | #异常<br>类型<br>修改\
    \ | #异常<br>描述<br>修改 | #异常<br>条件<br>修改 |\n|-------------|--------|-----------|-----------|-----------------|-----------------|-----------------|\n\
    | Commons IO  | 746    | 148       | 160       | 6               | 135       \
    \      | 200             |\n| JGraphT     | 979    | 87        | 51        | 1\
    \               | 55              | 130             |\n| GraphStream | 485   \
    \ | 58        | 55        | 1               | 31              | 39           \
    \   |\n| Guava       | 453    | 46        | 56        | 2               | 28 \
    \             | 140             |\n| Nashorn     | 1,332  | 72        | 32   \
    \     | 11              | 6               | 269             |\n| Android     |\
    \ 11,471 | 1,669     | 901       | 21              | 310             | 3,039 \
    \          |\n\n#### 表 **8** 不同项目中独立异常变更统计\n\n**RQ3** 结论:在代码演化过程中,不仅 API 的新 增、删除行为较为常见,异常的新增、删除和更\
    \ 改行为也十分频繁。在 75,433 个被分析的 API 中,约有 20% API 的异常抛出行为至少发生过 一次改变,这些 API 共涉及超过七千多处独立\
    \ 的异常变更。相比于 API 的存在性生命周期模 型,采用异常敏感的分析时,API 发生变动的比 例提高了 18%,该模型能够更加精准地描述 API 的实际变更情况,对框架/库代码的开发者和使\
    \ 用者都具有指导意义。\n\n# **5.2.4.** 对实验有效性的威胁\n\n在本文中,对实验有效性的威胁主要与数据集 的构建与选取有关。1)在手工基准测试集的构建阶\
    \ 段,设计思路的不同会在一定程度上影响在该数据 集上的评估结果,这一偏差难以避免。为了保障测 试集的公平性,本文在构建手工基准测试集时预先 对抛出异常的基本场景进行分类,再按照类别设计\
    \ 数据集代码。对于这些场景,该数据集仅考虑具有 指定特性的精简代码片段,用于测试异常分析工具 在具有不同特性代码上的基础分析能力。我们注意 到 WIT 不支持一些常见的语法特性,为保障公平\
    \ 性,我们仅根据数据集设计需要设计不同特性的代 码片段,而未在设计后主动添加移除特定工具(如 WIT)不支持的语法特性。2)在真实项目数据集的 选取上,真实项目的异常抛出代码风格、函数封装\
    \ 复杂度、相邻版本代码变更差异等均会影响评估结 果,为增强被测项目的代表性,本文复用已有的异 常断言标注集合[34]用于异常分析能力评估,并选 取了六个广泛使用且具有多个版本的\
    \ Java 开源项 目用于 API 变更分析评估,通过工具在不同被测项 目上的整体结果评估工具的综合分析能力。\n\n# 6. 相关工作\n\n## **6.1.**\
    \ 异常摘要提取\n\n异常(Exception)机制是 Java 中正式的错误报 告机制,为了能够及时有效地处理程序中的运行错 误,开发者需合理地抛出、捕获并处理异常。程序\
    \ 崩溃时,打印的异常堆栈信息是错误调试的一类重 要信息[\\[57\\]](#page-17-13)。由于异常机制的复杂性,研究人员围绕 着异常的使用[\\\
    [38\\]](#page-17-14)、异常抛出代码的编程指导 [\\[39\\]\\[40\\]](#page-17-15)、异常抛出行为的正确性测试[\\\
    [37\\]\\[56\\]](#page-17-16)、以及 基 于 程 序 异 常 抛 出 信 息 的 错 误 定 位 与 修 复\n\n[\\[47\\\
    ]\\[46\\]](#page-17-17)[\\[48\\]](#page-17-18)等方向开展了一系列工作。其中,为了 帮助开发人员了解代码中何时何处会抛出异常,理\
    \ 解程序的规范行为,异常的摘要信息,特别是其前 断言生成工作也受到了广泛的关注,主要类别包括 基于自然语言处理的方法和基于代码静态分析的 方法。\n\n\
    # **6.1.1** 基于自然语言处理的断言提取\n\n在开发过程中,断言信息可以帮助开发人员明 确方法的使用规范,避免API演化导致的代码缺陷; 在代码缺陷检测和定位时,前断言分析结果可以辅\
    \ 助测试人员构造高质量的测试用例,对满足/不满足 断言的行为进行系统地测试。\n\n基于自然语言处理(NLP)的断言生成方法被 广泛地应用,这类方法通过统计分析文档、注释等\
    \ 文 本 文 件 推 断 方 法 的 断 言 或 测 试 预 言 信 息 [\\[5\\]\\[20\\]](#page-16-4)[\\[21\\]\\\
    [22\\]](#page-16-13) [\\[23\\]\\[24\\]](#page-16-14)。Tan 等人在@Tcommen[t \\[1\\\
    ]](#page-16-0) 中通过定义自然语言模式和使用启发式方法来推 断程序的异常前断言,该方法仅关注空指针类型。 与之相比,Goff 等人提出的 ToraDoc[u\
    \ \\[21\\]](#page-16-13) 通过解 析 Javadoc 文档,自动为所有的异常行为构造测试 预言,工作 JDoctor [\\[22\\\
    ]](#page-16-15) 在此基础上扩展,实现了 面向更多程序行为的断言提取。此外,Zhai 等人提 出了从文档中自动生成 JML 规范的方法 C2[S\\\
    [20\\]](#page-16-16)。 由于大部分真实应用并不存在完整的 JML 规范,该 方法仅基于 JDK 的规范文档进行训练,其模型不一 定适用于其它的\
    \ Java 项目。基于自然语言处理的方 法可以有效基于文本分析实现断言提取,但无论是 方法文档或是代码注释,开发者对它们的编写情况 都是不确定的。代码中的文档、注释信息既可能缺\
    \ 失,也可能在代码演化过程中未被及时更新,因此, 这类方法适用于文档编写较为规范且被长期维护 的大型项目。但在大量真实项目中,存在着文档缺 失、不完整或未被及时维护的现象[\\\
    [25\\]\\[35\\]](#page-16-17)[\\[36\\]](#page-17-19),无 法准确体现 API 代码实现本身的演化情况。\n\
    \n# **6.1.2** 基于代码分析的断言提取\n\n另一类方法基于静态代码分析来提取断言信 息[\\[52\\]](#page-17-20)。Buse\
    \ 和 Weimer 基于 Java 异常分析工具 Jex [\\[30\\]](#page-16-18) 提出了一种自动推断 Java 方法异常抛出条件\
    \ 的方法 [\\[29\\]](#page-16-19)。该工作首先提取方法和异常的映射 表,然后采用符号执行和跨过程数据流分析技术提 取每个异常的抛出条件。由于该工作后向遍历了所\
    \ 有的控制流路径(control flow path),在单个方法 代码复杂、异常抛出前存在分支条件较多的情况下 会出现路径爆炸问题;收集到路径约束后,该方法\n\
    \n设计了一些约束处理规则以简化断言形式,但其生 成的结果均是围绕所有程序变量的,而不是只关注 异常和方法输入参数的关系。与之相似,Chandra 等 人也采用后向符号执行技术,提出了一种推断最弱\
    \ 前断言的技术 SnuggleBu[g \\[31\\]](#page-16-20),它将问题泛化为如 何找到从某入口点到达目标状态的前置条件,因此 该方法不限于异常分析。为了解决\
    \ Java 多态虚函数 调用关系分析带来的路径爆炸问题,该工作采用符 号执行和函数调用图交错的按需分析方法以提高 效率。但它们[\\[29\\]](#page-16-19)\
    \ [\\[31\\]](#page-16-20)均未提供可公开获取的工具。\n\n近期,Marcilio 等人[\\[26\\]](#page-16-10)\
    \ 提出了基于 Java 源码 分析的轻量级异常前断言分析方法 WIT。该方法可 以有效提取部分 Java 方法断言,但由于面向源代 码,其分析而受限于复杂的语法特性,如不能处理\
    \ 包含 for-each 循环语句, switch 语句, 和 try/catch 块的代码;此外,基于源码的分析依赖于变量名称 的匹配,在变量重新赋值时难以准确解析条件变量\
    \ 和输入参数的关系。WIT 项目的源码未公开,但工 具可公开获取。\n\n在基于代码分析的断言提取方法中,于源码的 分析可以有效提取部分方法的断言,但其受限于复\
    \ 杂且不断更新的 Java 语法特性、难以准确追踪内部 变量和外部参数之间的复杂关系[\\[26\\]](#page-16-10)。此外,对于上 层应用依赖的底层框架和第三方库,其源代码未必\
    \ 是可获取的。与之相比,基于字节码的分析不会受 限于高级语言的语法特性,并支持开展精确的控制 流和数据流追踪。为增加方法的普适性,适应不同 版本的 Java\
    \ 代码,并支撑框架/库源码不可获取的 分析场景,JavaExP 向 Java 字节码的静态分析技术, 通过追踪分析字节码中的异常抛出条件和变量取 值,实现异常相关的\
    \ API 语义变更分析。\n\n### **6.2. API**生命周期模型构建\n\nAPI 生命周期模型常被用于上层应用的 API 误 用检测或兼容性错误检测。Li\
    \ 等人在工作 CiD [\\[5\\]](#page-16-4) 中提出了安卓生命周期模型 (ALM),CiD 从安卓 开发框架中提取了完整的 API 方法列表,并给出不\
    \ 同 API 存在的版本范围。Huang 等人提出了 CIDE[R\\[8\\],](#page-16-21)该工作关注 API 回调函数变化导致的兼 容性问题,该工作依赖于手工构建的回调函数调用\
    \ 协议一致性图。工作 ACI[D\\[7\\]](#page-16-22)同时关注 API 调用问 题和 API 回调函数兼容性问题,该工作没有分析框 架代码,而是根据安卓框架官方提供的\
    \ API 差异列 表轻量级地获取其生命周期。本文也关注与框架 API 生命周期的提取,与这些工作相比,我们不仅 关注 API 的存在性问题,即在不同版本中\
    \ API 的新 增和删除情况,还重点分析了API中异常抛出情况, 特别是同一个 API 中异常抛出条件、描述、类型等 是否发生变化。\n\n除了 API\
    \ 方法的演化,工作[\\[11\\]](#page-16-23)还关注了框架 代码中字段(Field)信息的演化,并关注了字段变 化引发的上层代码缺陷。更多的工作[\\\
    [6\\]\\[9\\]](#page-16-5)[\\[10\\]](#page-16-24)关注 与在给定 API 生命周期模型的基础上,如何精确分 析上层应用代码,以找到\
    \ API 的误用问题,我们的 模型提取工作可以为这类研究提供支撑。\n\n# 7. 总结与展望\n\n针对框架/库项目和上层应用开发者在代码升 级演化过程中难以准确获取其开发或使用的API变\
    \ 更行为这一问题,本文基于静态分析方法,提出了 面向底层框架和第三方库的异常信息敏感的API生 命周期模型生成方法,形成原型工具 JavaExP。与 已有工作相比,JavaExP\
    \ 生成的异常摘要信息在准 确率和分析效率方面均有大幅提高。与异常不敏感 的 API 演化分析相比,异常敏感的 API 发生变动的 比例提高了 18%,在六个真实框架/库项目的\
    \ 60 个 版本中发现了超过七千多处独立的异常变更。\n\n这一工具可同时服务于框架/库的开发人员和 使用人员。一方面,对于框架/库的开发者,应在发 布新版本软件前,通过\
    \ API 生命周期分析工具精确 获取新版本代码中 API 中异常信息变更情况,确保 小版本升级时不产生 API 语义变更,大版本升级时 及时将语义变更情况更新在文档中。另一方面,对\
    \ 于应用开发者,在对所使用的框架/库代码进行版本 升级时,可通过分析工具查看当前版本到新版本中 API 的方法变更和异常变更情况,开展未捕获的异 常分析和异常传播分析等应用层检测,保障应用层\
    \ API 调用的正确性和鲁棒性,服务于软件供应链安 全分析。此外,对于基于大模型的自动代码生成, 框架/库 API 误用是生成代码中的一种典型错误模 式,API\
    \ 生命周期信息对于生成代码的版本一致性 检测和修复也有重要意义。\n\n考虑到真实的大规模框架/库中异常信息变动 非常频繁,在后续的研究工作中,我们将进一步探\
    \ 索如何从大量的异常信息变更中自动识别出可能 影响代码可靠性的语义变化、如何自动构造可触发 API 中的异常抛出行为的测试用例等研究问题,从 而精准定位上层软件系统中的\
    \ API 误用行为。\n\n# 致 谢 诚挚感谢评阅老师对论文提出的改进意见!\n\n### 参考文献:\n\n<span id=\"page-16-0\"\
    ></span>[1] Dependabot. https://docs.github.com/en/code-security/dependabot/ dependabot-alerts\n\
    \n<span id=\"page-16-1\"></span>[2] Hora, André, Romain Robbes, Marco Tulio Valente,\
    \ Nicolas Anquetil, Anne Etien, and Stéphane Ducasse. How do developers react\
    \ to API evolution? A large-scale empirical study. Software Quality Journal 26\
    \ (2018): 161-191.\n\n[3] Wu, Wei, Foutse Khomh, Bram Adams, Yann-Gaël Guéhéneuc,\
    \ and Giuliano Antoniol. An exploratory study of api changes and usages based\
    \ on apache and eclipse ecosystems. Empirical Software Engineering 21 (2016):\
    \ 2366-2412.\n\n<span id=\"page-16-2\"></span>[4] Bavota, Gabriele, Mario Linares-Vasquez,\
    \ Carlos Eduardo Bernal-Cardenas, Massimiliano Di Penta, Rocco Oliveto, and Denys\
    \ Poshyvanyk. The impact of api change-and fault-proneness on the user ratings\
    \ of android apps. IEEE Transactions on Software Engineering 41, no. 4 (2014):\
    \ 384-407.\n\n<span id=\"page-16-4\"></span>[5] Li Li, Tegawendé F Bissyandé,\
    \ Haoyu Wang, and Jacques Klein. 2018. Cid: Automating the detection of api-related\
    \ compatibility issues in android apps. https://github.com/lilicoding/CiD. In\
    \ Proceedings ofthe 27th ACM SIGSOFT Inter- national Symposium on Software Testing\
    \ and Analysis. 153–163.\n\n<span id=\"page-16-5\"></span>[6] Dongjie He, Lian\
    \ Li, Lei Wang, Hengjie Zheng, Guangwei Li, and Jingling Xue. 2018. Understanding\
    \ and detecting evolution-induced compatibility issues in android apps. In 2018\
    \ 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE).\
    \ IEEE, 167–177.\n\n<span id=\"page-16-22\"></span>[7] Tarek Mahmud, Meiru Che,\
    \ and Guowei Yang. 2021. Android compatibility issue detection using api differences.\
    \ In 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering\
    \ (SANER). IEEE, 480–490.\n\n<span id=\"page-16-21\"></span>[8] Huaxun Huang,\
    \ Lili Wei, Yepang Liu, and Shing-Chi Cheung. 2018. Under- standing and detecting\
    \ callback compatibility issues for android applications. In Proceedings ofthe\
    \ 33rdACM/IEEE International Conference on Automated Software Engineering. 532ś542.\n\
    \n[9] Patrick Mutchler, Yeganeh Safaei, Adam Doupé, and John Mitchell. 2016. Target\
    \ fragmentation in Android apps. In 2016 IEEE Security and Privacy Workshops (SPW).\
    \ IEEE, 204–213.\n\n<span id=\"page-16-24\"></span>[10] Yang Sen, Sen Chen, Lingling\
    \ Fan, Sihan Xu, Zhanwei Hui, and Song Huang. Compatibility Issue Detection for\
    \ Android Apps Based on Path-Sensitive Semantic Analysis. In 2023 IEEE/ACM 45th\
    \ International Conference on Software Engineering (ICSE), pp. 257-269. IEEE,\
    \ 2023.\n\n<span id=\"page-16-23\"></span>[11] Mahmud Tarek, Meiru Che, and Guowei\
    \ Yang. Android api field evolution and its induced compatibility issues. Proceedings\
    \ of the 16th ACM/IEEE International Symposium on Empirical Software Engineering\
    \ and Measurement. 2022.\n\n<span id=\"page-16-6\"></span>[12] 新增异常实例。[https://github.com/apache/commons-](https://github.com/apache/commons-io/commit/e03d721bb4dfd2e4ba7719f76ce17e860890dd2e)\n\
    \n[io/commit/e03d721bb4dfd2e4ba7719f76ce17e860890dd2e](https://github.com/apache/commons-io/commit/e03d721bb4dfd2e4ba7719f76ce17e860890dd2e)\n\
    \n[13] 删除异常实例。[https://github.com/aosp-](https://github.com/aosp-mirror/platform_frameworks_base/commit/8b73d86492c3bcd2fbca6545b89c159ace637b72)\n\
    \n[mirror/platform\\\\_frameworks\\\\_base/commit/8b73d86492c3bcd2fbca6545b89](https://github.com/aosp-mirror/platform_frameworks_base/commit/8b73d86492c3bcd2fbca6545b89c159ace637b72)\
    \ [c159ace637b72](https://github.com/aosp-mirror/platform_frameworks_base/commit/8b73d86492c3bcd2fbca6545b89c159ace637b72)\n\
    \n<span id=\"page-16-7\"></span>[14] 修改异常类型。[https://github.com/apache/commons](https://github.com/apache/commons-io/commit/af9bf289fbd7f6294ca399c54f4277e8631e903a)[io/commit/af9bf289fbd7f6294ca399c54f4277e8631e903a](https://github.com/apache/commons-io/commit/af9bf289fbd7f6294ca399c54f4277e8631e903a)\n\
    \n<span id=\"page-16-8\"></span>[15] 修改异常抛出条件。[https://github.com/apache/commons-](https://github.com/apache/commons-io/commit/50f9c9370c1286039fb6750e08e0fcbc20c6adc0)\n\
    \n[io/commit/50f9c9370c1286039fb6750e08e0fcbc20c6adc0](https://github.com/apache/commons-io/commit/50f9c9370c1286039fb6750e08e0fcbc20c6adc0)\n\
    \n<span id=\"page-16-9\"></span>[16] 修改异常描述文本。[https://github.com/apache/commons-](https://github.com/apache/commons-io/commit/8814b6d7efa235fc1410c9699eb136da780d70a2)\n\
    \n[io/commit/8814b6d7efa235fc1410c9699eb136da780d70a2](https://github.com/apache/commons-io/commit/8814b6d7efa235fc1410c9699eb136da780d70a2)\n\
    \n<span id=\"page-16-12\"></span>[17] 移动异常位置。[https://github.com/apache/commons-](https://github.com/apache/commons-io/commit/2d37ab6a0d53fce60095b352d36dddd9d26f5ab0)\n\
    \n[io/commit/2d37ab6a0d53fce60095b352d36dddd9d26f5ab0](https://github.com/apache/commons-io/commit/2d37ab6a0d53fce60095b352d36dddd9d26f5ab0)\n\
    \n<span id=\"page-16-3\"></span>[18] Yu, Dung-Feng, Cheng-Ying Chang, Hewijin\
    \ Christine Jiau, and Kuo-Feng Ssu. Which API Lifecycle Model is the Best for\
    \ API Removal Management?. ICSEA 2017: 230.\n\n[19] Shin Hwei Tan, Darko Marinov,\
    \ Lin Tan, and Gary T. Leavens. @tComment: Testing Javadoc Comments to Detect\
    \ Comment-Code Inconsistencies. ICST 2012: 260–269, 2012.\n\n<span id=\"page-16-16\"\
    ></span>[20] Juan Zhai, Yu Shi, Minxue Pan, Guian Zhou, Yongxiang Liu, Chunrong\
    \ Fang, Shiqing Ma, Lin Tan, and Xiangyu Zhang. 2020. C2S: translating natural\
    \ language comments to formal program specifications. ESEC/FSE 2020: 25-37, 2020.\n\
    \n<span id=\"page-16-13\"></span>[21] Alberto Goffi, Alessandra Gorla, Michael\
    \ D. Ernst, and Mauro Pezzè. 2016. Automatic generation of oracles for exceptional\
    \ behaviors. ISSTA 2016: 213–224, 2016.\n\n<span id=\"page-16-15\"></span>[22]\
    \ Arianna Blasi, Alberto Goffi, Konstantin Kuznetsov, Alessandra Gorla, Michael\
    \ D. Ernst, Mauro Pezzè, and Sergio Delgado Castellanos. Translating code comments\
    \ to procedure specifications. ISSTA 2018:242- 253, 2018.\n\n<span id=\"page-16-14\"\
    ></span>[23] Elizabeth Dinella, Gabriel Ryan, Todd Mytkowicz, and Shuvendu K.\
    \ Lahiri. 2022. TOGA: a neural method for test oracle generation. In Proceedings\
    \ of the 44th International Conference on Software Engineering (ICSE '22): 2130–2141,\
    \ 2022.\n\n[24] Rahul Pandita, Xusheng Xiao, Hao Zhong, Tao Xie, Stephen Oney,\
    \ and Amit Paradkar. Inferring method specifications from natural language api\
    \ descriptions. ICSE 2012: 815–825, 2012.\n\n<span id=\"page-16-17\"></span>[25]\
    \ Zhong, Hao, Na Meng, Zexuan Li, and Li Jia. An empirical study on API parameter\
    \ rules. ICSE 2020:899-911, 2020.\n\n<span id=\"page-16-10\"></span>[26] Diego\
    \ Marcilio and Carlo A. Furia, What Is Thrown? Lightweight Precise Automatic Extraction\
    \ of Exception Preconditions in Java Methods. ICSME 2022:340-35, 2022.\n\n[27]\
    \ Raymond P. L. Buse and Westley Weimer. Automatic documentation inference for\
    \ exceptions. ISSTA 2008: 273–282. 2008.\n\n[28] Yu Zhou, Changzhi Wang, Xin Yan,\
    \ Taolue Chen, Sebastiano Panichella, and Harald Gall. Automatic detection and\
    \ repair recommendation of directive defects in java api documentation. IEEE Transactions\
    \ on Software Engineering, 46(9):1004–1023, 2020.\n\n<span id=\"page-16-19\"></span>[29]\
    \ Raymond P. L. Buse and Westley Weimer. Automatic documentation inference for\
    \ exceptions. ISSTA 2008: 273–282. 2008.\n\n<span id=\"page-16-18\"></span>[30]\
    \ Martin P. Robillard and Gail C. Murphy. Static analysis to support the evolution\
    \ of exception structure in object-oriented systems. ACM Trans. Softw. Eng. Methodol.\
    \ 12(2):191–221, 2003.\n\n<span id=\"page-16-20\"></span>[31] Satish Chandra,\
    \ Stephen J. Fink, and Manu Sridharan. Snugglebug: a powerful approach to weakest\
    \ preconditions. PLDI 2009: 363–374. 2009.\n\n<span id=\"page-16-11\"></span>[32]\
    \ Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. The program dependence\
    \ graph and its use in optimization. ACM Trans. Program. Lang. Syst. 9, 3, 319–349,\
    \ 1987.\n\n[33] Cytron, Ron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman,\
    \ and F. Kenneth Zadeck. Efficiently computing static single assignment form and\
    \ the control dependence graph. ACM Transactions on Programming Languages and\
    \ Systems (TOPLAS) 13, no. 4 (1991): 451-490.\n\n<span id=\"page-17-10\"></span>[34]\
    \ Nassif, Mathieu, Alexa Hernandez, Ashvitha Sridharan, and Martin P. Robillard.\
    \ Generating unit tests for documentation. IEEE Transactions on Software Engineering\
    \ 48, no. 9 (2021): 3268-3279.\n\n<span id=\"page-17-19\"></span>[35] Emad Aghajani,\
    \ Csaba Nagy, Olga Lucero Vega-Márquez, Mario Linares-Vásquez, Laura Moreno, Gabriele\
    \ Bavota, and Michele Lanza. Software documentation issues unveiled. In Proceedings\
    \ of the 41st International Conference on Software Engineering, ICSE, 1199–1210,\
    \ 2019. [36] Emad Aghajani, Csaba Nagy, Mario Linares-Vásquez, Laura Moreno, Gabriele\
    \ Bavota, Michele Lanza, and David C. Shepherd. Software documentation: the practitioners'\
    \ perspective. In Proceedings of the ACM/IEEE 42nd International Conference on\
    \ Software Engineering (ICSE '20): 590–601, 2020.\n\n<span id=\"page-17-16\"></span>[37]\
    \ Francisco Dalton, Márcio Ribeiro, Gustavo Pinto, Leo Fernandes, Rohit Gheyi,\
    \ and Baldoino Fonseca. 2020. Is Exceptional Behavior Testing an Exception? An\
    \ Empirical Assessment Using Java Automated Tests. In Proceedings of the 24th\
    \ International Conference on Evaluation and Assessment in Software Engineering\
    \ (EASE '20). 170–179, 2020.\n\n<span id=\"page-17-14\"></span>[38] Haidar Osman,\
    \ Andrei Chiş, Jakob Schaerer, Mohammad Ghafari, and Oscar Nierstrasz. On the\
    \ evolution of exception usage in Java projects, 2017 IEEE 24th International\
    \ Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 422-426,\
    \ 2017.\n\n<span id=\"page-17-15\"></span>[39] Xiangyang Jia, Songqiang Chen,\
    \ Xingqi Zhou, Xintong Li, Run Yu, Xu Chen, Jifeng Xuan. Where to Handle an Exception?\
    \ Recommending Exception Handling Locations from a Global Perspective, 2021 IEEE/ACM\
    \ 29th International Conference on Program Comprehension (ICPC), pp. 369- 380,\
    \ 2021.\n\n[40] Hao Zhong. 2023. Which Exception Shall We Throw? In Proceedings\
    \ of the 37th IEEE/ACM International Conference on Automated Software Engineering\
    \ (ASE '22). Article 116, 1–12, 2022.\n\n<span id=\"page-17-0\"></span>[41] Exception\
    \ handling. Wikipedia. 2023.\n\n[https://en.wikipedia.org/wiki/Exception\\\\_handling](https://en.wikipedia.org/wiki/Exception_handling)\n\
    \n<span id=\"page-17-4\"></span>[42] Java Exception, Oracle.\n\n<https://docs.oracle.com/javase/8/docs/api/java/lang/Exception.html>\n\
    \n<span id=\"page-17-5\"></span>[43] Eckel, Bruce, and 侯捷. Java 编程思想. Vol. 2.\
    \ No. 02. 机械工业 出版社, 2002.\n\n<span id=\"page-17-6\"></span>[44] Soot. 2023[. https://github.com/soot-oss/soot](https://github.com/soot-oss/soot)\n\
    \n<span id=\"page-17-7\"></span>[45] Use-define chain. 2023[. https://en.wikipedia.org/wiki/Use](https://en.wikipedia.org/wiki/Use-define_chain)[define\\\
    \\_chain.](https://en.wikipedia.org/wiki/Use-define_chain)\n\n<span id=\"page-17-3\"\
    ></span>[46] JavaExP, 2023[. https://github.com/hanada31/JavaExP](https://github.com/hanada31/JavaExP)\n\
    \n<span id=\"page-17-17\"></span>[47] Jiwei Yan, Miaomiao Wang, Yepang Liu, Jun\
    \ Yan, Long Zhang. Locating Framework-specific Crashing Faults with Compact and\
    \ Explainable Candidate Set. The 45th IEEE/ACM International Conference on Software\
    \ Engineering, ICSE, 2023.\n\n<span id=\"page-17-18\"></span>[48] Rongxin Wu,\
    \ Hongyu Zhang, Shing-Chi Cheung, and Sunghun Kim. CrashLocator: locating crashing\
    \ faults based on crash stacks. In Proceedings of the 2014 International Symposium\
    \ on Software Testing and Analysis, ISSTA 2014. 204–214,2014.\n\n<span id=\"page-17-9\"\
    ></span>[49] Apache Commons IO, 2023. <https://github.com/apache/commons-io>\n\
    \n[50] Leonardo Mendonça de Moura and Nikolaj Bjørner. Z3: an efficient SMT solver.\
    \ In C. R. Ramakrishnan and Jakob Rehof, editors, Tools and Algorithms for the\
    \ Construction and Analysis of Systems, 14th International Conference, TACAS 2008\
    \ , pages 337–340. 2008.\n\n<span id=\"page-17-8\"></span>[51] ExceptionBench,\n\
    \n[https://github.com/hanada31/JavaExP/tree/master/Evaluation/RQ1/Exceptio](https://github.com/hanada31/JavaExP/tree/master/Evaluation/RQ1/ExceptionBench%20Code)\
    \ [nBench%20Code](https://github.com/hanada31/JavaExP/tree/master/Evaluation/RQ1/ExceptionBench%20Code)\n\
    \n<span id=\"page-17-20\"></span>[52] Rak-Amnouykit, Ingkarat, et al. The raise\
    \ of machine learning hyperparameter constraints in Python code. Proceedings of\
    \ the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis.\
    \ 2022. [53] Maven 仓库。<https://mvnrepository.com/>\n\n<span id=\"page-17-12\"\
    ></span><span id=\"page-17-11\"></span>[54] Blasi, Arianna, Alessandra Gorla,\
    \ Michael D. Ernst, and Mauro Pezzè. \"Call Me Maybe: Using NLP to Automatically\
    \ Generate Unit Test Cases Respecting Temporal Constraints.\" In Proceedings of\
    \ the 37th IEEE/ACM International Conference on Automated Software Engineering,\
    \ pp. 1-11. 2022.\n\n<span id=\"page-17-1\"></span>[55] Shaikh Mostafa, Rodney\
    \ Rodriguez, and Xiaoyin Wang. 2017. Experience paper: a study on behavioral backward\
    \ incompatibilities of Java software libraries. In Proceedings of the 26th ACM\
    \ SIGSOFT International Symposium on Software Testing and Analysis (ISSTA 2017).\
    \ Association for Computing Machinery, New York, NY, USA, 215–225.\n\n### 附中文参考文献:\n\
    \n[56] 姜淑娟,闫大顺. 一种快速测试Java异常处理机制的方法[J]. 小型 微型计算机系统,2005,26(10):1854-1857.\n\n\
    <span id=\"page-17-13\"></span>[57] 顾咏丰, 马萍, 贾向阳, 等. 软件崩溃研究进展. 中国科学: 信息 科学, 2019,\
    \ 49: 1383–1398.\n\n<span id=\"page-17-2\"></span>[58] 葛丽丽, 帅东昕, 谢金言, 张迎周, 薛渝川,\
    \ 杨嘉毅, 密杰, 卢跃. 面向软件供应链的异常分析方法综述. 软 件学报, 2023, 34(6): 2606– 2627."
- id: practical_guidelines_for_the_selection_and_evaluation_of_natural_language_processing_techniques_in_requirements_engineering_15_practical_guidelines_for_the_selection_and_evaluation_of_natural_language_processing_techniques_in_requirements_engineering
  title: "Practical Guidelines for the Selection and Evaluation of Natural\n  Language\
    \ Processing Techniques in Requirements Engineering"
  abstract: 'Natural Language Processing (NLP) is now a cornerstone of requirements

    automation. One compelling factor behind the growing adoption of NLP in

    Requirements Engineering (RE) is the prevalent use of natural language (NL) for

    specifying requirements in industry. NLP techniques are commonly used for

    automatically classifying requirements, extracting important information, e.g.,

    domain models and glossary terms, and performing quality assurance tasks, such

    as ambiguity handling and completeness checking. With so many different NLP

    solution strategies available and the possibility of applying machine learning

    alongside, it can be challenging to choose the right strategy for a specific RE

    task and to evaluate the resulting solution in an empirically rigorous manner.

    In this chapter, we present guidelines for the selection of NLP techniques as

    well as for their evaluation in the context of RE. In particular, we discuss

    how to choose among different strategies such as traditional NLP, feature-based

    machine learning, and language-model-based methods. Our ultimate hope for this

    chapter is to serve as a stepping stone, assisting newcomers to NLP4RE in

    quickly initiating themselves into the NLP technologies most pertinent to the

    RE field.'
  url: http://arxiv.org/abs/2401.01508v3
  keywords: ''
  document: '# 15. Practical Guidelines for the Selection and Evaluation of Natural
    Language Processing Techniques in Requirements Engineering


    Mehrdad Sabetzade[h](https://orcid.org/0000-0002-4711-8319) <sup>1</sup> and Chetan
    Aror[a](https://orcid.org/0000-0003-1466-7386) <sup>2</sup>


    <sup>1</sup> University of Ottawa, ON, Canada.


    <sup>2</sup> Monash University, Vic, Australia.


    Contributing authors: m.sabetzadeh@uottawa.ca; chetan.arora@monash.edu;


    #### Abstract


    Natural Language Processing (NLP) is now a cornerstone of requirements automation.
    One compelling factor behind the growing adoption of NLP in Requirements Engineering
    (RE) is the prevalent use of natural language (NL) for specifying requirements
    in industry. NLP techniques are commonly used for automatically classifying requirements,
    extracting important information, e.g., domain models and glossary terms, and
    performing quality assurance tasks, such as ambiguity handling and completeness
    checking. With so many different NLP solution strategies available and the possibility
    of applying machine learning alongside, it can be challenging to choose the right
    strategy for a specific RE task and to evaluate the resulting solution in an empirically
    rigorous manner. In this chapter, we present guidelines for the selection of NLP
    techniques as well as for their evaluation in the context of RE. In particular,
    we discuss how to choose among different strategies such as traditional NLP, feature-based
    machine learning, and language-model-based methods. Our ultimate hope for this
    chapter is to serve as a stepping stone, assisting newcomers to NLP4RE in quickly
    initiating themselves into the NLP technologies most pertinent to the RE field.


    # 1 Introduction


    NLP''s role in requirements automation is pivotal, due to the widespread use of
    natural language (NL) in industrial requirements specifications. Historically,
    NL has posed challenges for requirements analysis because of its inherent proneness
    to defects such as incompleteness and ambiguity. Recent breakthroughs in NLP,
    e.g., the emergence of large language models, have nonetheless drastically enhanced
    our ability to automatically analyze textual information. This development is
    poised to even further amplify the adoption and influence of NL in requirements
    engineering.


    Due to the rapid advancement of NLP, newcomers to NLP4RE may feel overwhelmed
    by the numerous potentially applicable technologies. Another challenge is the
    necessity to empirically assess a proposed automation solution, ensuring proper
    optimization, and, where applicable, improve performance over existing solutions.


    Over the past several years, we have studied various requirements automation problems,
    including checking compliance with requirements templates [\[5\]](#page-20-0),
    glossary construction [\[7\]](#page-20-1), model extraction [\[6\]](#page-20-2),
    requirements demarcation [\[2\]](#page-20-3), ambiguity handling [\[19\]](#page-21-0),
    and question answering [\[20\]](#page-21-1). With the benefit of hindsight, this
    chapter aims to reflect on our research process and offer our collective insights
    into how we approach NLP4RE problems. Before we start, we need to emphasize that
    our perspective is retrospective. Given the fast pace of progress in NLP technologies,
    new considerations may surface, and existing technologies could become outdated.
    Therefore, it is important for readers to consider the time this chapter was written
    (2023) when dealing with new technologies. This advice applies to most works in
    the fast-changing field of Applied AI.


    Structure. Section [2](#page-1-0) outlines the steps for automating pre-processing,
    analysis, and post-processing in NLP4RE. Section [3](#page-6-0) describes various
    NLP techniques and discusses their key considerations for automation in RE. Finally,
    Section [4](#page-20-4) summarizes the chapter and presents conclusions.


    # <span id="page-1-0"></span>2 Automation Steps in NLP4RE


    The automation process for NL requirements and related textual artifacts can be
    structured into three sequential steps. These steps, shown in Figure [1](#page-2-0)
    are: (1) Preprocessing, (2) Analysis, and (3) Post-processing. We outline these
    steps next.


    ### 2.1 Pre-processing


    The goal of pre-processing is to automatically examine the NL content of requirements
    or requirements-related artifacts (e.g., design documents and code) and generate
    structured information for use by the Analysis step (Section [2.2\)](#page-2-1).


    The specific information targeted by pre-processing depends on the needs of the
    subsequent Analysis step. Importantly, the information to obtain through preprocessing
    relies on the selection of the units of analysis for the Analysis step. In the
    context of NLP, "unit of analysis" refers to the particular textual components
    that are intended for processing and interpretation. Some common units of analysis
    are: words, phrases, sentences, and paragraphs. For instance, when the objective
    of Analysis is identifying statements that contain requirements, sentences are
    frequently adopted as the units of analysis [\[2\]](#page-20-3). We note that
    there is a composition relationship between different unit types in NLP. For example,
    a sentence is made up of phrases, and a phrase


    ![](_page_2_Figure_0.jpeg)


    #### <span id="page-2-0"></span>Fig. 1 NLP4RE Steps


    is made up of words. Because of this characteristic, it is possible to use a combination
    of units of analysis simultaneously, e.g., phrases alongside sentences.


    Typically, during the pre-processing phase, a set of "features" are calculated
    for the units of analysis (or the relationships between the units). A feature
    refers to a distinct attribute or characteristic of a unit of analysis. Features
    can be numeric (e.g., the number of tokens appearing in a sentence) or categorical
    (e.g., part-of-speech tags).


    The most common enabling technologies for computing features are presented in
    Figure [1](#page-2-0) under the Pre-processing activity. These technologies include
    the NLP Pipeline, Relevance Measures and Embeddings, which are discussed further
    in Section [3.](#page-6-0)


    #### <span id="page-2-1"></span>2.2 Analysis


    The core of the process shown in Figure [1](#page-2-0) is the Analysis step. In
    NLP4RE, this step typically manifests as one of the following three alternative
    activities: Classification, Clustering, and Text Generation.


    #### 2.2.1 Analysis Activities


    Classification involves the assignment of labels or categories to the units of
    analysis. There are numerous NLP4RE use cases for classification. An example use
    case would be differentiating between functional (F) and non-functional requirements
    (NF) [\[27\]](#page-22-0). This task can be framed as the assignment of F and
    NF labels to the units of analysis, which in this context, are typically sentences
    within a requirements document.


    Classification further extends to encompass verbatim information extraction. Verbatim
    information extraction involves directly extracting exact segments from source
    documents without abstraction, inference, or interpretation. This is done by marking
    off the text segments of interest and assigning labels to them. A typical use
    case is identifying requirements-related text segments in legal documents and
    annotating them with labels such as "permission", "obligation", "condition", and
    "exception" [\[43\]](#page-23-0).


    Clustering leverages inherent similarities among the units of analysis to organize
    them into groups or themes. Unlike classification, which requires predetermined
    labels, clustering emphasizes the intrinsic structure and similarities within
    the content. The goal is to bring together similar content based on shared features,
    thereby avoiding the need for explicit predefined categories. This makes clustering
    particularly useful when dealing with problems where the labels are not well-defined
    or when exploring content where the underlying patterns might not be immediately
    evident. For instance, clustering can be used to identify groups of closely related
    requirements phrases during glossary construction [\[7\]](#page-20-1); here there
    is no predetermined set of classes for the groups of related phrases that will
    emerge.


    Text Generation involves the automated creation of human-readable text based on
    either structured or unstructured inputs to aid the derivation, completion, understanding
    and communication of requirements. NLP4RE solutions based on text generation are
    a relatively recent development but are rapidly gaining momentum thanks to advances
    in generative language models like GPT [\[9\]](#page-21-2). Example use cases
    for text generation include constructing requirements models based on prompts
    and early-stage descriptions [\[16\]](#page-21-3), summarizing requirements-related
    documents [\[26\]](#page-22-1), and providing predictive assistance for requirements
    completion [\[31\]](#page-22-2).


    #### 2.2.2 Technique Selection


    Selecting suitable enabling technique(s) for the Analysis step is crucial. To
    make this selection easier, we have developed a decision process, shown in Figure
    [2.](#page-4-0) This simple process, which is based on our past experience, aims
    to facilitate narrowing the options for the Analysis step.


    The first and most important criterion in this process is decision node (a), as
    depicted in Figure [2.](#page-4-0) This decision concerns whether we have a well-established
    and pre-existing set of conceptual categories relevant to automation. For instance,
    consider the task of classifying functional and non-functional requirements. In
    this task, the categories would be functional and non-functional, and this understanding
    exists before classification. For another example, consider the task of domain
    model extraction. Here, all pertinent categories are identified and can be listed,
    such as class, attribute, association, cardinality constraint, and so on. In contrast,
    consider a problem like identifying similar and potentially redundant requirements.
    When presented with a requirements document, predicting the number of equivalence
    classes (clusters) is impossible. As a result, there is no predefined set of conceptual
    categories for this problem that can be known beforehand.


    ![](_page_4_Figure_0.jpeg)


    <span id="page-4-0"></span>Fig. 2 Identifying Suitable Enabling Technique(s) for
    a Specific Analysis Task


    Without established conceptual categories, dataset size is the next crucial criterion
    to consider. Historically, when predefined categories are not possible, clustering
    algorithms have been the preferred enabling technique for analysis. Recent advances
    in generative language models like ChatGPT and Llama nonetheless offer an alternative.
    For instance, when dealing with data sources such as requirements documents, one
    can use exploratory prompts like the following to uncover the main themes: "Cluster
    the primary concepts in the following: [contents of the data source]".


    As of writing, using a generative language model as an alternative to clustering
    algorithms is effective only for relatively small content volumes. Existing language
    models set a limit on total input and output tokens during interactive dialogs,
    known as "token limit" or "session size." This limit defines how much context
    the model is capable of taking into account for response generation. Currently,
    the largest token limit we are aware of is 32,768 tokens (GPT-4-32k); this would
    be insufficient for many NLP4RE problems, such as traceability retrieval, which
    can potentially involve millions of tokens.


    When an a-priori-known set of conceptual categories exists, the next question
    is whether a labelled dataset is available. This is captured by decision node
    (c) in Figure [2.](#page-4-0) When a labelled dataset is lacking, the most common
    enabling technique is query-based pattern matching. Although pattern matching
    does not require the explicit creation of labelled data, formulating the queries
    often entails some form of qualitative analysis, e.g., grounded theory [\[41\]](#page-23-1).
    Alternatively, language models can be employed when labelled data is unavailable.
    In such a scenario, one has to rely exclusively on the language model''s pre-training,
    without further specific training for the task at hand. For example, a language
    model could be asked the following: "Is this requirements statement functional
    or non-functional? [an individual requirements statement]".


    If labelled data is available, the next factor to consider is the volume of such
    data, as captured by decision node (d) in Figure [2.](#page-4-0) When a considerable
    amount of labelled data is available, there are two options: applying feature-based
    learning or utilizing the labelled data to "fine-tune" a language model. Fine-tuning
    involves adapting a pre-trained model to a specific task through targeted training.
    In cases of limited labelled data, achieving task adaptation for a language model
    with minimal examples – a technique known as few-shot learning – is likely to
    yield better results.


    It is important to note that there is no general rule as to what constitutes "considerable"
    or "limited" labelled data. Several parameters such as the quality of labels,
    the complexity of the relationships to be learned, the number of classes (in classification)
    and the range of values (in regression), the amount of noise in the data, the
    dimensionality of the feature space (in case of feature-based learning), and the
    desired level of accuracy to achieve can influence data needs. As such, experimentation
    on a case-by-case basis is crucial to determine whether the labelled data at hand
    should be regarded as considerable or limited. In our experience, and for the
    sake of offering ballpark figures, having fewer than 100 data points tends to
    constitute a limited amount. A considerable amount of data, on the other hand,
    is likely to materialize within the range of 500 to 5000 labelled data points.


    We need to highlight three important aspects related to the process in Figure
    [2.](#page-4-0) First, no individual decision model can encompass the full spectrum
    of techniques employed in NLP4RE. Our model aims to offer a simplified representation
    of common scenarios, rather than imposing constraints or promoting a lack of flexibility
    in technique selection. Second, the process is likely to evolve in the future
    to stay in step with NLP4RE research. In particular, capitalizing on the interactive
    capabilities of large language models, there is potential to further elaborate
    the process by considering prompting strategies and providing additional guidelines.
    However, due to the scarcity of NLP4RE approaches built on large language models,
    we have to defer doing so to the future. Finally, when selecting enabling techniques
    for analysis, the cost and environmental impact must be considered. Most notably,
    the resource-intensive nature of large language models requires justification,
    especially when alternatives cannot be dismissed due to compelling reasons such
    as lack of accuracy.


    #### 2.3 Post-processing


    Post-processing – the third step in the process of Figure [1](#page-2-0) – aims
    to enhance the results of the Analysis step or to adapt these results for human
    analysts'' better understanding. Post-processing is not needed in all NLP4RE solutions
    and is thus an optional step.


    To illustrate a simple scenario where post-processing is required, let us consider
    the task of requirements identification. For this task, one may apply the following
    heuristic as a post-processing step: if all but one sentence in a passage are
    categorized as requirements (during the Analysis step), that lone sentence should
    be reclassified from a non-requirement to a requirement. This adjustment will
    likely increase the accuracy of requirements identification [\[2\]](#page-20-3).


    For a more advanced example of post-processing, let us consider requirements completion
    based on predictions by a language model. In this context, the language model
    is likely to generate a non-negligible number of predictions that are not useful
    (false positives) alongside the useful ones. To reduce the incidence of unuseful
    predictions in the final results, the development of a post-processing filter
    becomes essential [\[31\]](#page-22-2).


    In its simplest form, post-processing can be light, e.g., in the case of the heuristic
    mentioned earlier for requirements identification. In more complex scenarios,
    like the one mentioned above where predictions need to be filtered, additional
    enabling techniques might be needed to carry out post-processing.


    # <span id="page-6-0"></span>3 Enabling Techniques: Overview and Guidelines


    In this section, we outline the various enabling techniques shown in Figure [1](#page-2-0)
    and provide practical guidelines for applying and evaluating them.


    #### <span id="page-6-1"></span>3.1 NLP Pipeline


    The NLP pipeline is a sequence of modules that incrementally add linguistic annotations
    to an input text. The pipeline typically begins with tasks like tokenization (breaking
    text into words or sub-words), sentence splitting (segmenting a passage into sentences),
    and lemmatization (reducing words to their base forms). Next and depending on
    the annotations required, the pipeline performs tasks such as part-ofspeech (POS)
    tagging (labelling words with their grammatical roles), named-entity recognition
    (identifying entities like names, dates, and locations), and syntactic parsing
    (analyzing sentence structure). Syntactic parsing includes two main techniques:
    constituency parsing (deconstructing sentences into grammatical constituents)
    and dependency parsing (determining grammatical relationships between words).


    Figures [3](#page-7-0) (a) and (b) respectively exemplify the annotations generated
    by the constituency parsing and dependency parsing modules for the following requirements
    sentence: R = "The flight simulator shall store log messages in the database.".
    The annotations generated by the constituency parser for this sentence are: NP
    (noun phrase), VP (verb phrase), and PP (prepositional phrase). These annotations
    capture the hierarchical constituents of the sentence. The relationships between
    the words in the sentence are given by the pairwise links generated through dependency
    parsing. For instance, from the dependency parse graph of Figure [3](#page-7-0)
    (b), one can determine that "simulator" functions as the subject (nsubj) for "store,"
    and that "messages" serves as the object (obj) for this transitive verb. Crucially,
    both parsing methods require sentence splitting and POS tagging. Figure [3\(](#page-7-0)a)
    illustrates sentence annotation (S),


    ![](_page_7_Figure_0.jpeg)


    © The Allen Institute for Artificial Intelligence - All Rights Reserved | Privacy
    Policy | Terms of Use | Business Code of Conduct (b) Dependency Parse Graph


    <span id="page-7-0"></span>The flight simulator shall store log messages in the
    database . DT NN NN MD VB NN NNS IN DT NN . compound aux compound det det nsubj
    obj case Fig. 3 Illustration of (a) Constituency Parsing and (b) Dependency Parsing.
    Both Parsing Methods Require Sentence Detection and POS Tagging.


    CoreNLP Tools: while both figures include POS tags (DT: determiner, NN: noun,
    NNS: plural noun, MD: modifier, VB: verb, IN: preposition).


    **Enter a TokensRegex expression to run against the above sentence:** TokensRegex
    Semgrex Tregex e.g., (?\$foxtype [{pos:JJ}]+ ) fox Match When using the NLP pipeline,
    it is important to consider the specific natural language(s) that require support.
    While most NLP modules have good performance over well-written English, their
    effectiveness can vary significantly when dealing with other languages or when
    processing text that deviates from grammatical norms, such as user feedback (e.g.,
    app reviews) or developer commit messages. Experimentation is therefore typically
    necessary for constructing an accurate NLP pipeline. NLP workbenches such as GATE
    [\[23\]](#page-22-3) and DKPro [\[14\]](#page-21-4) facilitate the integration
    of NLP modules from different NLP libraries. For instance, these workbenches enable
    the use of the POS tagger provided by one library, say, Apache OpenNLP [\[4\]](#page-20-5),
    alongside the constituency and dependency parsers from another library, say, Stanford
    CoreNLP [\[32\]](#page-22-4). This flexibility to combine NLP modules from different
    libraries enables systematic experimentation with various pipeline configurations
    to determine the optimal configuration for the task at hand. An example of such
    experimentation can be found in our work on checking conformance with requirements
    templates [\[5\]](#page-20-0).


    Visualisation provided using the brat visualisation/annotation software. If systematic
    experimentation with alternative NLP modules is not feasible or if there are constraints
    on using a single library, e.g., to minimize complexity, it would be important
    to conduct an error analysis on the annotations generated by the NLP pipeline.
    This analysis helps with ensuring the absence of systemic issues. Common


    8


    systemic issues include recurring errors in sentence detection, repeated inaccuracies
    in tokenization and POS tags, and incorrect parsing results.


    Takeaway: NLP Pipeline


    Prioritize pipeline implementations that are known to work well for the language(s)
    you need to support. Experimentation with different NLP modules is often useful
    for improving accuracy. If extensive experimentation with the NLP pipeline is
    not possible or you are limited to a single library, conduct an error analysis
    on the annotations to identify and address any systemic issues such as recurring
    errors in sentence detection, POS tags, and parsing.


    #### <span id="page-8-0"></span>3.2 Relevance Measures


    In the context of RE, relevance denotes the extent to which various requirement
    segments are related or how closely a specific requirements segment aligns with
    a particular query, topic, or artifact (e.g., a design document or a portion thereof).
    The concept of relevance is typically quantified using one or a combination of
    three distinct categories of metrics: syntactic, semantic, and statistical.


    - Syntactic Relevance is the string-based or structural relatedness between two
    or more text segments. There are numerous syntactic relevance measures. For a
    fairly comprehensive list of syntactic measures, consult [\[24\]](#page-22-5).
    An example metric in the syntactic category is Levenshtein [\[24\]](#page-22-5).
    This metric calculates the minimum number of single-character edits (insertions,
    deletions, or substitutions) required to transform one string into another. Levenshtein
    distance is usually normalized (scaled from 0 to 1) by dividing it by the maximum
    possible edit distance between the two strings. For instance, the (normalized)
    Levenshtein distance between the phrases "software system" and "software systems"
    is 0.9375, indicating that the two strings have considerable lexical overlap.

    - Semantic Relevance goes beyond string matching to measure similarity between
    word meanings. Semantic relevance is typically quantified using metrics like PATH
    within a semantic network such as WordNet [\[37\]](#page-23-2). WordNet captures
    various relationships, such as hypernymy and hyponymy, which denote an "is-a"
    connection, and meronymy and holonymy, representing a "part-of" association. To
    illustrate, consider the relationship between "vehicle" and "car", where "vehicle"
    serves as the hypernym of "car", and the relationship between "wheel" and "car",
    with "wheel" acting as the meronym of "car". PATH similarity calculates the shortest
    path between two concepts on the "is-a" hierarchy. For instance, the PATH score
    between the terms "cat" and "mammal" is higher than between "cat" and "vehicle",
    indicating that "cat" is semantically more related to "mammal" than "vehicle".

    - Statistical Relevance assesses relevance by analyzing the frequency and distribution
    of terms within a document, often employing algorithms such as TF-IDF and BM25.
    These algorithms are frequently normalized on a scale from 0 to 1 [\[12\]](#page-21-5).
    Statistical methods typically operate at the level of term frequency and do not
    necessitate


    a pre-constructed semantic network. For instance, TF-IDF evaluates a term''s importance
    within a document based on its frequency of occurrence in that document, normalized
    by its frequency across the entire corpus. BM25, which extends TF-IDF, takes into
    account further factors like term saturation and document length. To illustrate,
    consider a corpus of requirements documents. A term like "user authentication"
    might appear infrequently but could be highly significant. BM25 can rank a document
    that extensively discusses this term higher than a document that only mentions
    it in passing, thereby indicating its greater relevance in the context of security
    requirements. Statistical measures are more commonly employed in information retrieval
    (IR) problems within NLP4RE, such as querying requirements [\[3\]](#page-20-6).


    Applications and Other Considerations. Relevance measures serve two main use cases
    in NLP4RE. The first is to calculate similarity either within a set of requirements
    or between requirements and textual segments found in other development artifacts.
    The second use case is to assess the relative significance of terms in documents.
    Frequently, relevance measures are employed as features in both supervised and
    unsupervised learning.


    Different relevance measures can be combined to provide a more holistic characterization
    of relevance. For example, when tasked with constructing a requirements glossary,
    the combination of syntactic and semantic measures can help identify a wider range
    of variations among related domain terms. To illustrate, if our objective is to
    cluster terms related to a flight simulation system, we anticipate that "flight
    coordinates", "aircraft position", and all concepts associated with "flight positioning"
    should land in the same cluster [\[7\]](#page-20-1). Simultaneously applying both
    syntactic and semantic measures facilitates the determination of these terms being
    highly similar.


    In relation to syntactic measures, it is important to note that, because requirements
    frequently manifest variability in phrasing, vocabulary selection and syntactic
    structure, techniques like lemmatization and tokenization are often required prior
    to computing syntactic measures. This preprocessing helps mitigate variability
    and enhances the accuracy of comparisons [\[7\]](#page-20-1).


    Finally, and in relation to semantic measures, we note that these measures are
    quickly being replaced by more advanced techniques, notably embeddings. Embeddings
    not only capture semantic similarity but also contextual similarity, as we discuss
    in Section [3.3.](#page-10-0) Furthermore, while lexical resources like WordNet
    offer the advantage of establishing human-interpretable connections between words,
    techniques such as embeddings provide a more nuanced characterization of meaning,
    although they may not be entirely interpretable by humans. Consequently, when
    the primary goal is the application of similarity metrics, rather than explaining
    relationships, there is often limited justification for employing semantic measures
    like PATH in future research.


    #### Takeaway: Relevance Measures


    Combining different relevance measures often results in more accurate analytical
    outcomes. Relevance measures can be applied at different levels of granularity,
    ranging from individual tokens (e.g., Levenshtein distance) to entire documents
    (e.g., TF-IDF). Empirical evaluations of relevance measures can centre around
    identifying the most effective combination of these measures or benchmarking advanced
    solutions against relevance measures considered as baseline methods.


    #### <span id="page-10-0"></span>3.3 Embeddings


    Embeddings enable the conversion of words into numerical vectors. These vectors
    encapsulate the semantic connections among words, in turn supporting a more meaningful
    manipulation of language. Word embeddings are typically derived through self-supervised
    approaches such as Word2Vec [\[34\]](#page-22-6), GloVe [\[36\]](#page-23-3),
    and the pre-training of language models such as BERT [\[18\]](#page-21-6) and
    GPT [\[38\]](#page-23-4). For example, using the 300 dimensional variant of GloVe
    embedding vectors, the word "requirements" would be represented as a 300-dimensional
    vector: [-1.3598e-01, -1.8174e-01, · · · , -6.2015e-02].


    While the primary goal of embeddings is to represent individual words, methods
    also exist for generating embeddings for phrases and sentences. For example, a
    simple approach for obtaining sentence embeddings is to compute the weighted average
    of the word embeddings in a given sentence [\[10\]](#page-21-7).


    There are two main use cases for embeddings in the existing NLP4RE literature:
    (1) computing semantic similarity, typically through the cosine measure, and (2)
    using embeddings as features for learning. To illustrate, suppose that we are
    interested in identifying most similar requirements, e.g., as a way to find overlapping
    or redundant requirements. Consider the following three statements: R1 = "The
    system shall react to user input within one second."; R2 = "The system shall respond
    within one second."; and R3 = "The system shall encrypt sensitive data.". For
    a requirement sentence R, let emb(R) denote the sentence''s embeddings. By utilizing
    the 300 dimensional variant of GloVe and employing averaging to derive sentence
    embeddings from word embeddings, we would obtain the following: cosine(emb(R1),
    emb(R2)) ≈ 0.95 > cosine(emb(R1), emb(R3)) ≈ 0.83 > cosine(emb(R2), emb(R3)) ≈
    0.78. Now, the requirements analyst can, for example, sort the requirements pairs
    in descending order of similarity and inspect the most similar pairs to determine
    if there are overlaps or redundancies. Alternatively, when it is feasible to create
    a labelled dataset for training, the embeddings can be used as features – either
    on their own or alongside other features – for building a feature-based classifier
    that distinguishes similar and non-similar requirements pairs. In our illustrative
    example, and assuming that only R1 and R2 are deemed similar, one could infer
    (among other labelled data points) the following for training: emb(R1)|emb(R2)|SIMILAR
    and emb(R1)|emb(R3)|NOT-SIMILAR. Here, "|" denotes vector concatenation, and "SIMILAR"
    and "NOT-SIMILAR" denote labels for pairs of requirements.


    There are some important considerations to note when working with embeddings:


    Dimensionality of Embeddings. The dimensionality of embeddings, which refers to
    the number of dimensions (or features) used to represent each word as a vector,
    determines the richness of information in word vectors. While some dimensions
    may have clear interpretations, e.g., gender or sentiment, others can be complex,
    capturing subtle and abstract aspects of word semantics that would be difficult
    for humans to interpret directly. There is no universally suitable choice for
    the dimensionality of word embeddings. Although a larger dimensionality can provide
    increased semantic nuance and potentially improved accuracy, one must consider
    the curse of dimensionality [\[34\]](#page-22-6) – the inherent challenges that
    arise when dealing with high-dimensional data. We recommend experimentation with
    alternative embedding methods and dimensionality options to find an acceptable
    trade-off between accuracy for the analytical task at hand and the challenges
    posed by high-dimensional data. Note that the techniques discussed in Section
    [3.5](#page-14-0) for feature selection and reduction can also be applied to embeddings
    to reduce dimensionality.


    Non-contextual vs. Contextual Embeddings. Embeddings can be either noncontextual
    or contextual. Non-contextual embeddings, such as those produced by GloVe, create
    fixed word vectors that remain the same regardless of context. In contrast, contextual
    word embeddings, as produced by models like BERT and GPT, consider the surrounding
    words to generate word vectors that adapt to the context. To illustrate, consider
    the following two sentences: S = "Meeting privacy requirements is essential.";
    and S ′ = "The system shall meet all the privacy requirements stipulated by the
    GDPR." Using GloVe to obtain embeddings for the word "requirements" yields the
    same vector for both sentences. In contrast, if one uses models such as BERT or
    GPT, the embeddings obtained for the same word in different sentences would differ.
    For instance, the bert-base-uncased variant of BERT yields the following vectors
    for "requirements" in S and S ′ , respectively: [2.7466e-01, 4.8193e-01, · · ·
    , 4.1681e-01] and [-1.6852e-01, 3.5143e-01, · · · , 3.5699e-01]. This difference
    is due to the contextually different meaning of "requirements" in these two sentences,
    where the word conveys the sense of a prerequisite condition in S and the sense
    of a specification in S ′ .


    Contextual embeddings offer greater accuracy but come at a higher computational
    cost. It is therefore important not to dismiss non-contextual embeddings outright
    but to weigh their potential alongside contextual embeddings to determine whether
    the added accuracy of contextual embeddings is worth the extra cost.


    Domain-specific Embeddings. Domain-specific embeddings capture contextspecific
    word meanings that generic embeddings may miss. For instance, specialized BERT
    variants, such as BioBERT [\[28\]](#page-22-7) for biomedical texts and LegalBERT
    [\[15\]](#page-21-8) for legal documents, provide domain-specific embeddings for
    their respective domains. When domain-specific embeddings exist, it is worthwhile
    to compare them with generic embeddings for potential improvements. Further, in
    cases where domain-specific embeddings are unavailable, but a suitable domain-specific
    corpus is accessible, one can


    attempt to construct domain-specific embeddings from scratch. Recent efforts in
    software engineering, such as building Word2Vec and GloVe embeddings for model-driven
    engineering [\[30\]](#page-22-8), provide useful guidance in this regard.


    ### Takeaway: Embeddings


    Experiment with different embedding technologies and dimensionality options to
    strike a balance between accuracy and the challenges of high-dimensional data.
    Assess whether the added accuracy of contextual embeddings justifies their higher
    computational cost, or if non-contextual embeddings suffice for your specific
    task. Explore domain-specific embeddings when available, as they may be superior
    at capturing context-specific meanings.


    #### 3.4 Query-based Pattern Matching


    The annotations produced by the NLP pipeline provide a rich basis for defining
    queries that detect patterns of interest within an input text. Typically, pattern-matching
    queries work with "spans". Each span represents a distinct sequence of consecutive
    words or tokens within the given text.


    An important technical aspect in pattern matching is the choice of the query language.
    In NLP, span information can be flat, focusing on individual words and their properties
    (like POS tags), hierarchical, revealing how words combine into larger structures
    (as in constituency parsing), or graph-based, capturing relationships between
    words (as in dependency parsing). Different NLP toolkits offer different query
    languages; CoreNLP [\[32\]](#page-22-4), for instance, provides TokensRegex for
    token-based regular expressions, Tregex for tree-based linguistic structures,
    and Semgrex for syntactic dependency patterns. To illustrate, we exemplify these
    query languages:


    - (a) The TokensRegex query [{tag:/VB.\*/}] extracts all spans tagged as verbs.

    - (b) The Tregex expression NP[<NN | <NNS] extracts all spans that are Noun Phrases
    (NPs) and immediately dominate a singular noun (NN) or a plural noun (NNS).

    - (c) The Semgrex query {pos:/VB.\*/} >nsubj {}=subject >obj {}=object extracts
    verbs that both have a subject and an object, alongside the subject and the object.


    Figure [4](#page-13-0) shows the results of the above queries as applied to the
    annotations in Fig. [3.](#page-7-0) All three queries serve a purpose in NLP4RE.
    Query (a) produces results that can be used as a feature for identifying requirements,
    grounded in the hypothesis that a higher verb count signifies a higher likelihood
    of requirements being present. Query (b) identifies constituent noun phrases and
    verb phrases within a requirements statement. This information is valuable for
    various purposes, one of which is to validate whether the statement conforms to
    a specific template, such as EARS [\[33\]](#page-22-9). Query (c) is useful for
    constructing a domain model [\[6\]](#page-20-2); the query extracts a probable
    association. In the case of our example, the association would be "[flight] simulator
    stores [log] messages".


    Query-based pattern matching techniques often face criticism related to both the
    scope of the study that informs query development and the applicability of the
    resulting queries beyond their initial purpose. To address these concerns, we
    recommend a


    ![](_page_13_Figure_0.jpeg)


    <span id="page-13-0"></span>Visualisation provided using the brat visualisation/annotation
    software (http://brat.nlplab.org/). Fig. 4 Illustration of Query-based Pattern
    Matching over the Annotations of Fig. [3.](#page-7-0)


    two-fold approach. First, it is important for query designers to carefully document
    the query specification process, providing a clear explanation of the considered
    documents and domains. The primary objective should be to enhance empirical reliability,
    ensuring that the process is as reproducible as possible by others. Second and
    concerning generalizability, one should avoid using all the text under analysis
    for query development. This approach allows for the assessment of query generalizability
    on unseen text, resulting in a more credible evaluation. An even more robust strategy
    involves expanding the analysis beyond the immediate domain under study. For example,
    if the focus is on regulatory documents, it is common to derive queries in one
    legal jurisdiction, such as Europe, and subsequently evaluate query accuracy in
    texts from another jurisdiction, like Canada [\[43\]](#page-23-0). By adhering
    to these basic principles — detailed documentation of the query derivation process
    and assessments of generalizability — one can enhance the utility of query-based
    pattern matching techniques.


    #### Takeaway: Query-based Pattern Matching


    (1) When working with NLP annotations, select query language(s) that align with
    your specific analysis needs. (2) To ensure the reliability of query derivation,
    carefully document the steps you take to create the queries. This documentation
    should include the criteria, context, and content used for query design, making
    it easier for others to reproduce your work. (3) Refrain from using all the text
    you have for query development. To improve the applicability of your queries,
    evaluate their performance on unseen (or withheld) text or in different domains.


    ### <span id="page-14-0"></span>3.5 Feature-based Machine Learning


    Feature-based machine learning (ML) is concerned with using labelled data to train
    algorithms to make predictions based on predefined features. Feature-based ML
    has numerous applications in NLP4RE. For instance, it can be used for (1) categorizing
    input requirements as either functional or non-functional [\[27\]](#page-22-0),
    or (2) predicting the number of story points for user stories based on historical
    data [\[17\]](#page-21-9). The former application is a classification problem,
    entailing the assignment of discrete labels to data points ("functional" or "non-functional");
    whereas the latter scenario constitutes a regression problem as it involves estimating
    numeric values (story points).


    Building a feature-based ML model has five main steps. Below, we discuss these
    steps and outline some important practical considerations related to each step.


    - 1. Data collection involves gathering relevant and sufficient data, including
    the labelling process. This phase can be very time- and effort-intensive, particularly
    when manual labelling is required. To ensure consistency, it is crucial to define
    a clear and agreed-upon labelling task with protocols that annotators can consistently
    follow. To enhance internal validity, authors should avoid annotating their test
    data. When feasible, it is further important to employ multiple annotators with
    some overlap to enable the calculation of inter-annotator agreement. Detailed
    documentation of the data-collection protocol is essential for reliability [\[2,](#page-20-3)
    [3\]](#page-20-6).

    - 2. Data wrangling is concerned with handling missing data, noise removal (e.g.,
    stop words or redundant information), deciding about how to manage structured
    and unstructured data, and transforming results into the desired format. It is
    crucial to thoroughly document all techniques and decisions made in this step,
    as even minor changes can significantly impact the accuracy of the ML model [\[21\]](#page-21-10).

    - 3. Feature engineering is the process of defining relevant features for learning
    from the input data. In NLP4RE, features are usually defined over the outputs
    of the preprocessing techniques discussed in Sections [3.1–](#page-6-1)[3.3.](#page-10-0)
    For instance, a feature based on the NLP pipeline could be the number of verbs
    in a sentence. A feature using relevance measures might be the highest TF-IDF
    rank of a specific term across all articles in a corpus. Finally and in relation
    to embeddings, the components within an embedding vector can be regarded as features,
    as elaborated in Section [3.3.](#page-10-0)


    Features should be treated as hypotheses for addressing the problem at hand, and
    their usefulness must be evaluated. Techniques for computing feature importance,
    e.g., information gain [\[11\]](#page-21-11), and PCA analysis [\[1\]](#page-20-7),
    may be used for eliminating redundant or less significant features, thereby preventing
    overfitting. Feature engineering must also prioritize computational efficiency,
    particularly in real-time tasks such as live editing of requirements [\[2\]](#page-20-3),
    where almost instant feature computation is necessary. In such scenarios, certain
    computationally expensive features may need to be sacrificed, even if they offer
    marginal improvements. For example, the resource-intensive process of constituent
    parsing, despite its potential value, may prove impractical. Conducting a cost-effectiveness
    analysis, weighing the cost of computing each feature against its impact on the
    resulting ML model''s accuracy is therefore recommended.


    4. Model Selection, Tuning, and Training is concerned with choosing an appropriate
    ML algorithm, fine-tuning its hyperparameters, and training it over featureengineered
    data [\[22\]](#page-22-10). Initially, the computed feature data should be split
    into three sets: the training set (typically 70% of all the data), the validation
    set (usually 10% of the data) for model selection and hyperparameter optimization,
    and the test set (typically 20% of the data) to evaluate the trained ML model
    [\[39\]](#page-23-5). During dataset partitioning, it is paramount to avoid data
    leakage, which means avoiding any exposure of test set data during training and
    validation [\[42\]](#page-23-6). If the dataset covers multiple projects, it is
    advisable to ensure that the test set includes data from ''hold-out'' projects
    not involved in training or validation at all [\[39\]](#page-23-5).


    NLP4RE frequently encounters a scarcity of the kind of "abundant" data necessary
    for training complex ML algorithms, such as deep learning. In such instances,
    ML algorithms like Random Forest can provide scalable solutions, even when dealing
    with smaller datasets, noting of course that this advantage comes at the cost
    of requiring manual feature engineering.


    Model tuning is another vital step in the process. While hyperparameter optimization
    should theoretically be integrated with model selection, the number of combinations
    to evaluate when combining model selection and hyperparameter optimization can
    be exceedingly large [\[22\]](#page-22-10). For example, systematically exploring
    discrete values across key hyperparameters in the Random Forest algorithm can
    result in over 500 combinations. Given this challenge, a more practical approach
    would be to initially select a suitable ML algorithm by experimenting with multiple
    algorithms at their default settings, and then proceed to fine-tune the hyperparameters
    for the chosen algorithm. The choice of hyperparameter tuning strategy depends
    on available resources, such as an extensive grid search or a lightweight stochastic
    random search, for example.


    5. Evaluation involves assessing a trained ML model''s performance on a test set
    using metrics such as accuracy, precision, recall, F-score, and mean absolute
    error (MAE). Depending on the context, one can opt for "hold-out" test sets or
    k-fold crossvalidation. The selection and prioritization of metrics require special
    attention. For instance, in a binary classification task where 95% of samples
    belong to Class A and only 5% to Class B, a classifier exclusively predicting
    Class A would achieve 95% accuracy. Consequently, accuracy may not be a suitable
    metric when the dataset is imbalanced. Another notable point related to metrics
    is that, in NLP4RE, recall often outweighs precision in terms of importance, typically
    making recall a priority in solution development [\[13\]](#page-21-12). In relation
    to reporting, care needs to be taken when reporting aggregate metrics like F-score:
    such metrics should be reported alongside the source metrics (in this case, precision
    and recall) rather than as substitutes.


    Beyond reporting metrics, it is important to reflect on how these metrics translate
    into either benefits or drawbacks for users. For example, it is always valuable
    to contemplate the significance of various types of classification errors and
    determine their impact on users. When the cost of prediction errors is deemed
    too high, e.g., when the ML model''s predictions serve as recommendations requiring
    meticulous manual follow-up, one may consider implementing a human feedback loop
    to continuously retrain the model and reduce errors [\[8\]](#page-20-8).


    #### Takeaway: Feature-based ML


    Develop explicit procedures for manual data labelling during data collection and
    document these procedures. Keep track of data-wrangling decisions, as they can
    have a substantial impact on the outcomes. Approach features as hypotheses and
    confirm their significance before incorporating them into the final solution.
    Given the numerous combinations available for hyperparameter tuning during model
    selection and tuning, you may want to begin with experimentation using the default
    settings of machine learning algorithms. Ensure there is no data leakage, which
    means avoiding the inadvertent exposure of parts of test documents during the
    training and validation processes. The choice of evaluation metrics is of great
    importance and should be aligned with the specific NLP4RE task at hand.


    #### 3.6 Clustering Algorithms


    Clustering algorithms group similar data points into subsets or clusters to reveal
    patterns and structures within the data. This is achieved using a quantitative
    measure of similarity and ensuring that points in the same cluster are more similar
    to each other than to those in different clusters. In NLP4RE, relevance measures
    (Section [3.2\)](#page-8-0) and embeddings (Section [3.3\)](#page-10-0) are commonly
    used to compute similarity for clustering purposes. For instance, using GloVe
    embeddings, requirements statements can be transformed into vectors and then clustered
    using clustering algorithms such as Kmeans, agglomerative clustring or expectation
    maximization (EM) [\[46\]](#page-23-7). To illustrate, consider a system with
    six requirements: R1-R3 from Section [3.3](#page-10-0) and R4-R6 defined as follows:
    R4 = "The system shall allow users to customize the UI theme, available as ''dark''
    and ''light'' versions."; R5 = "The system shall allow users to sync data across
    multiple devices."; and R6 = "The system shall allow users to reset passwords
    only after email authentication.". Once sentence embeddings have been generated,
    cosine similarity between requirements pairs can be used as the basis for clustering.
    An illustrative clustering of these requirements, aimed at determining implementation
    responsibilities, might consist of [R1, R2] (system responsiveness), [R3, R6]
    (system protection), [R4] (system UI customization), and [R5] (system data management).
    Clustering has numerous applications in NLP4RE, including tasks such as traceability
    link retrieval, identifying overlapping or redundant requirements, and categorizing
    app reviews to pinpoint new feature requests. Below, we present some important
    practical considerations for an efficient utilization of clustering algorithms
    in NLP4RE.


    Determining the Number of Clusters (k). Choosing an appropriate number of clusters
    (k) is an important prerequisite for effectively applying many common clustering
    algorithms such as K-means and EM. Techniques like the Elbow method, Silhouette
    analysis, and Bayesian Information Criterion (BIC) can help estimate an appropriate
    k [\[46\]](#page-23-7). Another alternative is a recent summarization metric proposed
    in clustering app reviews [\[35\]](#page-23-8). Domain knowledge remains a key
    factor alongside these methods in deciding the number of clusters. The appropriate
    value of k is influenced by the task


    at hand and how users plan to utilize the resulting clusters. For instance, when
    clustering requirements terms, one may emphasize creating numerous small clusters,
    e.g., to simplify glossary construction [\[7\]](#page-20-1). On the other hand,
    when clustering core requirements within software product lines, it may be preferable
    to have a smaller number of clusters, as this streamlines the reviewing of common
    functions [\[40\]](#page-23-9).


    Hierarchical vs. Partitional vs. Soft Clustering. In partitional clustering algorithms,
    such as K-means, data is divided into non-overlapping clusters without any inherent
    structure. In contrast, hierarchical clustering creates a tree-like structure.
    Partitional methods are more suitable when the primary focus of the analysis is
    to rapidly identify overarching themes. For instance, Di Sorbo et al. [\[44\]](#page-23-10)
    adopt a partitional approach to categorize app reviews into pre-defined topics,
    determining the necessary changes in the apps according to user feedback. Hierarchical
    clustering, on the other hand, is better suited when there is a need to comprehend
    and visualize the relationships and nested structures within the dataset. For
    instance, Reinhartz-Berger and Kemelman [\[40\]](#page-23-9) use hierarchical
    clustering to explore the relationships between software product line requirements
    from different products by clustering the core requirements. It is worth noting
    that hierarchical clustering algorithms also provide mechanisms to create partitions.
    In soft clustering (also know as fuzzy clustering), each data point can belong
    to multiple clusters with varying degrees of membership. Soft clustering is ideal
    for situations where the boundaries between clusters are not rigidly defined,
    and instances may possess properties of multiple clusters. An example of this
    approach is the EM algorithm. An RE-related use case is clustering of requirements
    terms. In this context, it is beneficial to allow each term to have membership
    in different clusters [\[7\]](#page-20-1). For instance, the term "flight simulator"
    may find membership in both the "flight"-related and "simulator"-related clusters
    within a requirements document. Ultimately, the choice between partitional, hierarchical,
    or soft clustering depends on the specific task and analysis objectives at hand.
    Analysts should therefore understand the distinctions and potential applications
    of different types of clustering algorithms to ensure that their chosen algorithm
    aligns with the goals of their analysis.


    Evaluation. Cluster evaluation can be either internal or external. Internal evaluation
    assesses the quality of clusters without relying on external labels, focusing
    on the principles of cohesion and separation. Cohesion measures how closely related
    the members of the same cluster are, reflecting the compactness of the clusters,
    while separation assesses how distinct or well-separated a cluster is from others.
    A higher separation implies that clustering can more effectively distinguish between
    clusters. External evaluation, on the other hand, measures the quality of clusters
    by comparing them to a ground truth. This comparison can involve evaluating the
    overlap or mutual information between the original clusters and the generated
    ones. Developing a ground truth in clustering is challenging due to the inherent
    subjectivity of this task and its context dependence. Requirements and related
    artifacts can have multifaceted interpretations, leading to multiple valid ways
    of clustering based on different perspectives or objectives. Creating a good ground
    truth necessitates: (i) a clear understanding of the concept of clustering as
    well as the end goal to achieve, (ii) substantial time and effort, and (iii) vigilance
    against bias and inconsistency, as different experts may have


    contrasting opinions based on their experiences, potentially resulting in inconsistencies
    and posing threats to both internal and construct validity.


    #### Takeaway: Clustering Algorithms


    Important decisions in clustering include determining a suitable number of clusters
    (e.g., the Elbow method or Silhouette analysis), and opting between clustering
    types (partitional, hierarchical, or soft). The choice of clustering algorithm
    depends on the goal of the analysis and requires domain understanding. Evaluating
    the effectiveness of clustering is critical, which can be approached internally
    by assessing the cohesion and separation of clusters or externally by comparing
    against a ground truth. An external evaluation often poses challenges, as creating
    a ground truth for clustering is subjective and often requires substantial effort.


    ### 3.7 Large Language Models


    Language models (LMs) are statistical models that use neural networks to predict
    the next word in a sequence based on preceding words. For example, given the text
    "Paris is the capital of", a langauge model may predict the next word as "France".
    Language models increasingly serve as the foundation for various downstream NLP
    tasks such as text completion, translation, and summarization. Large language
    models (LLMs) like GPT-4 and BERT are scaled-up versions of the LM concept, with
    billions and sometimes even trillions of parameters. The descriptor "large" in
    LLM pertains to the model''s size in terms of the number of parameters. These
    parameters represent the neural network layers'' weights that the model acquires
    through training. Generally, larger models tend to perform better at comprehending
    context, drawing inferences and producing answers that resemble human responses.


    Hyperparameters. LLMs have a range of hyperparameters that can be adjusted during
    both training and fine-tuning. The hyperparameter profiles can vary among different
    LLMs, and the extent to which individual LLMs allow end-users to modify these
    hyperparameters also varies. Some common LLM hyperparameters include: (i) learning
    rate, determining how quickly the model adapts its weights during training; (ii)
    number of epochs, referring to how many times the model will go through the entire
    training dataset; (iii) batch size, denoting the number of training examples utilized
    in one iteration; (iv) sequence length, referring to the number of tokens that
    the model reads in one go; (v) dropout rate, referring to the fraction of input
    units to drop during training to mitigate overfitting; and (vi) temperature, a
    parameter that modulates the probability distribution over the predicted words,
    making the outputs more focused (lower values) or more random (higher values).


    Extensive experimentation across a broad range of LLM hyperparameter combinations
    currently presents challenges due to constraints in both time and budget. Nevertheless,
    it remains essential to select a practical subset of hyperparameter combinations
    that can be explored within the available resources. This approach enables a more
    informed understanding of how hyperparameters influence the performance of an
    LLM in conducting a specific task.


    Prompting. Prompting refers to providing a specific input or query to guide a
    generative AI model in producing the desired output, such as text or images [\[25\]](#page-22-11).
    Prompts, which are concise textual inputs given to generative AI models, including
    LLMs, convey information about the specific task that the model is expected to
    execute.


    Creating prompts that are effective in eliciting the desired output from an LLM
    requires good prompt engineering. Prompt engineering involves the selection of
    appropriate prompt patterns and prompting techniques [\[45\]](#page-23-11). Prompt
    patterns encompass various templates tailored for specific objectives. For example,
    the output customization pattern focuses on refining the format or structure of
    LLM-generated output, with the LLM often adopting a particular persona (role)
    while generating the output. Prompting techniques, on the other hand, are strategies
    to extract the best possible output from LLMs. Example prompting techniques include
    zero-shot prompting, few-shot prompting, chain-of-thought prompting, and tree-of-thought
    prompting [\[29\]](#page-22-12).


    When conducting empirical examinations of LLM-based solutions, it is important
    to take into account the alternative choices that one can make during prompt engineering.
    These alternatives should ideally be compared through empirical means. Nonetheless,
    much like the challenges encountered when exploring hyperparameters, the vast
    array of possible combinations of prompt patterns and prompting strategies may
    be too numerous to thoroughly investigate. Another important aspect to consider
    is that even minor alterations in prompts can lead to considerable variation in
    the outputs generated by LLMs. In view of this, empirical studies should also
    assess prompt robustness by examining multiple variants of the same prompt.


    Fine-tuning. While LLMs come pre-trained on very large corpora, they often require
    some level of fine-tuning to specialize them for particular tasks or domains.
    When the requirements automation task at hand aligns closely with common knowledge,
    such as ambiguity handling, one might achieve good results with little or no fine-tuning.
    However, if the task is specialized and involves RE-specific semantics, such as
    requirements classifications, fine-tuning often becomes necessary to ensure accurate
    results. When fine-tuning an LLM, one needs to be cognizant of the non-deterministic
    nature of the process, which is influenced by factors such as random initialization
    and regularization. Depending on the extent and diversity of the fine-tuning data,
    significant variations may be observed in results across different fine-tuning
    attempts. To account for this randomness, we recommend fine-tuning LLMs multiple
    times and reporting average results rather than relying on the outcome of a single
    fine-tuned model.


    #### Takeaway: Large Language Models


    When working with LLMs, explore hyperparameters within resource constraints. Invest
    in prompt engineering, using suitable prompt patterns and techniques, and empirically
    compare different alternatives. Take note of the non-deterministic nature of fine-tuning,
    and present results averaged over multiple fine-tuning runs.


    # <span id="page-20-4"></span>4 Summary and Conclusion


    The main goal of this chapter was to aid newcomers in the selection of appropriate
    NLP4RE techniques and the application of some essential principles for their evaluation.
    We acknowledge the wide array of NLP technologies employed in RE. Not all NLP4RE
    approaches may neatly align with the general, and sometimes simplified, framework
    we have outlined in this chapter.


    This chapter was written during a transformative period in the NLP field, spurred
    by the emergence of generative AI and large language models. We hope that this
    chapter can serve as a stepping stone for quickly grasping the NLP technologies
    most relevant to RE. With both the NLP and RE landscapes constantly evolving,
    our hope is to maintain this chapter as a living document, continuously integrating
    emerging trends and pertinent techniques for automated requirements analysis.


    Acknowledgements.The first author is grateful for the financial support provided
    by the Natural Sciences and Engineering Research Council of Canada (NSERC) through
    the Discovery and Discovery Accelerator programs.


    # References


    - <span id="page-20-7"></span>[1] Abdi H, Williams LJ (2010) Principal component
    analysis. Wiley interdisciplinary reviews: computational statistics 2(4):433–459.
    URL [https://api.semanticscholar.](https://api.semanticscholar.org/CorpusID:122379222)
    [org/CorpusID:122379222](https://api.semanticscholar.org/CorpusID:122379222)

    - <span id="page-20-3"></span>[2] Abualhaija S, Arora C, Sabetzadeh M, et al (2020)
    Automated demarcation of requirements in textual specifications: a machine learning-based
    approach. Empirical Software Engineering 25(6):5454–5497. [https://doi.org/10.](https://doi.org/10.1007/S10664-020-09864-1)
    [1007/S10664-020-09864-1](https://doi.org/10.1007/S10664-020-09864-1)

    - <span id="page-20-6"></span>[3] Abualhaija S, Arora C, Sleimi A, et al (2022)
    Automated question answering for improved understanding of compliance requirements:
    A multi-document study. In: 30th IEEE International Requirements Engineering Conference,
    RE, pp 39–50, <https://doi.org/10.1109/RE54965.2022.00011>

    - <span id="page-20-5"></span>[4] Apache OpenNLP (2006) Apache. URL [http://opennlp.apache.org,](http://opennlp.apache.org)
    last accessed: October 2023

    - <span id="page-20-0"></span>[5] Arora C, Sabetzadeh M, Briand L, et al (2015)
    Automated checking of conformance to requirements templates using natural language
    processing. IEEE Trans Software Eng 41(10):944–968. <https://doi.org/10.1109/tse.2015.2428709>

    - <span id="page-20-2"></span>[6] Arora C, Sabetzadeh M, Briand L, et al (2016)
    Extracting domain models from natural-language requirements: approach and industrial
    evaluation. In: Baudry B, Combemale B (eds) Proceedings of the ACM/IEEE 19th International
    Conference on Model Driven Engineering Languages and Systems, MODELS, pp 250–260,
    <https://doi.org/10.1145/2976767.2976769>

    - <span id="page-20-1"></span>[7] Arora C, Sabetzadeh M, Briand L, et al (2017)
    Automated extraction and clustering of requirements glossary terms. IEEE Trans
    Software Eng 43(10):918–945. <https://doi.org/10.1109/tse.2016.2635134>

    - <span id="page-20-8"></span>[8] Arora C, Sabetzadeh M, Briand LC (2019) An empirical
    study on the potential usefulness of domain models for completeness checking of
    requirements. Empir Softw Eng 24(4):2509–2539. <https://doi.org/10.1007/S10664-019-09693-X>

    - <span id="page-21-2"></span>[9] Arora C, Grundy J, Abdelrazek M (2023) Advancing
    requirements engineering through generative ai: Assessing the role of LLMs. CoRR
    abs/2310.13976. [https:](https://doi.org/10.48550/ARXIV.2310.13976) [//doi.org/10.48550/ARXIV.2310.13976](https://doi.org/10.48550/ARXIV.2310.13976)

    - <span id="page-21-7"></span>[10] Arora S, Liang Y, Ma T (2017) A simple but
    tough-to-beat baseline for sentence embeddings. In: 5th International Conference
    on Learning Representations, ICLR, URL <https://openreview.net/forum?id=SyK00v5xx>

    - <span id="page-21-11"></span>[11] Azhagusundari B, Thanamani AS, et al (2013)
    Feature selection based on information gain. International Journal of Innovative
    Technology and Exploring Engineering 2(2):18–21. URL <https://api.semanticscholar.org/CorpusID:212611078>

    - <span id="page-21-5"></span>[12] Baeza-Yates RA, Ribeiro-Neto B (1999) Modern
    information retrieval. Addison-Wesley Longman Publishing Co., Inc., USA, <https://doi.org/10.5555/553876>

    - <span id="page-21-12"></span>[13] Berry DM (2021) Empirical evaluation of tools
    for hairy requirements engineering tasks. Empir Softw Eng 26(5):111. <https://doi.org/10.1007/S10664-021-09986-0>

    - <span id="page-21-4"></span>[14] de Castilho RE, Gurevych I (2014) A broad-coverage
    collection of portable NLP components for building shareable analysis pipelines.
    In: Ide N, Grivolla J (eds) Proceedings of the Workshop on Open Infrastructures
    and Analysis Frameworks for HLT, OIAF4HLT@COLING, pp 1–11, <https://doi.org/10.3115/V1/W14-5201>

    - <span id="page-21-8"></span>[15] Chalkidis I, Fergadiotis M, Malakasiotis P,
    et al (2020) LEGAL-BERT: the muppets straight out of law school. CoRR abs/2010.02559.
    URL [https://arxiv.org/](https://arxiv.org/abs/2010.02559) [abs/2010.02559](https://arxiv.org/abs/2010.02559)

    - <span id="page-21-3"></span>[16] Chen B, Chen K, Hassani S, et al (2023) On
    the use of GPT-4 for creating goal models: An exploratory study. In: Schneider
    K, Dalpiaz F, Horkoff J (eds) 31st IEEE International Requirements Engineering
    Conference, RE, Workshops, pp 262–271, <https://doi.org/10.1109/REW57809.2023.00052>

    - <span id="page-21-9"></span>[17] Choetkiertikul M, Dam HK, Tran T, et al (2019)
    A deep learning model for estimating story points. IEEE Trans Software Eng 45(7):637–656.
    [https://doi.](https://doi.org/10.1109/TSE.2018.2792473) [org/10.1109/TSE.2018.2792473](https://doi.org/10.1109/TSE.2018.2792473)

    - <span id="page-21-6"></span>[18] Devlin J, Chang M, Lee K, et al (2019) BERT:
    pre-training of deep bidirectional transformers for language understanding. In:
    Burstein J, Doran C, Solorio T (eds) Proceedings of the 2019 Conference of the
    North American Chapter of the Association for Computational Linguistics: Human
    Language Technologies, NAACL-HLT, pp 4171–4186, <https://doi.org/10.18653/V1/N19-1423>

    - <span id="page-21-0"></span>[19] Ezzini S, Abualhaija S, Arora C, et al (2022)
    Automated handling of anaphoric ambiguity in requirements: A multi-solution study.
    In: XXXX (ed) 44th IEEE/ACM 44th International Conference on Software Engineering,
    ICSE, pp 187–199, <https://doi.org/10.1145/3510003.3510157>

    - <span id="page-21-1"></span>[20] Ezzini S, Abualhaija S, Arora C, et al (2023)
    AI-based question answering assistance for analyzing natural-language requirements.
    In: XXXX (ed) 45th IEEE/ACM International Conference on Software Engineering,
    ICSE, pp 1277–1289, <https://doi.org/10.1109/ICSE48619.2023.00113>

    - <span id="page-21-10"></span>[21] Fan Y, Arora C, Treude C (2023) Stop words
    for processing software engineering documents: Do they matter? In: 2nd IEEE/ACM
    International Workshop on Natural Language-Based Software Engineering, NLBSE@ICSE.
    IEEE, pp 40–47, <https://doi.org/10.1109/NLBSE59153.2023.00016>


    - <span id="page-22-10"></span>[22] Feurer M, Hutter F (2019) Hyperparameter Optimization,
    Springer International Publishing, Cham, pp 3–33. [https://doi.org/10.1007/978-3-030-05318-5](https://doi.org/10.1007/978-3-030-05318-5_1)
    1

    - <span id="page-22-3"></span>[23] GATE NLP Workbench (2020) GATE. URL [http://gate.ac.uk/,](http://gate.ac.uk/)
    last accessed: October 2023

    - <span id="page-22-5"></span>[24] Gomaa WH, Fahmy AA (2013) A survey of text
    similarity approaches. International Journal of Computer Applications 68(13):13–18.
    [https://doi.org/10.5120/](https://doi.org/10.5120/11638-7118) [11638-7118](https://doi.org/10.5120/11638-7118)

    - <span id="page-22-11"></span>[25] Hariri W (2023) Unlocking the potential of
    chatgpt: A comprehensive exploration of its applications, advantages, limitations,
    and future directions in natural language processing. CoRR abs/2304.02017. [https://doi.org/10.48550/ARXIV.2304.](https://doi.org/10.48550/ARXIV.2304.02017)
    [02017](https://doi.org/10.48550/ARXIV.2304.02017)

    - <span id="page-22-1"></span>[26] Jain C, Anish PR, Singh A, et al (2023) A transformer-based
    approach for abstractive summarization of requirements from obligations in software
    engineering contracts. In: Schneider K, Dalpiaz F, Horkoff J (eds) Proceedings
    of the 31st IEEE International Requirements Engineering Conference, (RE''23),
    pp 169–179, <https://doi.org/10.1109/RE57278.2023.00025>

    - <span id="page-22-0"></span>[27] Kurtanovic Z, Maalej W (2017) Automatically
    classifying functional and nonfunctional requirements using supervised machine
    learning. In: Moreira A, Ara´ujo J, Hayes J, et al (eds) 25th IEEE International
    Requirements Engineering Conference, RE, pp 490–495, <https://doi.org/10.1109/RE.2017.82>

    - <span id="page-22-7"></span>[28] Lee J, Yoon W, Kim S, et al (2020) Biobert:
    a pre-trained biomedical language representation model for biomedical text mining.
    Bioinform 36(4):1234–1240. <https://doi.org/10.1093/BIOINFORMATICS/BTZ682>

    - <span id="page-22-12"></span>[29] Liu P, Yuan W, Fu J, et al (2023) Pre-train,
    prompt, and predict: A systematic survey of prompting methods in natural language
    processing. ACM Comput Surv 55(9):195:1–195:35. <https://doi.org/10.1145/3560815>

    - <span id="page-22-8"></span>[30] L´opez JAH, Dur´a C, Cuadrado JS (2023) Word
    embeddings for model-driven engineering. In: 2023 ACM/IEEE 26th International
    Conference on Model Driven Engineering Languages and Systems (MODELS), pp 151–161,
    [https://doi.org/](https://doi.org/10.1109/MODELS58315.2023.00036) [10.1109/MODELS58315.2023.00036](https://doi.org/10.1109/MODELS58315.2023.00036)

    - <span id="page-22-2"></span>[31] Luitel D, Hassani S, Sabetzadeh M (2023) Using
    language models for enhancing the completeness of natural-language requirements.
    In: Ferrari A, Penzenstadler B (eds) Requirements Engineering: Foundation for
    Software Quality - 29th International Working Conference, REFSQ, pp 87–104, [https://doi.org/10.1007/](https://doi.org/10.1007/978-3-031-29786-1_7)
    [978-3-031-29786-1](https://doi.org/10.1007/978-3-031-29786-1_7) 7

    - <span id="page-22-4"></span>[32] Manning CD, Surdeanu M, Bauer J, et al (2014)
    The stanford corenlp natural language processing toolkit. In: Proceedings of the
    52nd Annual Meeting of the Association for Computational Linguistics, ACL, pp
    55–60, [https://doi.org/10.](https://doi.org/10.3115/V1/P14-5010) [3115/V1/P14-5010](https://doi.org/10.3115/V1/P14-5010)

    - <span id="page-22-9"></span>[33] Mavin A (2012) Listen, then use EARS. IEEE
    Softw 29(2):17–18. [https://doi.](https://doi.org/10.1109/MS.2012.36) [org/10.1109/MS.2012.36](https://doi.org/10.1109/MS.2012.36)

    - <span id="page-22-6"></span>[34] Mikolov T, Chen K, Corrado G, et al (2013)
    Efficient estimation of word representations in vector space. In: Bengio Y, LeCun
    Y (eds) 1st International Conference on Learning Representations, ICLR, URL <http://arxiv.org/abs/1301.3781>

    - <span id="page-23-8"></span>[35] Nema P, Anthonysamy P, Taft N, et al (2022)
    Analyzing user perspectives on mobile app privacy at scale. In: 44th IEEE/ACM
    44th International Conference on Software Engineering, ICSE, pp 112–124, [https://doi.org/10.1145/3510003.](https://doi.org/10.1145/3510003.3510079)
    [3510079](https://doi.org/10.1145/3510003.3510079)

    - <span id="page-23-3"></span>[36] Pennington J, Socher R, Manning CD (2014) Glove:
    Global vectors for word representation. In: Moschitti A, Pang B, Daelemans W (eds)
    Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing,
    EMNLP, pp 1532–1543, <https://doi.org/10.3115/V1/D14-1162>

    - <span id="page-23-2"></span>[37] Princeton University (2010) About WordNet.
    URL [https://wordnet.princeton.](https://wordnet.princeton.edu/) [edu/,](https://wordnet.princeton.edu/)
    last accessed: March 2019

    - <span id="page-23-4"></span>[38] Radford A, Narasimhan K, Salimans T, et al
    (2018) Improving language understanding by generative pre-training. OpenAI URL
    [https://api.semanticscholar.](https://api.semanticscholar.org/CorpusID:49313245)
    [org/CorpusID:49313245](https://api.semanticscholar.org/CorpusID:49313245)

    - <span id="page-23-5"></span>[39] Raschka S (2018) Model evaluation, model selection,
    and algorithm selection in machine learning. CoRR abs/1811.12808. URL <http://arxiv.org/abs/1811.12808>

    - <span id="page-23-9"></span>[40] Reinhartz-Berger I, Kemelman M (2020) Extracting
    core requirements for software product lines. Requir Eng 25(1):47–65. [https://doi.org/10.1007/](https://doi.org/10.1007/S00766-018-0307-0)
    [S00766-018-0307-0](https://doi.org/10.1007/S00766-018-0307-0)

    - <span id="page-23-1"></span>[41] Salda˜na J (2015) The coding manual for qualitative
    researchers. Sage Publications, Thousand Oaks, CA, USA, URL [https://us.sagepub.com/en-us/nam/](https://us.sagepub.com/en-us/nam/the-coding-manual-for-qualitative-researchers/book273583)
    [the-coding-manual-for-qualitative-researchers/book273583](https://us.sagepub.com/en-us/nam/the-coding-manual-for-qualitative-researchers/book273583)

    - <span id="page-23-6"></span>[42] Shabtai A, Elovici Y, Rokach L (2012) A Survey
    of Data Leakage Detection and Prevention Solutions. Springer, <https://doi.org/10.1007/978-1-4614-2053-8>

    - <span id="page-23-0"></span>[43] Sleimi A, Sannier N, Sabetzadeh M, et al (2021)
    An automated framework for the extraction of semantic legal metadata from legal
    texts. Empir Softw Eng 26(3):43. <https://doi.org/10.1007/S10664-020-09933-5>

    - <span id="page-23-10"></span>[44] Sorbo AD, Panichella S, Alexandru CV, et al
    (2016) What would users change in my app? summarizing app reviews for recommending
    software changes. In: Zimmermann T, Cleland-Huang J, Su Z (eds) Proceedings of
    the 24th ACM SIG-SOFT International Symposium on Foundations of Software Engineering,
    FSE, pp 499–510, <https://doi.org/10.1145/2950290.2950299>

    - <span id="page-23-11"></span>[45] White J, Fu Q, Hays S, et al (2023) A prompt
    pattern catalog to enhance prompt engineering with chatgpt. CoRR abs/2302.11382.
    [https://doi.org/10.](https://doi.org/10.48550/ARXIV.2302.11382) [48550/ARXIV.2302.11382](https://doi.org/10.48550/ARXIV.2302.11382)

    - <span id="page-23-7"></span>[46] Witten IH, Frank E, Hall MA (2011) Data mining:
    practical machine learning tools and techniques, 3rd Edition. Morgan Kaufmann,
    Elsevier, URL [https://](https://www.worldcat.org/oclc/262433473) [www.worldcat.org/oclc/262433473](https://www.worldcat.org/oclc/262433473)'
- id: what_is_an_app_store_the_software_engineering_perspective_wenhan_zhu_sebastian_proksch_daniel_m_german_michael_w_godfrey_li_li_shane_mcintosh
  title: What Is an App Store? The Software Engineering Perspective
  abstract: "\"App stores\" are online software stores where end users may browse,\
    \ purchase,\ndownload, and install software applications. By far, the best known\
    \ app stores\nare associated with mobile platforms, such as Google Play for Android\
    \ and\nApple's App Store for iOS. The ubiquity of smartphones has led to mobile\
    \ app\nstores becoming a touchstone experience of modern living. However, most\
    \ of app\nstore research has concentrated on properties of the apps rather than\
    \ the\nstores themselves. Today, there is a rich diversity of app stores and these\n\
    stores have largely been overlooked by researchers: app stores exist on many\n\
    distinctive platforms, are aimed at different classes of users, and have\ndifferent\
    \ end-goals beyond simply selling a standalone app to a smartphone\nuser.\n  We\
    \ survey and characterize the broader dimensionality of app stores, and\nexplore\
    \ how and why they influence software development practices, such as\nsystem design\
    \ and release management. We begin by collecting a set of app store\nexamples\
    \ from web search queries. By analyzing and curating the results, we\nderive a\
    \ set of features common to app stores. We then build a dimensional\nmodel of\
    \ app stores based on these features, and we fit each app store from our\nweb\
    \ search result set into this model. Next, we performed unsupervised\nclustering\
    \ to the app stores to find their natural groupings. Our results\nsuggest that\
    \ app stores have become an essential stakeholder in modern software\ndevelopment.\
    \ They control the distribution channel to end users and ensure that\nthe applications\
    \ are of suitable quality; in turn, this leads to developers\nadhering to various\
    \ store guidelines when creating their applications. However,\nwe found the app\
    \ stores operational model could vary widely between stores, and\nthis variability\
    \ could in turn affect the generalizability of existing\nunderstanding of app\
    \ stores."
  url: http://arxiv.org/abs/2401.04287v1
  keywords: ''
  document: "# What is an App Store? The Software Engineering Perspective\n\nWenhan\
    \ Zhu · Sebastian Proksch · Daniel M. German · Michael W. Godfrey · Li Li · Shane\
    \ McIntosh\n\nAuthor pre-print copy. The final publication is available at Springer\
    \ via: https://doi.org/ 10.1007/s10664-023-10362-3\n\nAbstract \"App stores\"\
    \ are online software stores where end users may browse, purchase, download, and\
    \ install software applications. By far, the best known app stores are associated\
    \ with mobile platforms, such as Google Play for Android and Apple's App Store\
    \ for iOS. The ubiquity of smartphones has led to mobile app stores becoming a\
    \ touchstone experience of modern living. App stores have been the subject of\
    \ many empirical studies. However, most of this research has concentrated on properties\
    \ of the apps rather than the stores themselves. Today, there is a rich diversity\
    \ of app stores and these stores have largely been overlooked by researchers:\
    \ app stores exist on many distinctive platforms, are aimed at different classes\
    \ of users, and have different end-goals beyond simply selling a standalone app\
    \ to a smartphone user.\n\nThe goal of this paper is to survey and characterize\
    \ the broader dimensionality of app stores, and to explore how and why they influence\
    \ software development practices, such as system design and release management.\
    \ We begin by collecting a set of app store examples from web search queries.\
    \ By analyzing and curating the results, we derive a set of features common to\
    \ app stores. We then build a dimensional model of app stores based on these features,\
    \ and we fit each app store from our web search result set into this model.\n\n\
    Wenhan Zhu · Michael W. Godfrey · Shane McIntosh\n\nSebastian Proksch Delft University\
    \ of Technology, Delft, Netherlands E-mail: s.proksch@tudelft.nl\n\nSchool of\
    \ Software, Beihang University, Beijing, China\n\nDaniel M. German Department\
    \ of Computer Science, University of Victoria, Victoria, Canada E-mail: dmg@uvic.ca\n\
    \nLi Li\n\nE-mail: lilicoding@ieee.org\n\narXiv:2401.04287v1 [cs.SE] 8 Jan 2024\n\
    \nDavid R. Cheriton School of Computer Science, University of waterloo, Waterloo,\
    \ Canada E-mail: {w65zhu, migod, shane.mcintosh}@uwaterloo.ca\n\nNext, we performed\
    \ unsupervised clustering to the app stores to find their natural groupings. Our\
    \ results suggest that app stores have become an essential stakeholder in modern\
    \ software development. They control the distribution channel to end users and\
    \ ensure that the applications are of suitable quality; in turn, this leads to\
    \ developers adhering to various store guidelines when creating their applications.\
    \ However, we found the app stores' operational model could vary widely between\
    \ stores, and this variability could in turn affect the generalizability of existing\
    \ understanding of app stores.\n\nKeywords app store, software release, software\
    \ distribution, empirical software engineering\n\n# 1 Introduction\n\nThe widespread\
    \ proliferation of smartphones and other mobile devices in recent years has in\
    \ turn produced an immense demand for applications that run on these platforms.\
    \ In response, online \"app stores\" such as Google Play and Apple's App Store\
    \ have emerged to facilitate the discovery, purchasing, installation, and management\
    \ of apps by users on their mobile devices. The success of mobile app stores has\
    \ enabled a new and more direct relationship between app creators and users. The\
    \ app store serves as a conduit between software creators (often, developers)\
    \ and their users, with some mediation provided by the app store. The app store\
    \ provides a \"one-stop shopping\" experience for users, who can compare competing\
    \ products and read reviews of other users. The app store might also acts as a\
    \ quality gatekeeper for the platform, providing varying levels of guarantees\
    \ about the apps, such as easy installation and removal, expected functionality,\
    \ and malware protection. To the software creator, the app store provides a centralized\
    \ marketplace for their app, where potential users can find, purchase, and acquire\
    \ the app easily; the app store also relieves the developer from basic support\
    \ problems related to distribution and installation, since apps must be shown\
    \ to install easily during the required approval process. Indeed, one of the key\
    \ side effects of mobile app stores is that it has forced software developers\
    \ to streamline their release management practices and ensure hassle-free deployment\
    \ at the user's end.\n\nThe success of mobile app stores has also led to the establishment\
    \ of a plethora of other kinds of app store, often for non-mobile platforms, serving\
    \ diverse kinds of user communities, offering different kinds of services, and\
    \ using a variety of monetization strategies. Many technical platforms now operate\
    \ in a store-centric way: essential services and functionality are provided by\
    \ the platform while access to extensions/add-ons is offered only through interaction\
    \ with the app store. For instance, Google Play, the app store, operates on top\
    \ of the technical platform Android, which provides the runtime environment for\
    \ the applications. When new technical platforms are introduced, an app store\
    \ is often expected to serve as a means to host and deliver products to its users\
    \ [1]. Example technical platforms that use app store-like approaches\n\ninclude\
    \ Steam [2], GitHub Marketplace [3], the Chrome Web Store [4], Word-Press [5],\
    \ AutoDesk [6], DockerHub [7], Amazon Web Services (AWS) [8], Homebrew [9], or\
    \ Ubuntu Packages [10].\n\nFor platforms that operate in this way, the app store\
    \ is an essential part of the platform's design. For example, consider source\
    \ code editors, such as VSCode and IntelliJ. The tool itself — which we consider\
    \ to be a technical platform in this context — offers the essential functionality\
    \ of a modern source code editor; however, many additional services are available\
    \ through the associated app store that are not included by default. Thus, extensions\
    \ that allow for language-specific syntax highlighting or version control integration\
    \ must be added manually by the user through interaction with the tool's app store.\
    \ We conjecture that the app store has fundamentally changed how some classes\
    \ of software systems are designed, from the overall ecosystem architecture of\
    \ the technical platform to the way in which add-ons are engineered to fit within\
    \ its instances.\n\nIn this work, we will explore the general space of app stores,\
    \ and also consider how app store-centric design can affect software development\
    \ practices. Previous research involving app stores has focused mainly on mobile\
    \ app stores, often concentrating on properties of the apps rather than properties\
    \ of the stores. For example, Harman et al. performed one of the first major studies\
    \ of app stores in 2012, focusing on the BlackBerry App World [11]. However, concentrating\
    \ the investigative scope so narrowly may lead to claims that do not generalize\
    \ well across the space of all app stores. For example, Lin et al. found that\
    \ reviews of games that appeared in mobile app stores differed significantly from\
    \ the reviews of the same game that appeared within the Steam platform's own app\
    \ store [12]. In our work, we aim to take a more holistic approach to studying\
    \ app stores by considering both mobile and non-mobile variants. In so doing,\
    \ we hope to create a more general model of app stores that fits this broader\
    \ space.\n\nTo achieve a holistic view, we start from the definition of an app\
    \ store. A precise definition of the term \"app store\" has been omitted in much\
    \ of the previous research in this area. Currently, Google Play and Apple's App\
    \ Store dominate the market and are the main targets of research on app stores;\
    \ in the past, the BlackBerry App World and Microsoft's Windows Phone Store were\
    \ also important players, but these stores are now defunct.<sup>1</sup> Wikipedia\
    \ recognizes Electronic AppWrapper [13] as the first true platform-specific electronic\
    \ marketplace for software applications, but the term became popular when Apple\
    \ introduced its App Store along with the iPhone 3G in 2008. Since then, the term\
    \ has largely come to refer to any centralized store for mobile applications.\
    \ We present our own working definition of the term \"app store\" in Sec. 2.4.\n\
    \nThe goal of this work is to survey and characterize the broader dimensionality\
    \ of app stores, and also to explore how and why they may feed back into software\
    \ development practices, such as release management. As a step toward\n\n<sup>1</sup>\
    \ The Windows Phone Store was absorbed into the broader Windows Store in 2015.\n\
    \nthis goal, we focus on two research questions (RQs) that aim to explore the\
    \ space of app stores:\n\n# RQ1: What fundamental features describe the space\
    \ of app stores?\n\nTo understand app stores, we first need a way to describe\
    \ them. It would be especially useful if this description framework would highlight\
    \ the similarities and differences of app stores. We start by collecting a set\
    \ of app store examples, and then extract from them a set of features that illustrate\
    \ important differences between them. We then expand this list of app stores with\
    \ search queries to derive a larger set of example stores. We explicitly seek\
    \ generalized web queries to broaden our search space beyond the common two major\
    \ mobile app stores of Apple and Google. By combining the web queries and the\
    \ initial set of app stores, we selected a representative set of app stores and\
    \ extracted their features. In the end, we first surveyed app stores and derived\
    \ a feature-based model to describe them; we then expanded the set of app stores\
    \ through web queries; and finally, we extracted features based on the model for\
    \ a representative set of app stores.\n\n#### RQ2: Are there groups of stores\
    \ that share similar features?\n\nDespite the ability to describe individual stores,\
    \ it is also important to understand the relationships between different stores.\
    \ Having a understanding of the natural groupings can help us gain insights into\
    \ the understanding of the generalizability of results gathered for different\
    \ app stores. We perform a K-means [14] clustering based on the extracted features\
    \ of the expanded set of app stores collected previously. The optimal k value\
    \ is determined by the Silhouette method [15]. The clustering results suggest\
    \ that there are 8 groups in the expanded set of app stores. The differences can\
    \ be observed in the type of application offered, standalone or extension, and/or\
    \ type of operation, business or community-oriented.\n\nIn this study, we make\
    \ several contributions towards a better understanding of the app store ecosystem.\n\
    \n- We identified a set of descriptive features that can be used to characterize\
    \ app stores.\n- We identified a set of 291 app stores and mapped 53 of them into\
    \ the feature space.\n- We identified 8 coherent groups of app stores based on\
    \ the similarity of features.\n- We discuss our insights on how the features and\
    \ the diversity of app stores can impact software engineering practices.\n\nOverall,\
    \ our study contributes towards a holistic view of app stores within software\
    \ engineering, which can form the basis for subsequent study of app stores in\
    \ general.\n\n# 2 Background and Related Work\n\n#### 2.1 Early App Store Research\n\
    \nTo date, research in this area has concentrated on a narrow set of app stores\
    \ that primarily involves mobile platforms. Harman et al. [11] proposed app stores\
    \ as a valid kind of software repository worthy of formal study within the broader\
    \ research area of mining software repositories; while their work was not specific\
    \ to mobile app stores, they used BlackBerry App World as their canonical example.\
    \ Ruiz et al. [16] studied the topic of reuse within app stores, focusing their\
    \ work on Android Marketplace. 2 In both cases, these early works did not provide\
    \ a formal definition of \"app store\", and tacitly used only app stores for mobile\
    \ platforms in their studies.\n\nIn their 2016 survey on app store research, Martin\
    \ et al. [17] observed that studies have often focused on only a few specific\
    \ app stores, and have ignored comparisons between app stores. In a recent literature\
    \ survey, Dąbrowski et al. [18] found the median number of app stores studied\
    \ to be 1, with the maximum being 3. We also note that results from one app store\
    \ study may not generalize to another store since the two stores may differ in\
    \ significant ways; for example, if a store does not allow users to provide their\
    \ own reviews of the apps within the store, app creators will have to rely on\
    \ other means to gain popularity and trust from users, such as promotion outside\
    \ of the app store. The same trend can be observed in more specific app store\
    \ topics such as app reviews; for example, Lin et al. [12] found that reviews\
    \ of games within the Steam app store can be dramatically different from reviews\
    \ of the same game in mobile app stores.\n\nExisting work has yet to explore the\
    \ full diversity of app stores, concentrating on Google Play and Apple's App Store,\
    \ and largely ignoring those such as Steam, AWS, and GitHub Marketplace that are\
    \ not specific to mobile platforms. With the heterogeneity of app stores and their\
    \ typical uses, we believe that the research in this area can be strengthened\
    \ by expanding the breadth to encompass a more diverse perspective on app stores;\
    \ in turn, this breadth can help to validate the generalizability of the study\
    \ findings.\n\n#### 2.2 App Stores in Recent Software Engineering Research\n\n\
    To better understand the involvement of app stores in recent research, we reviewed\
    \ relevant recent papers from the two flagship software engineering research conferences:\
    \ the ACM/IEEE International Conference on Software Engineering (\"ICSE\") and\
    \ the ACM SIGSOFT International Symposium on the Foundations of Software Engineering\
    \ (\"FSE\") We used Google Scholar to find papers containing the keyword \"app\
    \ store\" between January 2020 and April 2022 for the two conferences. We found\
    \ a total of 34 such papers (listed in Table 2.1). After reading through all of\
    \ them, we found that each paper\n\n<sup>2</sup> Android Marketplace has since\
    \ been re-branded as Google Play.\n\nfit into one of two broad categories: mining\
    \ software applications (20/34) and mining app store artifacts (14/34). We note\
    \ that our efforts do not constitute a comprehensive literature survey; instead,\
    \ our goal was to gain an overview of how app stores are involved in recent research,\
    \ and why app stores matter in their context.\n\n| Loc                  | Paper\
    \                                                                            \
    \                                                                       | Store\
    \                                         |\n|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------|\n\
    |                      | Mining software applications                        \
    \                                                                            \
    \                        |                                               |\n|\
    \ ICSE '21             | Atvhunter: Reliable version detection of third-party\
    \ libraries for vulnerability<br>identification in android applications [19] \
    \                        | Google Play                                   |\n|\
    \ ICSE '20             | How does misconfiguration of analytic services compromise\
    \ mobile privacy? [20]                                                       \
    \                   | Google Play                                   |\n| FSE '21\
    \              | Algebraic-datatype taint tracking, with applications to understanding\
    \ Android<br>identifier leaks [21]                                           \
    \       | Google Play                                   |\n| FSE '20         \
    \     | Code recommendation for exception handling [22]                      \
    \                                                                            \
    \       | Google Play                                   |\n| FSE '20         \
    \     | Static asynchronous component misuse detection for Android applications\
    \ [23]                                                                       \
    \     | F-Droid, Google Play, Wan<br>doujia App Store |\n| ICSE '21          \
    \   | Sustainable Solving: Reducing The Memory Footprint of IFDS-Based Data Flow<br>Analyses\
    \ Using Intelligent Garbage Collection [24]                        | Google Play\
    \                                   |\n| ICSE '22             | DescribeCtx: Context-Aware\
    \ Description Synthesis for Sensitive Behaviors in Mo<br>bile Apps [25]      \
    \                                                  | Google Play             \
    \                      |\n| ICSE '20             | Time-travel testing of android\
    \ apps [26]                                                                  \
    \                                              | Google Play                 \
    \                  |\n| ICSE '20             | An empirical assessment of security\
    \ risks of global android banking apps [27]                                  \
    \                                         | Play, APKMonk,<br>Google<br>and others\
    \        |\n| ICSE '21             | Too Quiet in the Library: An Empirical Study\
    \ of Security Updates in Android<br>Apps' Native Code [28]                   \
    \                                | Google Play                               \
    \    |\n| ICSE '20             | Accessibility issues in android apps: state of\
    \ affairs, sentiments, and ways for<br>ward [29]                             \
    \                              | Google Play                                 \
    \  |\n| ICSE '21             | Don't do that! hunting down visual design smells\
    \ in complex uis against design<br>guidelines [30]                           \
    \                            | Android                                       |\n\
    | ICSE '21             | Identifying and characterizing silently-evolved methods\
    \ in the android API [31]                                                    \
    \                     | Google Play                                   |\n| ICSE\
    \ '21             | Layout and image recognition driving cross-platform automated\
    \ mobile test<br>ing [32]                                                    \
    \               | Apple's App Store, Google<br>Play             |\n| FSE '21 \
    \             | An empirical study of GUI widget detection for industrial mobile\
    \ games [33]                                                                 \
    \            | Android Games                                 |\n| ICSE '21   \
    \          | Fine with \"1234\"? An Analysis of SMS One-Time Password Randomness\
    \ in An<br>droid Apps [34]                                                   \
    \           | Play,<br>Tencent<br>Google<br>Myapp           |\n| ICSE '21    \
    \         | IMGDroid: Detecting Image Loading Defects in Android Applications\
    \ [35]                                                                       \
    \           | Android                                       |\n| ICSE '21    \
    \         | GUIGAN: Learning to Generate GUI Designs Using Generative Adversarial\
    \ Net<br>works [36]                                                          \
    \       | Android                                       |\n| ICSE '20        \
    \     | Unblind your apps: Predicting natural-language labels for mobile gui components<br>by\
    \ deep learning [37]                                                | Google Play\
    \                                   |\n| FSE '21              | Frontmatter: mining\
    \ Android user interfaces at scale [38]                                      \
    \                                                         | Google Play      \
    \                             |\n|                      | Mining app store non-technical\
    \ attributes                                                                 \
    \                                              |                             \
    \                  |\n| ICSE '20             | Schrödinger's security: Opening\
    \ the box on app developers' security rationale [39]                         \
    \                                             | Apple's App Store, Google<br>Play\
    \             |\n| ICSE '20             | Scalable statistical root cause analysis\
    \ on app telemetry [40]                                                      \
    \                                    | Facebook App                          \
    \        |\n| ICSE '21<br>ICSE '21 | An empirical assessment of global COVID-19\
    \ contact tracing applications [41]<br>We'll Fix It in Post: What Do Bug Fixes\
    \ in Video Game Update Notes Tell | Android<br>Steam                         \
    \     |\n| ICSE '21             | Us? [42]<br>Automatically matching bug reports\
    \ with related app reviews [43]                                              \
    \                              | Google Play                                 \
    \  |\n| ICSE '21             | Prioritize crowdsourced test reports via deep screenshot\
    \ understanding [44]                                                         \
    \                    | Android                                       |\n| ICSE\
    \ '21             | A first look at human values-violation in app reviews [45]\
    \                                                                            \
    \                  | Google Play                                   |\n| ICSE '21\
    \             | Does culture matter? impact of individualism and uncertainty avoidance\
    \ on app                                                                     \
    \      | Apple's App Store                             |\n| ICSE '21         \
    \    | reviews [46]<br>COVID-19 vs social media apps: does privacy really matter?\
    \ [47]                                                                       \
    \  | Google Play, Apple's App                      |\n| ICSE '20             |\
    \ Society-oriented applications development: Investigating users' values from\
    \                                                                            \
    \ | Store<br>Google Play                          |\n| FSE '21              |\
    \ bangladeshi agriculture mobile applications [48]<br>Checking conformance of\
    \ applications against GUI policies [49]                                     \
    \ | Android                                       |\n| ICSE '21             |\
    \ Identifying key features from app user reviews [50]                        \
    \                                                                            \
    \ | Apple's App Store                             |\n| ICSE '21             |\
    \ Champ: Characterizing undesired app behaviors from user comments based on<br>market\
    \ policies [51]                                                       | Google\
    \ Play, Chinese an<br>droid app stores   |\n| ICSE '20             | Caspar: extracting\
    \ and synthesizing user stories of problems from app reviews [52]            \
    \                                                          | Apple's App Store\
    \                             |\n|                      |                    \
    \                                                                            \
    \                                                         |                  \
    \                             |\n\n> Mining software applications — App stores\
    \ have been extensively used as a mining source of software applications. In these\
    \ papers, the major focus is often on another subject and app stores provide a\
    \ source where they can collect applications for either a data source or verification\
    \ dataset. For example, Zhan et al. [19] proposed an approach to detect software\
    \ vulnerabilities in third-party libraries of Android applications. They leveraged\
    \ the app store to collect a dataset to verify the effectiveness of their approach.\
    \ In these studies, the app store is both a convenient and practical source of\
    \ data collection. However, the involvement of app stores may not be necessary\
    \ since the purpose is to gather a dataset of application. In Yang et al.'s work\
    \ [30], they leveraged Android applications from an existing dataset without the\
    \ need to collect from an app store. We argue that the importance of app stores\
    \ in these types of studies is the selection criteria used by the researchers\
    \ to collect applications from app stores. These features can include star ratings,\
    \ total downloads, and app category.\n\n> Mining app store artifacts — In these\
    \ studies, researchers focused on unique software artifacts that come from the\
    \ operation of the app stores. App stores have a much heavier involvement in these\
    \ studies compared to the previous group. App reviews is the major software artifact\
    \ the researchers focused on, where they leverage the data to identify features\
    \ of applications [50], locating bug reports [43], and detect undesired app behaviors\
    \ [51]. One interesting research practice we observed is where van der Linden\
    \ et al. [39] leveraged the developer contact information shared on app stores\
    \ to send out surveys related to security practices.\n\n#### 2.3 Store-Focused\
    \ Research\n\nAs stated above, we found that most recent research involving app\
    \ stores focuses on the applications they offer rather than on studying the app\
    \ stores themselves; in particular, most research in the domain focuses on the\
    \ development of mobile applications. Meanwhile, a few papers have specifically\
    \ considered app stores and their effects on software engineering, but again these\
    \ works focus heavily on mobile app stores.\n\nIn a recent paper, Al-Subaihin\
    \ et al. [53] interviewed developers about how app stores affect their software\
    \ engineering tasks. They found that developers often leverage the review section\
    \ from similar applications to help with understanding the expected user experience\
    \ and anticipated features. App stores also provides a kind of playground for\
    \ releasing beta version of apps to receive feedback from users. The built-in\
    \ communication channels also play a large role in informing development. The\
    \ interviews suggest that developers pay attention to viewing user requests in\
    \ app store via channels such as reviews and forums. The approval period of app\
    \ stores affects how developers plan their release. App stores introduce non-technical\
    \ challenges in the development process. Given the app store model of release,\
    \ app store-specific metrics, such as total number of downloads, are considered\
    \ highly important to developers.\n\nRunning an app store presents both technical\
    \ and non-technical challenges to the store owner. Technical challenges include\
    \ verifying that each app will install correctly, while non-technical challenges\
    \ include ensuring that the promotional information in the app's product page\
    \ adheres to store guidelines. Wang et al. [54] investigated several Android app\
    \ stores in China and compared them to Google Play. Their study showed that these\
    \ stores were much less diligent in screening the apps they offered, with a significantly\
    \ higher presence of fake, cloned, and malicious apps than Google Play.\n\nJansen\
    \ and Bloemendal surveyed the landscape of app stores from the perspective of\
    \ the business domain [55]. They selected 6 app stores — 5 mobile stores and 1\
    \ Windows store — at the time of publication (2013), and investigated each store\
    \ manually to find features (i.e., those actors can interact with) and policies\
    \ (i.e., rules, regulations and governing processes that limit the functional\
    \ reach of the features) from each app store. The actors they define are the same\
    \ as the three major stakeholders of the app store model (i.e., the store owner,\
    \ users, and developers). Our study further contributes to the understanding of\
    \ app stores. First, we studied a significantly larger set of app stores: our\
    \ methodology was focused towards the identification of as many different types\
    \ of stores as possible. In total, we studied 53 stores in various domains including\
    \ mobile, embedded systems, computer games, application add-ons, and open source\
    \ distributions and packaging systems. Second, Jansen and Bloemendal studied app\
    \ stores from the perspective of a software business; for example, in their work\
    \ they would consider features and policies on whether users are able to generate\
    \ affiliate links to earn revenue through sharing applications. In contrast, our\
    \ work focuses on app stores in the perspective of their role in the software\
    \ engineering process.\n\nIn our study, we approach app stores from a broad landscape\
    \ not limited to mobile app stores. We focus on the similarity of features offered\
    \ between stores to understand their natural groupings and discuss the challenges\
    \ in the diversity of app stores.\n\n#### 2.4 Working Definition of an App Store\n\
    \nPrevious researchers have often taken a casual approach to defining the term\
    \ \"app store\", when a definition has been provided at all. For example, in their\
    \ survey paper, Martin et al. define an app store as \"A collection of apps that\
    \ provides, for each app, at least one non-technical attribute\", with an app\
    \ defined as \"An item of software that anyone with a suitable platform can install\
    \ without the need for technical expertise\" [17]. However, we feel that this\
    \ definition is too generous. For example, consider a static website called Pat's\
    \ Apps that lists of a few of someone's (Pat's) favourite applications together\
    \ with their personalized ratings and reviews; superficially, this would satisfy\
    \ Martin et al.'s requirements as it is a collection of apps together with Pat's\
    \ own reviews (which are non-technical attributes). We feel that this kind of\
    \ \"store\" is outside our scope of study for several reasons: Pat's software\
    \ collection is not comprehensive, it is unlikely that Pat provides any technical\
    \ guarantees about quality of the apps, and a passive list of apps on a web page\
    \ does not constitute an automated \"store\".\n\n![](_page_8_Figure_1.jpeg)\n\n\
    Fig. 2.1 Three major stakeholders of most app stores\n\nJansen and Bloemendal\
    \ [55] define app store as \"An online curated marketplace that allows developers\
    \ to sell and distribute their products to actors within one or more multi-sided\
    \ software platform ecosystems.\" We note that this definition ignores that app\
    \ stores are expected to provide infrastructure for the deployment, installation,\
    \ and maintenance of the apps, which impacts the software development process.\
    \ Their model also ignores marketplaces that do not have payment mechanisms, such\
    \ as the Google Chrome Extensions store and the various open source apps stores,\
    \ where all of the software products may be free to download and install.\n\n\
    In our work, we seek to define an idea of app store beyond the well-known mobile\
    \ ones and with an emphasis on how their existence may affect the software development\
    \ cycle. Because we are focused on exploring the notion of what app stores are,\
    \ we formulate a working definition of the term; we did so to provide clear inclusion/exclusion\
    \ criteria for the candidate app stores that we discover in Sec. 3.\n\nOur working\
    \ definition was influenced by considering the three major stakeholders of the\
    \ app store model: the app creators who create and submit applications to the\
    \ store; the app stores themselves, and the organizations behind their operation\
    \ who curate the app collection and coordinate both the store and installation\
    \ mechanisms; and the end users who browse, download, review, and update their\
    \ applications through the app store (see Figure 2.1).\n\nWe thus arrived at the\
    \ following working definition for app store as an online distribution mechanism\
    \ that:\n\n- 1. offers access to a comprehensive collection of software or software-based\
    \ services (henceforth, \"apps\") that augment an existing technical infrastructure\
    \ (i.e., the runtime environment),\n- 2. is curated, i.e., provides some level\
    \ of guarantees about the apps, such as ensuring basic functionality and freedom\
    \ from malware, and\n- 3. provides an end-to-end automated \"store\" experience\
    \ for end users, where\n\t- (a) the user can acquire the app directly through\
    \ the store,\n- (b) users trigger store events, such as browsing, ordering, selecting\
    \ options, arranging payment, etc., and\n- (c) the installation process is coordinated\
    \ automatically between the store and the user's own instance of the technical\
    \ platform.\n\nWe can see that using this working definition, our Pat's Apps example\
    \ fails to meet all three of our main criteria.\n\nWe note that our working definition\
    \ above evolved during our investigations; it represents our final group consensus\
    \ on what is or is not an app store for the purposes of doing the subsequent exploratory\
    \ study. The steps by which the representation is finalized are discussed in Sec.\
    \ 3.1.2. For example, our working definition implicitly includes package managers\
    \ such as the Debian-Linux apt tool and Javascript's NPM tool. It is true that\
    \ package managers are typically non-commercial, and so are \"stores\" only in\
    \ a loose sense of the term; furthermore, they usually lack a mechanism for easy\
    \ user browsing of apps and do not provide a facility for user reviews. However,\
    \ at the same time, they are a good fit conceptually: they tend to be comprehensive,\
    \ curated, and offer an automated user experience for selection and installation.\
    \ Furthermore, some package managers serve as the backend to a more traditional\
    \ store-like experience; for example, the Ubuntu Software Center builds on a tool\
    \ aptitude, which interacts with software repositories to provide a user experience\
    \ similar to that of Google Play.\n\n### 3 Research Methodology\n\nTo investigate\
    \ the research questions, we designed a three-stage methodology that is illustrated\
    \ in Figure 3.1. The goal of the first two stages is to answer RQ1, while the\
    \ third stage addresses RQ2.\n\nIn the first stage (Step ○1 and ○2 ) we identified\
    \ our initial list of features using a small set of well-known app stores (Apple's\
    \ App Store, Google Play, Steam etc.) In the second stage (Steps ○3 , ○4 , and\
    \ ○5 ) we methodically expanded our list to a conceptually wider ranging set of\
    \ 53 app stores. We then described these stores using the features identified\
    \ in the first stage. A major goal of this stage was to evaluate whether the set\
    \ of available features was sufficient to describe the characteristics of all\
    \ these stores. This set of features forms the answer to RQ1.\n\nIn the third\
    \ stage (Step ○6 ), we took advantage of the labeling of the 53 stores. We used\
    \ K-means clustering analysis to identify groups of stores that shared similar\
    \ features. These groupings form the answer to RQ2.\n\nWe now describe our methodology\
    \ in more detail.\n\n#### 3.1 Extracting Features Describing App Stores\n\nOur\
    \ basic assumption is that an app store can be categorized based on a finite set\
    \ of features. The features would correspond to traits of the app store where\n\
    \n![](_page_10_Figure_1.jpeg)\n\nFig. 3.1 Methodology overview: There are three\
    \ main stages, further broken down into six steps.\n\nthey describe the distinguishing\
    \ qualities or functional characteristics of the app store. We encode these features\
    \ as binary values, i.e., each store has or does not have a given feature.\n\n\
    In order to identify such features, we first created a seeding set of representative\
    \ app stores. We started by enumerating well-known app stores that we were aware\
    \ of (Step ○1 ). Once this set of representative app stores was created, we used\
    \ an iterative process to identify the features that we felt best characterized\
    \ these stores (Step ○2 ). We then used these features to describe each store.\n\
    \n#### 3.1.1 Stage 1: Identifying Features\n\nFirst, each of the six authors was\
    \ tasked with identifying representative characteristics of five stores and the\
    \ possible features for each. Each author worked alone in this step; however,\
    \ to seek better reliability as well as encourage diverse opinions, each store\
    \ was assigned to two authors. We list the 15 stores that were assigned in this\
    \ step with a short description in Table 3.1. After that, all of the authors met\
    \ as a group to discuss their findings and further refine the proposed feature\
    \ set.\n\nIn the subsequent iterations, the authors worked in pairs, and the pairings\
    \ were reassigned after each iteration (Step ○2 ). In these iterations, each authorpair\
    \ was assigned a set of 2–3 app stores and was asked to describe them using the\
    \ current set of features; a key concern was to evaluate whether the existing\
    \ features were sufficient or needed refinement. For each store, each author-pair\
    \ analyzed both its store-front and its documentation; in some cases, we could\
    \ navigate the store as users but not as developers, in these cases, we relied\
    \ on the store's supporting documentation.\n\nAfter this step, the six authors\
    \ discussed their findings as a group and updated the set of features. The features\
    \ were discussed in detail to ensure that they were conceptually independent from\
    \ each other. We also made sure that each feature applied to at least one store\
    \ to ensure that it was relevant.\n\nOur process leveraged ideas from the coding\
    \ process of Grounded theory [56] to extract the features of app stores, and followed\
    \ the practice of open card sorting [57] to create the categorized feature set.\
    \ Similar to prior work [58–60], we followed practices of Grounded theory's coding\
    \ process to extract the features— where we consider codes as a specific feature\
    \ of app store operation — and stopped when we reached saturation with no new\
    \ features added after a new round of describing app stores. Similar to prior\
    \ work [61–63], we applied card sorting to the collected features so inter-related\
    \ features are grouped together. The authors formed a group in this process and\
    \ discussed how different features belong to the same conceptual group and stopped\
    \ when consensus was reached.\n\n| Store                  | Description      \
    \                                                                            \
    \              |\n|------------------------|------------------------------------------------------------------------------------------------------------|\n\
    | Google Play Store      | Google's app store for Android                    \
    \                                                         |\n| Apple App Store\
    \        | Store for Apple devices                                           \
    \                                         |\n| Samsung GalaxyApps     | Store\
    \ specifically for Samsung devices                                           \
    \                          |\n| GitHub Marketplace     | Providing applications\
    \ and services to integrate with GitHub plat<br>form                         \
    \         |\n| Atlassian Marketplace  | Providing applications and services to\
    \ integrate with various At<br>lassian products                       |\n| Homebrew\
    \               | Package manager for MacOS                                  \
    \                                                |\n| MacPorts               |\
    \ A package manager for MacOS                                                \
    \                                |\n| Ubuntu Packages        | Software repository\
    \ for the Ubuntu Linux distribution, with a<br>official front end Ubuntu Software\
    \ Center |\n| Steam                  | Gaming focused app store running on multiple\
    \ operating systems<br>(e.g., Windows, Linux)                   |\n| Nintendo\
    \ EShop         | Provides applications for Nintendo devices (e.g., Nintendo Switch,<br>Nintendo\
    \ 3DS)                        |\n| GoG                    | Gaming focused store\
    \ focusing on providing DRM free games                                       \
    \           |\n| JetBrains Plugin Store | Provides plugins to enhance the behavior\
    \ of JetBrains IDEs                                                 |\n| VSCode\
    \ Marketplace     | Provides plugins to enhance the editor                   \
    \                                                  |\n| Chrome Web Store     \
    \  | Provides extensions to enhance Chromium based web browsers              \
    \                                   |\n| AWS Marketplace        | Provides servers\
    \ and cloud services                                                         \
    \               |\n\nTable 3.1 Investigated stores for feature extraction\n\n\
    3.1.2 Stage 2: Expanding Our Set of App Stores and Further Evaluation and Refinement\
    \ the Features\n\nOnce we had agreed on the features, our next goal was to verify\
    \ that these features were capable of describing other app stores that were not\
    \ part of the initial seed, or if features were missing or needed refinement.\
    \ We used a common search engine, Google, to expand our set of app stores in a\
    \ methodical manner (Step ○3 ). To achieve the goal of including a broad range\
    \ of yet undiscovered app stores, we first derived general search terms by combining\
    \ synonyms for \"app\" and \"store\". More specifically, we have built all possible\
    \ combinations of the following terms to construct our search queries:\n\n# First\
    \ half software, (extension -hair -lash), (addon OR add-on), solution, plugin\
    \ OR plug-in, install, app, package\n\nSecond half repository, shop, (\"app store\"\
    \ OR store), (\"market place\" OR marketplace), manager\n\nFor example, a concrete\
    \ query was created by combining app and (\"app store\" OR store). For some queries,\
    \ it was necessary to refine the term to avoid noise in the results; for example,\
    \ searching for the term extension would mainly return results related to hair\
    \ product or eye lashes. In total, with 8 synonyms for app and 5 synonyms for\
    \ store we were able to create 40 unique Google search queries. We felt confident\
    \ that these search terms were representative when we found that the initial seed\
    \ list had been exhaustively covered.\n\nOur Google search was performed in November\
    \ 2020. We queried and stored the search results for each search query. Two authors\
    \ classified each result as to whether or not it corresponded to an app store.\
    \ We devised two inclusion criteria for this decision: 1) the store in question\
    \ should offer software or software-based services, and 2) the store in question\
    \ should offer an end-toend experience for users (ordering, delivery, installation).\
    \ We considered only direct hits to the store (e.g., product page), and we explicitly\
    \ excluded results that contain only indirect references to a store, such as blog\
    \ posts, videos, or news. Any disagreements were resolved through discussion.\
    \ However, despite our initial effort of maintaining a clear set of inclusion\
    \ criteria for app stores, several corner cases became apparent during the labeling\
    \ process. The first two authors discussed these cases as they arose, and continually\
    \ updated the inclusion criteria throughout the labeling process. In a few special\
    \ cases no agreement could be reached, so another author acted as a moderator\
    \ and resolved the disagreement by a majority vote. Over time, the inclusion criteria\
    \ and features evolved and eventually reached a stable state (in Step ○3 ). Our\
    \ final state of the inclusion/exclusion criteria is presented as the working\
    \ definition for app stores defined in Sec. 2.4.\n\nThe classification of search\
    \ results was stopped when a new results page did not contain any new links to\
    \ app stores, or once all 10 retrieved pages were analyzed. Initially, 586 URLs\
    \ were examined by the first two authors until a saturation of agreement was reached\
    \ (90.7% agreement rate). The first author continued to label the rest. In the\
    \ end, a total of 1,600 URLs were labeled. Multiple search results can refer to\
    \ the same store; these duplicates were detected and eliminated by using the root\
    \ domain of the URL. The most common duplicate references were found for the domains\
    \ google. com (61), apple. com (22), and microsoft. com (18). In the end, we found\
    \ 291 stores. We note that the exact number of unique stores may differ since\
    \ two root domains can point to the same store, kodi. tv and kodi. wiki , or the\
    \ same root domain may contain multiple stores, chrome. google. com and play.\
    \ google. com .\n\nIn the next step (Step ○5 ), we constructed and labeled a set\
    \ of app stores based on our identified features from Step ○2 . We began from\
    \ the URLs labeled in the last step and selected the first three occurring stores\
    \ for each search term; this resulted in 104 URLs pointing to 48 unique stores.\
    \ Two of the stores were could not be accessed by the authors: ASRock App Shop\
    \ requires physical hardware to use it, and PLCnext Store's website was unresponsive\
    \ at the time of labeling. These stores were removed from the list. In addition,\
    \ we discussed several more stores that we felt deserved explicit investigation:\
    \ AWS, Flatpak, GoG, MacPorts, Nintendo eShop, Steam, and Samsung's Galaxy Store.\
    \ These are the stores that the authors investigated in Step ○2 but did not show\
    \ up in the first three occurring results from the search terms. Meanwhile, the\
    \ added stores all show up in the list of 291 stores identified by all labeled\
    \ URLs.\n\nWe thus selected and labeled a total of 53 app stores. This sample\
    \ is nonexhaustive, but we believe that our wide range of search queries has created\
    \ a representative sample of the population of app stores that enables our experiments.\n\
    \nThe first two authors proceeded to describe 12 app stores, selected as the first\
    \ from each search query, using the set of features. This was done to make sure\
    \ there was consistency in the interpretation and use of each feature. After that,\
    \ the first author labeled the remaining stores.\n\nTo check the applicability\
    \ of our dimensions and the labeling guidelines, we have measured the inter-rater\
    \ agreement between two authors on the 12 stores. We used the Cohen's Kappa [64]\
    \ as a measurement for our inter-rater agreement. The Cohen's Kappa is widely\
    \ used in software engineering research [65]. We have reached an agreement of\
    \ 86.3% with Cohen's Kappa [64] of 0.711). Our agreement based on the Cohen's\
    \ Kappa is considered as a substantial [66] inter-rater agreement suggesting a\
    \ high confidence of agreement between the two raters.\n\nThe outcomes of RQ1\
    \ were a list of features that describe the main characteristics of app stores\
    \ grouped by dimensions, and a set of 53 App Stores, each labeled using these\
    \ features.\n\n#### 3.2 Finding Natural Groupings of App Stores\n\nWith the outcomes\
    \ of RQ1, we next performed a K-means clustering analysis to identify groups of\
    \ similar stores. K-means is a well known clustering algorithm widely used in\
    \ software engineering research [67–70]. It groups vectorized data points iteratively\
    \ until k centroids are formed. We used the K-means++ implementation [71] to conduct\
    \ the clustering process.\n\n#### 3.2.1 Stage 3: Cluster Analysis\n\nTo identify\
    \ related app stores, we decided to cluster them using the K-means algorithm (Step\
    \ ○6 ).\n\nTo prepare our labels for the K-means clustering process, we converted\
    \ each label of the feature to a binary value: 1 if the store has the feature,\
    \ and 0 if it does not. Having binary-encoded data ensured that we do not suffer\
    \ from having categorical values that do not make sense in the scope of K-means.\
    \ However, performing K-means on binary data can also be problematic, since the\
    \ initial centroids selected will be binary. To mitigate this issue, we applied\
    \ Principal Component Analysis (PCA) [72] to both reduce the dimensional space\
    \ and to produce a mapping in the continuous range. We kept all principal components\
    \ that explained a variance of at least 0.05. Finally, we used the Silhouette\
    \ method [15] to determine the best number of clusters within a range of 1 to\
    \ 20. To identify the features that best characterize each cluster, we have calculated\
    \ the deviation of each cluster centroid (i.e, the center of the cluster) from\
    \ the centroid-of-centroids (C ) over all clusters.\n\nAs an unsupervised method,\
    \ the result of K-means provides only the clustering result with the stores in\
    \ each cluster. We then further discussed the results of the K-means process and\
    \ categorized the clusters by the properties of the contained stores. Following\
    \ our discussion and categorization, we assigned groupings and names to each of\
    \ the clusters.\n\n#### 4 Results\n\nIn this section, we present the results of\
    \ our investigations into each of the research questions. The results are organized\
    \ based on the three stages discussed in Sec. 3.\n\n### RQ1: What fundamental\
    \ features describe the space of app stores?\n\n#### Stage 1: Features characterizing\
    \ app stores\n\nAs discussed in Sec. 3.1, we derived a set of features and organizational\
    \ categories that describe the set of studied app stores; the results of these\
    \ efforts are summarized in Table 4.1. We have modelled the features as a binary\
    \ representation; thus, each store either has or does not have this feature. We\
    \ note that for some categories, the features are mutually exclusive; for example,\
    \ in the category Rights Management, a store can have either Creator managed DRM\
    \ or Store-enforced DRM, but not both. In other categories, an app store may have\
    \ several of the features within a given category; for example, there may be several\
    \ kinds of communication channels between users, app creators, and the store owner\
    \ for a given app store. We now describe each high-level category in detail.\n\
    \n> Monetization — describes what, if any, payment options are provided to the\
    \ user directly by the store. If a product is offered free within the store, but\
    \ requires an activation key obtained elsewhere, we consider that the product\
    \ is free. While most of the options are self-explanatory, some may be less obvious.\
    \ For example, GitHub Marketplace offers seat-based subscriptions where app pricing\
    \ is calculated by the number of installations made to individual machines; usually,\
    \ this occurs within the context of enterprise purchase. Also, AWS offers resource-based\
    \ subscription where the price charged is determined by the amount of resources\
    \ — such as cloud storage and CPU time — that are used during the execution of\
    \ the service.\n\n> Rights Management — describes the Digital Rights Management\
    \ (DRM) policy of the store; the values describe whether the store uses a store-wide\
    \ DRM feature. For example, for Steam, all games have DRM encryption, whereas\
    \ the F-Droid store contains only open source apps, so there is no need for DRM.\n\
    \n> Do I need an account? — describes whether a user can access and use the store\
    \ without being registered with the app store. We find that most stores are either\
    \ account required (e.g., Apple's App Store) or no registration possible (e.g.,\
    \ Snapcraft). However, we also found that some stores can be used without an account\
    \ for some purposes, with other features requiring explicit\n\n|  |  |  | Table\
    \ 4.1 Features for describing app stores |  |  |\n|--|--|--|----------------------------------------------|--|--|\n\
    |--|--|--|----------------------------------------------|--|--|\n\n| Feature \
    \                                               | Description                \
    \                                                                            \
    \                                                                   |\n|--------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Monetization                                           | The type of payment\
    \ options directly offered by the app store.                                 \
    \                                                                           |\n\
    | Free                                                   | Free as in in the product\
    \ can be directly acquired                                                   \
    \                                                                     |\n| One-time\
    \ payment                                       | A single payment needed for\
    \ the product                                                                \
    \                                                                   |\n| Seat-based\
    \ subscription                                | The subscription is based on the\
    \ number of products provided                                                \
    \                                                              |\n| Time-based\
    \ subscription                                | A payment is needed by a set time\
    \ interval (e.g.\" monthy, yearly)                                           \
    \                                                              |\n| Resourced-based\
    \ subscription                           | A payment is needed by the amount of\
    \ resource used (e.g., API calls, CPU time)                                  \
    \                                                          |\n| Micro-transaction\
    \                                      | Additional payment can be collected based\
    \ on additional feature offered in a product                                 \
    \                                                     |\n| Custom pricing (i.e.,\
    \ \"Contact us for price\")          | The actual price is based on a per case\
    \ situation; this happens mostly in business-focused<br>app stores           \
    \                                                       |\n| Rights Management*\
    \                                     | How does the store take care of DRM on\
    \ the product provided.                                                      \
    \                                                        |\n| Creator-managed\
    \ DRM                                    | No DRM is offered by the store and\
    \ is taken care of by the creator                                            \
    \                                                            |\n| Store-enforced\
    \ DRM                                     | Store wide DRM for every product offered\
    \ in the store                                                               \
    \                                                      |\n| Do I need an account?*\
    \                                 | Whether it is possible to use the app store\
    \ without registration.                                                      \
    \                                                   |\n| Account required    \
    \                                   | An account is required to use the store\
    \                                                                            \
    \                                                       |\n| No registration possible\
    \                               | The store does not have an account system  \
    \                                                                            \
    \                                                   |\n| Some features requires\
    \ registration                    | Some content of the store is locked behind\
    \ an account, but the store can be used without<br>one.                      \
    \                                                    |\n| Product type       \
    \                                    | The type of product the store offers. \
    \                                                                            \
    \                                                        |\n| Standalone apps\
    \                                        | The product operates by itself    \
    \                                                                            \
    \                                                            |\n| Extension/add-ons\
    \ to apps/hardware                     | The product acts as a feature extension\
    \ to another application/hardware                                            \
    \                                                       |\n| Service/resources\
    \                                      | The software product is a service   \
    \                                                                            \
    \                                                          |\n| Package/library\
    \                                        | The product is not an end-user product,\
    \ but offers functionality to other products                                 \
    \                                                       |\n| Target audience*\
    \                                       | The intended users of the app store.\
    \                                                                            \
    \                                                          |\n| General purpose\
    \                                        | The app store is intended to be used\
    \ by everyone.                                                               \
    \                                                          |\n| Domain-specific<br>Type\
    \ of product creators            | The app store have a specific focus and is\
    \ very unlikely to be used by a normal person<br>The type of creators who submits\
    \ products to the app store.                     |\n| Business               \
    \                                | The creators mostly have a commercial or business\
    \ focus                                                                      \
    \                                             |\n| Community                 \
    \                             | The creators are from the community (e.g., open\
    \ source developers)                                                         \
    \                                               |\n| Intent of app store     \
    \                               | The reason why the app store exists from the\
    \ app stores' perspective.                                                   \
    \                                                  |\n| Community building/support\
    \                             | The app store aims to serve a technical community\
    \                                                                            \
    \                                             |\n| Profit                    \
    \                             | The app store aims to earn money             \
    \                                                                            \
    \                                                 |\n| Centralization of product\
    \ delivery                     | The app store aims to provide a way for customer\
    \ to gather apps in a centralized way                                        \
    \                                              |\n| Expanding a platform popularity/usefulness\
    \             | The app store aims to extend functionality from the platform it\
    \ is based on                                                                \
    \                               |\n| Role of intermediary                    \
    \               | The role app store play between the creator of products and\
    \ the customer of the app store.                                             \
    \                                   |\n| Embedded advertisement API          \
    \                   | Provides an advertisement method for creators to take advantage\
    \ of                                                                         \
    \                               |\n| CI/CD                                   \
    \               | Offers continuous integration/continuous deployment for creators\
    \                                                                            \
    \                              |\n| Checks at run time                       \
    \              | Provide checks when apps installed from the app store is ran\
    \                                                                            \
    \                                  |\n| Checks before making available to the\
    \ customer         | Provide checks when an app is submitted to the app store\
    \ for quality reasons                                                        \
    \                                      |\n| Composability*                   \
    \                      | The relationship between products provided in the app\
    \ store.                                                                     \
    \                                         |\n| Independent<br>Vendor internal\
    \ add-on/extension/unlock | The products in the app store are unrelated to each\
    \ other<br>Some products can be based on other products from the same creator\
    \ (e.g., game DLC,                          |\n|                             \
    \                           | app feature packs)                             \
    \                                                                            \
    \                                               |\n| Package manager type of app\
    \ relationship               | A dependency relationship exists between products\
    \ in the app store                                                           \
    \                                             |\n| Analytics                 \
    \                             | The type of analytical data provided by the app\
    \ store.                                                                     \
    \                                               |\n| Sentiment and popularity\
    \ ratings                       | Information related to the popularity of a product\
    \ (e.g., downloads, score ratings)                                           \
    \                                            |\n| Marketing feedback         \
    \                            | Information related to marketing for the creator\
    \ (e.g., sales, conversion, retention)                                       \
    \                                              |\n| Product usage data<br>Communication\
    \ channels           | Information related to the usage of the product. (e.g.,\
    \ logging, user profiling)<br>The methods where different parties of the app store\
    \ can communicate with each other. |\n| Documentation                        \
    \                  | Information related to the operation of the store (e.g.,\
    \ instructions to install applications)                                      \
    \                                      |\n| Product homepage                 \
    \                      | A homepage for a specific product in the app store  \
    \                                                                            \
    \                                          |\n| Ratings                      \
    \                          | Any form of rating customers can give to a product\
    \ (e.g., star, score, up/down vote)                                          \
    \                                            |\n| Written reviews (in text)  \
    \                            | A written viewer where customers can write their\
    \ experience to the product.                                                 \
    \                                              |\n| Community forum          \
    \                              | A forum like feature offered by the store where\
    \ people can discuss things related to the                                   \
    \                                               |\n|                         \
    \                               | store/product.                             \
    \                                                                            \
    \                                                   |\n| Support ticket      \
    \                                   | A system where customers can inquiry for\
    \ support questions related to the product offered<br>by the store.          \
    \                                                      |\n| Promotion/marketing\
    \                                    | The store offers a way to provide promotional/marketing\
    \ feature to the products in the<br>app store (e.g., featured apps, top downloads\
    \ of the month).                    |\n\n\\*: Categorical values are mutually\
    \ exclusive; one and only one categorical value in the dimension can apply to\
    \ a given store.\n\nregistration; for example, the Microsoft Store allows users\
    \ to download free applications without an account, but to purchase an app or\
    \ leave a review, an account is required.\n\n> Product type — describes the kinds\
    \ of applications that are offered by the store. For example, Google Play and\
    \ Steam focus on standalone apps, the VSCode Marketplace store offers add-ons\
    \ to an existing tool, and AWS allows users to \"rent\" web-based resources and\
    \ services.\n\n> Target audience — describes the intended user base of the store.\
    \ Generalpurpose stores offer products aimed at the broad general public of everyday\
    \ technology users; this includes stores such as Google Play, Steam, and the Chrome\
    \ Web Store. Domain-specific stores, on the other hand, have a dedicated focus\
    \ on a specialized field; for example, Adobe Magento focuses on building e-commerce\
    \ platforms.\n\n> Type of product creators — describes the typical focus of creators\
    \ submitting applications to the store. We distinguish between two groups of creators:\
    \ those with a commercial or business focus, and those with community focus such\
    \ as open source developers.\n\n> Intent of app store — describes the perceived\
    \ high-level goals of the app store. The values are derived from the app stores'\
    \ own descriptions of their goals, often found in \"About us\" web pages. For\
    \ example, both F-Droid and ApkPure are Android app stores; however, F-Droid's\
    \ focus is to provide a location to download and support FOSS software, while\
    \ ApkPure's goal is to provide a location for users to be able to download Android\
    \ apps when Google Play may be unavailable.\n\n> Role of intermediary — describes\
    \ the roles that the app store plays in mediating between the users and creators;\
    \ these are software engineering-related services that are mostly independent\
    \ of each other. For example, checks at run time tracks if the app store ensures\
    \ that its products function correctly (e.g., Steam tracking game stats). Also,\
    \ CI/CD indicates that the app store provides explicit support for continuous\
    \ integration and deployment of the apps, which may be linked to specific development\
    \ tools used by the creator.\n\n> Composability — describes the relationship between\
    \ products offered by the store. App stores of independent composability offer\
    \ products that have no relationship with each other, such as Firefox Add-ons.\
    \ Vendor internal add-on/extension/unlock means that the products within the app\
    \ store can be based on each other, but only when they are from the same vendor,\
    \ such as game DLC and micro-transaction unlocks. Package managers contain apps\
    \ that can have complicated dependency relationships regardless of the creator\
    \ of the products, such as the Ubuntu package management tool apt.\n\n> Analytics\
    \ — describes what kind of diagnostic information is provided by the store. We\
    \ distinguish between three kinds: Sentiment and popularity ratings offer user-based\
    \ information related to store products, such as number of installs in Home Assistant.\
    \ Marketing feedback tracks telemetry information for creators on the performance\
    \ of their product, such as GitHub Marketplace tracking retention rate for their\
    \ products for creators. Product usage data details the observed usage of the\
    \ products; for example, Steam tracks the average number of hours users spend\
    \ on each product.\n\n> Communication channels — tracks the types of methods the\
    \ store directly offers for communications between both users and creators. Since\
    \ most stores offer a product homepage for each of their products, the app creators\
    \ are largely free to put any information here. This means that if a creator wishes,\
    \ they can put links to other communication methods external to the store. We\
    \ do not track such information here since it is product dependent instead of\
    \ store dependent. While ratings and reviews/comments are often paired together,\
    \ during our exploration, we found cases where user ratings were permitted but\
    \ user reviews were not; thus, we have separate values for ratings and reviews.\
    \ Communication channels can take various forms with different variability, for\
    \ example, some stores allow responses for reviews. For this aspect, we stay at\
    \ a high level based on the functionality of the communication channels and consider\
    \ the variations as detailed implementation for each functionality.\n\nStage 2:\
    \ Expanded collection of app stores and labeled set of representative stores\n\
    \nIn stage 1, we identified 53 store candidates. To provide the required data\
    \ for our experiments, two authors explored these stores to identify which of\
    \ the fundamental features of the previous stage are true for each store. The\
    \ query results are summarized in Table 4.2, where we list the search term construction\
    \ keywords and the first 3 occurrence of stores by the search term. For example,\
    \ in search term constructed from (addon OR add-on) and (\"market place\") OR\
    \ marketplace, the first 3 occurrences are Google Play, PrestaShop, and CS-Cart.\n\
    \nThere are many app stores beyond Google Play and Apple's App Store. These app\
    \ stores exhibit a diverse set of features.\n\n#### RQ2: Are there groups of stores\
    \ that share similar features?\n\nUsing the labeled data of the 53 stores, we\
    \ were able to perform the K-means cluster analysis that we have introduced in\
    \ Sec. 3.2. With the number of clusters guided by the Silhouette method to choose\
    \ the best K value for Kmeans, our clustering resulted in eight clusters.\n\n\
    Due to the nature of unsupervised methods, K-means is able to identify only the\
    \ clusters and their members; no real-world meanings are extracted for why the\
    \ cluster members belong together. It is also important to note that the K-means\
    \ algorithm performs hard clustering; that is, it creates a partitioning of the\
    \ stores into mutually exclusive groups that together span the whole space. Thus\
    \ each store will be assigned to the unique cluster that the algorithm considers\
    \ to best represent it. For this reason, the raw results from K-means should not\
    \ be seen as authoritative, but rather as a vehicle for identifying groups of\
    \ stores with similar characteristics. Therefore, we leverage the K-means clustering\
    \ and further examine the clusters in detail to try to derive a human understandable\
    \ categorization of the stores.\n\nWe start by analyzing the differences between\
    \ clusters by analyzing the definitive characteristics of each cluster. In Sec.\
    \ 4, we show the details of the top 10 features that deviate the most from the\
    \ C. Column C contains\n\n|                                | OR<br>store\"<br>(\"\
    app                                 | store)       | OR<br>place\"<br>marketplace)<br>(\"\
    market                             | shop                                    \
    \         | repository                                           | manager   \
    \                                |\n|--------------------------------|-------------------------------------------------------|--------------|----------------------------------------------------------------------|--------------------------------------------------|------------------------------------------------------|-------------------------------------------|\n\
    | app                            | App<br>Google Play<br>Apple               \
    \            | Store,       | Google<br>BigCommerce,<br>HubSpot<br>Play,     \
    \                      | Store<br>Apple App                               | Guardian<br>IzzyOn-<br>F-Droid,<br>Project,<br>Droid\
    \ | Google Play                               |\n| software                  \
    \     | Store<br>Mac App                                      |              |\
    \ Sella-<br>MarketPlaceKit,<br>CS-Cart<br>cious,                       | ϕ   \
    \                                             | ϕ                            \
    \                        | ϕ                                         |\n| add-on)<br>OR<br>(addon\
    \        | Firefox<br>Store,<br>App<br>Assistant,<br>Mac         | Home<br>Add-\
    \ | Play,<br>CS-Cart<br>PrestaShop,<br>Google                            | PrestaShop,\
    \ Chrome<br>Store<br>Web               | Kodi                                \
    \                 | Ajour,<br>CurseForge,<br>Minion           |\n|           \
    \                     | ons                                                  \
    \ |              |                                                           \
    \           |                                                  |             \
    \                                         |                                  \
    \         |\n| plug-in)<br>OR<br>(plugin      | SketchUca-<br>THETA<br>RICOH<br>Google\
    \ Play,<br>tion, |              | JetBrains<br>WordPress,                    \
    \                          | Bou-<br>Plugin<br>Bukkit,<br>tique              \
    \ | Jet-<br>WordPress,<br>Brains                         | JMeter,<br>Autodesk<br>Jenkins,\
    \           |\n| -lash)<br>-hair<br>(extension  | Store,<br>Web<br>Edge<br>Chrome<br>crosoft\
    \            | Mi-          | Market-<br>Magento,<br>Adobe<br>Chrome Web<br>VSCode<br>place,\
    \       | Store<br>Chrome Web                              | GNOME<br>TYPO3,<br>SHELL\
    \                             | Store<br>Chrome Web                       |\n\
    | install                        | Apple<br>Play,<br>Google<br>Store         \
    \            | App          | Eclipse<br>Store<br>Google Play,               \
    \                      | Store,<br>Mi-<br>Play,<br>App<br>Google<br>Apple | Assis-<br>DockerHub<br>Home<br>Kodi,<br>tant,\
    \        | AP-<br>Daz3D<br>Play,<br>Google<br>KPure, |\n|                    \
    \            |                                                       |       \
    \       |                                                                    \
    \  | Store<br>crosoft                                 |                      \
    \                                |                                           |\n\
    | solution                       | Store,<br>Store<br>App<br>crosoft<br>Mac  \
    \            | Mi-          | CS-Cart                                        \
    \                      | ϕ                                                | ϕ\
    \                                                    | ϕ                     \
    \                    |\n| -book)<br>library<br>(software | Store<br>Microsoft\
    \                                    |              | GitHub<br>Marketplace,<br>Extensions,<br>Marketplace<br>VSCode<br>QT\
    \ | ϕ                                                | ϕ                     \
    \                               | ϕ                                         |\n\
    | package                        | Snapcraft<br>App<br>Google Play,<br>Apple \
    \            | Store,       | concrete5<br>CS-Cart,                          \
    \                      | Google Play                                      | PyPI,<br>Ubuntu\
    \ Packages<br>Packagist,               | NPM,<br>Chocolatey,<br>NuGet        \
    \      |\n\nTable 4.3 The 8 clusters found by the K-means algorithm, with top\
    \ deviated features from the centroid of centroids (C). Each cell with a value\
    \ represents one of the ten most influential features of the corresponding cluster.\
    \ The number indicates the percentage of stores with the specific feature. The\
    \ color encodes whether stores in that cluster are less (magenta) or more (green)\
    \ likely to have the feature, compared to the centroid.\n\n|                 \
    \                      |      |      |      |      |      | Cluster Index |  \
    \    |      |      |\n|---------------------------------------|------|------|------|------|------|---------------|------|------|------|\n\
    | Features                              | C    | 1    | 2    | 3    | 4    | 5\
    \             | 6    | 7    | 8    |\n| Monetization                         \
    \ |      |      |      |      |      |               |      |      |      |\n\
    | Free                                  | 1.00 |      |      |      |      | \
    \              |      |      |      |\n| One-time payment                    \
    \  | 0.35 | 0.00 |      | 0.00 | 0.00 |               |      |      | 1.00 |\n\
    | Seat-based subscription               | 0.09 |      | 0.50 |      |      | \
    \              |      |      |      |\n| Time-based subscription             \
    \  | 0.30 |      | 0.75 | 0.00 |      |               |      |      | 0.86 |\n\
    | Resource-based subscription           | 0.05 |      |      |      |      | \
    \              |      |      |      |\n| Micro-transactions                  \
    \  | 0.11 |      |      |      |      |               |      |      | 0.86 |\n\
    | Custom Pricing                        | 0.01 |      |      |      |      | \
    \              |      |      |      |\n| Rights Management                   \
    \  |      |      |      |      |      |               |      |      |      |\n\
    | Creator managed DRM                   | 0.72 |      | 0.25 | 1.00 |      | \
    \              |      |      | 0.14 |\n| Store-enforced DRM                  \
    \  | 0.27 |      | 0.75 |      |      |               |      |      | 0.86 |\n\
    | Do I need an account to use the store |      |      |      |      |      | \
    \              |      |      |      |\n| Account Required                    \
    \  | 0.33 |      |      | 0.00 |      | 0.75          | 1.00 |      | 0.86 |\n\
    | No registration possible              | 0.35 | 1.00 | 0.00 |      | 0.00 | \
    \              | 0.00 | 1.00 |      |\n| Some features require registration  \
    \  | 0.30 |      | 1.00 |      | 1.00 |               |      |      |      |\n\
    | Product Type                          |      |      |      |      |      | \
    \              |      |      |      |\n| Standalone apps                     \
    \  | 0.42 |      | 0.00 |      |      |               |      | 1.00 |      |\n\
    | Extension/add-ons to apps/hardware    | 0.68 | 0.33 |      |      |      | \
    \              |      | 0.00 |      |\n| Service/Resources                   \
    \  | 0.08 |      |      |      |      |               |      |      |      |\n\
    | Package/Library                       | 0.17 | 0.89 |      |      |      | \
    \              |      |      |      |\n| Target audience                     \
    \  |      |      |      |      |      |               |      |      |      |\n\
    | General purpose                       | 0.33 |      |      | 0.00 | 0.83 | \
    \              | 0.00 | 1.00 |      |\n| Domain-specific                     \
    \  | 0.67 |      |      | 1.00 | 0.17 |               | 1.00 | 0.00 |      |\n\
    | Type of product creators              |      |      |      |      |      | \
    \              |      |      |      |\n| Business                            \
    \  | 0.67 | 0.22 |      | 0.00 |      |               | 1.00 |      |      |\n\
    | Community                             | 0.67 |      |      | 1.00 |      | \
    \              | 0.11 |      |      |\n| Intent of app store                 \
    \  |      |      |      |      |      |               |      |      |      |\n\
    | Community building / support          | 0.52 |      | 1.00 |      | 1.00 | 0.00\
    \          | 0.11 |      |      |\n| Profit                                | 0.38\
    \ | 0.00 |      | 0.00 | 0.00 |               | 0.78 | 0.00 | 1.00 |\n| Centralization\
    \ of product delivery    | 0.84 |      |      |      |      |               |\
    \      |      |      |\n| Expanding the platform                | 0.76 |     \
    \ |      |      |      |               |      | 0.17 |      |\n| Role of intermediary\
    \                  |      |      |      |      |      |               |      |\
    \      |      |\n| Embedded Advertisement API            | 0.16 |      |     \
    \ |      |      |               |      |      | 0.71 |\n| CI/CD              \
    \                   | 0.05 |      |      |      |      |               |     \
    \ |      |      |\n| Checks at run time                    | 0.14 |      | 0.50\
    \ |      |      |               |      |      |      |\n| Quality/security checks\
    \               | 0.74 |      |      |      |      | 0.25          |      |  \
    \    |      |\n| Composability                         |      |      |      |\
    \      |      |               |      |      |      |\n| Independent          \
    \                 | 0.56 | 0.00 |      |      | 1.00 | 1.00          |      |\
    \      | 0.00 |\n| Vendor internal                       | 0.15 |      |     \
    \ |      |      |               |      |      | 1.00 |\n| Package manager type\
    \                  | 0.19 | 1.00 |      |      |      |               |      |\
    \      |      |\n| Analytics                             |      |      |     \
    \ |      |      |               |      |      |      |\n| Sentiment and popularity\
    \ ratings      | 0.73 |      |      |      |      | 0.00          |      | 0.33\
    \ |      |\n| Marking feedback                      | 0.25 |      |      |   \
    \   |      |               |      |      |      |\n| Product Usage data      \
    \              | 0.33 |      |      |      |      |               |      |   \
    \   |      |\n| Communication channels                |      |      |      | \
    \     |      |               |      |      |      |\n| Documentation (wikis, FAQs)\
    \           | 0.81 |      |      |      |      | 0.25          |      |      |\
    \      |\n| Product homepage                      | 0.97 |      |      |     \
    \ |      |               |      |      |      |\n| Star/Score/Up/Downvote rating\
    \         | 0.57 | 0.11 | 1.00 |      | 1.00 | 0.00          | 1.00 | 0.00 | \
    \     |\n| Written reviews (in text)             | 0.47 | 0.00 |      |      |\
    \ 1.00 | 0.00          | 0.89 | 0.00 |      |\n| Community Forum             \
    \          | 0.45 |      |      | 0.75 |      | 0.00          |      |      |\
    \      |\n| Support Ticket                        | 0.35 |      |      |     \
    \ |      |               |      |      |      |\n| Promotion/Marketing       \
    \            | 0.71 |      |      |      |      | 0.25          |      |     \
    \ |      |\n\nthe centroid-of-centroids with values for each feature. The remaining\
    \ columns represent each cluster by an index from 1 to 8. The values in these\
    \ columns represent the proportion of app stores in the cluster with a specific\
    \ feature, the mean, and the background color of each cell represent the deviation\
    \ of the particular cluster centroid (i.e., difference between the centroid of\
    \ this cluster and the centroid-of-centroids for the feature). Each row corresponds\
    \ to a feature of the stores, which makes it easy to understand which features\
    \ are descriptive of a cluster.\n\nThe table only shows the top 10 deviations\
    \ per cluster (i.e., column) to focus on the most important contributors to each\
    \ cluster. Since all features are binary — each store has or does not have the\
    \ feature— all values of the centroid-of-centroids are between [0, 1]; thus, a\
    \ positive deviation (shown with a green background) implies that the stores in\
    \ the cluster are more likely to have the attribute, and a negative deviation\
    \ (shown with a magenta background) implies that the stores are less likely to\
    \ have the attribute.\n\nFor example, for cluster 8 the most important contributor\
    \ is [Composability] Vendor internal add-on/extension/unlock where the centroid\
    \ of the cluster is 1. When comparing against the centroid-of-centroids (at 0.15),\
    \ the deviation is at 0.85; this implies that all stores in this cluster have\
    \ this feature. On the other hand, an example of negative deviation for cluster\
    \ 1 is the feature [Composability] Independent with a centroid of 0 indicating\
    \ that no stores in this cluster have this feature. Since the centroid-of-centroids\
    \ for this features is at 0.56, this implies the deviation for stores in this\
    \ cluster is −0.56.\n\nAfter the top characteristics that make each cluster distinctive\
    \ had been identified, we leveraged this information to name and describe each\
    \ cluster accordingly. Using the information from Sec. 4 which shows the defining\
    \ features of each cluster, we derived an organization of the clusters based on\
    \ several dimensions. The results are described in Table 4.4.\n\nOne important\
    \ dimension focuses on the type of application served by stores in the cluster.\
    \ We identified three major types of applications that differentiate the clusters:\
    \ General, where the store offers stand-alone programs that run without the need\
    \ of specific software (aside from a specific operating system, e.g., Google Play,\
    \ AWS, Steam); Extensions, where the store offers extensions to a specific program\
    \ or platform e.g., VSCode Marketplace for VSCode, Chrome Web Store for Google\
    \ Chrome; and Package manager, where the store offers stand-alone programs, but\
    \ also manages dependencyrelationships and requirements between different applications\
    \ in the store e.g., NPM, MacPorts, Ubuntu Packages. Another dimension in which\
    \ these clusters can be organized is whether they are Commercial (business-oriented)\
    \ or Community-managed (no money is involved).\n\nApp stores are not all alike.\
    \ Intuitive groupings emerge naturally from the data. Their differences can be\
    \ due to the type of application they offer standalone or extensions — and their\
    \ operational model, either business- or community-oriented. We found that app\
    \ stores in different groups of our clustering have different properties, and\
    \ these properties may have bearing on empirical studies involving app stores.\n\
    \n| and<br>stores<br>of<br>List<br>4.4<br>Table | with<br>cluster,<br>by<br>descriptions\
    \                                                                            \
    \                              | is<br>that<br>store<br>example<br>the       \
    \                                                                            \
    \                                 | centroid<br>cluster<br>to<br>closest     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \          |       |\n|---------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------|\n\
    | Type                                        | in Cluster<br>Stores         \
    \                                                                            \
    \                                       | Example Store                      \
    \                                                                            \
    \                                          | Cluster Description             \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                   | Index |\n| Commercial specialized<br>Extensions        |\
    \ Hub-<br>AutoDesk,<br>Boutique,<br>SketchUcation,<br>GoG,<br>Magento,<br>Plugin<br>BigCommerce,<br>Presta\
    \ Shop,<br>CS-Cart<br>Adobe<br>Spot,     | addons<br>to the ecommerce solution<br>Presta\
    \ Shop offers<br>platform.                                                   \
    \                                | Creators<br>are mostly business and their store\
    \ front offers rating sys-<br>are very domain specific.<br>written reviews.<br>in\
    \ the stores<br>and<br>Products<br>tems                                      \
    \                                                                            |\
    \ 6     |\n| Community specialized                       | Docker<br>Jme<br>VSCode<br>Assistant,<br>CurseForge,<br>Minion,<br>Marketplace<br>Home<br>Kodi,<br>Bukkit,<br>Hub,<br>ter,\
    \                      | center.<br>Kodi add-on components<br>to the<br>Kodi entertainment<br>extensions<br>offers\
    \                                                                | These are community\
    \ focused stores that offers free prod<br>also tailor to a specific domain.<br>Stores<br>to\
    \ users.<br>ucts                                                             \
    \                                                                            \
    \                  | 3     |\n| Community non-specialized                   |\
    \ Web<br>Marketplace,<br>Gnome,<br>Chrome<br>Add-ons,<br>Eclipse<br>Wordpress<br>Apkpure,<br>Firefox<br>Store,\
    \                                    | using<br>platform.<br>free<br>for users<br>Wordpress\
    \ offers<br>the wordpress<br>extensions                                      \
    \                         | in<br>stalling apps). Products offered in the stores\
    \ face a generic<br>Products in these stores offers extensions to the platform.<br>(e.g.,<br>registration<br>from\
    \ each other.<br>need<br>are independent<br>not<br>do<br>operations<br>audience\
    \ and<br>Essential                    | 4     |\n| General                   \
    \                  |                                                         \
    \                                                                            \
    \            |                                                               \
    \                                                                            \
    \               |                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                    |       |\n\
    | Commercial                                  | Nintendo<br>Samsung<br>App<br>Store,<br>Apple<br>Play<br>Store,<br>Steam,<br>Store,<br>Google<br>Microsoft<br>Galaxy<br>eShop,<br>AWS,<br>Store\
    \ | MicroSoft Store offers<br>for the<br>platform.<br>applications<br>windows\
    \                                                                            \
    \    | Typical stores many people encounter everyday. They run<br>supporting<br>products<br>internal<br>monetization\
    \ options.<br>vendor<br>offer<br>and<br>profit<br>most<br>for                \
    \                                                                            \
    \                  | 8     |\n| Community                                   |\
    \ Flat<br>Project<br>IzzyOnDroid,<br>F-Droid,<br>Guardian<br>Chocolatey,<br>Repository,<br>Snapcraft<br>pak,\
    \                                      | open<br>Android application store.<br>a\
    \ free and<br>source software only<br>F-Droid is                             \
    \                                      | Cre<br>and<br>community<br>only.<br>products<br>the<br>are\
    \ majority open source.<br>free<br>from<br>standalone<br>mostly<br>are<br>contain<br>stores<br>the<br>the\
    \ products<br>stores<br>for<br>These<br>ators                                \
    \                                         | 7     |\n| Manager<br>Package    \
    \                      | Packagist,<br>pack<br>MacPorts,<br>Ubuntu<br>Jenkins,<br>NuGet,<br>Typo3,<br>Ajour,<br>NPM,<br>PyPI,<br>ages\
    \                                    | the main<br>PHP<br>repository for<br>Packagist\
    \ is<br>packages.                                                            \
    \                               | Products<br>in package style with inter-dependency<br>limited<br>also<br>stores.<br>stores.<br>are<br>missing\
    \ for most<br>these<br>channels<br>for<br>is involved<br>Communication<br>reviews<br>system<br>are\
    \ free and most<br>and<br>relationships.<br>with ratings<br>account<br>No | 1\
    \     |\n| oriented<br>Subscription                    | Jet<br>Brains, Qt Marketplace,\
    \ con<br>Marketplace,<br>marketplace<br>Github<br>crete5                     \
    \                                      | to<br>Marketplace offers<br>to git repositories<br>actions<br>improve\
    \ the workflow<br>GitHub<br>and<br>applications<br>on<br>Github<br>related<br>hosted\
    \ | DRM<br>standalone<br>either provide service or extends a plat<br>supports<br>not<br>are<br>and<br>Products<br>services<br>store.<br>subscription<br>the<br>applications\
    \ and<br>by<br>management<br>offers<br>Often<br>form.                        \
    \                                    | 2     |\n| Other                      \
    \                 | RICOH<br>daz3D<br>Sellacious,<br>MarketPlaceKit,<br>THETA,\
    \                                                                            \
    \          | to the platform.<br>a ecommerce<br>provides<br>platform and<br>Sellacious\
    \ is<br>extensions                                                           \
    \    | The stores<br>the<br>offered.<br>to<br>centrally<br>channels<br>in the\
    \ stores.<br>communication<br>extensions<br>exist<br>distribute<br>on.<br>do not<br>platform\
    \ they are based<br>much<br>reviews<br>have<br>to<br>exists<br>not<br>Rating and<br>They\
    \ do<br>mostly                  | 5     |\n\n#### What is an App Store? The Software\
    \ Engineering Perspective 23\n\n# 5 Discussion\n\nIn this section, we discuss\
    \ our findings regarding what we consider app stores to be based on our clustering\
    \ results, and we describe various research opportunities involving the influence\
    \ of app stores on software engineering practices.\n\n# 5.1 What Is an App Store?\n\
    \nThe term app store became popular largely through Apple's App Store, which launched\
    \ in 2008 along with the iPhone 3G [73]. Other online software stores have also\
    \ appeared and have had the term applied to them. Originally, the term usually\
    \ referred to stores of applications for mobile devices, but we have found that\
    \ today there is ample diversity of the type of applications that app stores offer\
    \ and in the features they provide to app developers and users. App Stores are\
    \ also dynamic: features are continually being added, removed, and altered by\
    \ store owners in response to changes in their goals and feedback from their socio-technical\
    \ environments. For example, the Chrome Web Store initially introduced a built-in\
    \ monetization option that provided a mechanism for applications to receive payments\
    \ from its users; however, the store later decided to deprecate this monetization\
    \ option [74] and suggested developers to switch to alternative payment-handling\
    \ options.\n\nIn our work, we have employed a working definition through our inclusion/exclusion\
    \ criteria for app stores to be included in our research. However, due to the\
    \ complexity, diversity, and constantly evolving nature of app stores, we have\
    \ decided not to attempt a firm, prescriptive definition of the term. Instead,\
    \ in the following paragraphs, we will discuss each of several aspects of app\
    \ stores in detail, and hope that in the future, a more robust definition and\
    \ operating model can emerge.\n\n#### 5.1.1 Common Features of App Stores\n\n\
    Although we found significant diversity among the example app stores we studied,\
    \ we were able to identify a set of three common features that appear to span\
    \ the space of app stores.\n\n> Simple installation and updates of apps — An app\
    \ store facilitates simple installation of a selected application, and can also\
    \ enable simple updating. For some stores, apps are expected to run on the hardware\
    \ of the client; in others, the app store provides and manages the hardware where\
    \ the app runs. In both cases, the app store frees the user from worrying about\
    \ the technical details of installation, including compatibility with their specific\
    \ hardware and software configuration, as well as the installation of the app\
    \ and its dependencies, if any. Typically, app stores will also automate the installation\
    \ of updates to the application, again freeing the user from worrying about if\
    \ they have the latest version of the app with the latest features and bug fixes.\n\
    \n> App exploration and discovery — App Stores provide mechanisms that allow users\
    \ to find apps they might want to use. In its simple form, this mechanism might\
    \ be a search engine that returns a list of apps that match a given set of keywords\
    \ (such as homebrew, PyPI). In the labeled app stores, 73% of stores provide some\
    \ kind of aggregated recommendations (e.g., advertisement and trends in WordPress),\
    \ up to personal recommendations that are based on other apps the user has installed\
    \ before (e.g., Apple's App Store). User feedback via reviews (present in 47%\
    \ of the labeled app stores) and forums (present in 45% of the labeled app stores)\
    \ can provide further information to aid other users in identifying apps of possible\
    \ interest to them.\n\n> The app store guarantees the runtime environment — In\
    \ practice, app stores often execute within a runtime environment (RTE), such\
    \ as an operating system (e.g., Google Play on Android) or an extensible software\
    \ application (e.g., Firefox Add-ons on Firefox ). Many app stores simply sit\
    \ on top of the RTE, acting primarily as a gatekeeper for adding and deleting\
    \ apps. However, some app stores are more tightly integrated with the RTE; in\
    \ extreme cases, the app store can extend the RTE with the app store's own functionality\
    \ and together provide an augmented RTE for the applications managed through the\
    \ app store. Steam is a good example for extending the RTE with its own features;\
    \ developers can integrate with many services offered by Steam, such as an achievement\
    \ system that offers players recognition when they fulfill certain requirements\
    \ in the game. Figure 5.1 illustrates the situation where a product may integrate\
    \ with additional store-added features to the RTE, which in turn enriches the\
    \ user experience of the store users. When Product B is offered in App Store Y,\
    \ it will not have the features provided by App Store X.\n\nThe app store ensures\
    \ that apps are installed only when their runtime requirements are satisfied.\
    \ The process is often done through running checks on apps submitted to the app\
    \ store, which 74% of the labeled app stores perform specifically. By specifying\
    \ the runtime requirements, the assumption for both the developer and the user\
    \ is that if the application is installed implying that the requirements are satisfied\
    \ — it is expected to run properly. This is usually achieved by a software layer\
    \ on top of the RTE, provided by either the app store or the user. In its simplest\
    \ form, this software layer is responsible for installing and updating apps (see\
    \ \"Simple installation and updates of apps\" above). In some cases, this software\
    \ layer might also include a set of libraries that the apps can use to provide\
    \ features specific to the app store thus forming part of the RTE for the applications.\
    \ These libraries might range in purpose (domain specific, common GUI, resource\
    \ management, etc.). In extreme cases, this layer includes the operating system,\
    \ as it is the case with Apple's App Store. However, checks during runtime is\
    \ a very rare feature, which only 14% of the labeled app stores provides.\n\n\
    Some hardware platforms have become so tightly integrated to the software layer\
    \ of the app store that they can be considered monolithic: the hardware is rendered\
    \ unusable without the app store. This is exemplified by the Apple's\n\n![](_page_25_Figure_1.jpeg)\n\
    \nFig. 5.1 Stores may offer optional extensions to the runtime environment for\
    \ applications\n\nApp Store, where one cannot use the hardware without first having\
    \ an account in the app store; even operating system upgrades are distributed\
    \ via the store.\n\nThis tight level of integration has clear benefits for all\
    \ three stakeholders: end users have fewer installation technical details to worry\
    \ about; app developers can be assured that users will be able to install their\
    \ apps without the need for technical support; and app store owners can strictly\
    \ manage who has access to the user's RTE and how. However, such tight integration\
    \ is technically unnecessary and may even be undesirable. From a software engineering\
    \ perspective, such tight coupling could be seen as a \"design smell\", since\
    \ the operating system and the app store layers address fundamentally different\
    \ concerns. Also, tight integration can create an artificial barrier to competition,\
    \ effectively establishing a quasi-monopoly for the store owner; the store owner\
    \ may assume the role of gatekeeper not only for streamlining technical issues,\
    \ but also for business reasons, requiring a kind of toll to be paid by app developers\
    \ for access to the store. A recent initiative in the European Union [75] aims\
    \ to enable fair competition by enforcing that ecosystems are opened up, which\
    \ will likely also allow the installation of alternative software layers for other\
    \ app stores, a term called side-loading. In contrast to the Apple's tight control\
    \ of the operating system as part of its app store, Android allows third-party\
    \ app store software (e.g., F-Droid [76]) to be installed in co-existence with\
    \ the system default (often Google Play).\n\nAs mentioned above, some stores distribute\
    \ software that runs on hardware owned by the App Store itself; in these cases,\
    \ the RTE is fully managed and controlled by the store. For example GitHub Marketplace\
    \ and Atlassian Marketplace offer applications that run on GitHub and Atlassian\
    \ servers respectively. In most cases, these applications are not deployed to\
    \ the user's computers.\n\n#### 5.1.2 Different Types of App Stores\n\nWhile some\
    \ features are broadly shared by all app stores, in Sec. 4, we identified different\
    \ groups of app stores based on their features. For stores within the same group,\
    \ they often share common features, whereas across different groups, the stores\
    \ tend to have less in common. We now discuss the differences across the groups\
    \ in detail.\n\n> Diversity in goals — As a platform focusing on delivering products\
    \ to customers, the high-level goal of one app store can be dramatically different\
    \ from the other. Even app stores providing software for the same underlying RTE\
    \ can have radically different purposes. For example, consider the app stores\
    \ that run on Android. Google Play is the de facto store for Android applications.\
    \ F-Droid store, on the other hand, offers only free and open source Android applications,\
    \ and APKPure offers multiple versions of the same software so the user can decide\
    \ which version they would like to install.\n\nApple's app store offers applications\
    \ for all its RTEs: MacOS (laptop and desktops), iOS (phones and tables), and\
    \ the Safari browser. In contrast, Google has different stores for AndroidOS and\
    \ for its web browser, Chrome. The Microsoft Store sells hardware and apps for\
    \ Windows and XBox. Alexa Skills offers skills that enhance the voice agent Alexa's\
    \ capabilities.\n\nIn many program language ecosystems, the core language development\
    \ (focusing on the language features) and packaging system (focusing on extending\
    \ the functionality of the language) are led by separate organizations (e.g.,\
    \ NPM [77] and JavaScript [78]).\n\n> Diversity in business model — Another important\
    \ difference we observed is between business-managed and community-managed stores.\
    \ In businessmanaged stores (with few exceptions), a primary goal is to generate\
    \ a profit. These stores provide a payment mechanism between the app creator and\
    \ the purchaser, with the store keeping a percentage of any sales. These stores\
    \ have to solve three key concerns: first, implementing registration and authentication\
    \ of users and developers; second, some type of digital rights management, so\
    \ only users who have acquired the software can use it; and third, a payment mechanism\
    \ e.g., subscription, one-time payment, and advertisement.\n\nCommunity-managed\
    \ stores, on the other hand, are often run by volunteers, and their features focus\
    \ on facilitating not-for-profit product delivery from developer to user. Many\
    \ community stores offer limited community interactions compared to business stores\
    \ where customer feedback is important. For example, in the Kodi store, add-ons\
    \ have a web page (e.g., The Movie Database Python [79]). This page provides information\
    \ regarding installation of the add-on, such as known compatibility concerns,\
    \ download links, and installation requirements. Meanwhile, most communication\
    \ channels about the add-on are hosted elsewhere; for example, installation and\
    \ usage instructions, extended descriptions, and screenshots can be found in the\
    \ community forum instead.\n\nIt is important to note that the products contained\
    \ in community-oriented stores are not limited to open source software; some community-managed\
    \ app store policies often permit the distribution of proprietary software. In\
    \ the natural groupings we observed, no rights management is enforced from the\
    \ store side for Cluster 3; at the same time, most stores in Cluster 8 have some\
    \ form of rights management built-in to the store. For example, Homebrew permits\
    \ apps that are not open source if the apps are free to use; these apps might\
    \ include in-app purchases — such as an upgrade to a full-feature app — that are\
    \ handled outside of Homebrew.\n\n5.2 Implications for the Main Participant Stakeholders\n\
    \nThe results of our study includes an evidence-based detailed view of the broad\
    \ landscape of app stores. This view can help us improve the understanding of\
    \ the realities and potentialities of app stores in general. Meanwhile, the results\
    \ of our work can also benefit the different stakeholders involved with app stores,\
    \ including app creators, app stores themselves, users, and researchers.\n\n>\
    \ Application creators — Those who create applications — including those who design,\
    \ develop, test, and market apps — benefit from a holistic view of other stores\
    \ that will allow them identify potential new markets (stores where they can offer\
    \ their software) and to understand changing and emerging features that could\
    \ eventually come to their app store of choice. For new creators, this research\
    \ emphasizes that a software store has both technical requirements — such as the\
    \ use of a specific software development kit — and non-technical ones — such as\
    \ restrictions on what applications can do, approval processes and timelines —\
    \ and that these requirements vary significantly from one store to another.\n\n\
    > App Stores — The overview presented herein provides a framework for comparison\
    \ between app stores, particularly those that operate on the same market, such\
    \ as Android application stores. It can also help promote wide adoption of features\
    \ that are not universal, such as communication channels between users and developers.\n\
    \n> Users — With the diversity in app stores, especially when multiple app stores\
    \ are competing in the same domain, it allows users the chose of where to acquire\
    \ their applications. This allows for more diversity for how the apps are distributed\
    \ and the user's choice also affect the competition.\n\n> Researchers — As discussed\
    \ in Sec. 2, most prior research has focused on the applications offered in app\
    \ stores, and there is a need for research that focuses on studying the store\
    \ themselves. This emphasis could aid researchers in considering different points\
    \ of view when conducting app store-centric studies, and also suggest avenues\
    \ of exploration concerning how the development process is affected by the existence\
    \ of app stores.\n\nWe describe this point in detail in the next sections.\n\n\
    # 5.3 App Store Features\n\nIn this section, we discuss how each of feature groups\
    \ from Table 4.1 has been addressed by current SE research and we suggest some\
    \ possible future directions.\n\n> Monetization — App development can be affected\
    \ by their pricing strategy. For example different software architecture to support\
    \ a different system of monetization (e.g., locking functionality behind microtransactions)\
    \ [80]. Studies have shown a correlation between app features and pricing [11,\
    \ 81, 82]. Moreover, in many studies on apps [29, 83], free apps and charged apps\
    \ are often considered as different types of applications. Future work could further\
    \ explore how different monetization options affect app development.\n\n> Rights\
    \ management — Digital rights management is still an ongoing challenge in software\
    \ engineering. Existing studies have explored the options of implementing different\
    \ DRM systems to support developers [84,85]. DRM can also add challenges in other\
    \ development activities such as complicating the testing procedure [86] and affect\
    \ performance [87]. Often we can observe the store offering means for providing\
    \ and enforcing DRM. Because DRM is still a nascent technology within software\
    \ engineering, it remains an open area to explore for future study and how app\
    \ stores can play a role.\n\n> Account requirement — User identity enables telemetry\
    \ of user behavior. An account system is also the prerequisite of a store-wide\
    \ DRM system as discussed in the previous paragraph. Existing research has focused\
    \ on how to leverage the user identity information to create targeted recommender\
    \ systems [88] and also investigated the concerns of privacy-related issues [89].\
    \ The interest of developers (detailed tracing data) and users (privacy) are in\
    \ conflict, app stores that require user identification could prove to be an excellent\
    \ study subject for future research in that area.\n\n> Product type — Existing\
    \ research has already shown different software engineering practices based on\
    \ the software product. For example, gaming development is very different from\
    \ traditional software development and open source development [90, 91]. Research\
    \ have shown that different types of software can introduce specific challenges\
    \ unique to them [92,93]. Future research should better understand how the product\
    \ type affects user expectations and development practices, for example, with\
    \ respect to the delivery of software or the way creators and users can interact.\n\
    \n> Target audience — When an app developer decides on a specific app store to\
    \ sell their app, they are also effectively selecting for a specific type of user\
    \ [94– 96]. Users of a general-purpose store such as Google Play are different\
    \ and much more diverse than the user population [97] in very specialized stores,\
    \ such as the add-on store for a particular game. Research needs to understand\
    \ better which features are relevant in each specific context [41], so the experience\
    \ can be tailored to the concrete situation.\n\n> Type of product creators — Existing\
    \ research has shown many differences between open source and industrial software\
    \ development [91,98]. Some studies have touched the aspect of release engineering\
    \ in open source development [99], where developers would strategically select\
    \ which versions to release on the app store. However, we believe that there is\
    \ still room for more understanding in how targeting releases towards app stores\
    \ affects software development.\n\n> Intent of app store — While in most domains,\
    \ there exists a dominant app store, we can also observe situations where multiple\
    \ app stores compete in the same domain (e.g., game stores on PC, mobile app stores\
    \ in China [54]). In these situations, users have a choice of which app store\
    \ to use when the same application is offered. In practice, some studies have\
    \ explored how the high level operation of app stores can affect the software\
    \ delivery process especially involving security concerns [41, 51]. Competition\
    \ between app stores within the same domain remains largely unstudied, as does\
    \ how their operations can affect both developers and users.\n\n> Role of intermediary\
    \ — App stores provide a platform for users and developers. Researchers have explored\
    \ how it affects software development processes such as testing and release management\
    \ [100, 101]. There are many opportunities for security [102] and quality assurance\
    \ [53, 103] to be ensured on the app store side. Future study can explore how\
    \ the differences between apps managed through an app store and apps that are\
    \ not. For example, studying the difference between open-source web extensions\
    \ that are in and not in app stores.\n\n> Composability — Existing research has\
    \ explored co-installability in the scope of package manager systems [104, 105].\
    \ However, we only have limited understanding of co-installability for standalone\
    \ applications in an extension system. For example, if two standalone extensions\
    \ were to modify the same component of the underlying software, a potential incompatibility\
    \ could occur. Future research can explore this area by performing empirical studies\
    \ on existing systems to understand the issue of conflicts.\n\n> Analytics — App\
    \ stores as the central hub between developers and users have access to rich information\
    \ useful for analytics. Previous studies have taken advantage of the app store\
    \ specific information to help software developers [106–108]. For example, Ullmann\
    \ et al. [109] leveraged records of rating statistics and downloaded information\
    \ to study the factors in developing successful video games. Another study leveraged\
    \ analytic information collected by the app store to identify incompatible builds\
    \ of application and physical devices [110]. Future work can explore what are\
    \ the possible data to collect and form analytics, and how can the analytic data\
    \ be leveraged to help developers and users.\n\n> Communication channels — Communication\
    \ channels are the most studied area of app store features. Specifically, there\
    \ has been a heavy focus on app reviews, where researchers have leveraged the\
    \ information in app reviews to aid software development in areas such as extracting/locating\
    \ bug reports [43], discover feature requests [50] and collect user feedback [52].\
    \ However, existing studies also suggest that the use of communication channels\
    \ in app stores are often multi-purpose [18]. Researchers also find that some\
    \ interaction requirements between interested parties are relegated to other platforms\
    \ such as Twitter [111]. Future work can explore different types of communication\
    \ channels in their functionality and how they can integrate with app stores.\
    \ The corpora from communication channels are also rich information sources where\
    \ researchers can leverage to extract information about developer-user interactions.\n\
    \n#### 5.4 Research Opportunities Involving App Stores\n\nApp Stores are becoming\
    \ the primary channel for software delivery and exert considerable influence in\
    \ many aspects of the software development process. A previous study by Rosen\
    \ and Shihab [112] on Stack Overflow questions by mobile developers has shown\
    \ that app delivery is one of the biggest challenges developers face. Our results\
    \ in Sec. 4 demonstrate that there is a wide variety of types of stores, each\
    \ with different features and goals. Today, app stores encompass many kinds of\
    \ applications, from games running on the hardware of the user to add-ons for\
    \ applications that run on corporate servers such as GitHub. However, existing\
    \ research often focuses heavily on the applications offered inside app stores,\
    \ especially those of the two major mobile app stores. In the following paragraphs,\
    \ we discuss several research opportunities to study how app stores can affect\
    \ software development.\n\n#### 5.4.1 App Stores as Actors in Software Development\n\
    \n> App Stores affect the software product cycle — Researchers need to consider\
    \ how and why app stores can affect the software development life cycle. For example,\
    \ we know that app stores can constrain and sometimes even dictate software release\
    \ processes. Some stores go beyond this and exert a kind of socio-technical environmental\
    \ pressure on other software development practices, becoming a de facto stakeholder\
    \ in app development. Sometimes these environmental pressures are technical in\
    \ nature, where the app store might dictate the programming language or deployment\
    \ platform/OS; some app stores go further and create RTEs, software development\
    \ kits (SDKs), and user interface (UI) libraries that must be used by all app\
    \ developers. Sometimes these environmental pressures are non-technical in nature,\
    \ such as when the app store prescribes the kinds of application that is allowed\
    \ in the store. For example, Microsoft recently announced that it will not permit\
    \ app developers to profit from open source applications.<sup>3</sup> When an\
    \ app store operates in a manner such that it has control over what kind of application\
    \ to include, it creates a software ecosystem and as such, it faces the same challenges\
    \ that any other ecosystem has: how to thrive. In particular, stores need to understand\
    \ the needs of their developers and users to retain existing ones and attract\
    \ new ones. However, suggested by what we have observed in Sec. 4, app stores\
    \ are diverse with a large number of features that characterize and differentiate\
    \ between them. While stores are experimenting and evolving, each action is likely\
    \ to have an effect on the ecosystems they formed, both positively and negatively.\
    \ Thus, the impact of app stores in the economy and their markets is worthy of\
    \ further study.\n\n> An app may be offered in several app stores — Developers\
    \ want to run their software on the platform that is provided or supported by\
    \ the store, and as such they must accept the requirements and limitations that\
    \ such a store may impose. This issue is compounded when the app is being offered\
    \ in more than one store, as the developers might have to adapt their processes\
    \ to different sets of requirements, some of which might be conflicting. For instance,\
    \ an app can be both available in F-Droid (in Cluster 7) and Google Play (in Cluster\
    \ 8). In Google Play, it is common for applications to collect telemetry data\
    \ to better understand typical user behaviour; however, in F-Droid — an open source\
    \ and privacy-oriented store — such data collection is highly discouraged. Furthermore,\
    \ developers must also adapt to the features and limitations that a store provides\
    \ regarding software deployment, communication with users and — when they exist\
    \ — the mechanism available to profit from their software and to use digital rights\
    \ management. This is particularly interesting if the targeted app stores are\
    \ in different natural groupings. This introduces new areas of studies such as\
    \ how store policies propagate to applications over time, and how violations of\
    \ store policies can be detected automatically. Researchers have already begun\
    \ to investigate this topic through qualitative approaches to identify how applications\
    \ comply with specific policies that concern accessibility [29] and human values\
    \ [45].\n\n> App stores strongly affect the release engineering process — App\
    \ Stores are especially important in release engineering. Specifically, the release\
    \ process needs to consider how the application is to be packaged, deployed, and\
    \ updated. The heterogeneity of the platform provided by RTEs might also affect\
    \ the number of versions of the application that need to be deployed, e.g., variety\
    \ of target CPUs, different screen sizes and orientations, and amount of available\
    \ memory.\n\nWhen an application is developed for multiple stores, it must effectively\
    \ be managed as a product line; this is because multiple deliverables must be\
    \ created, one for each platform-store combination [113]. Multiple deliverables\
    \ can also help for telemetry reasons such as tracking the installation source\
    \ of the application [114]. The differences between packaged versions might be\n\
    \n<sup>3</sup> See Update to 10.8.7 https://docs.microsoft.com/en-us/windows/uwp/publish/\
    \ store-policies-change-history\n\nas significant as requiring the source code\
    \ to be written in different programming languages, using different frameworks;\
    \ also, each store is likely to require different deployment processes.\n\nFor\
    \ example, when cross-releasing browser add-ons, developers may have to rewrite\
    \ part of the functionality in Swift/Objective-C for better integration with Safari\
    \ (in the Apple's App Store), while at the same time maintaining a fully JavaScript\
    \ version for Chrome Web Store. Also, the scheduling of release activities is\
    \ often dictated by the release processes of the stores. A previous study has\
    \ showed that taking into consideration of app review times is an important factor\
    \ when planning releases [53]. The app store standardizes, and often simplifies,\
    \ the release engineering processes for its store; but it also becomes a potential\
    \ roadblock that might delay or even reject a new release.\n\n#### 5.4.2 The Challenge\
    \ of Transferring Understanding Between Stores\n\nAs noted above, prior work has\
    \ examined many aspects of app stores, yet the app store itself has rarely been\
    \ the focus of the research. In many studies, the app store serves as a convenient\
    \ collection of apps, and the research focuses on mobile development concerns\
    \ such as testing and bug localization. Even when research focuses on the app\
    \ store itself, the scope rarely extends beyond Google Play and Apple's App Store.\
    \ Based on our observations, the diversity of app stores in their operational\
    \ goals, business models, delivery channels, and feature sets can affect the generalizability\
    \ of research outcomes. For example, there have recently been many studies [12,18,43,45,46,50,52]\
    \ that focus on app reviews. However, for an app store that does not have reviews\
    \ (e.g., Nintendo eShop) none of the findings and tools can be leveraged (e.g.,\
    \ stores in Cluster 1, 5, and 7).\n\n> App Stores that have the same features\
    \ may still differ significantly — Depending on the problem domain, the details\
    \ of software development practices can vary dramatically. For example, game development\
    \ has been compared to both more traditional industrial software development [90]\
    \ and to open source software development [91]; in both cases, the development\
    \ processes can differ greatly. We conjecture that the same may also occur across\
    \ app stores, where despite the same feature is being offered in the different\
    \ stores, the convention of using them could be different. As mentioned above,\
    \ one specific observation has been made between the gaming-focused store Steam\
    \ and mobile stores (e.g., Google Play) in Cluster 8, where Lin et al. [12] found\
    \ that reviews across the platforms for the same app were often quite different\
    \ in tone. Such uncertainly invites future research to validate their findings\
    \ in one store to another to improve the generalizability of the results, and\
    \ also encourages replication studies to verify existing results on other stores.\n\
    \n> A feature not in the app store does not mean the functionality is missing\
    \ — While some app stores aim to provide a complete experience, where all interactions\
    \ from the developers and users are expected to be performed within the store,\
    \ some app stores export part of the work to other platforms. This can even occur\
    \ for common features that one might find essential. For instance, starred reviews\
    \ are universal in Cluster 2, 4, and 6 where typical users leverage this information\
    \ to decide whether an application is good; starred reviews are uncommon for other\
    \ stores in Cluster 1, 5, 7. The specialized store may have some other metric\
    \ to indicate popularity or quality, such as total number of downloads, but the\
    \ focus of the store is often to offer a managed way of installation. Other features,\
    \ such as application support, are left to other platforms such as social media.\
    \ Research can further explore the integration between app stores and other platforms.\n\
    \n#### 6 Threats to Validity\n\n> Internal Validity — Our initial seeding of app\
    \ stores comes from personal experience of app stores by the authors of the paper.\
    \ Personal bias could cause us to miss other types of app stores. However, given\
    \ the number of authors on this paper and our initial effort to consider as many\
    \ stores as possible, we feel that have created a wide, deep, and collaborative\
    \ \"best effort\". When we labeled app stores by their dimensions, it is a qualitative\
    \ process. As with any qualitative process, the results could be biased by the\
    \ authors performing the task. We tackled this issue by first labeling a few stores\
    \ separately by all authors and discussing the results until a consensus was achieved;\
    \ thus, we started with a set of \"gold standard\" labels. Then the labeling task\
    \ was delegated to two authors who continued to label the stores separately with\
    \ a portion of the store overlapping. The overlapping labels are then verified\
    \ by the Cohen's Kappa between the two authors to measure the agreement.\n\nWe\
    \ leveraged the K-means algorithm for the clustering process. We first applied\
    \ PCA techniques to reduce the dimensions of the initial labeling and provide\
    \ an orthogonal basis to feed the K-means clustering. When using other clustering\
    \ algorithms (e.g., Mean-shift, DBSCAN ), the clustering result might change;\
    \ while K-means is widely adopted for clustering process in SE research, by nature,\
    \ determining the proper k value is still a challenge. We followed common best\
    \ practice to use metrics (i.e., the Silhouette method) to determine the best\
    \ value k. Despite our efforts, the output of the K-means clustering is not perfect.\
    \ We mainly leveraged the K-means clustering as the first step to illustrate that\
    \ app stores forms natural clusters which are different from each other. Based\
    \ on the K-means output, we further grouped the clusters into types based on our\
    \ qualitative understanding of the app store space.\n\n> External Validity — During\
    \ the process of expanding app stores, we relied on the Google Search Engine to\
    \ find web results based on keywords. The results of this step rely on the capability\
    \ of Google and are subject to change over time as Google updates its search algorithms.\
    \ The order may also be affected by SEO operations. Combining results from other\
    \ search engines (e.g., DuckDuckGo, Bing) can help to reduce the bias.\n\nWhen\
    \ we applied our inclusion criteria, 1) app stores must contain software products\
    \ and 2) should offer an end-to-end experience for users (ordering, delivery,\
    \ installation), we excluded stores that focus on digital assets that are not\
    \ software, such as a pure assets store that offers cosmetic enhancements to desktop\
    \ environments; we also excluded stores that offer software products but in a\
    \ way such that installation is completely managed by users. An extreme example,\
    \ would be the software section of Amazon where software is sold as an activation\
    \ key which users would input to activate the software that they need to install\
    \ themselves. A more general inspection of all means of distribution software\
    \ can be performed to gain a broader understanding of software distribution.\n\
    \nWe relied on only publicly available information to label each store. So if\
    \ some functionality (e.g., analytics information) is not documented publicly,\
    \ we were unable to confirm whether the store has such functionality. We also\
    \ set a time limit to label each store so in case we were unable to find information\
    \ about the store, with each store receives the same amount of attention.\n\n\
    One of the main challenges for reproducibility and replicability is that the Google\
    \ Search results and app stores can change overtime. New app stores are likely\
    \ to emerge and existing app stores may introduce and remove features. The focus\
    \ of our study is not to establish an exhaustive catalog of app stores, nor to\
    \ study the historic evolution of a store. Our goal is to establish a framework\
    \ that can describe app stores and to understand whether the operations of app\
    \ stores follow different patterns. Based on the granularity which we extracted\
    \ features from app stores, we expect the majority of the feature groups will\
    \ remain stable over time. In the future, if researchers would like to repeat\
    \ our study, the labeling results may differ due to updates in the app store.\
    \ To mitigate this issue, we have included a snapshot of all Google Search results,\
    \ and documented how we would perform the labeling. So while the final labels\
    \ may differ, by applying the same process, a replication study would be possible\
    \ with updated data.\n\n#### 7 Summary\n\nIn this paper, we have explored the\
    \ idea of what an app store is and what features make app stores unique from each\
    \ other. We labeled a set of representative stores, curated from web search queries,\
    \ by their features to study the natural groupings of the stores. Our analysis\
    \ suggests that app stores can differ in the type of product offered in the store,\
    \ and whether the store is business oriented or community oriented. These natural\
    \ groupings of the stores challenge the manner in which app store research has\
    \ largely been mobile focused. Previous studies have already shown empirical differences\
    \ in activities in mobile app stores and game stores [12]. Our study further suggests\
    \ that in the future, when we study app stores, we will need to consider the generalizability\
    \ of the results across app stores. Since one type of app store may operate under\
    \ different constraints than another kind, results observed in one app store setting\
    \ may not generalize to others.\n\n# Conflict of Interests\n\nThe authors declared\
    \ that they have no conflict of interest.\n\n# Data Availability Statement\n\n\
    A dataset consists of the Google query results and the app store labeling results\
    \ are available on Zenodo. 4\n\nAcknowledgements We would like to thank the attendees\
    \ of the Shonan meeting [115] on \"Release Engineering for Mobile Applications\"\
    , where the paper's idea was conceived.\n\nOne of the authors has received funding\
    \ from the European Union's Horizon 2020 research and innovation programme under\
    \ grant agreement number 825328 (FASTEN).\n\n#### References\n\n- 1. C. Dixon,\
    \ R. Mahajan, S. Agarwal, A. Brush, B. Lee, S. Saroiu, and V. Bahl, \"The home\
    \ needs an operating system (and an app store),\" in SIGCOMM Workshop on Hot Topics\
    \ in Networks, ACM, 2010.\n- 2. Valve, \"Welcome to Steam.\" https://store.steampowered.com/,\
    \ 2022. Accessed: Jun. 22 2022.\n- 3. GitHub, \"GitHub Marketplace · to improve\
    \ your workflow · GitHub.\" https://github. com/marketplace?type=, 2022. Accessed:\
    \ Jun. 06 2022.\n- 4. Google, \"Chrome Web Store Extensions.\" https://chrome.google.com/webstore/\
    \ category/extensions, 2022. Accessed: Jun. 22, 2022.\n- 5. WordPress, \"WordPress\
    \ Plugins | WordPress.org.\" https://wordpress.org/plugins/, 2022. Accessed: Jun.\
    \ 22, 2022.\n- 6. Autodesk, \"Autodesk App Store : Plugins, Add-ons for Autodesk\
    \ software, AutoCAD, Revit, Inventor, 3ds Max, Maya ....\" https://apps.autodesk.com/,\
    \ 2022. Accessed: Jun. 22, 2022.\n- 7. Docker, \"Explore Docker's Container Image\
    \ Repository | Docker Hub.\" https://hub. docker.com/search?q=, 2022. Accessed:\
    \ Jun. 22, 2022.\n- 8. Amazon, \"AWS Marketplace: Homepage.\" https://aws.amazon.com/marketplace/,\
    \ 2022. Accessed: Jun. 22, 2022.\n- 9. Rémi Prévost, Mike McQuaid, and Danielle\
    \ Lalonde, \"The Missing Package Manager for macOS (or Linux) — Homebrew.\" https://brew.sh/,\
    \ 2022. Accessed: Jun. 22, 2022.\n- 10. Canonical, \"Ubuntu Software Center in\
    \ Launchpad.\" https://launchpad.net/ software-center, 2009. Accessed: Jun. 22,\
    \ 2022.\n- 11. M. Harman, Y. Jia, and Y. Zhang, \"App store mining and analysis:\
    \ MSR for App Stores,\" in Int. Conf. on Mining Software Repositories, IEEE, 2012.\n\
    - 12. D. Lin, C.-P. Bezemer, Y. Zou, and A. E. Hassan, \"An empirical study of\
    \ game reviews on the steam platform,\" in Empirical Software Engineering, Springer,\
    \ 2019.\n- 13. Wikipedia, \"Electronic AppWrapper Wikipedia.\" https://en.wikipedia.org/wiki/\
    \ Electronic\\_AppWrapper, 2022. Accessed: Jun. 22, 2022.\n- 14. J. MacQueen et\
    \ al., \"Some methods for classification and analysis of multivariate observations,\"\
    \ in Proceedings of the fifth Berkeley symposium on mathematical statistics and\
    \ probability, Oakland, CA, USA, 1967.\n- 15. P. J. Rousseeuw, \"Silhouettes:\
    \ a graphical aid to the interpretation and validation of cluster analysis,\"\
    \ in Journal of computational and applied mathematics, Elsevier, 1987.\n\n<sup>4</sup>\
    \ https://zenodo.org/record/7968192\n\n- 16. I. J. M. Ruiz, M. Nagappan, B. Adams,\
    \ and A. E. Hassan, \"Understanding reuse in the android market,\" in Int. Conf.\
    \ on Program Comprehension, IEEE, 2012.\n- 17. W. Martin, F. Sarro, Y. Jia, Y.\
    \ Zhang, and M. Harman, \"A survey of app store analysis for software engineering,\"\
    \ in Transactions on Software Engineering, IEEE, 2016.\n- 18. J. Dąbrowski, E.\
    \ Letier, A. Perini, and A. Susi, \"Analysing app reviews for software engineering:\
    \ a systematic literature review,\" in Empirical Software Engineering, Springer,\
    \ 2022.\n- 19. X. Zhan, L. Fan, S. Chen, F. Wu, T. Liu, X. Luo, and Y. Liu, \"\
    Atvhunter: Reliable version detection of third-party libraries for vulnerability\
    \ identification in android applications,\" in Int. Conf. on Software Engineering,\
    \ IEEE, 2021.\n- 20. X. Zhang, X. Wang, R. Slavin, T. Breaux, and J. Niu, \"How\
    \ does misconfiguration of analytic services compromise mobile privacy?,\" in\
    \ Int. Conf. on Software Engineering, IEEE, 2020.\n- 21. S. Rahaman, I. Neamtiu,\
    \ and X. Yin, \"Algebraic-datatype taint tracking, with applications to understanding\
    \ Android identifier leaks,\" in Joint Meeting on European Software Engineering\
    \ Conference and Symposium on the Foundations of Software Engineering, ACM, 2021.\n\
    - 22. T. Nguyen, P. Vu, and T. Nguyen, \"Code recommendation for exception handling,\"\
    \ in Joint Meeting on European Software Engineering Conference and Symposium on\
    \ the Foundations of Software Engineering, ACM, 2020.\n- 23. L. Pan, B. Cui, H.\
    \ Liu, J. Yan, S. Wang, J. Yan, and J. Zhang, \"Static asynchronous component\
    \ misuse detection for Android applications,\" in Joint Meeting on European Software\
    \ Engineering Conference and Symposium on the Foundations of Software Engineering,\
    \ ACM, 2020.\n- 24. S. Arzt, \"Sustainable Solving: Reducing The Memory Footprint\
    \ of IFDS-Based Data Flow Analyses Using Intelligent Garbage Collection,\" in\
    \ Int. Conf. on Software Engineering, IEEE, 2021.\n- 25. S. Yang, Y. Wang, Y.\
    \ Yao, H. Wang, Y. F. Ye, and X. Xiao, \"DescribeCtx: Context-Aware Description\
    \ Synthesis for Sensitive Behaviors in Mobile Apps,\" in Int. Conf. on Software\
    \ Engineering, IEEE, 2022.\n- 26. Z. Dong, M. Böhme, L. Cojocaru, and A. Roychoudhury,\
    \ \"Time-travel testing of android apps,\" in Int. Conf. on Software Engineering,\
    \ IEEE, 2020.\n- 27. S. Chen, L. Fan, G. Meng, T. Su, M. Xue, Y. Xue, Y. Liu,\
    \ and L. Xu, \"An empirical assessment of security risks of global android banking\
    \ apps,\" in Int. Conf. on Software Engineering, IEEE, 2020.\n- 28. S. Almanee,\
    \ A. Ünal, M. Payer, and J. Garcia, \"Too Quiet in the Library: An Empirical Study\
    \ of Security Updates in Android Apps' Native Code,\" in Int. Conf. on Software\
    \ Engineering, IEEE, 2021.\n- 29. A. Alshayban, I. Ahmed, and S. Malek, \"Accessibility\
    \ issues in android apps: state of affairs, sentiments, and ways forward,\" in\
    \ Int. Conf. on Software Engineering, IEEE, 2020.\n- 30. B. Yang, Z. Xing, X.\
    \ Xia, C. Chen, D. Ye, and S. Li, \"Don't do that! hunting down visual design\
    \ smells in complex uis against design guidelines,\" in Int. Conf. on Software\
    \ Engineering, IEEE, 2021.\n- 31. P. Liu, L. Li, Y. Yan, M. Fazzini, and J. Grundy,\
    \ \"Identifying and characterizing silently-evolved methods in the android API,\"\
    \ in Int. Conf. on Software Engineering: Software Engineering in Practice, IEEE,\
    \ 2021.\n- 32. S. Yu, C. Fang, Y. Yun, and Y. Feng, \"Layout and image recognition\
    \ driving crossplatform automated mobile testing,\" in Int. Conf. on Software\
    \ Engineering, IEEE, 2021.\n- 33. J. Ye, K. Chen, X. Xie, L. Ma, R. Huang, Y.\
    \ Chen, Y. Xue, and J. Zhao, \"An empirical study of GUI widget detection for\
    \ industrial mobile games,\" in Joint Meeting on European Software Engineering\
    \ Conference and Symposium on the Foundations of Software Engineering, ACM, 2021.\n\
    - 34. S. Ma, J. Li, H. Kim, E. Bertino, S. Nepal, D. Ostry, and C. Sun, \"Fine\
    \ with \"1234\"? An Analysis of SMS One-Time Password Randomness in Android Apps,\"\
    \ in Int. Conf. on Software Engineering, IEEE, 2021.\n- 35. W. Song, M. Han, and\
    \ J. Huang, \"IMGDroid: Detecting Image Loading Defects in Android Applications,\"\
    \ in Int. Conf. on Software Engineering, IEEE, 2021.\n- 36. T. Zhao, C. Chen,\
    \ Y. Liu, and X. Zhu, \"GUIGAN: Learning to Generate GUI Designs Using Generative\
    \ Adversarial Networks,\" in Int. Conf. on Software Engineering, IEEE, 2021.\n\
    - 37. J. Chen, C. Chen, Z. Xing, X. Xu, L. Zhut, G. Li, and J. Wang, \"Unblind\
    \ your apps: Predicting natural-language labels for mobile gui components by deep\
    \ learning,\" in Int. Conf. on Software Engineering, IEEE, 2020.\n- 38. K. Kuznetsov,\
    \ C. Fu, S. Gao, D. N. Jansen, L. Zhang, and A. Zeller, \"Frontmatter: mining\
    \ Android user interfaces at scale,\" in Joint Meeting on European Software Engineering\
    \ Conference and Symposium on the Foundations of Software Engineering, ACM, 2021.\n\
    - 39. D. Van Der Linden, P. Anthonysamy, B. Nuseibeh, T. T. Tun, M. Petre, M.\
    \ Levine, J. Towse, and A. Rashid, \"Schrödinger's security: Opening the box on\
    \ app developers' security rationale,\" in Int. Conf. on Software Engineering,\
    \ IEEE, 2020.\n- 40. V. Murali, E. Yao, U. Mathur, and S. Chandra, \"Scalable\
    \ statistical root cause analysis on app telemetry,\" in Int. Conf. on Software\
    \ Engineering: Software Engineering in Practice, IEEE, 2021.\n- 41. R. Sun, W.\
    \ Wang, M. Xue, G. Tyson, S. Camtepe, and D. C. Ranasinghe, \"An empirical assessment\
    \ of global COVID-19 contact tracing applications,\" in Int. Conf. on Software\
    \ Engineering, IEEE, 2021.\n- 42. A. Truelove, E. S. de Almeida, and I. Ahmed,\
    \ \"We'll Fix It in Post: What Do Bug Fixes in Video Game Update Notes Tell Us?,\"\
    \ in Int. Conf. on Software Engineering, IEEE, 2021.\n- 43. M. Haering, C. Stanik,\
    \ and W. Maalej, \"Automatically matching bug reports with related app reviews,\"\
    \ in Int. Conf. on Software Engineering, IEEE, 2021.\n- 44. S. Yu, C. Fang, Z.\
    \ Cao, X. Wang, T. Li, and Z. Chen, \"Prioritize crowdsourced test reports via\
    \ deep screenshot understanding,\" in Int. Conf. on Software Engineering, IEEE,\
    \ 2021.\n- 45. H. O. Obie, W. Hussain, X. Xia, J. Grundy, L. Li, B. Turhan, J.\
    \ Whittle, and M. Shahin, \"A first look at human values-violation in app reviews,\"\
    \ in Int. Conf. on Software Engineering: Software Engineering in Society, IEEE,\
    \ 2021.\n- 46. R. A.-L. Fischer, R. Walczuch, and E. Guzman, \"Does culture matter?\
    \ impact of individualism and uncertainty avoidance on app reviews,\" in Int.\
    \ Conf. on Software Engineering: Software Engineering in Society, IEEE, 2021.\n\
    - 47. O. Haggag, S. Haggag, J. Grundy, and M. Abdelrazek, \"COVID-19 vs social\
    \ media apps: does privacy really matter?,\" in Int. Conf. on Software Engineering:\
    \ Software Engineering in Society, IEEE, 2021.\n- 48. R. A. Shams, W. Hussain,\
    \ G. Oliver, A. Nurwidyantoro, H. Perera, and J. Whittle, \"Society-oriented applications\
    \ development: Investigating users' values from bangladeshi agriculture mobile\
    \ applications,\" in Int. Conf. on Software Engineering: Software Engineering\
    \ in Society, IEEE, 2020.\n- 49. Z. Zhang, Y. Feng, M. D. Ernst, S. Porst, and\
    \ I. Dillig, \"Checking conformance of applications against GUI policies,\" in\
    \ Joint Meeting on European Software Engineering Conference and Symposium on the\
    \ Foundations of Software Engineering, ACM, 2021.\n- 50. H. Wu, W. Deng, X. Niu,\
    \ and C. Nie, \"Identifying key features from app user reviews,\" in Int. Conf.\
    \ on Software Engineering, IEEE, 2021.\n- 51. Y. Hu, H. Wang, T. Ji, X. Xiao,\
    \ X. Luo, P. Gao, and Y. Guo, \"Champ: Characterizing undesired app behaviors\
    \ from user comments based on market policies,\" in Int. Conf. on Software Engineering,\
    \ IEEE, 2021.\n- 52. H. Guo and M. P. Singh, \"Caspar: extracting and synthesizing\
    \ user stories of problems from app reviews,\" in Int. Conf. on Software Engineering,\
    \ IEEE, 2020.\n- 53. A. A. Al-Subaihin, F. Sarro, S. Black, L. Capra, and M. Harman,\
    \ \"App Store Effects on Software Engineering Practices,\" in Transactions on\
    \ Software Engineering, IEEE, 2021.\n- 54. H. Wang, Z. Liu, J. Liang, N. Vallina-Rodriguez,\
    \ Y. Guo, L. Li, J. Tapiador, J. Cao, and G. Xu, \"Beyond google play: A large-scale\
    \ comparative study of chinese android app markets,\" in Internet Measurement\
    \ Conference 2018, 2018.\n- 55. S. Jansen and E. Bloemendal, \"Defining app stores:\
    \ The role of curated marketplaces in software ecosystems,\" in ICSOB, Springer,\
    \ 2013.\n- 56. D. Walker and F. Myrick, \"Grounded theory: An exploration of process\
    \ and procedure,\" in Qualitative health research, Sage, 2006.\n- 57. A. P. M.\
    \ Coxon et al., Sorting data: Collection and analysis. Sage, 1999.\n- 58. S. Adolph,\
    \ W. Hall, and P. Kruchten, \"Using grounded theory to study the experience of\
    \ software development,\" in Empirical Software Engineering, Springer, 2011.\n\
    - 59. R. Hoda, J. Noble, and S. Marshall, \"Developing a grounded theory to explain\
    \ the practices of self-organizing Agile teams,\" in Empirical Software Engineering,\
    \ Springer, 2012.\n- 60. Z. Masood, R. Hoda, and K. Blincoe, \"How agile teams\
    \ make self-assignment work: a grounded theory study,\" in Empirical Software\
    \ Engineering, Springer, 2020.\n- 61. C. Vassallo, S. Panichella, F. Palomba,\
    \ S. Proksch, H. C. Gall, and A. Zaidman, \"How developers engage with static\
    \ analysis tools in different contexts,\" in Empirical Software Engineering, Springer,\
    \ 2020.\n- 62. J. Chen, X. Xia, D. Lo, J. Grundy, and X. Yang, \"Maintenance-related\
    \ concerns for post-deployed Ethereum smart contract development: issues, techniques,\
    \ and future challenges,\" in Empirical Software Engineering, Springer, 2021.\n\
    - 63. P. Wang, C. Brown, J. A. Jennings, and K. T. Stolee, \"Demystifying regular\
    \ expression bugs,\" in Empirical Software Engineering, Springer, 2022.\n- 64.\
    \ J. Cohen, \"A coefficient of agreement for nominal scales,\" in Educational\
    \ and psychological measurement, Sage, 1960.\n- 65. J. Pérez, J. Díaz, J. Garcia-Martin,\
    \ and B. Tabuenca, \"Systematic literature reviews in software engineering—Enhancement\
    \ of the study selection process using Cohen's kappa statistic,\" in Journal of\
    \ Systems and Software, Elsevier, 2020.\n- 66. C. A. Lantz and E. Nebenzahl, \"\
    Behavior and interpretation of the κ statistic: Resolution of the two paradoxes,\"\
    \ in Journal of clinical epidemiology, Elsevier, 1996.\n- 67. P. Pickerill, H.\
    \ J. Jungen, M. Ochodek, M. Maćkowiak, and M. Staron, \"Phantom: Curating github\
    \ for engineered software projects using time-series clustering,\" Empirical Software\
    \ Engineering, 2020.\n- 68. V. Khatibi Bardsiri, D. N. A. Jawawi, S. Z. M. Hashim,\
    \ and E. Khatibi, \"A flexible method to estimate the software development effort\
    \ based on the classification of projects and localization of comparisons,\" Empirical\
    \ Software Engineering, 2014.\n- 69. A. Al-Subaihin, F. Sarro, S. Black, and L.\
    \ Capra, \"Empirical comparison of textbased mobile apps similarity measurement\
    \ techniques,\" Empirical Software Engineering, 2019.\n- 70. T. Kuchta, T. Lutellier,\
    \ E. Wong, L. Tan, and C. Cadar, \"On the correctness of electronic documents:\
    \ studying, finding, and localizing inconsistency bugs in PDF readers and files,\"\
    \ Empirical Software Engineering, 2018.\n- 71. D. Arthur and S. Vassilvitskii,\
    \ \"k-means++: The advantages of careful seeding,\" tech. rep., Stanford, 2006.\n\
    - 72. S. Wold, K. Esbensen, and P. Geladi, \"Principal component analysis,\" in\
    \ Chemometrics and intelligent laboratory systems, Elsevier, 1987.\n- 73. Apple,\
    \ \"Apple Introduces the New iPhone 3G.\" https://www.apple.com/ca/newsroom/ 2008/06/09Apple-Introduces-the-New-iPhone-3G/,\
    \ 2008. Accessed: Jul. 17, 2022.\n- 74. Google, \"Chrome Web Store payments deprecation.\"\
    \ https://developer.chrome.com/ docs/webstore/cws-payments-deprecation/, 2022.\
    \ Accessed: Mar. 16, 2022.\n- 75. E. Commission, \"Digital Markets Act: Commission\
    \ welcomes political agreement on rules to ensure fair and open digital markets.\"\
    \ https://ec.europa.eu/commission/ presscorner/detail/en/IP\\_22\\_1978, 2022.\
    \ Accessed: Jul. 13, 2022.\n- 76. F-Droid, \"F-Droid Free and Open Source Android\
    \ App Repository.\" https:// f-droid.org/, 2022. Accessed: Oct. 02, 2022.\n- 77.\
    \ npm, \"npm About.\" https://www.npmjs.com/about, 2022. Accessed: Oct. 02, 2022.\n\
    - 78. E. International, \"TC39 Specifying JavaScript..\" https://tc39.es/, 2022.\
    \ Accessed: Oct. 02, 2022.\n- 79. T. Kodi, \"The Movie Database Python | Matrix\
    \ | Addons | Kodi.\" https://kodi.tv/ addons/matrix/metadata.themoviedb.org.python,\
    \ 2022. Accessed: Jul. 13, 2022.\n- 80. V. V. H. Pham, X. Liu, X. Zheng, M. Fu,\
    \ S. V. Deshpande, W. Xia, R. Zhou, and M. Abdelrazek, \"PaaS-black or white:\
    \ an investigation into software development model for building retail industry\
    \ SaaS,\" in Int. Conf. on Software Engineering Companion (ICSE-C), IEEE, 2017.\n\
    - 81. A. Finkelstein, M. Harman, Y. Jia, W. Martin, F. Sarro, and Y. Zhang, \"\
    Investigating the relationship between price, rating, and popularity in the Blackberry\
    \ World App Store,\" Information and Software Technology, 2017.\n- 82. F. Sarro,\
    \ A. A. Al-Subaihin, M. Harman, Y. Jia, W. Martin, and Y. Zhang, \"Feature lifecycles\
    \ as they spread, migrate, remain, and die in app stores,\" in Int. requirements\
    \ engineering conference (RE), IEEE, 2015.\n- 83. W. Aljedaani, M. Nagappan, B.\
    \ Adams, and M. Godfrey, \"A comparison of bugs across the ios and android platforms\
    \ of two open source cross platform browser apps,\" in Int. Conf. on Mobile Software\
    \ Engineering and Systems, IEEE, 2019.\n- 84. Z. Lu, Y. Shi, R. Tao, and Z. Zhang,\
    \ \"Blockchain for digital rights management of design works,\" in Int. Conf on\
    \ Software Engineering and Service Science (ICSESS), IEEE, 2019.\n- 85. T. Gaber,\
    \ A. Ahmed, and A. Mostafa, \"Privdrm: A privacy-preserving secure digital right\
    \ management system,\" in Evaluation and Assessment in Software Engineering, ACM,\
    \ 2020.\n- 86. A. Sung, S. Kim, Y. Kim, Y. Jang, and J. Kim, \"Test automation\
    \ and its limitations: a case study,\" in Int. Conf. on Automated Software Engineering\
    \ (ASE), IEEE, 2019.\n- 87. M. Lemon, \"Two Point Hospital no longer uses Denuvo\
    \ DRM.\" https://www.vg247. com/two-point-hospital-no-longer-uses-denuvo-drm,\
    \ 2018. Accessed: Mar. 31, 2023.\n- 88. X. He, W. Dai, G. Cao, R. Tang, M. Yuan,\
    \ and Q. Yang, \"Mining target users for online marketing based on app store data,\"\
    \ in Int. Conf. on Big Data (Big Data), IEEE, 2015.\n- 89. G. L. Scoccia, M. Autili,\
    \ G. Stilo, and P. Inverardi, \"An empirical study of privacy labels on the Apple\
    \ iOS mobile app store,\" in Int. Conf. on Mobile Software Engineering and Systems,\
    \ 2022.\n- 90. E. Murphy-Hill, T. Zimmermann, and N. Nagappan, \"Cowboys, ankle\
    \ sprains, and keepers of quality: How is video game development different from\
    \ software development?,\" in Int. Conf. on Software Engineering, 2014.\n- 91.\
    \ L. Pascarella, F. Palomba, M. Di Penta, and A. Bacchelli, \"How is video game\
    \ development different from software development in open source?,\" in Int. Conf.\
    \ on Mining Software Repositories, IEEE, 2018.\n- 92. D. Lee, G. K. Rajbahadur,\
    \ D. Lin, M. Sayagh, C.-P. Bezemer, and A. E. Hassan, \"An empirical study of\
    \ the characteristics of popular Minecraft mods,\" Empirical Software Engineering,\
    \ 2020.\n- 93. M. H. Ibrahim, M. Sayagh, and A. E. Hassan, \"Too many images on\
    \ dockerhub! how different are images for the same system?,\" Empirical Software\
    \ Engineering, 2020.\n- 94. G. H. Subramanian, P. C. Pendharkar, and M. Wallace,\
    \ \"An empirical study of the effect of complexity, platform, and program type\
    \ on software development effort of business applications,\" Empirical Software\
    \ Engineering, 2006.\n- 95. I. Manotas, C. Bird, R. Zhang, D. Shepherd, C. Jaspan,\
    \ C. Sadowski, L. Pollock, and J. Clause, \"An empirical study of practitioners'\
    \ perspectives on green software engineering,\" in Int. Conf. on Software Engineering,\
    \ 2016.\n- 96. S. Gholami, H. Khazaei, and C.-P. Bezemer, \"Should you upgrade\
    \ official docker hub images in production environments?,\" in Int. Conf. on Software\
    \ Engineering: New Ideas and Emerging Results (ICSE-NIER), IEEE, 2021.\n- 97.\
    \ E. Guzman, L. Oliveira, Y. Steiner, L. C. Wagner, and M. Glinz, \"User feedback\
    \ in the app store: a cross-cultural study,\" in Int. Conf. on Software Engineering:\
    \ Software Engineering in Society, 2018.\n- 98. D. Lee, D. Lin, C.-P. Bezemer,\
    \ and A. E. Hassan, \"Building the perfect game–an empirical study of game modifications,\"\
    \ Empirical Software Engineering, 2020.\n- 99. M. Nayebi, H. Farahi, and G. Ruhe,\
    \ \"Which version should be released to app store?,\" in Int. Symposium on Empirical\
    \ Software Engineering and Measurement (ESEM), IEEE, 2017.\n- 100. M. Nayebi,\
    \ B. Adams, and G. Ruhe, \"Release Practices for Mobile Apps–What do Users and\
    \ Developers Think?,\" in Int. Conf. on software analysis, evolution, and reengineering\
    \ (saner), IEEE, 2016.\n- 101. S. Shen, X. Lu, Z. Hu, and X. Liu, \"Towards release\
    \ strategy optimization for apps in Google Play,\" in Proceedings of the 9th Asia-Pacific\
    \ Symposium on Internetware, 2017.\n- 102. G. Ferreira, L. Jia, J. Sunshine, and\
    \ C. Kästner, \"Containing malicious package updates in npm with a lightweight\
    \ permission system,\" in Int. Conf. on Software Engineering (ICSE), IEEE, 2021.\n\
    - 103. C. Tang, S. Chen, L. Fan, L. Xu, Y. Liu, Z. Tang, and L. Dou, \"A large-scale\
    \ empirical study on industrial fake apps,\" in Int. Conf. on Software Engineering:\
    \ Software Engineering in Practice (ICSE-SEIP), IEEE, 2019.\n- 104. J. Vouillon\
    \ and R. D. Cosmo, \"On software component co-installability,\" Transactions on\
    \ Software Engineering and Methodology (TOSEM), 2013.\n- 105. M. Claes, T. Mens,\
    \ R. Di Cosmo, and J. Vouillon, \"A historical analysis of Debian package incompatibilities,\"\
    \ in Int. Conf. on Mining Software Repositories, IEEE, 2015.\n- 106. C. McMillan,\
    \ M. Grechanik, and D. Poshyvanyk, \"Detecting similar software applications,\"\
    \ in Int. Conf. on Software Engineering (ICSE), IEEE, 2012.\n- 107. W. Martin,\
    \ F. Sarro, and M. Harman, \"Causal impact analysis for app releases in google\
    \ play,\" in Int. Symposium on Foundations of software engineering, 2016.\n- 108.\
    \ W. Maalej, M. Nayebi, and G. Ruhe, \"Data-driven requirements engineering-an\
    \ update,\" in Int. Conf. on Software Engineering: Software Engineering in Practice\
    \ (ICSE-SEIP), IEEE, 2019.\n- 109. G. C. Ullmann, C. Politowski, Y.-G. Guéhéneuc,\
    \ and F. Petrillo, \"What makes a game high-rated? towards factors of video game\
    \ success,\" in Int. ICSE Workshop on Games and Software Engineering: Engineering\
    \ Fun, Inspiration, and Motivation, 2022.\n- 110. H. Khalid, M. Nagappan, E. Shihab,\
    \ and A. E. Hassan, \"Prioritizing the devices to test your app on: A case study\
    \ of android game apps,\" in Int. Symposium on Foundations of Software Engineering,\
    \ 2014.\n- 111. M. Nayebi, H. Cho, H. Farrahi, and G. Ruhe, \"App store mining\
    \ is not enough,\" in Int. Conf. on Software Engineering Companion (ICSE-C), IEEE,\
    \ 2017.\n- 112. C. Rosen and E. Shihab, \"What are mobile developers asking about?\
    \ a large scale study using stack overflow,\" in Empirical Software Engineering,\
    \ Springer, 2016.\n- 113. H. Wang, X. Wang, and Y. Guo, \"Characterizing the global\
    \ mobile app developers: a large-scale empirical study,\" in Int. Conf. on Mobile\
    \ Software Engineering and Systems, IEEE, 2019.\n- 114. Y. Y. Ng, H. Zhou, Z.\
    \ Ji, H. Luo, and Y. Dong, \"Which Android app store can be trusted in China?,\"\
    \ in Computer Software and Applications Conference, IEEE, 2014.\n- 115. S. McIntosh,\
    \ Y. Kamei, and M. Nagappan, Release Engineering for Mobile Applications — Communications\
    \ of NII Shonan Meetings. Springer, 2019."
- id: next4_snapshots_in_ext4_file_system_aditya_dani_1_shardul_mangade_2_piyush_nimbalkar_3_harshad_shirwadkar_4
  title: 'Next4: Snapshots in Ext4 File System'
  abstract: 'The growing value of data as a strategic asset has given rise to the

    necessity of implementing reliable backup and recovery solutions in the most

    efficient and cost-effective manner. The data backup methods available today on

    linux are not effective enough, because while running, most of them block I/Os

    to guarantee data integrity. We propose and implement Next4 - file system based

    snapshot feature in Ext4 which creates an instant image of the file system, to

    provide incremental versions of data, enabling reliable backup and data

    recovery. In our design, the snapshot feature is implemented by efficiently

    infusing the copy-on-write strategy in the write-in-place, extent based Ext4

    file system, without affecting its basic structure. Each snapshot is an

    incremental backup of the data within the system. What distinguishes Next4 is

    the way that the data is backed up, improving both space utilization as well as

    performance.'
  url: http://arxiv.org/abs/2403.06790v1
  keywords: '**- Ext4, Snapshot, Copy-on-Write, Backup**'
  document: '# Next4: Snapshots in Ext4 File System


    Aditya Dani 1 , Shardul Mangade 2 , Piyush Nimbalkar 3 , Harshad Shirwadkar 4


    *Computer Engineering, Pune Institute of Computer Technology, Pune-411043, Maharashtra,
    India*


    <sup>1</sup>aditya.dani@gmail.com, <sup>2</sup>shardul.mangade@gmail.com, <sup>3</sup>piyushmnimbalkar@gmail.com,


    <sup>4</sup>harshadshirwadkar@gmail.com


    *Abstract***- The growing value of data as a strategic asset has given rise to
    the necessity of implementing reliable backup and recovery solutions in the most
    efficient and cost-effective manner. The data backup methods available today on
    Linux are not effective enough, because while running, most of them block I/Os
    to guarantee data integrity. We propose and implement Next4 file system based
    snapshot feature in Ext4 which creates an instant image of the file system, to
    provide incremental versions of data, enabling reliable backup and data recovery.
    In our design, the snapshot feature is implemented by efficiently infusing the
    copy-on-write strategy in the write-in-place, extent based Ext4 file system, without
    affecting its basic structure. Each snapshot is an incremental backup of the data
    within the system. What distinguishes Next4 is the way that the data is backed
    up, improving both space utilization as well as performance.**


    *Keywords***- Ext4, Snapshot, Copy-on-Write, Backup**


    #### 1. **INTRODUCTION**


    #### 1.1. **Motivation:**


    In any storage system, the feature that is of paramount importance to the user
    is data protection. While the user takes for granted that data will not be lost
    due to a system crash or a design bug, the user also expects that a storage system
    will protect him or her from inadvertent deletions, unwanted modifications, malicious
    agents, etc.


    Various solutions have been proposed by the storage industry, and have been adapted
    to various degrees. One very common method is by taking regular backups, either
    on the storage system itself, or onto tapes. This method has the major disadvantage
    of requiring massive storage capacity, and additionally, of causing substantial
    disruption in service while a backup is being made. Additionally, because of these
    disadvantages, it is not possible to create backups that are more frequent than
    about once a day, causing a large window of loss if data must be restored.


    # 1.2. **Snapshot Concept:**


    A snapshot is a point-in-time copy of a volume similar to taking a picture of
    the data at that instant. Snapshots look and behave like complete backups – they
    can be mounted as volumes, read simultaneously without affecting the volume that
    they are snapshots of, rolled back onto the volume if necessary, and deleted to
    free space. The ease and flexibility with which these operations may be performed
    has been instrumental in speeding up the adoption of snapshot technology in the
    IT industry.


    Snapshots can be implemented at volume level as well by a volume manager such
    as LVM/LVM2[1]. Logical Volume Manager (LVM)/LVM2 is a volume manager located
    between a file system and a device driver. The snapshot in LVM is achieved by
    block- level copy-on-write (COW) and is performed on a unit of Logical Volume
    in the Volume Group. However, the snapshot capabilities at the LVM level have
    some caveats as below:


    - The need to define a fixed volume size per snapshot.

    - Copy overhead per snapshot for every write operation.

    - Not scalable to O(1TB), requires O(1GB) RAM and long loading time.

    - There is some memory overhead per mounted snapshot volume.

    - Not possible to define a snapshot on a directory (sub volume).


    Some of these caveats can be tackled by changes to the LVM snapshot implementation,
    but some are fundamental to the volume level snapshot approach. For this reason
    it makes sense to try to reach the design goals by implementing snapshots at the
    file system level.


    #### 1.3. **Next4 Snapshots:**


    Next4 deals with implementation of file system based snapshot feature in Ext4
    file system, without disturbing the basic Ext4 structure and features. Ext4 is
    the successor of the popular and most widely used Ext3 file system. Next4 will
    enable to create an incremental, read only snapshot of the file system, which
    can be recovered back by mounting the snapshot file on a loop back device. Next4
    snapshots provide the simplicity of the LVM snapshots with high performance and
    scalability. The snapshot management capabilities include creating as many snapshots
    as desired and deleting any past snapshots to free up file system space.


    ## 2. **DESIGN DETAILS**


    #### **Snapshot File**


    Every snapshot taken is stored in a snapshot file, which is a regular sparse file.
    A sparse file is a type of computer file that attempts to use file system space
    more efficiently when blocks allocated to the file are mostly empty. This is achieved
    by writing brief information (metadata) *representing* the empty


    blocks to disk instead of the actual ''empty'' space which makes up the block,
    using less disk space. A snapshot file has size same as that of the entire file
    system and represents the state of the file system when the snapshot was taken.
    Every logical block offset in the snapshot file represents a physical block in
    the underlying block device. A mapped block in a snapshot file holds a copy of
    the physical block data at the time of snapshot creation. A ''hole'' in the snapshot
    file signifies that the snapshot''s version of this block is identical to a later
    snapshot''s version or to the version on the file system. Snapshot files are marked
    with a snapshot file flag, which is inherited from their parent directory and
    cannot be otherwise set on regular files.


    ![](_page_1_Figure_1.jpeg)


    #### **Copy on Write (COW)**


    Copy on write is a strategy in which a copy of data to be modified is made before
    write. In this method data from the original physical block is copied to a new
    physical location. The old data in the original physical block is then overwritten
    by new data. In case of a rewrite, after a snapshot is taken, the original data
    is preserved under snapshot file by the COW operation. Thus the logical offset
    in the snapshot file corresponding to the original physical block offset is mapped
    to the new physical location containing original data.


    #### **Move on Write (MOW)**


    Move on write is a slight variation of copy on write technique. In this case too
    copy of the data is made to a new physical location however, the new data is written
    at new physical location instead of the original physical location. Thus in case
    of rewrite after snapshot, logical offset in the snapshot file corresponds to
    the original physical location itself.


    #### **COW Bitmap**


    Cow bitmap keeps track of the blocks on which the COW or MOW operation is to be
    performed, in the same fashion as block bitmap keep track of the blocks which
    used by the file system. A COW bitmap is essentially a copy of the block bitmap
    at the time of creation of the snapshot and thus keeps track of the blocks which
    were present in the file system at that time. A ''set'' bit in COW bitmap indicates
    that the corresponding block is in use by a snapshot.


    ## **Exclude Bitmap**


    Exclude Bitmap keeps track of the blocks which are to be skipped from any COW
    or MOW operation, essentially the blocks mapped to the snapshot file. The result
    is that snapshot file blocks are never copied or moved to active snapshot. During
    initialization of a COW bitmap block, the block bitmap block is masked with the
    exclude bitmap block.


    # **Extent**


    Ext4 is an extent based file system, wherein extent mapped files can be used instead
    of the traditional block mapped files. An extent is a combination of two integers,
    the first stating the offset block and the second denoting the length i.e. number
    of contiguous blocks after the offset that are free or allocated. It thus improves
    large file performance and reduces fragmentation. A single extent in ext4 can
    map up to 128 MB of contiguous space with a 4 KB block size [2]. There can be
    4 extents stored in the inode. When there are more than 4 extents to a file, the
    rest of the extents are indexed in an Htree.


    ![](_page_1_Figure_13.jpeg)


    Fig.2.2 Extent


    #### 3. **WORKING**


    Let us illustrate the working by the following example:


    1. Suppose initially the file system consists of a file which contains data "HEADSHOT".
    As shown in figure 3.1 the file consists of two data extents (40-43) "HEAD" and
    (50-53) "SHOT" referred to by its inode at block number 10.


    ![](_page_1_Figure_18.jpeg)


    Fig. 3.1 File System


    2. Now at this stage if we take a snapshot S1 then, a new sparse file for the
    snapshot is created with its inode at block number 90 as shown in figure 3.2.This
    snapshot is the ''active'' snapshot as it is the only one which is being modified.
    Initially the snapshot file is empty and consists of holes for corresponding data
    blocks. Thus the logical offsets (L) 10, 40-43, 50-53 map to physical offsets
    (P) ''0'' which represents a ''hole''.


    ![](_page_2_Figure_0.jpeg)


    Fig. 3.2 Snapshot (S1) Take


    3. Suppose we have a re-write request for data at extent 40-43 from "HEAD" to
    "SNAP". Thus now we do a MOW operation for the data and COW operation for metadata
    (inode). As explained earlier, the data "SNAP" is written at a new location 60-63(MOW)
    and a copy of the inode at location 10 is made to the location 20 (COW). The metadata
    at location 10 is then modified to point extents "SNAP"(60-63) and "SHOT" (50-53).
    The logical offsets at 10 and 40-43 in the snapshot file are then mapped to blocks
    20 and 40-43 instead of ''holes''. Thus the file refers to data "SNAPSHOT" under
    the file system and the same file refers to data "HEADSHOT" under snapshot S1.


    ![](_page_2_Figure_3.jpeg)


    Fig. 3.3 Data Rewrite


    4. Now we take another snapshot S2, thus an empty snapshot file consisting of
    all holes mapping to data blocks on disk will be created (shown in figure 3.4)
    Now S2is the ''active'' snapshot as explained earlier.


    ![](_page_2_Figure_6.jpeg)


    Fig. 3.4 Snapshot (S2) Take


    5. Suppose we have a re-write request for data from "SH" to "FS" at location 50-51.
    The data "FS" is written at a new location 70-71(MOW) and a copy of the inode
    at location 10 is made to the location 30(COW). The metadata at location 10 is
    then modified to point extents "SNAP"(60-63) "FS" (70-71) and "OT"(52-53). The
    logical offsets at 10 and 50-51 in the snapshot file S2 are then mapped to blocks
    30 and 50-51 instead of ''holes''. Thus the file refers to data "SNAPFSOT" under
    the file system and the same file refers to data "SNAPSHOT" under snapshot S2.


    ![](_page_2_Figure_9.jpeg)


    Fig. 3.5 Data Rewrite – Extent Break


    6. Suppose now there is a request to delete data "OT". Thus entry for extent 70-71in
    inode at 10 is removed and the inode points to only "SNAP" 60-63 and "FS" 50-51.
    The extent containing data "OT" is not freed but is protected under the active
    snapshot S2 by MOW operation. The snapshot file inode maps the logical offset52-53
    to the blocks 52-53 instead of hole.


    ![](_page_2_Figure_12.jpeg)


    Fig. 3.6 Data Delete


    7. Now we wish to delete the snapshot S2, then the data blocks under S2 are checked
    for being referred to by any previous snapshots. In this case (as in figure 3.6)
    the data "SHOT"(50-53) is referred to by S1.The logical offsets 50-53 in the snapshot
    file S1 are then mapped to blocks 50-53 instead of ''holes''. The inode blocks
    at location 80 (S2) and 30 (File under S2) are then unallocated and the space
    is returned to the file system.(as shown in figure 3.7)


    ![](_page_3_Figure_0.jpeg)


    Fig. 3.7 Snapshot Delete


    # 4. **BENEFITS**


    - Snapshots are space efficient; require significantly less storage space as compared
    to traditional backup techniques.

    - Creation of a snapshot (backup) is time efficient and requires low performance
    overhead.

    - Some of the next generation file systems such as ZFS,

    - Btrfs support snapshot feature, however both are not ready for production use
    and both implement COW by default. By implementing COW and MOW along with snapshot
    feature in Ext4, which is already a file system used in production system[5][6],
    Next4 implementation will add use case for Ext4.


    ## 5. **CONCLUSION**


    In this paper, we present a file system level snapshot design suitable for recovery
    and backup. Snapshot technology represents one of the most significant storage
    enhancements in recent years, promising to reshape future data backup and recovery
    solutions. Apart from backup systems snapshot would also prove useful in applications
    such as software testing and system recovery tools. We implement snapshot in the
    extent based Ext4 file system. Ext4 is the successor of Ext3, the most widely
    used file system, and is shipped as the base file system in most Linux distributions
    today. Thus introducing snapshot feature in Ext4 will cater a huge number of users
    with its benefits.


    #### **ACKNOWLEDGEMENT**


    We wish to thank the following people for their contribution to the system or
    the paper. Mrs. Rekha Kulkarni whose reviews helped us to build on our own ideas.
    Mr. Vedang Manerikar and Mr. Chinmay Kamat, our guides whose ideas and timely
    criticism helped us to bring this project about. Mr. Amir Golstein, who laid the
    seed of the idea in the first place. Lastly, but not the least, we wish to thank
    the anonymous reviewers, who patiently read our paper and gave us valuable


    inputs which helped make significant improvements in this paper.


    #### **REFERENCE**


    - [1] D. Teigland, H. Mauelshagen, 2001, "Volume Managers in Linux", *USENIX Technical
    Conference*.

    - [2] The new ext4 file system: current status and future plans- Avantika Mathur,
    Mingming Cao, Suparna Bhattacharya *in the proceedings of Ottawa Linux Symposium
    2007.*

    - [3] "Ext4 block and inode allocator improvements" by Aneesh Kumar K.V., Mingming
    Cao, Jose R Santos, Andreas Dilger *in the proceedings of Ottawa Linux Symposium
    2008.*

    - [4] Maurice J. Bach, *The Design of the Unix Operating System*, Prentice Hall.

    - [5] "Android 2.3 Gingerbread to use Ext4 file system". The H Open. 14 December
    2010.

    - [6] "Google to switch to Ext4". Phoronix. 14 January 2010.

    - [7] Ext4 wiki: http://en.wikipedia.org/wiki/ext4.'
- id: crash_consistency_in_dram_nvm_disk_hybrid_storage_system_1_st_guoyu_wang_college_of_computer_science_and_technology_jilin_university_changchun_china
  title: Crash Consistency in DRAM-NVM-Disk Hybrid Storage System
  abstract: 'NVM is used as a new hierarchy in the storage system, due to its intermediate

    speed and capacity between DRAM, and its byte granularity. However, consistency

    problems emerge when we attempt to put DRAM, NVM, and disk together as an

    efficient whole. In this paper, we discuss the challenging consistency problems

    faced by heterogeneous storage systems, and propose our solution to the

    problems. The discussion is based on NVPC as a case study, but can be inspiring

    and adaptive to all similar heterogeneous storage systems.'
  url: http://arxiv.org/abs/2408.04238v1
  keywords: Consistency, Heterogeneous storage, Nonvolatile memory
  document: '# Crash Consistency in DRAM-NVM-Disk Hybrid Storage System


    1 st Guoyu Wang *College of Computer Science and Technology Jilin University*
    Changchun, China


    wgy21@mails.jlu.edu.cn


    3 rd Haoyang Wei *College of Computer Science and Technology Jilin University*
    Changchun, China hywei23@mails.jlu.edu.cn


    5 th Juncheng Hu<sup>∗</sup> *College of Computer Science and Technology Jilin
    University* Changchun, China jchu@jlu.edu.cn


    2 nd Xilong Che *College of Computer Science and Technology Jilin University*
    Changchun, China chexilong@jlu.edu.cn


    4 th Chenju Pei *College of Computer Science and Technology Jilin University*
    Changchun, China peicj2121@mails.jlu.edu.cn


    *Abstract*—NVM is used as a new hierarchy in the storage system, due to its intermediate
    speed and capacity between DRAM, and its byte granularity. However, consistency
    problems emerge when we attempt to put DRAM, NVM, and disk together as an efficient
    whole. In this paper, we discuss the challenging consistency problems faced by
    heterogeneous storage systems, and propose our solution to the problems. The discussion
    is based on NVPC as a case study, but can be inspiring and adaptive to all similar
    heterogeneous storage systems.


    *Index Terms*—Consistency, Heterogeneous storage, Nonvolatile memory


    #### I. INTRODUCTION


    With the emergence of non-volatile memory (NVM), various works have been proposed
    to leverage its byte-addressable and persistence characteristics. Among these
    approaches, the most compatible, efficient, and promising one is to use NVM to
    accelerate existing disk file systems [\[5\]](#page-7-0), [\[8\]](#page-8-0),
    [\[11\]](#page-8-1), in which case users can utilize NVM in their current system
    transparently without migration cost. However, we discover that the heterogeneity
    between DRAM, NVM, and disk makes it harder for these works to fully exploit the
    potential of NVM.


    NVPC [\[8\]](#page-8-0) is the only one of the accelerators that precisely accelerates
    only the slow path, i.e. sync writes, of the legacy storage stack, with no slow-down
    to its lower file system. We notice that its implementation abandons the layered
    design adopted by previous work, introducing an on-demand sync absorbing mechanism,
    which is the fundamental of its high efficiency. However, this design also introduces
    consistency


    <sup>∗</sup>Corresponding author.


    problems between NVM and disk, which are only briefly and insufficiently discussed
    in that work. We observe that this consistency problem is common to a heterogeneous
    storage system with different write sequences and access granularity. Thus we
    believe that it is necessary to further discuss the consistency problems in such
    systems.


    In this work, we will first introduce the background of NVM-based heterogeneous
    storage systems. Then based on NVPC, we will discuss the consistency problems
    and solutions. Specifically, for each heterogeneous characteristic, we will first
    figure out the exact problems that the system is facing. Then we will analyze
    the causes of the consistency problems. Finally, we will provide the solutions
    to each problem based on our analysis.


    #### II. HETEROGENEOUS STORAGE SYSTEMS


    As the new hierarchy of the storage system, NVM has a byte-addressable access
    pattern, with intermediate speed and capacity between DRAM and SSD. The unique
    characteristics of NVM bring both chances and challenges to its users. Various
    works have been proposed to leverage NVM, such as NVM-based file systems [\[1\]](#page-7-1),
    [\[2\]](#page-7-2), [\[12\]](#page-8-2), tiered memories [\[6\]](#page-7-3), [\[10\]](#page-8-3),
    and NVM-enabled databases [\[3\]](#page-7-4), [\[7\]](#page-8-4), [\[9\]](#page-8-5).
    However, when we put different storage layers with different characteristics together,
    the challenges become particularly noticeable.


    The early attempts to integrate heterogeneous storage devices are cross-media
    file systems. For example, Strata [\[4\]](#page-7-5) and Ziggurat [\[13\]](#page-8-6)
    are designed as monolithic file systems that use both DRAM, NVM, and disk, to
    provide a fast and a large capacity in the same time. Strategies are provided
    in these works to place data on the most suitable storage device. However, these
    cross-media file systems are usually complex and less mature than traditional
    disk file systems. The potential security risk and the data migration cost hinder
    their wide use.


    A novel approach is to utilize NVM as a transparent disk file system accelerator.
    SPFS [\[11\]](#page-8-1) is an NVM-based overlay file system atop the disk file
    system, providing sync write prediction and absorption to eliminate the slow foreground
    I/O hang. Since SPFS is a separate layer before the DRAM page cache, when a write
    is executed, it should either be absorbed by SPFS or be left to the lower page
    cache and disk file system, at which point we don''t know if there will be a sync
    next. If the decision is wrong, we may suffer from the long disk I/O on a false-positive,
    or experience unnecessary slow NVM write on a false-negative. The two-tier indexing
    also introduces extra slow-down to disk file systems.


    P2CACHE [\[5\]](#page-7-0) is another NVM-based overlay accelerator, trying to
    adopt both the fast read speed of DRAM and the persistency of NVM. The difference
    from SPFS is that P2CACHE puts DRAM and NVM into one layer. Each write on P2CACHE
    is stored to both the DRAM and the NVM. This double-write mechanism is easy to
    implement, and can provide a strong consistency. However, the cost of accelerating
    sync writes is the slow-down to all normal writes.


    NVPC [\[8\]](#page-8-0) is the latest work that provide transparent disk file
    system acceleration with no extra performance tax. The key of its efficient acceleration
    is the balance between heterogeneous storage devices. Specifically, reads, writes,
    and disk writebacks are always served by the fast DRAM. Only the slow sync will
    log relevant writes to the NVM. Meanwhile, NVPC provide an active sync strategy
    to efficiently absorb small sync writes with the byte-addressing ability of NVM.


    Though NVPC is the only accelerator that introduces no slow-down, the performance
    doesn''t come for free. The NVMabsorbed sync writes, the async write-back to disk,
    the different write granularity between disk and NVM, and the different access
    modes (queued v.s. direct) between disk and NVM, lead to great challenges of the
    eventual consistency of data. The consistency problems and the solutions are only
    briefly and partially addressed in the paper of NVPC. We find that the problems
    are more complex than they seem to be, and worth to be discussed further. We are
    taking NVPC as a case study in this paper, but we believe that the discussions
    are also meaningful to the design of all heterogeneous storage systems that adopt
    different devices with different write sequences and different write granularity.


    # III. CONSISTENCY PROBLEMS AND SOLUTIONS IN THE SYSTEM


    To analyze the consistency problems faced by heterogeneous storage systems, we
    need to first clarify the definition and the scope of a sync operation. Sync (e.g.
    fsync) on Linux or other POSIX-compatible systems forces all data for a file to
    be transferred to the storage device. The sync will not return until the data
    is successfully applied to the storage, at which point the storage reaches a consistent
    state with the DRAM page cache. For the special case, O SYNC, the difference is
    that there is a sync operation implicitly following each write operation on a
    file descriptor. However, its consistency model shows no difference with an explicit
    sync. We do not discuss the multi-descriptor or multi-thread behavior of sync
    and normal writes here, because it is somewhat undefined, and such ambiguity should
    be eliminated with locks by users.


    From the user''s aspect, sync is usually used as a "barrier" on the storage system,
    implying that *any event happens after the return of the sync can be based on
    the premise that the data before the sync has been persisted by the storage*.
    We will focus on the file system events, i.e. read, write, sync, and write-back
    here, because any other events that may influence the external visibility are
    based on the promise of the file system.


    We also need to define what is a crash for the consistency discussion. When we
    refer to a crash, it usually means that the power is down at some point of time.
    After that, all volatile states of the system are vanished, and the only way to
    grab data is to access persistent storage devices. In the discussion scope of
    NVPC, the significant feature of crash is that after the crash, all page cache
    are lost, and NVPC needs to recover data from NVM and disk.


    Definition 1. The event type set E = {read(r), write(w), sync, writeback(wb),
    crash, "(,)", "[, ]"}.


    Definition 2. The sequence "(,)" on the set of events of a file system defines
    such a relation: a, b, c ∈ E, if a happens before b, and b happens before c, and
    there are no crash event besides a, b, and c, then (a, b, c). The number of events
    in "(,)" is variable. Note that "(,)" only defines the order of the events inside,
    but does not imply that the events should happen adjacently, i.e, (read, write,
    sync, crash, write) ⇔ (read, crash, write).


    Definition 3. The sequence "[, ]" on the set of events of a file system defines
    such a relation: if (a, b, c), and any event X besides a, b, and c between the
    first element a and the last element c satisfy X ̸∈ {write, sync, writeback},
    then [a, b, c]. The number of events in "[, ]" is variable.


    <span id="page-1-0"></span>Theorem 1. If (write, sync, crash, read), then when
    read is performed, the data on the storage should be no earlier than the write.


    <span id="page-1-1"></span>Theorem 2. The sync semantics of a file system are
    not violated, if and only if for each (write, sync, crash, read), Theorem [1](#page-1-0)
    is respected.


    Theorem [1](#page-1-0) and Theorem [2](#page-1-1) are axiomatic according to the
    definition of sync operation.


    In NVPC or other similar heterogeneous storage systems, we would expect that the
    sync semantics are not violated. However, since we have two (or more) write destination
    devices with different write sequences and different access granularity, consistency
    problems emerge. The following discussion will be based on NVPC, but the same
    problems and solutions also apply to other heterogeneous storage systems.


    ### <span id="page-2-9"></span>*A. Problems from Write Sequence Difference*


    To maximize the performance of the system while maintaining the capacity, some
    data should be written to the NVM, and some data to the disk. Specifically, in
    NVPC, those write requests with urgent persist needs are directed to the NVM,
    while other writes obey the async write-back rule from the DRAM page cache to
    the disk. This leads to different write sequences on NVM and disk. In this section,
    we suppose that the NVM and the disk have the same write granularity, which is
    a page, to demonstrate the problems brought by different write sequences.


    Fig. [1](#page-3-0) shows a workflow on NVPC. At t2, both page cache, disk, and
    NVM reach a consistent state. Then as we perform operations on NVPC, data flows
    to different places as expected. However, when we inject crashes into the timeline,
    we will find some problematic cases caused by the different write sequences between
    disk and NVM.


    <span id="page-2-0"></span>Scenario A.1. If we crash at t5, then after recovery,
    we have V 1 on disk and V 2 on NVM. It seems like NVM has successfully stored
    the newer data version (V 2) because of the sync (O2). However, since we don''t
    have a timestamp on the data, we don''t know whether the disk version (V 1) or
    the NVM version (V 2) is fresher. From the diagram we can see that V 2 is fresher,
    so let''s assume that we adopt the data on NVM after a crash. In such case, if
    we perform O3 after the crash, we have (O1, sync, crash, O3), and O3 returns V
    2 from the NVM, which respects Theorem [1.](#page-1-0) Thus according to Theorem
    [2,](#page-1-1) the sync semantics are not violated.


    <span id="page-2-5"></span>Scenario A.2. If we crash at t8, then after recovery,
    we have V 3 on disk and V 2 on NVM. Now the disk has the fresher version. If we
    follow the assumption in Scenario [A.1,](#page-2-0) then after the crash when
    we perform O5 we adopt V 2 on NVM instead of V 3 on disk. Now we encounter a data
    rollback because we are replacing newer V 3 with older V 2. But it still doesn''t
    violate the sync semantics, because there is no sync between O4 and O5, i.e. (O4,
    ¬sync, crash, O5).


    <span id="page-2-1"></span>Scenario A.3. If we crash at t10, then after recovery,
    we have V 3 on disk and V 2 on NVM, just like Scenario [A.3.](#page-2-1) However,
    the difference is that we performed a sync (O6) before the crash. Since the page
    is not dirty at t9, O6 will return with nothing done. But when we perform O7 after
    the crash, following the assumption in Scenario [A.1,](#page-2-0) we will get
    V 2 from the NVM instead of the V 3 on disk. This violates Theorem [1,](#page-1-0)
    because (O4, sync, crash, O7), but the data of O4 (V 3) is lost if we perform
    O7 after a crash. The only way to fix this is to adopt the data version on the
    disk, but this in turn leads to the violation of Theorem [1](#page-1-0) in Scenario
    [A.1.](#page-2-0)


    <span id="page-2-2"></span>*Problem* 1*.* The different write sequences of disk
    and NVM, e.g. V 1 → V 3 and V 1 → V 2 in Fig. [1,](#page-3-0) may lead to two
    different final versions of data on the two storage devices. Since we don''t know
    which one is fresher, choosing any one of them as the final version can violate
    Theorem [1,](#page-1-0) and thus violates the sync semantics.


    <span id="page-2-4"></span>*Solution* 1*.* Since Problem [1](#page-2-2) is caused
    by the missing version information for disk and NVM data, we can solve it by adding
    the lost information. Specifically, we can maintain a global persistent variable
    in the NVM for each page to indicate which storage device has the latest data
    version of that page. Then we can choose the right data according to this information
    after the crash. The process is described in Algorithm [1.](#page-2-3)


    <span id="page-2-3"></span>Algorithm 1 Solution to problem 1: maintain a persistent
    variable for each data page.


    |     | 1: global variables                             |

    |-----|-------------------------------------------------|

    | 2:  | latest dev[1 page num] ▷ Device that stores the |

    |     | latest data. Persistent.                        |

    |     | 3: end global variables                         |

    |     | 4: procedure WRITEBACK(page)                    |

    | 5:  | WRITE DISK(page)                                |

    | 6:  | latest dev[page.index] ← DISK                   |

    |     | 7: end procedure                                |

    |     | 8: procedure SYNC(page)                         |

    | 9:  | if page is dirty then                           |

    | 10: | WRITE NVM(page)                                 |

    | 11: | latest dev[page.index] ← NVM                    |

    | 12: | end if                                          |

    |     | 13: end procedure                               |

    |     | 14: function CRASH RECOVER(page index)          |

    | 15: | if latest dev[page index] = DISK<br>then        |

    | 16: | return READ DISK(page index)                    |

    | 17: | else if latest dev[page index] = NVM<br>then    |

    | 18: | return READ NVM(page index)                     |

    | 19: | end if                                          |

    |     | 20: end function                                |


    <span id="page-2-6"></span>Proposition 1. Solution [1](#page-2-4) solves Problem
    [1.](#page-2-2)


    *Proof.* To prove that all (w, sync, crash, r) respect Theorem [1,](#page-1-0)
    we can simply prove that the last (w, sync, crash, r) respects Theorem [1,](#page-1-0)
    because when w is persisted, the whole page with the data version no earlier than
    w is persisted, meaning that the results of all previous writes are persisted.
    Now (w, sync, crash, r) has and only has the following three possible cases to
    prove in the context of Problem [1:](#page-2-2)


    <span id="page-2-7"></span>*Case* 1.1*.* A write-back wb happens after the write
    w before the sync operation is called. We mark it as [w, wb, sync, crash, r].
    In this case, according to Algorithm [1,](#page-2-3) wb writes the data of w to
    the disk, marks the page as clean, and marks the page''s latest dev as DISK. The
    sync needs to do nothing on the already-cleaned page. Then after the crash, the
    r will read the recovered data from DISK, which is the data of w, respecting Theorem
    [1.](#page-1-0)


    <span id="page-2-8"></span>*Case* 1.2*.* A write-back wb happens after the sync
    before the crash. We mark it as [w, sync, wb, crash, r]. In this case, the sync
    first writes the data of w to the NVM and marks the


    <span id="page-3-0"></span>![](_page_3_Figure_0.jpeg)


    <span id="page-3-1"></span>Fig. 2. Space-time diagram for problematic cases caused
    by variant write granularity.


    page''s latest dev as NVM. Then wb writes the data again to the disk and marks
    the page''s latest dev as DISK. Then after the crash, the r will read the recovered
    data from DISK, which is the data of w, respecting Theorem [1.](#page-1-0)


    *Case* 1.3*.* The crash occurred before the write-back wb would have a chance
    to perform. We mark it as [w, sync, crash, r]. In this case, the sync writes the
    data of w to the NVM and marks the page''s latest dev as NVM. Then after the crash,
    the r will read the recovered data from NVM, which is the data of w, respecting
    Theorem [1.](#page-1-0)


    According to Theorem [2,](#page-1-1) now that all cases respect Theorem [1,](#page-1-0)
    Algorithm [1](#page-2-3) is proved to solve Problem [1.](#page-2-2)


    #### <span id="page-3-2"></span>*B. Problems from Write Granularity Difference*


    To leverage the byte-addressable characteristic of NVM, NVPC introduces small
    sync writes. Thus on NVM, data can be written with any length, which is different
    from the block granularity of disk. Such arbitrary write length support can improve
    the performance of small sync writes, but brings further consistency problems
    to the system.


    Fig. [2](#page-3-1) shows a workflow on NVPC with arbitrary write length support.
    At t2, both page cache, disk, and NVM reach a consistent state. Then as we perform
    operations on NVPC, data flows to different places correctly. The difference with
    Fig. [1](#page-3-0) is that the write to the NVM is no longer fixed to a page.
    For each NVM record, it can persist a sync write event with any write length below
    a page. Note that for ease of management, the data should not cross page boundaries,
    or it should be divided into multiple records according to page boundaries. Also
    note that NVPC will perform a whole-page sync before starting a series of arbitrary
    length sync writes, so that previous writes are not lost. We can mark wholepage
    normal sync as sync<sup>N</sup> , arbitrary-length sync write as [w, syncA], and
    a series of arbitrary length sync writes as (sync<sup>N</sup> , ¬w, [w, syncA]
    <sup>n</sup>), n ≥ 1. To rebuild the whole page data from NVM, NVPC has to backtrack
    all partial writes on the same page. Now when we inject crashes into the timeline,
    more problematic cases occur, due to the different write granularity between disk
    and NVM.


    Scenario B.1. Without Solution [1,](#page-2-4) the workflow in Fig. [2](#page-3-1)
    still faces the same consistency problems as Scenario [A.1](#page-2-0) and Scenario
    [A.2.](#page-2-5) E.g. when a crash happens at t4 or t8, NVPC will have trouble
    with choosing data between the disk version and the NVM version. By adding Solution
    [1,](#page-2-4) these problems can be solved similarly. The proof is the same
    and is omitted.


    Scenario B.2. Suppose that we have adopted Solution [1.](#page-2-4) Now if we
    crash at t10, then after the recovery we have V 3 (a317--) on disk, and V 1 →
    O1 → O6 on NVM. By Algorithm [1](#page-2-3) we will choose the NVM as the latest
    data version, and from the NVM we can rebuild abcxyz. We have (writeO6, syncO6,
    [crash, O7]) and the data of O6 (xyz) is successfully applied to the final version
    data, so that O7 can read it correctly, respecting Theorem [1.](#page-1-0) However,
    the final result abcxyz is actually violating Theorem [1.](#page-1-0) Because
    the arbitrary write length on NVM means that O6''s write may not overwrite previous
    write O3, and we need to also check (O3, syncO4, crash, O7) in this workflow.
    When we rebuild abcxyz from the NVM we only have the outcome of O1 and O6, but
    O3''s data 317 is lost. Thus (O3, syncO4, crash, O7) violates Theorem [1](#page-1-0)
    even if Solution [1](#page-2-4) is adopted.


    <span id="page-4-2"></span>*Problem* 2*.* The problem we are facing in Scenario
    [B.2](#page-2-5) is that the write sequence and the write granularity of NVM are
    both different from disk, e.g. in Fig. [2,](#page-3-1) the disk has V 1 ⇒ V 3,
    and the NVM has V 1 ⇒ O1(part of V 2)⇒ O6(part of V 4). Thus when we retrieve
    data from NVM, sync data that is persisted on disk by write-back may lost, because
    later NVM records do not take charge of previous writes that are out of its range.
    E.g. at t6 O3 is successfully recorded by the disk, while at t9 the NVM only records
    O6, but not the full V 4, leading to the loss of O3.


    <span id="page-4-1"></span>*Solution* 2*.* It is worth noting that an NVM sync
    write does not record data out of its range, but a disk write-back records all
    current data of a page, including any previous writes that may influence the current
    data version. Thus we don''t need to worry about the disk, and should focus on
    the unrecorded hollows of a page on the NVM. Now we record each disk write-back
    event on the NVM, like the yellow bubbles shown in Fig. [2.](#page-3-1) The bubble
    represents that at that point of time the disk has maintained a full data version
    of the page, including the results of all previous writes. So when we backtrack
    the NVM records, whenever we meet a write-back event we will know that there is
    a reliable data copy on the disk, and we don''t need to backtrack on the NVM any
    further. Then to rebuild the latest data version, we just apply the tracked useful
    NVM operations to the disk data version. This process is described in Algorithm
    [2.](#page-4-0)


    # <span id="page-4-0"></span>Algorithm 2 Solution to problem 2: record write-back
    events on the NVM.


    - 1: procedure WRITEBACK(page)

    - 2: WRITE DISK(page)

    - 3: record.type ← WRITEBACK

    - 4: record.page index ← page.index

    - 5: WRITE NVM(record)

    - 6: end procedure

    - 7: procedure SYNC WRITE(page index, data, off, len)

    - 8: record.type ← WRITE

    - 9: record.page index ← page index

    - 10: record.data ← data

    - 11: record.off ← off

    - 12: record.len ← len

    - 13: WRITE NVM(record)

    - 14: end procedure

    - 15: function CRASH RECOVER(page index)

    - 16: record ← LAST NVM RECORD ON(page index)

    - 17: useful records ← [ ]

    - 18: i ← 0

    - 19: while record ̸= NULL and record.type ̸= WRITEBACK do

    - 20: useful records[i] ← record

    - 21: i = i + 1

    - 22: record ← PREV NVM RECORD ON SAME IDX( record)

    - 23: end while


    ```

    24: page ← READ DISK(page index)

    ```

    - 25: for i > 0 do

    - 26: i = i − 1

    - 27: WRITE PAGE(page, record.data, record.off, record.len)

    - 28: end for

    - 29: return page


    ```

    30: end function

    ```

    <span id="page-4-3"></span>Proposition 2. Solution [2](#page-4-1) solves both
    Problem [1](#page-2-2) and Problem [2.](#page-4-2)


    *Proof.* Solution [2](#page-4-1) is a superset of Solution [1.](#page-2-4) It
    is trivial to see that if we apply Solution [2](#page-4-1) to Problem [1,](#page-2-2)
    the cases in the proof of Proposition [1](#page-2-6) can still be proved in the
    same way. Thus for Problem [1,](#page-2-2) we can use Solution [2](#page-4-1)
    as a stronger substitute for Solution [1](#page-2-4) rather than a supplement.


    Besides the cases in the proof of Proposition [1,](#page-2-6) we need to further
    examine the results for multiple arbitrary-length sync writes, because on the
    NVM these sync writes may not cover the whole page in the context of Problem [2.](#page-4-2)
    Note that writeback still handles all writes before it, thus only the latest writeback
    needs to be further considered. There are four special cases of (w, sync, crash,
    r) left to be proved:


    *Case* 2.1*.* [w0, sync<sup>N</sup> , [w1, syncA] <sup>n</sup>, crash, r], n ≥
    1. This means that write-back never happens during the workflow before the crash,
    and at least one pair of arbitrary-length sync writes happens before the crash.
    In this case, NVPC backtracks each sync record and rebuilds the whole-page data
    according to its design, thus each (w, sync, crash, r) can be recovered, which
    respects Theorem [1.](#page-1-0)


    *Case* 2.2*.* [w0, wb, sync<sup>N</sup> , [w1, syncA] <sup>n</sup>, crash, r],
    n ≥ 1. This means that write-back happens before a series of arbitrary-length
    sync writes and their initial sync<sup>N</sup> . In this case, the (w1, syncA,
    crash, r) has been proved in Case [2.1.](#page-2-7) So we should focus on (w0,
    sync, crash, r). According to Algorithm [2,](#page-4-0) wb writes the full-page
    data to the disk, and marks a write-back event on the NVM, so that after the crash,
    the recovered arbitrary-length sync writes will be performed based on the wb version.
    The wb version data includes w0, so (w0, sync, crash, r) respects Theorem [1.](#page-1-0)
    Thus each (w, sync, crash, r) in this case respects Theorem [1.](#page-1-0)


    *Case* 2.3*.* [w0, sync<sup>N</sup> , wb, [w1, syncA] <sup>n</sup>, crash, r],
    n ≥ 1. This means that write-back happens just after the initial sync<sup>N</sup>
    of a series of arbitrary-length sync writes. In this case, (w0, sync, crash, r)
    respects Theorem [1](#page-1-0) because, just like we proved in Case [2.2,](#page-2-8)
    the wb writes its previous writes including w0, which can be recovered after crash.
    Other (w1, syncA, crash, r) has been proved in Case [2.1.](#page-2-7) Thus each
    (w, sync, crash, r) in this case respects Theorem [1.](#page-1-0)


    *Case* 2.4*.* [w0, syncA, wb, [w1, syncA] <sup>n</sup>, crash, r], n ≥ 1. This
    means that write-back happens between a series of arbitrary-length sync writes.
    In the same way as Case [2.2,](#page-2-8) wb makes (w0, sync, crash, r) respect
    Theorem [1.](#page-1-0) In the same way as Case [2.1,](#page-2-7) (w1, syncA,
    crash, r) respects Theorem [1.](#page-1-0) Thus each (w, sync, crash, r) in this
    case respects Theorem [1.](#page-1-0)


    Proof to other cases, e.g. write-back happens after the last sync, will be the
    same with the proof of Proposition [1](#page-2-6) even under the context of Problem
    [2.](#page-4-2) According to Theorem [2,](#page-1-1) now that all cases respect
    Theorem [1,](#page-1-0) Algorithm [2](#page-4-0) is proved to solve Problem [2.](#page-4-2)


    # *C. Problems from Write-back Duration*


    We should be aware that the write-back process does not happen at a point of time,
    but is a duration of time. Due to the slow speed of the disk, the legacy storage
    stack adopts a queue-based design to decouple the write process from the host
    side and the device side. The queue mechanism can largely improve the I/O throughput,
    but it brings challenges to NVPC. Specifically, we can only know the start and
    the end time points of a write-back event, but we can''t know the exact time point
    that the data is persisted to the device.


    A write-back process can be described as follows: First, the page is marked as
    write-back, and enters the I/O queue, which is the start of write-back. Then,
    the disk consumes the pages in the queue and persists them properly. After the
    page is successfully persisted, the disk signals a finish event to tell the host,
    which is the end of the write-back. The implementation varies, but a write-back
    process always obeys the following principles:


    - 1) The real write-disk event (wb<sup>r</sup> ) happens after the start of write-back
    (wb<sup>s</sup> ) before the end of write-back (wb<sup>e</sup> ), and a page can
    only be in one write-back event. I.e. (wb<sup>s</sup> , ¬wb, wb<sup>r</sup> ,
    ¬wb, wb<sup>e</sup> ) is always correct.

    - 2) The data written to the disk is the data version that the real write-disk
    event (wb<sup>r</sup> ) happens. Since we don''t know the exact time of wb<sup>r</sup>
    , we can only be sure that the data version of the wb is not earlier than the
    last data before wb<sup>s</sup> , and is not later than the first data after wb<sup>e</sup>
    .

    - 3) At wb<sup>s</sup> the DIRTY state of a page is cleared, and the WRITEBACK
    state is set, within a pair of lock / unlock. The WRITEBACK state is cleared at
    wb<sup>e</sup> . During the write-back (wb<sup>s</sup> to wb<sup>e</sup> ), if
    the page is written again, the DIRTY state is set again, which will not be cleared
    until the next wb<sup>s</sup> .


    Fig. [3](#page-6-0) shows an example workflow in which the uncertain write-back
    time point may lead to the loss of write operations. At t1, both page cache, disk,
    and NVM reach a consistent state. Suppose that we only have arbitrary-length sync
    writes, because it''s easy to see that ensuring the consistency of fullpage sync
    is a relaxed subset of ensuring the consistency of arbitrary-length sync. At t2,
    t5, and t8 there are three sync writes generating V 2, V 3, and V 4. At t3 the
    page encounters a write-back, but it''s just the start of the write-back process.
    The data is written to the disk at t6, and V 3 is the version written, because
    O2 happens after wb<sup>s</sup> (t3) before wb<sup>r</sup> (t6) and generate V
    3. Then at t9, the host is notified that the writeback is finished. Note that
    we can only mark the write-back event on the NVM (Algorithm [2\)](#page-4-0) at
    the time of wb<sup>s</sup> or wb<sup>e</sup> . Now when we inject crashes between
    the write-back process, some problems that we failed to discuss in Section [III-A](#page-2-9)
    and Section [III-B](#page-3-2) may occur.


    Scenario C.1. Suppose that we crash before the real writeback, say, at t4. If
    we mark write-back on the NVM at wb<sup>s</sup> (t3), then until the crash time
    the data version that we expect to appear on the disk (no earlier than V 2) has
    not been written to the disk yet, and the disk version is still V 1. Then after
    the crash, if we follow Algorithm [2](#page-4-0) we will get -rst--, which is
    rebuilt from V 1 → O2. Obviously, O1 is lost during the rebuild. So we can assume
    again that the write-back is marked at wb<sup>e</sup> (t9). Then if we crash at
    t4, the rebuild process can still generate V 2 from V 1 → O1, which is currently
    respecting Theorem [1.](#page-1-0)


    Scenario C.2. Suppose that we crash at t10 after the writeback ends, and the write-back
    will be marked on the NVM at t9, according to Scenario [C.1.](#page-2-0) Now when
    we rebuild the data after the crash, we will get V 3 from the disk and nothing
    from the NVM, because everything on the NVM is before the write-back mark at t9
    and is abandoned. Now it is obvious that


    ![](_page_6_Figure_0.jpeg)


    <span id="page-6-0"></span>Fig. 3. Space-time diagram for problematic cases caused
    by an uncertain write-back time.


    O3 is lost, due to the postponement of the write-back mark. If we move the mark
    back to wb<sup>s</sup> (t3), it will work for this scenario, but will break Scenario
    [C.1](#page-2-0) as we just discussed.


    <span id="page-6-2"></span>*Problem* 3*.* The problems in Scenario [C.1](#page-2-0)
    and Scenario [C.2](#page-2-5) are caused by the uncertain write-back time between
    wb<sup>s</sup> and wb<sup>e</sup> . Specifically, the reason is that we don''t
    know which data version is the exact one being written to the disk, and when is
    it actually written. So when we choose wb<sup>s</sup> as the mark point, we may
    lose the data between the last write-back and wb<sup>s</sup> if the system crashes
    after wb<sup>s</sup> before wb<sup>r</sup> . Otherwise when we choose wb<sup>e</sup>
    as the mark point, we may lose the data between wb<sup>r</sup> and wb<sup>e</sup>
    if the system crashes after wb<sup>e</sup> .


    <span id="page-6-1"></span>*Solution* 3*.* Since we know the start and end of
    a write-back, we can be sure that at least the versions before wb<sup>s</sup>
    can be abandoned once the write-back is successful, and the success of the write-back
    happens no later than wb<sup>e</sup> . Thus we have the conclusion that at wb<sup>e</sup>
    , the data before wb<sup>s</sup> is safely expired. Now when a write-back happens,
    we can temporarily record the time point (e.g. an auto-increment NVM record id)
    of wb<sup>s</sup> to prepare the data version that is going to expire. Then not
    until wb<sup>e</sup> will we make a real persistent record of the writeback event
    with the previously recorded time, indicating that eventually at this time point
    the data we recorded is confirmed to be useless. The process is shown in Algorithm
    [3,](#page-7-6) which is a modification to Algorithm [2.](#page-4-0) Maybe there
    are writes after wb<sup>s</sup> that are persisted by the disk at wb<sup>r</sup>
    (e.g. V 3 in Fig. [3\)](#page-6-0), there is no need to worry because NVPC ensures
    that data will be persisted by NVM when the page has a state of DIRTY or WRITEBACK,
    meaning that all sync writes between wb<sup>s</sup> and wb<sup>e</sup> will be
    recorded by NVM and replayed after crash. Thus persisting any data version between
    wb<sup>s</sup> and wb<sup>e</sup> to disk is acceptable, and any (write, sync)
    pair crossing or inside the write-back is recoverable.


    Proposition 3. Solution [3](#page-6-1) solves Problem [3.](#page-6-2)


    *Proof.* For Problem [3](#page-6-2) and Solution [3,](#page-6-1) we can generate
    a sequence with atomic sync writes before wb<sup>s</sup> , between wb<sup>s</sup>
    and wb<sup>r</sup> , between wb<sup>r</sup> and wb<sup>e</sup> , and after wb<sup>e</sup>
    : [w1, sync, wb<sup>s</sup> , w2, sync, wb<sup>r</sup> , w3, sync, wb<sup>e</sup>
    , w4, sync]. We inject [crash, r] among each pair of operations to check if Solution
    [3](#page-6-1) works well. We also need to deal with the special case that a wb<sup>e</sup>
    happens between a pair of [w, sync]: [w, wb<sup>e</sup> , sync, crash, r]. Then
    in the same way it is easy to prove that wb<sup>s</sup> or wb<sup>r</sup> inserted
    between [w, sync] will not cause any fault. All the cases to be proved are listed
    below:


    *Case* 3.1*.* Crashing before wb<sup>s</sup> is the same as the cases we discussed
    in the proof of Proposition [1](#page-2-6) and Proposition [2.](#page-4-3)


    *Case* 3.2*.* Crashing between [wb<sup>s</sup> , w2] generates [w1, sync, wb<sup>s</sup>
    , crash, r]. According to Algorithm [3,](#page-7-6) though we have prepared to
    mark w<sup>1</sup> as expired, since wb<sup>e</sup> never happens, the write-back
    record doesn''t exist on the NVM. So when we rebuild the data, we use the previous
    disk data and the sync write records on the NVM, like wb<sup>s</sup> never happens.
    In this case, (w1, sync, crash, r) obviously respects Theorem [1.](#page-1-0)
    In the same way we can prove that crashing between [w2, wb<sup>r</sup> ] respects
    Theorem [1.](#page-1-0)


    *Case* 3.3*.* Crashing between [wb<sup>r</sup> , w3] generates [w1, sync, wb<sup>s</sup>
    , w2, sync, wb<sup>r</sup> , crash, r]. According to Algorithm [3,](#page-7-6)
    the NVM write-back record fails to be persisted, but the data version before wb<sup>r</sup>
    , including w<sup>1</sup> and w2, is written to the disk successfully. When we
    rebuild the data, we will replay all previous writes since the last write-back
    onto the disk data version that already contains them. This does not violate the
    sync semantics, because we are actually replaying all operations again, which
    contains each sync write and respects Theorem [1.](#page-1-0) In the same way
    we can prove that crashing between [w3, wb<sup>e</sup> ] respects Theorem [1.](#page-1-0)


    <span id="page-7-6"></span>Algorithm 3 Solution to problem 3: record write-back
    events on the NVM with a proper design for wb<sup>s</sup> and wb<sup>e</sup> .


    |            | 1: global variables                                                               |  |

    |------------|-----------------------------------------------------------------------------------|--|

    | 2:         | prep rec[1 page num]<br>▷ Prepared write-back                                     |  |

    |            | record for the later mark.                                                        |  |

    | 3:         | page ver id[1 page num]<br>▷ An auto-increment                                    |  |

    |            | id to track page version.                                                         |  |

    |            | 4: end global variables                                                           |  |

    |            | ▷ This is wbs<br>5: procedure WRITEBACK(page)                                     |  |

    | 6:         | record.type ← WRITEBACK                                                           |  |

    | 7:         | record.page index ← page.index                                                    |  |

    | 8:         | record.exp vid ← page ver id[page.index]                                          |  |

    | 9:         | prep rec[page.index] ← record                                                     |  |

    | 10:        | QUEUE WRITE DISK(page)                                                            |  |

    |            | 11: end procedure                                                                 |  |

    |            | 12: procedure WRITEBACK CALLBACK(page)<br>▷ This is                               |  |

    |            | wbe                                                                               |  |

    | 13:        | prep rec[page.index].vid<br>←                                                     |  |

    |            | page ver id[page.index]                                                           |  |

    | 14:        | page ver id[page.index]<br>=                                                      |  |

    |            | page ver id[page.index] + 1                                                       |  |

    | 15:        | WRITE NVM(prep rec[page.index])                                                   |  |

    |            | 16: end procedure                                                                 |  |

    |            | 17: procedure SYNC WRITE(page index, data, off, len)                              |  |

    | 18:        | record.type ← WRITE                                                               |  |

    | 19:        | record.page index ← page index                                                    |  |

    | 20:        | record.data ← data                                                                |  |

    | 21:        | record.off ← off                                                                  |  |

    | 22:        | record.len ← len                                                                  |  |

    | 23:        | record.vid ← page ver id[page.index]                                              |  |

    | 24:        | page ver id[page.index]<br>=                                                      |  |

    |            | page ver id[page.index] + 1                                                       |  |

    | 25:        | WRITE NVM(record)                                                                 |  |

    |            | 26: end procedure                                                                 |  |

    |            | 27: function CRASH RECOVER(page index)<br>record ← LAST NVM RECORD
    ON(page index) |  |

    | 28:        | exp vid ← 0                                                                       |  |

    | 29:        | useful records ← [ ]                                                              |  |

    | 30:        | i ← 0                                                                             |  |

    | 31:        | while record ̸= NULL and record.vid ≥ exp vid                                     |  |

    | 32:        | do                                                                                |  |

    |            | if record.type = WRITEBACK then                                                   |  |

    | 33:<br>34: | exp vid ← record.exp vid                                                          |  |

    | 35:        | else                                                                              |  |

    | 36:        | useful records[i] ← record                                                        |  |

    | 37:        | end if                                                                            |  |

    | 38:        | i = i + 1                                                                         |  |

    | 39:        | record ← PREV NVM RECORD ON SAME IDX(                                             |  |

    |            | record)                                                                           |  |

    | 40:        | end while                                                                         |  |

    | 41:        | page ← READ DISK(page index)                                                      |  |

    | 42:        | for i > 0 do                                                                      |  |

    | 43:        | i = i − 1                                                                         |  |

    | 44:        | record ← useful records[i]                                                        |  |

    | 45:        | WRITE PAGE(page,<br>record.data,<br>record.off,                                   |  |

    |            | record.len)                                                                       |  |

    | 46:        | end for                                                                           |  |

    | 47:        | return page                                                                       |  |

    |            | 48: end function                                                                  |  |

    |            |                                                                                   |  |


    *Case* 3.4*.* Crashing after w<sup>4</sup> generates [w1, sync, wb<sup>s</sup>
    , w2, sync, wb<sup>r</sup> , w3, sync, wb<sup>e</sup> , w4, sync, crash, r]. According
    to Algorithm [3,](#page-7-6) after the recovery NVPC thinks that it has the data
    version before wb<sup>s</sup> on the disk, which includes w1. But actually the
    data version on the disk includes both w<sup>1</sup> and w2. The write operations
    w2, w3, and w<sup>4</sup> are persisted by the NVM, and will be replayed in sequence
    to the version on the disk. Though w<sup>2</sup> is replayed unnecessarily, it
    still respects Theorem [1.](#page-1-0) Since all writes are persisted and replayed,
    each (w, sync, crash, r) respects Theorem [1.](#page-1-0) In the same way we can
    prove that crashing between [wb<sup>e</sup> , w4] respects Theorem [1.](#page-1-0)


    *Case* 3.5*.* [wb<sup>s</sup> , w, wb<sup>e</sup> , sync, crash, r]. In this case,
    the write between wb<sup>s</sup> and wb<sup>e</sup> will re-dirty the page, so
    the sync can still persist it to NVM, and after the crash we can rebuild it because
    it happens after wb<sup>s</sup> . Thus (w, sync, crash, r) in this case respects
    Theorem [1.](#page-1-0)


    According to Theorem [2,](#page-1-1) now that all cases respect Theorem [1,](#page-1-0)
    Algorithm [3](#page-7-6) is proved to solve Problem [3.](#page-6-2)


    #### IV. CONCLUSION


    Heterogeneous storage devices have different characteristics that make system
    designers hard to rein. In this work, we take NVPC as the research target and
    discuss the difficulties of its data consistency, including the problems from
    the heterogeneity of write sequence, granularity, and mode, along with the solutions
    to the proposed problems.


    ## REFERENCES


    - <span id="page-7-1"></span>[1] Mingkai Dong, Heng Bu, Jifei Yi, Benchao Dong,
    and Haibo Chen. Performance and protection in the ZoFS user-space NVM file system.
    In *Proceedings of the 27th ACM Symposium on Operating Systems Principles*, pages
    478–493, Huntsville Ontario Canada, October 2019. ACM.

    - <span id="page-7-2"></span>[2] Subramanya R. Dulloor, Sanjay Kumar, Anil Keshavamurthy,
    Philip Lantz, Dheeraj Reddy, Rajesh Sankaran, and Jeff Jackson. System software
    for persistent memory. In *Proceedings of the Ninth European Conference on Computer
    Systems - EuroSys ''14*, pages 1–15, Amsterdam, The Netherlands, 2014. ACM Press.

    - <span id="page-7-4"></span>[3] Zhicheng Ji, Kang Chen, Leping Wang, Mingxing
    Zhang, and Yongwei Wu. Falcon: Fast OLTP Engine for Persistent Cache and Non-Volatile
    Memory. In *Proceedings of the 29th Symposium on Operating Systems Principles*,
    SOSP ''23, pages 531–544, New York, NY, USA, October 2023. Association for Computing
    Machinery.

    - <span id="page-7-5"></span>[4] Youngjin Kwon, Henrique Fingler, Tyler Hunt,
    Simon Peter, Emmett Witchel, and Thomas Anderson. Strata: A Cross Media File System.
    In *Proceedings of the 26th Symposium on Operating Systems Principles*, SOSP ''17,
    pages 460–477, New York, NY, USA, October 2017. Association for Computing Machinery.

    - <span id="page-7-0"></span>[5] Zhen Lin, Lingfeng Xiang, Jia Rao, and Hui Lu.
    P2CACHE: Exploring Tiered Memory for In-Kernel File Systems Caching. In *2023
    USENIX Annual Technical Conference (USENIX ATC 23)*, pages 801–815, 2023.

    - <span id="page-7-3"></span>[6] Hasan Al Maruf, Hao Wang, Abhishek Dhanotia,
    Johannes Weiner, Niket Agarwal, Pallab Bhattacharya, Chris Petersen, Mosharaf
    Chowdhury, Shobhit Kanaujia, and Prakash Chauhan. TPP: Transparent Page Placement
    for CXL-Enabled Tiered-Memory. In *Proceedings of the 28th ACM International Conference
    on Architectural Support for Programming Languages and Operating Systems, Volume
    3*, ASPLOS 2023, pages 742–755, New York, NY, USA, March 2023. Association for
    Computing Machinery.

    - <span id="page-8-4"></span>[7] Chaoyi Ruan, Yingqiang Zhang, Chao Bi, Xiaosong
    Ma, Hao Chen, Feifei Li, Xinjun Yang, Cheng Li, Ashraf Aboulnaga, and Yinlong
    Xu. Persistent Memory Disaggregation for Cloud-Native Relational Databases. In
    *Proceedings of the 28th ACM International Conference on Architectural Support
    for Programming Languages and Operating Systems, Volume 3*, ASPLOS 2023, pages
    498–512, New York, NY, USA, March 2023. Association for Computing Machinery.

    - <span id="page-8-0"></span>[8] Guoyu Wang, Xilong Che, Haoyang Wei, Shuo Chen,
    Puyi He, and Juncheng Hu. NVPC: A Transparent NVM Page Cache, August 2024.

    - <span id="page-8-5"></span>[9] Jing Wang, Youyou Lu, Qing Wang, Minhui Xie,
    Keji Huang, and Jiwu Shu. Pacman: An Efficient Compaction Approach for Log-Structured
    Key-Value Store on Persistent Memory. In *2022 USENIX Annual Technical Conference
    (USENIX ATC 22)*, pages 773–788, 2022.

    - <span id="page-8-3"></span>[10] Johannes Weiner, Niket Agarwal, Dan Schatzberg,
    Leon Yang, Hao Wang, Blaise Sanouillet, Bikash Sharma, Tejun Heo, Mayank Jain,
    Chunqiang Tang, and Dimitrios Skarlatos. TMO: transparent memory offloading in
    datacenters. In *Proceedings of the 27th ACM International Conference on Architectural
    Support for Programming Languages and Operating Systems*, ASPLOS ''22, pages 609–621,
    New York, NY, USA, February 2022. Association for Computing Machinery.

    - <span id="page-8-1"></span>[11] Hobin Woo, Daegyu Han, Seungjoon Ha, Sam H.
    Noh, and Beomseok Nam. On Stacking a Persistent Memory File System on Legacy File
    Systems. In *21st USENIX Conference on File and Storage Technologies (FAST 23)*,
    pages 281–296, 2023.

    - <span id="page-8-2"></span>[12] Jian Xu and Steven Swanson. NOVA: a log-structured
    file system for hybrid volatile/non-volatile main memories. In *Proceedings of
    the 14th Usenix Conference on File and Storage Technologies*, FAST''16, pages
    323–338, USA, February 2016. USENIX Association.

    - <span id="page-8-6"></span>[13] Shengan Zheng, Morteza Hoseinzadeh, and Steven
    Swanson. Ziggurat: A Tiered File System for Non-Volatile Main Memories and Disks.
    In *17th USENIX Conference on File and Storage Technologies (FAST 19)*, pages
    207–219, 2019.'
- id: modern_computing_vision_and_challenges_sukhpal_singh_gill_a_huaming_wu_b_panos_patros_c_carlo_ottaviani_d_priyansh_arora_e_victor_casamayor_pujol_f_david_haunschild_g_ajith_kumar_parlikad_h_oktay_cetinkaya_i_hanan_lutfiyya_j_vlado_stankovski_k_ruidong_li_l_yuemin_ding_m_junaid_qadir_n_ajith_abraham_o_p_soumya_k_ghosh_q_houbing_herbert_song_r_rizos_sakellariou_s_omer_rana_t_joel_j_p_c_rodrigues_u_v_salil_s_kanhere_w_schahram_dustdar_f_steve_uhlig_a_kotagiri_ramamohanarao_x_and_rajkumar_buyya_y
  title: 'Modern Computing: Vision and Challenges'
  abstract: 'Over the past six decades, the computing systems field has experienced

    significant transformations, profoundly impacting society with transformational

    developments, such as the Internet and the commodification of computing.

    Underpinned by technological advancements, computer systems, far from being

    static, have been continuously evolving and adapting to cover multifaceted

    societal niches. This has led to new paradigms such as cloud, fog, edge

    computing, and the Internet of Things (IoT), which offer fresh economic and

    creative opportunities. Nevertheless, this rapid change poses complex research

    challenges, especially in maximizing potential and enhancing functionality. As

    such, to maintain an economical level of performance that meets ever-tighter

    requirements, one must understand the drivers of new model emergence and

    expansion, and how contemporary challenges differ from past ones. To that end,

    this article investigates and assesses the factors influencing the evolution of

    computing systems, covering established systems and architectures as well as

    newer developments, such as serverless computing, quantum computing, and

    on-device AI on edge devices. Trends emerge when one traces technological

    trajectory, which includes the rapid obsolescence of frameworks due to business

    and technical constraints, a move towards specialized systems and models, and

    varying approaches to centralized and decentralized control. This comprehensive

    review of modern computing systems looks ahead to the future of research in the

    field, highlighting key challenges and emerging trends, and underscoring their

    importance in cost-effectively driving technological progress.'
  url: http://arxiv.org/abs/2401.02469v1
  keywords: ': Modern Computing Edge AI Edge Computing Artificial Intelligence Machine
    Learning Cloud Computing Quantum Computing Computing'
  document: "# Modern Computing: Vision and Challenges\n\nSukhpal Singh Gill*<sup>a</sup>*\
    \ , Huaming Wu*<sup>b</sup>* , Panos Patros*<sup>c</sup>* , Carlo Ottaviani*<sup>d</sup>*\
    \ , Priyansh Arora*<sup>e</sup>* , Victor Casamayor Pujol*<sup>f</sup>* , David\
    \ Haunschild*<sup>g</sup>* , Ajith Kumar Parlikad*<sup>h</sup>* , Oktay Cetinkaya*<sup>i</sup>*\
    \ , Hanan Lutfiyya*<sup>j</sup>* , Vlado Stankovski*<sup>k</sup>* , Ruidong Li*<sup>l</sup>*\
    \ , Yuemin Ding*<sup>m</sup>*, Junaid Qadir*<sup>n</sup>* , Ajith Abraham*o,p*\
    \ , Soumya K. Ghosh*<sup>q</sup>* , Houbing Herbert Song*<sup>r</sup>* , Rizos\
    \ Sakellariou*<sup>s</sup>* , Omer Rana*<sup>t</sup>* , Joel J. P. C. Rodrigues*u,v*\
    \ , Salil S. Kanhere*<sup>w</sup>* , Schahram Dustdar*<sup>f</sup>* , Steve Uhlig*<sup>a</sup>*\
    \ , Kotagiri Ramamohanarao*<sup>x</sup>* and Rajkumar Buyya*<sup>y</sup>*\n\n\
    *<sup>a</sup>School of Electronic Engineering and Computer Science, Queen Mary\
    \ University of London, London, UK,*\n\n- *<sup>c</sup>Raygun Performance Monitoring,\
    \ Wellington, New Zealand,*\n- *<sup>d</sup>Department of Computer Science and\
    \ York Centre for Quantum Technologies, University of York, York, UK,*\n- *<sup>e</sup>Microsoft,\
    \ Schiphol, Netherlands,*\n- *<sup>f</sup> Distributed Systems Group, Vienna University\
    \ of Technology, Vienna, Austria,*\n- *<sup>g</sup> Detecon International GmbH,\
    \ Munich, Germany,*\n- *h Institute for Manufacturing, Department of Engineering,\
    \ University of Cambridge, Cambridge, UK,*\n\n*<sup>i</sup>Oxford e-Research Centre\
    \ (OeRC), Department of Engineering Science, University of Oxford, Oxford, UK,*\n\
    \n- *<sup>j</sup>Department of Computer Science, University of Western Ontario,\
    \ London, Canada,*\n- *<sup>k</sup>Faculty of Computer and Information Science,\
    \ University of Ljubljana, Ljubljana, Slovenia,*\n- *l Institute of Science and\
    \ Engineering, Kanazawa University, Japan,*\n- *<sup>m</sup>Tecnun School of Engineering,\
    \ University of Navarra, Spain,*\n- *<sup>n</sup>Department of Computer Science\
    \ and Engineering, College of Engineering, Qatar University, Doha, Qatar,*\n-\
    \ *<sup>o</sup>Bennett University, Greater Noida, India,*\n- *<sup>p</sup>Machine\
    \ Intelligence Research Labs, Auburn, WA, USA,*\n- *<sup>q</sup> Department of\
    \ Computer Science and Engineering, Indian Institute of Technology, Kharagpur,\
    \ India,*\n- *<sup>r</sup> Department of Information Systems University of Maryland,\
    \ Baltimore County (UMBC), Baltimore, USA,*\n- *<sup>s</sup> Department of Computer\
    \ Science, University of Manchester, Oxford Road, Manchester, UK,*\n- *<sup>t</sup>School\
    \ of Computer Science and Informatics, Cardiff University, Cardiff, UK,*\n- *<sup>u</sup>Department\
    \ of Computer Science, College of Computer and Information Sciences, King Saud\
    \ University, Riyadh, Saudi Arabia,*\n- *<sup>v</sup>COPELABS, Lusófona University,\
    \ Lisbon, Portugal,*\n- *<sup>w</sup>School of Computer Science and Engineering,\
    \ The University of New South Wales (UNSW), Sydney, Australia,*\n- *<sup>x</sup>Retired\
    \ Professor, The University of Melbourne, Victoria, Australia,*\n\n*<sup>y</sup>Cloud\
    \ Computing and Distributed Systems (CLOUDS) Laboratory, School of Computing and\
    \ Information Systems, The University of Melbourne, Australia,*\n\n## A R T I\
    \ C L E I N F O\n\n*Keywords*: Modern Computing Edge AI Edge Computing Artificial\
    \ Intelligence Machine Learning Cloud Computing Quantum Computing Computing\n\n\
    #### A B S T R A C T\n\nOver the past six decades, the computing systems field\
    \ has experienced significant transformations, profoundly impacting society with\
    \ transformational developments, such as the Internet and the commodification\
    \ of computing. Underpinned by technological advancements, computer systems, far\
    \ from being static, have been continuously evolving and adapting to cover multifaceted\
    \ societal niches. This has led to new paradigms such as cloud, fog, edge computing,\
    \ and the Internet of Things (IoT), which offer fresh economic and creative opportunities.\
    \ Nevertheless, this rapid change poses complex research challenges, especially\
    \ in maximizing potential and enhancing functionality. As such, to maintain an\
    \ economical level of performance that meets ever-tighter requirements, one must\
    \ understand the drivers of new model emergence and expansion, and how contemporary\
    \ challenges differ from past ones. To that end, this article investigates and\
    \ assesses the factors influencing the evolution of computing systems, covering\
    \ established systems and architectures as well as newer developments, such as\
    \ serverless computing, quantum computing, and on-device AI on edge devices. Trends\
    \ emerge when one traces technological trajectory, which includes the rapid obsolescence\
    \ of frameworks due to business and technical constraints, a move towards specialized\
    \ systems and models, and varying approaches to centralized and decentralized\
    \ control. This comprehensive review of modern computing systems looks ahead to\
    \ the future of research in the field, highlighting key challenges and emerging\
    \ trends, and underscoring their importance in cost-effectively driving technological\
    \ progress.\n\n<sup>∗</sup>Correspondence to: School of Electronic Engineering\
    \ and Computer Science, Queen Mary University of London, London, E1 4NS, UK.\n\
    \ns.s.gill@qmul.ac.uk (S.S. Gill); whming@tju.edu.cn (H. Wu); panos@raygun.com\
    \ (P. Patros); carlo.ottaviani@york.ac.uk (C. Ottaviani); priyansh.arora@microsoft.com\
    \ (P. Arora); v.casamayor@dsg.tuwien.ac.at\n\n(V.C. Pujol); david.haunschild@detecon.com\
    \ (D. Haunschild); aknp2@cam.ac.uk (A.K. Parlikad); oktay.cetinkaya@eng.ox.ac.uk\
    \ (O. Cetinkaya); hanan@csd.uwo.ca (H. Lutfiyya); vlado.stankovski@fri.uni-lj.si\
    \ (V. Stankovski); lrd@se.kanazawa-u.ac.jp (R. Li); yueminding@tecnun.es (Y. Ding);\n\
    \n*<sup>b</sup>Center for Applied Mathematics, Tianjin University, Tianjin, China,*\n\
    \n#### **1. Introduction**\n\nThe Internet, the expansive computational backbone\
    \ of interactive machines, is largely responsible for the 21st century's social,\
    \ financial, and technological growth [\\[1\\]](#page-39-0). The growing reliance\
    \ on the computing resources it encapsulates has pushed the complexity and scope\
    \ of such platforms, leading to the development of innovative computing systems.\
    \ These systems have genuinely improved the capabilities and expectations of computing\
    \ equipment driven by rapid technical and user-driven evolution [\\[2\\]](#page-40-0).\
    \ For instance, vintage mainframes combined centralized data processing and storage\
    \ with transmission interfaces for user input. Due to advancements in clusters\
    \ and packet-switching technologies, microchip gadgets, and graphical user interfaces,\
    \ technology originally shifted from big, centrally-run mainframe computers to\
    \ Personal Computers (PCs). The globalization of network standards made it possible\
    \ for interconnected networks worldwide to communicate and share data [\\[3\\\
    ]](#page-40-1). Businesses slowly combined sensor and actuator goals with built-in\
    \ network connectivity by creating architectures and standards that submit tasks\
    \ to remote pools of computing resources, such as memory, storage, and data processing\
    \ [\\[4\\]](#page-40-2). As a result, newer models like the Internet of Things\
    \ (IoT) and edge computing are now beginning to expand the reach of technology\
    \ outside the confines of traditional network nodes [\\[5\\]](#page-40-3).\n\n\
    Over the past six decades, computing models have fundamentally shifted to address\
    \ the problems posed by the ever-evolving nature of our civilization and its associated\
    \ computer system architectures [\\[6\\]](#page-40-4). The evolution of computing\
    \ from mainframes to workstations to the cloud to autonomous and decentralized\
    \ architectures, such as edge computing and IoT technologies, however, maintains\
    \ identical core parts and traits that characterize their function [\\[7\\]](#page-40-5).\
    \ Research in computing underpins all of them! Advancements in areas like security,\
    \ computer hardware acceleration, edge computing, and energy efficiency typically\
    \ serve as catalysts for innovation and entrepreneurship that span across various\
    \ business domains [\\[8\\]](#page-40-6). While computing systems and other forms\
    \ of system integration create new problems/opportunities, software frameworks\
    \ have been developed to address them. Thus, middleware, network protocols, and\
    \ safe segregation techniques must be continually developed and refined to support\
    \ novel computing systems—and their innovative use cases.\n\n#### **1.1. Motivation**\n\
    \nBy tracking the effect of computing systems on the community, this comprehensive\
    \ study seeks to (a) establish the essential features and components of modern\
    \ computing\n\nKanhere); dustdar@dsg.tuwien.ac.at (S. Dustdar);\n\nsteve.uhlig@qmul.ac.uk\
    \ (S. Uhlig); rkotagiri@gmail.com (K.\n\nRamamohanarao); rbuyya@unimelb.edu.au\
    \ (R. Buyya)\n\nORCID(s): 0000-0002-3913-0369 (S.S. Gill)\n\nsystems, (b) thoroughly\
    \ assess the development of innovations and behavioral patterns that inspired\
    \ the invention of these paradigms, and (c) recognize significant developments\
    \ throughout the models, such as the integration of system design, the shifting\
    \ between centralization and decentralization, and lags in model conceptualization\
    \ and development.\n\nThis investigation suggests that next-generation computing\
    \ systems will facilitate the decentralization of computational services. This\
    \ will be achieved via the composition of decentralized calculation tools with\
    \ workload-specific targets for performance to create dramatically more complex\
    \ structures. These will satisfy holistic operational demands, such as improved\
    \ capacity and power accessibility.\n\n#### **1.2. Related Surveys and Our Contributions**\n\
    \nComputing being a rapidly growing topic, the time is right for a novel, forward-thinking\
    \ study to summarize, improve, and integrate the existing and newly-generated\
    \ information, and to explore possible trends and future viewpoints. Previously,\
    \ Pujol et al. [\\[9\\]](#page-40-7) provided a survey on distributed computing\
    \ continuum systems that focused on business models. Further back in 2018, Buyya\
    \ et al. [\\[1\\]](#page-39-0) presented a manifesto on fundamental issues, developments,\
    \ and impacts in cloud computing research. Meanwhile, Gill et al. [\\[4\\]](#page-40-2)\
    \ offered a visionary survey of advances in computing paradigms for fog, edge,\
    \ and serverless computing. Further, Shalf [\\[10\\]](#page-40-8) summarized the\
    \ 2020 state of the art of technological roadmaps and their implications for the\
    \ future of systems, including what a post-exascale system would entail. Finally,\
    \ in 2021, Angel et al. [\\[11\\]](#page-40-9) reviewed leading computational\
    \ frameworks for cloud and edge computing, and showcased breakthroughs that had\
    \ been brought about via the merging of Machine Learning (ML) with these models.\n\
    \nIn order to evaluate and identify the most pressing research issues of modern\
    \ computing, we have developed the very first taxonomy of its type. We performed\
    \ a gap analysis of the current surveys using several criteria, as shown in Table\
    \ [1,](#page-2-0) which underpinned the design of our work. Hence, our study uniquely\
    \ contributes by (a) exploring the history of computing paradigm shifts with a\
    \ focus on technology drivers, (b) providing a thorough taxonomy of computing\
    \ systems, (c) introducing the hype cycle for modern computing systems with a\
    \ focus on new trends, and (d) discussing the effects and cost-effective performance\
    \ requirements of modern computing.\n\nThe **key contributions** of this article\
    \ are summarized as follows:\n\n- It offers a concise overview of the transition\
    \ from early to modern computing.\n- The study explores the evolution of computing\
    \ paradigms, focusing on technological drivers (1960–2023).\n- Following a novel\
    \ methodology, the article produces a taxonomy of modern computing based on traits\
    \ of\n\njqadir@qu.edu.qa (J. Qadir); ajith.abraham@ieee.org (A. Abraham); skg@cse.iitkgp.ac.in\
    \ (S.K. Ghosh); songh@umbc.edu (H.H. Song); rizos@manchester.ac.uk (R. Sakellariou);\
    \ ranaof@cardiff.ac.uk (O. Rana); joeljr@ieee.org (J.J.P.C. Rodrigues); salil.kanhere@unsw.edu.au\
    \ (S.S.\n\n#### <span id=\"page-2-0\"></span>Table 1\n\nComparison of this work\
    \ with existing studies\n\n| Work                                            |\
    \                                   | [9]  | [1]  | [4]  | [10] | [11] | Our Work\
    \ |\n|-------------------------------------------------|-----------------------------------|------|------|------|------|------|----------|\n\
    | Year                                            |                          \
    \         | 2023 | 2018 | 2022 | 2020 | 2021 | 2024     |\n| A Taxonomy of Modern\
    \ Computing                  |                                   |      |    \
    \  |      |      |      | ✓        |\n| Evolution of Computing Paradigms (1960\
    \ to 2023) |                                   |      |      |      |      | \
    \     | ✓        |\n|                                                 | Standalone\
    \ vs.                    |      |      |      |      |      |          |\n|  \
    \                                               | Networked Computing        \
    \       |      |      |      |      |      | ✓        |\n| Classification of Computing\
    \                     | General Purpose vs.               |      |      |    \
    \  |      |      |          |\n|                                             \
    \    | Specialized Computing             |      |      |      |      |      |\
    \ ✓        |\n|                                                 | Centralized\
    \ vs.                   |      |      |      |      |      |          |\n|   \
    \                                              | Decentralized Computing     \
    \      |      |      |      |      |      | ✓        |\n|                    \
    \                             | Computing Trends and              |      |   \
    \   |      |      |      |          |\n|                                     \
    \            | Emerging Technologies             | ✓    | ✓    | ✓    | ✓    |\
    \ ✓    | ✓        |\n|                                                 | Computational\
    \ Methodologies:      |      |      |      |      |      |          |\n|     \
    \                                            | Parallel vs. Sequential Computing\
    \ |      |      |      |      |      | ✓        |\n|                         \
    \                        | Focus/ Paradigms                  |      | ✓    | \
    \     |      |      | ✓        |\n| Traits of Computing                      \
    \       | Technologies/ Impact Areas        |      |      |      |      |    \
    \  | ✓        |\n|                                                 | Trends/ Observations\
    \              |      |      |      |      |      | ✓        |\n| Impact and Performance\
    \ Criteria                 | Performance Metrics               |      |      |\
    \      |      |      | ✓        |\n|                                         \
    \        | Efficiency Metrics                |      |      |      |      |   \
    \   | ✓        |\n|                                                 | Social Impact\
    \                     |      |      |      |      |      | ✓        |\n|     \
    \                                            | Security and Compliance       \
    \    |      |      |      |      |      | ✓        |\n|                      \
    \                           | Economic and Management           |      |     \
    \ |      |      |      | ✓        |\n| Open Challenges and Future Directions \
    \          |                                   | ✓    | ✓    | ✓    | ✓    | ✓\
    \    | ✓        |\n| Emerging Trends in Modern Computing: Hype Cycle |       \
    \                            |      |      |      |      |      | ✓        |\n\
    \ncomputing such as 1) focus or paradigms; 2) technologies or impact areas; and\
    \ 3) trends or observations.\n\n- It presents a comprehensive classification of\
    \ computing: 1) Standalone vs. Networked Computing; 2) General Purpose vs. Specialized\
    \ Computing, 3) Centralized vs. Decentralized Computing, 4) Computing Trends and\
    \ Emerging Technologies; and 5) Computational Methodologies: Parallel vs. Sequential\
    \ Computing.\n- The study identifies the impact and performance criteria of modern\
    \ computing in terms of performance metrics, efficiency metrics, social impact,\
    \ security and compliance, and economics and management.\n- It provides an in-depth\
    \ summary of computing traits and resources for further research.\n- The article\
    \ identifies open challenges and research directions for the traits of computing.\n\
    - Finally, it introduces the hype cycle for modern computing systems, spotlighting\
    \ emerging trends.\n\n## **1.3. Article Organization**\n\nThe article is organized\
    \ as follows: Section [2](#page-2-1) offers a concise overview of the transition\
    \ from early to modern computing. Section [3](#page-4-0) explores the evolution\
    \ of computing paradigms, focusing on technological drivers. Section [4](#page-6-0)\
    \ presents a classification of computing systems, and Section [5](#page-28-0)\
    \ examines the impact and performance criteria in modern computing. The article\
    \ concludes in Section [7,](#page-39-1) summarizing computing-related technologies\
    \ and trends through a hype cycle in Section [6.](#page-37-0) The list of acronyms\
    \ used in this study is given in Appendix A.\n\n# <span id=\"page-2-1\"></span>**2.\
    \ Early Computing to Modern Computing: A Vision**\n\nOver the last six decades,\
    \ advancements in computing systems have optimized the efficiency of the available\
    \ hardware [\\[12\\]](#page-40-10). Over this time period, novel computing models\
    \ and innovations have been developed and replaced the previous state-of-the-art,\
    \ all of which incrementally contribute to the current technology status [\\[2\\\
    ]](#page-40-0). Fig. [1](#page-3-0) shows the transition from early computing\
    \ to contemporary computing. Originally, a single system could only carry out\
    \ a single task; hence, a user needed various systems working in tandem to achieve\
    \ their desired tasks. However, to safely share information between computers—in\
    \ order to overcome the problem of executing only one task at a time—a reliable\
    \ communication mechanism is essential [\\[13\\]](#page-40-11). To that end, our\
    \ investigation unfolds across three key sections: Section [3](#page-4-0) delves\
    \ into the evolution of computing paradigms, emphasizing technological drivers.\
    \ Section [4](#page-6-0) offers a comprehensive classification of computing systems.\
    \ The discussion in Section [5](#page-28-0) revolves around the impact and performance\
    \ criteria of modern computing. Section [6](#page-37-0) introduces the hype cycle\
    \ for modern computing systems, spotlighting emerging trends.\n\n<span id=\"page-3-0\"\
    ></span>![](_page_3_Figure_0.jpeg)\n\nFigure 1:Modern Computing: <sup>A</sup>\
    \ Taxonomy\n\nModern Computing: Vision and Challenges\n\n# <span id=\"page-4-0\"\
    ></span>**3. Evolution of Computing Paradigms: Technological Drivers**\n\nFigure\
    \ [1](#page-3-0) illustrates the progression of computing technology starting\
    \ from the year 1960.\n\n# **3.1. Client Server**\n\nIn the year 1960, a centralized\
    \ platform (a.k.a, distribution integration) was developed to share workloads\
    \ (a.k.a., jobs) between the resource providers (i.e., server instances) and service\
    \ consumers (i.e., customers) [\\[12\\]](#page-40-10). Supporting it, a networking\
    \ system was utilized for communications between client devices and servers, and\
    \ servers exchange resources for customers to perform their tasks using a load\
    \ balancing mechanism [\\[14\\]](#page-40-12). Illustrative examples of the clientserver\
    \ model's application include the Email and the World Wide Web (WWW). However,\
    \ users in this configuration were unable to freely interact with one another.\n\
    \n#### **3.2. Supercomputer**\n\nA supercomputer is a powerful computer with extraordinary\
    \ processing capability, such that it can handle complex calculations in several\
    \ areas of science, including climate study, quantum physics, and molecular simulation\
    \ [\\[15\\]](#page-40-13). Energy utilization and heat control in supercomputers\
    \ endured as a key research problem throughout their growth in the 1960s [\\[16\\\
    ]](#page-40-14). Supercomputers, such as Multivac, HAL-9000, and Machine Stops,\
    \ have been instrumental in underpinning/enabling dramatic technological advancements\
    \ [\\[14\\]](#page-40-12).\n\n# **3.3. Proprietary Mainframe**\n\nTo handle massive\
    \ amounts of data (including dealing with transactions, customer data analysis,\
    \ and censuses), a high-speed machine with large computing power is required [\\\
    [17\\]](#page-40-15). Virtualization on mainframes allows for increased efficiency,\
    \ protection, and dependability. In the year 2017, IBM announced the newest version\
    \ of its mainframe, the IBM z14 [\\[13\\]](#page-40-11). Being built to support\
    \ massive economic activity and despite their high price tag, mainframe computers\
    \ deliver outstanding efficiency [\\[14\\]](#page-40-12).\n\n## **3.4. Cluster\
    \ Computing**\n\nCluster computing is a method of increasing the efficiency of\
    \ a computing system by utilizing several nodes to complete a single operation\
    \ [\\[18\\]](#page-40-16). In order to coordinate various computing nodes, this\
    \ type of technology requires a rapid Local Area Network (LAN) for exchanging\
    \ information among them [\\[19\\]](#page-40-17).\n\n## **3.5. Home PCs**\n\n\
    The early days of the Internet coincided with the flourishing of Personal Computers\
    \ (PC) kept at one's home [\\[3\\]](#page-40-1). The Internet was evolving into\
    \ a foundational network, connecting local networks to the larger Internet using\
    \ self-adaptive network protocols, such as Transmission Control Protocol/Internet\
    \ Protocol (TCP/IP)—in contrast to the original Network Control Protocol (NCP)-based\
    \ Advanced Research Projects Agency Network (ARPANET) mechanisms [\\[2\\]](#page-40-0).\
    \ As a result, there was a sharp increase in the number of hosts on the Internet,\
    \ which quickly overwhelmed centralized naming technologies like *HOSTS.TXT*.\
    \ In the year 1985, the earliest publicly available version of a Domain Name System\
    \ (DNS) was released for the Unix BIND system [\\[20\\]](#page-40-18). This system\
    \ translates hostnames into IP addresses. Pioneer Windows, Icons, Menus, and Pointers\
    \ (WIMP)-based Graphical User Interfaces (GUIs) on computers, such as the Xerox\
    \ Star and the Apple LISA, proved that customers could successfully use machines\
    \ in their homes for tasks like playing video games and surfing the Internet [\\\
    [21\\]](#page-40-19).\n\n# **3.6. Open MPP/SMP**\n\nMassive Parallel Processing\
    \ (MPP) and Symmetric Multi-Processing (SMP) systems are the two most common forms\
    \ of parallel computing platforms [\\[16\\]](#page-40-14). In an SMP setup, multiple\
    \ processors run the same Operating System (OS) concurrently while sharing the\
    \ rest of the hardware's capacity (e.g., disc space and RAM). Naturally, resource\
    \ pooling influences the computational speed of completing a given assignment.\
    \ In an MPP scenario, the file system can be shared, while no other resources\
    \ are pooled for use during task processing [\\[14\\]](#page-40-12). Incorporating\
    \ more machines and their associated storage and RAM space, increases the ability\
    \ to scale according to the Universal Scalability Law (an extension of Amdahl's\
    \ Law), assuming the proportion of work that can be parallelized and the interprocess\
    \ communication penalty:\n\n$$\nCapacity = \\frac{N}{1 + \\sigma \\cdot (N - 1)\
    \ + \\kappa \\cdot N \\cdot (N - 1)}.\n$$\n (1)\n\n# **3.7. Grid Computing**\n\
    \nThis technology enables a group to work together towards the same objective\
    \ by executing non-interactive, and largely IO-intensive tasks [\\[19\\]](#page-40-17).\
    \ Each application running on only one grid is a top priority [\\[12\\]](#page-40-10).\
    \ In addition to allocating and managing resources, grid computing also offers\
    \ a reliable architecture, as well as tracking and exploration support.\n\n# **3.8.\
    \ WWW**\n\nThe primary web browsers, websites, and web servers all came into existence\
    \ in the later stages of the 1980s and early 1990s, underpinned by the development\
    \ of Hyper Text Transport Protocol (HTTP) and Hyper Text Markup Language (HTML)\
    \ [\\[2\\]](#page-40-0). The platform for the interconnected system of networks\
    \ that makes up the WWW was made possible by the standardizing technology of TCP/IP\
    \ network protocols. This allowed for a dramatic increase in the total number\
    \ of servers linked to the Web and introduced Information Technology (IT) to the\
    \ general public. Software applications were thus able to communicate with one\
    \ another beyond address spaces and networking, e.g., via novel technologies like\
    \ Remote Procedure Calls (RPCs) [\\[22\\]](#page-40-20).\n\n## **3.9. Commodity\
    \ Clusters**\n\nCommodity cluster computing employs several computers simultaneously,\
    \ which can inexpensively execute user tasks [\\[19\\]](#page-40-17). In an effort\
    \ to standardize their processes, several companies use open standards while building\
    \ commodity computers [\\[14\\]](#page-40-12). This allowed immediate computing\
    \ business needs to be met using ready-made processors.\n\n## **3.10. Peer to\
    \ Peer (P2P)**\n\nP2P is a distributed framework to share workloads or jobs amongst\
    \ multiple peers; alternatively, computers and peers may interact with one another\
    \ openly at the application layer [\\[23\\]](#page-40-21). With no mediator in\
    \ the center, users of a peerto-peer system can share resources like memory, CPU\
    \ speed, and storage space. Peer-to-peer communication utilizes the TCP/IP protocol\
    \ suite [\\[24\\]](#page-40-22). Interactive media, sharing file infrastructure,\
    \ and content distribution are some of the most common use cases for P2P technology.\n\
    \n## **3.11. Web Services**\n\nThe technology supporting web services enables\
    \ the exchange of data between various Internet-connected devices in machine-understandable\
    \ data formats, such as JavaScript Object Notation (JSON) and Extensible Markup\
    \ Language (XML), over the WWW [\\[25\\]](#page-40-23). Commonly, web-based services\
    \ operate as a connection between end users and database servers.\n\n## **3.12.\
    \ Service-Oriented Architecture (SOA)**\n\nThe SOA paradigm enables software elements\
    \ to be reused and made compatible through advertised service designs/APIs [\\\
    [26\\]](#page-40-24). It is normally easier to include services in new apps: the\
    \ apps can be architected to adhere to standardized protocols and leverage consistent\
    \ design patterns. This frees the software engineer from the burden of recreating\
    \ or duplicating current features or figuring out how to link to and interoperate\
    \ with current systems—e.g., via using Software Development Kits (SDKs) that implement\
    \ common functionalities, such as networking, retries, marshalling of data and\
    \ error handling [\\[27\\]](#page-40-25). Each SOA API exposes the logic and data\
    \ necessary to carry out a single, self-contained business operation (such as\
    \ vetting the creditworthiness of a client, determining the loan's due date, or\
    \ handling an insurance application) [\\[28\\]](#page-40-26). The loose integration\
    \ provided by the service's design allows for the service to be invoked with limited\
    \ knowledge of the underlying service implementation.\n\n## **3.13. Virtualized\
    \ Clusters**\n\nVirtualization enables a guest computer system to be implemented\
    \ on top of a host computer system, which abstracts away the problem of physically\
    \ supporting and maintaining multiple types/architectures of physical machines\
    \ [\\[19\\]](#page-40-17). With a virtualized cluster, several Virtual Machines\
    \ (VMs) may pool their resources to complete a single job. VM hypervisors, which\
    \ execute the guest system on the host system, allow software-based virtualization\
    \ to run either on top of an OS or directly (bare-metal) on hardware [\\[14\\\
    ]](#page-40-12). Costs and complexity are reduced, and a greater number of tasks\
    \ may be completed with identical hardware by adopting a VMbased system.\n\n####\
    \ **3.14. High Performance Computing (HPC) System**\n\nHPC is the computing method\
    \ of choice when dealing with computationally intensive issues, which tend to\
    \ arise in the domains of commerce, technology, and research [\\[14,](#page-40-12)\
    \ [19\\]](#page-40-17). A scheduler in an HPC system manages accessibility to\
    \ the various computing resources available for use in solving various issues\
    \ [\\[29\\]](#page-40-27). HPC systems utilize a pooled set of resources, allowing\
    \ them to perform workloads or tasks via the allocation of concurrent resources\
    \ and online utilization of various resources.\n\n# **3.15. Autonomic Computing**\n\
    \nOne of the first global initiatives to build computer systems with minimum human\
    \ involvement to achieve preset goals was IBM's autonomic computing program in\
    \ 2006 [\\[30\\]](#page-40-28). It was mostly based on research on nerves, thinking,\
    \ and coordination. Autonomic computing research examines how software-intensive\
    \ systems may make choices and behave autonomously to achieve user-specified goals\
    \ [\\[4\\]](#page-40-2). Control for closed- and open-loop systems has shaped\
    \ autonomic computing [\\[31\\]](#page-40-29). Complex systems can have several\
    \ separate control networks.\n\n#### **3.16. Mobile Computing**\n\nThe term \"\
    mobile computing\" is used to describe a wide range of IT components that give\
    \ consumers mobility in their usage of computation, information, and associated\
    \ equipment and capabilities [\\[32\\]](#page-40-30). An especially popular definition\
    \ of \"mobile\" is accessing information while moving, when an individual is not\
    \ confined to a fixed place. Accessibility at a fixed spot may also be thought\
    \ of as mobile, especially if it is provided by hardware that consumers can move\
    \ as needed but that remains in one place while functioning [\\[33\\]](#page-40-31).\
    \ Mobile computing devices are becoming essential across industries, boosting\
    \ efficiency and creativity in fields such as healthcare, retail, manufacturing,\
    \ and the arts.\n\n## **3.17. Cloud Computing**\n\nSoftware as a service (SaaS),\
    \ platform as a service (PaaS), and infrastructure as a service (IaaS) are all\
    \ examples of Internet-accessible web services [\\[1\\]](#page-39-0). Google Mail\
    \ is an excellent instance of a SaaS product since it provides a wide range of\
    \ useful features without the burden of installation and ongoing upkeep costs.\
    \ PaaS providers like Microsoft provide a scalable environment where users can\
    \ install their applications [\\[34\\]](#page-40-32). Amazon is a prime instance\
    \ of an IaaS provider since it provides users with access to servers, networks,\
    \ storage, and other hardware components necessary to run applications and other\
    \ workloads efficiently and effectively. Using distant facilities for performing\
    \ user operations (processing, administration, and storage of data) over the Internet\
    \ is known as \"cloud computing,\" abbreviated as \"XaaS,\" where X = \"I,\" \"\
    P,\" \"S,\" etc. Cloud computing enables the pooling of resources to reduce execution\
    \ costs and enhance service accessibility [\\[35\\]](#page-40-33). There are four\
    \ major types of cloud computing systems: public, private, hybrid, and communal.\
    \ Dependability, safety, and cost-effectiveness are just a few examples of Quality\
    \ of service (QoS) characteristics that should be considered while developing\
    \ a successful cloud service.\n\n# **3.18. IoT**\n\nControllers, gadgets, and\
    \ detection devices are all examples of IoT devices that can communicate with\
    \ one another over the WWW [\\[5\\]](#page-40-3). IoT has many potential uses\
    \ in many different areas, including farming, medical treatment, climate prediction,\
    \ logistics, home automation, and industrial automation [\\[36\\]](#page-40-34).\n\
    \n# **3.19. Fog Computing**\n\nThis cutting-edge design makes extensive use of\
    \ mobile devices, also known as fog nodes, which are utilized for data storage\
    \ and processing, and rely on the web for inter-node connectivity [\\[37\\]](#page-40-35).\
    \ The data plane and the control plane are the two main components of fog computing\
    \ [\\[38\\]](#page-40-36). Although the control layer is a gateway component and\
    \ determines the network's layout, the data plane offers capabilities at the network's\
    \ edge to decrease delay and boost QoS [\\[39\\]](#page-40-37). Fog computing\
    \ supports IoT gadgets such as smartphones, detectors, and health monitors.\n\n\
    # **3.20. Edge Computing**\n\nEdge computing is a method that delegates processing\
    \ to dispersed edge devices for data processing and information exchange [\\[40\\\
    ]](#page-40-38). In addition, edge computing enhances QoS, decreases delay, and\
    \ lowers transmitting expenses by computing huge volumes of data on gadgets at\
    \ the edge rather than in the public cloud [\\[41\\]](#page-40-39). However, edge\
    \ computing relies on a constantly available web connection to perform certain\
    \ tasks in a timely manner, so it's best used for applications that can execute\
    \ autonomously without centralized control for prolonged periods of time [\\[42\\\
    ]](#page-40-40).\n\n# **3.21. Serverless Computing**\n\nThe serverless computing\
    \ paradigm eliminates the need to manage servers and other infrastructure components\
    \ [\\[43\\]](#page-40-41) centrally. Since serverless computing eliminates the\
    \ need for software engineers to manage servers, it is expected to grow much faster.\
    \ With serverless computing, hosting companies may easily handle infrastructure\
    \ management and automatic provisioning [\\[44\\]](#page-40-42). Because of this,\
    \ less effort and resources are needed to oversee the infrastructure.\n\n## **3.22.\
    \ Osmotic Computing**\n\nOsmotic computing is a growing idea that merges IoT,\
    \ cloud, fog, and edge technology for the constantly changing administration of\
    \ IT services. The dramatic increase in the size of resources in the network's\
    \ periphery is the primary force behind this trend. By defining, creating, and\
    \ implementing a computing model, this paradigm focuses on methods to improve\
    \ edge and cloud-based IoT services [\\[45\\]](#page-40-43). To manage resources\
    \ and resolve data difficulties in IoT and data science, osmotic computing applies\
    \ the fundamental concepts of the osmosis phenomenon in chemistry [\\[46\\]](#page-40-44).\
    \ The primary objective of this computing model is to distribute workloads and\
    \ efficiently use available resources among servers without degrading service\
    \ delivery or efficiency.\n\n# **3.23. Dew Computing**\n\nDew computing is \"\
    a software-hardware organization model for computers situated in the cloud computing\
    \ environment,\" where a local machine complements and operates independently\
    \ of cloud services [\\[47\\]](#page-40-45). Dew computing may bridge the gap\
    \ between cloud and on-premises computing. Data and services stored in the cloud\
    \ are accessible regardless of an Internet connection. The need for constant Internet\
    \ access is the primary restriction on cloud and fog computing. Complementing\
    \ fog and edge computing with considerable Internet reliance, an extra layer,\
    \ including dew computing, is necessary to keep apps and services alive and functioning.\
    \ Even if dew computing is not conducted entirely online, it nevertheless uses\
    \ cloud computing and depends on collaboration for data and operations, for example,\
    \ One Drive [\\[48\\]](#page-40-46).\n\n# **3.24. Quantum Computing**\n\nQuantum\
    \ computing is a radically different way to analyze knowledge and data. Several\
    \ possibilities can be taken advantage of when processing information stored in\
    \ the quantum states of quantum machines that are unavailable when analyzing information\
    \ in a conventional fashion [\\[49\\]](#page-40-47). The phenomena of quantum\
    \ entanglement and superposition are two such examples. Because of quantum entanglement,\
    \ it is difficult to offer a comprehensive description from the understanding\
    \ of merely the component states, which is a defining characteristic of quantum\
    \ systems. One definition of the term \"superposition\" is the potential of merging\
    \ quantum states to create a new valid quantum state [\\[50\\]](#page-40-48).\
    \ The primary purpose driving the effort to construct a quantum computer was the\
    \ modelling of quantum systems; however, it was not until the identification of\
    \ quantum algorithms capable of achieving realistic objectives that the enthusiasm\
    \ for constructing such devices began to garner increasing scrutiny [\\[51\\]](#page-41-0).\n\
    \n# <span id=\"page-6-0\"></span>**4. Classification of Computing: Paradigms,\
    \ Technologies and Trends**\n\nIn this section, we discuss the different types\
    \ of computing and classify them into different broad categories as shown in Fig.\
    \ [1.](#page-3-0) Table [2](#page-7-0) briefly describes traits of computing that\
    \ are used in this classification such as 1) focus or paradigms; 2) technologies\
    \ or impact areas; and 3) trends or observations.\n\n## **4.1. Standalone vs.\
    \ Networked Computing**\n\nStandalone computing occurs when a computer is not\
    \ connected to another computer in any way, whether through wired or WiFi connections\
    \ [\\[52\\]](#page-41-1). Multiple computers linked together form a network, a\
    \ model that falls under networked computing.\n\n| Trait              | Description\
    \                                                                            \
    \            |\n|--------------------|----------------------------------------------------------------------------------------------------|\n\
    | Focus/ Paradigms   | We discuss well-established computing paradigms, from client-server\
    \ to quantum computing, which    |\n|                    | have been explored\
    \ in the last decade.                                                        \
    \     |\n| Technologies/ Im   | We cover key research that has grown over time\
    \ by utilizing these well-established computing       |\n| pact Areas        \
    \ | paradigms and how this has led to many breakthroughs in the underlying technology.\
    \                 |\n| Trends/<br>Observa | The new trends, such as large-scale\
    \ machine learning, digital twins, edge AI, bitcoin currency, 6G |\n| tions  \
    \            | & Beyond and quantum Internet and biologically-inspired computing,\
    \ for the next generation of      |\n|                    | computing, have come\
    \ to light due to these advances in computing paradigms and technology.      \
    \   |\n\n<span id=\"page-7-0\"></span>Table 2 Summary of Computing Traits\n\n\
    ## *4.1.1. Standalone Computing*\n\nIn this section, we discuss the main focus\
    \ or paradigms, technologies or impact areas, and various trends or observations\
    \ within standalone computing.\n\n#### *4.1.1.1. Focus/Paradigms*\n\nThe following\
    \ are the main focus or paradigms for standalone computing:\n\n*1) PCs*: Individuals\
    \ use PCs, which leverage microprocessors designed for personal use. Before the\
    \ PC, businesses had to operate computers by connecting several users' terminals\
    \ to a separate, massive mainframe system [\\[3\\]](#page-40-1). By the end of\
    \ the 1980s, technical developments had enabled the construction of a compact\
    \ computer that a person could purchase and use as a word processor or for various\
    \ computing objectives [\\[2\\]](#page-40-0).\n\n*2) Embedded Systems*: A computer\
    \ (often a microcontroller or microprocessor) is built into (i.e., embedded in)\
    \ the design of a device [\\[53\\]](#page-41-2). Most of the time, an individual\
    \ does not even realize they are using a computer because there might not be any\
    \ obvious hints of applications, data, or software [\\[54\\]](#page-41-3). The\
    \ software that operates a microwave oven or an engine control unit of a contemporary\
    \ vehicle are two instances of items with undetectable integrated systems.\n\n\
    ## *4.1.1.2. Technologies/Impact Areas*\n\nThe key technologies and affected domains\
    \ for standalone computing include:\n\n*1) Single-board Computers (SBCs)*: In\
    \ an SBC, the CPU, I/O, memory, and various other components are all housed on\
    \ one integrated circuit board; the quantity of memory is fixed; and there are\
    \ no slots to be expanded for additional hardware [\\[55\\]](#page-41-4).\n\n\
    *2) Raspberry Pi 4*: The Raspberry Pi is a family of tiny SBCs that have been\
    \ developed to allow programming and computing capabilities to be available to\
    \ all. The Raspberry Pi Model B became the inaugural board produced by the foundation\
    \ behind the Raspberry Pi [\\[55\\]](#page-41-4). Due to its immense popularity,\
    \ other variants have subsequently been developed, each with its own set of advantages.\
    \ These include the Raspberry Pi computation component, which has been optimized\
    \ for use in embedded systems [\\[56\\]](#page-41-5).\n\n*3) NVIDIA Jetson Series*:\
    \ This is a line of Graphics Processing Units (GPUs) that includes the initial\
    \ processors built with the explicit purpose of powering self-driving robots [\\\
    [57\\]](#page-41-6). With up to 32 Tera Operations Per Second (TOPS) of Artificial\
    \ Intelligence (AI) efficiency, these GPUs efficiently handle optical measurements,\
    \ sensor fusion, positioning, visualization, obstacle detection, and path-planning,\
    \ all of which are essential for the development of robotics [\\[55\\]](#page-41-4).\
    \ The Jetson Xavier series focuses on creating specialized robots and edge robots,\
    \ with several distinct manufacturing components.\n\n## *4.1.1.3. Trends/Observations*\n\
    \nThe main trends and observations regarding standalone computing are:\n\n*1)\
    \ Adoption of AI/ML*: NVIDIA Jetson Nano, for instance, enables consumers to equip\
    \ billions of low-power AI/ML systems with remarkable new features [\\[58\\]](#page-41-7).\
    \ It paves the way for a wide variety of integrated IoT services, such as low-cost\
    \ Network Video Recorders (NVRs), consumer automation, and analytics-rich gateways\
    \ [\\[55\\]](#page-41-4). With its ready-to-try applications and enthusiastic\
    \ software developer community, Jetson Nano serves as the ideal tool for beginning\
    \ students to gain knowledge about AI and robotics in real-life situations.\n\n\
    *2) Cybersecurity*: Embedded systems are compact, specifically designed devices\
    \ built to carry out a single task, frequently in real-time, while using as few\
    \ resources as possible [\\[54\\]](#page-41-3). Installing protective measures\
    \ on these platforms to guard against dangers like unauthorized usage or fraudulent\
    \ attacks drives the need for embedded security [\\[59\\]](#page-41-8). These\
    \ safeguards are included in electrical components, firmware, and applications\
    \ to achieve an all-encompassing defence.\n\n## *4.1.2. Networked Computing*\n\
    \nIn this section, we discuss the main focus or paradigms, technologies or impact\
    \ areas, and various trends or observations within networked computing.\n\n# *4.1.2.1.\
    \ Focus/Paradigms*\n\nThe following are the main focus or paradigms for networked\
    \ computing:\n\n*1) Networking/Connectivity*: Servers in cloud computing underpin\
    \ the services and Application Programming Interfaces (APIs) provided to internal\
    \ and external clients. Communication on several levels, both inside and among\
    \ data centers, is essential for effectively implementing cloud services [\\[1\\\
    ]](#page-39-0). Crucially, networking ensures that all parts can talk to one another\
    \ in a safe, frictionless, effective, and adaptable way. Many developments and\
    \ studies in networking during the past ten years have focused on the cloud [\\\
    [60\\]](#page-41-9). For instance, Software-Defined Networking (SDN) and Network\
    \ Function Virtualization (NFV) aim to construct adaptable, versatile, and programmable\
    \ computer networks to lessen the financial and time commitments of cloud service\
    \ providers [\\[61\\]](#page-41-10). Scalability challenges have spurred several\
    \ current developments in network design for the Cloud Data Centers (CDCs), as\
    \ well as the necessity for a flat addressing space, and the excess demand for\
    \ machines. Notwithstanding these developments, numerous networking issues require\
    \ a resolution. The excessive energy consumption of modern CDCs is a major issue\
    \ [\\[60\\]](#page-41-9). Especially because it is a common practice in data centers\
    \ to have all networking equipment active at all times. Furthermore, unlike computing\
    \ servers, most network parts (including switches, hubs, and routers), cannot\
    \ be energy-proportionate; features like hibernation during periods of low traffic\
    \ and connection-rate adaptability are not built in by default [\\[62\\]](#page-41-11).\
    \ Consequently, the design and execution of approaches and technologies that seek\
    \ to minimize network energy usage and make it proportionate to the incoming load\
    \ continue to be outstanding issues. QoS assurance presents another complex challenge\
    \ within CDC networks [\\[63\\]](#page-41-12). Service Level Agreements (SLAs)\
    \ in modern clouds focus mostly on computing and storage. There is currently no\
    \ way to encapsulate network performance constraints like latency and bandwidth\
    \ assurances without resorting to \"best effort\" because no abstraction or method\
    \ guarantees performance isolation. Providing network connections across widely\
    \ dispersed resources (in other words, installing a \"virtual cluster\" encompassing\
    \ resources in an amalgamated cloud setting), exacerbates this difficulty [\\\
    [64\\]](#page-41-13). However, there are numerous open challenges to deliver reliability\
    \ assurances for these networks—due to packages needing to navigate the (public)\
    \ Internet, including resources in various locations [\\[65\\]](#page-41-14).\n\
    \n# *4.1.2.2. Technologies/Impact Areas*\n\nThe key technologies and affected\
    \ domains for networked computing include:\n\n4.1.2.2.1. Internet of Things (IoT)\n\
    \nDevices (a.k.a., things) that can detect, control, and communicate are now routinely\
    \ integrated with continuous control and monitoring functions via the Internet\
    \ [\\[1\\]](#page-39-0). These devices have become ubiquitous in modern society,\
    \ found in homes, on public transport, along highways, and in vehicles. Because\
    \ of this, IoT applications may function in many contexts and provide a sophisticated\
    \ evaluation and administration of complicated relationships [\\[66\\]](#page-41-15).\
    \ As a result, IoT devices and services may solve problems in many application\
    \ domains, such as digital health, facility administration systems, production,\
    \ and transportation. IoT-based systems have to deal with limited processing power,\
    \ memory, and storage space because (i) platforms are constantly changing, so\
    \ devices that join a network have to be able to adapt to these changes; (ii)\
    \ devices differ in how well they work with computers and what features they offer;\
    \ and (iii) to ensure the safety of the IoT data that has been acquired, a federated\
    \ system is needed [\\[5\\]](#page-40-3).\n\nThese days, popular IoT use cases\
    \ include medical care, smart cities, climate prediction, water supply management,\
    \ and highway surveillance, all of which leverage the capabilities of cloud, serverless,\
    \ fog, and edge computing for processing user data to meet QoS requirements [\\\
    [67\\]](#page-41-16).\n\n- **Healthcare:** Among the many significant IoT applications\
    \ is medical care, which is designed to treat conditions including heart attacks,\
    \ diabetes, cancer, COVID-19, and influenza [\\[68\\]](#page-41-17). For instance,\
    \ a patient's heart condition may be instantly diagnosed using a variety of medical\
    \ devices in an interconnected IoT and computing environment [\\[69\\]](#page-41-18).\
    \ Additionally, modern technology like Virtual Reality (VR) or AI can enhance\
    \ the present healthcare system in the fight against inevitable pandemics [\\\
    [70\\]](#page-41-19).\n- **Agriculture:** In order to forecast variables like\
    \ yield, rainfall, and crop quality, the agricultural industry is making use of\
    \ modern technology to analyze a wide range of data pertaining to agriculture\
    \ [\\[71\\]](#page-41-20). One use case is the development of cloud-based agricultural\
    \ systems that can autonomously forecast the state of agriculture using data collected\
    \ from a variety of IoT or edge sensors. Additionally, to facilitate automated\
    \ farming, an iOS or Android application is created to handle the massive amounts\
    \ of data and supply the information they need to the agriculturalists through\
    \ their edge devices [\\[72\\]](#page-41-21).\n- **Smart Home:** Owners may optimize\
    \ energy consumption and offer the necessary protection with the deployment of\
    \ cameras through the implementation of smart homes, which allow them to operate\
    \ their home devices from their cell phones [\\[36\\]](#page-40-34). For instance,\
    \ a resource management approach that incorporates cloud and fog computing may\
    \ be used for controlling edge devices utilizing a smartphone application, which\
    \ in turn regulates the room's humidity, lighting, surveillance systems, fans,\
    \ and voltage, such as via sensors connected to different household devices [\\\
    [73\\]](#page-41-22).\n- **Traffic Management**: IoT is crucial in the efficient\
    \ management of traffic through the use of a number of sensors and controllers\
    \ [\\[74\\]](#page-41-23). To identify potholes, for instance, an IoT-based intelligent\
    \ transportation system is created. In addition, its efficiency was assessed using\
    \ a range of machine learning approaches and performance metrics [\\[75\\]](#page-41-24).\
    \ Additionally, data may be processed swiftly using fog and edge computing methodologies\
    \ to notify about potholes early, thereby reducing the likelihood of mishaps.\n\
    - **Weather Forecasting:** Through the use of cloud computing and the IoT, scientists\
    \ and weather forecasters may better gather data to inform their work [\\[76\\\
    ]](#page-41-25). Scientists have long relied on visual observations, data\n\n\
    storage, and the public presentation of meteorological factors like air quality\
    \ and moisture to better understand and explain these phenomena [\\[77\\]](#page-41-26).\
    \ The findings may be made using an IoT system that relies on sensors and can\
    \ transmit the results to the cloud.\n\nCloud services have long been relied upon\
    \ by IoT applications to handle processing and permanent storage. Still, as the\
    \ number of 'things' proliferates, such services are increasingly unable to keep\
    \ up with the real-time demands of IoT gadgets [\\[78\\]](#page-41-27). This is\
    \ due to the high quantity of data and the short reaction times required by systems\
    \ that operate in the real world over wide geographical areas. By moving resource\
    \ orchestration from servers to edge networks, fog/edge computing expands the\
    \ capabilities of cloud systems: Set up as a series of nested \"cloudlets\" that\
    \ may perform data intake, processing, and administration [\\[79\\]](#page-41-28).\
    \ Compared to cloud services, geographically localized solutions use less power\
    \ and allow for more mobile resources by decreasing reaction times and increasing\
    \ intake bandwidth through horizontal scalability. These features make fog/edge\
    \ computing a potential future architecture for IoT applications since this architectural\
    \ model allows for scalability on a logical and geographical scale with near-instantaneous\
    \ response latency [\\[32\\]](#page-40-30).\n\nBy aggregating information from\
    \ implanted and mobile gadgets and establishing mobile area networks, smart ehealth\
    \ apps can track information about patients in a continuous fashion [\\[80\\]](#page-41-29).\
    \ By performing tasks like healthcare equipment noise filtering, data reduction\
    \ and fusion, and analytics that identify harmful patterns in patients' wellbeing,\
    \ smart gateways gather and interpret data from devices locally [\\[81\\]](#page-41-30).\
    \ At the same time, longer-term patterns may be evaluated at cloud levels.\n\n\
    In addition, IoT systems supported by fog computing may adjust their actions based\
    \ on the information they receive from sensors. For example, if a heart attack\
    \ is recognized by initial processing at the fog layer, the intelligent gateway\
    \ gathering signals from the defibrillator may adaptively boost the sample size\
    \ before the attack. Similarly, the Industrial Internet of Things (IIoT) benefits\
    \ from integrating edge, fog and cloud layers to provide specific and nearly realtime\
    \ actions [\\[82\\]](#page-41-31). Smart grids and energy management are central\
    \ to the Internet of Energy (IoE) paradigm. Coarsegrained information on network\
    \ health may be gathered from dispersed networks of energy producers that track\
    \ power usage, generation and/or battery life. While 'Smart-Meters' may communicate\
    \ energy needs to service providers on a more detailed scale, monitoring capacity,\
    \ generation, and use [\\[80\\]](#page-41-29). Therefore, IoT is a foundational\
    \ technology for future systems, like electric automobiles and decentralized power\
    \ grids [\\[33\\]](#page-40-31). In addition, the increased safety, reliability,\
    \ and durability of electricity distribution that this type of grid may provide\
    \ can better satisfy the evolving needs of consumers. In-depth surveys are a good\
    \ resource for IoT researchers who want to explore more.\n\n4.1.2.2.2. Software-Defined\
    \ Network (SDN) SDN transcends traditional network paradigms by separating control\
    \ logic from the underlying hardware and centralizing network management [\\[83\\\
    ]](#page-41-32). This innovative approach facilitates programmable network architectures\
    \ and streamlines management by distinctly segregating network policies, hardware\
    \ implementation, and traffic forwarding [\\[84\\]](#page-41-33). Integral to\
    \ cloud computing, SDN enhances communication and automates configurations, revolutionizing\
    \ network adaptability and resource utilization in diverse environments [\\[85\\\
    ]](#page-41-34).\n\nNFV is another approach that utilizes software programs to\
    \ perform traditionally hardware-based networking tasks, such as DNS, load balancing,\
    \ and intrusion detection. NFV not only lowers costs but also enhances the flexibility\
    \ of network functions and service responsiveness. Furthermore, VM consolidation\
    \ in a virtualized network can help reduce energy costs by minimizing the number\
    \ of VMs in operation [\\[86\\]](#page-41-35). SDN-based cloud computing optimizes\
    \ network virtualization while decreasing electricity consumption. Crucially,\
    \ SDN increases the abstraction of physical assets and automates and optimizes\
    \ the setup process [\\[85\\]](#page-41-34).\n\nMany questions still need to be\
    \ answered by scholars and investigators. First, ensuring data safety during transit\
    \ across multiple cloud data centers is absolutely necessary for SDN-based cloud\
    \ computing [\\[87\\]](#page-41-36). Second, even if SDNenabled cloud infrastructures\
    \ may be replicated, the balance between cost and energy use remains. Deploying\
    \ SDN-based cloud computing systems is necessary to offer an economical network\
    \ virtualization service with lower energy costs and greater dependability [\\\
    [83\\]](#page-41-32). Furthermore, this may also boost data distribution and outcome\
    \ collection by utilizing methods inspired by AI-based models, allowing us to\
    \ expand existing information connectivity in such SDN contexts to accommodate\
    \ blockchain-based systems.\n\n#### *4.1.2.3. Trends/Observations*\n\nThe main\
    \ trends and observations regarding networked computing are as follows:\n\n####\
    \ 4.1.2.3.1. Intelligent Edge\n\nThe IoT connects billions of new devices, generating\
    \ massive amounts of information that, inevitably, proves challenging to process.\
    \ Over 41.6 billion IoT gadgets are estimated to be in operation by the end of\
    \ 2025 [\\[88\\]](#page-41-37). Increasing numbers of products, including connected\
    \ autos, smart meters, and in-store sensors, are being created and installed by\
    \ companies to improve customer experience while generating enormous quantities\
    \ of data [\\[4\\]](#page-40-2).\n\nMeanwhile, this emerging data must be gathered,\
    \ managed, and processed immediately. *What exactly will this mean?* Edge and\
    \ fog computing might be a method for moving ahead. In the coming years, edge\
    \ computing is forecast to receive far greater focus than fog computing. In contrast\
    \ to traditional cloud computing, which analyzes data at a remote data center,\
    \ edge computing performs so locally. In fog computing, it is possible to execute\
    \ a portion of the work in the cloud, while edge devices perform other aspects\
    \ [\\[89\\]](#page-41-38). Since computing at the edge uses far less network bandwidth\
    \ than conventional computing, the data exchanged among connected devices could\
    \ take a long time. Computing it nearby, either on the gadget itself or within\
    \ a local network, will be more cost- and energy-effective. On the contrary, edge\
    \ computing may provide cloud computing with much-needed support in coping with\
    \ the vast volumes of data created by the IoT and other connected devices [\\\
    [90\\]](#page-41-39). Emerging IoT devices create and transport data across the\
    \ fog and edge, and their processing power is leveraged to carry out processes\
    \ that could otherwise be performed in the cloud. Hence, managing these systems\
    \ with fog and edge, IoT devices and support from the cloud requires distributing\
    \ the intelligence along the computing tiers, which leads to edge intelligent\
    \ [\\[91\\]](#page-41-40).\n\nThe terms \"fog\" and \"edge\" allude to these novel\
    \ network nodes for IoT devices. Thus, they aid businesses in reducing their reliance\
    \ on the cloud by transmitting information to analytics platforms. Businesses\
    \ can lessen their dependency on cloud platforms for data processing and thereby\
    \ reduce latency across networks by implementing edge and fog solutions [\\[92\\\
    ]](#page-41-41). This will allow rapid evidencebased recommendations to assist\
    \ them in their decisionmaking process. Nevertheless, once real-time processing\
    \ is complete, edge devices must transfer data to the cloud for statistics to\
    \ be performed on it [\\[93\\]](#page-41-42).\n\nA company's communication network\
    \ is largely concerned with enabling various remote apps and providing endless\
    \ storage space, thanks to cloud computing, connectivity, and computing capacity.\
    \ That will ultimately alter data processing at the edge in real-time, which is\
    \ essential for optimal data utilization [\\[90\\]](#page-41-39). Future-proof\
    \ network infrastructures will need to accommodate an unprecedented influx of\
    \ smart devices. For real-time intelligence, it is crucial to have the decision-making\
    \ process located close to where the data is produced. Self-driving automobiles\
    \ and selfsustainable, smart factory equipment, for instance, require to be making\
    \ split-second decisions [\\[94\\]](#page-42-0). Further, airline sensors collect\
    \ data on engine efficiency in real time, allowing for predictive maintenance\
    \ before a plane ever takes off. Potential cost reductions might be considerable.\
    \ The more business connections an organization has, the more processing power\
    \ and intelligence it can provide.\n\n## 4.1.2.3.2. 6G and Beyond\n\nThe advancement\
    \ to Industry 5.0 and the foundation of a technology-driven economy hinge on the\
    \ development of Beyond 5G (B5G) and 6G networks. As communication and technological\
    \ advancements increase, international industrial sectors will increasingly depend\
    \ on 5G and B5G networks to provide revolutionary services and applications that\
    \ will inevitably require ultra-low latency, unprecedented reliability, and continuous\
    \ mobility [\\[95\\]](#page-42-1). Meanwhile, underpinned by Moore's law, mobile\
    \ devices have been rapidly adopting systems-technology co-optimization (STCO)\
    \ and related system-building approaches, which departs from the conventional\
    \ system-on-a-chip (SoC) approach [\\[96\\]](#page-42-2).\n\nThrough cloud-based\
    \ principles, including utilizing functioning between and among data centers,\
    \ connecting in a\n\nmicro-service setting, and concurrently offering reliable\
    \ services and applications, it is expected that B5G/6G networks will be able\
    \ to serve a wide variety of applications [\\[97\\]](#page-42-3). Both B5G and\
    \ 6G networks aim to enable the smooth and complete integration of many industries,\
    \ including the IoT, aerial networks (also known as drones), satellite accessibility,\
    \ and submerged connectivity [\\[98\\]](#page-42-4). To keep up with this astonishing\
    \ expectation, the next generation of networks (B5G/6G) will largely rely on cutting-edge\
    \ AI/ML technology for intelligent network operations and administration. B5G\
    \ and 6G infrastructures are anticipated to provide computationally intensive\
    \ applications and services paired with infrastructure shifts [\\[99\\]](#page-42-5).\n\
    \nEdge computing has received a lot of interest and is being evaluated as an integrated\
    \ service in 6G networks to enable the two fundamental changes in network infrastructure\
    \ and network services. While many studies have focused on features like cache\
    \ services and compute offloading methods, little is known about mobile edge computing\
    \ implementation. The necessity of moving forward with a softwarecentric strategy\
    \ from the network core to the wireless layer was emphasized in the first efforts\
    \ that contributed significantly to the conception of 5G [\\[100\\]](#page-42-6).\
    \ As with 5G networks, 6G networks will depend heavily on SDN, which, together\
    \ with NFV, represents a departure from the conventional hardware-centric strategy\
    \ [\\[9\\]](#page-40-7). The mobile edge computing paradigm also encourages moving\
    \ the base station (BS) and the core network functions to different places. BS\
    \ functions are moved upstream to the cloud, and core network functions are moved\
    \ downstream to the devices. The resulting boundary between the BS and the end\
    \ device might be seen as an \"edge\" or \"fog\" domain [\\[73\\]](#page-41-22).\n\
    \nWhile cloud computing has made it possible for users to access richer and more\
    \ complicated apps by tapping into the resources of a remote cloud server, an\
    \ alternative technique is needed to meet the extremely delicate latency criteria\
    \ stated for use cases in 5G and maybe 6G [\\[101\\]](#page-42-7). This heterogeneous\
    \ network design directly results from the complicated traffic distributions in\
    \ today's wireless networks. A wireless access point (AP), a macro BS, and a small\
    \ cell BS are just a few examples of network access nodes that may provide stable\
    \ and smooth connections for mobile users [\\[102\\]](#page-42-8). These network\
    \ access nodes provide edge computing at network edges with less delay. The design\
    \ of diverse mobile edge computing networks has gained more and more interest\
    \ due to the varied properties of network access nodes, such as coverage capability\
    \ and power transmission [\\[101\\]](#page-42-7). Nevertheless, it is imperative\
    \ to carefully plan for the offloading of computing tasks to many access nodes\
    \ in a network [\\[103,](#page-42-9) [104\\]](#page-42-10).\n\nIn a heterogeneous\
    \ network design, intelligently distributing tasks and resources among different\
    \ nodes can substantially boost system performance [\\[55\\]](#page-41-4). For\
    \ instance, by collaborating, the edge and cloud can elevate IoT tasks' QoS. While\
    \ cloud servers manage compute-intensive tasks well, edge servers excel at processing\
    \ tasks demanding minimal data or low latency [\\[41\\]](#page-40-39). Strategically\
    \ assigning tasks among edge servers can redistribute work from overburdened nodes\
    \ to less active ones, thus accelerating execution times.\n\n# **4.2. General\
    \ Purpose vs. Specialized Computing**\n\nLeveraging fit-for-purpose software and\
    \ given enough time, general-purpose computing (which includes desktop PCs, laptops,\
    \ mobile devices like tablets and smartphones, and even certain televisions) can\
    \ handle just about any computation [\\[105\\]](#page-42-11). A CPU, memory, input/output\
    \ systems, and a bus are the main parts of any general-purpose computing system.\
    \ In contrast, integrated computers, are used in intelligent systems, and are\
    \ often referred to as \"specialpurpose\" computing systems.\n\n## *4.2.1. General-Purpose\
    \ Computing*\n\nIn this section, we discuss the main focus, paradigms, technologies,\
    \ and impact areas, as well as various trends and observations about general-purpose\
    \ computing.\n\n# *4.2.1.1. Focus/Paradigms*\n\nThe following are the main focus\
    \ areas and paradigms associated with general-purpose computing:\n\n*1) Von Neumann\
    \ Architecture*: A computing device with a Von Neumann architecture has its main\
    \ components—the CPU, memory, and I/O—connected via a single bus [\\[106\\]](#page-42-12).\
    \ The efficiency of computers was greatly enhanced by the advent of this architecture,\
    \ which provided effective means of storing and executing instructions. The fundamental\
    \ idea behind this design is that data and instructions are handled in the same\
    \ way. In other words, the data being handled and the program instructions themselves\
    \ share the same storage and processing resources: a memory address can contain\
    \ either an instruction to be executed or data; the software execution pathways\
    \ decide how to interpret it [\\[107\\]](#page-42-13). This design substantially\
    \ simplifies the framework and features of a computer, making it more accessible\
    \ to both software engineers and non-technical users.\n\n*2) Integrated Computing*:\
    \ Compatibility throughout cloud applications and services is commonly achieved\
    \ by implementing software adapters and libraries and deploying application containers\
    \ for computing to facilitate mobility [\\[108\\]](#page-42-14). Nevertheless,\
    \ there is still a variety of challenges that have existed since the beginning\
    \ of cloud computing but, due to their complexities, have not been adequately\
    \ resolved yet [\\[60\\]](#page-41-9). One of these challenges is encouraging\
    \ cloud connectivity without mandating a baseline set of capabilities for all\
    \ services; ideally, customers can combine complicated features from several providers.\
    \ Another area of investigation is how to develop cloud interoperability middleware\
    \ that can facilitate the offering of complex services by composing more straightforward\
    \ services from multiple 3rd-party providers [\\[109\\]](#page-42-15). Such a\
    \ high degree of abstraction would empower users to make service decisions based\
    \ on their requirements, such as price, turnaround time, privacy, etc. This brings\
    \ up an additional key area that needs further study: the manner in which to allow\
    \ user-level middleware (intercloud and hybrid clouds) to discover potential services\
    \ for an ensemble without assistance from cloud service\n\nproviders [\\[110\\\
    ]](#page-42-16). A strategy that relies on cloud providers working together is\
    \ unlikely to be successful because their financial goals lie in keeping all the\
    \ features they offer to their consumers (i.e., they have no incentive to help\
    \ due to the fact that just a portion of the offerings in an ensemble are themselves).\
    \ Consequently, the middleware that allows the melody of services must address\
    \ challenges at both of its connections: Firstly, the middleware should seamlessly\
    \ and abstractly provide the service to cloud users. Secondly, for the consumers,\
    \ a service might be implemented in its entirety by sub-services offered by one\
    \ vendor (maybe leveraging a 3rd-part SaaS organization able to offer the functionality),\
    \ or it might be acquired through composing multiple services from various providers\
    \ [\\[111\\]](#page-42-17). The provider user interface makes it possible to access\
    \ complex functions without requiring special cooperation from providers [\\[109\\\
    ]](#page-42-15). The widespread use of cloud compatibility can offer commercial\
    \ and financial advantages to cloud manufacturers, but frequently integrated clouds\
    \ (which were achieved via Cloud Federation) cannot be realized until such time\
    \ [\\[112\\]](#page-42-18). This calls for the development of intercloud markets,\
    \ distinctive approaches to invoicing and accounting, as well as novel cloud-suitable\
    \ pricing systems.\n\n## *4.2.1.2. Technologies/Impact Areas*\n\nThe key technologies\
    \ and affected domains for generalpurpose computing include:\n\n# 4.2.1.2.1. Programming\
    \ Models\n\nClusters are a type of parallel or distributed computational system\
    \ that consists of a group of interconnected standalone computers that work collectively\
    \ as a single integrated computing resource. Clusters and grids are platforms\
    \ that communicate with each other to serve as a single resource [\\[113\\]](#page-42-19).\
    \ A multi-core parallel architecture describes this form of capability, which\
    \ is based on specific functions. Conversely, cloud computing emerged on top of\
    \ clusters to abstract leveraging their computing resources and coordinate enormous\
    \ data sets.\n\nA programming model is tightly coupled to where data is transmitted\
    \ to manage an application's functions. Important metrics to remember while building\
    \ a programming model are efficiency, adaptability, goal architecture, and code\
    \ maintainability [\\[114\\]](#page-42-20). Data analytics software often handles\
    \ massive data sets that require many phases of processing. Certain steps have\
    \ to be carried out in order, while others are executed simultaneously across\
    \ several nodes in a cluster, grid, or cloud. The capacity of algorithms to perform\
    \ statistical analysis on huge amounts of data will be crucial to unlocking achievements\
    \ in industrial advances and nextgeneration scientific discoveries [\\[115\\]](#page-42-21).\n\
    \nWith the exponential growth of data comes the difficulty of organizing massive\
    \ data sets, which in turn increases their complexity due to the ways they connect\
    \ with each other. Its many processes include moving, archiving, replicating,\
    \ processing, and erasing data. Data life-cycle complexities can be reduced via\
    \ solutions that automate and improve data management activities. It has been\
    \ shown that two limitations affect the data life cycle [\\[116\\]](#page-42-22).\
    \ The framework used is the first limitation, initially regarding how it operates\
    \ on data derived from consumers and apps. The second limitation derives from\
    \ the observation that data is spread over several systems and infrastructures.\
    \ That is why big data applications need to be capable of communicating amongst\
    \ various systems that deal with the data and the effects that information and\
    \ occurrences might have. The focus of this work is the second limitation, the\
    \ big data infrastructure itself, and it includes a comprehensive analysis of\
    \ the programming models and settings necessary to overcome this limitation.\n\
    \nA programming model is underpinned by how quickly and smoothly its data is manipulated.\
    \ A few elements to consider when creating a programming model include operation,\
    \ adaptability, target designs, and the simplicity of maintenance code modification\
    \ procedures [\\[117\\]](#page-42-23). For the sake of service, it is sometimes\
    \ necessary to sacrifice at least one of these aspects. The exchange of computation\
    \ for data storage or transmission is a usual instance of algorithmic manipulation.\
    \ These difficulties can be mitigated by employing parallel methods and technology.\
    \ A software engineer might undoubtedly leverage many variants of the same technique\
    \ to enable distinct performance adjustments on different hardware architectures.\
    \ Modern computing clusters comprise nodes with more than one CPU, and their hardware\
    \ designs range from tiny to super powerful.\n\n#### 4.2.1.2.2. Virtualization\n\
    \nWith virtualization, the original physical object is replaced with a virtual\
    \ one. The OSs of server infrastructure, hard drives, and PCs are some of the\
    \ most typical targets for virtualization in a data center. Thus, virtualization\
    \ decouples higher-level software and OSs from the underlying computing system\
    \ [\\[118\\]](#page-42-24).\n\nVMs are a key component of hardware virtualization,\
    \ standing in for a \"real\" computer running an OS. Emulating a computer system\
    \ is what VMs do. A hypervisor makes a copy of the underlying hardware so that\
    \ several OSs can share the same resources [\\[119\\]](#page-42-25). Despite being\
    \ around for half a century, VMs are experiencing a surge in popularity because\
    \ of the rise of the mobile workforce and desktop PCs. Server virtualization,\
    \ which employs a hypervisor to effectively \"duplicate\" the underlying hardware,\
    \ is a primary use case for virtualization technology in the corporate world [\\\
    [120\\]](#page-42-26). In a non-virtualized setting, the guest OS generally works\
    \ in tandem with the hardware [\\[121\\]](#page-42-27).\n\nOSs may be virtualized\
    \ and continue functioning as if running on hardware, giving businesses access\
    \ to similar performance levels while reducing hardware costs [\\[122\\]](#page-42-28).\
    \ The majority of guest OSs do not need full access to hardware; therefore, even\
    \ if virtualization efficiency is lower than hardware efficacy, it remains preferred.\
    \ This means firms are less reliant on a single piece of hardware and have more\
    \ leeway to make necessary changes.\n\nFollowing the success of server virtualization,\
    \ other sections of the data center have also begun to implement the same approach.\
    \ Virtualization technology for OSs has been around for generations [\\[123\\\
    ]](#page-42-29). In this implementation, the software enables the hardware to\
    \ run several OSs in parallel. Companies that want to adopt a cloud-like IT infrastructure\
    \ should prioritize virtualization. Using server resources more effectively is\
    \ one of the primary benefits of virtualizing a data center [\\[124\\]](#page-42-30).\
    \ Thanks to virtualization, IT departments may use a single VM to host a wide\
    \ variety of applications, workloads, and OSs, with the flexibility to add or\
    \ subtract resources as required easily. The use of virtualization allows firms\
    \ to expand readily. Organizations may better monitor resource utilization and\
    \ react to shifting needs using such systems.\n\n#### 4.2.1.2.3. Multicore Processors\n\
    \nFor improved performance and more efficient use of energy, integrated circuits\
    \ with several processing cores, or \"cores,\" are becoming increasingly common.\
    \ Furthermore, these processors enable more effective parallel processing and\
    \ multithreading, allowing for simultaneous processing of numerous jobs [\\[125\\\
    ]](#page-42-31). A computer with a dual-core arrangement is functionally equivalent\
    \ to one with two or more individual CPUs. Sharing a socket between two CPUs accelerates\
    \ communication between them. The use of processors with multiple cores is one\
    \ technique to enhance processor performance while surpassing the practical restrictions\
    \ of semiconductor manufacturing and design. Using several processors helps prevent\
    \ any potentially dangerous overheating [\\[126\\]](#page-42-32). Multicore processors\
    \ are compatible with any up-to-date computer hardware architectures. These days,\
    \ multicore processors are standard in desktop and portable computers. Nevertheless,\
    \ the actual power and utility of these CPUs depend on software built to leverage\
    \ parallelism [\\[127\\]](#page-42-33). Application tasks are broken up into many\
    \ processing threads in a parallel strategy, distributing and managing them over\
    \ multiple CPUs.\n\n#### *4.2.1.3. Trends/Observations*\n\nThe main trends and\
    \ observations regarding general-purpose computing are as follows:\n\n#### 4.2.1.3.1.\
    \ Software Systems\n\nWeb-based computing and Software Engineering (SE) are closely\
    \ related disciplines. For instance, service-oriented SE provides various advantages\
    \ to the software creation procedure and app development by merging the greatest\
    \ elements of services and the cloud. In contrast to cloud computing, which is\
    \ concerned with effectively transmitting services to consumers using adaptable\
    \ virtualization of resources and load balancing, service-oriented SE is concerned\
    \ with architectural design (service searching and composition) [\\[128\\]](#page-42-34).\n\
    \nCustomers and developers are both essential to the evolution of hardware innovations,\
    \ which is why software engineering is a crucial discipline [\\[129\\]](#page-42-35).\
    \ With the help of distributed computing and virtualization, customers may set\
    \ up automatically managed VMs and cloud services for their initiatives and applications.\
    \ Thanks to cloud services, teams working on software may now more easily collaborate\
    \ on the development, testing, and distribution of their products. Here are some\
    \ scenarios in which cloud computing might improve software engineering: The production\
    \ timeline can be compressed [\\[130\\]](#page-42-36). As a result of the availability\
    \ of ample computing resources made possible by cloud computing and virtualization,\
    \ software engineers no longer need to rely just on a single physical computer.\
    \ The time it takes to install the required applications may be decreased by retrieving\
    \ cloud services, indicating that development activities can be performed with\
    \ increased parallelism thanks to cloud computing. Third, VMs and cloud instances\
    \ may substantially improve the setup and delivery procedures.\n\nUsing sufficient\
    \ virtualization resources from a private or public cloud, developers can speed\
    \ up the building and testing process, which is otherwise, extremely timeconsuming\
    \ [\\[123\\]](#page-42-29). To circumvent this, a simplified system for managing\
    \ code versions is required. In software development, code branches are used for\
    \ refining and adding features. With cloud computing, there's no need to invest\
    \ in or lease expensive hardware only to store some code. A distributed software\
    \ engineering team may access apps more easily in a cloud setting, and service\
    \ quality can be enhanced through dynamic resource allocation. As a result, the\
    \ software construction process is streamlined thanks to cloud computing, which\
    \ eliminates the need for development servers to rely on specific physical computers\
    \ [\\[129\\]](#page-42-35). Nevertheless, there are obstacles when merging software\
    \ engineering and cloud computing. The majority of the difficulties are with moving\
    \ the data. Because different cloud providers use various APIs to offer cloud\
    \ services, migrating software and data from one cloud to another while avoiding\
    \ vendor lock-in is challenging. Avoiding over-reliance on any one set of APIs\
    \ is one way to fix this problem while building and releasing applications in\
    \ the cloud. The problem of dependability and accessibility is another obstacle.\
    \ If everything is moved to the cloud, it will be difficult to retrieve the data\
    \ if the cloud is compromised by hackers or affected by an unexpected calamity.\
    \ The engineering teams are responsible for creating a local backup of their work\
    \ [\\[131\\]](#page-42-37).\n\nCloud computing allows software engineering academics\
    \ to study multinational software development. Several investigations have examined\
    \ the feasibility of using cloud computing to lower operational, delivery, and\
    \ software development expenses. Researchers have investigated the feasibility\
    \ of replacing services with a cloud-based platform for student-to-student knowledge\
    \ exchange and collaboration [\\[132\\]](#page-42-38). Software systems have been\
    \ supplanted by systems running on the cloud to reduce expenditures and maximize\
    \ the utilization of resources. The conventional data management techniques have\
    \ become increasingly cumbersome in the past few years due to the rapid increase\
    \ in available data. A new frontier for study in software engineering has opened\
    \ up thanks to the IoT, Blockchain (the distributed ledger), and ML/AI, with data\
    \ management being the primary challenge [\\[133\\]](#page-42-39). These studies\
    \ also provide a springboard for further study and innovative approaches to cloud\
    \ data management, leading to the development of advanced technologies like Cisco's\
    \ pioneering fog computing [\\[134\\]](#page-42-40). Enterprise software developers\
    \ are creating an abstraction\n\nlayer, or \"Blockchain-as-a-Service\", and selling\
    \ it to other businesses as a subscription service [\\[4\\]](#page-40-2). These\
    \ numerous new fields rely significantly on software engineering, yet they could\
    \ not exist without it.\n\n#### 4.2.1.3.2. Simulations\n\nThe capacity to carry\
    \ out research, analyze strengths and shortcomings, and demonstrate viability\
    \ is hampered in new or emerging computing domains due to the lack of mature technology\
    \ and sufficient infrastructure. In many cases, the time and resources needed\
    \ to acquire the necessary physical resources make it impractical to conduct the\
    \ necessary research [\\[79\\]](#page-41-28). An alternative approach that can\
    \ approximate a physical environment is a simulator. Additionally, simulation\
    \ offers the ability to test suggested hypotheses in lightweight and low-cost\
    \ settings. Real-world testing of novel methods is difficult and expensive because\
    \ of the time and effort required to gather the necessary hardware resources (particularly\
    \ for large-scale tests) and create the necessary software applications and systems\
    \ [\\[135\\]](#page-42-41). Investigators demonstrate the viability of their ideas\
    \ by modelling and simulation, and then conduct tests to confirm their concepts\
    \ in a monitored environment utilizing simulation tools. Simulation software provides\
    \ a convenient setting for testing solutions to real-world issues by allowing\
    \ users to experiment and see what happens [\\[136\\]](#page-42-42). If a commercially\
    \ available simulator is inadequate for user needs, then researchers should consider\
    \ building their own, complete with graphical user interfaces. This is especially\
    \ true if users need to simulate components of emerging computer architectures\
    \ [\\[137\\]](#page-42-43). Researchers could benefit greatly from using a simulator\
    \ to formulate questions and analyze different theoretical frameworks in simulated\
    \ setups, therefore stimulating more research and fostering the development of\
    \ communities within the relevant field.\n\n#### *4.2.2. Specialized Computing*\n\
    \nIn this section, we discuss the main focus or paradigms, technologies or impact\
    \ areas, and various trends or observations within specialized computing.\n\n\
    ## *4.2.2.1. Focus/Paradigms*\n\nThe following are the main focus or paradigms\
    \ for Specialized Computing:\n\n#### 4.2.2.1.1. Reconfigurable Computing\n\nThe\
    \ modern paradigm of reconfigurable computing enables hardware components to swiftly\
    \ alter their configuration and functioning in response to changing processing\
    \ needs. Reconfigurable computer devices, such as Field-Programmable Gate Arrays\
    \ (FPGAs), can be reprogrammed to perform a variety of different functions [\\\
    [138\\]](#page-42-44). The main function of reconfigurable computing is to fill\
    \ the void among generalpurpose CPUs and Application-Specific Integrated Circuits\
    \ (ASICs) [\\[19\\]](#page-40-17). It allows hardware to be optimized for efficiency,\
    \ power efficiency, and flexibility by matching application requirements. Static\
    \ and dynamic switching are the two primary modes of operation for reconfigurable\
    \ technology. In static reconfiguration, the component settings are adjusted prior\
    \ to the computer starting to compute. However, dynamic reconfiguration permits\
    \ hardware changes to be made while the system is running, allowing for dynamic\
    \ modifications to hardware behavior.\n\n## 4.2.2.1.2. Domain-Specific Architectures\n\
    \nAs computing and the digital transformation spread to various use cases, such\
    \ as cloud (AI/HPC), networking, edge, the IoT, and self-driving cars, highly\
    \ domain-specific computational tasks are making it more likely that Domain-Specific\
    \ Architectures (DSAs) can enable big performance gains [\\[139\\]](#page-43-0).\
    \ Using ChatGPT and other comparable software that are powered by large language\
    \ models–—which are fundamental to achieving generative AI–—provides greater specialization\
    \ inside AI workloads at extremely high volume, which motivates further hardware\
    \ specialization [\\[81\\]](#page-41-30). DSAs, or application-domain-specific\
    \ hardware and software, have substantial market potential. As a result of their\
    \ superior performance on tasks that profit from a significant amount of parallel\
    \ computing, such as AI workloads (learning and predicting), GPUs and Tensor Processing\
    \ Units (TPUs) are currently controlling a sizable portion of the data center\
    \ market [\\[140\\]](#page-43-1). Meanwhile, accelerations of 15–50 times the\
    \ original speed, depending on the workload, are not uncommon. In the automobile\
    \ industry, minimal latency and high-performance inference are provided via tailor-made\
    \ solutions from industry leaders.\n\n#### 4.2.2.1.3. Exascale Computing\n\nTo\
    \ handle the massive computations required by convergent modelling, simulation,\
    \ AI, and data analysis, an entirely novel type of supercomputer called exascale\
    \ computing has emerged [\\[2\\]](#page-40-0). This is motivated by advanced computational\
    \ needs in science and engineering.\n\nExascale computing (also supercomputing)\
    \ becomes essential to expedite the generation of knowledge. Researchers and technologists\
    \ may employ data analysis driven by exascale supercomputing to expand the frontiers\
    \ of our existing understanding and promote breakthrough ideas. Supercomputing\
    \ capabilities are in high demand as the world moves towards exascale computing\
    \ to ensure continued scientific and technological advancements, while our civilization's\
    \ technological and scientific frameworks are progressing quickly thanks to exascale\
    \ computing [\\[141\\]](#page-43-2). The immense potential of these tools necessitates\
    \ their careful operation, especially as cultures worldwide undergo rapid changes\
    \ in their moral frameworks and their perceptions of what it means to live sustainably.\
    \ As such, novel responses to formerly intractable issues are being uncovered\
    \ thanks to exascale computing.\n\nExascale supercomputers are prohibitively expensive\
    \ to construct; thus academics and scientists rely on funding to lease them instead\
    \ of buying their own [\\[142\\]](#page-43-3). Exascale computing systems produce\
    \ enormous quantities of heat because of the volume of data they process. They\
    \ require extremely cold environments to be stored in or unique cooling mechanisms\
    \ built into the systems and racks themselves for optimal performance. Differentiating\
    \ them from other types of supercomputers and quantum computers, they are computer\
    \ systems with the largest capacity and most powerful hardware [\\[143\\]](#page-43-4).\n\
    \nTo further our understanding of the universe, exascale computers can model elementary\
    \ physical processes like the granular interactions of atoms. Quite a few sectors\
    \ rely on this capacity to analyze, forecast, and construct the world of tomorrow:\
    \ for instance, better predict the weather, investigate in detail the interaction\
    \ between rain, wind, clouds, and various other atmospheric occurrences, analyze\
    \ their effects on one another at a molecular level and so on. Mathematical formulas\
    \ can be used to determine the millisecond-bymillisecond effects of all forces\
    \ acting in a certain environment at a specific time [\\[144\\]](#page-43-5).\
    \ These seemingly trivial interactions rapidly generate billions of possible permutations,\
    \ which need trillions of mathematical equations to calculate and analyze. This\
    \ kind of speed is only achievable on an exascale machine. By studying the results\
    \ of these computations, researchers can gain a deeper insight into the nature\
    \ of our universe [\\[143\\]](#page-43-4). Exascale supercomputers, despite their\
    \ challenges, can literally increase our understanding, enabling us to address\
    \ the problems of the future.\n\n4.2.2.1.4. Analog Computing\n\nA novel approach\
    \ may minimize errors in ultra-fast analog optical neural networks. Larger and\
    \ more complicated machine-learning models need stronger and more effective computing\
    \ gear. However, standard digital computers are lagging. Compared to a digital\
    \ neural network, an analog optical network's performance in areas like image\
    \ classification and voice recognition is comparable. However, its speed and energy\
    \ efficiency far exceed those of its digital counterparts [\\[145\\]](#page-43-6).\
    \ Nevertheless, hardware faults in these analog devices might impact the accuracy\
    \ of calculations. One possible source of this inaccuracy is microscopic flaws\
    \ in the hardware itself [\\[146\\]](#page-43-7). Errors tend to multiply rapidly\
    \ in a complex optical neural network. Even when using errorcorrection approaches,\
    \ due to the basic features of the components that make up an optical neural network,\
    \ a certain degree of error is inescapable [\\[147\\]](#page-43-8). Conversely,\
    \ the optical switches that make up the network's architecture can reduce mistakes\
    \ they typically accrue by adding a modest hardware component.\n\n#### 4.2.2.1.5.\
    \ Neuromorphic Computing\n\nWhen applied to AI, neuromorphic computing makes it\
    \ possible for AI to learn and make decisions independently, significantly improving\
    \ over the first generation of developing AI. To acquire abilities in areas like\
    \ recognizing voice and sophisticated tactical games, including chess and Go,\
    \ neuromorphic algorithms are now involved in deep learning [\\[145\\]](#page-43-6).\n\
    \nNext-generation AI will imitate the human brain's capacity to comprehend and\
    \ react to circumstances instead of merely operating from formulaic algorithms\
    \ [\\[148\\]](#page-43-9). When it comes to understanding what they've read, neuromorphic\
    \ computing systems will seek out patterns and use their 'common sense' and the\
    \ surrounding context. When Google's Deep Dream AI was programmed to hunt for\
    \ dog faces, it notably showed the limitations of algorithm-only computer systems\
    \ [\\[147\\]](#page-43-8): Any images that it interpreted as having dog faces\
    \ were transformed into dog faces.\n\nThird-generation AI computing attempts to\
    \ simulate the elaborate structure of a living brain's neural network [\\[149\\\
    ]](#page-43-10). This calls for AI with computing and analytic capabilities on\
    \ par with the extremely efficient biological brain. To demonstrate their exceptional\
    \ energy economy, human brains can surpass supercomputers using less than 20 watts\
    \ of electricity. Spiking Neural Networks (SNN) are the AI equivalent of our synaptic\
    \ neural network [\\[150\\]](#page-43-11). They leverage many layers of artificial\
    \ neurons, and each spiking neuron may fire and interact with its neighbors in\
    \ response to external inputs.\n\nMost AI neural network architectures follow\
    \ the Von Neumann design [\\[106\\]](#page-42-12), which divides the memory and\
    \ computation into discrete nodes. Computers exchange information by reading it\
    \ from memory, sending it to the CPU for processing, and then returning it to\
    \ storage. This constant back-and-forth wastes a lot of time and effort. It causes\
    \ a slowdown that becomes more noticeable while processing huge data sets. As\
    \ a response, multiple neuromorphic devices can be utilized to supplement and\
    \ improve the performance of traditional technologies, such as CPUs, GPUs, and\
    \ FPGAs [\\[146\\]](#page-43-7). Low-power neurological systems may perform powerful\
    \ activities, including learning, browsing, and monitoring. A practical instance\
    \ would involve immediate voice recognition on mobile phones without the CPU needing\
    \ to interact with the cloud.\n\n## *4.2.2.2. Technologies/Impact Areas*\n\nThe\
    \ key technologies and affected domains for Specialized Computing include:\n\n\
    *1) Graphics Processing Unit (GPU)*: GPUs have rapidly risen in prominence as\
    \ a crucial component of both home and enterprise computers [\\[18\\]](#page-40-16).\
    \ A GPU is a special type of computer chip deployed in a variety of application\
    \ domains, most notably the rendering of moving images. While GPUs are best recognized\
    \ for their usage in gaming, they are also finding increasing application in the\
    \ fields of creative creation and AI [\\[151\\]](#page-43-12). The initial purpose\
    \ of GPUs was to speed up the display of 3D visuals. They improved their functionality\
    \ as they got more adaptable and programmable over time. This paved the way for\
    \ more complex lighting and shadow characteristics and photorealistic environments\
    \ to be implemented by graphics developers. Additional engineers started using\
    \ GPUs to drastically speed up various tasks in deep learning, HPC, and other\
    \ fields [\\[138\\]](#page-42-44).\n\n*2) Compute Unified Device Architecture\
    \ (CUDA)*: The demand for more powerful computers grows daily. As a result of\
    \ constraints like size, climate, etc., vendors throughout the world are finding\
    \ it difficult to make future improvements to CPUs [\\[18\\]](#page-40-16). Service\
    \ providers that provide solutions in this kind of environment have begun to seek\
    \ out performance improvements elsewhere. The use of GPUs for parallel processing\
    \ is one option that enables significant speed gains [\\[152\\]](#page-43-13).\
    \ The total number of cores in a GPU is significantly greater than that of a CPU.\
    \ Although CPUs are designed for sequential processing, offloading them to GPUs\
    \ enables parallel processing. For general-purpose computing on NVIDIA's GPUs,\
    \ users can rely on CUDA, which allows for the execution of processes in parallel\
    \ on the GPU without any specific order requirement [\\[138\\]](#page-42-44).\
    \ Offloading compute-intensive activities to Nvidia's GPU using CUDA is straightforward\
    \ thanks to the library's support for the popular C, C++, and Fortran programming\
    \ languages [\\[152\\]](#page-43-13). CUDA is employed in scenarios needing extensive\
    \ computational power or suitable for parallel processing to achieve high performance.\
    \ Fields such as AI, healthcare analysis, science, digital transformation, cryptocurrency\
    \ mining, and scientific modeling, among others, depend on CUDA technology.\n\n\
    #### *4.2.2.3. Trends/Observations*\n\nThe main trends and observations regarding\
    \ Specialized Computing are as follows:\n\n*Large-Scale ML*: As big data grows,\
    \ ML algorithms with many variables are needed to ensure that these models can\
    \ handle very large data sets and make accurate predictions, including hidden\
    \ features with many dimensions, middle representations, and selection functions\
    \ [\\[153\\]](#page-43-14). The need for ML systems to train complicated models\
    \ with millions to trillions of variables has increased as a result [\\[154\\\
    ]](#page-43-15). Distributed clusters of tens to hundreds of devices are often\
    \ used for ML systems because they can handle the high computing needs of ML algorithms\
    \ at these sizes. Yet, developing algorithms and software systems for these distributed\
    \ clusters requires intensive analysis and design [\\[155\\]](#page-43-16). The\
    \ latest advances in industrial-scale ML have focused on exploring new concepts\
    \ and approaches for (a) highly specialized monolithic concepts for large-scale\
    \ straight applications, such as different distributed topic models or regression\
    \ models, and (b) for adaptable and readily programmable universally applicable\
    \ distributed ML platforms such as GraphLab based on vertex programming and Petuum\
    \ using a parameter-driven server [\\[156\\]](#page-43-17). It is widely acknowledged\
    \ that knowledge of distributed system topologies and programming is essential;\
    \ however, ML-rooted statistical and algorithmic discoveries can yield even more\
    \ fruit for large-scale ML systems in the form of principles and techniques specific\
    \ to distributed machine learning applications. These guidelines and techniques\
    \ shed light on several crucial questions:\n\n- How to share an ML application\
    \ among nodes?\n- How to connect machine-learning calculations with machine-to-machine\
    \ dialog?\n- How should one proceed with having such a conversation?\n- What ought\
    \ to be conveyed among machines? And, should they cover many big ML-related topics,\
    \ from practical use cases to technical implementations to theoretical investigations\
    \ [\\[98\\]](#page-42-4)?\n\nUnderstanding how these concepts and tactics may\
    \ be made effective, generally applicable, and easy to develop is the primary\
    \ goal of large-scale ML systems studies, as is ensuring that scientifically validated\
    \ accuracy and scalability assurances underpin them.\n\n## **4.3. Centralized\
    \ vs. Decentralized Computing**\n\nA central server controls and processes most\
    \ of the data in a centralized network, whereas no single entity has influence\
    \ over a decentralized network.\n\n## *4.3.1. Centralized Computing*\n\nIn this\
    \ section, we discuss the main focus or paradigms, technologies or impact areas,\
    \ and various trends or observations within centralized computing.\n\n# *4.3.1.1.\
    \ Focus/Paradigms*\n\nThe following are the main focus or paradigms for centralized\
    \ computing:\n\n*1) Cloud Computing*: The adoption of cloud computing, which revolutionized\
    \ how end-users and software engineers interact with applications and computing\
    \ systems, led to the rise of technology as the fifth utility [\\[1\\]](#page-39-0).\
    \ Cloud computing was successfully accepted by giving consumers on-demand access\
    \ to the computing power they want, the freedom to modify their resource consumption\
    \ as needed, and the transparency of paying just whatever is being utilized. Business\
    \ groups, regulatory bodies, and universities have all been quick to endorse it\
    \ since it first appeared. Like contemporary society relying on essential utilities,\
    \ the cloud has grown into the economy's foundation by providing immediate utilization\
    \ of subscription-driven computing resources [\\[157\\]](#page-43-18). As a result\
    \ of using cloud technology, innovative companies can be launched quickly, existing\
    \ ones can expand globally, advances in science can be sped up, and novel computing\
    \ methods can be developed for ubiquitous and pervasive apps [\\[34\\]](#page-40-32).\
    \ SaaS, PaaS, and IaaS have served as the three primary service models that have\
    \ pushed uptake in the cloud thus far [\\[35\\]](#page-40-33).\n\n• *Mobile Cloud\
    \ Computing*: To provide value to mobility consumers, network operators, and cloud\
    \ service providers, mobile cloud computing integrates mobile devices, cloud computing,\
    \ and communication networks. With the help of mobile cloud computing, a wide\
    \ variety of handheld gadgets can run complex mobile apps. Under this paradigm,\
    \ handling and storing data is done by servers rather than individual mobile devices\
    \ [\\[32\\]](#page-40-30). Several advantages result from the use of mobile cloud\
    \ computing apps based on this architecture: (i) battery life has significantly\
    \ increased; (ii) there has been an increase in both the speed and size of data\
    \ being stored and processed; (iii) the system's emphasis on \"store once, access\
    \ anywhere\" eliminates complex data synchronization; and (iv) stability and scalability\
    \ have been dramatically enhanced. Nevertheless, inadequate network capacity is\
    \ a significant challenge for mobile cloud computing [\\[33\\]](#page-40-31).\
    \ Wireless mobile cloud services have capacity constraints in contrast to their\
    \ cable counterparts. The spectrum of mobile devices offers a wide range of wavelengths.\
    \ This has resulted in slower access speeds, as much as one-third in comparison\
    \ to a wired network. Due to the increased likelihood of data loss on a wireless\
    \ network, it is more challenging to recognize and deal with security risks on\
    \ mobile devices than on desktop computers [\\[158\\]](#page-43-19). Customers\
    \ frequently report issues with accessibility to services, including network outages,\
    \ overcrowding on public transit, lack of coverage, etc. Customers may occasionally\
    \ experience a low-energy signal, which slows down access and impacts data storage.\
    \ Mobile cloud computing is employed on several OS-driven platforms, including\
    \ Apple iOS, Android, and Windows Phone, resulting in network modifications that\
    \ need cross-platform compatibility [\\[159\\]](#page-43-20). Mobile gadgets have\
    \ a greater environmental impact due to their high energy consumption and low\
    \ output [\\[60\\]](#page-41-9). As the use of mobile cloud computing grows, so\
    \ does the problem of the increased drain on mobile devices' batteries. A device's\
    \ battery life is crucial for using its software and executing other tasks. Although\
    \ the modified code is tiny in size, offloading uses more energy than running\
    \ it locally [\\[160\\]](#page-43-21).\n\n• *Green Cloud Computing*: In the last\
    \ few decades, Information and Communication Technology (ICT) has significantly\
    \ evolved, drawing on technological advancements from the past two centuries.\
    \ This evolution has elevated computing to the status of a fundamental service,\
    \ akin to traditional utilities such as water, electricity, gas, and telephony,\
    \ thereby establishing it as the fifth essential utility in modern society [\\\
    [161\\]](#page-43-22). Modern cloud computing systems are becoming progressively\
    \ large-scale and dispersed as more and more businesses and organizations have\
    \ shifted their computing workload to the cloud—while others opt out of maintaining\
    \ code altogether and instead leverage cloud-powered SaaS services. A cloud computing\
    \ infrastructure of this magnitude not only offers more affordable and dependable\
    \ services but also, increases energy effectiveness and reduces the global community's\
    \ carbon impact [\\[162\\]](#page-43-23). Every minor enhancement is much appreciated.\
    \ In an effort to achieve zero carbon emissions, the community has recently been\
    \ aggressively exploring a more sustainable version of cloud computing called\
    \ green cloud computing to lessen reliance on fossil fuels and curb its carbon\
    \ footprint [\\[163\\]](#page-43-24).\n\nGreen cloud computing is a system that\
    \ considers its constraints and goals to minimize energy consumption. Researchers\
    \ are focusing on scheduling workloads and resources in light of carbon emissions,\
    \ in order to increase the effectiveness of the resources used [\\[164\\]](#page-43-25).\
    \ Additionally, forecasting problems with hardware and creating management systems\
    \ to use hardware with varying degrees of dependability can maximize device lifetime\
    \ and reuse. Further, utilizing micro-data centers—rather than standard server\
    \ data centers—is a promising approach to boost efficiency and save costs. These\
    \ facilities can accommodate future growth, serve huge populations, and dissipate\
    \ heat effectively [\\[165\\]](#page-43-26).\n\nFurthermore, virtualization is\
    \ another ecologically friendly technique that boosts the versatility of system\
    \ resources. Through improved tracking and control, servers may pool their resources\
    \ more effectively [\\[166\\]](#page-43-27). Innovations and practices that support\
    \ sustainable development are constantly being developed as organisations rely\
    \ more heavily on cloud services to enable \"green cloud computing\".\n\n####\
    \ *4.3.1.2. Technologies/Impact Areas*\n\nThe key technologies and affected domains\
    \ for centralized computing include:\n\n*1) Cloud Storage Technologies*: Files\
    \ and information stored in the cloud may be accessed from anywhere with a web\
    \ connection or via secure network access. Transferring files to the cloud puts\
    \ the responsibility for data security squarely on the shoulders of the cloud\
    \ provider, rather than consumers. The service provider hosts, manages, and maintains\
    \ the servers where user data is stored, and they also guarantee that users always\
    \ have access to their files [\\[167\\]](#page-43-28). When compared to storing\
    \ data on local discs or storage networks, cloud-based storage is a more affordable\
    \ and scalable option. There is a limit to the quantity of information that can\
    \ be stored on a hard disc. When users exhaust internal storage space, they must\
    \ copy their data to removable media. The difference between on-premises storage\
    \ networks and cloud storage is that the latter sends data to servers located\
    \ in a remote data centre. VMs, which are abstracted on top of an actual server,\
    \ make up the vast majority of users' servers [\\[168\\]](#page-43-29). Known\
    \ as autoscaling, a cloud provider spins up more virtual servers as necessary\
    \ to accommodate users' ever-increasing storage demands. Files, blocks, and objects\
    \ are the three primary categories of cloud storage, which are accessible in private,\
    \ public, and hybrid cloud configurations.\n\n*2) Microservices*: Microservices\
    \ are a type of application architecture in which several autonomous services\
    \ collaborate using simple APIs. A cloud-native software development method, microservice\
    \ architecture separates an app's main functionality into its own modules [\\\
    [169\\]](#page-43-30). By compartmentalizing the app's components, the development\
    \ and operations teams may collaborate without interfering with each other. If\
    \ several engineers can collaborate on the same project simultaneously, it takes\
    \ less time to complete. This is in contrast with the monolith software architecture,\
    \ which had been the standard for application development in the past [\\[170\\\
    ]](#page-43-31). All of an app's features and services are tightly bound together\
    \ and run as one seamless whole under a monolithic architecture [\\[171\\]](#page-43-32).\
    \ The application's architecture becomes more involved whenever new features are\
    \ introduced, or existing ones enhanced. Because of this, optimizing a single\
    \ feature inside the application requires disassembling the whole thing, which\
    \ is a time-consuming and tedious process. This additionally necessitates that\
    \ scaling the application as a whole is required if scaling any one process inside\
    \ it—rather than just scaling out just that overloaded element [\\[172\\]](#page-43-33).\
    \ Microservice architectures separate an app's essential features into individual\
    \ processes. To adapt to shifting business requirements, software engineering\
    \ teams may develop and maintain new elements independently of the rest of the\
    \ application. The monolith has been the standard for application development\
    \ in the past. An application's features and services are tightly bound together\
    \ and run seamlessly under a monolithic architecture [\\[173\\]](#page-43-34).\
    \ Microservices' malleability might hasten the deployment of novel modifications,\
    \ necessitating the development of novel patterns. In software engineering, a\
    \ \"pattern\" is supposed to refer to any mathematical approach that is known\
    \ to function. An \"anti-pattern\" is an erroneous pattern that is often applied\
    \ to achieve a solution but often ends up causing even more problems.\n\n*3) Container\
    \ Technologies*: Given the advent of Docker, container technology has gained widespread\
    \ use in the cloud computing sector, where it is used to efficiently execute user\
    \ workloads [\\[174\\]](#page-43-35). Since containers are independent entities\
    \ that may run without sharing data with other containers, this technology provides\
    \ an inexpensive cloud environment for deploying applications. In a container,\
    \ applications deployed on the same hardware server can share the same underlying\
    \ resources while maintaining their own distinct processes [\\[175\\]](#page-43-36).\
    \ Container technology leverages Linux kernel capabilities, such as libcontainer\
    \ and control groups (cgroups). By utilizing cgroups and namespaces, Docker can\
    \ operate containers independently within a host node, providing the container\
    \ with its own dedicated set of runtime resources (including the host's networked\
    \ devices, disc space, memory, and CPU). In addition, namespaces provide for more\
    \ efficient application deployment and development by separating the program's\
    \ perspective from the operating environment [\\[176\\]](#page-43-37). Furthermore,\
    \ containerization becomes an example of creating, publishing, and running applications\
    \ in an isolated way and is indicated as a Container as a Service (CaaS). There\
    \ are three primary advantages of CaaS: (1) containers boot up in no time at all;\
    \ (2) they consume fewer resources than VMs; and (3) many instances may be operated\
    \ at once using container technology [\\[177\\]](#page-43-38). Recent investigations\
    \ [\\[178\\]](#page-43-39) into container technology reveal unanswered research\
    \ questions. Firstly, containers are less secure than VMs since they share the\
    \ kernel, but this is something that may be fixed in future versions with the\
    \ help of Unikernel. Secondly, optimizing container performance is a time-consuming\
    \ endeavor that requires buffer space. Swarm and Kubernetes are two examples of\
    \ cutting-edge cloud computing tools that may be used for handling user-created\
    \ QoS-based container clusters [\\[179,](#page-43-40) [180\\]](#page-43-41). Thirdly,\
    \ because containers share the same computing/hardware resources, co-located tenants\
    \ can suffer from unpredictable performance interference when the CPU Shares algorithm\
    \ is used, and even worse, they can leak information enabling side-channel attacks\
    \ to be performed by a malicious tenant [\\[181\\]](#page-43-42).\n\n*4) Serverless\
    \ Computing*: The use of serverless computing in the creation of apps for the\
    \ cloud is gaining traction [\\[182\\]](#page-44-0). The goal of serverless computing\
    \ is to ensure that only the most effective serverless technologies are deployed,\
    \ reducing costs while increasing benefits [\\[183\\]](#page-44-1). Meanwhile,\
    \ companies in all industries are adopting AI since it is the next generation\
    \ of innovation. Due to these AI-driven platforms, we've been able to make more\
    \ accurate, timely decisions [\\[184\\]](#page-44-2). They have altered the methods\
    \ used to conduct business, communicate with customers, and assess company information.\
    \ Complex ML systems can significantly affect developers' output and efficiency\
    \ [\\[185\\]](#page-44-3). However, switching to a serverless architecture may\
    \ be able to solve many of the issues that engineers face. The serverless design\
    \ ensures that the machine learning models are administered correctly and that\
    \ all available resources are utilized efficiently. Developers will be able to\
    \ devote a greater amount of time to training AI models rather than maintaining\
    \ the server environment [\\[186\\]](#page-44-4). Creating ML algorithms is a\
    \ common practice when confronting difficult problems. They perform tasks such\
    \ as data analysis and preprocessing, model training, and AI model tuning [\\\
    [186\\]](#page-44-4). Serverless computing running AI tasks will provide for reliable\
    \ data storage and communication.\n\n#### *4.3.1.3. Trends/Observations*\n\nThe\
    \ main trends and observations regarding centralized computing are as follows:\n\
    \n*1) AI-driven Computing*: The fundamental benefit of autonomic computing is\
    \ a reduced overall cost of ownership. Therefore, the cost of upkeep will be drastically\
    \ reduced. The number of technicians required to keep everything running smoothly\
    \ will go down as a result, too. Autonomous IT systems driven by AI will reduce\
    \ the time and money needed for installation and upkeep while also improving IT\
    \ system stability [\\[4\\]](#page-40-2). In accordance with higher-order benefits,\
    \ businesses would be more capable of handling their operations with the help\
    \ of IT systems that are able to adopt and execute directions based on their business\
    \ plan and allow for adjustments in reaction to evolving circumstances. Using\
    \ AI-based autonomic computing has several advantages, including reducing the\
    \ expense and quantity of human labor needed to manage large server farms, which\
    \ is made possible through server consolidation [\\[187\\]](#page-44-5). Using\
    \ AI for self-driving computers will simplify system administration. As a result,\
    \ computer systems will be greatly enhanced. Server load distribution is another\
    \ potential use case since it allows for parallel data processing across several\
    \ computers. Meanwhile from an energy perspective, analyzing the power grid in\
    \ real-time allows for more cost-effective and long-term power policy decisions\
    \ to be made [\\[1\\]](#page-39-0). There are benefits to using remote data centers\
    \ instead of keeping data in-house. Despite the hefty upfront expenses, businesses\
    \ may obtain AI technology relatively easily by paying a monthly fee on the cloud.\
    \ When employing an AI-powered system, there may be no need for human involvement\
    \ in data analysis [\\[188\\]](#page-44-6). Using AI in the cloud can potentially\
    \ make businesses more effective, strategic, and insight-driven. AI can increase\
    \ output by automating routine processes and data analysis without human intervention\
    \ [\\[74\\]](#page-41-23). For instance, integrating AI technology with Google\
    \ Cloud Stream statistics could enable real-time personalization, anomaly detection,\
    \ and management scenario prediction [\\[189\\]](#page-44-7). As the number of\
    \ cloud-based applications grows, it is essential to implement a system of rigorous\
    \ data protection based on intelligence. Network security systems backed by AI-enabled\
    \ traffic tracing and analysis; AI-enabled devices can sound an alarm as soon\
    \ as an anomaly is detected. Such methods will ensure keeping sensitive data protected.\n\
    \n*2)* Net Zero Emissions: Several data center operators have committed to being\
    \ carbon neutral by the year 2030 as sustainability becomes an increasingly hot\
    \ subject in the industry [\\[190\\]](#page-44-8). But are these promises only\
    \ a reaction to the possibility of legislation, or is it actually making progress?\
    \ If business planes are a major contributor to global warming, how do they plan\
    \ to cut their carbon footprint so rapidly? The data centers' businesses in the\
    \ United States use about as much power as the state of New Jersey [\\[191\\]](#page-44-9).\
    \ If all of the power came from renewable resources, this level of demand would\
    \ not be a problem. Liquid cooling and energy generation both require water, and\
    \ a typical data centre uses as much water as an urban area of 30,000 to 50,000\
    \ individuals [\\[192\\]](#page-44-10). Becoming a pioneer in sustainability might\
    \ also bring up emerging markets. Companies are going to utilize green data centers\
    \ to offset their carbon footprints as they grow and become more energy efficient\
    \ and sustainable [\\[193\\]](#page-44-11). A car company, for instance, might\
    \ employ emission-free data centers for all of its corporate services. Last but\
    \ not least, adopting environmentally friendly practices may help businesses comply\
    \ with environmental rules, avoid fines, and get access to attractive, low-interest,\
    \ long-term capital investment possibilities [\\[194\\]](#page-44-12).\n\n####\
    \ *4.3.2. Decentralized Computing*\n\nIn this section, we discuss the main focus\
    \ or paradigms, technologies or impact areas, and various trends or observations\
    \ within decentralized computing.\n\n#### *4.3.2.1. Focus/Paradigms*\n\nThe following\
    \ are the main focus or paradigms for decentralized computing:\n\n*1) Parallel\
    \ Computing*: Through the utilization of several processor cores, parallel computing\
    \ can perform multiple tasks simultaneously. The ability to divide and conquer\
    \ a work into smaller, more manageable chunks is what sets parallel computing\
    \ apart from its serial counterpart [\\[195\\]](#page-44-13). Real-world events\
    \ may be modelled and simulated effectively on parallel computing systems [\\\
    [196\\]](#page-44-14). As processing and network speeds continue to increase at\
    \ an exponential rate, adopting a parallel architecture is no longer just a nice-to-have.\
    \ The IoT and big data will eventually require us to process terabytes of data\
    \ simultaneously. Devices such as dual-core, quad-core, eight-core, and even 56-core\
    \ CPUs utilize parallel computing. Therefore, although parallel computers are\
    \ not brand new, this is the problem: These new technologies are spitting up ever-faster\
    \ networks, and computer efficiency has surged 250,000 times in 20 years [\\[197\\\
    ]](#page-44-15). For instance, AI technologies will sift through more than 100\
    \ million patients' heart rhythms in the medical sector alone, looking for signals\
    \ of A-fib or V-tach, saving many lives in the process [\\[196\\]](#page-44-14).\
    \ When the systems must slowly move through each procedure, they will not be able\
    \ to complete it on time. As great as the potential is, parallel computing may\
    \ be nearing the edge of what it can achieve with conventional processors. Parallel\
    \ calculations may see significant improvements in the coming decade, thanks to\
    \ quantum computers. In a current, unauthorized announcement, Google claimed to\
    \ have achieved *quantum supremacy* [\\[76,](#page-41-25) [198\\]](#page-44-16).\
    \ If it is accurate, then Google has created a machine that can perform in 4 minutes\
    \ whatever would require the most capable supercomputer on the planet 10,000 years\
    \ to achieve [\\[51\\]](#page-41-0). Quantum computing is a major step forward\
    \ for parallel computation. Imagine it like this: Processing in a serial fashion\
    \ does one task at a time. An 8-core simultaneous computer can do eight tasks\
    \ simultaneously. There are fewer particles in the universe than there are qubits'\
    \ states in a 300-qubit quantum computer [\\[198\\]](#page-44-16).\n\n*2) Fog\
    \ Computing*: The proliferation of IoT devices and the effort needed for analyzing\
    \ and storing enormous amounts of knowledge led to the development of fog computing\
    \ as a complementary service to traditional cloud computing. Fog computing, which\
    \ provides fundamental network functions, can back IoT apps that require a small\
    \ response-time window [\\[37\\]](#page-40-35). Due to the dispersed, diverse,\
    \ and constrained nature of the fog computing paradigm, it is challenging to spread\
    \ IoT application operations effectively within fog nodes to meet QoS and Quality\
    \ of Experience (QoE) limitations [\\[39\\]](#page-40-37). Vehicle-to-Everything\
    \ (V2X), medical tracking, and manufacturing automation adopt fog computing as\
    \ it delivers the ability to compute close to the consumer to match fast response\
    \ demands for these applications. Due to the proliferation of IoT devices, these\
    \ applications generate massive volumes of data. Cloud computing falls short of\
    \ satisfying latency demands due to the transmission of data over long distances\
    \ and network overload. Bridging data sources and CDCs, it sets up a network of\
    \ gateways, routers, switches, and compute resources [\\[199\\]](#page-44-17).\
    \ The use of fog computing enhances the capabilities of cloud computing due to\
    \ its minimal latency and cost-effectiveness, as well as the decrease in bandwidth\
    \ necessary for the transit of data. It is more secure to process confidential\
    \ information locally at the fog nodes, and if/when needed, only submit trained\
    \ models—not raw data—to intermediate nodes and eventually the cloud for aggregation,\
    \ e.g., via federated learning [\\[200\\]](#page-44-18). These applications collect\
    \ data from various IoT devices to deliver useful insights and deal with latency\
    \ issues [\\[201\\]](#page-44-19).\n\n*3) P2P Network*: This network is formed\
    \ in its most basic form when two or more PCs are linked to one another and exchange\
    \ resources without passing through a third computer that acts as a server [\\\
    [23\\]](#page-40-21). A P2P network might be a spontaneous connection, which would\
    \ consist of two or more computers linked together using a Universal Serial Bus\
    \ for the purpose of file sharing. In a fixed infrastructure, P2P networking utilizes\
    \ copper lines to connect six PCs located in a single workplace [\\[24\\]](#page-40-22).\
    \ Alternately, a peer-to-peer network may be an ecosystem that is considerably\
    \ larger in scale and is characterized by the use of specialized protocols and\
    \ apps to establish direct links between consumers over the web.\n\n*4) Osmotic\
    \ Computing*: This model has become pervasive in various settings, from urban\
    \ planning and healthcare to linked vehicles and Industry 4.0 [\\[46\\]](#page-40-44).\
    \ It lays the groundwork for a system in which vehicles, pedestrians, and urban\
    \ infrastructure interact and share real-time information to improve traffic flow.\
    \ As more people use IoT applications housed in different types of networks (cloud,\
    \ edge, and IoT), it is now clear that the providers who make up the IoT's service\
    \ ecosystem (data, service, network, and equipment) are all interconnected [\\\
    [48\\]](#page-40-46). In this setting, buyers and sellers implicitly expect their\
    \ data and services to be secure and trustworthy. There is no requirement for\
    \ familiarity with the federated ecosystem (service, data, and network) for users\
    \ of the IoT apps to connect with many applications using a web-based user interface\
    \ [\\[202\\]](#page-44-20). Users send their information to application providers\
    \ without realizing that those trusted suppliers may share that information with\
    \ any third parties (such as a company that hosts analytics on the cloud or a\
    \ company that provides the infrastructure for mobile devices). Security issues\
    \ may arise for software due to the wide variety of computing devices available\
    \ from different manufacturers and their presence in an untrusted realm with no\
    \ overarching authority [\\[203\\]](#page-44-21).\n\n*5) Dew Computing*: It stands\
    \ out because of its near-complete independence from Internet access, its users'\
    \ physical closeness to servers, its low latency, outstanding speed, excellent\
    \ user interface, and adaptability in terms of control available to users [\\\
    [204\\]](#page-44-22). Instead of serving as a replacement for cloud computing,\
    \ dew computing serves as a useful supplement. In the not-too-distant future,\
    \ people throughout the globe might be able to limit their time spent online,\
    \ increasing their efficiency and effectiveness. Countries have adopted measures\
    \ to handle the influx of Internet users caused by the COVID-19 blackout. To lighten\
    \ the Internet's burden, video streaming services are reducing visual quality,\
    \ while others just update their software outside of peak viewing times. The dew\
    \ computer's proximity to the user in the design means it can facilitate all electronic\
    \ interactions with fewer steps and more efficient data transfer [\\[204\\]](#page-44-22).\n\
    \n*6) Edge Computing*: Since its origins in content delivery networks, distributed\
    \ computing has matured into the mainstream as an edge computing paradigm that\
    \ places resources near the client's end. Big data is typically best stored in\
    \ the cloud, whereas immediate information created by consumers and exclusively\
    \ for the customer needs computing power and storage on the edge [\\[40\\]](#page-40-38).\
    \ To accommodate growing mobile user needs, cloud providers have realized they\
    \ must shift crucial processing to the device. With its high performance and low\
    \ cost, edge computing is a key driver for AI. This can be the most helpful method\
    \ to see how AI relates to edge computing. Due to the data- and compute-intensive\
    \ characteristics of AI, edge computing aids AI-powered applications in resolving\
    \ their technical problems. AI/ML systems consume large amounts of data to discover\
    \ trends and provide trustworthy recommendations [\\[205\\]](#page-44-23). AI\
    \ use cases that need video analysis face latency challenges and rising expenses\
    \ due to the cloud-based transmission of high- -definition video data. The delay\
    \ and reliance on central processing in cloud computing are problematic when ML\
    \ inputs, outputs, and (re-)training data must be handled in real-time. It is\
    \ possible to perform computation and decisions at the edge, eliminating the need\
    \ for costly backbone connections and allowing immediate action on the data. Client\
    \ information regarding location is stored at the edge instead of in the cloud\
    \ for security reasons. When data is streamed to the cloud, all relevant data\
    \ and datasets are uploaded. Edge networks for computing have introduced several\
    \ difficulties associated with infrastructure management because of their dispersed\
    \ and intricate nature [\\[206\\]](#page-44-24). Managing resources efficiently\
    \ requires carrying out several tasks. Examples include VM consolidation, resource\
    \ optimization, energy efficiency, workload prediction, and scheduling. Resource\
    \ management has historically relied on static, established guidelines, mostly\
    \ based on operations research methodologies, even in dynamic, rapidly changing\
    \ settings and in immediate situations. To deal with these issues, especially\
    \ when choices must be made, AI-based solutions are being used more and more frequently.\
    \ AI/ML methods have become increasingly common in the past few years [\\[207\\\
    ]](#page-44-25). However, selecting where on edge to carry out a task can be challenging,\
    \ as it requires considering tradeoffs like the volume of data on edge servers\
    \ and the ability to move users [\\[208\\]](#page-44-26). The cache has to anticipate\
    \ the consumer's next destination for it to build on the notion of mobility [\\\
    [209\\]](#page-44-27). It is situated at a suitable edge to cut costs and energy\
    \ consumption. Several different methods, including genetic algorithms, neural\
    \ network models, and reinforcement learning, are utilized in this process.\n\n\
    • *Mobile Edge Computing*: Mobile Edge Computing now Multi-access Edge Computing\
    \ (MEC)—expands its possibilities by introducing cloud computing to the web's\
    \ edge. Initially targeted solely on the edge nodes of mobile networks, MEC has\
    \ since expanded its scope to include conventional networks and, ultimately, integrated\
    \ networks. While typical cloud computing occurs on servers located far from the\
    \ end-user and devices, MEC enables activities to be carried out at base stations,\
    \ centralized controllers, and various other aggregating sites on the Internet\
    \ [\\[210\\]](#page-44-28). MEC improves consumer QoE by redistributing cloud\
    \ computing workloads to customers' individual, on-premises servers, thus relieving\
    \ congestion on mobile networks and lowering latency [\\[211\\]](#page-44-29).\
    \ Innovative applications, services, and user experiences are being unlocked at\
    \ a dizzying rate thanks to advances in edge data generation, collection, and\
    \ analysis and in the transmission of data between devices and the cloud [\\[212\\\
    ]](#page-44-30). Because of this, MEC is accessible to consumers and businesses\
    \ in a wide range of contexts and industries. Integrating MEC into a camera network\
    \ improves the speed with which data may be stored and processed. With sufficient\
    \ processing power and bandwidth, data may be immediately analyzed locally instead\
    \ of being sent to a remote data center [\\[213\\]](#page-44-31). Self-driving\
    \ automobiles and autonomous mobile robots (AMRs) are two examples of emerging\
    \ technologies that require powerful ML to arrive at judgments rapidly. If such\
    \ decisions take place in a remote data center, only seconds might be the distinction\
    \ between nearly escaping failures and causing a tragedy [\\[205\\]](#page-44-23).\
    \ Because the vehicle must avoid hitting pedestrians, animals, and other vehicles,\
    \ judgments must be made on the vehicle. Machineto-machine (M2M) communication\
    \ will be essential to the success of 6G as the forthcoming generation of a global\
    \ wireless standard and the technological advances that will emerge from it [\\\
    [101\\]](#page-42-7).\n\n## *4.3.2.2. Technologies/Impact Areas*\n\nThe key technologies\
    \ and affected domains for decentralized computing include:\n\n#### 4.3.2.2.1.\
    \ Distributed Ledger Technology\n\nThe computing paradigms of fog, edge, and cloud\
    \ are currently experiencing explosive growth in both the business and academic\
    \ worlds. Security, confidentiality, and data integrity in these systems have\
    \ become increasingly important as their practical applications have expanded\
    \ [\\[214\\]](#page-44-32). Data loss, theft, and corruption from malicious software\
    \ like ransomware, trojans, and viruses raise serious considerations in this area.\
    \ For the system's and most importantly, endusers' sake, it is crucial that data\
    \ integrity be maintained, and that no data be delivered from an unauthenticated\
    \ source. Medical care, innovative cities, transport, and monitoring are all examples\
    \ of applications of critical importance where the margin for error is near zero\
    \ [\\[4\\]](#page-40-2).\n\n• *Blockchain*: Because the majority of edge devices\
    \ have limited computing and storage capacity, developing an appropriate system\
    \ for data security, and preserving integrity is challenging. The IoT and other\
    \ real-time systems have used blockchain technology for data security [\\[134\\\
    ]](#page-42-40). To store and monitor the worth of an asset over time, a blockchain\
    \ is, in theory, a set of distributed ledgers. When new information is added to\
    \ the system, it becomes a block with a Proof of Work (PoW). A PoW is a hash value\
    \ that cannot be made without changing the PoW of the blocks that came before\
    \ it in the ledger. Miners create and verify these PoWs while also mining blocks\
    \ in the Fog network [\\[215\\]](#page-44-33).\n\nAfter a miner has completed\
    \ the PoW, it broadcasts the newly created block into the network, where the other\
    \ nodes check its legitimacy before joining it in the chain. Also, the fraudulent\
    \ change of data in a blockchain will not work unless at least half of the copies\
    \ of the data in question are changed individually by carrying out the same actions.\
    \ With such a strict time constraint, modifying any data in the blockchain will\
    \ be extremely difficult. Network nodes must offer route selection, preservation,\
    \ financial services, and mining for the blockchain to function. Considering these\
    \ challenges, numerous groups have worked to develop solid frameworks for combining\
    \ blockchain and fog computing [\\[133\\]](#page-42-39).\n\nThe majority of these\
    \ systems employ a dynamic allocation mining technique in which the least-used\
    \ nodes mine and validate the chains. In contrast, the remaining nodes are employed\
    \ for load balancing, computation, and data collection [\\[108,](#page-42-14)\
    \ [216\\]](#page-44-34). The blockchain on a large portion of the network is replicated\
    \ at those nodes if a worker detects an issue in relation to blockchain manipulation\
    \ or signature forging. Furthermore, blockchains offer public-key encryption with\
    \ adaptive key exchange for further security. Blockchain is a deceptively simple\
    \ central notion, but incorporating it into fog computing systems presents several\
    \ challenges. Cost and upkeep are major factors surrounding storage capacity and\
    \ scalability. Only complete nodes (nodes that can fully validate the transactions\
    \ or blocks) store the whole chain, which still results in massive storage needs.\
    \ Data anonymity and privacy issues are another blockchain shortcoming. Privacy\
    \ is, therefore, not incorporated into the blockchain architecture; consequently,\
    \ thirdparty tools are necessary for accomplishing these crucial requirements\
    \ [\\[217\\]](#page-44-35). This might result in less efficient applications that\
    \ demand more resources (both computationally and in terms of storage space) to\
    \ run. There are still numerous unresolved issues and potential future developments\
    \ for blockchains in IoT architectures [\\[13\\]](#page-40-11).\n\nInsufficient\
    \ resources are the main barrier to excellent data protection and dependability.\
    \ Because of resource limits, more complex encryption or key generation cannot\
    \ be incorporated with these chains of data [\\[218\\]](#page-44-36). Only restricted\
    \ encryption algorithms may be implemented. By considering resource limitations,\
    \ more effective algorithms may be created. In high fault-rate scenarios, wherein\
    \ the edge nodes are susceptible to attack at any time, modifying such chains\
    \ is another essential approach [\\[219\\]](#page-44-37). Network and I/O bandwidth\
    \ needs are greatly increased due to the necessity of revalidating blocks and\
    \ copying chains from the primary network. The majority of frameworks additionally\
    \ use a master-slave architecture, which introduces a potential weak spot. In\
    \ diverse settings, this is to be expected. The balance between cost and reliability\
    \ must be meticulously evaluated when considering redundancy [\\[132\\]](#page-42-38).\
    \ The blockchain flaws also continue to impact fog architectures. There is a need\
    \ to develop efficient consensus techniques that can validate blocks with little\
    \ block sharing and copying. Those curious might learn more about blockchain by\
    \ reading an in-depth report on the topic.\n\n# 4.3.2.2.2. Federated Learning\n\
    \nData is needed for ML model training, testing, and validation. Information is\
    \ stored in locations accessible by thousands or millions of users (devices).\
    \ Rather than sharing the entire dataset required to train a model, federated\
    \ devices only communicate the parameters specific to that device's instance of\
    \ the model. The parameter sharing mechanism is defined by the federated learning\
    \ topology [\\[220\\]](#page-44-38). Each participant in a centralized topology\
    \ contributes the parameters of the model to a centralized server, which then\
    \ trains the centralized model and returns the trained parameters to each participant.\
    \ Parameters are typically shared among a smaller group of peers in other configurations,\
    \ including peer-to-peer or hierarchical ones. ML methods that require large or\
    \ geographically dispersed data sets may benefit from federated learning. However,\
    \ there is no universally applicable machine-learning solution [\\[221\\]](#page-44-39).\
    \ Several unanswered questions remain about federated learning that researchers\
    \ and developers are hard at work trying to address [\\[222,](#page-44-40) [223\\\
    ]](#page-44-41). There are a lot of opportunities for efficient communication\
    \ in federated learning. This means the master server or other entities acquiring\
    \ the parameters must be able to cope with occasional interruptions or delays\
    \ in transmission. Getting all the federated devices to talk to each other and\
    \ stay in sync is still an open issue [\\[222\\]](#page-44-40). There is typically\
    \ a lack of transparency between federated parties and a central server regarding\
    \ the computing capacity of the federated parties. However, it is still challenging\
    \ to ensure that the training activities will operate on a diverse mix of devices\
    \ [\\[220\\]](#page-44-38). Federated parties' data sets might be quite varied\
    \ in terms of data amount, reliability, and variety [\\[224\\]](#page-44-42).\
    \ It is challenging to predict how statistically diverse the training data sets\
    \ will be and how to protect against any detrimental effects this diversity may\
    \ have. Efficient deployment of privacyenhancing solutions is required to prevent\
    \ data loss due to shared model parameters.\n\n## 4.3.2.2.3. Bitcoin Currency\n\
    \nTransaction settlement using blockchain technology was initially proposed with\
    \ the digital (crypto-)currency Bitcoin. The blockchain is a distributed ledger\
    \ that verifies monetary transactions using PoW and may be configured to record\
    \ anything of worth. Blockchains, including bitcoins and cryptocurrencies, are\
    \ innovative in operating apps across networks [\\[225\\]](#page-44-43). Designers\
    \ create smart contracts for Bitcoin money exchanges, which are subsequently carried\
    \ out on blockchain VMs [\\[226\\]](#page-45-0).\n\nBlockchain relies on a decentralized,\
    \ concurrency-agnostic runtime environment and consensus mechanism. Blocks of\
    \ data may be disseminated across Bitcoin ledgers via a peer-to-peer network with\
    \ no requirement for a centralized authority, thanks to the Bitcoin enabling network\
    \ [\\[226\\]](#page-45-0). The data in the blockchain is certified by the members\
    \ to keep it safe and open, and anybody is welcome to join the network. Cloud\
    \ computing may use this property, and the security of cloud storage, in particular,\
    \ can benefit from it. Cloud computing infrastructures enable the execution of\
    \ complex applications and the handling of massive data sets. Centralized data\
    \ centers coupled with Fog or IoT devices at the network edge cannot efficiently\
    \ handle the enormous data storage required to deliver high-availability, real-time,\
    \ low-latency services [\\[227\\]](#page-45-1).\n\nA distributed cloud design\
    \ is required to deal with these problems instead of the more conventional network\
    \ architecture. Blockchain technology, a fundamental element of distributed cloud\
    \ systems, offers detailed control over resources by enabling their management\
    \ through distributed apps [\\[228\\]](#page-45-2). It also allows for the tracking\
    \ of resource usage, providing both customers and service providers with the means\
    \ to verify that the agreed-upon QoS is being met. A marketplace is a platform\
    \ where everyone may promote their computer resources while discovering what they\
    \ require using AI-based techniques or models of prediction [\\[229\\]](#page-45-3).\
    \ Blockchains, compared to cloud computing, offer fewer computer resources available\
    \ to run distributed applications, such as less space for storing data, less powerful\
    \ VMs, and a more unstable protocol. As a result, apps that are sensitive to delay\
    \ and those that use a lot of resources need to find solutions to these problems\
    \ [\\[230\\]](#page-45-4).\n\nCombining blockchain and cloud computing to develop\
    \ a blockchain-based distributed cloud can provide novel advantages and solve\
    \ current restrictions. Data moves closer to its owner and user through Blockchain's\
    \ distributed cloud, providing on-demand resources, security, and cost-effective\
    \ access to infrastructure [\\[231\\]](#page-45-5). In the meantime, the high\
    \ price and substantial consumption of electricity from clouds may be solved with\
    \ a blockchain-based distributed cloud. Cloud storage security is another area\
    \ where blockchain may play a role in the future [\\[232\\]](#page-45-6). By dividing\
    \ user data into smaller pieces before storing it everywhere, it is possible to\
    \ encrypt it further. A small portion of the data is accessible to the hacker,\
    \ not the entire file. In addition to eradicating data-altering hackers from the\
    \ network, a backup copy of the data may be used to restore any changes [\\[229\\\
    ]](#page-45-3). The use of quantum computers to circumvent the mathematical impossibility\
    \ of modern encryption is one of their most publicized uses. In the meantime,\
    \ many online publications have predicted the end of Bitcoin and other cryptocurrency\
    \ use after Google stated it had achieved quantum supremacy.\n\n#### *4.3.2.3.\
    \ Trends/Observations*\n\nThe main trends and observations regarding decentralized\
    \ computing are as follows:\n\n*Serverless Edge Computing*: Serverless' 'scale-to-zero'\
    \ feature, which releases unoccupied containers from the system, works well for\
    \ energy-conscious IoT scenarios with load-inconsistent applications. On the other\
    \ hand, finegrained scaling (i.e., at the function stage) is capable of handling\
    \ extremely distinct needs and execution settings at the edge [\\[185\\]](#page-44-3).\
    \ Many IoT applications rely on instances initiated by sensing or actuating, just\
    \ like functions in serverless [\\[102\\]](#page-42-8). However, unlike serverless\
    \ functions, IoT devices often sense or act only on rare occasions, whereas they\
    \ sleep the majority of the time to conserve power. So, first, serverless appears\
    \ to be an ideal paradigm of execution. However, combining serverless, edge computing,\
    \ and IoT applications is challenging because serverless was originally designed\
    \ for cloud environments, which do not have the same constraints as edge computing\
    \ devices [\\[233\\]](#page-45-7). In light of this opportunity, it is essential\
    \ to combine serverless, edge computing, and IoT applications to address this\
    \ challenge. This is crucial to be addressed, as the fact is that although this\
    \ adaptation looks needed and helpful, its practicality necessitates comprehensive\
    \ inspections to avoid ramifications.\n\n# *4.3.3. Hybrid Computing*\n\nIt involves\
    \ combining both a centralized network and a decentralized network. In this section,\
    \ we discuss the main focus or paradigms, technologies or impact areas, and various\
    \ trends or observations within hybrid computing.\n\n# *4.3.3.1. Focus/Paradigms*\n\
    \nThe following are the main focus or paradigms for hybrid computing:\n\n*Fog-Cloud-Edge\
    \ Orchestration*: Increasingly, IoT technologies are required in daily life. Smart\
    \ cities, automated manufacturing, virtual reality, and autonomous cars are just\
    \ a few instances of the vast variety of sectors where the application of these\
    \ technologies has been rising quickly [\\[234\\]](#page-45-8). This type of IoT\
    \ application frequently necessitates access to heterogeneous distant, local,\
    \ and multi-cloud compute resources, in addition to a globally dispersed array\
    \ of sensors. The expanded Fog-Cloud-Edge orchestration paradigm is born from\
    \ this. This new paradigm has made it a necessity to expand application-orchestration\
    \ needs (i.e., self-service deployment and run-time administration) beyond the\
    \ confines of a purely cloud-based infrastructure and across the full breadth\
    \ of cloud or edge resources. Recent years have seen an increased focus on the\
    \ research and advancement of orchestrating platforms in both business and academic\
    \ settings as a means of meeting this need.\n\n#### *4.3.3.2. Technologies/Impact\
    \ Areas*\n\nThe key technologies and affected domains for hybrid computing include:\n\
    \n*1) Cryptocurrencies*: Decentralized networks with powerful computational power\
    \ were pioneered by cryptocurrencies. There is no centralized authority that controls\
    \ the cryptocurrency market or issues new cryptocurrencies. Bitcoin, the first\
    \ decentralized digital currency, was launched in 2009 and employs blockchain\
    \ technology to record transactions and save user histories [\\[235\\]](#page-45-9).\
    \ Blockchain Explorer and similar tools reveal Bitcoin's decentralized network\
    \ activity as it moves from one wallet to another, and they also reveal the activity\
    \ of other cryptocurrency networks. There is no equivalent technology that would\
    \ enable such transparency in the private banking business, nor would such a publication\
    \ ever be made public. Decentralization design incorporates many additional features\
    \ that make it hard for bad actors to forge bitcoin or steal from user accounts,\
    \ such as synchronizing the blockchain across all machines on the network [\\\
    [236\\]](#page-45-10). Bitcoin and other cryptocurrencies are required to function\
    \ on decentralized networks: A blockchain does not have a central controlling\
    \ computer or administrator.\n\n*2) Machine Economy*: The emerging machine economy\
    \ refers to the exchange of resources (such as power, data storage, processing\
    \ power, currency, and network connections) in the upcoming global networks of\
    \ computers [\\[237\\]](#page-45-11). Together, the data centers that power the\
    \ cloud, the web, and monetary exchanges, form a network that will support the\
    \ machines that power the future economy. This is the time when AI willfully conceals\
    \ or exaggerates its powers. AI conceals and safeguards limited supplies to protect\
    \ the crucial scarce resource of computation cycles used to generate AI insights.\
    \ The organization is guarding the computation cycles used to generate AI insights,\
    \ which are the most crucial scarce resource in this case. Lies, trickery, and\
    \ barter to coax AI into parting with its limited resources will become an increasingly\
    \ hot issue in the coming years [\\[238\\]](#page-45-12). To prevent itself from\
    \ being overused, AI will have to resort to dishonest behavior. The machine economy\
    \ is going to be among the most significant developments to come for human culture;\
    \ and will be among the hottest topics of the emerging payment and AI technologies\
    \ needed to fund future interstellar and interplanetary travel.\n\n#### *4.3.3.3.\
    \ Trends/Observations*\n\nThe main trends and observations regarding hybrid computing\
    \ are as follows:\n\n*Distributed Computing Continuum*: Emerging from the convergence\
    \ of IoT, edge, fog, and cloud computing, Distributed Computing Continuum Systems\
    \ (DCCS) represent a novel computing paradigm that harnesses the collective power\
    \ and heterogeneity of these diverse computing tiers to address the demanding\
    \ computational requirements of future applications [\\[239\\]](#page-45-13).\
    \ These applications, ranging from autonomous vehicles and e-Health to smart cities,\
    \ holographic communications, and virtual reality, demand unprecedented levels\
    \ of computational power, low latency, and efficient data management. Achieving\
    \ these stringent requirements necessitates seamless integration and collaborative\
    \ operation among all computing tiers, transforming the underlying infrastructure\
    \ into a unified, intelligent system. As exemplified by edge and fog computing,\
    \ the underlying infrastructure of DCCS plays a pivotal role in determining its\
    \ performance. This geographically distributed, heterogeneous, and resource-constrained\
    \ infrastructure poses significant challenges, needing new approaches that can\
    \ dynamically adapt to application and user demands [\\[9\\]](#page-40-7). Cloud-centric\
    \ methodologies, often tailored to cloud-specific assumptions, fall short in addressing\
    \ the characteristics of edge, fog, and DCCS environments.\n\nTo address these\
    \ challenges, DCCS advocates for decentralized intelligence, empowering each component\
    \ of the underlying infrastructure to make autonomous decisions based on its specific\
    \ tasks and local conditions [\\[240\\]](#page-45-14). This approach leverages\
    \ the concept of service level objectives (SLOs), well-established in cloud computing,\
    \ to define the operational goals of each component of the system. By modularizing\
    \ and distributing SLOs across the system, a DCCS can achieve scalable intelligence\
    \ within its infrastructure. Further, incorporating the Markov Blanket concept\
    \ into SLO management enables causal filtering, ensuring that only conditionally\
    \ dependent variables are considered when making decisions. This selective filtering,\
    \ coupled with causal inference or active inference, empowers each component to\
    \ make informed decisions independently, adapting to its dynamic environment and\
    \ the overall system's requirements [\\[241\\]](#page-45-15). This loosely-coupled\
    \ architecture fosters a resilient and adaptive DCCS, capable of catering to the\
    \ diverse and evolving demands of future applications.\n\n## **4.4. Computational\
    \ Methodologies: Parallel vs. Sequential Computing**\n\nParallel computing implies\
    \ a computer model wherein numerous tasks are completed concurrently, employing\
    \ a number of processors or threads [\\[242\\]](#page-45-16). In this paradigm,\
    \ many processes run concurrently and their outputs are pooled. Tasks can be conducted\
    \ in parallel instead of sequentially, potentially reducing execution times.\n\
    \n#### *4.4.1. Parallel Computing*\n\nIn this section, we discuss the main focus\
    \ or paradigms, technologies or impact areas, and various trends or observations\
    \ within parallel computing.\n\n#### *4.4.1.1. Focus/Paradigms*\n\nThe following\
    \ are the main focus or paradigms for parallel computing.\n\n*Simultaneous Data\
    \ Processing*: In order to handle many parts of a task at once, parallel processing\
    \ employs multiple processors, or CPUs. By breaking down large computations into\
    \ smaller ones, systems may drastically speed up their execution [\\[242\\]](#page-45-16).\
    \ Parallel processing is possible on current computers with multiple cores and\
    \ on any machine with more than one CPU. Multi-core processors are embedded processors\
    \ containing two or more CPUs for increased performance, lowered energy use, and\
    \ more efficient handling of many tasks. Two to four cores are common in modern\
    \ computers, with some models supporting up to 12. Modern computers commonly use\
    \ parallel processing to complete complex processes and calculations. At the most\
    \ basic level, sequential and parallel-serial processes differ in how registers\
    \ are employed. Shift registers work in series, computing every bit one at a time,\
    \ while registers with concurrent loading handle each bit of a word concurrently\
    \ [\\[243\\]](#page-45-17). Using multiple functional units that can execute identical\
    \ or distinct tasks in parallel enables the management of more complex parallel\
    \ processing.\n\n# *4.4.1.2. Technologies/Impact Areas*\n\nThe key technologies\
    \ and affected domains for parallel computing include:\n\n*1) ASICs*: Application-Specific\
    \ Integrated Circuits (ASICs) are integrated circuits designed for specific uses.\
    \ As their name suggests, ASICs are limited to a single function. They provide\
    \ a single function and are consistent throughout their service life [\\[138\\\
    ]](#page-42-44). ASICs are semiconductor devices and circuitry developed to carry\
    \ out a particular task. In contrast to mainstream processors, including CPUs\
    \ and GPUs, both the speed and the energy efficiency of ASICs are optimized to\
    \ fit the needs of a specific application [\\[244\\]](#page-45-18). Their excellent\
    \ performance, minimal energy use, and small form factor make them ideal for mass-produced\
    \ goods that can afford the higher bespoke design costs.\n\n*2) FPGA*: A Field\
    \ Programmable Gate Array (FPGA) is a semiconductor that can be programmed to\
    \ provide unique logic for use in both early system prototype design and the last\
    \ version of a system to circumvent obsolescence [\\[138\\]](#page-42-44). In\
    \ contrast to other bespoke or semi-custom integrated circuits, FPGAs can be easily\
    \ reprogrammed by a software update to meet the changing requirements of the larger\
    \ system they are integrated into, using hardware design languages, such Verilog\
    \ and *Very High-Speed Integrated Circuit Hardware Description Language (VHDL)*\
    \ [\\[245\\]](#page-45-19). Nowadays, most rapidly expanding applications are\
    \ perfect fits for FPGAs, which include edge computing, AI, network security,\
    \ 5G, industrial control, and automated machinery.\n\n# *4.4.1.3. Trends/Observations*\n\
    \nThe main trends and observations regarding parallel computing are as follows:\n\
    \n*1) Neuro-symbolic AI*: Advances in deep learning techniques have unlocked a\
    \ few of AI's enormous possibilities. Consequently, it is now obvious that these\
    \ methods are at a breaking point and that such sub-symbolic or neuro-inspired\
    \ solutions only function effectively for particular kinds of issues and are typically\
    \ opaque to both analysis and comprehension [\\[246\\]](#page-45-20). However,\
    \ symbolic AI methods, founded on rules, logic, and reasoning, perform significantly\
    \ better in terms of openness, comprehensibility, authenticity, and reliability\
    \ than sub-symbolic methods. A new path termed neuro-symbolic AI was recently\
    \ recommended, integrating the effectiveness of sub-symbolic AI alongside the\
    \ visibility of symbolic AI [\\[247\\]](#page-45-21). This synergy has the potential\
    \ to yield a new generation of AI devices and platforms that are both comprehensible\
    \ and expansion-intolerant and can combine logic with learning in a generic fashion.\n\
    \n*2) Scalability*: The most important advantage of scalable design is improved\
    \ efficiency, as well as the capacity to deal with sudden spikes in traffic or\
    \ severe loads with little to no warning [\\[248\\]](#page-45-22). An application\
    \ or online company may continue to operate smoothly during busy periods with\
    \ the assistance of a scalable system, preventing businesses from incurring financial\
    \ losses or suffering reputational harm [\\[173\\]](#page-43-34). If a system\
    \ is organized into component services (for example, using the microservices system\
    \ design), monitoring, updating features, troubleshooting, and scaling may become\
    \ simpler tasks.\n\n## *4.4.2. Sequential Computing*\n\nIn this section, we discuss\
    \ the main focus or paradigms, technologies or impact areas, and various trends\
    \ or observations within sequential computing.\n\n# *4.4.2.1. Focus/Paradigms*\n\
    \nThe following are the main focus or paradigms for sequential computing:\n\n\
    *One-process-at-a-time execution*: In the context of computing, sequential computing\
    \ describes a paradigm in which operations are carried out in a certain order,\
    \ with the output of one operation feeding into the data being the input of the\
    \ subsequent one [\\[249\\]](#page-45-23). A single processor carries out all\
    \ of the model's tasks in the sequence specified by the code.\n\n## *4.4.2.2.\
    \ Technologies/Impact Areas*\n\nThe key technologies and affected domains for\
    \ sequential computing include:\n\n*Traditional Von Neumann Architecture*: This\
    \ architecture is a sequential computing-based concept for digital machines. This\
    \ system includes a CPU, RAM, and I/O devices, all interconnected by a bus [\\\
    [250\\]](#page-45-24). The CPU of a system based on the Von Neumann architecture\
    \ processes instructions sequentially, feeding the output of one into the input\
    \ channel of the subsequent one [\\[107\\]](#page-42-13).\n\n# *4.4.2.3. Trends/Observations*\n\
    \nThe main trends and observations regarding sequential computing are as follows:\n\
    \n*1) In-Memory Computing*: In-memory computing is a method used to perform computations\
    \ solely in memory (like RAM). This word usually refers to massive and complicated\
    \ computations that must be executed on a cluster of computers using specialized\
    \ systems software [\\[249\\]](#page-45-23). As a clustering system, the machines\
    \ pool their RAM, so the computation is effectively done across machines and uses\
    \ the combined RAM capacity of all the machines collectively.\n\n*2) Energy-efficiency*:\
    \ Power effectiveness and sustainability have emerged as major issues for HPC\
    \ systems as their processing capacity increases [\\[251\\]](#page-45-25). To\
    \ reduce electrical usage while increasing computational performance, scientists\
    \ are inventing environmentally friendly hardware layouts, investigating innovative\
    \ cooling strategies, and fine– tuning algorithms. The general efficiency of HPC\
    \ systems is being improved by the development of energy-aware scheduling and\
    \ utilization strategies.\n\n*3) Performance Optimization*: Since single-processor\
    \ efficiency can no longer develop at a rapid pace, the era of the single-microprocessor\
    \ computer is coming to an end. It's time for a new era in computing when parallelism\
    \ takes centre stage and sequential computing takes a back seat [\\[252\\]](#page-45-26).\
    \ There are still significant scientific and engineering obstacles to overcome,\
    \ but now is a good moment to try new approaches to computer programming and hardware\
    \ design. Various computer architectures have emerged, each tailored to certain\
    \ performance and efficiency goals. The next wave of discoveries will certainly\
    \ necessitate enhancements to computer hardware and software [\\[253\\]](#page-45-27).\
    \ No one can say for sure if we'll succeed in making parallel computing as mainstream\
    \ and user-friendly as yesterday's peak sequential single-processor computer systems\
    \ in the field of computing. Innovative novel applications that motivate the computer\
    \ business will slow down if parallel programming and associated software activities\
    \ don't become popular, and if creativity slows down across the economy as a whole,\
    \ many other sectors will suffer as well [\\[121\\]](#page-42-27).\n\n## **4.5.\
    \ Computing Trends and Emerging Technologies**\n\nNew computing trends and emerging\
    \ technologies continue to advance the field of computing, improving the adaptability,\
    \ self-management, and sustainability of many types of industrial systems.\n\n\
    #### *4.5.1. Advanced Computing Styles and Trends*\n\nIn this section, we discuss\
    \ advanced computing styles and trends and their related technologies and paradigms.\n\
    \n#### *4.5.1.1. Focus/Paradigms*\n\nThe following are the main focus or paradigms\
    \ for advanced computing styles:\n\n*Quantum AI*: Quantum computing is attractive\
    \ because it is a unique innovation that can radically change AI and computing\
    \ in general. In this section, we look into what quantum computing can do and\
    \ how it can affect AI and the wider economy. The implications of this computing\
    \ method might have far-reaching effects on several facets of our cultural and\
    \ financial lives [\\[4\\]](#page-40-2). The widespread impact of AI suggests\
    \ that combining it with quantum computing might unleash dramatic change in the\
    \ field of AI [\\[198\\]](#page-44-16).\n\nSeveral algorithms that made it possible\
    \ to do tasks previously thought impossible for conventional computers emerged\
    \ in the wake of the foundational studies that formalized the notion of a quantum\
    \ computer [\\[254\\]](#page-45-28). The development of Shor's algorithm, an effective\
    \ method for dividing enormous amounts of data, has bolstered research into quantum\
    \ computing and quantum cryptography. Yet, existing cutting-edge technologies\
    \ are not yet accurate enough to execute Shor's algorithm successfully, which\
    \ requires a degree of precision for performing register initialization, quantum\
    \ operations on multiple qubits, and storing quantum states. It is also crucial\
    \ to remember that quantum computers have particular limits [\\[76\\]](#page-41-25).\
    \ The acceleration afforded by quantum computers grows exponentially compared\
    \ to the amount of time a conventional computer takes (Grover's method); hence,\
    \ it is not predicted that it will effectively solve NPhard efficiency issues.\
    \ The benefits of quantum computing, such as quantum superposition and entanglement,\
    \ typically vanish rapidly with the complexity and magnitude (i.e., the number\
    \ of quantum systems involved) of the underlying hardware, making the process\
    \ of designing a quantum computer non-trivial. Despite this, the curiosity of\
    \ significant technologically advanced players (IBM, Microsoft, Google, Amazon,\
    \ Intel, and Honeywell) has skyrocketed in the past few years, and a plethora\
    \ of fresh startups have emerged to propose remedies for quantum computing using\
    \ technologies as diverse as superconducting devices, encased ions, and integrated\
    \ light circuits. Corporations like these are among the numerous that are investing\
    \ in quantum research and development at the moment [\\[255\\]](#page-45-29).\n\
    \nAlthough there are many obstacles to overcome, the Google AI team has achieved\
    \ considerable strides in the past few years, gaining a quantum edge by developing\
    \ Sycamore, a programmable quantum computer. Similarly, IBM has now launched the\
    \ Eagle chip, the first quantum computer with more than 100 qubits of hardware\
    \ [\\[256\\]](#page-45-30). This is only the beginning of an intensive research\
    \ and development program, with the tech giant hoping to increase the number of\
    \ qubits to over a thousand by 2024 [\\[51\\]](#page-41-0). But as was previously\
    \ stated, protecting these devices from ambient noise is a significant constraint\
    \ when trying to retain the subtle characteristics of composite quantum states\
    \ while still allowing for coherence in quantum development. Because of this,\
    \ a quantum computer's components require ultra-low temperatures in the order\
    \ of fractions of a Kelvin, which presents hurdles for both device design and\
    \ material development [\\[257\\]](#page-45-31).\n\n#### *4.5.1.2. Trends/Technologies*\n\
    \nThe main trends and technologies regarding advanced computing styles are as\
    \ follows:\n\n*1) Edge AI*: Recent advancements in AI efficiency, the rise of\
    \ IoT devices, and the emergence of edge computing have all unleashed the promise\
    \ of edge AI. This has opened up previously unimaginable uses for edge AI, such\
    \ as helping radiologists make diagnoses, assisting in driving cars and fertilizing\
    \ crops [\\[92\\]](#page-41-41). Since its inception in the mid-1990s—paired with\
    \ the emergence of content delivery networks that utilize edge servers positioned\
    \ near users to stream online and gaming video—edge computing has been the subject\
    \ of much discussion and adoption by professionals and businesses. Almost every\
    \ sector today has tasks that may benefit from adopting edge AI. In truth, edge\
    \ applications are driving the next generation of AI computing, which will improve\
    \ people's lives in various settings, such as at home, at work, at school, and\
    \ on the road. AI at the edge refers to the application of AI to physical devices.\
    \ In contrast to storing all of an organization's data in a single centralized\
    \ spot, such as a cloud provider's data centre or a private data warehouse, \"\
    Edge AI\" allows for AI calculations to be performed close to the users at the\
    \ network's edge. Because the Internet is accessible all across the globe, any\
    \ area might be thought of as its outskirts. Omnipresent traffic signals, autonomous\
    \ equipment, and mobile phones are just a few examples. It might also be anything\
    \ from a shop to a factory to a healthcare facility. Companies of all sizes strive\
    \ to automate more of their processes because doing so improves productivity,\
    \ effectiveness, and safety [\\[258\\]](#page-45-32). Computer software may aid\
    \ with this through the ability to recognize patterns and dependably carry out\
    \ identical tasks repeatedly. However, it is challenging to fully convey them\
    \ in a system of algorithms and regulations because the world is unpredictable\
    \ and human actions cover infinite circumstances. Today, as edge AI has progressed,\
    \ robots and devices can work with the \"intelligence\" of human cognition no\
    \ matter what they are. Intelligent IoT apps driven by AI may learn to adjust\
    \ to novel circumstances and effectively complete identical or similar tasks [\\\
    [259\\]](#page-45-33). Substantial progress in important areas has allowed for\
    \ the practical deployment of AI models at the edge. Furthermore, developments\
    \ in neural networks, along with other areas of AI, have laid the groundwork for\
    \ universal ML [\\[260\\]](#page-45-34). Many companies are finding that they\
    \ can successfully train AI models and put them into action at the edge. AI in\
    \ the periphery requires widely distributed computing resources. Recent advancements\
    \ in enormously parallel GPUs are currently used to run neural networks. The development\
    \ of devices connected to the IoT is partly responsible for the present age's\
    \ unparalleled surge in data volume [\\[261\\]](#page-45-35). The development\
    \ of sensors, smart cameras, robots, and other data-gathering equipment has made\
    \ it possible to begin using AI models at the edge in nearly all facets of business.\
    \ The increased speed, dependability, and security that 5G/6G is delivering to\
    \ the battleground are also helping IoT use cases [\\[118\\]](#page-42-24).\n\n\
    *2) Biologically-inspired Computing*: The term \"bio-inspired computing\" refers\
    \ to creating computer systems by drawing inspiration from the natural world.\
    \ As an aside, computer science is also used to model and understand biological\
    \ processes [\\[145\\]](#page-43-6). Computing architectures that take cues from\
    \ nature can function as autonomous, flexible networks. Similarly, bio-inspired\
    \ computing offers a fresh perspective on AI by building modular, self-improving\
    \ systems [\\[262\\]](#page-45-36). Swarm intelligence refers to the ability of\
    \ swarms of autonomous entities to generate intelligence by collaborating in ways\
    \ reminiscent of the behavior of bees or ants. Biologists, software engineers,\
    \ computer scientists, physicists, mathematicians, and geneticists all work together\
    \ on the subject of bio-inspired computing [\\[263\\]](#page-45-37). Compared\
    \ to their digital counterparts, biological systems have several distinct benefits.\
    \ AI has advanced thanks to incorporating many concepts originally derived from\
    \ natural processes into machine learning. Adaptable and responsive autonomous\
    \ robots might be extremely useful in high-risk settings like conflict zones and\
    \ hazardous clean-up activities [\\[146\\]](#page-43-7). Tasks like crop pollination\
    \ might be performed by swarms of small robots. Bio-inspired technology is being\
    \ used in cognitive modelling by developing artificial neural network systems\
    \ based on neuron function within the brain. Training, growing, and collaborating\
    \ on computer chips is becoming a reality [\\[264\\]](#page-45-38). When these\
    \ nodes are linked by self-organizing wireless links, they form a system well\
    \ adapted to modelling issues with several basic causes [\\[263\\]](#page-45-37).\
    \ Self-learning and reconfigurable chips mean less time spent loading software\
    \ and more time spent getting things done. Such systems might help explain the\
    \ propagation of ideas through a community or construct a model of brain function\
    \ that reflects true biological processes. The use of DNA in natural computing\
    \ is a topic of current study. Data storage, covert messaging, and even computation\
    \ are all possibilities that have been proposed by DNA bioinformatics studies\
    \ DNA [\\[265\\]](#page-45-39). DNA molecules may also form practical structures\
    \ by self-assembly. The computer hardware, such as switches, CPUs, and timers,\
    \ might be replaced by biological components. It is already possible to employ\
    \ some biological substances in electronics. Even internal cell programming for\
    \ purposes like medication secretion is feasible.\n\n*3) Explainable Artificial\
    \ Intelligence (XAI)*: Successful completion of computer engineering tasks depends\
    \ on wise decision-making. Can workloads be reliably executed on an automated\
    \ system? Is there any way to understand how the trained models came to their\
    \ conclusions? Problems like this are typical and must be solved until any computer\
    \ can be used in action [\\[4\\]](#page-40-2). Incorrect decision-making about\
    \ such complicated and cutting-edge technology is costly in terms of resources\
    \ and money. Many AI/ML implementations in computer systems have improved resource\
    \ utilization and energy usage through better decision-making. However, the forecasts\
    \ made by these AI/ML models for computing devices are still not usable, interpretable,\
    \ or implementable. Such restrictions are a common problem for AI/ML models [\\\
    [266\\]](#page-45-40). Most current research has focused on clarifying how QoS\
    \ is accomplished, even though QoS remains a top priority. Is there anything academics\
    \ can do to help the IT industry move forward? Therefore, when attempting to make\
    \ educated judgments on handling resources (a prime manifestation of AI for computing),\
    \ a solid grounding in Explainable AI (XAI) and experience with XAI methods and\
    \ tools is required [\\[267\\]](#page-45-41). Forecasting of resource and power\
    \ consumption and SLA variances, as well as the implementation of promptly proactive\
    \ action to resolve these concerns, are examples of the types of Explainable AI\
    \ techniques that may be used. XAI forecasting algorithms must be correctly developed\
    \ to make computing more practical, explicable, and deployable [\\[268\\]](#page-45-42).\n\
    \n*4) Semantic Web and Decentralized Systems Integration*: Fog computing has emerged\
    \ as a software engineering culture and practice that combines at least five different\
    \ technology types: IoT, AI, Cloud-to-Edge Computing, Blockchain, and Digital\
    \ Twins [\\[269\\]](#page-46-0). Various recent projects have presented their\
    \ vision of integration between the Semantic Web and decentralized systems, for\
    \ example, networks based on Blockchain technologies [\\[270\\]](#page-46-1).\
    \ Here, the main challenge is to achieve a new generation of trustworthy, sustainable,\
    \ human-centric, performant, and scalable smart applications.\n\n*5) Quantum Internet*:\
    \ It is an ecosystem enabling quantum devices to communicate and share data in\
    \ a setting that uses quantum physics' peculiar rules. In principle, this would\
    \ grant the quantum Internet hitherto unattainable skills via standard web apps\
    \ [\\[59\\]](#page-41-8). Quantum devices, such as a quantum computer or a quantum\
    \ processor, may generate the quantum states of qubits, which can then be used\
    \ to encode information. Sending qubits over a network of physically distinct\
    \ quantum devices is, in essence, what the quantum Internet will be all about.\
    \ Importantly, this will occur because of the strange characteristics of quantum\
    \ states. That probably sounds like the conventional web [\\[271\\]](#page-46-2).\
    \ However, if one wants to transmit qubits around, then they need to use a quantum\
    \ channel instead of a conventional one, which requires making use of the peculiar\
    \ behavior of particles at the subatomic level—–the so-called \"quantum states\"\
    \ that have both fascinated and perplexed scientists for decades. Information\
    \ transmission on the quantum Internet is based on quantum physics, a completely\
    \ foreign field [\\[254\\]](#page-45-28). One may need to set aside all knowledge\
    \ of classical computing to comprehend the quantum ecology of a possible Internet\
    \ 2.0. One could imagine that their favorite web browser will not have much in\
    \ common with the quantum Internet [\\[4\\]](#page-40-2).\n\n#### *4.5.2. Industry\
    \ and Sustainability Trends*\n\nIn this section, we discuss industry and sustainability\
    \ trends and their related technologies and paradigms.\n\n#### *4.5.2.1. Focus/Paradigms*\n\
    \nThe following are the main focus or paradigms for industry and sustainability\
    \ trends:\n\n*Carbon-Neutral Computing*: The expansion of the computer age is\
    \ an important factor in the data centre industry's advancement; however, the\
    \ push towards carbon neutrality is a more dramatic paradigm change and the industry's\
    \ biggest challenge to date. Large-scale cloud providers have pledged to attain\
    \ zero emissions on all initiatives by 2030 [\\[272\\]](#page-46-3). The fight\
    \ against climate change must include data centers. Everything from everyday conveniences\
    \ like Internet banking and shopping to cutting-edge technologies like machine\
    \ learning, quantum technology, and autonomous vehicles would be impossible without\
    \ them. There is no denying of the ever-increasing need for data centers. Nevertheless,\
    \ because of the damage they cause to the natural world, they also attract greater\
    \ scrutiny [\\[190\\]](#page-44-8). A sustainable future with a zero-carbon footprint\
    \ is possible because of these advancements in electricity, water effectiveness,\
    \ and land utilization. Online conferences and handheld gadgets make it feasible\
    \ for individuals to work from their homes and cut transit carbon emissions; however,\
    \ each bit of data has a carbon footprint of its own [\\[192\\]](#page-44-10).\
    \ Therefore, whereas electronic devices provide opportunities to enhance our oversight\
    \ of water and materials and to support sustainable economic growth, simply sending\
    \ a message provides for the challenging environmental impact of data. However,\
    \ this may differ greatly depending on the spot and efficiency of the data centers\
    \ that deal with traffic [\\[193\\]](#page-44-11). Crucially, as globalization\
    \ brings online amenities to more societies, physical infrastructure, such as\
    \ data centers, must grow to accommodate an increase in consumers, a majority\
    \ of whom will be in regions around the globe that currently lack access to green\
    \ power availability.\n\n# *4.5.2.2. Trends/Technologies*\n\nThe main trends and\
    \ technologies regarding advanced computing styles are as follows:\n\n*1) Industry\
    \ 4.0*: The Fourth Industrial Revolution, or Industry 4.0, reshapes how goods\
    \ are made, enhanced, and disseminated. Emerging innovations such as the IoT,\
    \ cloud computing, analytics, and AI/ML are being incorporated into manufacturing\
    \ facilities and processes [\\[273\\]](#page-46-4). Advanced sensors, software\
    \ with embedded capabilities, and robots are used in these \"smart industries\"\
    \ to gather information for more informed decision-making. When data from manufacturing\
    \ operations is combined with data from Enterprise Resource Planning (ERP), supply\
    \ chain, customer service, and other corporate systems, information that was previously\
    \ kept separate can be seen and understood in completely new ways, which leads\
    \ to even more value being created [\\[274\\]](#page-46-5). Improved efficiency\
    \ and responsiveness to clients is made possible by the advent of technological\
    \ innovations such as enhanced automation, predictive maintenance, and automatic\
    \ optimization of process enhancements [\\[275\\]](#page-46-6). To enter the fourth\
    \ industrial revolution, the manufacturing sector must embrace the development\
    \ of smart factories. The ability to see industrial assets in real-time and access\
    \ preventative maintenance tools may be gained by analyzing the massive volumes\
    \ of big data generated from sensors on the production line. Smart factories implementing\
    \ cutting-edge IoT technology see gains in output and quality [\\[276\\]](#page-46-7).\
    \ Manufacturing inaccuracies and costs can be reduced by using AI-powered visual\
    \ insights instead of traditional business models for human inspection. Quality\
    \ assurance staff may monitor production operations from almost any location with\
    \ minimal expenditure using a smartphone linked to the cloud. Companies may save\
    \ money on costly repairs by identifying problems early on with the help of ML\
    \ algorithms [\\[49\\]](#page-40-47). Any business operating in the industrial\
    \ sector, from individual to process production and even in the energy and mining\
    \ industries, may use the ideas and tools of Industry 4.0.\n\n*2) Digital Twins*:\
    \ A digital twin is a computerized model of and connected with a real-world object\
    \ that may be used to test and improve its design, performance, and usability\
    \ [\\[277\\]](#page-46-8). Smart sensors embedded in the object capture data in\
    \ real-time, allowing a digital depiction of the asset to be produced [\\[99\\\
    ]](#page-42-5). The model may be used through an asset's lifespan, from development\
    \ and testing to actual usage, revamping and eventual retirement. To create a\
    \ digital representation of a physical object, digital twins utilize many technologies.\
    \ The term \"IoT\" describes the network of interconnected devices and the underlying\
    \ infrastructure that enables them to exchange data and instructions with one\
    \ another and the cloud as a whole. With gratitude to the introduction of affordable\
    \ computer chips and high-bandwidth connectivity, one can now have trillions of\
    \ gadgets hooked up to the global web. Digital twins use data from IoT sensors\
    \ to replicate physical properties in a virtual form [\\[278\\]](#page-46-9).\
    \ The information is sent into a system or panel to be viewed as it changes in\
    \ real time. Studying, solving issues, and pattern recognition are just a few\
    \ examples of the kinds of cognitive challenges that AI seeks to address [\\[279\\\
    ]](#page-46-10). AI/ML-based algorithms and statistical models let machines do\
    \ tasks with little to no human help. They do this by relying on patterns of observation\
    \ and inference. Machine learning techniques used in digital twins process enormous\
    \ amounts of sensor data, allowing for the identification of data patterns. Optimization\
    \ of performance, servicing, emissions outputs, and efficiency may all be gained\
    \ using data insights provided by AI/ML [\\[280\\]](#page-46-11). There are several\
    \ significant distinctions between digital twins and modelling: even though both\
    \ leverage virtual model-based simulations, a digital twin maintains a two-way\
    \ connection and can affect the physical object. Offline optimization and the\
    \ design process are two common applications of simulation. Developers use simulators\
    \ to test out different iterations of a product. On the contrary, digital twins\
    \ are interactive and dynamically updated virtual worlds. Both their scope and\
    \ their utility have increased.\n\n#### *4.5.3. Adaptive and Self-Managing Systems*\n\
    \nIn this section, we discuss adaptive and self-managing systems and their related\
    \ technologies and paradigms.\n\n## *4.5.3.1. Focus/Paradigms*\n\nThe following\
    \ are the main focus or paradigms for adaptive and self-managing systems:\n\n\
    *Autonomic Computing*: IBM's autonomic computing program was one of the earliest\
    \ worldwide efforts to develop computing systems with little human intervention\
    \ required to accomplish predetermined goals [\\[30\\]](#page-40-28). It was primarily\
    \ based on findings about how human nerves and thinking work and how they are\
    \ coordinated—bioinspiration, as discussed above. In autonomic computing, researchers\
    \ explore how software-intensive systems can make decisions and act without human\
    \ interaction to reach the (user-specified) \"administration\" objectives [\\\
    [281\\]](#page-46-12). The concept of control for closed- and open-loop systems\
    \ has significantly impacted the foundations of autonomic computing [\\[31\\]](#page-40-29).\
    \ Multiple independent control networks may coexist in practice inside complex\
    \ systems. The integration of ML and AI to enhance resource utilization and efficiency\
    \ at scale remains an important obstacle regardless of investigations into autonomic\
    \ frameworks to handle computing resources, from a single resource (e.g., a web\
    \ server) to resource groupings (e.g., several servers inside a CDC) [\\[4\\]](#page-40-2).\
    \ Autonomous and selfmanaging systems can be implemented on a spectrum from fully\
    \ automated to partially automated with human oversight through the use of AI/ML\
    \ to improve the efficiency and performance of the computing systems.\n\n## *4.5.3.2.\
    \ Trends/Technologies*\n\nThe main trends and technologies regarding adaptive\
    \ and self-managing systems are as follows:\n\n*SDN-NFV*: The explosion of IoT\
    \ devices and the concomitant flood of sensor data enable knowledge-driven IoT\
    \ applications, including connected cities and smart agriculture [\\[84\\]](#page-41-33).\
    \ To begin providing such services, one must develop a data-gathering method that\
    \ is flexible enough to adapt to shifting conditions in the field. Network programmability\
    \ (SDN or NFV) enables the easy reconfiguration of IoT networks [\\[86\\]](#page-41-35).\
    \ Current SDN/NFV-based approaches in the IoT environment nevertheless fail owing\
    \ to a shortage of knowledge of resources and overhead, as well as incompatibility\
    \ with conventional protocols [\\[1\\]](#page-39-0). This void must be filled\
    \ by prioritizing resource and power limitations in the creation of SDN/NFV-enabled\
    \ IoT nodes and network protocols. Assigning traffic sources to those Virtual\
    \ Network Functions (VNFs) across the most efficient paths, with sufficient energy\
    \ and network reliability, may maximize the number of active NFV nodes [\\[9\\\
    ]](#page-40-7).\n\n**Summary:** Table [3](#page-29-0) lists a summary of open\
    \ challenges and future directions in Paradigms/ Technologies/ Impact Areas, along\
    \ with recommendations for further reading. Table [4](#page-30-0) lists the summary\
    \ of Trends/Observations for modern computing along with the recommendations for\
    \ future reading.\n\n# <span id=\"page-28-0\"></span>**5. Impact and Performance\
    \ Criteria**\n\nIn this section, we discuss the impact of contemporary computing\
    \ and performance criteria.\n\n# **5.1. Performance Metrics**\n\nWe are considering\
    \ QoS, SLA, autoscaling, and fault tolerance as performance metrics for computing\
    \ systems.\n\n# *5.1.1. QoS and SLA*\n\nPredicting how a cloud computing system\
    \ will work in real-time is a major difficulty, even if AI techniques are used\
    \ [\\[282\\]](#page-46-13). The efficiency of a computer may be measured using\
    \ QoS metrics, including execution time, cost, scalability, elasticity, latency,\
    \ and dependability. A SLA, a legally binding contract between a cloud service\
    \ consumer and provider, defines QoS standards and potential penalties should\
    \ they be violated [\\[283\\]](#page-46-14). Today, various IoT applications can\
    \ use blockchain and similar technologies. Each one has its own QoS factors that\
    \ depend on its area, goal, and demand [\\[284\\]](#page-46-15). An SLA may also\
    \ be assessed with a metric called SLA violation rate, which determines compensation\
    \ in the event of an SLA breach by estimating the divergence of the real SLA compared\
    \ to the needed (estimated or predicted) SLA [\\[285\\]](#page-46-16). Since compromized\
    \ QoS in one cloud service may negatively impact the QoS of the entire computing\
    \ system, QoS is becoming increasingly crucial while assembling cloud services.\
    \ Provisioning the proper quantity and quality of cloud resources that will satisfy\
    \ the QoS of an application's price range, response time, and deadline is essential\
    \ for providing an effective cloud service [\\[286\\]](#page-46-17). Consequently,\
    \ cloud providers should guarantee to offer sufficient resources to minimize or\
    \ reduce the SLA violation rate, allowing users' workloads to\n\n#### <span id=\"\
    page-29-0\"></span>Table 3\n\nSummary of open challenges and future directions\
    \ in Paradigms/Technologies/Impact Areas along with further reading\n\n| Paradigms/\
    \                                       | Open Challenges and Future Directions\
    \                                                                            \
    \                                                     | Further Reading      \
    \                       |\n|--------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------|\n\
    | Technologies/ Impact<br>Areas                    |                         \
    \                                                                            \
    \                                                                  |         \
    \                                    |\n| Cloud Computing                    \
    \              | What are the tradeoffs that need to be established between the\
    \ various QoS                                                                \
    \                            | ACM CSUR [1]                                |\n\
    |                                                  | requirements brought on by\
    \ the large variety of IoT applications operating on cloud<br>systems?       \
    \                                                                |           \
    \                                  |\n| Autonomic<br>Comput<br>ing           \
    \            | What additional problems may be addressed by an autonomic computing\
    \ expansion<br>that is based on AI/ML as the number of IoT and scientific workloads\
    \ increases?      | Elsevier IoT [4]                            |\n| Mobile<br>Cloud<br>Com\
    \                           | How would AI-based deep learning algorithms be used\
    \ to anticipate the resource                                                 \
    \                                       | ACM CSUR [60]                      \
    \         |\n| puting                                           | demands<br>beforehand<br>for<br>diverse<br>geographic<br>resources<br>needed<br>for<br>mobile<br>cloud\
    \                                                                |           \
    \                                  |\n|                                      \
    \            | computing, requiring new strategies for provisioning and scheduling\
    \ resources?                                                                 \
    \                       |                                             |\n| Green\
    \ Cloud Comput                               | How can improved methods for effective\
    \ data encoding for lower bandwidth usage                                    \
    \                                                    | ACM CSUR [162]        \
    \                      |\n| ing                                              |\
    \ and energy-effective transmission in data-intensive IoT devices make cloud computing<br>more\
    \ environmentally friendly?                                                | \
    \                                            |\n| Fog Computing              \
    \                      | How can AI approaches be utilized to properly schedule\
    \ tasks when working in locations                                            \
    \                                    | Elsevier JPDC [39] &                  \
    \      |\n|                                                  | with varying amounts\
    \ of fog resources?                                                          \
    \                                                                      | IEEE\
    \ COMST [41]                             |\n| Edge Computing                 \
    \                  | In what ways edge computing can be utilized to boost power\
    \ and resource utilization,<br>hence enhancing QoS?                          \
    \                                | IEEE<br>COMST<br>[206]<br>[41]            \
    \  |\n| Mobile Edge Comput                               | How can novel resource\
    \ provisioning and scheduling policies be developed for mobile               \
    \                                                                    | IEEE<br>COMST<br>[213]\
    \                      |\n| ing                                              |\
    \ edge computing that makes use of AI-based deep learning approaches to forecast\
    \ the                                                                        \
    \            | [41]<br>&<br>ACM<br>CSUR                    |\n|              \
    \                                    | resource requirements beforehand for resources\
    \ that are located in different locations?                                   \
    \                                            | [60]                          \
    \              |\n| Serverless Computing                             | How to\
    \ reduce the cold start time and increase scalability using serverless edge<br>computing?\
    \                                                                        | IEEE<br>TSC<br>[186]<br>&<br>ACM\
    \ CSUR [183] |\n| Osmotic Computing                                | How can osmotic\
    \ computing improve resource availability or performance at the<br>network edge\
    \ while moving services from the data center to the edge for AI/ML-driven | ACM\
    \ TOIT [46]                               |\n|                               \
    \                   | adaptive administration of microservices?              \
    \                                                                            \
    \                                   |                                        \
    \     |\n| Dew Computing                                    | How should dew computing\
    \ allow a highly scalable method that can increase or reduce                 \
    \                                                                  | Elsevier\
    \ IoT [48]                           |\n|                                    \
    \              | the real-time demands of performing operations at runtime via\
    \ utilizing AI?                                                              \
    \                             |                                             |\n\
    | Programming Models                               | How to select a programming\
    \ model that efficiently gathers data when and where it                      \
    \                                                               | Procedia<br>Computer\
    \                        |\n|                                                \
    \  | is needed while keeping complexity low relative to the total number of processors\
    \ at                                                                         \
    \         | Science [115]                               |\n|                 \
    \                                 | hand?                                    \
    \                                                                            \
    \                                                 |                          \
    \                   |\n| Virtualization                                   | How\
    \ can unbreakable security for VMs be ensured if consumers do not follow     \
    \                                                                            \
    \           | ACM CSUR [122]                              |\n|               \
    \                                   | recommended practices when it comes to login\
    \ credentials, installations, and other<br>operations?                       \
    \                                              |                             \
    \                |\n| IoT                                              | How to\
    \ ensure that an SLA is upheld while responding to customer requests as quickly<br>as\
    \ possible using IoT applications?                                           |\
    \ IEEE COMST [78]                             |\n| Integrated Computing      \
    \                       | How may QoS characteristics change if communication\
    \ between layers in a fog                                                    \
    \                                       | ACM CSUR [108] &                   \
    \         |\n|                                                  | edge/cloud computing\
    \ paradigm is improved?                                                      \
    \                                                                      | Elsevier\
    \ FGCS [112]                         |\n| Connectivity/                      \
    \              | How can satisfying the demand or need for network solutions enabling\
    \ high per                                                                   \
    \                      | ACM<br>CSUR<br>[60]<br>&                    |\n| Networking\
    \                                       | formance, resilience, dependability,\
    \ scalability, adaptability, and cybersecurity remain<br>constant?           \
    \                                                      | IEEE COMST [61]     \
    \                        |\n| Container                                      \
    \  | How can the QoS in data processing be enhanced by leveraging containers with\
    \                                                                            \
    \              | Springer JoS [174] &                        |\n| Technologies\
    \                                     | virtualization?                      \
    \                                                                            \
    \                                                     | Wiley CCPE [178]     \
    \                       |\n| Microservices                                   \
    \ | How to handle errors, ensure data integrity, and communicate effectively amongst<br>services\
    \ in a distributed system using a microservice architecture?               | IEEE\
    \ TSC [172]                              |\n| Software-defined Net           \
    \                  | What are some ways in which SDN might help minimize power\
    \ usage in cloud and                                                         \
    \                                 | Wiley ETT [84]                           \
    \   |\n| works                                            | edge computing?  \
    \                                                                            \
    \                                                                         |  \
    \                                           |\n| Distributed<br>Ledger       \
    \                     | How can distributed ledger technology (Blockchain) be\
    \ utilized to secure the data for                                            \
    \                                     | IEEE<br>COMST<br>[108]               \
    \       |\n| Technology                                       | IoT applications?\
    \                                                                            \
    \                                                                         | [216]\
    \                                       |\n| (Blockchain)                    \
    \                 |                                                          \
    \                                                                            \
    \                                 |                                          \
    \   |\n| Federated Learning                               | How could companies\
    \ ensure privacy in federated learning services, which differ from           \
    \                                                                       | Elsevier\
    \ KBS [222] &                        |\n|                                    \
    \              | learning in data centers in that users' data is disclosed to\
    \ third parties or the centralized                                           \
    \                              | CIE [220]                                   |\n\
    |                                                  | server while exchanging model\
    \ changes during the training stage?                                         \
    \                                                             |              \
    \                               |\n| Software Engineering                    \
    \         | How can fault tolerance be improved in computing systems dynamically\
    \ without                                                                    \
    \                      | Elsevier JSS [129]                          |\n|    \
    \                                              | manually writing the software\
    \ code by utilizing AI to \"automatically\" diagnose and                     \
    \                                                               |            \
    \                                 |\n|                                       \
    \           | fix an error?                                                  \
    \                                                                            \
    \                           |                                             |\n\
    | Distributed<br>Comput<br>ing<br>Continuum<br>Sys | How can Distributed Computing\
    \ Continuum Systems consider all computing tiers as<br>a single system and optimize\
    \ future applications in a decentralized manner?        | IEEE TKDE [239]    \
    \                         |\n| tems                                          \
    \   |                                                                        \
    \                                                                            \
    \                   |                                             |\n|       \
    \                                           |                                \
    \                                                                            \
    \                                                           |                \
    \                             |\n\n<span id=\"page-30-0\"></span>\n\n| Table 4\
    \                                                                      |  |  |\
    \  |\n|------------------------------------------------------------------------------|--|--|--|\n\
    | Summary of Trends/Observation for modern computing along with future reading\
    \ |  |  |  |\n\n| Trends/<br>Observation | Open Challenges and Future Directions\
    \                                                                            \
    \                                      | Further Reading    |\n|------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------|--------------------|\n\
    |                        |                                                   \
    \                                                                            \
    \                         |                    |\n| AI-driven<br>Computing | How\
    \ to optimize the management of resources using the latest AI/ ML models in<br>computing\
    \ systems?                                                    | Elsevier IoT [4]\
    \   |\n| Large<br>Scale         | How can businesses mitigate the risks associated\
    \ with the proliferation of sensitive                                        \
    \                           | IEEE TKDE [155]    |\n| Machine                |\
    \ information that arise as a result of the proliferation of data produced by\
    \ AI and ML                                                                  |\
    \                    |\n| Learning               | systems?                  \
    \                                                                            \
    \                                                 |                    |\n| Edge\
    \ AI                | What strategies should be employed to oversee the simulation\
    \ and information trans                                                      \
    \               | Elsevier<br>IoTCPS |\n|                        | mission among\
    \ peripheral devices and other systems? What network infrastructures         \
    \                                                              | [92]<br>&<br>ACM\
    \   |\n|                        | should be utilized to enable this communication?\
    \                                                                            \
    \                           | SIGCOMM [261]      |\n| Bitcoin                |\
    \ How can computing be utilized to maximize the efficiency of computation or processing\
    \                                                                  | Elsevier<br>JNCA\
    \   |\n| Currency               | capacity usage in cryptocurrency for cloud mining?\
    \                                                                            \
    \                         | [226]              |\n| Industry 4.0           | How\
    \ can AI, the cloud, and edge computing be used to do predictive analysis that\
    \                                                                       | IEEE<br>COMST\
    \      |\n|                        | involves company resources?             \
    \                                                                            \
    \                                   | [273]              |\n| Intelligent    \
    \        | How to deal with big problems that come up when designing system-level,\
    \ algorithm                                                                  \
    \    | IEEE COMST [88]    |\n| Edge                   | level, or architectural-level\
    \ developments or innovations for integrated cognitive ability,              \
    \                                              |                    |\n|     \
    \                   | like making decisions in real-time, keeping AI training\
    \ and inference environmentally                                              \
    \                    |                    |\n|                        | friendly,\
    \ and deploying protection?                                                  \
    \                                                                  |         \
    \           |\n| XAI                    | How can the forecasting of resource\
    \ and power consumption and SLA variances, as                                \
    \                                        | ACM CSUR [266]     |\n|           \
    \             | well as the implementation of promptly proactive action, reduce\
    \ SLA violations and                                                         \
    \            |                    |\n|                        | enhance QoS using\
    \ XAI?                                                                       \
    \                                                          |                 \
    \   |\n| Exascale Com           | How to make energy-efficient computing as power-hungry\
    \ as the supercomputers that                                                 \
    \                     | ACM CSUR [142]     |\n| puting                 | do calculations\
    \ and transfer data within the computing environment nowadays?               \
    \                                                            |               \
    \     |\n| 6G<br>and<br>Be        | What role 6G may play in reducing latency\
    \ and improving reaction times by                                            \
    \                                  | IEEE COMST [98]    |\n| yond            \
    \       | transmitting data between edge devices at high speeds?             \
    \                                                                            \
    \        |                    |\n| Quantum AI             | What steps should\
    \ be taken to build the cloud-based quantum computing infrastruc             \
    \                                                          | Wiley SPE [51]  \
    \   |\n|                        | tures that are expected to be the foundation\
    \ for our usage of quantum computers and                                     \
    \                               |                    |\n|                    \
    \    | simulators, which will supplement our existing classical computing hardware?\
    \                                                                           |\
    \                    |\n| Quantum                | How can the benefits of quantum\
    \ networking be preserved while integrating the                              \
    \                                            | IEEE<br>COMST      |\n| Internet\
    \               | quantum Internet into currently operating conventional technology\
    \ that will have to                                                          \
    \          | [254]              |\n|                        | exist alongside\
    \ and communicate effortlessly with today's internet services?               \
    \                                                            |               \
    \     |\n| Analog<br>Com          | How is it that analog computers can do complicated\
    \ computations faster and more                                               \
    \                         | Nature Electronics |\n| puting<br>Neuromorphic | accurately\
    \ than their digital equivalents, which utilize ML methods?<br>How might neuromorphic\
    \ systems, which model the brain's structure and function | [146]<br>Nature  \
    \  |\n| Computing              | and use analog circuits to do AI tasks, pave\
    \ the way for creating incredibly adaptable,                                 \
    \                               | Computational      |\n|                    \
    \    | self-learning machines?                                               \
    \                                                                            \
    \     | Science [149]      |\n| Biologically           | What can researchers\
    \ take away from brain cells concerning ways to minimize the                 \
    \                                                       | Elsevier ESA [263] |\n\
    | inspired               | energy needed for computation, AI, and ML, given that\
    \ these cells can easily combine                                             \
    \                      |                    |\n| Computing              | smaller\
    \ tasks to execute larger ones?                                              \
    \                                                                    |       \
    \             |\n| Digital Twins          | How can network digital twins aid\
    \ in speeding up preliminary installations by preparing                      \
    \                                          | IEEE<br>COMST      |\n|         \
    \               | navigation, protection, digitization, and evaluation in simulation\
    \ while offering the                                                         \
    \         | [278]              |\n|                        | scalability and interoperability\
    \ of complex networks?                                                       \
    \                                           |                    |\n| Net Zero\
    \ Com           | How can companies mitigate the negative ecological impact of\
    \ their IT infrastructure                                                    \
    \               | IEEE<br>COMST      |\n| puting                 | by constructing\
    \ environmentally friendly data centers and improving energy effec           \
    \                                                            | [190]         \
    \     |\n|                        | tiveness, given that these centers use significant\
    \ quantities of electricity and release                                      \
    \                         |                    |\n|                        | enormous\
    \ quantities of waste heat while also providing powerful computing services? \
    \                                                                   |        \
    \            |\n\nbe executed in accordance with their set time and cost constraints\
    \ [\\[287\\]](#page-46-18). In that regard, the diversity of applications and\
    \ their behaviors on different machines requires a tighter description of their\
    \ needs to minimize SLA violation while not over-provisioning infrastructure [\\\
    [288\\]](#page-46-19). QoS-aware resource management methods, which can determine\
    \ and meet the QoS needs of a computing system, such as SLOdriven modeling and\
    \ execution-reordering of web requests, are crucial to its success in the future\
    \ [\\[289\\]](#page-46-20). Several research issues must be overcome before QoS\
    \ can be attained effectively [\\[290\\]](#page-46-21). Initially, the execution\
    \ time of an application is large, and its performance is diminished due to a\
    \ lack of cloud resources during runtime—which can be compounded by transparent\
    \ processes to the developer, such as garbage collection, magnifying the potential\
    \ of inexplicable SLO violations [\\[291\\]](#page-46-22). Additionally, finding\
    \ the requirement for effective SLA-aware resource management methods decreases\
    \ the SLA violation rate and preserves the overall efficiency of the computing\
    \ system. Finally, to reach the ultimate goal of having multiple clouds, there\
    \ has to be a unified SLA standard across all cloud providers [\\[292\\]](#page-46-23).\
    \ Since many IoT applications rely on cloud computing systems that employ AI-based\
    \ supervised or unsupervised algorithms for learning or models for forecasting,\
    \ it is imperative to determine the appropriate balance amongst various QoS needs.\n\
    \n#### *5.1.2. Autoscaling*\n\nThanks to the dynamic nature of the cloud, self-adapting\
    \ techniques may be used to reduce resource costs without compromizing QoS [\\\
    [293\\]](#page-46-24). Resource autoscaling, or strategy, reconfiguration, and\
    \ provisioning, allows for self-additivity. Scientists have looked into autoscaling,\
    \ or the dynamic modification of computational resources like VMs, for several\
    \ reasons [\\[123\\]](#page-42-29). These include the desire to learn more about\
    \ (a) horizontal changes, or the addition or removal of VMs; (b) vertical transformations,\
    \ or the addition or removal of VM resources; (c) choice-making techniques, such\
    \ as analytical modelling, control theory, and neural networks; and (d) utilizing\
    \ a range of pricing models, such as on-demand. When it comes to latency-sensitive\
    \ QoS requirements, the primary challenge for autoscaling methods is figuring\
    \ out how to make a scaling decision quickly enough. AI prediction is the initial\
    \ step towards making decisions in the quickest way possible [\\[248\\]](#page-45-22).\
    \ However, traditional ML may not be up to the task when it comes to IoT applications\
    \ requiring real-time mistake correction due to a lack of autonomous error correction\
    \ [\\[294\\]](#page-46-25). Also, the rise of latency-sensitive IoT apps and microservices\
    \ that need responses in the range of milliseconds has made things worse while\
    \ containerbased solutions and burstable efficiency resources should make it possible\
    \ to deploy and provision resources in the cloud quickly. To prevent a potentially\
    \ disastrous situation, a smart car's onboard computer constantly monitors data\
    \ such as the vehicle's speed, the location of other drivers and passengers, and\
    \ the road conditions [\\[295\\]](#page-46-26). The cloud alone cannot answer\
    \ this problem due to the instability and latency in connections between the cloud\
    \ and users; instead, autoscaling techniques for IoT applications must take these\
    \ factors into account [\\[296\\]](#page-46-27). The truth is that autoscaling\
    \ needs to be made bigger because the cloud naturally gets in the way of Industry\
    \ 4.0 ideas, like real-time management, and making decisions without a central\
    \ authority.\n\n#### *5.1.3. Fault Tolerance*\n\nProviders of cloud computing\
    \ services owe it to their customers to make such services available without interruption,\
    \ regardless of what problems arise [\\[297\\]](#page-46-28). To meet the QoS\
    \ standards of a computing system efficiently, fault tolerance approaches are\
    \ employed. Software, hardware, and even networks may all go wrong when a computer\
    \ system operates. In addition, fault resilience guarantees the reliability and\
    \ accessibility of cloud services [\\[4\\]](#page-40-2). Timeout breakdowns, overload\
    \ issues, and resource-lack failures are further examples of cloud dependability\
    \ issues. A major breakdown has the potential to cause a cascade of failures in\
    \ the system [\\[298\\]](#page-46-29). Several proactive and reactive fault tolerance\
    \ approaches have been developed to cope with these kinds of failures. The most\
    \ common method of handling faults in long-running processes is called \"checkpointing,\"\
    \ and it involves preserving the current state after each modification [\\[299\\\
    ]](#page-46-30). Additionally, checkpoints are employed if there is a possibility\
    \ of not beginning at the same position [\\[1\\]](#page-39-0). Replication-based\
    \ resilience is another well-known method; it involves duplicating the nodes or\
    \ jobs until they are completed. If a system is overloaded or malfunctioning,\
    \ a task migration-based resilience solution can move the work to another computer.\
    \ Computer systems must have autonomous resilience-aware resource management technology,\
    \ reliability of service methods, and reliable information integrity (e.g., blockchain)\
    \ to keep running. Reliability impacts QoS in cloud computing while still delivering\
    \ it effectively. One of the biggest obstacles in cloud computing is figuring\
    \ out how to deliver a secure and effective cloud service while cutting down on\
    \ power consumption and emissions [\\[300\\]](#page-46-31). Cloud computing has\
    \ built-in redundancy to maintain service availability, QoS, and performance guarantees.\
    \ Resource management must consider varying failures and workload prototypes for\
    \ medical care, urban planning, and agricultural applications to run well [\\\
    [71\\]](#page-41-20). Predicting failure in systems that use cloud computing is\
    \ difficult and can impact the dependability of the system [\\[299\\]](#page-46-30).\
    \ Predicting faults and achieving the requisite dependability of the cloud service\
    \ while maintaining QoS necessitates several machine or deep learning approaches\
    \ [\\[13\\]](#page-40-11). Replication-based fault tolerance solutions are effective\
    \ for IoT applications because they reduce task delay and response time. A dependable\
    \ cloud storage system that will offer an effective retrieval system for processing\
    \ big data is also required to deal with big data applications [\\[301\\]](#page-46-32).\n\
    \n#### **5.2. Efficiency Metrics**\n\nWe are considering energy consumption, carbon\
    \ footprint, and serviceability as efficiency metrics for computing systems.\n\
    \n#### *5.2.1. Energy Consumption*\n\nData collection and processing have risen\
    \ exponentially during the last several years. This pattern has been pushing cloud\
    \ systems to the limits of their computational and, by extension, energy consumption\
    \ capacities [\\[302\\]](#page-46-33). Annually, CDCs have increased their power\
    \ use by around 20% to 25% [\\[303\\]](#page-46-34). This shift has led to the\
    \ rise of decentralized computer architectures such as Fog and Edge. The latency\
    \ and cost-effectiveness of cloud computing are all vastly improved by moving\
    \ parts of its computation to distributed edge devices and networks. There nevertheless\
    \ exist difficulties associated with this. Irregular energy supply, even without\
    \ the power supply itself, presents significant issues for numerous highly critical\
    \ and remote sensing applications.\n\nThe ever-growing number of IoT devices and\
    \ the data they produce have put networking's ability to handle information, compute,\
    \ and transfer data throughput to the test [\\[162\\]](#page-43-23). Meanwhile,\
    \ smaller IoT devices are currently created with limited computing power, storage\
    \ spaces, and energy. Hence, it is imperative to boost the performance of fog\
    \ and edge nodes in the network. Sustainability in CDCs and minimizing their carbon\
    \ impact have also become more pressing concerns. This must be accomplished without\
    \ lowering the bar for QoS [\\[304\\]](#page-46-35). Notwithstanding the obstacles,\
    \ there have been several advances in this area. Software, hardware, and transitional\
    \ approaches have all been taken to the energy management problem.\n\nApproaches\
    \ and techniques are being designed to optimize software efficiency, supported\
    \ by computational models [\\[304\\]](#page-46-35). One example is mobile edge\
    \ computing offloading. Hardware-wise, particularly for the application, devices\
    \ were designed to provide peak performance while minimizing energy consumption.\
    \ Energy efficiency in Wireless Sensor Networks (WSNs) has been extensively researched\
    \ [\\[4\\]](#page-40-2). Fog/edge-node sleep time scheduling, active resource\
    \ management, and additional energy-saving strategies have all been used in the\
    \ intermediate phase. There are still many unanswered questions and potential\
    \ avenues for development when it comes to the effectiveness and longevity of\
    \ fog, edge, and cloud infrastructures.\n\nAdvanced algorithms for encoding data\
    \ into fewer bits are explored to reduce transmitter power needs, which are crucial\
    \ due to limited transmission bandwidth, more critical than direct CPU power needs.\
    \ Despite the need for specialized hardware, encoding methods may be used by taking\
    \ advantage of the universal encoders present in virtually all mobile devices\
    \ [\\[13\\]](#page-40-11). Yet, it has become impossible to lower the ideal bandwidth\
    \ due to the rising quantity of data exchange and loss. Preparing for CPU and\
    \ data utilization in a way that minimizes heat generation requires modelling\
    \ at the transistor level, which necessitates the development of 3D thermal simulation\
    \ systems [\\[75\\]](#page-41-24).\n\nLastly, the aim is to minimize power consumption\
    \ to the point that the CPU and transceiver may be powered entirely by energy\
    \ harvesting or scavenging approaches [\\[305\\]](#page-46-36). Consequently,\
    \ the Fog/Edge network's granularity may be decreased, leading to more widely\
    \ scattered, overbearing, and resilient architectures. In various fields, like\
    \ energy limits, blockchain algorithms might be studied with various versatile\
    \ AI-based learning approaches for enhanced energy scheduling.\n\n#### *5.2.2.\
    \ Carbon Footprint*\n\nEnd-user needs for applications and the resulting growth\
    \ in storage in the Exabyte range will result in the first Exascale system by\
    \ 2025, followed by a Zettascale system by 2035 [\\[2\\]](#page-40-0). While this\
    \ is certainly something to be proud of, there are also many difficulties that\
    \ come along with it. Keeping everything running requires massive amounts of energy,\
    \ which poses a major obstacle. At the moment, over ten percent of the world's\
    \ power is used each year by the ICT sector [\\[190\\]](#page-44-8). The rebound\
    \ effect, which leads to even higher demand and consumption, makes it counterproductive\
    \ to create everlarger systems by increasing efficiency. The next generation of\
    \ autonomous system paradigms will likely place a greater emphasis on power and\
    \ carbon footprints in light of climate change and the projected 1.5°C rise in\
    \ worldwide temperatures owing to emissions of carbon dioxide by 2100 [\\[2\\\
    ]](#page-40-0). This is not merely about lowering energy use per unit of processing,\
    \ as is the case now, but also about more basic issues with systems that assume\
    \ continuous stable power supplies, connectivity with sources of clean energy,\
    \ and alternate techniques of minimizing energy usage [\\[306\\]](#page-46-37).\
    \ The study and treatment of systems as living ecosystems rather than as collections\
    \ of discrete components is a topic of great interest, and this includes the comprehensive\
    \ integration of managing energy (asynchronous computation, power scaling, wake-on-LAN,\
    \ air conditioning, etc.).\n\n#### *5.2.3. Serviceability/Usability*\n\nThe fields\
    \ of human-computer interaction and networked systems have yet to fully merge\
    \ with each other. This closer synchronization would be especially helpful for\
    \ cloud computing [\\[1\\]](#page-39-0). Despite significant work on resource\
    \ management and the back-end associated concerns, accessibility is a vital component\
    \ in lowering the costs of organizations investigating cloud services and infrastructure.\
    \ Costs associated with labor might decrease since customers will receive superior\
    \ service and increase their output [\\[307\\]](#page-46-38).\n\nNIST's Cloud\
    \ Usability model addresses five dimensions of cloud usability: capability, personalization,\
    \ reliability, security, and value, all of which have been highlighted as critical\
    \ issues [\\[308\\]](#page-46-39). The term \"capable\" refers to the degree to\
    \ which cloud service can fulfil the needs of its customers. With the assistance\
    \ of personal customization options, individuals and businesses will have the\
    \ capability to modify the visual style and adjust or eliminate features from\
    \ interfaces for various services. Trustworthy, robust, and useful are attributes\
    \ associated with possessing a system that fulfils its duties throughout state\
    \ situations, is safely protected, and delivers value to customers accordingly.\
    \ Current cloud initiatives have mostly concentrated on wrapping up sophisticated\
    \ services into APIs that can be accessed by end users [\\[307\\]](#page-46-38).\
    \ HPC Cloud is the most evident example. To make HPC applications more accessible\
    \ and easier to use, researchers have developed several different services. In\
    \ addition to being packaged as services, these systems provide Web interfaces\
    \ through which their settings may be set and their input and output files managed.\n\
    \nDevOps is another path associated with cloud usage that has gained popularity\
    \ in recent years [\\[309\\]](#page-46-40). DevOps has increased the efficiency\
    \ of both software engineers and administrators when it comes to developing and\
    \ delivering remedies on the cloud. Cloud computing is important not only for\
    \ creating brand new solutions AIOps and MLOps [\\[310\\]](#page-46-41) but also,\
    \ for streamlining the process of moving existing applications from onsite settings\
    \ to adaptable, multi-tenant cloud services.\n\n#### **5.3. Social Impact**\n\n\
    We are considering the digital divide, ethical AI, and digital humanism as social\
    \ impact metrics for computing systems.\n\n#### *5.3.1. Digital Divide*\n\nCorporations\
    \ in rural areas have significant challenges due to the difficulty of gaining\
    \ a connection to broadband connectivity and, by extension, cloud-based resources\
    \ [\\[311\\]](#page-46-42). Access to the web is one example of a long-standing\
    \ infrastructural gap between urban and rural areas. There are a lot of companies\
    \ that can not expand and innovate because they lack access to new technology.\
    \ Businesses in rural areas face another obstacle: the high cost of maintaining\
    \ and upgrading on-premises IT infrastructure. Cloud computing's main benefits\
    \ are the ability to work together and think creatively. The cloud encourages\
    \ teamwork by facilitating real-time, distributed collaboration. This greater\
    \ collaboration encourages invention. As a result, rural enterprises may now compete\
    \ on an equal basis with their metropolitan competitors [\\[312\\]](#page-46-43).\
    \ Accessibility to data and fundamental information is also crucial. The benefit\
    \ of using the cloud has increased significantly with the advent of generative\
    \ AI. Comprehensive sales, marketing, and manufacturing capabilities are provided\
    \ by core AI services, but these cannot be reproduced with human processing and\
    \ can be too costly to install on-site for modest organizations. The proliferation\
    \ of cloud computing has expanded business opportunities, but not equally. By\
    \ utilizing the cloud, companies in rural areas may overcome the constraints of\
    \ their physical location [\\[313\\]](#page-47-0). Cloud computing's greater availability,\
    \ decreased cost, scalable effectiveness, and improved cooperation may breathe\
    \ new life into the rural economy and propel it towards long-term success.\n\n\
    #### *5.3.2. Ethical AI*\n\nAI systems require vast amounts of data, including\
    \ details on businesses and their clients [\\[314\\]](#page-47-1). The value of\
    \ knowing the data owner surpasses that of having private information that cannot\
    \ be linked to a specific person. When dealing with sensitive information, companies\
    \ regularly face problems related to data security and regulatory compliance [\\\
    [315\\]](#page-47-2). Autonomic computing using AI needs to take into account\
    \ privacy rules and data protection. While AI has the potential to be a game-changer,\
    \ it has not always been successful in achieving its aims. A hunt for answers\
    \ by an AI may result in a flood of insensitive comments [\\[316\\]](#page-47-3).\
    \ The vast number of AI decisions and the stakes involved make this field fraught\
    \ with peril. Prior to expanding the use of this invention, it is crucial to develop\
    \ accountability and ownership.\n\n#### *5.3.3. Digital Humanism*\n\nThe unavoidable\
    \ consequences of digital colonization driven by business need a counter-force\
    \ of digital humanism motivated by care for humanity and the Earth [\\[317\\]](#page-47-4).\
    \ We have never been both so interdependent, yet so isolated. Modern digital systems\
    \ allow for global communication. One no longer has to be in the same room as\
    \ someone else to have a conversation, collaborate on a project, or just have\
    \ fun with them. The cell phone is rapidly becoming an integral part of people's\
    \ daily lives all across the world. Connectivity between the developing world\
    \ and the developed nations of the world is rapidly expanding, for both good and\
    \ ill. These interconnections are causing conflicts that could have been prevented\
    \ when individuals and ideas were separated by space. Western materialism and\
    \ commerce meet Eastern spirituality and culture in the virtual world [\\[318\\\
    ]](#page-47-5). Therefore, although humans may all end up in the cloud at some\
    \ point, the barriers of mutual respect and compassion that keep us from crashing\
    \ into one another are more than frayed. Most modern digital accounting and tracking\
    \ systems are used by private companies seeking to maximize profits at the expense\
    \ of others, enriching a few elites at the expense of a much larger underclass\
    \ [\\[319\\]](#page-47-6). In contrast, if the cloud could be utilized for humanity's\
    \ benefit, manufacturing and distribution might be dramatically enhanced. Controlled\
    \ well, such instruments will allow for fine-tuning of many crucial societal functions,\
    \ particularly at the subnational and neighborhood levels.\n\n# **5.4. Security\
    \ and Compliance**\n\nWe are considering data protection, privacy regulations,\
    \ and resilience to attacks as security and compliance metrics for computing systems.\n\
    \n## *5.4.1. Security, Privacy and Resiliency*\n\nIn recent years, there has been\
    \ a dramatic change in academia and business towards the IoT, edge computing,\
    \ and cloud computing in order to serve customers better. With this massive paradigm\
    \ shift, comes a slew of problems and difficulties with protecting the confidentiality\
    \ and safety of the information stored on these devices [\\[320\\]](#page-47-7).\
    \ Edge computing's many distinguishing features—its low latency, geographical\
    \ dispersion, end-device accessibility, high processing power, variability, etc.—make\
    \ it imperative that security and privacy mechanisms be both flexible and powerful\
    \ [\\[321\\]](#page-47-8). In addition, creating universally compatible software\
    \ platforms is challenging due to the wide variety of use cases and device types.\n\
    \nSeveral elements become important in the research of these security and associated\
    \ challenges in the cloud and fog computing models: End-user confidence and privacy;\
    \ verification and validation of sources inside nodes; secure communications between\
    \ sensor, compute, and broker nodes; detection and prevention of malicious attacks;\
    \ secure, reliable and decentralized data storage, such as Blockchain [\\[231\\\
    ]](#page-45-5). Some of the problems that have already been addressed in this\
    \ field include adaptive mutual authentication, identifying and retrieval of harmful\
    \ or malfunctioning nodes, the detection and defence against assaults, the avoidance\
    \ of harmful hazards, and the protection of user information from theft. Unmanned\
    \ Aerial Vehicle (UAV)-aided computing devices can now maintain their anonymity\
    \ while contributing to distributed frameworks in AI technology, such as computer\
    \ vision and path learning, supporting data processing and decision-making [\\\
    [322\\]](#page-47-9). Other efforts in fog forensics have also given digital evidence\
    \ by recreating prior computer activities and identifying how these events contrast\
    \ with cloud forensics in important ways.\n\nThe past few years have seen significant\
    \ progress in several key areas related to Fog Radio Access Networks (F-RANs),\
    \ including mobility management, interference reduction, and resource optimization\
    \ [\\[323\\]](#page-47-10). Novel approaches have evolved for varied applications\
    \ handling privacy challenges. Face recognition and resolution, vehicle crowd\
    \ sensing, geographic location sensing and data processing, renewable node storage\
    \ systems and data centers, and fogbased public cloud computing are promising\
    \ new research areas. Prevention against data theft, attacks involving manin-the-middle,\
    \ confidentiality of users, location confidentiality, forward privacy, reliable\
    \ user-level key management, and many other weaknesses have all been addressed\
    \ through such efforts [\\[4\\]](#page-40-2).\n\nThere are scaling issues with\
    \ many fog/cloud privacy and security models that prevent them from fully applying\
    \ to the next-generation edge computing transition [\\[324\\]](#page-47-11). Because\
    \ of fog computing's decentralized nature, numerous new security concerns, which\
    \ are not an issue in the cloud, emerge in the fog layer and IoT devices. The\
    \ deployment of authentication systems is hampered by the prevalence of threats\
    \ such as advanced persistent threats (APT attacks), malware, distributed denial\
    \ of service (DDoS) attacks, twoway communication, and micro-servers without hardware\
    \ protection mechanisms in edge data centers [\\[325\\]](#page-47-12). Additionally,\
    \ these studies show how the mobile edge computing architecture might change in\
    \ the future. For example, edge nodes working together could make real-time encryption\
    \ more efficient. The computational capacity of both edge and distant resources\
    \ has not been completely used in previous efforts, and security flaws have been\
    \ addressed from a restricted viewpoint. New phenomena appear when cloud-like\
    \ capacities are distributed to the network's periphery [\\[231\\]](#page-45-5).\
    \ Edge data center collaboration, service migration on a local and global scale,\
    \ end-user concurrency, QoS, real-time applications, load distribution, server\
    \ overflow issues, stolen device detection, and dependable node interaction are\
    \ all examples of such scenarios. Future studies can focus on new areas, such\
    \ as evolving game-theoretical strategies to the privacy algorithms encouraged\
    \ by adversarial attack scenarios, communication protocols in sensor cloud systems,\
    \ and clustering model-based security evaluation (AIbased forecasting approaches),\
    \ which can be investigated as potential solutions to these issues [\\[236\\]](#page-45-10).\
    \ Mobile devices' presence in these data centers should be taken into account\
    \ by safeguarding systems.\n\n## **5.5. Economic and Management**\n\nWe are considering\
    \ cost-efficiency, resource allocation, application design, computing economics,\
    \ and data management under economics and management for computing systems.\n\n\
    ## *5.5.1. Cost-Efficiency*\n\nMinimizing cloud expenditures while maximizing\
    \ application performance and efficacy is the goal of cloud cost optimization,\
    \ which entails striking a fine balance between technological standards and corporate\
    \ goals [\\[302\\]](#page-46-33). Costeffective cloud computing refers to the\
    \ practice of utilizing cloud providers in the most economical way feasible to\
    \ operate software, complete tasks, and create value for a company. Optimization\
    \ as a practice varies from fundamental business management to challenging scientific\
    \ and technical fields including operational research, statistical and data analysis,\
    \ and modelling and prediction [\\[314\\]](#page-47-1). Corporations may maximize\
    \ the return on their investments in cloud computing through cost optimization,\
    \ which reduces wasteful expenditures and strengthens their operational effectiveness\
    \ [\\[326\\]](#page-47-13). By avoiding economic hazards, aligning spending with\
    \ company goals, and establishing a secure, scalable, and cost-effective cloud\
    \ infrastructure, corporations can maximize the return on their investments in\
    \ cloud computing. In general, efficient cloud cost management preserves essential\
    \ resources against the risk of unanticipated expenditures and financial mismanagement.\
    \ Changing to a cloud-native methodology involves more than just updating technology;\
    \ it also necessitates a substantial adjustment in mindset [\\[1\\]](#page-39-0).\
    \ Building scalable apps that make efficient use of resources requires developers\
    \ to think in terms of the cloud from the start. To optimize cloud expenditures,\
    \ a cloudnative application design requires an in-depth familiarity with the services\
    \ and resources offered by different cloud service providers. Managed service\
    \ options are superior to autonomous technologies since they require less effort\
    \ and time investment [\\[327\\]](#page-47-14). A sophisticated knowledge of the\
    \ user application's demands, regulatory demands, and possible financial consequences\
    \ is necessary to choose between a single and multi-cloud installation plan. An\
    \ organization's administration might be simplified by adopting a singlecloud\
    \ approach, but doing so could leave it vulnerable to vendor lock-in and service\
    \ restrictions [\\[2\\]](#page-40-0). Contrarily, a multicloud strategy can increase\
    \ complexity in administration but has the ability to optimize costs, provide\
    \ greater flexibility, and lessen the danger of vendor lock-in. Identifying which\
    \ is the most economical and profitable implementation approach requires careful\
    \ consideration of the specific features, pricing methods, and competencies of\
    \ different cloud services.\n\n## *5.5.2. Resource Allocation*\n\nThe sheer size\
    \ of today's CDCs makes resource management in networked systems a formidable\
    \ challenge. In large-scale distributed architectures, the variety of network\
    \ devices, elements, and ways to connect raises the difficulty of resource management\
    \ strategies [\\[328\\]](#page-47-15). Consequently, there is a necessity for\
    \ innovative resource allocation methodologies that would add to the reliability\
    \ and effectiveness of these systems while keeping them cost-effective and sustainable.\
    \ While resource management is fundamental to distributed systems (be it the cloud,\
    \ the IoT, or fog computing), additional guarantees are needed to ensure that\
    \ these systems operate well in terms of latency, dependability, cost-effectiveness,\
    \ and throughput [\\[329\\]](#page-47-16). The software layer is just one part\
    \ of these larger systems, which also require consideration of networking, server\
    \ architecture, and ventilation. By incorporating blockchain technology into operations\
    \ like resource sharing and VM migration, cloud systems may be more secure [\\\
    [330\\]](#page-47-17). There is a pressing need to investigate novel approaches\
    \ to managing computer system resources by taking a systemic perspective and using\
    \ AI models. Moreover, experiment-driven strategies for examining methods to optimize\
    \ resource management methods may be investigated [\\[331\\]](#page-47-18). Borg\
    \ was opened up by Google as Kubernetes, which is an instance of a cluster management\
    \ system that incorporates data abstraction into resource management. Users are\
    \ freed from worrying about the nuts and bolts of resource management and may\
    \ instead focus on composing cloud-native applications.\n\nBorg conceptually separates\
    \ the whole cluster into cells, each housing a Borgmaster (controller) and a Borglet\
    \ (which initiates and terminates tasks within the cell's perimeter). The master\
    \ node coordinates with the Borglets and processes RPCs from clients requesting\
    \ actions like creating jobs or reading data [\\[253\\]](#page-45-27). This centralized\
    \ design is very suitable for scaling. The primary benefit of this architecture\
    \ is that operations that have already been started will continue to execute even\
    \ if the master or a Borglet fails [\\[332\\]](#page-47-19).\n\nA system known\
    \ as Mesos can facilitate the equitable distribution of commodity clusters. It\
    \ coordinates the use of commodity clusters by many systems. The fundamental idea\
    \ is to make use of available resources [\\[333\\]](#page-47-20). In this model,\
    \ Mesos determines how many resources to give to every framework depending on\
    \ the limitations associated with that framework, and the frameworks then choose\
    \ which offers to take. Thus, scheduling choices must be made by frameworks. In\
    \ addition, Mesos facilitates the creation of domain-specific frameworks (like\
    \ Spark) that may greatly enhance performance. To schedule and manage available\
    \ resources, YARN is used as a framework [\\[1\\]](#page-39-0). It enables services\
    \ to ask for computing power at various topological levels, including individual\
    \ servers, networks, and whole racks. The primary component in charge of allocation\
    \ is YARN's resource management. Similarly to Mesos, it enables several frameworks\
    \ to collaborate on the same commodity clusters [\\[332\\]](#page-47-19). YARN's\
    \ integrated reliability masks the complexities of failure identification and\
    \ recovery.\n\n• **Heterogeneous Resources and Workloads:** There is a lack of\
    \ cohesion in the existing literature about managing resources and workloads in\
    \ diverse cloud settings. As a result, there is no common setting in which cloud\
    \ applications can make optimal use of heterogeneity in VMs, vendors, and hardware\
    \ architectures [\\[151\\]](#page-43-12). Consequently, the initiative recommends\
    \ an overarching program that takes into consideration diversity throughout. Effective\
    \ solutions can be picked from a collection of workload and resource handling\
    \ methods, depending on an application's needs [\\[334\\]](#page-47-21). Heterogeneous\
    \ memory control is necessary for this purpose. Modern memory control techniques\
    \ rely heavily on hypervisors, thereby minimizing the potential advantages of\
    \ heterogeneity. Recent calls for action have advocated for alternatives that\
    \ focus on heterogeneity awareness in the guest OS. Another chasm is that between\
    \ heterogeneity and abstraction [\\[335\\]](#page-47-22). Accelerator-specific\
    \ languages and low-level programming initiatives are necessary for today's programming\
    \ paradigms to utilize hardware processors. Furthermore, such models allow for\
    \ the creation of useful research software. As a result, service-oriented and\
    \ user-driven applications on cloud platforms are hampered in their ability to\
    \ take advantage of heterogeneity. Kick-starting an international community initiative\
    \ to come up with an open-source, high-level programming language that is suitable\
    \ for cutting-edge and creative Web-based applications in a heterogeneous setting\
    \ is a worthwhile step to take [\\[336\\]](#page-47-23). Whenever fog computing\
    \ matures and application migration occurs, such aids will be invaluable.\n\n\
    ## *5.5.3. Application Design*\n\nBy 2025, analysts predict 61 billion connected\
    \ devices will generate 40 percent of global data at the cost of \\$2.5 trillion\
    \ [\\[337\\]](#page-47-24). Medical services, near-real-time traffic management\
    \ systems, precise farming, intelligent towns and cities, etc., are just a few\
    \ examples of IoT applications that are driving the need for improved processing\
    \ capacity, data storage, confidentiality, security, and trustworthy communication.\
    \ Additionally, as the data produced by these devices is used to resolve real-time\
    \ challenges, credibility, uniformity, and accessibility of the data must be maintained.\
    \ It's challenging to design such complex applications for IoT systems [\\[338\\\
    ]](#page-47-25). As a result, it is essential to develop application designs and\
    \ architectures that are not only dependable and quick enough to deliver effective\
    \ efficiency but additionally, scalable to manage massive amounts of data through\
    \ these devices. These are the most important factors to consider when developing\
    \ such apps for cloud environments. Firstly, a data packet's latency is the time\
    \ it takes to travel between an IoT device and the cloud before returning. For\
    \ timesensitive information, even a millisecond delay might have drastic consequences.\
    \ For instance, having a crisis-sensing instrument that only sounds an alert after\
    \ a disaster has already taken place is not a viable solution. Data needing immediate\
    \ reaction should be analyzed as close as possible to the origin [\\[339\\]](#page-47-26).\
    \ Secondly, if all this data is transferred to the cloud for storage and analysis,\
    \ the resulting traffic will be massive, using up all available bandwidth. The\
    \ distance between the device and the cloud also increases transmission latency,\
    \ which slows down responses and reduces user experience. Therefore, some tasks\
    \ must be transferred from the cloud to an edge server located between the Internet\
    \ servers and the mobile device: such solutions better satisfy end-users' requirements.\n\
    \nBy storing and processing certain IoT data directly on IoT devices, the fog\
    \ computing model reduces the load on the cloud and keeps costs down. Large-scale,\
    \ geographically dispersed applications that rely heavily on real-time data benefit\
    \ from the fog's consistency [\\[340\\]](#page-47-27). Fog computing may be the\
    \ most appropriate choice to enable effective IoT and provide reliable and safe\
    \ services and resources to many IoT users. Big data analytics, IoT devices, fog,\
    \ and edge computing have become the foundations for smart city programs worldwide\
    \ [\\[341\\]](#page-47-28). In transport, fog computing is useful for several\
    \ tasks, including vehicle-to-vehicle interaction, smart-sensor-based congestion\
    \ control system management, driverless car management, and self-parking, among\
    \ others. Furthermore, governments may employ these applications to make the lives\
    \ of their residents safer and more environmentally friendly, making them a sustainable\
    \ approach. Emergency services, such as those dealing with fires or natural disasters,\
    \ can also benefit from this technology by receiving timely alerts about developing\
    \ crises to help them make informed choices.\n\nFarming software that tracks weather\
    \ and climatic data like rainfall, wind speed, and temperatures, makes it easier\
    \ for farmers to reap a harvest. An IoT agriculture platform is suggested for\
    \ cloud and fog computing, with applications including automated agricultural\
    \ monitoring, visual inspection for pest control, and more efficient use of farm\
    \ resources [\\[338\\]](#page-47-25). Meanwhile, in the medical field, more and\
    \ more people are using fitness trackers, blood pressure monitors, and heart rate\
    \ monitors to track vital signs and gather data for medical analysis. Thanks to\
    \ these innovations, physicians can check their patients' health from afar, and\
    \ patients have more say in their care and decisions.\n\n#### *5.5.4. Computing\
    \ Economics*\n\nThere are several promising new avenues for study in the financial\
    \ aspects of cloud computing. It is becoming clearer that the lower costs of container\
    \ deployment can be used to handle real-time workloads [\\[342\\]](#page-47-29).\
    \ This is speeding up the switch from VMs to containers for cloud computing.\n\
    \n- **Cost-Effective Computing Models:** In serverless computing, no billing for\
    \ computing resources is made until a function is invoked. Processes executed\
    \ in these lambda functions tend to be narrower in focus and designed for processing\
    \ data streams. Whether or not serverless computing is beneficial for a given\
    \ application depends on its projected runtime behavior and workload [\\[1\\]](#page-39-0).\
    \ Averaged versus peak transaction rates; scaling the number of simultaneous operations\
    \ on the infrastructure (i.e., operating multiplies simultaneous functions with\
    \ a growing number of consumers); and benchmark implementation of serverless functions\
    \ across various backend hardware platforms [\\[343\\]](#page-47-30). Conversely,\
    \ increased employment of fog and edge computing characteristics with cloud-based\
    \ data centers gives tremendous study potential in cloud economics.\n- **Economic\
    \ Impact of Computing Technologies:** It is possible to lower the expenses of\
    \ running cloud services and infrastructure by combining reliable resources of\
    \ the cloud with more ephemeral resources\n\nat the consumer's edge. To make such\
    \ technology accessible at the edge, nevertheless, it is anticipated that consumers\
    \ will require some sort of inducement [\\[157\\]](#page-43-18). Expanding the\
    \ cloud market to include new types of service providers is possible because of\
    \ the accessibility of cloud and edge resources. Researchers call these intermediate\
    \ facilities located between the conventional data center and the user-owned or\
    \ provisioned resources, microdata centers [\\[344\\]](#page-47-31). The federation\
    \ concept in computing allows for many microdata center operators to operate together\
    \ to distribute workloads in a given region at desired pricing.\n\n## *5.5.5.\
    \ Data Management*\n\nMetadata handling for datasets is not given much attention\
    \ in cloud IaaS and PaaS services for storing and information administration,\
    \ which instead prioritize file, partially structured, and structured data separately.\
    \ In contrast to traditional, organized data warehouses, proponents of \"Data\
    \ Lakes\" advocate for businesses to store all their data in unstructured formats\
    \ on the cloud, using services like Hadoop [\\[1\\]](#page-39-0). Nevertheless,\
    \ using them might be difficult due to the absence of information for tracking\
    \ and defining the origin and authenticity of the data.\n\nThroughout the past\
    \ ten years, research archives have become exceptional in handling vast, varied\
    \ datasets and the accompanying information that provides context for their usage.\
    \ Collocating data and computing resources in a small number of strategically\
    \ located data centers worldwide allow for economies of scale, a major advantage\
    \ of CDCs [\\[346\\]](#page-47-32). Nevertheless, bandwidth restrictions across\
    \ worldwide networks and delays in gaining access to data present obstacles [\\\
    [348\\]](#page-47-33). This becomes an increasingly pressing issue as IoT and\
    \ 5G mobile networks expand. However, the cloud providers' access to private data\
    \ and critical confidential information still poses a risk for businesses that\
    \ need to guarantee strict privacy for their end-users. Likewise, there are no\
    \ foolproof auditing techniques to prove that the cloud service provider has not\
    \ obtained the data, even though regulatory measures are in place. In a hybrid\
    \ setup, customers may handle confidential information under their watchful eye\
    \ while still taking advantage of the advantages of public clouds, thanks to the\
    \ proximity of private data centers to public CDCs connected by an independent\
    \ high-bandwidth network. Furthermore, effective approaches to managing resource\
    \ flexibility in such contexts should be explored [\\[349\\]](#page-47-34). In\
    \ addition, it is preferable to have high-level programming abstractions and bindings\
    \ to platforms that can allocate and oversee resources in these massively dispersed\
    \ settings.\n\nFinally, with the IoT, deep learning, and blockchain all set to\
    \ be housed on clouds, it's important to look at specialist data management services\
    \ to ensure their success [\\[350\\]](#page-47-35). As indicated above, IoT will\
    \ include a strengthened requirement to deal with streaming data, their effective\
    \ storage, and a requirement to integrate data management on the edge effortlessly\
    \ with administration in the cloud [\\[38\\]](#page-40-36). When unregulated edge\
    \ devices are involved, integrity and authenticity become even more crucial. As\
    \ the use of deep learning\n\n#### <span id=\"page-37-1\"></span>Table 5\n\nSummary\
    \ of open challenges and future directions in the above-discussed impact of modern\
    \ computing and performance criteria with future reading\n\n| Impact and Perfor<br>mance\
    \ Criteria | Open Challenges and Future Directions                           \
    \                                                                            \
    \       | Further Reading           |  |  |\n|-------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------|--|--|\n\
    | QoS and SLA                         | How can SLAs and QoS be preserved in real-time\
    \ when cloud computing and                                                   \
    \                         | ACM CSUR [285] and        |  |  |\n|             \
    \                        | edge resources and tasks are executed?            \
    \                                                                            \
    \                     | Wiley IJCS [287]          |  |  |\n| Autoscaling     \
    \                    | How can it be ensured that computing resources need to\
    \ meet SLAs and QoS                                                          \
    \                 | ACM CSUR [293]            |  |  |\n|                     \
    \                | are effectively autoscaled in real-time?                  \
    \                                                                            \
    \             |                           |  |  |\n| Fault Tolerance         \
    \            | How can reliable support be continuously provided with environmentally\
    \                                                                            \
    \ | Elsevier SETA [298]       |  |  |\n|                                     |\
    \ friendly services?                                                         \
    \                                                                        |   \
    \                        |  |  |\n| Energy<br>Consump                   | How\
    \ can modern computing benefit from AI/ML to provide environmentally         \
    \                                                                    | Springer\
    \ Cluster Com      |  |  |\n| tion                                | friendly services\
    \ and low energy consumption?                                                \
    \                                                      | puting [302]        \
    \      |  |  |\n| Carbon Footprint                    | What technological advancements\
    \ may decrease the impact of climate change                                  \
    \                                        | IEEE COMST [190]          |  |  |\n\
    |                                     | and how could environmentally-friendly\
    \ computing have a lower-carbon foot                                         \
    \                                 |                           |  |  |\n|     \
    \                                | print?                                    \
    \                                                                            \
    \                             |                           |  |  |\n| Serviceability\
    \                      | What methodologies should be employed to develop and\
    \ measure key per                                                            \
    \                   | Wiley ETT [307]           |  |  |\n|                   \
    \                  |                                                         \
    \                                                                            \
    \               |                           |  |  |\n|                       \
    \              | formance indicators, also known as KPIs, in order to assess the\
    \ success of<br>initiatives that aim to make cloud computing more usable and secure?\
    \ |                           |  |  |\n|                                     |\
    \                                                                            \
    \                                                                        |   \
    \                        |  |  |\n| Digital Divide                      | How\
    \ does the use of the cloud help overcome the digital divide? Can ICTs help  \
    \                                                                    | Elsevier<br>Telematics\
    \    |  |  |\n|                                     | bridge the digital divide\
    \ in infrastructural growth?                                                 \
    \                                              | and Informatics [311]     | \
    \ |  |\n| Ethical AI                          | When designing and implementing\
    \ AI in computing devices, what ethical                                      \
    \                                        | Nature Machine Intel      |  |  |\n\
    |                                     | concerns must be taken into account? \
    \                                                                            \
    \                                  | ligence [345]             |  |  |\n| Digital\
    \ Humanism                    | How may digital tools stimulate original thought\
    \ and the independent thinking                                               \
    \                       | Elsevier<br>Journal<br>of |  |  |\n|               \
    \                      | of individuals, and whether or not the synergy of these\
    \ traits can promote a                                                       \
    \                | Business<br>Research      |  |  |\n|                      \
    \               | digital shift in the workplace?                            \
    \                                                                            \
    \            | [317]                     |  |  |\n| Security, Privacy &      \
    \           | What measures can be taken to ensure that personal information is\
    \ protected                                                                  \
    \      | IEEE COMST [321]          |  |  |\n| Resiliency                     \
    \     | and data is securely processed in the cloud when IoT apps collect and\
    \ analyze                                                                    \
    \  |                           |  |  |\n|                                    \
    \ | massive amounts of data?                                                 \
    \                                                                          | \
    \                          |  |  |\n| Cost-Efficiency                     | How\
    \ can impending difficulties like the prohibitive cost of setting up and     \
    \                                                                    | Springer\
    \ Cluster Com      |  |  |\n|                                     | running big\
    \ systems testing environments and the influence of global warming           \
    \                                                            | puting [302]  \
    \            |  |  |\n|                                     | on the architecture\
    \ of upcoming systems be overcome?                                           \
    \                                                    |                       \
    \    |  |  |\n| Resource                            | What are the best practices\
    \ for successfully provisioning cloud and edge                               \
    \                                            | ACM CSUR [331]            |  |\
    \  |\n| Allocation                          | resources for many IoT apps before\
    \ scheduling such resources?                                                 \
    \                                     |                           |  |  |\n| Heterogeneous\
    \                       | How can the heterogeneity of resources and workloads\
    \ impact the efficiency                                                      \
    \                   | ACM CSUR [151]            |  |  |\n| Workloads/        \
    \                  | of a computing system at runtime?                       \
    \                                                                            \
    \               |                           |  |  |\n| Resources             \
    \              |                                                             \
    \                                                                            \
    \           |                           |  |  |\n| Application Design        \
    \          | How can more efficient IoT apps be developed to make greater use\
    \ of available                                                               \
    \       | ACM CSUR [201]            |  |  |\n|                               \
    \      | computer power?                                                     \
    \                                                                            \
    \   |                           |  |  |\n| Computing                         \
    \  | How can businesses strengthen their CapEx (Capital Expenditure) and OpEx\
    \                                                                           |\
    \ Elsevier<br>Telecommu     |  |  |\n| Economics                           | (Operational\
    \ Expenditure) strategies by learning about the primary economic             \
    \                                                           | nications Policy\
    \ [342]    |  |  |\n|                                     | advantages of cloud\
    \ computing in terms of return on investment (ROI), total                    \
    \                                                    |                       \
    \    |  |  |\n|                                     | cost of ownership (TCO),\
    \ and relocation?                                                            \
    \                                               |                           |\
    \  |  |\n| Data Management                     | How can organizations make optimal\
    \ use of AI/ML approaches for enormous                                       \
    \                                     | Springer JBD [346] &      |  |  |\n| \
    \                                    | amounts of data to ensure efficient data\
    \ administration and analysis?                                               \
    \                               | ACM CSUR [347]            |  |  |\n\ngrows,\
    \ it will become more important to be able to manage trained models well and make\
    \ sure they can be quickly loaded and switched between to make online and distributed\
    \ analytics applications possible [\\[347\\]](#page-47-37). Finally, blockchain\
    \ and decentralized ledgers can improve data management and tracking by providing\
    \ greater transparency and auditability. While initially used by the financial\
    \ sector (of which cryptocurrencies are only one prominent example), these systems\
    \ may be expanded to store other company data safely with an inherent auditing\
    \ record.\n\n**Summary:** Table [5](#page-37-1) lists the summary of open challenges\
    \ and future directions in the above-discussed impact of modern computing and\
    \ performance criteria, along with recommendations for future reading.\n\n# <span\
    \ id=\"page-37-0\"></span>**6. Emerging Trends in Modern Computing**\n\nThe advent\
    \ of modern computing technology has made it possible to resolve several real-world\
    \ issues, including delayed responses and low latency. It has facilitated the\
    \ development of start-ups led by promising young minds from all over the world,\
    \ providing access to massive computing capacity for tackling difficult issues\
    \ and accelerating scientific advancement. Thanks to its ground-breaking improvements\
    \ in efficiency in domains like neural networks, Natural\n\n<span id=\"page-38-0\"\
    ></span>![](_page_38_Figure_1.jpeg)\n\n# **Hype Cycle for Modern Computing**\n\
    \nFigure 2: Hype Cycle for Modern Computing\n\nLanguage Processing (NLP), and\
    \ related applications, AI has been gaining popularity lately. Computing is a\
    \ vital infrastructure for running AI services due to its enormous processing\
    \ power, and AI has the potential to improve existing computing by making resource\
    \ management effective. Several AI models rely on outside data sets and largescale\
    \ computer capacity, both of which might be easier to access with today's computing\
    \ systems. Currently, training advanced models of AI in large numbers is becoming\
    \ even more crucial. Additionally, extensive application of AI in contemporary\
    \ computer systems may be possible due to ground-breaking XAI research. In the\
    \ decades to come, AI will place substantial stress on computing resources. To\
    \ meet these demands, it's necessary to develop new approaches to research and\
    \ methodology that make use of AI models to solve problems with adaptability,\
    \ delay, and handling of resources and cybersecurity. Scalability and adaptability\
    \ are two open issues that have not yet made full use of AI models as an economical\
    \ way to boost the performance of computer applications.\n\nOur analysis has led\
    \ us to categorize certain areas of computing into three separate maturity levels:\
    \ a period of five to ten years, over a decade, and under five years. Several\
    \ novel innovations are on the horizon that might significantly improve the utilization\
    \ of modern computing, and the article has highlighted them all over the coming\
    \ decade. Figure [2](#page-38-0) depicts the hype cycle for modern computing systems\
    \ along with their new trends. Researchers extensively study computing paradigms\
    \ and technologies, with edge AI and federated learning now dominating. New areas\
    \ of study within computing, such as distributed computing continuum and AI-driven\
    \ computing are just scratching the surface. Applications for computing in these\
    \ domains may not mature for another five to 10 years. Quantum ML, sustainability,\
    \ Net Zero Computing, XAI, and the quantum Internet are all expected to be in\
    \ the spotlight for at least another decade. Digital twins, cyber security, edge\
    \ intelligence, edge computing, and blockchain technology have generated an unprecedented\
    \ level of excitement. They are expected to be completely built-in under five\
    \ years with the help of modern technology. Machine Economics, In-Memory Computing,\
    \ Bitcoin Currency and AIOps/MLOps have all reached their peak of inflated expectations\
    \ for the following five to 10 years of noteworthy evolution. Significant progress\
    \ needs to be made before biologically inspired computing, neurosymbolic AI, analog\
    \ computing, neuromorphic computing, 6G, and quantum computing can be considered\
    \ hype-worthy. Cloud and fog computing has been trending heavily over the past\
    \ few years, and that trend could persist for the next five to ten years.\n\n\
    # <span id=\"page-39-1\"></span>**7. Summary and Conclusions**\n\nThis research\
    \ offers a comprehensive exploration of the evolution of modern computing systems\
    \ over the past sixty years, tracking the transition from classical computers\
    \ to quantum computing and examining their key components, such as physical architecture,\
    \ conceptual units, and communication methods. We analyze the influence of conceptualization\
    \ and physical models on the shift from centralized to decentralized structures,\
    \ a significant change since the Internet's inception. Developments in microcontroller\
    \ architecture, operating system design, and networking infrastructure have given\
    \ rise to ubiquitous computing models like the Internet of Things (IoT), pushing\
    \ the boundaries of both physical and conceptual realms. The move towards specialized\
    \ hardware and software, particularly in data-driven fields like AI, represents\
    \ a shift from earlier focuses on system flexibility and adaptability. This article\
    \ also addresses issues of accessibility and potential inequalities, emphasizing\
    \ the need to ensure these technologies positively impact society and everyday\
    \ life. Integrating recent advancements with ongoing challenges in the application\
    \ of established technological trends, this work provides an in-depth analysis\
    \ of the next wave of scientific research in computing. It summarizes current\
    \ findings, acknowledges limitations, and outlines new trends and key challenges,\
    \ considering the impact of emerging trends and envisioning future research paths\
    \ in modern computing. This review aims to be a valuable resource for experts,\
    \ technologists, and academics interested in the latest developments and future\
    \ directions in the field of modern computing.\n\n## **Acknowledgements**\n\n\
    We thank the Editor-in-Chief (Prof. Ke Xue) and anonymous reviewers for their\
    \ insightful comments and recommendations to improve the overall quality and organization\
    \ of the article. We would also like to express our gratitude to Neil Butler (CEO,\
    \ CloudScaler, UK), Marco AS Netto (Microsoft Azure HPC, USA) and Manmeet Singh\
    \ (University of Texas at Austin, USA) for their thoughtful remarks and valuable\
    \ suggestions.\n\n# **Conflict of Interest**\n\nOn behalf of all authors, the\
    \ corresponding author states that there is no conflict of interest.\n\n# **Data\
    \ availability**\n\nNo data was used for the research described in the article.\n\
    \n<span id=\"page-39-2\"></span>\n\n| Table 6          |\n|------------------|\n\
    | List of Acronyms |\n\n| Abbreviation | Description                         \
    \     |\n|--------------|------------------------------------------|\n| PCs  \
    \        | Personal Computers                       |\n| DNS          | Domain\
    \ Name System                       |\n| MPP          | Massive Parallel Processing\
    \              |\n| AI           | Artificial Intelligence                  |\n\
    | SMP          | Symmetric Multi Processing               |\n| OS           |\
    \ Operating System                         |\n| GUI          | Graphical User\
    \ Interfaces                |\n| IoT          | Internet of Things           \
    \            |\n| HTTP         | Hyper Text Transport Protocol            |\n\
    | HTML         | Hyper Text Markup Language               |\n| WWW          |\
    \ World Wide Web                           |\n| RPC          | Remote Procedure\
    \ Calls                   |\n| JSON         | JavaScript Object Notation     \
    \          |\n| XML          | Extensible Markup Language               |\n| SOA\
    \          | Service-Oriented Architecture            |\n| CDC          | Cloud\
    \ Data Centers                       |\n| HPC          | High Performance Computing\
    \               |\n| IT           | Information Technology                   |\n\
    | SaaS         | Software as a Service                    |\n| PaaS         |\
    \ Platform as a Service                    |\n| IaaS         | Infrastructure\
    \ as a Service              |\n| SBC          | Single-board Computers       \
    \            |\n| SDN          | Software-Defined Networking              |\n\
    | NVF          | Network Function Virtualization          |\n| IIoT         |\
    \ Industrial Internet of Things            |\n| QoS          | Quality of Service\
    \                       |\n| IoE          | Internet of Energy               \
    \        |\n| B5G          | Beyond 5G                                |\n| SLA\
    \          | Service-Level Agreement                  |\n| FPGA         | Field-Programmable\
    \ Gate Arrays           |\n| ASICs        | Application-Specific Integrated Circuits\
    \ |\n| GPU          | Graphics Processing Units                |\n| CUDA     \
    \    | Compute Unified Device Architecture      |\n| TPU          | Tensor Processing\
    \ Units                  |\n| ICT          | Information and Communication Technology\
    \ |\n| CaaS         | Container as a Service                   |\n| QoE      \
    \    | Quality of Experience                    |\n| V2X          | Vehicle-to-Everything\
    \                    |\n| MEC          | Multi-access Edge Computing         \
    \     |\n| VM           | Virtual Machines                         |\n| M2M  \
    \        | Machine-to-Machine                       |\n| PoW          | Proof\
    \ of Work                            |\n| XAI          | Explainable Artificial\
    \ Intelligence      |\n| UAV          | Unmanned Aerial Vehicle              \
    \    |\n| DDoS         | Distributed Denial of Service            |\n| STCO  \
    \       | Systems-Technology Co-Optimisation       |\n| SoC          | System-on-a-Chip\
    \                         |\n| ML           | Machine Learning               \
    \          |\n| SLO          | Service Level Objective                  |\n\n\
    # **Appendix A. List of Acronyms**\n\nTable [6](#page-39-2) shows the list of\
    \ acronyms.\n\n#### **References**\n\n<span id=\"page-39-0\"></span>[1] R. Buyya\
    \ *et al.*, \"A manifesto for future generation cloud computing: Research directions\
    \ for the next decade,\" *ACM Computing Surveys* *(CSUR)*, vol. 51, no. 5, pp.\
    \ 1–38, 2018.\n\n- <span id=\"page-40-0\"></span>[2] D. Lindsay *et al.*, \"The\
    \ evolution of distributed computing systems: from fundamental to new frontiers,\"\
    \ *Computing*, vol. 103, no. 8, pp. 1859–1878, 2021.\n- <span id=\"page-40-1\"\
    ></span>[3] R. Yamashita, \"History of personal computers in japan,\" *International\
    \ Journal of Parallel, Emergent and Distributed Systems*, vol. 35, no. 2, pp.\
    \ 143–169, 2020.\n- <span id=\"page-40-2\"></span>[4] S. S. Gill *et al.*, \"\
    Ai for next generation computing: Emerging trends and future directions,\" *Internet\
    \ of Things*, vol. 19, p. 100514, 2022.\n- <span id=\"page-40-3\"></span>[5] J.\
    \ Gubbi *et al.*, \"Internet of things (iot): A vision, architectural elements,\
    \ and future directions,\" *Future Generation Computer Systems*, vol. 29, no.\
    \ 7, pp. 1645–1660, 2013.\n- <span id=\"page-40-4\"></span>[6] R. Muralidhar *et\
    \ al.*, \"Energy efficient computing systems: Architectures, abstractions and\
    \ modeling to techniques and standards,\" *ACM Computing Surveys (CSUR)*, vol.\
    \ 54, no. 11s, pp. 1–37, 2022.\n- <span id=\"page-40-5\"></span>[7] A. Chakraborty\
    \ *et al.*, \"Journey from cloud of things to fog of things: Survey, new trends,\
    \ and research directions,\" *Software: Practice and Experience*, vol. 53, no.\
    \ 2, pp. 496–551, 2023.\n- <span id=\"page-40-6\"></span>[8] A. Beloglazov *et\
    \ al.*, \"Energy-aware resource allocation heuristics for efficient management\
    \ of data centers for cloud computing,\" *Future Generation Computer Systems*,\
    \ vol. 28, no. 5, pp. 755–768, 2012.\n- <span id=\"page-40-7\"></span>[9] V. Casamayor\
    \ Pujol *et al.*, \"Fundamental research challenges for distributed computing\
    \ continuum systems,\" *Information*, vol. 14, no. 3, p. 198, 2023.\n- <span id=\"\
    page-40-8\"></span>[10] J. Shalf, \"The future of computing beyond moore's law,\"\
    \ *Philosophical Transactions of the Royal Society A*, vol. 378, no. 2166, p.\
    \ 20190061, 2020.\n- <span id=\"page-40-9\"></span>[11] N. A. Angel *et al.*,\
    \ \"Recent advances in evolving computing paradigms: Cloud, edge, and fog technologies,\"\
    \ *Sensors*, vol. 22, no. 1, p. 196, 2021.\n- <span id=\"page-40-10\"></span>[12]\
    \ B. P. Rimal *et al.*, \"A taxonomy and survey of cloud computing systems,\"\
    \ in *2009 fifth international joint conference on INC, IMS and IDC*, pp. 44–51,\
    \ IEEE, 2009.\n- <span id=\"page-40-11\"></span>[13] S. S. Gill *et al.*, \"Transformative\
    \ effects of IoT, blockchain and artificial intelligence on cloud computing: Evolution,\
    \ vision, trends and open challenges,\" *Internet of Things*, vol. 8, p. 100118,\
    \ 2019.\n- <span id=\"page-40-12\"></span>[14] M. J. Flynn, \"Very high-speed\
    \ computing systems,\" *Proceedings of the IEEE*, vol. 54, no. 12, pp. 1901–1909,\
    \ 1966.\n- <span id=\"page-40-13\"></span>[15] C. E. Kozyrakis *et al.*, \"A new\
    \ direction for computer architecture research,\" *Computer*, vol. 31, no. 11,\
    \ pp. 24–32, 1998.\n- <span id=\"page-40-14\"></span>[16] T. L. Casavant *et al.*,\
    \ \"A taxonomy of scheduling in general-purpose distributed computing systems,\"\
    \ *IEEE Transactions on software engineering*, vol. 14, no. 2, pp. 141–154, 1988.\n\
    - <span id=\"page-40-15\"></span>[17] J. Yu *et al.*, \"A taxonomy of workflow\
    \ management systems for grid computing,\" *Journal of grid computing*, vol. 3,\
    \ pp. 171–200, 2005.\n- <span id=\"page-40-16\"></span>[18] J. D. Owens *et al.*,\
    \ \"GPU computing,\" *Proceedings of the IEEE*, vol. 96, no. 5, pp. 879–899, 2008.\n\
    - <span id=\"page-40-17\"></span>[19] K. Compton *et al.*, \"Reconfigurable computing:\
    \ a survey of systems and software,\" *ACM Computing Surveys (csuR)*, vol. 34,\
    \ no. 2, pp. 171–210, 2002.\n- <span id=\"page-40-18\"></span>[20] S. Wright,\
    \ \"Cybersquatting at the intersection of internet domain names and trademark\
    \ law,\" *IEEE Communications Surveys & Tutorials*, vol. 14, no. 1, pp. 193–205,\
    \ 2010.\n- <span id=\"page-40-19\"></span>[21] B. J. Jansen, \"The graphical user\
    \ interface,\" *ACM SIGCHI Bulletin*, vol. 30, no. 2, pp. 22–26, 1998.\n- <span\
    \ id=\"page-40-20\"></span>[22] B. H. Tay *et al.*, \"A survey of remote procedure\
    \ calls,\" *ACM SIGOPS Operating Systems Review*, vol. 24, no. 3, pp. 68–79, 1990.\n\
    - <span id=\"page-40-21\"></span>[23] R. R. Suryono *et al.*, \"Peer to peer (p2p)\
    \ lending problems and potential solutions: A systematic literature review,\"\
    \ *Procedia Computer Science*, vol. 161, pp. 204–214, 2019.\n- <span id=\"page-40-22\"\
    ></span>[24] R. Schollmeier *et al.*, \"Protocol for peer-to-peer networking in\
    \ mobile environments,\" in *Proceedings. 12th International Conference on Computer\
    \ Communications and Networks (IEEE Cat. No. 03EX712)*, pp. 121–127, IEEE, 2003.\n\
    - <span id=\"page-40-23\"></span>[25] G. Alonso *et al.*, *Web services*. Springer,\
    \ 2004.\n- <span id=\"page-40-24\"></span>[26] R. Perrey *et al.*, \"Service-oriented\
    \ architecture,\" in *2003 Symposium on Applications and the Internet Workshops,\
    \ 2003. Proceedings.*,\n\npp. 116–119, IEEE, 2003.\n\n- <span id=\"page-40-25\"\
    ></span>[27] V. Maffione *et al.*, \"A software development kit to exploit rina\
    \ programmability,\" in *2016 IEEE International Conference on Communications\
    \ (ICC)*, pp. 1–7, IEEE, 2016.\n- <span id=\"page-40-26\"></span>[28] L. Resende,\
    \ \"Handling heterogeneous data sources in a soa environment with service data\
    \ objects (sdo),\" in *Proceedings of the 2007 ACM SIGMOD international conference\
    \ on Management of data*, pp. 895–897, 2007.\n- <span id=\"page-40-27\"></span>[29]\
    \ M. F. Mergen *et al.*, \"Virtualization for high-performance computing,\" *ACM\
    \ SIGOPS Operating Systems Review*, vol. 40, no. 2, pp. 8– 11, 2006.\n- <span\
    \ id=\"page-40-28\"></span>[30] J. O. Kephart *et al.*, \"The vision of autonomic\
    \ computing,\" *Computer*, vol. 36, no. 1, pp. 41–50, 2003.\n- <span id=\"page-40-29\"\
    ></span>[31] S. Singh *et al.*, \"Star: Sla-aware autonomic management of cloud\
    \ resources,\" *IEEE Transactions on Cloud Computing*, vol. 8, no. 4, pp. 1040–1053,\
    \ 2017.\n- <span id=\"page-40-30\"></span>[32] M. Othman *et al.*, \"A survey\
    \ of mobile cloud computing application models,\" *IEEE communications surveys\
    \ & tutorials*, vol. 16, no. 1, pp. 393–413, 2013.\n- <span id=\"page-40-31\"\
    ></span>[33] A. S. AlAhmad *et al.*, \"Mobile cloud computing models security\
    \ issues: A systematic review,\" *Journal of Network and Computer Applications*,\
    \ vol. 190, p. 103152, 2021.\n- <span id=\"page-40-32\"></span>[34] M. H. Anwar\
    \ *et al.*, \"Recommender system for optimal distributed deep learning in cloud\
    \ datacenters,\" *Wireless Personal Communications*, pp. 1–25, 2022.\n- <span\
    \ id=\"page-40-33\"></span>[35] F. Durao *et al.*, \"A systematic review on cloud\
    \ computing,\" *The Journal of Supercomputing*, vol. 68, pp. 1321–1346, 2014.\n\
    - <span id=\"page-40-34\"></span>[36] S. S. Gill *et al.*, \"ROUTER: Fog enabled\
    \ cloud based intelligent resource management approach for smart home iot devices,\"\
    \ *Journal of Systems and Software*, vol. 154, pp. 125–138, 2019.\n- <span id=\"\
    page-40-35\"></span>[37] S. Iftikhar *et al.*, \"Ai-based fog and edge computing:\
    \ A systematic review, taxonomy and future directions,\" *Internet of Things*,\
    \ p. 100674, 2022.\n- <span id=\"page-40-36\"></span>[38] S. S. Gill *et al.*,\
    \ \"Fog-based smart healthcare as a big data and cloud service for heart patients\
    \ using IoT,\" in *International Conference on Intelligent Data Communication\
    \ Technologies and Internet of Things (ICICI) 2018*, pp. 1376–1383, Springer,\
    \ 2019.\n- <span id=\"page-40-37\"></span>[39] J. Singh *et al.*, \"Fog computing:\
    \ A taxonomy, systematic review, current trends and research challenges,\" *Journal\
    \ of Parallel and Distributed Computing*, vol. 157, pp. 56–85, 2021.\n- <span\
    \ id=\"page-40-38\"></span>[40] W. Shi *et al.*, \"Edge computing: Vision and\
    \ challenges,\" *IEEE Internet of Things journal*, vol. 3, no. 5, pp. 637–646,\
    \ 2016.\n- <span id=\"page-40-39\"></span>[41] G. K. Walia *et al.*, \"Ai-empowered\
    \ fog/edge resource management for iot applications: A comprehensive review, research\
    \ challenges and future perspectives,\" *IEEE Communications Surveys & Tutorials*,\
    \ vol. 26, no. 1, pp. 1–56, 2023.\n- <span id=\"page-40-40\"></span>[42] W. Z.\
    \ Khan *et al.*, \"Edge computing: A survey,\" *Future Generation Computer Systems*,\
    \ vol. 97, pp. 219–235, 2019.\n- <span id=\"page-40-41\"></span>[43] E. Jonas\
    \ *et al.*, \"Cloud programming simplified: A berkeley view on serverless computing,\"\
    \ *arXiv preprint arXiv:1902.03383*, 2019.\n- <span id=\"page-40-42\"></span>[44]\
    \ H. B. Hassan *et al.*, \"Survey on serverless computing,\" *Journal of Cloud\
    \ Computing*, vol. 10, no. 1, pp. 1–29, 2021.\n- <span id=\"page-40-43\"></span>[45]\
    \ A. Buzachis *et al.*, \"Modeling and emulation of an osmotic computing ecosystem\
    \ using osmotictoolkit,\" in *Proceedings of the 2021 Australasian Computer Science\
    \ Week Multiconference*, pp. 1–9, 2021.\n- <span id=\"page-40-44\"></span>[46]\
    \ B. Neha *et al.*, \"A systematic review on osmotic computing,\" *ACM Transactions\
    \ on Internet of Things*, vol. 3, no. 2, pp. 1–30, 2022.\n- <span id=\"page-40-45\"\
    ></span>[47] P. P. Ray, \"An introduction to dew computing: definition, concept\
    \ and implications,\" *IEEE Access*, vol. 6, pp. 723–737, 2017.\n- <span id=\"\
    page-40-46\"></span>[48] M. Gushev, \"Dew computing architecture for cyber-physical\
    \ systems and IoT,\" *Internet of things*, vol. 11, p. 100186, 2020.\n- <span\
    \ id=\"page-40-47\"></span>[49] Y. Qu *et al.*, \"A blockchained federated learning\
    \ framework for cognitive computing in industry 4.0 networks,\" *IEEE Transactions\
    \ on Industrial Informatics*, vol. 17, no. 4, pp. 2964–2973, 2020.\n- <span id=\"\
    page-40-48\"></span>[50] T. Kovachy *et al.*, \"Quantum superposition at the half-metre\
    \ scale,\" *Nature*, vol. 528, no. 7583, pp. 530–533, 2015.\n- <span id=\"page-41-0\"\
    ></span>[51] S. S. Gill *et al.*, \"Quantum computing: A taxonomy, systematic\
    \ review and future directions,\" *Software: Practice and Experience*, vol. 52,\
    \ no. 1, pp. 66–114, 2022.\n- <span id=\"page-41-1\"></span>[52] S. R. Gulliver\
    \ *et al.*, \"Pervasive and standalone computing: the perceptual effects of variable\
    \ multimedia quality,\" *International journal of human-computer studies*, vol.\
    \ 60, no. 5-6, pp. 640–665, 2004.\n- <span id=\"page-41-2\"></span>[53] S. Ravi\
    \ *et al.*, \"Security in embedded systems: Design challenges,\" *ACM Transactions\
    \ on Embedded Computing Systems (TECS)*, vol. 3, no. 3, pp. 461–491, 2004.\n-\
    \ <span id=\"page-41-3\"></span>[54] L. De Micco *et al.*, \"A literature review\
    \ on embedded systems,\" *IEEE Latin America Transactions*, vol. 18, no. 02, pp.\
    \ 188–205, 2019.\n- <span id=\"page-41-4\"></span>[55] P. J. Basford *et al.*,\
    \ \"Performance analysis of single board computer clusters,\" *Future Generation\
    \ Computer Systems*, vol. 102, pp. 278– 291, 2020.\n- <span id=\"page-41-5\"></span>[56]\
    \ A. Pajankar, \"Raspberry pi supercomputing and scientific programming,\" *Ashwin\
    \ Pajankar*, 2017.\n- <span id=\"page-41-6\"></span>[57] T. Hwu *et al.*, \"A\
    \ self-driving robot using deep convolutional neural networks on neuromorphic\
    \ hardware,\" in *2017 International Joint Conference on Neural Networks (IJCNN)*,\
    \ pp. 635–641, IEEE, 2017.\n- <span id=\"page-41-7\"></span>[58] A. A. Süzen *et\
    \ al.*, \"Benchmark analysis of jetson tx2, jetson nano and raspberry pi using\
    \ deep-cnn,\" in *2020 International Congress on Human-Computer Interaction, Optimization\
    \ and Robotic Applications (HORA)*, pp. 1–5, IEEE, 2020.\n- <span id=\"page-41-8\"\
    ></span>[59] A. Kumar *et al.*, \"Securing the future internet of things with\
    \ postquantum cryptography,\" *Security and Privacy*, vol. 5, no. 2, p. e200,\
    \ 2022.\n- <span id=\"page-41-9\"></span>[60] J. Ren *et al.*, \"A survey on end-edge-cloud\
    \ orchestrated network computing paradigms: Transparent computing, mobile edge\
    \ computing, fog computing, and cloudlet,\" *ACM Computing Surveys (CSUR)*, vol.\
    \ 52, no. 6, pp. 1–36, 2019.\n- <span id=\"page-41-10\"></span>[61] C. Wang *et\
    \ al.*, \"Integration of networking, caching, and computing in wireless systems:\
    \ A survey, some research issues, and challenges,\" *IEEE Communications Surveys\
    \ & Tutorials*, vol. 20, no. 1, pp. 7–38, 2017.\n- <span id=\"page-41-11\"></span>[62]\
    \ J. Z. Ahmadabadi *et al.*, \"Star-quake: A new operator in multiobjective gravitational\
    \ search algorithm for task scheduling in iot based cloud-fog computing system,\"\
    \ *IEEE Transactions on Consumer Electronics*, 2023.\n- <span id=\"page-41-12\"\
    ></span>[63] M. Maray *et al.*, \"Computation offloading in mobile cloud computing\
    \ and mobile edge computing: survey, taxonomy, and open issues,\" *Mobile Information\
    \ Systems*, vol. 2022, 2022.\n- <span id=\"page-41-13\"></span>[64] M. F. Bari\
    \ *et al.*, \"On orchestrating virtual network functions,\" in *2015 11th international\
    \ conference on network and service management (CNSM)*, pp. 50–56, IEEE, 2015.\n\
    - <span id=\"page-41-14\"></span>[65] Y. Cai *et al.*, \"Compute-and data-intensive\
    \ networks: The key to the metaverse,\" in *2022 1st International Conference\
    \ on 6G Networking (6GNet)*, pp. 1–8, IEEE, 2022.\n- <span id=\"page-41-15\"></span>[66]\
    \ E. Al-Masri *et al.*, \"Energy-efficient cooperative resource allocation and\
    \ task scheduling for internet of things environments,\" *Internet of Things*,\
    \ vol. 23, p. 100832, 2023.\n- <span id=\"page-41-16\"></span>[67] M. Sriraghavendra\
    \ *et al.*, \"Dosp: A deadline-aware dynamic service placement algorithm for workflow-oriented\
    \ iot applications in fogcloud computing environments,\" *Energy Conservation\
    \ Solutions for Fog-Edge Computing Paradigms*, pp. 21–47, 2022.\n- <span id=\"\
    page-41-17\"></span>[68] P. Verma *et al.*, \"Fcmcps-covid: Ai propelled fog–cloud\
    \ inspired scalable medical cyber-physical system, specific to coronavirus disease,\"\
    \ *Internet of Things*, vol. 23, p. 100828, 2023.\n- <span id=\"page-41-18\"></span>[69]\
    \ F. Desai *et al.*, \"Healthcloud: A system for monitoring health status of heart\
    \ patients using machine learning and cloud computing,\" *Internet of Things*,\
    \ vol. 17, p. 100485, 2022.\n- <span id=\"page-41-19\"></span>[70] S. Iftikhar\
    \ *et al.*, \"Fogdlearner: A deep learning-based cardiac health diagnosis framework\
    \ using fog computing,\" in *Proceedings of the 2022 Australasian Computer Science\
    \ Week*, pp. 136–144, ACM, 2022.\n- <span id=\"page-41-20\"></span>[71] S. S.\
    \ Gill *et al.*, \"IoT based agriculture as a cloud and big data service: the\
    \ beginning of digital india,\" *Journal of Organizational and End User Computing\
    \ (JOEUC)*, vol. 29, no. 4, pp. 1–23, 2017.\n- <span id=\"page-41-21\"></span>[72]\
    \ A. Sengupta *et al.*, \"Mobile edge computing based internet of agricultural\
    \ things: a systematic review and future directions,\" *Mobile Edge Computing*,\
    \ pp. 415–441, 2021.\n- <span id=\"page-41-22\"></span>[73] S. Iftikhar *et al.*,\
    \ \"Fog computing based router-distributor application for sustainable smart home,\"\
    \ in *2022 IEEE 95th Vehicular Technology Conference:(VTC2022-Spring)*, pp. 1–5,\
    \ IEEE, 2022.\n- <span id=\"page-41-23\"></span>[74] K. Bansal *et al.*, \"Deepbus:\
    \ Machine learning based real time pothole detection system for smart transportation\
    \ using iot,\" *Internet Technology Letters*, vol. 3, no. 3, p. e156, 2020.\n\
    - <span id=\"page-41-24\"></span>[75] S. Tuli *et al.*, \"ithermofog: Iot-fog\
    \ based automatic thermal profile creation for cloud data centers using artificial\
    \ intelligence techniques,\" *Internet Technology Letters*, vol. 3, no. 5, p.\
    \ e198, 2020.\n- <span id=\"page-41-25\"></span>[76] M. Singh *et al.*, \"Quantum\
    \ artificial intelligence for the science of climate change,\" in *Artificial\
    \ Intelligence, Machine Learning and Blockchain in Quantum Satellite, Drone and\
    \ Network*, pp. 199–207, CRC Press, 2022.\n- <span id=\"page-41-26\"></span>[77]\
    \ M. Singh *et al.*, \"Quantifying covid-19 enforced global changes in atmospheric\
    \ pollutants using cloud computing based remote sensing,\" *Remote Sensing Applications:\
    \ Society and Environment*, vol. 22, p. 100489, 2021.\n- <span id=\"page-41-27\"\
    ></span>[78] M. Stoyanova *et al.*, \"A survey on the internet of things (iot)\
    \ forensics: challenges, approaches, and open issues,\" *IEEE Communications Surveys\
    \ & Tutorials*, vol. 22, no. 2, pp. 1191–1221, 2020.\n- <span id=\"page-41-28\"\
    ></span>[79] N. Mansouri *et al.*, \"Cloud computing simulators: A comprehensive\
    \ review,\" *Simulation Modelling Practice and Theory*, vol. 104, p. 102144, 2020.\n\
    - <span id=\"page-41-29\"></span>[80] S. Tuli *et al.*, \"Healthfog: An ensemble\
    \ deep learning based smart healthcare system for automatic diagnosis of heart\
    \ diseases in integrated IoT and fog computing environments,\" *Future Generation\
    \ Computer Systems*, vol. 104, pp. 187–200, 2020.\n- <span id=\"page-41-30\"></span>[81]\
    \ S. S. Gill *et al.*, \"Chatgpt: Vision and challenges,\" *Internet of Things\
    \ and Cyber-Physical Systems*, vol. 3, pp. 262–271, 2023.\n- <span id=\"page-41-31\"\
    ></span>[82] M. Vila *et al.*, \"Edge-to-cloud sensing and actuation semantics\
    \ in the industrial Internet of Things,\" *Pervasive and Mobile Computing*, vol.\
    \ 87, p. 101699, Dec. 2022.\n- <span id=\"page-41-32\"></span>[83] D. Kreutz *et\
    \ al.*, \"Software-defined networking: A comprehensive survey,\" *Proceedings\
    \ of the IEEE*, vol. 103, no. 1, pp. 14–76, 2014.\n- <span id=\"page-41-33\"></span>[84]\
    \ T. Mekki *et al.*, \"Software-defined networking in vehicular networks: A survey,\"\
    \ *Transactions on Emerging Telecommunications Technologies*, vol. 33, no. 10,\
    \ p. e4265, 2022.\n- <span id=\"page-41-34\"></span>[85] J. Son *et al.*, \"A\
    \ taxonomy of software-defined networking (sdn) enabled cloud computing,\" *ACM\
    \ computing surveys (CSUR)*, vol. 51, no. 3, pp. 1–36, 2018.\n- <span id=\"page-41-35\"\
    ></span>[86] L. Poutievski *et al.*, \"Jupiter evolving: transforming google's\
    \ datacenter network via optical circuit switches and software-defined networking,\"\
    \ in *Proceedings of the ACM SIGCOMM 2022 Conference*, pp. 66–85, 2022.\n- <span\
    \ id=\"page-41-36\"></span>[87] A. Kumar *et al.*, \"A secure drone-to-drone communication\
    \ and software defined drone network-enabled traffic monitoring system,\" *Simulation\
    \ Modelling Practice and Theory*, vol. 120, p. 102621, 2022.\n- <span id=\"page-41-37\"\
    ></span>[88] X. Wang *et al.*, \"Convergence of edge computing and deep learning:\
    \ A comprehensive survey,\" *IEEE Communications Surveys & Tutorials*, vol. 22,\
    \ no. 2, pp. 869–904, 2020.\n- <span id=\"page-41-38\"></span>[89] J. Zhang *et\
    \ al.*, \"Mobile edge intelligence and computing for the internet of vehicles,\"\
    \ *Proceedings of the IEEE*, vol. 108, no. 2, pp. 246–261, 2019.\n- <span id=\"\
    page-41-39\"></span>[90] S. Chen *et al.*, \"Internet of things based smart grids\
    \ supported by intelligent edge computing,\" *IEEE Access*, vol. 7, pp. 74089–74102,\
    \ 2019.\n- <span id=\"page-41-40\"></span>[91] V. C. Pujol *et al.*, \"Edge intelligence—research\
    \ opportunities for distributed computing continuum systems,\" *IEEE Internet\
    \ Computing*, vol. 27, no. 4, pp. 53–74, 2023.\n- <span id=\"page-41-41\"></span>[92]\
    \ R. Singh *et al.*, \"Edge ai: a survey,\" *Internet of Things and Cyber-Physical\
    \ Systems*, 2023.\n- <span id=\"page-41-42\"></span>[93] Y. Jia *et al.*, \"Flowguard:\
    \ An intelligent edge defense mechanism against IoT DDoS attacks,\" *IEEE Internet\
    \ of Things Journal*, vol. 7, no. 10, pp. 9552–9562, 2020.\n- <span id=\"page-42-0\"\
    ></span>[94] B. Yang *et al.*, \"Edge intelligence for autonomous driving in 6g\
    \ wireless system: Design challenges and solutions,\" *IEEE Wireless Communications*,\
    \ vol. 28, no. 2, pp. 40–47, 2021.\n- <span id=\"page-42-1\"></span>[95] F. Liu\
    \ *et al.*, \"Integrated sensing and communications: Toward dualfunctional wireless\
    \ networks for 6g and beyond,\" *IEEE journal on selected areas in communications*,\
    \ vol. 40, no. 6, pp. 1728–1767, 2022.\n- <span id=\"page-42-2\"></span>[96] M.\
    \ Ishtiaq *et al.*, \"Edge computing in iot: A 6g perspective,\" *arXiv preprint\
    \ arXiv:2111.08943*, 2021.\n- <span id=\"page-42-3\"></span>[97] A. Kumar *et\
    \ al.*, \"A drone-based networked system and methods for combating coronavirus\
    \ disease (covid-19) pandemic,\" *Future Generation Computer Systems*, vol. 115,\
    \ pp. 1–19, 2021.\n- <span id=\"page-42-4\"></span>[98] Y. Shi *et al.*, \"Machine\
    \ learning for large-scale optimization in 6g wireless networks,\" *IEEE Communications\
    \ Surveys & Tutorials*, 2023.\n- <span id=\"page-42-5\"></span>[99] A. Alkhateeb\
    \ *et al.*, \"Real-time digital twins: Vision and research directions for 6G and\
    \ beyond,\" *IEEE Communications Magazine*, 2023.\n- <span id=\"page-42-6\"></span>[100]\
    \ S. A. Ansar *et al.*, \"Intelligent Fog-IoT Networks with 6G endorsement: Foundations,\
    \ applications, trends and challenges,\" *6G Enabled Fog Computing in IoT: Applications\
    \ and Opportunities*, pp. 287– 307, 2023.\n- <span id=\"page-42-7\"></span>[101]\
    \ I. F. Akyildiz *et al.*, \"6G and beyond: The future of wireless communications\
    \ systems,\" *IEEE Access*, vol. 8, pp. 133995–134030, 2020.\n- <span id=\"page-42-8\"\
    ></span>[102] S. Ghafouri *et al.*, \"Mobile-kube: Mobility-aware and energyefficient\
    \ service orchestration on kubernetes edge servers,\" in *2022 IEEE/ACM 15th International\
    \ Conference on Utility and Cloud Computing (UCC)*, pp. 82–91, IEEE, 2022.\n-\
    \ <span id=\"page-42-9\"></span>[103] H. Wu *et al.*, \"Energy-efficient decision\
    \ making for mobile cloud offloading,\" *IEEE Transactions on Cloud Computing*,\
    \ vol. 8, no. 2, pp. 570–584, 2020.\n- <span id=\"page-42-10\"></span>[104] H.\
    \ Wu *et al.*, \"Lyapunov-Guided Delay-Aware Energy Efficient Offloading in IIoT-MEC\
    \ Systems,\" *IEEE Transactions on Industrial Informatics*, vol. 19, no. 2, pp.\
    \ 2117–2128, 2023.\n- <span id=\"page-42-11\"></span>[105] J. D. Owens *et al.*,\
    \ \"A survey of general-purpose computation on graphics hardware,\" *Computer\
    \ graphics forum*, vol. 26, no. 1, pp. 80– 113, 2007.\n- <span id=\"page-42-12\"\
    ></span>[106] J. Von Neumann, *John von Neumann: selected letters*, vol. 27. American\
    \ Mathematical Soc., 2005.\n- <span id=\"page-42-13\"></span>[107] D. Kimovski\
    \ *et al.*, \"Beyond von neumann in the computing continuum: Architectures, applications,\
    \ and future directions,\" *IEEE Internet Computing*, 2023.\n- <span id=\"page-42-14\"\
    ></span>[108] R. Yang *et al.*, \"Integrated blockchain and edge computing systems:\
    \ A survey, some research issues and challenges,\" *IEEE Communications Surveys\
    \ & Tutorials*, vol. 21, no. 2, pp. 1508–1532, 2019.\n- <span id=\"page-42-15\"\
    ></span>[109] S. H. Alsamhi *et al.*, \"Computing in the sky: A survey on intelligent\
    \ ubiquitous computing for uav-assisted 6g networks and industry 4.0/5.0,\" *Drones*,\
    \ vol. 6, no. 7, p. 177, 2022.\n- <span id=\"page-42-16\"></span>[110] J. Chen\
    \ *et al.*, \"Deep learning with edge computing: A review,\" *Proceedings of the\
    \ IEEE*, vol. 107, no. 8, pp. 1655–1674, 2019.\n- <span id=\"page-42-17\"></span>[111]\
    \ H. Singh *et al.*, \"Metaheuristics for scheduling of heterogeneous tasks in\
    \ cloud computing environments: Analysis, performance evaluation, and future directions,\"\
    \ *Simulation Modelling Practice and Theory*, vol. 111, p. 102353, 2021.\n- <span\
    \ id=\"page-42-18\"></span>[112] A. Botta *et al.*, \"Integration of cloud computing\
    \ and internet of things: a survey,\" *Future generation computer systems*, vol.\
    \ 56, pp. 684–700, 2016.\n- <span id=\"page-42-19\"></span>[113] F. Cappello *et\
    \ al.*, \"Computing on large-scale distributed systems: XtremWeb architecture,\
    \ programming models, security, tests and convergence with grid,\" *Future generation\
    \ computer systems*, vol. 21, no. 3, pp. 417–437, 2005.\n- <span id=\"page-42-20\"\
    ></span>[114] D. Andrews *et al.*, \"Achieving programming model abstractions\
    \ for reconfigurable computing,\" *IEEE transactions on very large scale integration\
    \ (VLSI) systems*, vol. 16, no. 1, pp. 34–44, 2007.\n- <span id=\"page-42-21\"\
    ></span>[115] J. C. Jackson *et al.*, \"Survey on programming models and environments\
    \ for cluster, cloud, and grid computing that defends big data,\" *Procedia Computer\
    \ Science*, vol. 50, pp. 517–523, 2015.\n- <span id=\"page-42-22\"></span>[116]\
    \ C. Cao *et al.*, \"A novel multi-objective programming model of relief distribution\
    \ for sustainable disaster supply chain in large-scale natural disasters,\" *Journal\
    \ of cleaner production*, vol. 174, pp. 1422– 1435, 2018.\n- <span id=\"page-42-23\"\
    ></span>[117] M. Butts *et al.*, \"A structural object programming model, architecture,\
    \ chip and tools for reconfigurable computing,\" in *15th Annual IEEE Symposium\
    \ on Field-Programmable Custom Computing Machines (FCCM 2007)*, pp. 55–64, IEEE,\
    \ 2007.\n- <span id=\"page-42-24\"></span>[118] X. Shen *et al.*, \"Holistic network\
    \ virtualization and pervasive network intelligence for 6g,\" *IEEE Communications\
    \ Surveys & Tutorials*, vol. 24, no. 1, pp. 1–30, 2021.\n- <span id=\"page-42-25\"\
    ></span>[119] S. Jin *et al.*, \"H-svm: Hardware-assisted secure virtual machines\
    \ under a vulnerable hypervisor,\" *IEEE Transactions on Computers*, vol. 64,\
    \ no. 10, pp. 2833–2846, 2015.\n- <span id=\"page-42-26\"></span>[120] Y. Mansouri\
    \ *et al.*, \"A review of edge computing: Features and resource virtualization,\"\
    \ *Journal of Parallel and Distributed Computing*, vol. 150, pp. 155–183, 2021.\n\
    - <span id=\"page-42-27\"></span>[121] J. Zhang *et al.*, \"Performance analysis\
    \ of 3d xpoint ssds in virtualized and non-virtualized environments,\" in *2018\
    \ IEEE 24th International Conference on Parallel and Distributed Systems (ICPADS)*,\
    \ pp. 1– 10, IEEE, 2018.\n- <span id=\"page-42-28\"></span>[122] I. Alam *et al.*,\
    \ \"A survey of network virtualization techniques for internet of things using\
    \ sdn and nfv,\" *ACM Computing Surveys (CSUR)*, vol. 53, no. 2, pp. 1–40, 2020.\n\
    - <span id=\"page-42-29\"></span>[123] Y. Xing *et al.*, \"Virtualization and\
    \ cloud computing,\" in *Future Wireless Networks and Information Systems: Volume\
    \ 1*, pp. 305–312, Springer, 2012.\n- <span id=\"page-42-30\"></span>[124] A.\
    \ Agache *et al.*, \"Firecracker: Lightweight virtualization for serverless applications,\"\
    \ in *17th USENIX symposium on networked systems design and implementation (NSDI\
    \ 20)*, pp. 419–434, 2020.\n- <span id=\"page-42-31\"></span>[125] G. Blake *et\
    \ al.*, \"A survey of multicore processors,\" *IEEE Signal Processing Magazine*,\
    \ vol. 26, no. 6, pp. 26–37, 2009.\n- <span id=\"page-42-32\"></span>[126] D.\
    \ Gizopoulos *et al.*, \"Architectures for online error detection and recovery\
    \ in multicore processors,\" in *2011 Design, Automation & Test in Europe*, pp.\
    \ 1–6, IEEE, 2011.\n- <span id=\"page-42-33\"></span>[127] R. Delgado *et al.*,\
    \ \"New insights into the real-time performance of a multicore processor,\" *IEEE\
    \ Access*, vol. 8, pp. 186199–186211, 2020.\n- <span id=\"page-42-34\"></span>[128]\
    \ M. Piattini *et al.*, \"Toward a quantum software engineering,\" *IT Professional*,\
    \ vol. 23, no. 1, pp. 62–66, 2021.\n- <span id=\"page-42-35\"></span>[129] E.-M.\
    \ Arvanitou *et al.*, \"Software engineering practices for scientific software\
    \ development: A systematic mapping study,\" *Journal of Systems and Software*,\
    \ vol. 172, p. 110848, 2021.\n- <span id=\"page-42-36\"></span>[130] R. R. Althar\
    \ *et al.*, \"The realist approach for evaluation of computational intelligence\
    \ in software engineering,\" *Innovations in Systems and Software Engineering*,\
    \ vol. 17, no. 1, pp. 17–27, 2021.\n- <span id=\"page-42-37\"></span>[131] M.\
    \ De Stefano *et al.*, \"Software engineering for quantum programming: How far\
    \ are we?,\" *Journal of Systems and Software*, vol. 190, p. 111326, 2022.\n-\
    \ <span id=\"page-42-38\"></span>[132] G. Sharma *et al.*, \"Applications of blockchain\
    \ in automated heavy vehicles: Yesterday, today, and tomorrow,\" in *Autonomous\
    \ and Connected Heavy Vehicle Technology*, pp. 81–93, Elsevier, 2022.\n- <span\
    \ id=\"page-42-39\"></span>[133] J. Al-Jaroodi *et al.*, \"Blockchain in industries:\
    \ A survey,\" *IEEE Access*, vol. 7, pp. 36500–36515, 2019.\n- <span id=\"page-42-40\"\
    ></span>[134] J. Doyle *et al.*, \"Blockchainbus: A lightweight framework for\
    \ secure virtual machine migration in cloud federations using blockchain,\" *Security\
    \ and Privacy*, vol. 5, no. 2, p. e197, 2022.\n- <span id=\"page-42-41\"></span>[135]\
    \ L. Jurado Perez *et al.*, \"Simulation of scalability in cloud-based iot reactive\
    \ systems leveraged on a wsan simulator and cloud computing technologies,\" *Applied\
    \ Sciences*, vol. 11, no. 4, p. 1804, 2021.\n- <span id=\"page-42-42\"></span>[136]\
    \ R. Buyya *et al.*, \"A strategy for advancing research and impact in new computing\
    \ paradigms,\" in *Green Mobile Cloud Computing*, pp. 297– 308, Springer, 2022.\n\
    - <span id=\"page-42-43\"></span>[137] C. Brady *et al.*, \"All roads lead to\
    \ computing: Making, participatory simulations, and social computing as pathways\
    \ to computer science,\" *IEEE Transactions on Education*, vol. 60, no. 1, pp.\
    \ 59–66, 2016.\n- <span id=\"page-42-44\"></span>[138] O. Ferraz *et al.*, \"\
    A survey on high-throughput non-binary ldpc decoders: Asic, fpga, and gpu architectures,\"\
    \ *IEEE Communications*\n\n*Surveys & Tutorials*, vol. 24, no. 1, pp. 524–556,\
    \ 2021.\n\n- <span id=\"page-43-0\"></span>[139] N. P. Jouppi *et al.*, \"A domain-specific\
    \ architecture for deep neural networks,\" *Communications of the ACM*, vol. 61,\
    \ no. 9, pp. 50–59, 2018.\n- <span id=\"page-43-1\"></span>[140] J. Cong *et al.*,\
    \ \"Customizable computing—from single chip to datacenters,\" *Proceedings of\
    \ the IEEE*, vol. 107, no. 1, pp. 185–203, 2018.\n- <span id=\"page-43-2\"></span>[141]\
    \ H. Ji *et al.*, \"Magnetic reconnection in the era of exascale computing and\
    \ multiscale experiments,\" *Nature Reviews Physics*, vol. 4, no. 4, pp. 263–282,\
    \ 2022.\n- <span id=\"page-43-3\"></span>[142] S. Heldens *et al.*, \"The landscape\
    \ of exascale research: A data-driven literature analysis,\" *ACM Computing Surveys\
    \ (CSUR)*, vol. 53, no. 2, pp. 1–43, 2020.\n- <span id=\"page-43-4\"></span>[143]\
    \ Y. Kim *et al.*, \"Evidence for the utility of quantum computing before fault\
    \ tolerance,\" *Nature*, vol. 618, no. 7965, pp. 500–505, 2023.\n- <span id=\"\
    page-43-5\"></span>[144] H. Anzt *et al.*, \"Preparing sparse solvers for exascale\
    \ computing,\" *Philosophical Transactions of the Royal Society A*, vol. 378,\
    \ no. 2166, p. 20190053, 2020.\n- <span id=\"page-43-6\"></span>[145] F. Zangeneh-Nejad\
    \ *et al.*, \"Analogue computing with metamaterials,\" *Nature Reviews Materials*,\
    \ vol. 6, no. 3, pp. 207–225, 2021.\n- <span id=\"page-43-7\"></span>[146] W.\
    \ Zhang *et al.*, \"Neuro-inspired computing chips,\" *Nature Electronics*, vol.\
    \ 3, no. 7, pp. 371–382, 2020.\n- <span id=\"page-43-8\"></span>[147] M. Zhao\
    \ *et al.*, \"Reliability of analog resistive switching memory for neuromorphic\
    \ computing,\" *Applied Physics Reviews*, vol. 7, no. 1, 2020.\n- <span id=\"\
    page-43-9\"></span>[148] A. Zador *et al.*, \"Catalyzing next-generation artificial\
    \ intelligence through neuroai,\" *Nature communications*, vol. 14, no. 1, p.\
    \ 1597, 2023.\n- <span id=\"page-43-10\"></span>[149] C. D. Schuman *et al.*,\
    \ \"Opportunities for neuromorphic computing algorithms and applications,\" *Nature\
    \ Computational Science*, vol. 2, no. 1, pp. 10–19, 2022.\n- <span id=\"page-43-11\"\
    ></span>[150] F. C. Morabito *et al.*, \"Advances in ai, neural networks, and\
    \ brain computing: An introduction,\" in *Artificial Intelligence in the Age of\
    \ Neural Networks and Brain Computing*, pp. 1–8, Elsevier, 2024.\n- <span id=\"\
    page-43-12\"></span>[151] V. Rosenfeld *et al.*, \"Query processing on heterogeneous\
    \ cpu/gpu systems,\" *ACM Computing Surveys (CSUR)*, vol. 55, no. 1, pp. 1–38,\
    \ 2022.\n- <span id=\"page-43-13\"></span>[152] J. Sanders *et al.*, *CUDA by\
    \ example: an introduction to generalpurpose GPU programming*. Addison-Wesley\
    \ Professional, 2010.\n- <span id=\"page-43-14\"></span>[153] S. Tuli *et al.*,\
    \ \"Predicting the growth and trend of COVID-19 pandemic using machine learning\
    \ and cloud computing,\" *Internet of things*, vol. 11, p. 100222, 2020.\n- <span\
    \ id=\"page-43-15\"></span>[154] L. E. Lwakatare *et al.*, \"Large-scale machine\
    \ learning systems in real-world industrial settings: A review of challenges and\
    \ solutions,\" *Information and software technology*, vol. 127, p. 106368, 2020.\n\
    - <span id=\"page-43-16\"></span>[155] M. Wang *et al.*, \"A survey on large-scale\
    \ machine learning,\" *IEEE Transactions on Knowledge and Data Engineering*, vol.\
    \ 34, no. 6, pp. 2574–2594, 2020.\n- <span id=\"page-43-17\"></span>[156] M. N.\
    \ Angenent *et al.*, \"Large-scale machine learning for business sector prediction,\"\
    \ in *Proceedings of the 35th Annual ACM Symposium on Applied Computing*, pp.\
    \ 1143–1146, 2020.\n- <span id=\"page-43-18\"></span>[157] R. Buyya *et al.*,\
    \ \"Cloud computing and emerging it platforms: Vision, hype, and reality for delivering\
    \ computing as the 5th utility,\" *Future Generation Computer Systems*, vol. 25,\
    \ no. 6, pp. 599–616, 2009.\n- <span id=\"page-43-19\"></span>[158] S. U. Malik\
    \ *et al.*, \"Effort: Energy efficient framework for offload communication in\
    \ mobile cloud computing,\" *Software: Practice and Experience*, vol. 51, no.\
    \ 9, pp. 1896–1909, 2021.\n- <span id=\"page-43-20\"></span>[159] X. Jin *et al.*,\
    \ \"A survey of research on computation offloading in mobile cloud computing,\"\
    \ *Wireless Networks*, vol. 28, no. 4, pp. 1563–1585, 2022.\n- <span id=\"page-43-21\"\
    ></span>[160] P. Patros *et al.*, \"Toward sustainable serverless computing,\"\
    \ *IEEE Internet Computing*, vol. 25, no. 6, pp. 42–50, 2021.\n- <span id=\"page-43-22\"\
    ></span>[161] M. Masdari *et al.*, \"Green cloud computing using proactive virtual\
    \ machine placement: challenges and issues,\" *Journal of Grid Computing*, vol.\
    \ 18, no. 4, pp. 727–759, 2020.\n- <span id=\"page-43-23\"></span>[162] S. S.\
    \ Gill *et al.*, \"A taxonomy and future directions for sustainable cloud computing:\
    \ 360 degree view,\" *ACM Computing Surveys*\n\n*(CSUR)*, vol. 51, no. 5, pp.\
    \ 1–33, 2018.\n\n- <span id=\"page-43-24\"></span>[163] W. Shu *et al.*, \"Research\
    \ on strong agile response task scheduling optimization enhancement with optimal\
    \ resource usage in green cloud computing,\" *Future Generation Computer Systems*,\
    \ vol. 124, pp. 12–20, 2021.\n- <span id=\"page-43-25\"></span>[164] Q. Zhou *et\
    \ al.*, \"Energy efficient algorithms based on vm consolidation for cloud computing:\
    \ comparisons and evaluations,\" in *2020 20th IEEE/ACM International Symposium\
    \ on Cluster, Cloud and Internet Computing (CCGRID)*, pp. 489–498, IEEE, 2020.\n\
    - <span id=\"page-43-26\"></span>[165] R. F. Mansour *et al.*, \"Design of cultural\
    \ emperor penguin optimizer for energy-efficient resource scheduling in green\
    \ cloud computing environment,\" *Cluster Computing*, vol. 26, no. 1, pp. 575–586,\
    \ 2023.\n- <span id=\"page-43-27\"></span>[166] M. Singh *et al.*, \"Dynamic shift\
    \ from cloud computing to industry 4.0: Eco-friendly choice or climate change\
    \ threat,\" in *IoT-based Intelligent Modelling for Environmental and Ecological\
    \ Engineering: IoT Next Generation EcoAgro Systems*, pp. 275–293, Springer, 2021.\n\
    - <span id=\"page-43-28\"></span>[167] W. Zeng *et al.*, \"Research on cloud storage\
    \ architecture and key technologies,\" in *Proceedings of the 2nd International\
    \ Conference on Interaction Sciences: Information Technology, Culture and Human*,\
    \ pp. 1044–1048, 2009.\n- <span id=\"page-43-29\"></span>[168] M. Hota *et al.*,\
    \ \"Leveraging cloud-native microservices architecture for high performance real-time\
    \ intra-day trading: A tutorial,\" *6G Enabled Fog Computing in IoT: Applications\
    \ and Opportunities*, pp. 111–129, 2023.\n- <span id=\"page-43-30\"></span>[169]\
    \ M. Kumar *et al.*, \"Qos-aware resource scheduling using whale optimization\
    \ algorithm for microservice applications,\" *Software: Practice and Experience*,\
    \ 2023.\n- <span id=\"page-43-31\"></span>[170] J. Ghofrani *et al.*, \"Challenges\
    \ of microservices architecture: A survey on the state of the practice.,\" *ZEUS*,\
    \ vol. 2018, pp. 1–8, 2018.\n- <span id=\"page-43-32\"></span>[171] C. Song *et\
    \ al.*, \"Chainsformer: A chain latency-aware resource provisioning approach for\
    \ microservices cluster,\" in *International Conference on Service-Oriented Computing*,\
    \ pp. 197–211, Springer, 2023.\n- <span id=\"page-43-33\"></span>[172] F. Al-Doghman\
    \ and Mothers, \"AI-enabled secure microservices in edge computing: Opportunities\
    \ and challenges,\" *IEEE Transactions on Services Computing*, 2022.\n- <span\
    \ id=\"page-43-34\"></span>[173] M. Xu *et al.*, \"Coscal: Multifaceted scaling\
    \ of microservices with reinforcement learning,\" *IEEE Transactions on Network\
    \ and Service Management*, vol. 19, no. 4, pp. 3995–4009, 2022.\n- <span id=\"\
    page-43-35\"></span>[174] O. Bentaleb *et al.*, \"Containerization technologies:\
    \ Taxonomies, applications and challenges,\" *The Journal of Supercomputing*,\
    \ vol. 78, no. 1, pp. 1144–1181, 2022.\n- <span id=\"page-43-36\"></span>[175]\
    \ A. Barbalace *et al.*, \"Edge computing: The case for heterogeneousisa container\
    \ migration,\" in *Proceedings of the 16th ACM SIG-PLAN/SIGOPS International Conference\
    \ on Virtual Execution Environments*, pp. 73–87, 2020.\n- <span id=\"page-43-37\"\
    ></span>[176] M. Golec *et al.*, \"Biosec: A biometric authentication framework\
    \ for secure and private communication among edge devices in IoT and industry\
    \ 4.0,\" *IEEE Consumer Electronics Magazine*, vol. 11, no. 2, pp. 51–56, 2020.\n\
    - <span id=\"page-43-38\"></span>[177] V. Struhár *et al.*, \"Real-time containers:\
    \ A survey,\" in *2nd Workshop on Fog Computing and the IoT (Fog-IoT 2020)*, Schloss\
    \ Dagstuhl-Leibniz-Zentrum für Informatik, 2020.\n- <span id=\"page-43-39\"></span>[178]\
    \ E. Casalicchio *et al.*, \"The state-of-the-art in container technologies: Application,\
    \ orchestration and security,\" *Concurrency and Computation: Practice and Experience*,\
    \ vol. 32, no. 17, p. e5668, 2020.\n- <span id=\"page-43-40\"></span>[179] Z.\
    \ Zhong *et al.*, \"A cost-efficient container orchestration strategy in kubernetes-based\
    \ cloud computing infrastructures with heterogeneous resources,\" *ACM Transactions\
    \ on Internet Technology (TOIT)*, vol. 20, no. 2, pp. 1–24, 2020.\n- <span id=\"\
    page-43-41\"></span>[180] V. Mallikarjunaradhya *et al.*, \"An overview of the\
    \ strategic advantages of AI-powered threat intelligence in the cloud,\" *Journal\
    \ of Science & Technology*, vol. 4, no. 4, pp. 1–12, 2023.\n- <span id=\"page-43-42\"\
    ></span>[181] P. Patros *et al.*, \"Investigating resource interference and scaling\
    \ on multitenant paas clouds,\" in *Proceedings of the 26th Annual International\
    \ Conference on Computer Science and Software Engineering*, pp. 166–177, 2016.\n\
    - <span id=\"page-44-0\"></span>[182] S. Kounev *et al.*, \"Toward a definition\
    \ for serverless computing,\" *Leibniz-Zentrum fur Informatik*, 2021.\n- <span\
    \ id=\"page-44-1\"></span>[183] H. Shafiei *et al.*, \"Serverless computing: a\
    \ survey of opportunities, challenges, and applications,\" *ACM Computing Surveys*,\
    \ vol. 54, no. 11s, pp. 1–32, 2022.\n- <span id=\"page-44-2\"></span>[184] M.\
    \ Golec *et al.*, \"Qos analysis for serverless computing using machine learning,\"\
    \ in *Serverless Computing: Principles and Paradigms*, pp. 175–192, Springer,\
    \ 2023.\n- <span id=\"page-44-3\"></span>[185] M. S. Aslanpour *et al.*, \"Serverless\
    \ edge computing: vision and challenges,\" in *Proceedings of the 2021 Australasian\
    \ Computer Science Week Multiconference*, pp. 1–10, 2021.\n- <span id=\"page-44-4\"\
    ></span>[186] Y. Li *et al.*, \"Serverless computing: state-of-the-art, challenges\
    \ and opportunities,\" *IEEE Transactions on Services Computing*, vol. 16, no.\
    \ 2, pp. 1522–1539, 2022.\n- <span id=\"page-44-5\"></span>[187] M. Kumar *et\
    \ al.*, \"Ai-based sustainable and intelligent offloading framework for iiot in\
    \ collaborative cloud-fog environments,\" *IEEE Transactions on Consumer Electronics*,\
    \ 2023.\n- <span id=\"page-44-6\"></span>[188] S. Iftikhar *et al.*, \"Tesco:\
    \ Multiple simulations based aiaugmented fog computing for qos optimization,\"\
    \ in *2022 IEEE Smartworld, Ubiquitous Intelligence & Computing, Scalable Computing\
    \ & Communications, Digital Twin, Privacy Computing, Metaverse, Autonomous & Trusted\
    \ Vehicles (SmartWorld/UIC/ScalCom/DigitalTwin/PriComp/Meta)*, pp. 2092–2099,\
    \ IEEE, 2022.\n- <span id=\"page-44-7\"></span>[189] F. Firouzi *et al.*, \"The\
    \ convergence and interplay of edge, fog, and cloud in the ai-driven internet\
    \ of things (iot),\" *Information Systems*, vol. 107, p. 101840, 2022.\n- <span\
    \ id=\"page-44-8\"></span>[190] Z. Cao *et al.*, \"Toward a systematic survey\
    \ for carbon neutral data centers,\" *IEEE Communications Surveys & Tutorials*,\
    \ vol. 24, no. 2, pp. 895–936, 2022.\n- <span id=\"page-44-9\"></span>[191] M.\
    \ A. B. Siddik *et al.*, \"The environmental footprint of data centers in the\
    \ united states,\" *Environmental Research Letters*, vol. 16, no. 6, p. 064017,\
    \ 2021.\n- <span id=\"page-44-10\"></span>[192] A. Senthilkumar *et al.*, \"Enhancement\
    \ of r600a vapour compression refrigeration system with mwcnt/tio2 hybrid nano\
    \ lubricants for net zero emissions building,\" *Sustainable Energy Technologies\
    \ and Assessments*, vol. 56, p. 103055, 2023.\n- <span id=\"page-44-11\"></span>[193]\
    \ T. A. Kurniawan *et al.*, \"Decarbonization in waste recycling industry using\
    \ digitalization to promote net-zero emissions and its implications on sustainability,\"\
    \ *Journal of environmental management*, vol. 338, p. 117765, 2023.\n- <span id=\"\
    page-44-12\"></span>[194] R. Wilkinson *et al.*, \"Environmental impacts of earth\
    \ observation data in the constellation and cloud computing era,\" *Science of\
    \ the Total Environment*, vol. 909, p. 168584, 2024.\n- <span id=\"page-44-13\"\
    ></span>[195] A. K. Bhardwaj *et al.*, \"Heart: Unrelated parallel machines problem\
    \ with precedence constraints for task scheduling in cloud computing using heuristic\
    \ and meta-heuristic algorithms,\" *Software: Practice and Experience*, vol. 50,\
    \ no. 12, pp. 2231–2251, 2020.\n- <span id=\"page-44-14\"></span>[196] G. C. Fox\
    \ *et al.*, *Parallel computing works!* Elsevier, 2014.\n- <span id=\"page-44-15\"\
    ></span>[197] H. Wu *et al.*, \"A multi-dimensional parametric study of variability\
    \ in multi-phase flow dynamics during geologic co2 sequestration accelerated with\
    \ machine learning,\" *Applied Energy*, vol. 287, p. 116580, 2021.\n- <span id=\"\
    page-44-16\"></span>[198] S. S. Gill, \"Quantum and blockchain based serverless\
    \ edge computing: A vision, model, new trends and future directions,\" *Internet\
    \ Technology Letters*, p. e275, 2021.\n- <span id=\"page-44-17\"></span>[199]\
    \ Z. M. Nayeri *et al.*, \"Application placement in fog computing with AI approach:\
    \ Taxonomy and a state of the art survey,\" *Journal of Network and Computer Applications*,\
    \ vol. 185, p. 103078, 2021.\n- <span id=\"page-44-18\"></span>[200] P. Patros\
    \ *et al.*, \"Rural ai: Serverless-powered federated learning for remote applications,\"\
    \ *IEEE Internet Computing*, vol. 27, no. 2, pp. 28–34, 2023.\n- <span id=\"page-44-19\"\
    ></span>[201] R. Mahmud *et al.*, \"Application management in fog computing environments:\
    \ A taxonomy, review and future directions,\" *ACM Computing Surveys (CSUR)*,\
    \ vol. 53, no. 4, pp. 1–43, 2020.\n- <span id=\"page-44-20\"></span>[202] A. Ruggeri\
    \ *et al.*, \"An innovative blockchain-based orchestrator for osmotic computing,\"\
    \ *Journal of Grid Computing*, vol. 20, pp. 1–17, 2022.\n- <span id=\"page-44-21\"\
    ></span>[203] S. S. Gill *et al.*, \"Secure: Self-protection approach in cloud\
    \ resource management,\" *IEEE Cloud Computing*, vol. 5, no. 1, pp. 60–72, 2018.\n\
    - <span id=\"page-44-22\"></span>[204] I. Ahammad *et al.*, \"A review on cloud,\
    \ fog, roof, and dew computing: IoT perspective,\" *International Journal of Cloud\
    \ Applications and Computing (IJCAC)*, vol. 11, no. 4, pp. 14–41, 2021.\n- <span\
    \ id=\"page-44-23\"></span>[205] Y. Mao *et al.*, \"A survey on mobile edge computing:\
    \ The communication perspective,\" *IEEE communications surveys & tutorials*,\
    \ vol. 19, no. 4, pp. 2322–2358, 2017.\n- <span id=\"page-44-24\"></span>[206]\
    \ Q. Luo *et al.*, \"Resource scheduling in edge computing: A survey,\" *IEEE\
    \ Communications Surveys & Tutorials*, vol. 23, no. 4, pp. 2131– 2165, 2021.\n\
    - <span id=\"page-44-25\"></span>[207] K. Cao *et al.*, \"An overview on edge\
    \ computing research,\" *IEEE Access*, vol. 8, pp. 85714–85728, 2020.\n- <span\
    \ id=\"page-44-26\"></span>[208] N. Kotsehub *et al.*, \"Flox: Federated learning\
    \ with faas at the edge,\" in *2022 IEEE 18th International Conference on e-Science\
    \ (e-Science)*, pp. 11–20, 2022.\n- <span id=\"page-44-27\"></span>[209] O. Almurshed\
    \ *et al.*, \"Adaptive edge-cloud environments for rural ai,\" in *2022 IEEE International\
    \ Conference on Services Computing (SCC)*, pp. 74–83, 2022.\n- <span id=\"page-44-28\"\
    ></span>[210] N. Abbas, Y. Zhang, A. Taherkordi, and T. Skeie, \"Mobile edge computing:\
    \ A survey,\" *IEEE Internet of Things Journal*, vol. 5, no. 1, pp. 450–465, 2017.\n\
    - <span id=\"page-44-29\"></span>[211] J. Du *et al.*, \"Computation energy efficiency\
    \ maximization for nomabased and wireless-powered mobile edge computing with backscatter\
    \ communication,\" *IEEE Transactions on Mobile Computing*, pp. 1–16, 2023.\n\
    - <span id=\"page-44-30\"></span>[212] P. Mach *et al.*, \"Mobile edge computing:\
    \ A survey on architecture and computation offloading,\" *IEEE communications\
    \ surveys & tutorials*, vol. 19, no. 3, pp. 1628–1656, 2017.\n- <span id=\"page-44-31\"\
    ></span>[213] Y. Siriwardhana *et al.*, \"A survey on mobile augmented reality\
    \ with 5g mobile edge computing: Architectures, applications, and technical aspects,\"\
    \ *IEEE Communications Surveys & Tutorials*, vol. 23, no. 2, pp. 1160–1192, 2021.\n\
    - <span id=\"page-44-32\"></span>[214] M. Golec *et al.*, \"BlockFaaS: Blockchain-enabled\
    \ Serverless Computing Framework for AI-driven IoT Healthcare Applications,\"\
    \ *Journal of Grid Computing*, vol. 21, no. 4, p. 63, 2023.\n- <span id=\"page-44-33\"\
    ></span>[215] Z. Zheng *et al.*, \"Blockchain challenges and opportunities: A\
    \ survey,\" *International Journal of Web and Grid Services*, vol. 14, no. 4,\
    \ pp. 352–375, 2018.\n- <span id=\"page-44-34\"></span>[216] K. Gai *et al.*,\
    \ \"Blockchain meets cloud computing: A survey,\" *IEEE Communications Surveys\
    \ & Tutorials*, vol. 22, no. 3, pp. 2009–2030, 2020.\n- <span id=\"page-44-35\"\
    ></span>[217] S. A. Moqurrab *et al.*, \"A deep learning-based privacy-preserving\
    \ model for smart healthcare in internet of medical things using fog computing,\"\
    \ *Wireless Personal Communications*, vol. 126, no. 3, pp. 2379–2401, 2022.\n\
    - <span id=\"page-44-36\"></span>[218] M. Golec *et al.*, \"Aiblock: Blockchain\
    \ based lightweight framework for serverless computing using ai,\" in *2022 22nd\
    \ IEEE International Symposium on Cluster, Cloud and Internet Computing (CCGrid)*,\
    \ pp. 886–892, IEEE, 2022.\n- <span id=\"page-44-37\"></span>[219] M. Kumar *et\
    \ al.*, \"Blockchain inspired secure and reliable data exchange architecture for\
    \ cyber-physical healthcare system 4.0,\" *Internet of Things and Cyber-Physical\
    \ Systems*, 2023.\n- <span id=\"page-44-38\"></span>[220] L. Li *et al.*, \"A\
    \ review of applications in federated learning,\" *Computers & Industrial Engineering*,\
    \ vol. 149, p. 106854, 2020.\n- <span id=\"page-44-39\"></span>[221] J. Yang *et\
    \ al.*, \"A federated learning attack method based on edge collaboration via cloud,\"\
    \ *Software: Practice and Experience*, 2022.\n- <span id=\"page-44-40\"></span>[222]\
    \ C. Zhang *et al.*, \"A survey on federated learning,\" *Knowledge-Based Systems*,\
    \ vol. 216, p. 106775, 2021.\n- <span id=\"page-44-41\"></span>[223] W. Jiang\
    \ *et al.*, \"Federated split learning for sequential data in satellite–terrestrial\
    \ integrated networks,\" *Information Fusion*, vol. 103, p. 102141, Mar. 2024.\n\
    - <span id=\"page-44-42\"></span>[224] P. Kairouz *et al.*, \"Advances and open\
    \ problems in federated learning,\" *Foundations and Trends® in Machine Learning*,\
    \ vol. 14, no. 1– 2, pp. 1–210, 2021.\n- <span id=\"page-44-43\"></span>[225]\
    \ G. Wu *et al.*, \"Privacy-preserving offloading scheme in multi-access mobile\
    \ edge computing based on madrl,\" *Journal of Parallel and*\n\n*Distributed Computing*,\
    \ vol. 183, p. 104775, 2024.\n\n- <span id=\"page-45-0\"></span>[226] M. S. Ferdous\
    \ *et al.*, \"A survey of consensus algorithms in public blockchain systems for\
    \ crypto-currencies,\" *Journal of Network and Computer Applications*, vol. 182,\
    \ p. 103035, 2021.\n- <span id=\"page-45-1\"></span>[227] A. Manimuthu *et al.*,\
    \ \"A literature review on Bitcoin: Transformation of crypto currency into a global\
    \ phenomenon,\" *IEEE Engineering Management Review*, vol. 47, no. 1, pp. 28–35,\
    \ 2019.\n- <span id=\"page-45-2\"></span>[228] J. Xu *et al.*, \"A survey of blockchain\
    \ consensus protocols,\" *ACM Computing Surveys*, 2023.\n- <span id=\"page-45-3\"\
    ></span>[229] X. Wang *et al.*, \"Blockchain intelligence for internet of vehicles:\
    \ Challenges and solutions,\" *IEEE Communications Surveys & Tutorials*, 2023.\n\
    - <span id=\"page-45-4\"></span>[230] U. Rahardja *et al.*, \"Good, bad and dark\
    \ bitcoin: a systematic literature review,\" *Aptisi Transactions on Technopreneurship\
    \ (ATT)*, vol. 3, no. 2, pp. 115–119, 2021.\n- <span id=\"page-45-5\"></span>[231]\
    \ M. Golec *et al.*, \"IFaaSBus: A security-and privacy-based lightweight framework\
    \ for serverless computing using IoT and machine learning,\" *IEEE Transactions\
    \ on Industrial Informatics*, vol. 18, no. 5, pp. 3522–3529, 2021.\n- <span id=\"\
    page-45-6\"></span>[232] G. Qu *et al.*, \"Chainfl: A simulation platform for\
    \ joint federated learning and blockchain in edge/cloud computing environments,\"\
    \ *IEEE Transactions on Industrial Informatics*, vol. 18, no. 5, pp. 3572–3581,\
    \ 2022.\n- <span id=\"page-45-7\"></span>[233] M. Golec *et al.*, \"Healthfaas:\
    \ Ai based smart healthcare system for heart patients using serverless computing,\"\
    \ *IEEE Internet of Things Journal*, 2023.\n- <span id=\"page-45-8\"></span>[234]\
    \ S. Svorobej *et al.*, \"Orchestration from the cloud to the edge,\" *The Cloud-to-Thing\
    \ Continuum: Opportunities and Challenges in Cloud, Fog and Edge Computing*, pp.\
    \ 61–77, 2020.\n- <span id=\"page-45-10\"></span><span id=\"page-45-9\"></span>[235]\
    \ W. K. Härdle *et al.*, \"Understanding cryptocurrencies,\" 2020.\n- [236] P.\
    \ Weichbroth *et al.*, \"Security of cryptocurrencies: A view on the state-of-the-art\
    \ research and current developments,\" *Sensors*, vol. 23, no. 6, p. 3155, 2023.\n\
    - <span id=\"page-45-11\"></span>[237] A. Schweizer *et al.*, \"To what extent\
    \ will blockchain drive the machine economy? perspectives from a prospective study,\"\
    \ *IEEE Transactions on Engineering Management*, vol. 67, no. 4, pp. 1169– 1183,\
    \ 2020.\n- <span id=\"page-45-12\"></span>[238] M. Khan *et al.*, \"A review of\
    \ distributed ledger technologies in the machine economy: challenges and opportunities\
    \ in industry and research,\" *Procedia CIRP*, vol. 107, pp. 1168–1173, 2022.\n\
    - <span id=\"page-45-13\"></span>[239] S. Dustdar *et al.*, \"On distributed computing\
    \ continuum systems,\" *IEEE Transactions on Knowledge and Data Engineering*,\
    \ vol. 35, no. 4, pp. 4092–4105, 2022.\n- <span id=\"page-45-14\"></span>[240]\
    \ P. K. Donta *et al.*, \"Exploring the potential of distributed computing continuum\
    \ systems,\" *Computers*, vol. 12, no. 10, p. 198, 2023.\n- <span id=\"page-45-15\"\
    ></span>[241] A. Morichetta *et al.*, \"A roadmap on learning and reasoning for\
    \ distributed computing continuum ecosystems,\" in *IEEE International Conference\
    \ on Edge Computing (EDGE)*, pp. 25–31, Institute of Electrical and Electronics\
    \ Engineers (IEEE), Feb. 2021.\n- <span id=\"page-45-16\"></span>[242] C. J. Beasley\
    \ *et al.*, \"A new look at simultaneous sources,\" in *Seg technical program\
    \ expanded abstracts 1998*, pp. 133–135, Society of Exploration Geophysicists,\
    \ 1998.\n- <span id=\"page-45-17\"></span>[243] S. Aminizadeh *et al.*, \"The\
    \ applications of machine learning techniques in medical data processing based\
    \ on distributed computing and the internet of things,\" *Computer Methods and\
    \ Programs in Biomedicine*, p. 107745, 2023.\n- <span id=\"page-45-18\"></span>[244]\
    \ L. Petrou *et al.*, \"The first family of application-specific integrated circuits\
    \ for programmable and reconfigurable metasurfaces,\" *Scientific reports*, vol.\
    \ 12, no. 1, p. 5826, 2022.\n- <span id=\"page-45-19\"></span>[245] K. E. Murray\
    \ *et al.*, \"Vtr 8: High-performance cad and customizable fpga architecture modelling,\"\
    \ *ACM Transactions on Reconfigurable Technology and Systems (TRETS)*, vol. 13,\
    \ no. 2, pp. 1–55, 2020.\n- <span id=\"page-45-20\"></span>[246] P. Hitzler *et\
    \ al.*, *Neuro-symbolic artificial intelligence: The state of the art*. IOS Press,\
    \ 2022.\n- <span id=\"page-45-21\"></span>[247] M. Gaur *et al.*, \"Knowledge-infused\
    \ learning: A sweet spot in neurosymbolic ai,\" *IEEE Internet Computing*, vol.\
    \ 26, no. 4, pp. 5–11, 2022.\n- <span id=\"page-45-22\"></span>[248] J. Du *et\
    \ al.*, \"Computation energy efficiency maximization for intelligent reflective\
    \ surface-aided wireless powered mobile edge computing,\" *IEEE Transactions on\
    \ Sustainable Computing*, 2023.\n- <span id=\"page-45-23\"></span>[249] J. Cuadrado\
    \ *et al.*, \"Intelligent simulation of multibody dynamics: space-state and descriptor\
    \ methods in sequential and parallel computing environments,\" *Multibody system\
    \ dynamics*, vol. 4, pp. 55–73, 2000.\n- <span id=\"page-45-24\"></span>[250]\
    \ Y. Zhang *et al.*, \"Transparent computing: Spatio-temporal extension on von\
    \ neumann architecture for cloud services,\" *Tsinghua Science and Technology*,\
    \ vol. 18, no. 1, pp. 10–21, 2013.\n- <span id=\"page-45-25\"></span>[251] Q.\
    \ Jiang *et al.*, \"Adaptive scheduling of stochastic task sequence for energy-efficient\
    \ mobile cloud computing,\" *IEEE Systems Journal*, vol. 13, no. 3, pp. 3022–3025,\
    \ 2019.\n- <span id=\"page-45-26\"></span>[252] D. Bufistov *et al.*, \"A general\
    \ model for performance optimization of sequential systems,\" in *2007 IEEE/ACM\
    \ International Conference on Computer-Aided Design*, pp. 362–369, IEEE, 2007.\n\
    - <span id=\"page-45-27\"></span>[253] M. S. Aslanpour *et al.*, \"Performance\
    \ evaluation metrics for cloud, fog and edge computing: A review, taxonomy, benchmarks\
    \ and standards for future research,\" *Internet of Things*, vol. 12, p. 100273,\
    \ 2020.\n- <span id=\"page-45-28\"></span>[254] A. Singh *et al.*, \"Quantum internet—applications,\
    \ functionalities, enabling technologies, challenges, and research directions,\"\
    \ *IEEE Communications Surveys & Tutorials*, vol. 23, no. 4, pp. 2218–2247, 2021.\n\
    - <span id=\"page-45-29\"></span>[255] N. P. De Leon *et al.*, \"Materials challenges\
    \ and opportunities for quantum computing hardware,\" *Science*, vol. 372, no.\
    \ 6539, p. eabb2823, 2021.\n- <span id=\"page-45-30\"></span>[256] K. N. Smith\
    \ *et al.*, \"Scaling superconducting quantum computers with chiplet architectures,\"\
    \ in *2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO)*,\
    \ pp. 1092–1109, IEEE, 2022.\n- <span id=\"page-45-31\"></span>[257] R. F. Spivey\
    \ *et al.*, \"High-stability cryogenic system for quantum computing with compact\
    \ packaged ion traps,\" *IEEE Transactions on Quantum Engineering*, vol. 3, pp.\
    \ 1–11, 2021.\n- <span id=\"page-45-32\"></span>[258] A. R. Nandhakumar *et al.*,\
    \ \"EdgeAISim: A Toolkit for Simulation and Modelling of AI Models in Edge Computing\
    \ Environments,\" *Measurement: Sensors*, 2023.\n- <span id=\"page-45-33\"></span>[259]\
    \ M. Xue *et al.*, \"Ddpqn: An efficient dnn offloading strategy in local-edge-cloud\
    \ collaborative environments,\" *IEEE Transactions on Services Computing*, vol.\
    \ 15, no. 2, pp. 640–655, 2022.\n- <span id=\"page-45-34\"></span>[260] Y.-L.\
    \ Lee *et al.*, \"Techology trend of edge AI,\" in *2018 International Symposium\
    \ on VLSI Design, Automation and Test (VLSI-DAT)*, pp. 1–2, IEEE, 2018.\n- <span\
    \ id=\"page-45-35\"></span>[261] A. Y. Ding *et al.*, \"Roadmap for edge ai: A\
    \ dagstuhl perspective,\" 2022.\n- <span id=\"page-45-36\"></span>[262] D. Murugesan\
    \ *et al.*, \"Comparison of biologically inspired algorithm with socio-inspired\
    \ technique on load frequency control of multisource single-area power system,\"\
    \ in *Applied Genetic Algorithm and Its Variants: Case Studies and New Developments*,\
    \ pp. 185–208, Springer, 2023.\n- <span id=\"page-45-37\"></span>[263] A. K. Kar,\
    \ \"Bio inspired computing–a review of algorithms and scope of applications,\"\
    \ *Expert Systems with Applications*, vol. 59, pp. 20–32, 2016.\n- <span id=\"\
    page-45-38\"></span>[264] M. Xu *et al.*, \"esdnn: deep neural network based multivariate\
    \ workload prediction in cloud computing environments,\" *ACM Transactions on\
    \ Internet Technology (TOIT)*, vol. 22, no. 3, pp. 1–24, 2022.\n- <span id=\"\
    page-45-39\"></span>[265] B. Denkena *et al.*, \"Reprint of: Gentelligent processes\
    \ in biologically inspired manufacturing,\" *CIRP Journal of Manufacturing Science\
    \ and Technology*, vol. 34, pp. 105–118, 2021.\n- <span id=\"page-45-40\"></span>[266]\
    \ R. Dwivedi *et al.*, \"Explainable AI (XAI): Core ideas, techniques, and solutions,\"\
    \ *ACM Computing Surveys*, vol. 55, no. 9, pp. 1–33, 2023.\n- <span id=\"page-45-41\"\
    ></span>[267] A. B. Tosun *et al.*, \"Histomapr™: An explainable AI (XAI) platform\
    \ for computational pathology solutions,\" in *Artificial Intelligence and Machine\
    \ Learning for Digital Pathology: State-of-the-Art and Future Challenges*, pp.\
    \ 204–227, Springer, 2020.\n- <span id=\"page-45-42\"></span>[268] A. B. Arrieta\
    \ *et al.*, \"Explainable artificial intelligence (XAI): Concepts, taxonomies,\
    \ opportunities and challenges toward responsible\n\nAI,\" *Information fusion*,\
    \ vol. 58, pp. 82–115, 2020.\n\n- <span id=\"page-46-0\"></span>[269] P. Kochovski\
    \ *et al.*, \"Trust management in a blockchain based fog computing platform with\
    \ trustless smart oracles,\" *Future Generation Computer Systems*, vol. 101, pp.\
    \ 747–759, 2019.\n- <span id=\"page-46-1\"></span>[270] K. Shkembi *et al.*, \"\
    Semantic web and blockchain technologies: Convergence, challenges and research\
    \ trends,\" *Journal of Web Semantics*, vol. 79, p. 100809, 2023.\n- <span id=\"\
    page-46-2\"></span>[271] A. D. Córcoles *et al.*, \"Challenges and opportunities\
    \ of near-term quantum computing systems,\" *Proceedings of the IEEE*, vol. 108,\
    \ no. 8, pp. 1338–1352, 2019.\n- <span id=\"page-46-3\"></span>[272] K. C. Seto\
    \ *et al.*, \"From low-to net-zero carbon cities: The next global agenda,\" *Annual\
    \ review of environment and resources*, vol. 46, pp. 377–415, 2021.\n- <span id=\"\
    page-46-4\"></span>[273] G. Aceto *et al.*, \"A survey on information and communication\
    \ technologies for industry 4.0: State-of-the-art, taxonomies, perspectives, and\
    \ challenges,\" *IEEE Communications Surveys & Tutorials*, vol. 21, no. 4, pp.\
    \ 3467–3501, 2019.\n- <span id=\"page-46-5\"></span>[274] G. Aceto *et al.*, \"\
    Industry 4.0 and health: Internet of things, big data, and cloud computing for\
    \ healthcare 4.0,\" *Journal of Industrial Information Integration*, vol. 18,\
    \ p. 100129, 2020.\n- <span id=\"page-46-6\"></span>[275] Y. K. Teoh *et al.*,\
    \ \"Iot and fog computing based predictive maintenance model for effective asset\
    \ management in industry 4.0 using machine learning,\" *IEEE Internet of Things\
    \ Journal*, 2021.\n- <span id=\"page-46-7\"></span>[276] T. Zheng *et al.*, \"\
    The applications of industry 4.0 technologies in manufacturing context: a systematic\
    \ literature review,\" *International Journal of Production Research*, vol. 59,\
    \ no. 6, pp. 1922–1954, 2021.\n- <span id=\"page-46-8\"></span>[277] W. Yu *et\
    \ al.*, \"Energy digital twin technology for industrial energy management: Classification,\
    \ challenges and future,\" *Renewable and Sustainable Energy Reviews*, vol. 161,\
    \ p. 112407, 2022.\n- <span id=\"page-46-9\"></span>[278] S. Mihai *et al.*, \"\
    Digital twins: A survey on enabling technologies, challenges, trends and future\
    \ prospects,\" *IEEE Communications Surveys & Tutorials*, 2022.\n- <span id=\"\
    page-46-10\"></span>[279] Y. Wang *et al.*, \"A survey on digital twins: architecture,\
    \ enabling technologies, security and privacy, and future prospects,\" *IEEE Internet\
    \ of Things Journal*, 2023.\n- <span id=\"page-46-11\"></span>[280] M. Kor *et\
    \ al.*, \"An investigation for integration of deep learning and digital twins\
    \ towards construction 4.0,\" *Smart and Sustainable Built Environment*, vol.\
    \ 12, no. 3, pp. 461–487, 2023.\n- <span id=\"page-46-12\"></span>[281] S. Singh\
    \ *et al.*, \"Qos-aware autonomic resource management in cloud computing: a systematic\
    \ review,\" *ACM Computing Surveys (CSUR)*, vol. 48, no. 3, pp. 1–46, 2015.\n\
    - <span id=\"page-46-13\"></span>[282] A. Morichetta *et al.*, \"Demystifying\
    \ deep learning in predictive monitoring for cloud-native SLOs,\" in *2023 IEEE\
    \ 16th International Conference on Cloud Computing (CLOUD)*, pp. 1–11, July 2023.\
    \ ISSN: 2159-6190.\n- <span id=\"page-46-14\"></span>[283] S. A. Wright, \"Performance\
    \ modeling, benchmarking and simulation of high performance computing systems,\"\
    \ 2019.\n- <span id=\"page-46-15\"></span>[284] H. Materwala *et al.*, \"Qos-sla-aware\
    \ adaptive genetic algorithm for multi-request offloading in integrated edge-cloud\
    \ computing in internet of vehicles,\" *Vehicular Communications*, vol. 43, p.\
    \ 100654, 2023.\n- <span id=\"page-46-16\"></span>[285] Y. Sharma *et al.*, \"\
    Sla management in intent-driven service management systems: A taxonomy and future\
    \ directions,\" *ACM Computing Surveys*, 2023.\n- <span id=\"page-46-17\"></span>[286]\
    \ S. Khan *et al.*, \"Guaranteeing end-to-end qos provisioning in soa based sdn\
    \ architecture: A survey and open issues,\" *Future Generation Computer Systems*,\
    \ vol. 119, pp. 176–187, 2021.\n- <span id=\"page-46-18\"></span>[287] S. Dilek\
    \ *et al.*, \"QoS-aware IoT networks and protocols: A comprehensive survey,\"\
    \ *International Journal of Communication Systems*, vol. 35, no. 10, p. e5156,\
    \ 2022.\n- <span id=\"page-46-19\"></span>[288] V. C. Pujol *et al.*, \"Towards\
    \ a Prime Directive of SLOs,\" in *2023 IEEE International Conference on Software\
    \ Services Engineering (SSE)*, pp. 61–70, July 2023.\n- <span id=\"page-46-20\"\
    ></span>[289] P. Patros *et al.*, \"Slo request modeling, reordering and scaling,\"\
    \ in *Proceedings of the 27th annual international conference on computer science\
    \ and software engineering*, pp. 180–191, 2017.\n- <span id=\"page-46-21\"></span>[290]\
    \ S. Singh *et al.*, \"The journey of qos-aware autonomic cloud computing,\" *IT\
    \ Professional*, vol. 19, no. 2, pp. 42–49, 2017.\n- <span id=\"page-46-22\"></span>[291]\
    \ P. o. Patros, \"Investigating the effect of garbage collection on service level\
    \ objectives of clouds,\" in *2017 IEEE International Conference on Cluster Computing\
    \ (CLUSTER)*, pp. 633–634, IEEE, 2017.\n- <span id=\"page-46-23\"></span>[292]\
    \ X. Zeng *et al.*, \"Sla management for big data analytical applications in clouds:\
    \ A taxonomy study,\" *ACM Computing Surveys (CSUR)*, vol. 53, no. 3, pp. 1–40,\
    \ 2020.\n- <span id=\"page-46-24\"></span>[293] C. Qu *et al.*, \"Auto-scaling\
    \ web applications in clouds: A taxonomy and survey,\" *ACM Computing Surveys\
    \ (CSUR)*, vol. 51, no. 4, pp. 1– 33, 2018.\n- <span id=\"page-46-25\"></span>[294]\
    \ T. Lorido-Botran *et al.*, \"A review of auto-scaling techniques for elastic\
    \ applications in cloud environments,\" *Journal of grid computing*, vol. 12,\
    \ pp. 559–592, 2014.\n- <span id=\"page-46-26\"></span>[295] P. Singh *et al.*,\
    \ \"Rhas: robust hybrid auto-scaling for web applications in cloud computing,\"\
    \ *Cluster Computing*, vol. 24, no. 2, pp. 717–737, 2021.\n- <span id=\"page-46-27\"\
    ></span>[296] T. Heinze *et al.*, \"Auto-scaling techniques for elastic data stream\
    \ processing,\" in *Proceedings of the 8th ACM International Conference on Distributed\
    \ Event-Based Systems*, pp. 318–321, 2014.\n- <span id=\"page-46-28\"></span>[297]\
    \ S. S. Gill *et al.*, \"Holistic resource management for sustainable and reliable\
    \ cloud computing: An innovative solution to global challenge,\" *Journal of Systems\
    \ and Software*, vol. 155, pp. 104–129, 2019.\n- <span id=\"page-46-29\"></span>[298]\
    \ S. Bharany *et al.*, \"Energy efficient fault tolerance techniques in green\
    \ cloud computing: A systematic survey and taxonomy,\" *Sustainable Energy Technologies\
    \ and Assessments*, vol. 53, p. 102613, 2022.\n- <span id=\"page-46-30\"></span>[299]\
    \ S. S. Gill *et al.*, \"Failure management for reliable cloud computing: a taxonomy,\
    \ model, and future directions,\" *Computing in Science & Engineering*, vol. 22,\
    \ no. 3, pp. 52–63, 2018.\n- <span id=\"page-46-31\"></span>[300] S. S. Gill *et\
    \ al.*, \"Tails in the cloud: a survey and taxonomy of straggler management within\
    \ large-scale cloud data centres,\" *The Journal of Supercomputing*, vol. 76,\
    \ pp. 10050–10089, 2020.\n- <span id=\"page-46-32\"></span>[301] S. S. Gill, \"\
    A manifesto for modern fog and edge computing: Vision, new paradigms, opportunities,\
    \ and future directions,\" in *Operationalizing Multi-Cloud Environments: Technologies,\
    \ Tools and Use Cases*, pp. 237–253, Springer, 2021.\n- <span id=\"page-46-33\"\
    ></span>[302] A. Katal *et al.*, \"Energy efficiency in cloud computing data centers:\
    \ a survey on software technologies,\" *Cluster Computing*, vol. 26, no. 3, pp.\
    \ 1845–1875, 2023.\n- <span id=\"page-46-34\"></span>[303] E. Masanet *et al.*,\
    \ \"Recalibrating global data center energy-use estimates,\" *Science*, vol. 367,\
    \ no. 6481, pp. 984–986, 2020.\n- <span id=\"page-46-35\"></span>[304] S. Iftikhar\
    \ *et al.*, \"Hunterplus: AI based energy-efficient task scheduling for cloud–fog\
    \ computing environments,\" *Internet of Things*, vol. 21, p. 100667, 2023.\n\
    - <span id=\"page-46-36\"></span>[305] S. Tuli *et al.*, \"HUNTER: AI based holistic\
    \ resource management for sustainable cloud computing,\" *Journal of Systems and\
    \ Software*, vol. 184, p. 111124, 2022.\n- <span id=\"page-46-37\"></span>[306]\
    \ T. Schneider *et al.*, \"Harnessing ai and computing to advance climate modelling\
    \ and prediction,\" *Nature Climate Change*, vol. 13, no. 9, pp. 887–889, 2023.\n\
    - <span id=\"page-46-38\"></span>[307] M. Hartmann *et al.*, \"Edge computing\
    \ in smart health care systems: Review, challenges, and research directions,\"\
    \ *Transactions on Emerging Telecommunications Technologies*, vol. 33, no. 3,\
    \ p. e3710, 2022.\n- <span id=\"page-46-39\"></span>[308] H. J. Baek *et al.*,\
    \ \"Enhancing the usability of brain-computer interface systems,\" *Computational\
    \ intelligence and neuroscience*, vol. 2019, 2019.\n- <span id=\"page-46-40\"\
    ></span>[309] M. H. Miraz *et al.*, \"Adaptive user interfaces and universal usability\
    \ through plasticity of user interface design,\" *Computer Science Review*, vol.\
    \ 40, p. 100363, 2021.\n- <span id=\"page-46-41\"></span>[310] J. Diaz-de Arcaya\
    \ *et al.*, \"A joint study of the challenges, opportunities, and roadmap of mlops\
    \ and aiops: A systematic survey,\" *ACM Computing Surveys*, vol. 56, no. 4, pp.\
    \ 1–30, 2023.\n- <span id=\"page-46-42\"></span>[311] I. Celik, \"Exploring the\
    \ determinants of artificial intelligence (ai) literacy: Digital divide, computational\
    \ thinking, cognitive absorption,\" *Telematics and Informatics*, vol. 83, p.\
    \ 102026, 2023.\n- <span id=\"page-46-43\"></span>[312] S. S. Gill *et al.*, \"\
    Transformative effects of ChatGPT on modern education: Emerging Era of AI chatbots,\"\
    \ *Internet of Things and*\n\n*Cyber-Physical Systems*, vol. 4, pp. 19–23, 2024.\n\
    \n- <span id=\"page-47-0\"></span>[313] C. Le Roux *et al.*, \"Can cloud computing\
    \ bridge the digital divide in south african secondary education?,\" *Information\
    \ development*, vol. 27, no. 2, pp. 109–116, 2011.\n- <span id=\"page-47-1\"></span>[314]\
    \ C. G. M. Arce *et al.*, \"Optimizing business performance: Marketing strategies\
    \ for small and medium businesses using artificial intelligence tools,\" *Migration\
    \ Letters*, vol. 21, no. S1, pp. 193–201, 2024.\n- <span id=\"page-47-2\"></span>[315]\
    \ J. Qadir *et al.*, \"Toward accountable human-centered ai: rationale and promising\
    \ directions,\" *Journal of Information, Communication and Ethics in Society*,\
    \ vol. 20, no. 2, pp. 329–342, 2022.\n- <span id=\"page-47-3\"></span>[316] L.\
    \ Munn, \"The uselessness of AI ethics,\" *AI and Ethics*, vol. 3, no. 3, pp.\
    \ 869–877, 2023.\n- <span id=\"page-47-4\"></span>[317] V. Scuotto *et al.*, \"\
    The digital humanism era triggered by individual creativity,\" *Journal of Business\
    \ Research*, vol. 158, p. 113709, 2023.\n- <span id=\"page-47-5\"></span>[318]\
    \ J. Schaap *et al.*, \"'gods in world of warcraft exist': Religious reflexivity\
    \ and the quest for meaning in online computer games,\" *New Media & Society*,\
    \ vol. 19, no. 11, pp. 1744–1760, 2017.\n- <span id=\"page-47-6\"></span>[319]\
    \ D. Magni *et al.*, \"Digital humanism and artificial intelligence: the role\
    \ of emotions beyond the human–machine interaction in society 5.0,\" *Journal\
    \ of Management History*, 2023.\n- <span id=\"page-47-7\"></span>[320] Q. Yu *et\
    \ al.*, \"Lagrange coded computing: Optimal design for resiliency, security, and\
    \ privacy,\" in *The 22nd International Conference on Artificial Intelligence\
    \ and Statistics*, pp. 1215–1225, PMLR, 2019.\n- <span id=\"page-47-8\"></span>[321]\
    \ F. O. Olowononi *et al.*, \"Resilient machine learning for networked cyber physical\
    \ systems: A survey for machine learning security to securing machine learning\
    \ for cps,\" *IEEE Communications Surveys & Tutorials*, vol. 23, no. 1, pp. 524–552,\
    \ 2020.\n- <span id=\"page-47-9\"></span>[322] Z. Liu *et al.*, \"Efficient dropout-resilient\
    \ aggregation for privacypreserving machine learning,\" *IEEE Transactions on\
    \ Information Forensics and Security*, vol. 18, pp. 1839–1854, 2022.\n- <span\
    \ id=\"page-47-10\"></span>[323] J. K. Samriya *et al.*, \"Secured data offloading\
    \ using reinforcement learning and markov decision process in mobile edge computing,\"\
    \ *International Journal of Network Management*, vol. 33, no. 5, p. e2243, 2023.\n\
    - <span id=\"page-47-11\"></span>[324] I. Ullah *et al.*, \"Privacy preserving\
    \ large language models: Chatgpt case study based vision and framework,\" *arXiv\
    \ preprint arXiv:2310.12523*, 2023.\n- <span id=\"page-47-12\"></span>[325] H.\
    \ Kim *et al.*, \"Resilient authentication and authorization for the internet\
    \ of things (iot) using edge computing,\" *ACM Transactions on Internet of Things*,\
    \ vol. 1, no. 1, pp. 1–27, 2020.\n- <span id=\"page-47-13\"></span>[326] C. Delacour\
    \ *et al.*, \"Energy-performance assessment of oscillatory neural networks based\
    \ on vo \\_2 devices for future edge ai computing,\" *IEEE Transactions on Neural\
    \ Networks and Learning Systems*, 2023.\n- <span id=\"page-47-14\"></span>[327]\
    \ Z. Quan *et al.*, \"A historical review on learning with technology: From computers\
    \ to smartphones,\" in *Encyclopedia of Information Science and Technology, Sixth\
    \ Edition*, pp. 1–21, IGI Global, 2025.\n- <span id=\"page-47-15\"></span>[328]\
    \ A. Mijuskovic *et al.*, \"Resource management techniques for cloud/fog and edge\
    \ computing: An evaluation framework and classification,\" *Sensors*, vol. 21,\
    \ no. 5, p. 1832, 2021.\n- <span id=\"page-47-16\"></span>[329] S. Singh *et al.*,\
    \ \"A survey on resource scheduling in cloud computing: Issues and challenges,\"\
    \ *Journal of grid computing*, vol. 14, pp. 217– 264, 2016.\n- <span id=\"page-47-17\"\
    ></span>[330] C.-H. Hong *et al.*, \"Resource management in fog/edge computing:\
    \ a survey on architectures, infrastructure, and algorithms,\" *ACM Computing\
    \ Surveys (CSUR)*, vol. 52, no. 5, pp. 1–37, 2019.\n- <span id=\"page-47-18\"\
    ></span>[331] B. Jamil *et al.*, \"Resource allocation and task scheduling in\
    \ fog computing and internet of everything environments: A taxonomy, review, and\
    \ future directions,\" *ACM Computing Surveys (CSUR)*, vol. 54, no. 11s, pp. 1–38,\
    \ 2022.\n- <span id=\"page-47-19\"></span>[332] A. Raju *et al.*, \"A comparative\
    \ study of spark schedulers' performance,\" in *2019 4th international conference\
    \ on computational systems and information technology for sustainable solution\
    \ (CSITSS)*, pp. 1–5, IEEE, 2019.\n- <span id=\"page-47-20\"></span>[333] S. Henning\
    \ *et al.*, \"Benchmarking scalability of stream processing frameworks deployed\
    \ as microservices in the cloud,\" *Journal of Systems and Software*, vol. 208,\
    \ p. 111879, 2024.\n- <span id=\"page-47-21\"></span>[334] J. Feng *et al.*, \"\
    Heterogeneous computation and resource allocation for wireless powered federated\
    \ edge learning systems,\" *IEEE Transactions on Communications*, vol. 70, no.\
    \ 5, pp. 3220–3233, 2022.\n- <span id=\"page-47-22\"></span>[335] A. Garofalo\
    \ *et al.*, \"A heterogeneous in-memory computing cluster for flexible end-to-end\
    \ inference of real-world deep neural networks,\" *IEEE Journal on Emerging and\
    \ Selected Topics in Circuits and Systems*, vol. 12, no. 2, pp. 422–435, 2022.\n\
    - <span id=\"page-47-23\"></span>[336] H. Wu *et al.*, \"Collaborate edge and\
    \ cloud computing with distributed deep learning for smart city internet of things,\"\
    \ *IEEE Internet of Things Journal*, vol. 7, no. 9, pp. 8099–8110, 2020.\n- <span\
    \ id=\"page-47-24\"></span>[337] V. Kumar, \"Digital enablers,\" in *The Economic\
    \ Value of Digital Disruption: A Holistic Assessment for CXOs*, pp. 1–110, Springer,\
    \ 2023.\n- <span id=\"page-47-25\"></span>[338] K. Sha *et al.*, \"A survey of\
    \ edge computing-based designs for IoT security,\" *Digital Communications and\
    \ Networks*, vol. 6, no. 2, pp. 195–202, 2020.\n- <span id=\"page-47-26\"></span>[339]\
    \ J. B. Sequeiros *et al.*, \"Attack and system modeling applied to IoT, cloud,\
    \ and mobile ecosystems: Embedding security by design,\" *ACM Computing Surveys\
    \ (CSUR)*, vol. 53, no. 2, pp. 1–32, 2020.\n- <span id=\"page-47-27\"></span>[340]\
    \ A. Kaur *et al.*, \"The future of cloud computing: opportunities, challenges\
    \ and research trends,\" in *2nd International Conference on I-SMAC (IoT in Social,\
    \ Mobile, Analytics and Cloud)(I-SMAC) I-SMAC*, pp. 213–219, IEEE, 2018.\n- <span\
    \ id=\"page-47-28\"></span>[341] A. Sebastian *et al.*, \"Memory devices and applications\
    \ for inmemory computing,\" *Nature nanotechnology*, vol. 15, no. 7, pp. 529–544,\
    \ 2020.\n- <span id=\"page-47-29\"></span>[342] K. Vu *et al.*, \"Ict as a driver\
    \ of economic growth: A survey of the literature and directions for future research,\"\
    \ *Telecommunications Policy*, vol. 44, no. 2, p. 101922, 2020.\n- <span id=\"\
    page-47-30\"></span>[343] L. Tesfatsion, \"Agent-based computational economics:\
    \ Overview and brief history,\" *Artificial Intelligence, Learning and Computation\
    \ in Economics and Finance*, pp. 41–58, 2023.\n- <span id=\"page-47-31\"></span>[344]\
    \ C. Vairetti *et al.*, \"Analytics-driven complaint prioritisation via deep learning\
    \ and multicriteria decision-making,\" *European Journal of Operational Research*,\
    \ vol. 312, no. 3, pp. 1108–1118, 2024.\n- <span id=\"page-47-36\"></span>[345]\
    \ A. Jobin *et al.*, \"The global landscape of AI ethics guidelines,\" *Nature\
    \ machine intelligence*, vol. 1, no. 9, pp. 389–399, 2019.\n- <span id=\"page-47-32\"\
    ></span>[346] R. H. Hariri *et al.*, \"Uncertainty in big data analytics: survey,\
    \ opportunities, and challenges,\" *Journal of Big Data*, vol. 6, no. 1, pp. 1–16,\
    \ 2019.\n- <span id=\"page-47-37\"></span>[347] L. Cao, \"Data science: a comprehensive\
    \ overview,\" *ACM Computing Surveys (CSUR)*, vol. 50, no. 3, pp. 1–42, 2017.\n\
    - <span id=\"page-47-33\"></span>[348] B. K. Daniel, \"Big data and data science:\
    \ A critical review of issues for educational research,\" *British Journal of\
    \ Educational Technology*, vol. 50, no. 1, pp. 101–113, 2019.\n- <span id=\"page-47-34\"\
    ></span>[349] P. K. Donta *et al.*, \"Governance and sustainability of distributed\
    \ continuum systems: a big data approach,\" *Journal of Big Data*, vol. 10, no.\
    \ 1, pp. 1–31, 2023.\n- <span id=\"page-47-35\"></span>[350] M. H. ur Rehman *et\
    \ al.*, \"The role of big data analytics in industrial internet of things,\" *Future\
    \ Generation Computer Systems*, vol. 99, pp. 247–259, 2019."
- id: xaas_acceleration_as_a_service_to_enable_productive_high_performance_cloud_computing_xaas_acceleration_as_a_service_to_enable_productive_high_performance_cloud_computing
  title: "XaaS: Acceleration as a Service to Enable Productive High-Performance\n\
    \  Cloud Computing"
  abstract: 'HPC and Cloud have evolved independently, specializing their innovations
    into

    performance or productivity. Acceleration as a Service (XaaS) is a recipe to

    empower both fields with a shared execution platform that provides transparent

    access to computing resources, regardless of the underlying cloud or HPC

    service provider. Bridging HPC and cloud advancements, XaaS presents a unified

    architecture built on performance-portable containers. Our converged model

    concentrates on low-overhead, high-performance communication and computing,

    targeting resource-intensive workloads from climate simulations to machine

    learning. XaaS lifts the restricted allocation model of Function-as-a-Service

    (FaaS), allowing users to benefit from the flexibility and efficient resource

    utilization of serverless while supporting long-running and

    performance-sensitive workloads from HPC.'
  url: http://arxiv.org/abs/2401.04552v1
  keywords: ''
  document: '# XaaS: Acceleration as a Service to Enable Productive High-Performance
    Cloud Computing


    Torsten Hoefler ETH Zurich & Swiss National Supercomputing Centre (CSCS) Switzerland


    > Andrew Jones Microsoft United Kingdom


    Daniel Reed Utah University USA


    Marcin Copik ETH Zurich Switzerland


    Ian Foster Argonne National Laboratory USA


    > Matthias Troyer Microsoft USA


    Dan Ernst NVIDIA USA


    Argonne National Laboratory USA


    Pete Beckman


    Manish Parashar Utah University USA


    Thomas Schulthess Swiss National Supercomputing Centre (CSCS) Switzerland


    Jack Dongarra University of Tennessee USA


    ## ABSTRACT


    HPC and Cloud have evolved independently, specializing their innovations into
    performance or productivity. Acceleration as a Service (XaaS) is a recipe to empower
    both fields with a shared execution platform that provides transparent access
    to computing resources, regardless of the underlying cloud or HPC service provider.
    Bridging HPC and cloud advancements, XaaS presents a unified architecture built
    on performance-portable containers. Our converged model concentrates on low-overhead,
    high-performance communication and computing, targeting resource-intensive workloads
    from climate simulations to machine learning. XaaS lifts the restricted allocation
    model of Function-as-a-Service (FaaS), allowing users to benefit from the flexibility
    and efficient resource utilization of serverless while supporting long-running
    and performancesensitive workloads from HPC.


    ## INTRODUCTION


    Acceleration as a Service (XaaS) is a recipe for enabling high-performance computing
    (HPC) workloads in the cloud. Cloud computing ("the Cloud") provides the opportunity
    to offer computational capabilities as a simple transactional service, similar
    to how we use electricity or the internet. Today''s Cloud already offers a wide
    range of powerful services, from online storage to specific applications


    ![](_page_0_Picture_16.jpeg)


    such as video calls or search. However, its performance is limited by inefficiencies
    in current Cloud architectures. XaaS addresses those inefficiencies and enables
    the computation of high-performance accelerated workloads, ranging from simulations
    to AI/ML inference and training, as a high-performance cloud service capable of
    serving most demanding workloads.


    XaaS provides different opportunities for people with different backgrounds and
    mindsets. Members of the HPC community will find a vision for productive high-performance
    computing connecting today''s manually compiled-and-run HPC applications to a
    new world of automated high-performance containers running finegrained transactional
    computations. Members of the datacenter systems and cloud computing communities
    will find a vision for lifting standard container deployments seamlessly to low-overhead,
    high-performance accelerated infrastructures, enabling the fastest communication
    and specialized computing at the highest system utilization and reliability, whereby
    deployed containers utilize library interfaces and remote direct memory access
    (RDMA) technologies for specialized acceleration and communication with close-to-zero
    overheads compared to traditional bare-metal deployments.


    Here, we define HPC workloads as resource-intensive and performance sensitive
    applications. Traditionally, HPC systems were aimed at executing extremely demanding
    scientific computing workloads. Recently, HPC systems have also been employed
    for data analytics, machine learning, and other workloads that, like scientific
    computing, require massive concurrency and rapid interprocess communication. Supercomputing
    is the subset of HPC that uses the fastest and most powerful general purpose scientific
    computing systems available at any given time [\[7\]](#page-7-0). Cloud computing
    can be characterized by the desire to separate provider and user by a simple,
    clear, and automatable interface (ideally as simple as a power socket!) and by
    business and operations models designed to ensure that user requests can always
    be satisfied. To this end, cloud computing employs composable (micro)services
    that run in containers and interact through clearly defined interfaces (e.g.,
    REST, JSON) that often however compromise performance.


    Applications that only rely on container and cloud service interfaces are called
    "cloud native." Container creation, deployment, and management are largely handled
    by the de-facto standards Docker and Kubernetes. However, cloud service interfaces
    such as storage or machine learning inference are usually specific to the provider''s
    ecosystem. Most modern cloud systems aim to offer


    Torsten Hoefler, Marcin Copik, Pete Beckman, Andrew Jones, Ian Foster, Manish
    Parashar, Daniel Reed, Matthias Troyer, Thomas Schulthess, Dan Ernst, and Jack
    Dongarra


    <span id="page-1-1"></span>![](_page_1_Figure_1.jpeg)


    Figure 1: Both Cloud and HPC converge to containers as an application and service
    deployment model. Containers bind all dependencies and system aspects (users,
    rights, etc.) into a single portable unit that can be flexibly deployed. XaaS
    enables HPC features for such containers.


    an execution environment for cloud-native containers, which is similar to an operating
    system''s interface to a process. The Cloud Native Foundation seeks to define
    an interface in the spirit of the POSIX interfaces[a](#page-1-0) . This design
    is traditionally aimed at providing a productive ecosystem. Only recently, performance
    has become a center of attention when using compute accelerators for demanding
    video processing tasks or AI/ML workloads. Thus, the goals of modern cloud computing
    and HPC align well and could converge towards the same infrastructure.


    HPC and Cloud have progressed largely independently in the past. Both according
    to their specialization: The Cloud innovates in terms of business model, software
    packaging (containers), and productive ecosystems (e.g., cloud native) and HPC
    in terms of performance (e.g., RDMA) and abstractions for performance (performance
    libraries). However, each field trails the other in other respects: for example,
    HPC has explored as-aservices abstractions [\[1\]](#page-7-1) and is only just
    beginning to embrace the simpler deployment philosophy of containerized environments,
    while cloud started to explore ideas of RDMA. Each feature was established in
    the other community a decade ago. XaaS provides a way to accelerate this transition
    to a common architecture based on high-performance containers. Figure [1](#page-1-1)
    shows a schematic overview of where each field is coming from and what containerized
    deployments could enable today or in the near future. If those two communities
    do not join forces, they are bound to re-invent each other''s methods.


    All-in-all, the high-level architectural vision for a converged high-performance
    cloud with XaaS is based on three fundamental principles:


    #### (1) Performance portable containers (Infrastructure)


    <span id="page-1-0"></span><sup>a</sup><https://kubernetes.io/blog/2016/09/cloud-native-application-interfaces/>


    #### (2) High-performance communication and I/O (Input/Output) (3) High-performance
    allocation, scheduling, and accounting (Invocation)


    In the following, we outline three key techniques that can be used to build this
    architecture: Flexible hooked libraries and specialized builds can enable performance
    portability of the container infrastructure [\[4\]](#page-7-2). RDMA and other
    direct memory access techniques can provide the lowest overhead interface to the
    outside world [\[6\]](#page-7-3). Direct peer-to-peer allocations and high-performance
    scheduling and accounting can provide performant and available integration into
    a full system [\[6\]](#page-7-3).


    ### STATE OF THE ART


    We provide detailed descriptions of HPC and CC, considering each field''s idiosyncrasies
    and commonalities.


    HPC has traditionally supported demanding workloads in centralized datacenters.
    Supercomputers have long been used to serve the most demanding applications, such
    as weather prediction or the numerical simulation of complex structures; more
    recently, they are also used to train very large-scale AI models. Due to the necessary
    large investment, supercomputers often pool the resources of many individuals
    at the regional or national level to address problems relevant to society. While
    they are architected to run the largest jobs, they may spend much of their life
    running smaller applications. HPC centers have long led the design and development
    of large-scale systems, often in collaboration with system vendors. HPC has driven
    the wide adoption of vector processing, massive parallelism based on commodity
    CPUs, general-purpose GPUs, and high-performance interconnects for multiple decades
    through long-term engagement with vendor partners.


    <span id="page-2-0"></span>


    | Cloud Overview          | Generic            |            |           |                          |
    Specialized            |                        |

    |-------------------------|--------------------|------------|-----------|--------------------------|------------------------|------------------------|

    |                         | IaaS               | PaaS       | CaaS      | FaaS                     |
    SaaS                   | DaaS                   |

    | Hardware Environment    | ✓                  | ✓          | ✓         | ✓                        |
    ✓                      | ✓                      |

    | Software Environment    |                    | ✓          | ✓         | ✓                        |
    Pre-Configured Service |                        |

    | Bespoke Software        |                    |            | ✓         | ✓                        |                        |                        |

    | Fine-grained Accounting |                    |            |           | ✓                        |
    ✓                      | ✓                      |

    | Example Services        | AWS EC2, Azure VMs | Google App | Azure AKS | AWS
    Lambda, Azure        | Gmail                  | OneDrive, Box          |

    |                         | GCP Compute Engine | Engine     | AWS EKS   | Functions,
    GCP Functions | Microsoft 365          | Xignite for stock data |


    Table 1: Comparison point of existing Cloud offerings.


    Cloud emerged as a paradigm to sell compute cycles to a diverse set of customers,
    ranging from anonymous customers with credit cards to long-term engagements. The
    Cloud''s success in this endeavor has allowed it to realize, at scale, the vision
    of utility [\[2,](#page-7-4) [8\]](#page-7-5) and grid computing [\[10\]](#page-7-6)
    whereby computing as a service enables new services in many fields, including
    computational sciences [\[9\]](#page-7-7). This approach changed the dynamics
    of IT businesses at large, giving startups a significantly lower barrier of entry
    compared to the dot-com days where the necessary CapEx proved to be a huge burden.
    The Cloud''s aim to widen the customer base has led to a wide range of offerings
    at various levels of complexity and capability of compute services, encompassing
    Infrastructures (IaaS), Platforms (PaaS), Containers (CaaS), and Functions (FaaS),
    as well as full application services such as Service Architectures/Software (SaaS)
    and Data (DaaS). The focus is usually on reducing the barrier of entry and improving
    usability instead of performance, leading to relatively inefficient but simple
    web interfaces such as REST. The latest push in this direction is the definition
    of cloud-native interfaces, for which performance and efficiency initially played
    only a secondary role. Yet, due to economies of scale, cloud computing has become
    more performance-sensitive, especially in the emerging AI area.


    It appears as if the market-driven Cloud field is moving organically towards a
    productive higher-performance environment in order to reduce costs of centralized
    services. Meanwhile, many organizations in the community-driven HPC field remain
    in some sort of innovator''s dilemma whereby today''s traditional HPC environment,
    with its batch system setups, makefiles, and other venerable features, works well
    enough to throttle development and experimentation. Yet this environment is increasingly
    not fit for purpose for emerging workloads that involve complex workflows or realtime
    computing. Only a bottom-up movement, with potentially some top-down incentives,
    can change the field. Only the right productive high-performance technology will
    move the community! We believe we need an architecture that enables portable,
    composable, and scalable workloads that allows users to build community-driven
    platforms at various levels. We believe that a fine-grained billable and containerized
    deployment, similar to FaaS (Table [1\)](#page-2-0) but allowing much longer runtimes
    and large parallel jobs, would serve the community well. While we do not prescribe
    implementations for such a service, we believe a microservices architecture could
    be used to implement and operate a XaaS infrastructure. We continue by capturing
    and contrasting the state of


    the art in both HPC and Cloud along multiple axes: usage, accounting, hardware,
    co-design, scheduling, and security, and we outline a path to convergence towards
    productive highperformance accelerated cloud computing.


    The basis of XaaS exosystem is a portable container API that abstracts interfaces
    from cloud and HPC providers together with a standard operating system layer (Figure
    [2\)](#page-3-0). The key addition in the XaaS software ecosystem is a system-specific
    set of accelerated APIs for compute (e.g., BLAS), communication (e.g., MPI, libfabric),
    and I/O (e.g., NetCDF) that are tuned to each target system and maintained by
    the provider. A recompilation layer would apply to the workflow of either building
    or deploying containers and is not shown. A standard XaaS layer enables portable
    accelerated domain-specific simulations and services in specific domains such
    as weather and climate, quantum chromodynamics and quantum simulations, or material
    sciences. Those domain-specific containers would be maintained by the respective
    community.


    On-premise HPC and Cloud are two extremes in a tradeoff between capital expense
    (CapEx) and operational expense (OpEx). A convergence of workloads and interfaces
    across both enables interesting opportunities to balance the two in the future.


    ### Containers


    Containers form an interesting design point in software deployment. They emulate
    important parts of an operating system (e.g., a file system, processes, users)
    in a lightweight runtime that runs on a host operating system. The key is that
    containers provide a standardized clean and slim interface to the host OS and
    can thus be portable across many platforms and architectures. They have their
    weaknesses, for example, excessive memory consumption due to limited sharing [\[15\]](#page-7-8).
    Yet, they form an interesting point solution in a complex design space. Originally,
    computers ran individual applications that had to interface to all hardware directly.
    The emergence of multiprogramming in OSs then drove the adoption of portable interfaces
    (POSIX). The cloud started its journey by offering rented virtualized hardware
    as "Infrastructure as a Service" (IaaS), whereby customers would deploy their
    full OS as a virtual machine. Concurrently, HPC centers offered compute time to
    applications running in a machine-specific environment. Deploying a new application
    in such an environment routinely takes hours. The main difference to early Cloud
    VMs was that HPC applications were typically recompiled (to optimize them) for
    the specific machine and Cloud deployments were typically binary compatible (often
    x86). Such


    Torsten Hoefler, Marcin Copik, Pete Beckman, Andrew Jones, Ian Foster, Manish
    Parashar, Daniel Reed, Matthias Troyer, Thomas Schulthess, Dan Ernst, and Jack
    Dongarra


    <span id="page-3-0"></span>![](_page_3_Figure_1.jpeg)


    Figure 2: XaaS ecosystem and components.


    portable Cloud VMs are deployable in minutes on today''s cloud providers and provide
    the highest isolation as well as flexible choice of OS. When accounting for costs,
    VMs are typically charged by the hour.


    Containers started as a way to package libraries and dependencies together with
    an application and quickly developed into an encapsulated OS-like environment
    for more complex services. Most containers are significantly smaller than an OS
    VM (Megabytes vs. tens of Gigabytes) and can be deployed in seconds rather than
    minutes. Their light weight enables a finer-grained accounting for "Container
    as a Service" (CaaS), often at a minute or second granularity. Containers also
    support fast scale-up: a container image can be replicated to other machines to
    spin up more compute instances in seconds. The latest development, "Function as
    a Service" (FaaS) separates the deployment from the use of the containers. Requests
    simply invoke a function (which is defined in a container) that returns a result.
    Initially, such functions were stateless, but they have recently been extended
    with local state and can of course access cloud APIs for persistent storage. The
    main benefit of FaaS is that the user is not involved in the deployment, which
    simplifies life for users while also enabling a fine-grained billing model on
    a millisecond scale for each function and allowing the operator to schedule function
    executions creatively. Such functions can be executed in containers or even micro-VMs
    for higher isolation.


    Portability requires that binary containers execute on different machines. This
    needs both compatible container APIs as well as compatible binary executable formats.
    Furthermore, many highperformance workloads require running parallel computations
    distributed to multiple machines; thus, containers need to be able to communicate
    efficiently over a network. Today''s containers are based on standards defined
    by Docker and the Open Container Initiative (OCI) and portability is achieved
    by compiling containers for a given target architecture. For example, the popular
    container repository DockerHub lists seven architectures ranging from x86 and
    ARM to IBM''s Z series. Yet, performance-critical workloads requiring lowest-overhead
    communications have received comparatively little attention so far. We define
    performance portable containers as containers that achieve excellent performance
    on


    a variety of architectures. The term "excellent" admits various detailed definitions,
    such as "percent of peak" or "utilization", which we purposefully leave open.


    ### Using resources


    Users of HPC systems often engage with centers in a longterm (multi-year or decadal)
    relationship. This is partially due to what one could call "data gravity", i.e.,
    the hardship of moving massive amounts of data, but also due to the complexity
    of setting up a new environment and social aspects such as working practices and
    personal relationships. HPC centers are interested in high utilization of their
    machines with economy-of-scale arguments. Today''s batch systems typically reorder
    jobs to achieve the highest utilization. This often leads to delays of large jobs
    but can also accelerate the scheduling of smaller jobs through "backfilling" a
    gap that a waiting larger job may cause. This mode of operation is of course only
    amenable to run-to-completion jobs and cannot be used to operate online services
    or interactive sessions. Important urgent or interactive applications such as
    disease and pandemic simulation [\[5\]](#page-7-9), real-time tsunami and earthquake
    simulation [\[11,](#page-7-10) [17\]](#page-7-11), and time-constrained data processing
    to guide future experiments [\[14,](#page-7-12) [16\]](#page-7-13) require bespoke
    solutions on HPC systems or simply move to cloud systems. A corollary of this
    mode of operation is that (1) system availability plays a secondary role – HPC
    systems are often down for days at a time during working hours; (2) even system
    reliability is secondary because checkpoint/restart is a viable mode of operation
    as long as the storage system is reliable.


    Cloud users want to remain flexible and able to change systems to allow the market
    to regulate pricing. Yet, cloud providers have little incentive to standardize
    their interfaces to achieve easy portability. Proprietary interfaces and the high
    monetary costs of moving data out of the cloud result in some form of involuntary
    gravity towards a specific vendor. Fundamentally, all cloud systems work similarly:
    they provide customers with a set of online services and microservices. Even though
    providers can pass on their cost to customers if the market allows, optimizing
    the cost of foundational services can save millions of dollars in operational
    costs and is thus attractive to providers. Sometimes, performance considerations
    even lead to service consolidation. However, providers have only indirect incentives
    to improve the performance of customer workloads (who are charged per minute compute
    time). In addition, new models such as FaaS allow providers to use their infrastructure
    more efficiently and thus lower costs while improving usability and enabling completely
    new service and billing models (pay as you go and scale down to zero). For many
    cloud services, availability is critical and indeed non-negotiable as many important
    online systems run in cloud settings (e.g., credit card transactions, communication
    infrastructure). Availability is achieved by highly resilient and redundant infrastructure
    that increases costs at all levels. Scalability (aka "elasticity") is also important,
    and while aggregate user demand may exhibit less variance than that of individual
    users, it ultimately requires costly idle resources at the time of each request.
    In practice, resources are limited and requests can only be fulfilled if resources
    are available.


    Opportunities of converged XaaS. Both paradigms drive towards convergence: HPC
    requires increasingly reliable services, for example, for running performance-
    and availability-critical data systems such as the materials cloud[b](#page-4-0)
    , medical clouds[c](#page-4-1) , metagenomic analysis services [\[13\]](#page-7-14),
    and earth virtualization engines [\[12\]](#page-7-15). Cloud systems, on the other
    hand, already run batch jobs for background processing and are increasingly running
    large-scale bulk-synchronous AI training workloads in an HPC-like setting integrated
    with many services. One aspect to drive this convergence would be to consciously
    split workloads into interactive and non-interactive parts. For example, for a
    climate simulation, producing the data is a non-interactive component but analyzing
    and navigating the data is often driven by interactive discovery.


    Another important topic is ease-of-use. Cloud architectures with containers in
    HPC would allow communities to build their own platforms on top of a portable
    containerized environment. This way, HPC providers could support high-performance
    container interfaces and communities could layer domainspecific services inside
    containers, e.g., a climate simulation setup pre-installed in a container. The
    domain-specific layers could then drive scientific reproducibility and faster
    progress.


    ### Scheduling


    By scheduling we mean the process of allocating resources to compute jobs. Ideally,
    a compute job would never wait for resources and always start immediately. Yet,
    having some jobs wait may greatly increase the average utilization in a compute
    system by shifting demand in time. From a user''s perspective, one needs to consider
    the whole response time. Humans operate in milliseconds and interactive requests,
    such as loading webpages, should return in that time-frame. Some high-performance
    jobs such as ML inference need to operate in those time frames while others, such
    as climate simulations, do not. Yet, even for non-interactive workloads, large
    amounts of computation must sometimes be provided in short timeframes, such as
    in emergency situations like natural disasters or pandemics.


    High-performance computers are usually used through batch systems that enable
    complex orchestration of scheduling of different hardware types with advanced
    requests such as


    reservations. They aim at high utilization and trade-off interactivity and waiting
    times and sometimes also performance (e.g., allocating arbitrary nodes instead
    of close nodes). Some HPC centers are beginning to offer basic interactive services
    (at least a debug queue) and more and more are beginning to support "run forever"
    (server) type workloads. Such workloads are often supported by bespoke solutions
    or cloud technologies in which some begin to employ a microservice architecture
    as infrastructure. Thus, service workloads are slowly finding their way into HPC
    infrastructure and the job-based allocation model changes slowly. One could say
    that a services allocation model requires committing some resources forever (at
    least very long periods of time) and not on a per-job basis.


    Cloud initially scheduled only single VMs but moved quickly to groups of VMs to
    deploy microservices with orchestrators such as Kubernetes. The business was mostly
    focused around services for which reliability and availability is much more important
    than performance. Thus, performance was often sacrificed for reliability, for
    example when allocating groups of VMs into different racks to avoid correlated
    failures in the power supply. In addition, service level agreements often state
    time expectations for submit-tocompletion of interactive services. In addition,
    most cloud service providers run batch jobs to operate parts of the services that
    do not need to be interactive, for example, backups, nightly builds, or precomputed
    inference suggestions.


    Opportunities of converged XaaS. Portable high-performance containers would be
    beneficial for Cloud and HPC. For example, if one aims to collect low-rate sensor
    data over long periods of time, a normal cloud service is sufficient and cheap.
    However, when it comes to processing or analyzing this data, a XaaS job is likely
    better. For serving results to external users XaaS may be appropriate if requests
    are computationally expensive, or a normal cloud service may be more cost-effective
    for data access requests. Cloud service providers also see growing demand for
    non-interactive and large compute jobs such as AI (re)training on incoming data.
    Both, HPC and Cloud providers need to analyze the requirements of interactive
    vs. non-interactive jobs carefully; XaaS could provide additional flexibility
    and new opportunities for both cases.


    ## Accounting for resources


    HPC resources are often provided by agencies that make the acquisition of large
    resources easier than the money it would cost. Users propose research projects
    to acquire fixed allocations of resources to be consumed in a fixed time period.
    Those allocations cannot be repurposed for other things such as personnel. This
    approach, while it enables explorative high-risk research without the fiscal limitations,
    leads to a setup where research groups can acquire computational resources relatively
    cheaply (in terms of effort) but must invest their own people''s time into using
    them. Sometimes, users form consortia to support each other in such efforts, often
    focused on specific software (e.g., the US Lattice Quantum Chromodynamics or the
    Icosahedral Nonhydrostatic Weather and Climate Model Collaboration). However,
    such a setup often makes it hard to justify investing personnel resources into
    code optimizations, and performance consciousness thus varies largely across research
    groups and communities. Ultimately, users care about the


    <span id="page-4-0"></span><sup>b</sup><https://www.materialscloud.org/>


    <span id="page-4-1"></span><sup>c</sup><https://www.cancergenomicscloud.org/>


    total time and effort it takes to install, optimize, and execute their codes in
    a specific platform, rather than the aggregate efficiency of that platform.


    Cloud resources are acquired with real money paid by the users directly in highly
    varying plans ranging from pay-as-you-go credit card transactions to year-long
    rentals for fixed provisioning. Many accounting schemes are complex and set up
    to have users spend more at a certain provider (e.g., free starting credits, through
    loyalty programs, or simply charging for outbound data copies while providing
    free inbound data copying). Performance has a direct pricing incentive and one
    can translate person-effort into money rather directly.


    Opportunities of converged XaaS. Funding agencies are already thinking about merging
    the two models. For example, NSF''s open science grid cloud and cloudbank operate
    with an allocation-based funding model at the user-facing side but buy the compute
    resources with real money from private and public clouds. This model exploits
    the flexibility to trade off CapEx and OpEx and the power of large-volume contracts.


    ## Early hardware access, co-design, and code optimization


    HPC centers often provide early access to hardware that they are going to deploy
    for users, in order to improve "application readiness". Sometimes even pre-production
    hardware is offered in collaboration with vendors who are interested to optimize
    key applications for their architectures to provide the best price/performance
    ratio for compute centers and users. Achieving the best price/performance also
    drives system-level co-design that balances relatively high-level ratios, for
    example, network bandwidth per compute or storage bandwidth per compute. Engaging
    in more detailed hardware designs with vendors is complex because, despite the
    specialized purpose of HPC systems, their application mix is frequently diverse.
    Some HPC architectures were designed for specific applications (for example, IBM''s
    BlueGene was originally designed for biological applications), but they are generally
    used for a larger set of applications. Thus, co-design happens to a limited extent
    for some systems but is certainly not common practice today.


    Cloud service providers usually have access to early vendor designs and plans
    early on, but rarely expose that information to their users. One reason for this
    is that they want to run standard setups that they can scale quickly, cheaply,
    and at low risk to large user-bases. Diversity in special-purpose and early access
    hardware tends to hinder this scaling. Yet, today''s cloud providers are often
    first to roll out the newest technologies, and specialized compute may be supported
    if the user base is large enough or the service is profitable enough. For optimizing
    the workloads to the target architecture, cloud providers usually rely on HPC
    techniques such as libraries or compilers. Large markets (e.g., SQL databases
    or AI) can drive significant specialization and co-design at scale. Many of the
    architectures that providers use internally to provide such large-scale services
    are prime examples of co-design but are usually not exposed to the general public.


    Opportunities of converged XaaS. Hardware vendors pay more attention to larger
    markets and opportunities. Thus, an economyof-scale argument benefits both HPC
    and Cloud. Today, most vendor attention is focused on cloud providers and thus
    growing the performance-awareness in this context would be beneficial for all.
    The opportunity to co-design hardware for AI and HPC workloads is huge and could
    be fueled by XaaS setups, especially when combined with the flexibility of future
    chiplet-based architectures.


    ### Security and Isolation


    HPC systems traditionally do not focus on security and isolation at the system
    level. They either deploy unconnected ("air gapped") systems or have relatively
    weak security standards because users are generally trusted after a careful admission
    check. HPC systems and users also generally trust system and network administrators.
    Yet, recently, with the increased importance of HPC in AI, health-care, and defense,
    security of HPC systems is receiving much more attention.


    Cloud systems see security and isolation as mission-critical requirements. Encryption
    is often the default and trusted execution environments and even zero-trust environments
    are being rolled out. These capabilities are necessary because cloud providers
    (want to) admit anonymous users to their systems based solely on a credit card
    or other payment. Such users cannot be trusted. Furthermore, some big customers
    are not comfortable trusting the operator''s sysadmins. Thus cloud providers routinely
    implement special measures to implement "zero trust" settings (e.g., encrypt all
    stored data by default with user-provided securely handled keys).


    Opportunities of converged XaaS. As both HPC and Cloud have to deal with sensitive
    data and computations, both will require performant security solutions. Cloud
    systems could benefit from high-performance security systems to minimize overheads
    when providing privacy and isolation.


    ### Summary


    From our state of the art discussion, we conclude that XaaS opens many opportunities
    when converging high-performance and cloud approaches and workloads. XaaS requires
    but also enables a culture change in the communities to enable layered highperformance
    software platforms driven by performanceportable XaaS containers. Thus, we believe
    that we are at a perfect time and in a perfect setting to converge on XaaS architectures!


    ## HIGH-PERFORMANCE ACCELERATED CLOUD COMPUTING - A ROAD TO CONVERGENCE


    High-Performance Acceleration as a Service aims at a significant market, with
    AI as a service and HPC as a service being subsets, i.e., platforms that XaaS
    would enable. It will allow new solutions and scalable business on both the provider
    and user sides. Mainstream and most productive software development happens in
    the cloud space today and spawns a significant workforce that would provide value
    to the HPC community. Yet, cloud development is often not aimed at the highest-performing
    solutions, which provides an opportunity for cloud computing to benefit from decreased
    cost and CO2 output for higher-performance solutions.


    Networking support and support for acceleration are two key areas of difference
    in HPC and cloud infrastructures today. While HPC has used both for decades, they
    are only now becoming relevant in generic cloud settings. XaaS should enable both
    in a manner that is consistent with the original vision of plug and play.


    We now refine the observations made above into three principal technical requirements
    that we already outlined in the introduction. We outline (a path toward) technical
    solutions for each of those requirements in the next section.


    Performance portability needs to ensure not only high-performing containers but
    also the ability to move containers between systems while still achieving good
    performance on all. These requirements imply low overheads for isolation and virtualization
    as well as support for native acceleration and specialization features at each
    system.


    High-performance communication and I/O is required to move data in and out of
    the portable environment. These capabilities are needed both for data stored in
    the provider''s system (e.g., storage access) and for data exchanged between different
    instances of containers during the computation (e.g., MPI communication). Low
    overhead schemes require operating system bypass solutions, well-known from HPC,
    whereby user-space applications directly communicate with the hardware.


    High-performance allocation systems are needed to reduce the waiting time for
    user applications. These allocation systems also need to support complex scheduling
    policies to differentiate interactive and batch jobs and potentially large requests
    that need to launch thousands of container instances into a large-scale job. Providing
    these capabilities will likely require decentralized or at least parallelized
    scheduling strategies.


    ### ENABLING TECHNOLOGIES FOR XAAS


    We now briefly outline technologies and strategies that could be used to implement
    each of the three principal requirements (aka the "three Is"): Infrastructure
    for portable containers, fast communication and Input/Output to containers, and
    low-overhead and flexible Invocation.


    ## High-Performance Container Infrastructure and Input/Output


    Containers provide a simple and effective environment for software deployment
    by minimizing the interface to the outer (operating) system to clearly defined
    and slim calls. The Open Container Initiative (OCI) defines standards for container
    management. OCI offers hooks that allow dynamically linking system-specific libraries
    to containers during deployment. These hooks enable the provider to bind system-optimized
    libraries to the container without the full system being aware of the software
    running in the container. This additional layer of indirection allows programmers
    to extend the slim container interface with their own calls to performance libraries
    (e.g., BLAS or DNN). These capabilities can be enabled with Docker containers
    sitting on top of standard Linux namespaces and cgroups, for example.


    Existing HPC container infrastructures such as Apptainer (former Singularity)
    and Sarus are designed with performance in mind and take advantage of such features.
    Yet, there is no widely agreed standard for what libraries are supported for hooking
    across systems and what are the detailed interfaces and semantics of their calls.


    Having such a flexible library hooks interface also comes with some burdens. For
    example, not all libraries have the same hooks if you want to hook into an MPI
    library, the interface will depend on whether the container binary was compiled
    against Open MPI or MPICH. Unfortunately, each has different ABI definitions.
    This problem can be solved, albeit at the cost of additional complexity, by implementing
    multiple ABIs in each provider. The ecosystem could benefit from an ABI standardization.


    Library hooks solve the problem whenever performance-critical parts can be isolated
    into defined function calls. However, sometimes, complex application logic makes
    up for the majority of the time. In this case, compilers may be able to take advantage
    of specialties of the target architecture''s instruction set architecture (ISA).
    For example, NVIDIA''s H100 tensor cores offer much more functionality than V100
    cores, and Intel CPUs that support AVX2 are more powerful than those that support
    AVX1 only. Using such features requires recompilation to the specific target architecture.
    Unfortunately, such recompilation is somewhat in conflict with the simple binary-deployment
    strategy of containers, and endangers the model of "compile and test on my laptop
    and then deploy on the largest supercomputers".


    One approach to consider for the ISA issue is deployment recompilation, similar
    to software deployment models in Gentoo Linux or Spack. One could attach a set
    of build scripts to each software to rebuild it at the target system using the
    system-specific optimizing compiler. This approach would greatly increase the
    complexity of container deployment in different execution environments - from
    simple binary ISAs and APIs to complex source codes. One could protect from failure
    by always including portable binaries that use only the lowest-common-denominator
    ISA features, but that approach would compromise performance portability. Another
    approach would be to ship precompiled source code in a compiler intermediate representation
    form (e.g., LLVM IR or DaCe SDFGs [\[3\]](#page-7-16)) that are then optimized
    at the target architecture. Other portability approaches such as WASM are probably
    not performant enough.


    ## Fine-grained Invocation, Billing, Operations, and Integration


    Simple and fast invocation is key for accelerated high-performance cloud services.
    Such services often form workflows that are triggered or interfaced to from the
    outside. The connection to outside users could be offered through a web-service
    interface, for example based on a REST API such as FireCREST[d](#page-6-0) , which
    extends the established console interface with modern standard web services. Yet,
    REST must not be on the critical path due to its performance limitations, e.g.,
    when transferring large data volumes. Yet, as a control interface, for example,
    to coordinate the deployment of a job or a virtual cluster, it is sufficient.
    Thus, as in Globus, the


    <span id="page-6-0"></span><sup>d</sup><https://products.cscs.ch/firecrest/>


    Torsten Hoefler, Marcin Copik, Pete Beckman, Andrew Jones, Ian Foster, Manish
    Parashar, Daniel Reed, Matthias Troyer, Thomas Schulthess, Dan Ernst, and Jack
    Dongarra


    control channel may be REST, while the data channel employs high-performance protocols.


    XaaS should support batch jobs as well as interactive services and enable deployment
    at various levels. While the typical deployment of XaaS may likely be FaaS, run-forever
    services could be deployed either at the IaaS, PaaS, CaaS, or FaaS levels. This
    variety of deployment levels will enable users to build and deploy their own high-performance
    microservice architectures in an environment that is most productive for them.
    Service providers can then support such executions or subsets of such executions
    (e.g., only FaaS) based on their business model.


    ### OPPORTUNITIES


    We close by summarizing some of the opportunities of XaaS going forward. A shared
    and compatible execution platform between cloud providers and high-performance
    computing centers provides many opportunities. It would widen the market and enable
    seamless access to various compute resources, independent of the provider. Data
    location remains a challenging and somewhat fundamental issue, but decoupling
    the interfaces to data placement and to purchasing compute cycles will democratize
    big parts of the market. Furthermore, XaaS layers can enable scientific communities
    to distribute not only their source code but also their whole setup to others
    and thus enable seamless execution of their software across many architectures
    and providers at reasonable performance. A flexible scheduling and execution interface
    for XaaS maintains many of the benefits of FaaS workloads such that providers
    can increase their machine utilization; it will also enable large longer-running
    computations and sophisticated scheduling strategies.


    ### ACKNOWLEDGMENTS


    The authors would like to thank Satoshi Matsuoka for valuable advice and comments.


    ### REFERENCES


    - <span id="page-7-1"></span>[1] Moustafa AbdelBaky, Manish Parashar, Hyunjoo
    Kim, Kirk E. Jordan, Vipin Sachdeva, James Sexton, Hani Jamjoom, Zon-Yin Shae,
    Gergina Pencheva, Reza Tavakoli, and Mary F. Wheeler. 2012. Enabling High-Performance
    Computing as a Service. Computer 45, 10 (2012), 72–80.<https://doi.org/10.1109/MC.2012.293>

    - <span id="page-7-4"></span>[2] Michael Armbrust, Armando Fox, Rean Griffith,
    Anthony D Joseph, Randy H Katz, Andrew Konwinski, Gunho Lee, David A Patterson,
    Ariel Rabkin, Ion Stoica, et al. 2009. Above the clouds: A berkeley view of cloud
    computing. Technical Report. Technical Report UCB/EECS-2009-28, EECS Department,
    University of California . . . .

    - <span id="page-7-16"></span>[3] Tal Ben-Nun, Johannes de Fine Licht, Alexandros
    N. Ziogas, Timo Schneider, and Torsten Hoefler. 2019. Stateful Dataflow Multigraphs:
    A Data-Centric Model for Performance Portability on Heterogeneous Architectures.
    In Proceedings of the International Conference for High Performance Computing,
    Networking, Storage and Analysis (Denver, Colorado) (SC ''19). Association for
    Computing Machinery, New York, NY, USA, Article 81, 14 pages. [https://doi.org/10.1145/](https://doi.org/10.1145/3295500.3356173)
    [3295500.3356173](https://doi.org/10.1145/3295500.3356173)

    - <span id="page-7-2"></span>[4] Lucas Benedicic, Felipe A. Cruz, Alberto Madonna,
    and Kean Mariotti. 2019. Sarus: Highly Scalable Docker Containers for HPC Systems.
    In High Performance Computing, Michèle Weiland, Guido Juckeland, Sadaf Alam, and
    Heike Jagode (Eds.). Springer International Publishing, Cham, 46–60.

    - <span id="page-7-9"></span>[5] Nick Brown, Rupert Nash, Piero Poletti, Giorgio
    Guzzetta, Mattia Manica, Agnese Zardini, Markus Flatken, Jules Vidal, Charles
    Gueunet, Evgenij Belikov, Julien Tierny, Artur Podobas, Wei Der Chien, Stefano
    Markidis, and Andreas Gerndt. 2021. Utilising urgent computing to tackle the spread
    of mosquito-borne diseases. In 2021 IEEE/ACM HPC for Urgent Decision Making (UrgentHPC).
    36–44. [https:](https://doi.org/10.1109/UrgentHPC54802.2021.00010) [//doi.org/10.1109/UrgentHPC54802.2021.00010](https://doi.org/10.1109/UrgentHPC54802.2021.00010)

    - <span id="page-7-3"></span>[6] Marcin Copik, Konstantin Taranov, Alexandru Calotoiu,
    and Torsten Hoefler. 2023. rFaaS: Enabling High Performance Serverless with RDMA
    and Leases. In


    2023 IEEE International Parallel and Distributed Processing Symposium (IPDPS).
    897–907.<https://doi.org/10.1109/IPDPS54959.2023.00094>


    - <span id="page-7-0"></span>[7] Jack J. Dongarra, Iain S. Duff, Danny C. Sorensen,
    and Henk A. van der Vorst. 1998. Numerical Linear Algebra for High-Performance
    Computers. Society for Industrial and Applied Mathematics.<https://doi.org/10.1137/1.9780898719611>
    arXiv[:https://epubs.siam.org/doi/pdf/10.1137/1.9780898719611](https://arxiv.org/abs/https://epubs.siam.org/doi/pdf/10.1137/1.9780898719611)

    - <span id="page-7-5"></span>[8] Ian Foster. 2011. Globus Online: Accelerating
    and Democratizing Science through Cloud-Based Services. IEEE Internet Computing
    15, 3 (2011), 70–73. [https:](https://doi.org/10.1109/MIC.2011.64) [//doi.org/10.1109/MIC.2011.64](https://doi.org/10.1109/MIC.2011.64)

    - <span id="page-7-7"></span>[9] Ian Foster and Dennis B Gannon. 2017. Cloud computing
    for science and engineering. MIT Press.

    - <span id="page-7-6"></span>[10] Ian Foster, Yong Zhao, Ioan Raicu, and Shiyong
    Lu. 2008. Cloud Computing and Grid Computing 360-Degree Compared. In 2008 Grid
    Computing Environments Workshop. 1–10.<https://doi.org/10.1109/GCE.2008.4738445>

    - <span id="page-7-10"></span>[11] Thierry Goubier, Natalja Rakowsky, and Sven
    Harig. 2020. Fast Tsunami Simulations for a Real-Time Emergency Response Flow.
    In 2020 IEEE/ACM HPC for Urgent Decision Making (UrgentHPC). 21–26. [https://doi.org/10.1109/](https://doi.org/10.1109/UrgentHPC51945.2020.00008)
    [UrgentHPC51945.2020.00008](https://doi.org/10.1109/UrgentHPC51945.2020.00008)

    - <span id="page-7-15"></span>[12] Torsten Hoefler, Bjorn Stevens, Andreas F.
    Prein, Johanna Baehr, Thomas Schulthess, Thomas F. Stocker, John Taylor, Daniel
    Klocke, Pekka Manninen, Piers M. Forster, Tobias Kölling, Nicolas Gruber, Hartwig
    Anzt, Claudia Frauen, Florian Ziemen, Milan Klöwer, Karthik Kashinath, Christoph
    Schär, Oliver Fuhrer, and Bryan N. Lawrence. 2023. Earth Virtualization Engines:
    A Technical Perspective. Computing in Science & Engineering 25, 3 (2023), 50–59.
    <https://doi.org/10.1109/MCSE.2023.3311148>

    - <span id="page-7-14"></span>[13] Kevin P. Keegan, Elizabeth M. Glass, and Folker
    Meyer. 2016. MG-RAST, a Metagenomics Service for Analysis of Microbial Community
    Structure and Function. Springer New York, New York, NY, 207–233. [https://doi.org/10.1007/978-1-4939-](https://doi.org/10.1007/978-1-4939-3369-3_13)
    [3369-3\\_13](https://doi.org/10.1007/978-1-4939-3369-3_13)

    - <span id="page-7-12"></span>[14] Anthony Kremin, Stephen Bailey, Julien Guy,
    Theodore Kisner, and Kai Zhang. 2020. Rapid Processing of Astronomical Data for
    the Dark Energy Spectroscopic Instrument. In 2020 IEEE/ACM HPC for Urgent Decision
    Making (UrgentHPC). 1–9. <https://doi.org/10.1109/UrgentHPC51945.2020.00006>

    - <span id="page-7-8"></span>[15] Wei Qiu, Marcin Copik, Yun Wang, Alexandru Calotoiu,
    and Torsten Hoefler. 2023. User-guided Page Merging for Memory Deduplication in
    Serverless Systems. In 2023 IEEE International Conference on Big Data (Big Data).
    IEEE Computer Society.

    - <span id="page-7-13"></span>[16] Rafael Vescovi, Ryan Chard, Nickolaus D. Saint,
    Ben Blaiszik, Jim Pruyne, Tekin Bicer, Alex Lavens, Zhengchun Liu, Michael E.
    Papka, Suresh Narayanan, Nicholas Schwarz, Kyle Chard, and Ian T. Foster. 2022.
    Linking scientific instruments and computation: Patterns, technologies, and experiences.
    Patterns 3, 10 (2022), 100606.<https://doi.org/10.1016/j.patter.2022.100606>

    - <span id="page-7-11"></span>[17] K.K. Yoshimoto, D.J. Choi, R.L. Moore, A. Majumdar,
    and E. Hocks. 2012. Implementations of Urgent Computing on Production HPC Systems.
    Procedia Computer Science 9 (2012), 1687–1693.<https://doi.org/10.1016/j.procs.2012.04.186>
    Proceedings of the International Conference on Computational Science, ICCS 2012.


    ### BIOGRAPHIES


    Torsten Hoefler is a professor at ETH Zurich and the Chief Architect for Machine
    Learning at the Swiss National Supercomputing Center. His research interests revolve
    around high-performance artificial intelligence and computing systems. Hoefler
    received his highest degree in Computer Science from Indiana University. He is
    a fellow of the IEEE and ACM as well as a member of Academia Europaea. Contact
    him at [http://htor.ethz.ch/.](http://htor.ethz.ch/)


    Marcin Copik is a senior PhD student at ETH Zurich. He received a Master''s degree
    from RWTH Aachen, Germany. His research interests are in high-performance solutions
    for serverless computing and cloud computing techniques for HPC. He received a
    Microsoft Research PhD Fellowship and ACM-IEEE CS George Michael HPC Fellowship.
    Contact him at [https://mcopik.github.io.](https://mcopik.github.io)


    Pete Beckman is Co-Director of the Northwestern University / Argonne Institute
    for Science and Engineering. His research interests include High-Performance System
    Software and Operating Systems. Beckman received his PhD in Computer Science from
    Indiana University. Contact him at [beckman@anl.gov.](beckman@anl.gov)


    Andrew Jones is a Principal Program Manager at Microsoft at Redmond, WA, USA.
    His research interests include planning and delivery of large-scale high performance
    computing (HPC) services; technical and economic evaluation methods for HPC technologies
    and services; and the economic and human aspects of HPC, such as cost-value models
    and evolution of HPC skills. Jones received his BSc in Physics from the University
    of Manchester. He is a member at ACM SIGHPC. Contact him at [www.linkedin.com/in/andrewjones.](www.linkedin.com/in/andrewjones)
    Ian Foster is Distinguished Fellow and Director of the Data Science and Learning
    Division at Argonne National Laboratory in Lemont, Illinois 60439, USA, and Professor
    of Computer Science at the University of Chicago, Chicago, Illinois 60637, USA.
    His research interests include distributed and high-performance computing and
    their applications in the sciences. Foster received his PhD in Computer Science
    from Imperial College. He is a Fellow of the AAAS, ACM, BCS, and IEEE. Contact
    him at [foster@anl.gov.](foster@anl.gov)


    Manish Parashar is Director of the Scientific Computing and Imaging (SCI) Institute,
    Chair in Computational Science and Engineering, and Presidential Professor, Kalhert
    School of Computing at the University of Utah, Salt Lake City, UT, 84112. His
    research interests are in the broad areas of parallel and distributed computing
    and computational and data-enabled science and engineering. Parashar received
    his Ph.D. in Computer Engineering from Syracuse University. He is the founding
    chair of the IEEE Technical Community on High Performance Computing (TCHPC), and
    is Fellow of AAAS, ACM, and IEEE. Contact him at [http://manishparashar.org.](http://manishparashar.org)


    Daniel Reed is a Presidential Professor and Professor of Computer Science and
    Electrical & Computer Engineering at the University of Utah in Salt Lake City,
    Utah, 84117, USA. His research interests include computational science, science
    and engineering policy, and high-performance computing. Reed received his Ph.D.
    in computer science from Purdue University. He is a fellow of the ACM, IEEE, and
    AAAS. Contact him at [dan.reed@utah.edu.](dan.reed@utah.edu)


    Matthias Troyer is Technical Fellow and Corporate Vice President at Microsoft
    Corporation in Redmond, WA. His interests include Quantum Computation, High-Performance
    Cloud Computing and AI acceleration for for science. Troyer received his PhD in
    Physics from ETH Zurich. Contact him at [matthias.troyer@microsoft.com.](matthias.troyer@microsoft.com)
    Thomas Schulthess is Director of the Swiss National Supercomputing Center (CSCS).
    His research interests include High-Performance and Cloud Computing. Schulthess
    received his PhD in Physics from ETH Zurich. Contact him at [schulthess@cscs.ch.](schulthess@cscs.ch)


    Daniel Ernst is Director of System Architecture at Nvidia. His research interests
    include computer memory systems architecture, system performance modeling, and
    hardware/software co-design. Ernst received his PhD in Computer Science and Engineering
    from the University of Michigan. Contact him at [dane@nvidia.com.](dane@nvidia.com)


    Jack Dongarra is Professor at the University of Tennessee Knoxville. His research
    interests include High-Performance Computing, Parallel Programming, and Numerical
    Algorithms. Dongarra received his PhD in Applied Mathematics from the University
    of New Mexico. He is a Fellow of the IEEE, ACM, SIAM, and AAAS, member of the
    US NAE, the US NAS, and a Fellow of the British Royal Society, as well as recipient
    of the ACM A.M. Turing Award. Contact him at [dongarra@icl.utk.edu.](dongarra@icl.utk.edu)'
- id: a_logic_for_repair_and_state_recovery_in_byzantine_fault_tolerant_multi_agent_systems_a_logic_for_repair_and_state_recovery_in_byzantine_fault_tolerant_multi_agent_systems
  title: "A Logic for Repair and State Recovery in Byzantine Fault-tolerant\n  Multi-agent\
    \ Systems"
  abstract: 'We provide an epistemic logical language and semantics for the modeling
    and

    analysis of byzantine fault-tolerant multi-agent systems. This not only

    facilitates reasoning about the agents'' fault status but also supports model

    updates for implementing repair and state recovery. For each agent, besides the

    standard knowledge modality our logic provides an additional modality called

    hope, which is capable of expressing that the agent is correct (not faulty),

    and also dynamic modalities enabling change of the agents'' correctness status.

    These dynamic modalities are interpreted as model updates that come in three

    flavours: fully public, more private, or involving factual change. We provide

    complete axiomatizations for all these variants in the form of reduction

    systems: formulas with dynamic modalities are equivalent to formulas without.

    Therefore, they have the same expressivity as the logic of knowledge and hope.

    Multiple examples are provided to demonstrate the utility and flexibility of

    our logic for modeling a wide range of repair and state recovery techniques

    that have been implemented in the context of fault-detection, isolation, and

    recovery (FDIR) approaches in fault-tolerant distributed computing with

    byzantine agents.'
  url: http://arxiv.org/abs/2401.06451v3
  keywords: ''
  document: "# A Logic for Repair and State Recovery in Byzantine Fault-tolerant Multi-agent\
    \ Systems\n\nHans van Ditmarsch1[0000−0003−4526−8687] , Krisztina Fruzsa2[0000−0002−2013−1003]<sup>⋆</sup>\
    \ , Roman Kuznets2[0000−0001−5894−8724]⋆⋆\f, and Ulrich Schmid2 [0000−0001−9831−8583]\n\
    \n<sup>1</sup> CNRS, University of Toulouse, IRIT, France hansvanditmarsch@gmail.com\
    \ <sup>2</sup> Embedded Computing Systems Group, TU Wien, Austria krisztina.fruzsa@tuwien.ac.at,\
    \ {rkuznets,s}@ecs.tuwien.ac.at\n\nAbstract. We provide novel epistemic logical\
    \ language and semantics for modeling and analysis of byzantine fault-tolerant\
    \ multi-agent systems, with the intent of not only facilitating reasoning about\
    \ the agents' fault status but also supporting model updates for repair and state\
    \ recovery. Besides the standard knowledge modalities, our logic provides additional\
    \ agent-specific hope modalities capable of expressing that an agent is not faulty,\
    \ and also dynamic modalities enabling change to the agents' correctness status.\
    \ These dynamic modalities are interpreted as model updates that come in three\
    \ flavors: fully public, more private, and/or involving factual change. Tailored\
    \ examples demonstrate the utility and flexibility of our logic for modeling a\
    \ wide range of fault-detection, isolation, and recovery (FDIR) approaches in\
    \ mission-critical distributed systems. By providing complete axiomatizations\
    \ for all variants of our logic, we also create a foundation for building future\
    \ verification tools for this important class of fault-tolerant applications.\n\
    \nKeywords: byzantine fault-tolerant distributed systems · FDIR · multi-agent\
    \ systems · modal logic\n\n## <span id=\"page-0-1\"></span>1 Introduction and\
    \ Overview\n\nState of the art. A few years ago, the standard epistemic analysis\
    \ of distributed systems via the runs-and-systems framework [\\[13,](#page-20-0)\
    \ [18,](#page-20-1) [28\\]](#page-21-0) was finally extended [\\[22](#page-20-2)[–24\\\
    ]](#page-20-3) to fault-tolerant systems with (fully) byzantine agents [\\[25\\\
    ]](#page-21-1).[3](#page-0-0) Byzantine agents constitute the worst-case scenario\
    \ in terms of fault-tolerance: not only can they arbitrarily deviate from their\
    \ respective protocols, but the perception of their own actions and observed events\
    \ can be corrupted, possibly unbeknownst to them, resulting in false memories.\
    \ Whether byzantine agents are actually present in a system, the very possibility\
    \ of their presence has drastic and debilitating effects on the epistemic state\
    \ of all agents, including the correct (i.e., non-faulty) ones, due to the inability\
    \ to rule out so-called brain-in-a-vat scenarios [\\[29\\]](#page-21-2): a brain-in-a-vat\
    \ agent is a faulty agent with completely corrupted perceptions that provide no\
    \ reliable information about the system [\\[23\\]](#page-20-4). In such a system,\
    \ no agent can ever know certain elementary facts, such as their own or some other\
    \ agent's correctness, no matter whether the system is asynchronous [\\[23\\]](#page-20-4)\
    \ or synchronous [\\[34\\]](#page-21-3). Agents can, however, sometimes know their\
    \ own faultiness or obtain belief in some other agents' faultiness [\\[33\\]](#page-21-4).\n\
    \n<sup>⋆</sup> Was a PhD student in the FWF doctoral program LogiCS (W1255) and\
    \ also supported by the FWF project DMAC (P32431).\n\n<sup>⋆⋆</sup> This research\
    \ was funded in whole or in part by the Austrian Science Fund (FWF) project ByzDEL\
    \ [\\[10.55776/P33600\\]](https://doi.org/10.55776/P33600). For open access purposes,\
    \ the author has applied a CC BY public copyright license to any author accepted\
    \ manuscript version arising from this submission.\n\n<span id=\"page-0-0\"></span><sup>3</sup>\
    \ The term 'byzantine' is not always used consistently in the literature. In some\
    \ instances, agents were called byzantine despite exhibiting only restricted (sometimes\
    \ even benign [\\[10\\]](#page-20-5)) types of faults. In those terms, agents\
    \ we call 'byzantine' in this paper would be called 'fully byzantine.'\n\n####\
    \ 2 H. van Ditmarsch, K. Fruzsa, R. Kuznets, U. Schmid\n\nIn light of knowledge\
    \ Kiϕ often being unachievable in systems with byzantine agents, [\\[23\\]](#page-20-4)\
    \ also introduced a weaker epistemic notion called hope. It was initially defined\
    \ as\n\n$$\nH_i\\varphi := correct_i \\rightarrow K_i(correct_i \\rightarrow \\\
    varphi),\n$$\n\nwhere the designated atom correct<sup>i</sup> represents agent\
    \ i's correctness. In this setting, one can define belief as Biϕ := Ki(correct<sup>i</sup>\
    \ → ϕ) [\\[33\\]](#page-21-4). Hope was successfully used in [\\[15\\]](#page-20-6)\
    \ to analyze the Firing Rebels with Relay (FRR) problem, which is the core of\
    \ the well-known consistent broadcasting primitive [\\[36\\]](#page-21-5). Consistent\
    \ broadcasting has been used as a pivotal building block in fault-tolerant distributed\
    \ algorithms, e.g., for byzantine fault-tolerant clock synchronization [\\[9,](#page-20-7)\
    \ [16,](#page-20-8) [31,](#page-21-6) [36,](#page-21-5) [39\\]](#page-21-7), synchronous\
    \ consensus [\\[37\\]](#page-21-8), and as a general reduction of distributed\
    \ task solvability in systems with byzantine failures to solvability in systems\
    \ with crash failures [\\[26\\]](#page-21-9).\n\nThe hope modality was first axiomatized\
    \ in [\\[14\\]](#page-20-9) using correct<sup>i</sup> as designated atoms. Whereas\
    \ the resulting logic turned out to be well-suited for modeling and analyzing\
    \ problems in byzantine fault-tolerant distributed computing systems like FRR\
    \ [\\[15\\]](#page-20-6), it is unfortunately not normal. Our long-term goal of\
    \ also creating the foundations for automated verification of such applications\
    \ hence suggested to look for an alternative axiomatization. In [\\[6\\]](#page-19-0),\
    \ we presented a normal modal logic that combines KB4<sup>n</sup> hope modalities\
    \ with S5<sup>n</sup> knowledge modalities, which is based on defining correct<sup>i</sup>\
    \ := ¬Hi⊥ via frame-characterizable axioms. This logic indeed unlocks powerful\
    \ techniques developed for normal modal logics both in model checkers like DEMO\
    \ [\\[11\\]](#page-20-10) or MCK [\\[17\\]](#page-20-11) and, in particular, in\
    \ epistemic theorem proving environments such as LWB [\\[20\\]](#page-20-12).\n\
    \nStill, both versions [\\[6,](#page-19-0)[14\\]](#page-20-9) of the logic of\
    \ hope target byzantine fault-tolerant distributed systems only where, once faulty,\
    \ agents remain faulty and cannot be \"repaired\" to become correct again. Indeed,\
    \ solutions for problems like FRR employ fault-masking techniques based on replication\
    \ [\\[35\\]](#page-21-10), which prevent the adverse effects of the faulty agents\
    \ from contaminating the behavior of the correct agents but do not attempt to\
    \ change the behavior of the faulty agents. Unfortunately, fault masking is only\
    \ feasible if no more than a certain fraction f of the overall n agents in the\
    \ system may become faulty (e.g., n ≥ 3f + 1 in the case of FRR). Should it ever\
    \ happen that more than f agents become faulty in a run, no properties can typically\
    \ be guaranteed anymore, which would be devastating in mission-critical applications.\n\
    \nFault-detection, isolation, and recovery (FDIR) is an alternative fault-tolerance\
    \ technique, which attempts to discover and repair agents that became faulty in\
    \ order to subsequently reintegrate them into the system. The primary target here\
    \ are permanent faults, which do not go away \"by themselves\" after some time\
    \ but rather require explicit corrective actions. Pioneering fault-tolerant systems\
    \ implementations like MAFT [\\[21\\]](#page-20-13) and GUARDS [\\[30\\]](#page-21-11)\
    \ combined fault-masking techniques like byzantine agreement [\\[25\\]](#page-21-1)\
    \ and FDIR approaches to harvest the best of both worlds.\n\nVarious paradigms\
    \ have been proposed for implementing the steps in FDIR: Fault-detection can be\
    \ done by a central FDIR unit, which is implemented in some very reliable technology\
    \ and oversees the whole distributed system. Alternatively, distributed FDIR employs\
    \ distributed diagnosis [\\[38\\]](#page-21-12), e.g., based on evidence [\\[1\\\
    ]](#page-19-1), and is typically combined with byzantine consensus [\\[25\\]](#page-21-1)\
    \ to ensure agreement among the replicated FDIR units. Agents diagnosed as faulty\
    \ are subsequently forced to reset and execute built-in self tests, possibly followed\
    \ by repair actions like hardware reconfiguration. Viewed at a very abstract level,\
    \ the FDI steps of FDIR thus cause a faulty agent to become correct again. Becoming\
    \ correct again is, however, not enough to enable the agent to also participate\
    \ in the (on-going) execution of the remaining system. The latter also requires\
    \ a successful state recovery step R, which makes the local state of the agent\
    \ consistent with the current global system state. Various recovery techniques\
    \ have been proposed for this purpose, ranging from pro-active recovery [\\[32\\\
    ]](#page-21-13), where the local state of every agent is periodically replaced\
    \ by a majority-voted version, to techniques based on checkpointing & rollback\
    \ or message-logging & replay, see [\\[12\\]](#page-20-14) for a survey. The common\
    \ aspect of all these techniques is that the local state of the recovering agent\
    \ is changed based on information originating from other agents.\n\nOur contribution.\
    \ In this paper, we provide the first logic that not only enables one to reason\
    \ about the fault status of agents, but also provides mechanisms for updating\
    \ the model so as to\n\nchange the fault status of agents, as well as their local\
    \ states. Instead of handling such dynamics in the byzantine extension of the\
    \ runs-and-systems framework [\\[22–](#page-20-2)[24\\]](#page-20-3), i.e., in\
    \ a temporal epistemic setting, we do it in a dynamic epistemic setting: we restrict\
    \ our attention to the instants where the ultimate goal of (i) the FDI steps (successfully\
    \ repairing a faulty processor) and (ii) the R step (recovering the repaired processor's\
    \ local state) is reached, and investigate the dynamics of the agents' correctness/faultiness\
    \ and its interaction with knowledge at these instants.\n\nOur approach enables\
    \ us to separate the issue of (1) verifying the correctness of the specification\
    \ of an FDIR mechanism from the problem of (2) guaranteeing the correctness of\
    \ its protocol implementation, and to focus on (1). Indeed, verifying the correctness\
    \ of the implementation of some specification is the standard problem in formal\
    \ verification, and powerful tools exist that can be used for this purpose. However,\
    \ even a fully verified FDIR protocol would be completely useless if the FDIR\
    \ specification was erroneous from the outset, in the sense that it does not correctly\
    \ identify and hence repair faulty agents in some cases. Our novel logics and\
    \ the underlying model update procedures provide, to the best of our knowledge,\
    \ the first suitable foundations for (1), as they allow to formally specify (1.a)\
    \ when a model update shall happen, and (1.b) the result of the model update.\
    \ While we cannot claim that no better approach exists, our various examples at\
    \ least reveal that we can model many crucial situations arising in FDIR schemes.\n\
    \nIn order to introduce the core features of our logic and its update mechanisms,\
    \ we use a simple example: Consider two agents a and b, each knowing their own\
    \ local states, where global state ij, with i, j ∈ {0, 1}, means that a's local\
    \ state is i and b's local state is j. To describe agent a's local state i we\
    \ use an atomic proposition pa, where p<sup>a</sup> is true if i = 1 in global\
    \ state ij and p<sup>a</sup> is false if i = 0, and similarly for b's local state\
    \ j and atomic proposition pb.\n\n![](_page_2_Figure_4.jpeg)\n\nKnowledge and\
    \ hope of the agents is represented in a Kripke model M for our system consisting\
    \ of four states (worlds), shown in the left part of the figure above. Knowledge\
    \ K<sup>i</sup> is interpreted by a knowledge relation K<sup>i</sup> and hope\
    \ H<sup>i</sup> is interpreted by a hope relation H<sup>i</sup> . Worlds that\
    \ are Ki-indistinguishable, in the sense that agent i cannot distinguish which\
    \ of the worlds is the actual one, are connected by an i-labeled link, where we\
    \ assume reflexivity, symmetry, and transitivity. Worlds ij that are in the non-empty\
    \ part of the H<sup>i</sup> relation, where agent i is correct, have i outlined\
    \ as **0** or **1**. For example, in the world depicted as 0**1** above, agent\
    \ a is faulty and agent b is correct.\n\nNow assume that we want agent a to become\
    \ correct in states 01 and 11 where p<sup>b</sup> is true. For example, this could\
    \ be dictated by an FDIR mechanism that caused b to diagnose a as faulty. Changing\
    \ the fault status of a accordingly (while not changing the correctness of b)\
    \ results in the updated model on the right in the above figure. Note that a was\
    \ correct in state 00 in the left model, but did not know this, whereas agent\
    \ a knows that she is correct in state 00 after the update. Such a model update\
    \ will be specified in our approach by a suitable hope update formula for every\
    \ agent, which, in the above example, is ¬Ha⊥ ∨ p<sup>b</sup> for agent a and\
    \ ¬Hb⊥ for agent b. Note carefully that every hope update formula implicitly specifies\
    \ both (a) the situation in the original model in which a change of the hope relation\
    \ is applied, namely, some agent i's correctness/faultiness status encoded as\
    \ ¬Hi⊥/Hi⊥, and (b) the result of the respective update of the hope relation.\n\
    \nClearly, different FDIR approaches will require very different hope update formulas\
    \ for describing their effects. In our logic, we provide two basic hope update\
    \ mechanisms that can be used here: public updates, in which the agents are certain\
    \ about the exact hope updates occurring at other agents, and private updates\
    \ (strictly speaking, semi-private updates [\\[5\\]](#page-19-2)), in which the\
    \ agents may be uncertain about the particular hope updates occurring at other\
    \ agents. The former\n\n#### 4 H. van Ditmarsch, K. Fruzsa, R. Kuznets, U. Schmid\n\
    \nis suitable for FDIR approaches where a central FDIR unit in the system triggers\
    \ and coordinates all FDIR activities, the latter is needed for some distributed\
    \ FDIR schemes.\n\nMoreover, whereas the agents' local states do not necessarily\
    \ have to be changed when becoming correct, FDIR usually requires to erase traces\
    \ of erroneous behavior before recovery from the history in the R step. Our logic\
    \ hence provides an additional factual change mechanism for accomplishing this\
    \ as well. For example, simultaneously with or after becoming correct, agents\
    \ may also need to change their local state by making false the atomic proposition\
    \ that records that step 134 of the protocol was (erroneously) executed. Analogous\
    \ to hope update formulas, suitable factual change formulas are used to encode\
    \ when and how atomic propositions will change. Besides syntax and semantics,\
    \ we provide complete axiomatizations of all variants of our logic, and demonstrate\
    \ its utility and flexibility for modeling a wide range of FDIR mechanisms by\
    \ means of many application examples. In order to focus on the essentials, we\
    \ use only 2-agent examples for highlighting particular challenges arising in\
    \ FDIR. We note, however, that it is usually straightforward to generalize those\
    \ for more than two agents, and to even combine them for modeling more realistic\
    \ FDIR scenarios.\n\nSummary of the utility of our logic. Besides contributing\
    \ novel model update mechanisms to the state-of-the-art in dynamic epistemic logic,\
    \ the main utility of our logic is that it enables epistemic reasoning and verification\
    \ of FDIR mechanism specifications. Indeed, even a fully verified protocol implementation\
    \ of some FDIR mechanism would be meaningless if its specification allowed unintended\
    \ effects. Our hope update/factual change formulas formally and exhaustively specify\
    \ what the respective model update accomplishes, i.e., encode both the preconditions\
    \ for changing some agent's fault status/atomic propositions and the actual change.\
    \ Given an initial model and these update formulas, our logic thus enables one\
    \ to check (even automatically) whether the updated model has all the properties\
    \ intended by the designer, whether certain state invariants are preserved by\
    \ the update, etc. Needless to say, there are many reasons why a chosen specification\
    \ might be wrong in this respect: the initial model might not provide all the\
    \ required information, undesired fault status changes could be triggered in some\
    \ worlds, or supporting information required for an agent to recover its local\
    \ state might not be available. The ability to (automatically) verify the absence\
    \ of such undesired effects of the specification of an FDIR mechanism is hence\
    \ important in the design of mission-critical distributed systems.\n\nPaper organization.\
    \ Section [2](#page-3-0) recalls the syntax and semantics of the logic for knowledge\
    \ and hope [\\[6\\]](#page-19-0). Section [3](#page-4-0) expands this language\
    \ with dynamic modalities for publicly changing hope. Section [4](#page-11-0)\
    \ generalizes the language to private updates. In Sect. [5,](#page-16-0) we add\
    \ factual change to our setting. Some conclusions in Sect. [6](#page-19-3) complete\
    \ our paper.\n\n## <span id=\"page-3-0\"></span>2 A Logic of Hope and Knowledge\n\
    \nWe succinctly present the logic of hope and knowledge [\\[6\\]](#page-19-0).\
    \ Throughout our presentation, let A := {1, . . . , n} be a finite set of agents\
    \ and let Prop be a non-empty countable set of atomic propositions.\n\nSyntax.\
    \ The language LKH is defined as\n\n$$\n\\varphi ::= p \\mid \\neg \\varphi \\\
    mid (\\varphi \\land \\varphi) \\mid K_i \\varphi \\mid H_i \\varphi,\n$$\n\\\
    n\n$$\n(1)\n$$\n\nwhere p ∈ Prop and i ∈ A. We take ⊤ to be the abbreviation for\
    \ some fixed propositional tautology and ⊥ for ¬⊤. We also use standard abbreviations\
    \ for the remaining boolean connectives, Kbiϕ for the dual modality ¬Ki¬ϕ for\
    \ 'agent a considers ϕ possible', Hbiϕ for ¬Hi¬ϕ, and EGϕ for mutual knowledge\
    \ V <sup>i</sup>∈<sup>G</sup> Kiϕ in a group G ⊆ A. Finally, we define belief\
    \ Biϕ as Ki(¬Hi⊥ → ϕ); we recall that ¬Hi⊥ means that i is correct.\n\nStructures.\
    \ A Kripke model is a tuple M = (W, π, K, H) where W is a non-empty set of worlds\
    \ (or states), π: Prop → P(W) is a valuation function mapping each atomic proposition\
    \ to the set of worlds where it is true, and K : A → P(W × W) and H : A → P(W\
    \ × W) are functions that assign to each agent i a knowledge relation K<sup>i</sup>\
    \ ⊆ W ×W respectively a hope relation H<sup>i</sup> ⊆ W ×W, where we have written\
    \ K<sup>i</sup> resp. H<sup>i</sup> for K(i) and H(i). We write Hi(w) for {v |\
    \ (w, v) ∈ Hi} and wHiv for (w, v) ∈ H<sup>i</sup> , and similarly for K<sup>i</sup>\
    \ . We require knowledge relations K<sup>i</sup> to be equivalence relations and\
    \ hope relations H<sup>i</sup> to be shift-serial (that is, if wHiv, then there\
    \ exists a z ∈ W such that vHiz). In addition, the following conditions should\
    \ also be satisfied:\n\n$$\n\\mathcal{H} \\text{in} \\mathcal{K}: \\qquad \\mathcal{H}_i\
    \ \\subseteq \\mathcal{K}_i, \\text{one} \\mathcal{H}: \\qquad (\\forall w, v\
    \ \\in W)(\\mathcal{H}_i(w) \\neq \\varnothing \\land \\mathcal{H}_i(v) \\neq\
    \ \\varnothing \\land w \\mathcal{K}_i v \\Longrightarrow w \\mathcal{H}_i v).\n\
    $$\n\nIt can be shown that all H<sup>i</sup> relations are so-called partial equivalence\
    \ relations: they are transitive and symmetric binary relations [\\[27\\]](#page-21-14).\n\
    \nThe class of Kripke models (W, π, K, H) (given A and Prop) is named KH.\n\n\
    Semantics. We define truth for formulas ϕ ∈ LKH at a world w of a model M = (W,\
    \ π, K, H) ∈ KH in the standard way: in particular, M, w |= p iff w ∈ π(p) where\
    \ p ∈ Prop; boolean connectives are classical; M, w |= Kiϕ iff M, v |= ϕ for all\
    \ v such that wKiv; and M, w |= Hiϕ iff M, v |= ϕ for all v such that wHiv. A\
    \ formula ϕ is valid in model M, denoted M |= ϕ, iff M, w |= ϕ for all w ∈ W,\
    \ and it is valid, notation |= ϕ (or KH |= ϕ) iff it is valid in all models M\
    \ ∈ KH.\n\nAxiomatization. The axiom system KH for knowledge and hope is given\
    \ below.\n\nP all propositional tautologies T <sup>K</sup> Kiϕ → ϕ H† Hi¬Hi⊥ KH\
    \ Hiϕ ↔ ¬Hi⊥ → Ki(¬Hi⊥ → ϕ) K<sup>K</sup> Ki(ϕ → ψ) ∧ Kiϕ → Kiψ MP from ϕ and\
    \ ϕ → ψ, infer ψ 4 <sup>K</sup> Kiϕ → KiKiϕ Nec<sup>K</sup> from ϕ, infer Kiϕ\
    \ 5 <sup>K</sup> ¬Kiϕ → Ki¬Kiϕ\n\n<span id=\"page-4-1\"></span>Theorem 1 ([\\\
    [6\\]](#page-19-0)). KH is sound and complete with respect to KH.\n\n### <span\
    \ id=\"page-4-0\"></span>3 Public Hope Update\n\n#### 3.1 Syntax and Semantics\n\
    \nDefinition 2 (Logical language). Language L pub KH is obtained from LKH by adding\
    \ one new construct:\n\n$$\n\\varphi ::= p \\mid \\neg \\varphi \\mid (\\varphi\
    \ \\land \\varphi) \\mid K_i \\varphi \\mid H_i \\varphi \\mid [\\varphi, \\ldots,\
    \ \\varphi] \\varphi.\n$$\n\nWe read a formula of the shape [ϕ1, . . . , ϕn]ψ,\
    \ often abbreviated as [~ϕ]ψ as follows: after revising or updating hope for agent\
    \ i with respect to ϕ<sup>i</sup> for all agents i ∈ A simultaneously, ψ (is true).\
    \ We call the formula ϕ<sup>i</sup> the hope update formula for agent i.\n\nDefinition\
    \ 3 (Semantics of public hope update). Let a tuple ~ϕ ∈ (L pub KH ) <sup>n</sup>,\
    \ a model M = (W, π, K, H) ∈ KH, and a world w ∈ W be given. Then\n\n$$\nM, w\
    \ \\models [\\vec{\\varphi}]\\psi \\quad \\text{iff} \\quad M^{\\vec{\\varphi}},\
    \ w \\models \\psi,\n$$\n\nwhere M ~ϕ := (W, π, K, H~ϕ) such that for each agent\
    \ i ∈ A:\n\n$$\nw\\mathcal{H}_i^{\\chi}v \\qquad \\text{iff} \\qquad w\\mathcal{K}_iv,\
    \ \\quad M, w \\models \\chi, \\quad \\text{and} \\quad M, v \\models \\chi\n\
    $$\n\nand where we write H χ i for (H~ϕ)<sup>i</sup> if the i-th formula in ~ϕ\
    \ is χ. If M, w 6|= χ, then H χ i (w) = ∅: agent i is faulty in state w after\
    \ the update, i.e., Hi⊥ is true. Whereas if M, w |= χ, then H χ i (w) 6= ∅: agent\
    \ i is correct in state w after the update, i.e., ¬Hi⊥ is true. If the hope update\
    \ formula for agent i is ¬Hi⊥, then ¬Hi⊥ is true in the same states before and\
    \ after the update. Therefore, H ¬Hi⊥ <sup>i</sup> = H<sup>i</sup> : the hope\
    \ relation for i does not change. On the other hand, if the hope update formula\
    \ for agent i is Hi⊥, then H Hi⊥ i (w) = ∅ iff Hi(w) 6= ∅: the correctness of\
    \ agent i flips in every state. If we wish to model that agent i becomes more\
    \ correct (in the model), then the hope update formula for agent i should have\
    \ the shape ¬Hi⊥∨ϕ: the left disjunct ¬Hi⊥ guarantees that in all states where\
    \ i already was correct, she remains correct. We write\n\n$$\n[\\varphi]_i \\\
    psi\n$$\n for  $[\\neg H_1 \\bot, \\dots, \\neg H_{i-1} \\bot, \\varphi, \\neg\
    \ H_{i+1} \\bot, \\dots, \\neg H_n \\bot] \\psi$ \n\n<span id=\"page-5-1\"></span>Similarly,\
    \ we write [ϕ]Gψ if the hope update formulas for all agents i ∈ G is ϕ and other\
    \ agents j have the trivial hope update formula ¬Hj⊥.\n\nProposition 4. If ~ϕ\
    \ ∈ (L pub KH ) <sup>n</sup> and M = (W, π, K, H) ∈ KH, then M ~ϕ ∈ KH.\n\nProof.\
    \ Let i ∈ A and χ be the ith formula in ~ϕ. We need to show that relation H χ\
    \ i is shift-serial and that it satisfies properties HinK and oneH.\n\n- [shift-serial]:\
    \ Let w ∈ W. Assume v ∈ H<sup>χ</sup> i (w), that is, wKiv, and M, w |= χ and\
    \ M, v |= χ. Now vKiw follows by symmetry of K<sup>i</sup> . Therefore, H χ i\
    \ (v) 6= ∅ since w ∈ H<sup>χ</sup> i (v).\n- [HinK]: This follows by definition.\n\
    - [oneH]: Let w, v ∈ W. Assume that H χ i (w) 6= ∅, that H χ i (v) 6= ∅, and that\
    \ wKiv. It follows that there exists some w ′ ∈ H<sup>χ</sup> i (w), implying\
    \ that M, w |= χ, and v ′ ∈ H<sup>χ</sup> i (v), implying that M, v |= χ. Now\
    \ wH χ i v follows immediately. ⊓⊔\n\nThe hope update ϕ for an agent a is reminiscent\
    \ of the refinement semantics of public announcement ϕ [\\[4\\]](#page-19-4).\
    \ However, unlike a public announcement, the hope update installs an entirely\
    \ novel hope relation and discards the old one.\n\n#### 3.2 Applications\n\nIn\
    \ this section, we apply the logical semantics just introduced to represent some\
    \ typical scenarios that occur in FDIR applications. We provide several simple\
    \ two-agent examples.\n\nExample 5 (Correction based on agent b having diagnosed\
    \ a as faulty). To correct agent a based on KbHa⊥, we update agent a's hope relation\
    \ based on formula ¬Ha⊥ ∨ KbHa⊥ (and agent b's hope relation based on formula\
    \ ¬Hb⊥). We recall that the disjunct ¬Ha⊥ guarantees that agent a will stay correct\
    \ if she already was. The resulting model transformation is:\n\n![](_page_5_Figure_13.jpeg)\n\
    \nAfter the update, in state 00, where a was correct but did not know this, and\
    \ state 10, where a knew she was faulty, we get:\n\nAt state 00: M, 00 |= [¬Ha⊥\
    \ ∨ KbHa⊥]a¬Ha⊥ a remains correct M, 00 |= [¬Ha⊥ ∨ KbHa⊥]aKa¬Ha⊥ a learned that\
    \ she is correct At state 10: M, 10 |= [¬Ha⊥ ∨ KbHa⊥]aHa⊥ a is still faulty M,\
    \ 10 |= [¬Ha⊥ ∨ KbHa⊥]aKba¬Ha⊥ a now considers it possible that she is correct\
    \ M, 10 |= [¬Ha⊥ ∨ KbHa⊥]aKbKba¬Ha⊥ b learned that\n\n<span id=\"page-5-0\"></span>\n\
    \na considers it possible that she is correct\n\nA straightforward generalization\
    \ of this hope update is correction based on distributed fault detection, where\
    \ all agents in some sufficiently large group G need to diagnose agent a as faulty.\
    \ If G is fixed, ¬Ha⊥ ∨ EGHa⊥ achieves this goal. If any group G of at least k\
    \ > 1 agents is eligible, then\n\n$$\n\\neg H_a \\perp \\vee \\bigvee_{G \\subseteq\
    \ \\mathcal{A}}^{|G|=k} E_G H_a \\perp\n$$\n\n<span id=\"page-6-0\"></span>is\
    \ the formula of choice.\n\nExample 6. We provide additional examples illustrating\
    \ the versatility of our approach:\n\n1. Self-correction under constraints. Unfortunately,\
    \ Example [5](#page-5-0) cannot be applied in byzantine settings in general, since\
    \ knowledge of other agents' faults is usually not attainable [\\[23\\]](#page-20-4).\
    \ Hence, one has to either resort to a weaker belief-based alternative or else\
    \ to an important special case of Example [5,](#page-5-0) namely, self-correction,\
    \ where G = {a}, i.e., agent a diagnoses itself as faulty. This remains feasible\
    \ in the byzantine setting because one's own fault is among the few things an\
    \ agent can know in such systems [\\[23\\]](#page-20-4). Let us illustrate this.\n\
    \nSelf-correction of agent a without constraints is carried out on the condition\
    \ that a knows he is faulty (KaHa⊥). The hope update formula for self-correction\
    \ of agent a with an optional additional constraint ϕ is\n\n$$\n\\neg H_a \\bot\
    \ \\vee (\\varphi \\wedge K_a H_a \\bot)\n$$\n\nwhere the ¬Ha⊥ part corresponds\
    \ to the worlds where agent a is already correct and the ϕ ∧ KaHa⊥ part says that,\
    \ if he knows that he is faulty (KaHa⊥), then he attempts to selfcorrect and succeeds\
    \ if, additionally, a (possibly external) condition ϕ holds. Very similarly to\
    \ Example [5](#page-5-0) we now add an additional constraint ϕ = pb. Notice that\
    \ the update is indeed slightly different than in Example [5,](#page-5-0) as a\
    \ no longer becomes correct in world 01.\n\n$$\n\\begin{array}{c|c}\\n01 & b \\\
    \\\n01 & b \\\\\na \\\\\nb \\\\\nb \\\\\n10\\n\\end{array}\\n\\quad\\n\\begin{array}{c|c}\\\
    n01 & b \\\\\na \\\\\nb \\\\\n10\\n\\end{array}\\n\\quad\\n\\begin{array}{c|c}\\\
    n01 & b \\\\\na \\\\\nb \\\\\nb \\\\\n10\\n\\end{array}\\n\\quad\\n\\begin{array}{c|c}\\\
    n11 \\\\\na \\\\\nb \\\\\nb \\\\\n00\\n\\end{array}\\n\\quad\\n\\begin{array}{c|c}\\\
    n01 & b \\\\\nb \\\\\na \\\\\nb \\\\\n10\\n\\end{array}\n$$\n\nAfter the update,\
    \ in state 00, where a was correct but did not know this, and state 10, where\
    \ a knew she was faulty, we get:\n\n| At state 00:                           \
    \     |                                             |\n|---------------------------------------------|---------------------------------------------|\n\
    | M, 00  = [¬Ha⊥ ∨ (pb<br>∧ KaHa⊥)]a¬Ha⊥      | a remains correct            \
    \               |\n| M, 00  = [¬Ha⊥ ∨ (pb<br>∧ KaHa⊥)]aKbaHa⊥    | a still considers\
    \ it possible she is faulty |\n| At state 10:                                |\
    \                                             |\n| M, 10  = [¬Ha⊥ ∨ (pb<br>∧ KaHa⊥)]aHa⊥\
    \       | a remains faulty                            |\n| M, 10  = [¬Ha⊥ ∨ (pb<br>∧\
    \ KaHa⊥)]aKba¬Ha⊥   | a now considers it possible she is correct  |\n| M, 10 \
    \ = [¬Ha⊥ ∨ (pb<br>∧ KaHa⊥)]aKbKba¬Ha⊥ | b learned that                      \
    \        |\n|                                             | a considers it possible\
    \ she is correct      |\n\n2. Update with fail-safe behavior. This example specifies\
    \ a variant of self-correction where a faulty agent is only made correct when\
    \ it knows that it is faulty. When it considers it possible that it is correct,\
    \ however, it deliberately fails itself. This can be viewed as a way to ensure\
    \ fail-safe behavior in the case of hazardous system states. What is assumed here\
    \ is that a deliberately failed agent just stops doing anything, i.e., halts,\
    \ so that it can subsequently be made correct via another model update, for example.\
    \ In order to specify a model update for fail-safe behavior of agent a, the hope\
    \ update formula KaHa⊥ can be used. The resulting model transformation is:\n\n\
    8 H. van Ditmarsch, K. Fruzsa, R. Kuznets, U. Schmid\n\n![](_page_7_Figure_1.jpeg)\n\
    \nAfter the update, in state 00, where a was correct but did not know this, and\
    \ state 10, where a knew she was faulty, we get:\n\n| At state 00:           \
    \    |                                 |\n|----------------------------|---------------------------------|\n\
    | M, 00  = [KaHa⊥]aHa⊥       | a became faulty                 |\n| M, 00  = [KaHa⊥]aKaHa⊥\
    \     | a learned that she is faulty    |\n| At state 10:               |    \
    \                             |\n| M, 10  = [KaHa⊥]a¬Ha⊥      | a became correct\
    \                |\n| M, 10  = [KaHa⊥]aKa¬Ha⊥    | a now knows that she is correct\
    \ |\n| M, 10  = [KaHa⊥]aKbbKa¬Ha⊥ | b now considers it possible     |\n|     \
    \                       | a knows she is correct          |\n\nThis hope update\
    \ would fail agent a also in global states where she knows that she is correct,\
    \ which might seem counterintuitive. In fault-tolerant systems with fully byzantine\
    \ agents, this consideration is moot since agents cannot achieve the knowledge\
    \ of their own correctness anyway [\\[23\\]](#page-20-4).\n\n3. Belief-based correction.\
    \ Since it is generally impossible for agent b 6= a to achieve KbHa⊥ in byzantine\
    \ settings [\\[23\\]](#page-20-4), correction based on knowledge of faults by\
    \ other agents is not implementable in practice. What can, in principle, be achieved\
    \ in such systems is belief BbHa⊥ of faults of other agents, where belief is defined\
    \ as Biϕ := Ki(¬Hi⊥ → ϕ) for any agent i and any formula ϕ.\n\nTo correct agent\
    \ b based on agent a believing b to be faulty, we update agent b's hope relation\
    \ based on formula ¬Hb⊥ ∨BaHb⊥. Note that BaHb⊥ is indeed initially true in world\
    \ 00: if a is correct, namely only in state 00 (and not in state 01), then b is\
    \ incorrect.\n\n![](_page_7_Figure_7.jpeg)\n\nAfter the update, in state 00, where\
    \ b was faulty but did not know this, and state 10, where b was correct but did\
    \ not know this, we get:\n\nAt state 00: M, 00 |= [¬Hb⊥ ∨ BaHb⊥]b¬Hb⊥ b became\
    \ correct M, 00 |= [¬Hb⊥ ∨ BaHb⊥]bKb¬Hb⊥ b learned that he is correct M, 00 |=\
    \ [¬Hb⊥ ∨ BaHb⊥]b¬BaHb⊥ a no longer believes that b is faulty At state 01: M,\
    \ 01 |= [¬Hb⊥ ∨ BaHb⊥]bKa¬Hb⊥ a learned that b is correct M, 01 |= [¬Hb⊥ ∨ BaHb⊥]bKbKa¬Hb⊥\
    \ b learned that a knows that b is correct\n\nAgent b is now correct in all states.\
    \ Agents a and b therefore have common knowledge that b is correct.\n\nByzantine\
    \ agents. We now turn our attention to a different problem that needs to be solved\
    \ in fault-tolerant distributed systems like MAFT [\\[21\\]](#page-20-13) and\
    \ GUARDS [\\[30\\]](#page-21-11) that combine fault-masking approaches with FDIR.\
    \ What is needed here is to monitor whether there are at most f faulty agents\
    \ among the n agents in the system, and take countermeasures when the formula\n\
    \n$$\nByz_f := \\bigvee_{\\substack{G \\subseteq \\mathcal{A} \\\\ |G| = n - f}}\
    \ \\bigwedge_{i \\in G} \\neg H_i \\bot\n$$\n\nis in danger of getting violated\
    \ or even is violated already. The most basic way to enforce the global condition\
    \ Byz<sup>f</sup> in a hope update is by a constraint on the hope update formulas,\
    \ rather than by their actual shape. All that is needed here is to ensure, given\
    \ hope update formulas ~ϕ = (ϕ1, . . . , ϕn), that at least n − f of those are\
    \ true, which can be expressed by the formula\n\n$$\n\\vec{\\varphi}^{\\,n-f}:=\\\
    bigvee_{\\substack{G\\subseteq\\mathcal{A}\\\\|G|=n-f}}\\bigwedge_{i\\in G}\\\
    varphi_i.\n$$\n\nWe now have the validity\n\n$$\n\\models \\vec{\\varphi}^{n-f}\
    \ \\rightarrow [\\vec{\\varphi}]Byz_f.\n$$\n\nIn particular, we also have the\
    \ weaker\n\n$$\n\\models \\mathit{Byz}_f \\land \\vec{\\varphi}^{n-f} \\to [\\\
    vec{\\varphi}] \\mathit{Byz}_f.\n$$\n\nIn other words,\n\n$$\nM, w \\models \\\
    text{Byz}_f \\land \\vec{\\varphi}^{n-f} \\quad \\text{implies} \\quad M^{\\vec{\\\
    varphi}}, w \\models \\text{Byz}_f.\n$$\n\nWe could also consider generalized\
    \ schemas such as: M |= Byz<sup>f</sup> ∧ ~ϕ n−f implies M ~ϕ |= Byz<sup>f</sup>\
    \ . In all these cases, the initial assumption Byz<sup>f</sup> is superfluous.\n\
    \nSuch a condition is, of course, too abstract for practical purposes. What would\
    \ be needed here are concrete hope update formulas by which we can update a model\
    \ when Byz<sup>f</sup> might become false resp. is false already, in which case\
    \ it must cause the correction of sufficiently many agents to guarantee that Byz<sup>f</sup>\
    \ is still true resp. becomes true again after the update. Recall that belief\
    \ Biψ is defined as Ki(¬Hi⊥ → ψ). If we define\n\n$$\nB_{\\geq f}\\psi := \\bigvee_{\\\
    substack{G \\subseteq \\mathcal{A} \\\\ |G|=f}} \\bigwedge_{i \\in G} B_i \\psi,\n\
    $$\n\nit easy to see by the pigeonhole principle that\n\n$$\n\\models Byz_f \\\
    land B_{\\geq f+1}\\psi \\to \\psi.\n$$\n\nUsing ψ = Ha⊥ will hence result in\
    \ one fewer faulty agent. To the formula B≥f+1Ha⊥ we add a disjunct ¬Ha⊥ to ensure\
    \ correct agents remain correct.\n\n$$\n\\models Byz_f \\land B_{\\geq f+1}H_a\
    \ \\bot \\rightarrow [\\neg H_a \\bot \\lor B_{\\geq f+1}H_a \\bot]_aByz_{f-1}.\n\
    $$\n\n#### 3.3 Axiomatization\n\n<span id=\"page-8-0\"></span>Axiomatization KH\
    \ pub of the logical semantics for L pub KH extends axiom system KH with axioms\
    \ describing the interaction between hope updates and other logical connectives.\
    \ The axiomatization is a straightforward reduction system, where the interesting\
    \ interaction happens in hope update binding hope.\n\nDefinition 7 (Axiomatization\
    \ KH pub). KH pub extends KH with axioms\n\n[~ϕ]p ↔ p [~ϕ]Kiψ ↔ K<sup>i</sup>\
    \ [~ϕ]ψ [~ϕ]¬ψ ↔ ¬[~ϕ]ψ [~ϕ]Hiψ ↔ ϕ<sup>i</sup> → Ki(ϕ<sup>i</sup> → [~ϕ]ψ) [~ϕ](ψ\
    \ ∧ ξ) ↔ [~ϕ]ψ ∧ [~ϕ]ξ [~ϕ][~χ]ψ ↔ -[~ϕ]χ1, . . . , [~ϕ]χ<sup>n</sup> ψ\n\nwhere\
    \ ~ϕ = (ϕ1, . . . , ϕn) ∈ (L pub KH ) <sup>n</sup>, ~χ = (χ1, . . . , χn) ∈ (L\
    \ pub KH ) <sup>n</sup>, ψ, ξ ∈ Lpub KH , p ∈ Prop, and i ∈ A.\n\n<span id=\"\
    page-9-1\"></span>Theorem 8 (Soundness). For all ϕ ∈ Lpub KH , KH pub <sup>⊢</sup>\
    \ <sup>ϕ</sup> implies KH |<sup>=</sup> <sup>ϕ</sup>.\n\nProof. In light of Theorem\
    \ [1,](#page-4-1) it is sufficient to show the validity of the new axioms. More\
    \ precisely, we consider an arbitrary model M = (W, π, K, H) ∈ KH and state w\
    \ ∈ W and show that each axiom is true in state w:\n\n– Axiom [~ϕ]p ↔ p is valid\
    \ because M, w |= [~ϕ]p iff M ~ϕ, w |= p iff w ∈ π(p) iff M, w |= p. – Axiom [~ϕ]¬ψ\
    \ ↔ ¬[~ϕ]ψ is valid because M, w |= [~ϕ]¬ψ iff M ~ϕ, w |= ¬ψ iff M ~ϕ, w 6|= ψ\
    \ iff M, w 6|= [~ϕ]ψ iff M, w |= ¬[~ϕ]ψ. – Axiom [~ϕ](ψ ∧ ξ) ↔ [~ϕ]ψ ∧ [~ϕ]ξ is\
    \ valid because M, w |= [~ϕ](ψ ∧ ξ) iff M ~ϕ, w |= ψ ∧ ξ iff M ~ϕ, w |= ψ and\
    \ M ~ϕ, w |= ξ iff M, w |= [~ϕ]ψ and M, w |= [~ϕ]ξ iff M, w |= [~ϕ]ψ ∧ [~ϕ]ξ.\
    \ – Axiom [~ϕ]Kiψ ↔ K<sup>i</sup> [~ϕ]ψ is valid because M, w |= [~ϕ]Kiψ iff M\
    \ ~ϕ, w |= Kiψ iff ∀v ∈ Ki(w) M ~ϕ, v |= ψ iff ∀v ∈ Ki(w) M, v |= [~ϕ]ψ iff M,\
    \ w |= K<sup>i</sup> [~ϕ]ψ. – Axiom [~ϕ]Hiψ ↔ ϕ<sup>i</sup> → Ki(ϕ<sup>i</sup>\
    \ → [~ϕ]ψ) is valid because M, w |= [~ϕ]Hiψ iff M ~ϕ, w |= Hiψ iff ∀v ∈ Hϕ<sup>i</sup>\
    \ i (w) M ~ϕ, v |= ψ iff (∀v ∈ W) v ∈ Ki(w) & M, w |= ϕ<sup>i</sup> & M, v |=\
    \ ϕ<sup>i</sup> =⇒ M ~ϕ, v |= ψ iff M, w |= ϕ<sup>i</sup> =⇒ (∀v ∈ W) v ∈ Ki(w)\
    \ & M, v |= ϕ<sup>i</sup> =⇒ M ~ϕ, v |= ψ iff M, w |= ϕ<sup>i</sup> =⇒ ∀v ∈ Ki(w)\
    \ (M, v |= ϕ<sup>i</sup> =⇒ M ~ϕ, v |= ψ) iff M, w |= ϕ<sup>i</sup> =⇒ ∀v ∈ Ki(w)\
    \ (M, v |= ϕ<sup>i</sup> =⇒ M, v |= [~ϕ]ψ) iff M, w |= ϕ<sup>i</sup> =⇒ ∀v ∈ Ki(w)\
    \ M, v |= ϕ<sup>i</sup> → [~ϕ]ψ iff M, w |= ϕ<sup>i</sup> =⇒ M, w |= Ki(ϕ<sup>i</sup>\
    \ → [~ϕ]ψ) iff M, w |= ϕ<sup>i</sup> → Ki(ϕ<sup>i</sup> → [~ϕ]ψ). – To show the\
    \ validity of axiom [~ϕ][~χ]ψ ↔ -[~ϕ]χ1, . . . , [~ϕ]χ<sup>n</sup> ψ, we first\
    \ show that\n\n$$\n(M^{\\vec{\\varphi}})^{\\vec{\\chi}} = M^{([\\vec{\\varphi}]\
    \ \\chi_1, \\ldots, [\\vec{\\varphi}] \\chi_n)}.\n$$\n\nSince domain W, valuation\
    \ π, and accessibility relations K<sup>i</sup> for all i ∈ A are the same in the\
    \ initial model M and all updated models, we only need to show that every agent\
    \ i's hope accessibility relation (H~ϕ) ~χ i = (H~ϕ) χi i from model (M ~ϕ) ~χ\
    \ coincides with i's hope accessibility relation H [~ϕ]χi i from model M [~ϕ]χ1,...,[~ϕ]χn\
    \ : w(H~ϕ) χi i v iff wKiv, and M ~ϕ, w |= χ<sup>i</sup> , and M ~ϕ, v |= χ<sup>i</sup>\
    \ iff wKiv, and M, w |= [~ϕ]χ<sup>i</sup> , and M, v |= [~ϕ]χ<sup>i</sup> iff\
    \ wH [~ϕ]χi i v. It remains to note that M, w |= [~ϕ][~χ]ψ iff M ~ϕ, w |= [~χ]ψ\
    \ iff (M ~ϕ) ~χ, w |= ψ iff M [~ϕ]χ1,...,[~ϕ]χn , w |= ψ iff M, w |= -[~ϕ]χ1,\
    \ . . . , [~ϕ]χ<sup>n</sup> ψ. ⊓⊔\n\n<span id=\"page-9-0\"></span>Every formula\
    \ in L pub KH is provably equivalent to a formula in LKH (Lemma [13\\)](#page-11-1).\
    \ To prove this, we first define the weight or complexity of a given formula (Def.\
    \ [9\\)](#page-9-0) and show a number of inequalities comparing the left-hand\
    \ side to the right-hand side of the reduction axioms in axiomatization KH pub\
    \ (Lemma [10\\)](#page-10-0). Subsequently, we define a translation from L pub\
    \ KH to LKH (Def. [11\\)](#page-10-1) and finally show that the translation is\
    \ a terminating rewrite procedure (Prop. [12\\)](#page-11-2).\n\nDefinition 9.\
    \ The complexity c : L pub KH → **N** of L pub KH -formulas is defined recursively,\
    \ where p ∈ Prop, i ∈ A, and c(~ϕ) := max{c(ϕi) | 1 ≤ i ≤ n}:\n\n$$\nc(p) := 1\n\
    $$\n  \n\\n\n$$\nc(\\neg \\varphi) := c(\\varphi) + 1\n$$\n  \n\\n\n$$\nc(\\varphi\
    \ \\wedge \\xi) := \\max\\{c(\\varphi), c(\\xi)\\} + 1\n$$\n  \n\\n\n$$\nc(\\\
    varphi \\wedge \\xi) := \\max\\{c(\\varphi), c(\\xi)\\} + 1\n$$\n  \n\\n\n$$\n\
    c(\\varphi \\xi) := (c(\\varphi) + 1) \\cdot c(\\xi)\n$$\n\n<span id=\"page-10-0\"\
    ></span>Lemma 10. For each axiom θ<sup>l</sup> ↔ θ<sup>r</sup> from Def. [7,](#page-8-0)\
    \ c(θl) > c(θr).\n\nProof. – For axiom [~ϕ]p ↔ p:\n\n$$\nc([\\vec{\\varphi}]p)\
    \ = (c(\\vec{\\varphi}) + 1) \\cdot c(p) > c(p).\n$$\n\n– For axiom [~ϕ]¬ψ ↔ ¬[~ϕ]ψ:\n\
    \n$$\nc([\\vec{\\varphi}]\\neg\\psi) = (c(\\vec{\\varphi}) + 1) \\cdot c(\\neg\\\
    psi) = (c(\\vec{\\varphi}) + 1) \\cdot (c(\\psi) + 1)\n$$\n  \n> \n$$\n(c(\\vec{\\\
    varphi}) + 1) \\cdot c(\\psi) + 1 = c([\\vec{\\varphi}]\\psi) + 1 = c(\\neg[\\\
    vec{\\varphi}]\\psi).\n$$\n\n– For axiom [~ϕ](ψ ∧ ξ) ↔ [~ϕ]ψ ∧ [~ϕ]ξ:\n\n$$\n\
    c([\\vec{\\varphi}](\\psi \\wedge \\xi)) = (c(\\vec{\\varphi}) + 1) \\cdot c(\\\
    psi \\wedge \\xi) = (c(\\vec{\\varphi}) + 1) \\cdot (\\max\\{c(\\psi), c(\\xi)\\\
    } + 1)\n$$\n  \n> \n$$\n(c(\\vec{\\varphi}) + 1) \\cdot \\max\\{c(\\psi), c(\\\
    xi)\\} + 1 = \\max\\left\\{(c(\\vec{\\varphi}) + 1) \\cdot c(\\psi), (c(\\vec{\\\
    varphi}) + 1) \\cdot c(\\xi)\\right\\} + 1\n$$\n  \n= \n$$\n\\max\\left\\{c([\\\
    vec{\\varphi}]\\psi), c([\\vec{\\varphi}]\\xi)\\right\\} + 1 = c([\\vec{\\varphi}]\\\
    psi \\wedge [\\vec{\\varphi}]\\xi).\n$$\n\n– For axiom [~ϕ]Kiψ ↔ K<sup>i</sup>\
    \ [~ϕ]ψ:\n\n$$\nc([\\vec{\\varphi}]K_i\\psi) = (c(\\vec{\\varphi})+1) \\cdot c(K_i\\\
    psi) = (c(\\vec{\\varphi})+1) \\cdot (c(\\psi)+1)\n$$\n  \n> \n$$\n(c(\\vec{\\\
    varphi})+1) \\cdot c(\\psi) + 1 = c([\\vec{\\varphi}]\\psi) + 1 = c(K_i[\\vec{\\\
    varphi}]\\psi).\n$$\n\n– For axiom [~ϕ]Hiψ ↔ ϕ<sup>i</sup> → Ki(ϕ<sup>i</sup>\
    \ → [~ϕ]ψ) , given that\n\n$$\n\\varphi_i \\to K_i(\\varphi_i \\to [\\vec{\\varphi}]\\\
    psi) \\quad = \\quad \\neg(\\varphi_i \\land \\neg K_i \\neg (\\varphi_i \\land\
    \ \\neg [\\vec{\\varphi}]\\psi)) :\n$$\n\n$$\nc([\\vec{\\varphi}]H_i\\psi) = (c(\\\
    vec{\\varphi})+1) \\cdot c(H_i\\psi) = (c(\\vec{\\varphi})+1) \\cdot (c(\\psi)+4)\
    \ = (c(\\vec{\\varphi})+1) \\cdot c(\\psi) + (c(\\vec{\\varphi})+1) \\cdot 4\n\
    $$\n  \n\\n\n$$\n= c([\\vec{\\varphi}]\\psi) + 4 \\cdot c(\\vec{\\varphi}) + 4\
    \ > c([\\vec{\\varphi}]\\psi) + 7 = \\max\\Big\\{c(\\varphi_i), \\ c([\\vec{\\\
    varphi}]\\psi) + 5\\Big\\} + 2\n$$\n  \n\\n\n$$\n= \\max\\Big\\{c(\\varphi_i),\
    \ \\ \\max\\{c(\\varphi_i), c([\\vec{\\varphi}]\\psi) + 1\\} + 4\\Big\\} + 2\n\
    $$\n  \n\\n\n$$\n= \\max\\Big\\{c(\\varphi_i), \\ c(\\varphi_i \\wedge \\neg[\\\
    vec{\\varphi}]\\psi) + 3\\Big\\} + 2\n$$\n  \n\\n\n$$\n= \\max\\Big\\{c(\\varphi_i),\
    \ \\ c(\\varphi_i \\wedge \\neg[\\vec{\\varphi}]\\psi) + 3\\Big\\} + 2\n$$\n \
    \ \n\\n\n$$\n= \\max\\Big\\{c(\\varphi_i), \\ c(\\neg(\\varphi_i \\wedge \\neg[\\\
    vec{\\varphi}]\\psi)) + 2\\Big\\} + 2\n$$\n  \n\\n\n$$\n= \\max\\Big\\{c(\\varphi_i),\
    \ \\ c(K_i \\neg(\\varphi_i \\wedge \\neg[\\vec{\\varphi}]\\psi)) + 1\\Big\\}\
    \ + 2\n$$\n  \n\\n\n$$\n= \\max\\Big\\{c(\\varphi_i), \\ c(K_i \\neg(\\varphi_i\
    \ \\wedge \\neg[\\vec{\\varphi}]\\psi)) + 2\\Big\\}\n$$\n  \n\\n\n$$\n= c(\\varphi_i\
    \ \\wedge \\neg K_i \\neg(\\varphi_i \\wedge \\neg[\\vec{\\varphi}]\\psi)) + 1\
    \ = c(\\neg(\\varphi_i \\wedge \\neg K_i \\neg(\\varphi_i \\wedge \\neg[\\vec{\\\
    varphi}]\\psi))\\Big).\n$$\n\n– For axiom [~ϕ][~χ]ψ ↔ -[~ϕ]χ1, . . . , [~ϕ]χ<sup>n</sup>\
    \ ψ:\n\n<span id=\"page-10-1\"></span>c [~ϕ][~χ]ψ = c(~ϕ)+ 1 · c [~χ]ψ = c(~ϕ)+\
    \ 1 · c(~χ)+ 1 · c(ψ) > c(~ϕ)+ 1 · <sup>c</sup>(~χ)+ 1 · c(ψ) = maxc(~ϕ) + 1 ·\
    \ c(χ1), . . . , c(~ϕ) + 1 · c(χn) + 1 · c(ψ) = max c [~ϕ]χ<sup>1</sup> , . .\
    \ . , c [~ϕ]χ<sup>n</sup> + 1 · c(ψ) = c -[~ϕ]χ1, . . . , [~ϕ]χ<sup>n</sup> ψ\
    \ . ⊓⊔\n\nDefinition 11. The translation t : L pub KH → LKH is defined recursively,\
    \ where p ∈ Prop, i ∈ A, and the ith formula of ~ϕ is ϕi:\n\n| t(p)   | := p \
    \                   | t<br><br>[~ϕ]p               | := p                    \
    \                  |\n|--------|-------------------------|------------------------------|-------------------------------------------|\n\
    | t(¬ϕ)  | := ¬t(ϕ)                | <br><br>t<br>[~ϕ]¬ξ          | <br><br>:=\
    \ ¬t<br>[~ϕ]ξ                    |\n|        | t(ϕ ∧ ξ) := t(ϕ) ∧ t(ξ) | <br><br>t<br>[~ϕ](ξ\
    \ ∧ χ)     | <br><br>:= t<br>[~ϕ]ξ ∧ [~ϕ]χ             |\n| t(Kiϕ) | := Kit(ϕ)\
    \               | <br><br>t<br>[~ϕ]Kiξ         | <br><br>:= t<br>Ki<br>[~ϕ]ξ \
    \              |\n| t(Hiϕ) | := Hit(ϕ)               | <br><br>t<br>[~ϕ]Hiξ  \
    \       | <br><br>:= t<br>ϕi<br>→ Ki(ϕi<br>→ [~ϕ]ξ) |\n|        |            \
    \             | <br><br>t<br>[~ϕ][χ1, , χn]ξ | <br><br><br>:= t<br>[~ϕ]χ1, , [~ϕ]χn<br>ξ\
    \ |\n\n<span id=\"page-11-2\"></span>Proposition 12 (Termination). For all ϕ ∈\
    \ Lpub KH , t(ϕ) ∈ LKH .\n\nProof. This follows by induction on c(ϕ). ⊓⊔\n\n<span\
    \ id=\"page-11-1\"></span>Lemma 13 (Equiexpressivity). Language L pub KH is equiexpressive\
    \ with LKH .\n\nProof. It follows by induction on c(ϕ) that KH pub ⊢ ϕ ↔ t(ϕ)\
    \ for all ϕ ∈ Lpub KH , where, by Prop. [12,](#page-11-2) t(ϕ) ∈ LKH . ⊓⊔\n\n\
    <span id=\"page-11-3\"></span>Theorem 14 (Soundness and completeness). For all\
    \ ϕ ∈ Lpub KH ,\n\nKH pub ⊢ ϕ ⇐⇒ KH |= ϕ.\n\nProof. Soundness was proved in Theorem\
    \ [8.](#page-9-1) To prove completeness, assume KH |= ϕ. According to Lemma [13,](#page-11-1)\
    \ we have KH pub ⊢ ϕ ↔ t(ϕ). Therefore, by Theorem [8,](#page-9-1) KH |= ϕ ↔ t(ϕ)\
    \ follows. Since KH |= ϕ (by assumption), we obtain KH |= t(ϕ). By applying Theorem\
    \ [1,](#page-4-1) KH ⊢ t(ϕ) further follows. Consequently, KH pub ⊢ t(ϕ). Finally,\
    \ since KH pub ⊢ ϕ ↔ t(ϕ), KH pub ⊢ ϕ. ⊓⊔\n\n<span id=\"page-11-4\"></span>Corollary\
    \ 15 (Necessitation for public hope updates). For all ψ ∈ Lpub KH and ~ϕ ∈ (L\
    \ pub KH ) n,\n\nKH pub ⊢ ψ =⇒ KH pub ⊢ [~ϕ]ψ.\n\nProof. Assume KH pub ⊢ ψ. By\
    \ Theorem [14,](#page-11-3) KH |= ψ. In particular, for any M = (W, π, K, H) ∈\
    \ KH, we have M ~ϕ |= ψ since M ~ϕ ∈ KH by Prop. [4.](#page-5-1) Thus, M ~ϕ, w\
    \ |= ψ for all w ∈ W. In other words, M, w |= [~ϕ]ψ for all w ∈ W, i.e., M |=\
    \ [~ϕ]ψ. Since KH |= [~ϕ]ψ, we get KH pub ⊢ [~ϕ]ψ by Theorem [14.](#page-11-3)\
    \ ⊓⊔\n\n### <span id=\"page-11-0\"></span>4 Private Hope Update\n\nIn the case\
    \ of the public hope update mechanism introduced in Sect. [3,](#page-4-0) after\
    \ the update there is no uncertainty about what happened. In some distributed\
    \ FDIR schemes, including self-correction, however, the hope update at an agent\
    \ occurs in a less public way. To increase the application coverage of our logic,\
    \ we therefore provide the alternative of private hope updates. For that, we use\
    \ structures inspired by action models. Strictly speaking, such updates are known\
    \ as semi-private (or semi-public) updates, as the agents are aware of their uncertainty\
    \ and know what they are uncertain about, whereas in fully private update the\
    \ agent does not know that the action took place [\\[5\\]](#page-19-2) and may,\
    \ in fact, believe that nothing happened. The resulting language can be viewed\
    \ as a generalization of L pub KH , where the latter now becomes a special case.\n\
    \n#### 4.1 Syntax and Semantics\n\nDefinition 16 (Hope update model). A hope update\
    \ model for a logical language L is a tuple\n\n$$\nU = (E, \\vartheta, \\mathcal{K}^U)\n\
    $$\n\nwhere E is a finite non-empty set of actions, ϑ : E → (A → L) is a hope\
    \ update function, and K<sup>U</sup> : A → P(E × E) such that all K<sup>U</sup>\
    \ <sup>i</sup> are equivalence relations. For ϑ(e)(i) we write ϑi(e). As before,\
    \ formulas ϑi(e) ∈ L are hope update formulas. A pointed hope update model (for\
    \ the logical language L) is a pair (U, e) where e ∈ E.\n\n<span id=\"page-12-0\"\
    ></span>Definition 17 (Language L priv KH ). Language L priv KH is obtained from\
    \ LKH by adding one new construct:\n\nϕ ::= p | ¬ϕ | (ϕ ∧ ϕ) | Kiϕ | Hiϕ | [U,\
    \ e]ϕ\n\nwhere (U, e) is a pointed hope update model for language L priv KH .\n\
    \nDefinition [17](#page-12-0) is given by mutual recursion as usual: formulas\
    \ may include hope update models while hope update models must include formulas\
    \ to be used as hope update formulas. All (pointed) hope update models till the\
    \ end of this section are for language L priv KH .\n\n<span id=\"page-12-1\"></span>Definition\
    \ 18 (Semantics of private hope update). Let U = (E, ϑ, K<sup>U</sup> ) be a hope\
    \ update model, M = (W, π, K, H) ∈ KH, w ∈ W, and e ∈ E. Then:\n\n$$\nM, w \\\
    models [U, e] \\varphi \\quad \\text{iff} \\quad M \\times U, (w, e) \\models\
    \ \\varphi,\n$$\n\nwhere M × U = (W<sup>×</sup>, π<sup>×</sup>, K<sup>×</sup>,\
    \ H<sup>×</sup>) is such that:\n\nW<sup>×</sup> := W × E (w, e) ∈ π <sup>×</sup>(p)\
    \ iff w ∈ π(p) (w, e)K × i (v, f) iff wKiv and eK<sup>U</sup> i f (w, e)H<sup>×</sup>\
    \ i (v, f) iff (w, e)K × i (v, f), and M, w |= ϑi(e), and M, v |= ϑi(f)\n\nPublic\
    \ hope updates can be viewed as singleton hope update models. Given formulas ~ϕ\
    \ ∈ (L pub KH ) n, define pub := ({e}, ϑ, Kpub), where ϑi(e) := ϕ<sup>i</sup>\
    \ and Kpub := {(e, e)}.\n\nDifference with action models. Although our hope update\
    \ models look like action models, they are not really action models in the sense\
    \ of [\\[2\\]](#page-19-5). Our actions do not have executability preconditions,\
    \ such that the updated model is not a restricted modal product but rather the\
    \ full product. Another difference is that, by analogy with Kripke models for\
    \ knowledge and hope, we would then have expected a hope relation in the update\
    \ models. But there is none in our approach.\n\n<span id=\"page-12-3\"></span>Proposition\
    \ 19. M × U ∈ KH for any hope update model U and M ∈ KH.\n\nProof. The proof is\
    \ somewhat similar to that of Prop. [4.](#page-5-1) It is obvious that all K ×\
    \ i are equivalence relations. Let us show now that for all i ∈ A relations H<sup>×</sup>\
    \ i are shift-serial and that they satisfy the properties HinK and oneH.\n\n-\
    \ H<sup>×</sup> i is shift-serial: Let (w, e) ∈ W×. Assume (w, e)H<sup>×</sup>\
    \ i (v, f), that is, (w, e)K × i (v, f), and M, w |= ϑi(e), and M, v |= ϑi(f).\
    \ (v, f)K × i (w, e) follows by symmetry of K × i . Therefore, H<sup>×</sup> i\
    \ (v, f) 6= ∅ since (w, e) ∈ H<sup>×</sup> i (v, f) .\n- H × i satisfies HinK:\
    \ This follows by definition.\n- <span id=\"page-12-2\"></span>– H × i satisfies\
    \ oneH: Let (w, e),(v, f) ∈ W<sup>×</sup>. Assume that H × i (w, e) 6= ∅, H ×\
    \ i (v, f) 6= ∅, and (w, e)K × i (v, f). As H × i (w, e) 6= ∅, M, w |= ϑi(e).\
    \ As H × i (v, f) 6= ∅, M, v |= ϑi(f). Therefore, (w, e)H × i (v, f). ⊓⊔\n\nDefinition\
    \ 20. Let U = (E, ϑ, K<sup>U</sup> ) and U ′ = (E′ , ϑ′ , K<sup>U</sup> ′ ) be\
    \ hope update models. The composition (U;U ′ ) is (E′′, ϑ′′ , KU;<sup>U</sup>\
    \ ′ ) such that:\n\n$$\nE''\n$$\n  \n\\n\n$$\n\\begin{array}{rcl}\\n&:=& E \\\
    times E' \\\\\n\\vartheta''_i\\big((e, e')\\big) &:=& [U, e]\\vartheta'_i(e')\
    \ \\\\\n(e, e')\\mathcal{K}_i^{U;U'}(f, f') & iff & e\\mathcal{K}_i^U f \\text{\
    \ and } e'\\mathcal{K}_i^{U'} f'\\n\\end{array}\n$$\n\nSince K<sup>U</sup> i and\
    \ K<sup>U</sup> ′ i are equivalence relations, K U;U ′ i is also an equivalence\
    \ relation, so that (U;U ′ ) is a hope update model.\n\n#### 4.2 Applications\n\
    \nThe arguably most important usage of private updates in distributed FDIR is\
    \ to express the uncertainty of agents about whether an update affects other agents.\n\
    \nExample 21. We present several uses of private hope updates:\n\n1. Private correction.\
    \ We reconsider the example from Sect. [1,](#page-0-1) only this time we privately\
    \ correct agent a based on p<sup>b</sup> such that agent b is uncertain whether\
    \ the hope update happens. This can be modeled by two hope update formulas for\
    \ agent a: ¬Ha⊥ ∨ p<sup>b</sup> and ¬Ha⊥. With ¬Ha⊥ ∨ p<sup>b</sup> we associate\
    \ an event cp<sup>b</sup> where the correction takes place based on the additional\
    \ constraint pb, and with ¬Ha⊥ we associate an event noc where correction does\
    \ not take place. Writing ϑ(e) = (ϑa(e), ϑb(e) , we get U := (E, ϑ, K<sup>U</sup>\
    \ ), where:\n\n$$\nE = \\{c_{p_b}, noc\\}\n$$\n  \n\\n\n$$\n\\vartheta(c_{p_b})\
    \ := (\\neg H_a \\bot \\lor p_b, \\neg H_b \\bot)\n$$\n  \n\\n\n$$\n\\mathcal{K}_b^U\
    \ := \\text{the identity relation } \\{(e, e) \\mid e \\in E\\}\n$$\n  \n\\n\n\
    $$\n\\vartheta(noc) := (\\neg H_a \\bot, \\neg H_b \\bot)\n$$\n  \n\\n\n$$\n\\\
    mathcal{K}_b^U := \\text{the universal relation } E \\times E\n$$\n\n![](_page_13_Figure_9.jpeg)\n\
    \nWhen labeling worlds in the figure above, we have abstracted away from the event\
    \ being executed in a world. Having the same name, therefore, does not mean being\
    \ the same world. For example, the world **01** at the front of the cube 'really'\
    \ is the pair (01, c<sup>p</sup><sup>b</sup> ) with H<sup>a</sup> (01, c<sup>p</sup><sup>b</sup>\
    \ ) 6= ∅ and H<sup>b</sup> (01, c<sup>p</sup><sup>b</sup> ) 6= ∅. We now have\
    \ for example that, in state 01, where b knew that a was faulty but a herself\
    \ did not know this:\n\n$$\nM, 01 \\models [U, c_{p_b}] (\\neg H_a \\bot \\land\
    \ K_a \\neg H_a \\bot)\n$$\n a became correct and now knows she is correct  \n\
    \\n\n$$\nM, 01 \\models [U, c_{p_b}] \\neg K_b K_a \\neg H_a \\bot\n$$\n b does\
    \ not know that a knows she is correct  \n\\n\n$$\nM, 01 \\models [U, c_{p_b}]\
    \ \\neg (K_b H_a \\bot \\lor K_b \\neg H_a \\bot)\n$$\n b does not know whether\
    \ a is correct\n\n2. Self-correction under uncertainty of who self-corrects. Recall\
    \ that the hope update formula for self-correction of a generally has form ¬Ha⊥\
    \ ∨ (ϕ ∧ KaHa⊥). Instead of two agents, as in Example [6,](#page-6-0) now consider\
    \ any number n = |A| of agents. Of course, the difference with Example [6](#page-6-0)\
    \ only kicks in if n ≥ 3.\n\nWe can encode that an arbitrary agent self-corrects,\
    \ while the remaining agents are uncertain which agent this is, by a hope update\
    \ model consisting of n events e1, . . . , e<sup>n</sup> where event e<sup>i</sup>\
    \ represents that agent i self-corrects. We now set ϑi(ei) := ¬Hi⊥∨(ψ<sup>i</sup>\
    \ ∧KiHi⊥) for each i ∈ A (where ψ<sup>i</sup> is some optional constraint for\
    \ agent i to self-correct) and ϑ<sup>j</sup> (ei) := ¬Hj⊥ for all j 6= i. We let\
    \ each agent be unable to distinguish among any events wherein it does not self-correct:\n\
    \n$$\ne_i \\mathcal{K}_j^U e_k \\quad \\Longleftrightarrow \\quad i = j = k \\\
    text{ or } j \\notin \\{i, k\\}.\n$$\n\nThus, if an agent considers it possible\
    \ that multiple agents know that they are incorrect, then after this update such\
    \ an agent would generally not know whether somebody self-corrected and, if so,\
    \ who it was.\n\n3. Self-correction under uncertainty of the source of state recovery.\
    \ An alternative generalization of Example [6](#page-6-0) is that it remains public\
    \ that a given agent a self-corrects but there is uncertainty over the agent from\
    \ whom agent a can get its state recovery information, which can be encoded via\
    \ formulas ϕ<sup>i</sup> in a's hope update formulas ¬Ha⊥ ∨ (ϕ<sup>i</sup> ∧ KaHa⊥),\
    \ for i ∈ A with i 6= a (we assume that a does not get the recovery information\
    \ from itself). Among these ϕ<sup>i</sup> the recovering agent a non-deterministically\
    \ chooses one. This is implemented in a hope update model of size n − 1, with\
    \ events e<sup>i</sup> for all i 6= a such that ϑa(ei) := ¬Ha⊥ ∨ (ϕ<sup>i</sup>\
    \ ∧ KaHa⊥) and ϑ<sup>j</sup> (ei) = ¬Hj⊥ for all j 6= a, and such that K<sup>U</sup>\
    \ a is the identity on this domain of events (as a knows what choice it makes\
    \ between the ϕ<sup>i</sup> 's), whereas for i 6= a, relation K<sup>U</sup> i\
    \ is the universal relation on this domain (any other agent remains uncertain\
    \ among all these alternatives).\n\n#### <span id=\"page-14-0\"></span>4.3 Axiomatization\n\
    \nDefinition 22 (Axiomatization KH priv). KH priv extends KH with axioms\n\n$$\n\
    [U, e]\\rho \\leftrightarrow p \\qquad [U, e] \\neg \\varphi \\leftrightarrow\
    \ \\neg [U, e] \\varphi [U, e] (\\varphi \\wedge \\psi) \\leftrightarrow [U, e]\
    \ \\varphi \\wedge [U, e] \\psi \\qquad [U, e][U', e'] \\varphi \\leftrightarrow\
    \ \\big[ (U; U'), (e, e') \\big] \\varphi [U, e] K_i \\varphi \\leftrightarrow\
    \ \\bigwedge_{e \\mathcal{K}_i^U f} K_i[U, f] \\varphi \\qquad [U, e] H_i \\varphi\
    \ \\leftrightarrow \\left( \\vartheta_i(e) \\to \\bigwedge_{e \\mathcal{K}_i^U\
    \ f} K_i(\\vartheta_i(f) \\to [U, f] \\varphi) \\right)\n$$\n\nwhere ϕ, ψ ∈ Lpriv\
    \ KH , (U ′ , e′ ) is a pointed hope update model, p ∈ Prop, i ∈ A, and U = (E,\
    \ ϑ, K<sup>U</sup> ) is a hope update model with e, f ∈ E.\n\n<span id=\"page-14-1\"\
    ></span>Theorem 23 (Soundness). For all ϕ ∈ Lpriv KH , KH priv <sup>⊢</sup> <sup>ϕ</sup>\
    \ implies KH |<sup>=</sup> <sup>ϕ</sup>.\n\nProof. As in Theorem [8,](#page-9-1)\
    \ it is sufficient to show the validity of the new axioms. Additionally, the proofs\
    \ for first three axioms for atomic propositions, negation, and conjunction are\
    \ similar to those for the analogous axioms of KH pub and of action model logic,\
    \ so are omitted here. For the remaining three axioms, consider arbitrary Kripke\
    \ model M = (W, π, K, H) ∈ KH with w ∈ W, as well as hope update models U = (E,\
    \ ϑ, K<sup>U</sup> ) and U ′ = (E ′ , ϑ′ , K<sup>U</sup> ′ ) with e, f ∈ E and\
    \ e ′ ∈ E ′ . Let M × U = (W×, π×, K×, H×) according to Def. [18](#page-12-1)\
    \ and (U;U ′ ) = (E′′, ϑ′′ , K<sup>U</sup>;<sup>U</sup> ′ ) according to Def.\
    \ [20.](#page-12-2) To avoid unnecessary clutter, in this proof we use single\
    \ parentheses instead of double ones, e.g., writing H<sup>×</sup> i (w, e) instead\
    \ of H<sup>×</sup> i (w, e) .\n\n– Axiom [U, e]Kiϕ ↔ V eK<sup>U</sup> i <sup>f</sup>\
    \ K<sup>i</sup> [U, f]ϕ is valid because M, w |= [U, e]Kiϕ iff M × U,(w, e) |=\
    \ Kiϕ iff ∀(v, f) ∈ K<sup>×</sup> i (w, e) M × U,(v, f) |= ϕ iff ∀(v, f) ∈ K<sup>×</sup>\
    \ i (w, e) M, v |= [U, f]ϕ iff (∀v ∈ W)(∀f ∈ E) v ∈ Ki(w) & eK<sup>U</sup> i f\
    \ =⇒ M, v |= [U, f]ϕ iff (∀f ∈ E) eK<sup>U</sup> i f =⇒ ∀v ∈ Ki(w) M, v |= [U,\
    \ f]ϕ iff (∀f ∈ E) eK<sup>U</sup> i f =⇒ M, w |= K<sup>i</sup> [U, f]ϕ iff M,\
    \ w |= V eK<sup>U</sup> i <sup>f</sup> K<sup>i</sup> [U, f]ϕ – Axiom [U, e]Hiϕ\
    \ ↔ ϑi(e) → V eK<sup>U</sup> i <sup>f</sup> K<sup>i</sup> ϑi(f) → [U, f]ϕ is valid\
    \ because\n\nM, w |= [U, e]Hiϕ iff M × U,(w, e) |= Hiϕ iff\n\n$$\n(\\forall (v,\
    \ f) \\in \\mathcal{H}_i^{\\times}(w, e)) \\quad M \\times U, (v, f) \\models\
    \ \\varphi \\quad \\text{iff}\n$$\n\\n\n$$\n(\\forall (v, f) \\in \\mathcal{K}_i^{\\\
    times}(w, e)) \\quad (M, w \\models \\vartheta_i(e) \\& M, v \\models \\vartheta_i(f)\
    \ \\implies M \\times U, (v, f) \\models \\varphi) \\quad \\text{iff}\n$$\n\\\
    n\n$$\nM, w \\models \\vartheta_i(e) \\implies (\\forall (v, f) \\in \\mathcal{K}_i^{\\\
    times}(w, e)) \\quad (M, v \\models \\vartheta_i(f) \\implies M, v \\models [U,\
    \ f] \\varphi) \\quad \\text{iff}\n$$\n\\n\n$$\nM, w \\models \\vartheta_i(e)\
    \ \\implies (\\forall (v, f) \\in \\mathcal{K}_i^{\\times}(w, e)) \\quad M, v\
    \ \\models \\vartheta_i(f) \\rightarrow [U, f] \\varphi \\quad \\text{iff}\n$$\n\
    \\n\n$$\nM, w \\models \\vartheta_i(e) \\implies (\\forall v \\in W)(\\forall\
    \ f \\in E)(v \\in \\mathcal{K}_i(w) \\& e\\mathcal{K}_i^U f \\implies M, v \\\
    models \\vartheta_i(f) \\rightarrow [U, f] \\varphi) \\quad \\text{iff}\n$$\n\\\
    n\n$$\nM, w \\models \\vartheta_i(e) \\implies (\\forall f \\in E)(e\\mathcal{K}_i^U\
    \ f \\implies M, w \\models K_i(\\vartheta_i(f) \\rightarrow [U, f] \\varphi))\
    \ \\quad \\text{iff}\n$$\n\\n\n$$\nM, w \\models \\vartheta_i(e) \\implies M,\
    \ w \\models \\bigwedge_{e \\in \\mathcal{K}_i^U f} K_i(\\vartheta_i(f) \\rightarrow\
    \ [U, f] \\varphi) \\quad \\text{iff}\n$$\n\\n\n$$\nM, w \\models \\vartheta_i(e)\
    \ \\implies M, w \\models \\bigwedge_{e \\in \\mathcal{K}_i^U f} K_i(\\vartheta_i(f)\
    \ \\rightarrow [U, f] \\varphi) \\quad \\text{iff}\n$$\n\\n\n$$\nM, w \\models\
    \ \\vartheta_i(e) \\implies M, w \\models \\bigwedge_{e \\in \\mathcal{K}_i^U\
    \ f} K_i(\\vartheta_i(f) \\rightarrow [U, f] \\varphi) \\quad \\text{iff}\n$$\n\
    \\n\n$$\nM, w \\models \\vartheta_i(e) \\implies M, w \\models (\\mathcal{K}_i^U\
    \ f \\land \\varphi_i(f) \\rightarrow [U, f] \\varphi) \\quad \\text{iff}\n$$\n\
    \\n<math display=\"</math>\n\n- w,(e, e′ ) K ; i v,(f, f′ ) iff wKiv, and eK<sup>U</sup>\
    \ i f, and e ′K<sup>U</sup> ′ i f ′ ;\n- (w, e), e′ H ×× i (v, f), f′ iff wKiv,\
    \ and eK<sup>U</sup> i f, and e ′K<sup>U</sup> ′ i f ′ , and M × U,(w, e) |= ϑ\
    \ ′ i (e ′ ), and M × U,(v, f) |= ϑ\n\n$$\nw\\mathcal{K}_i v, \\text{ and } e\\\
    mathcal{K}_i^U f, \\text{ and } e'\\mathcal{K}_i^U f', \\text{ and } M \\times\
    \ U, (w, e) \\models \\vartheta_i'(e'), \\text{ and } M \\times U, (v, f) \\models\
    \ \\vartheta_i'(f');\n$$\n  \n\\n• \n$$\n(w, (e, e'))\\mathcal{H}_i^i(v, (f, f'))\
    \ \\text{ iff }\n$$\n  \n\\n\n$$\nw\\mathcal{K}_i v, \\text{ and } e'\\mathcal{K}_i^U\
    \ f, \\text{ and } e'\\mathcal{K}_i^U f', \\text{ and } M, w \\models [U, e]\\\
    vartheta_i'(e'), \\text{ and } M, v \\models [U, f]\\vartheta_i'(f').\n$$\n\n\
    ′\n\n′\n\nwKiv, and eK<sup>U</sup> i f, and e ′K<sup>U</sup> i f , and M, w |=\
    \ [U, e]ϑ i (e ), and M, v |= [U, f]ϑ i (f It is immediate that\n\n$$\n((w, e),\
    \ e') \\in \\pi^{\\times \\times}(p) \\iff (w, (e, e')) \\in \\pi^{\\cdot}(p),\n\
    $$\n  \n\n$$\n((w, e), e')\\mathcal{K}_i^{\\times \\times}((v, f), f') \\iff (w,\
    \ (e, e'))\\mathcal{K}_i^{\\cdot}(v, (f, f')),\n$$\n  \n\n$$\n((w, e), e')\\mathcal{H}_i^{\\\
    times \\times}((v, f), f') \\iff (w, (e, e'))\\mathcal{H}_i^{\\cdot}(v, (f, f')).\n\
    $$\n\nThus, function f : W×× → W; defined by\n\n$$\nf: ((w, e), e') \\mapsto (w,\
    \ (e, e'))\n$$\n\nis an isomorphism between these models. It remains to note that\
    \ M, w |= [U, e][U ′ , e′ ]ϕ iff M × U,(w, e) |= [U ′ , e′ ]ϕ iff (M × U) × U\
    \ ′ , (w, e), e′ |= ϕ. Due to isomorphism f, this is equivalent to M × (U;U ′\
    \ ), w,(e, e′ ) |= ϕ iff M, w |= -(U;U ′ ),(e, e′ ) ϕ. ⊓⊔\n\nSimilarly to the\
    \ previous section, one can show that every formula in L priv KH is provably equivalent\
    \ to a formula in LKH . For that Def. [9](#page-9-0) can be adapted by defining\
    \ complexity of hope update models U = (E, ϑ, K<sup>U</sup> ) to be c(U) := max\
    \ c ϑi(e)) | i ∈ A, e ∈ E and replacing the last clause in Def. [9](#page-9-0)\
    \ with\n\n<span id=\"page-15-0\"></span>\n$$\nc([U, e]\\varphi) := (c(U) + |E|)\
    \ \\cdot c(\\varphi).\n$$\n\nwhere |E| is the number of actions in hope update\
    \ model U. It can be shown that Lemma [10](#page-10-0) also holds for all axioms\
    \ from Def. [22.](#page-14-0) Based on these complexity-decreasing left-to-right\
    \ reductions, a translation t: L priv KH → LKH can be defined by analogy with\
    \ Def. [11.](#page-10-1) Essentially the same argument as in Prop. [12](#page-11-2)\
    \ shows that this translation is a terminating rewrite procedure. Thus:\n\nProposition\
    \ 24 (Termination). For all ϕ ∈ Lpriv KH , t(ϕ) ∈ LKH .\n\nThe same argument as\
    \ in Lemma [13](#page-11-1) and Theorem [14](#page-11-3) yields\n\n<span id=\"\
    page-15-1\"></span>Lemma 25 (Equiexpressivity). Language L priv KH is equiexpressive\
    \ with LKH , i.e., for all formulas ϕ ∈ Lpriv KH , KH priv <sup>⊢</sup> <sup>ϕ</sup>\
    \ <sup>↔</sup> <sup>t</sup>(ϕ).\n\n#### Theorem 26 (Soundness and completeness).\
    \ For all ϕ ∈ Lpriv KH ,\n\n$$\n\\mathscr{K}\\!\\mathscr{H}^{priv}\\vdash\\varphi\\\
    qquad\\Longleftrightarrow\\qquad\\mathcal{K}\\mathcal{H}\\models\\varphi.\n$$\n\
    \nFinally, as in Corollary [15,](#page-11-4) necessitation for private hope update\
    \ is an admissible inference rule in KH priv. In other words, if KH priv ⊢ ϕ,\
    \ then KH priv ⊢ [U, e]ϕ.\n\n### <span id=\"page-16-0\"></span>5 Factual Change\n\
    \nIn this section, we provide a way to add factual change to our model updates.\
    \ This is going along well-trodden paths in dynamic epistemic logic [\\[3,](#page-19-6)\
    \ [7,](#page-20-15) [8\\]](#page-20-16).\n\n### 5.1 Syntax, Semantics, and Axiomatization\n\
    \nDefinition 27 (Hope update model with factual change). To obtain a hope update\
    \ model with factual change U = (E, ϑ, σ, K<sup>U</sup> ) from a hope update model\
    \ (E, ϑ, K<sup>U</sup> ) for a language L we add parameter σ : E → (Prop → L).\
    \ We require that each σ(e) be only finitely different from the identity function,\
    \ i.e., that the set {p ∈ Prop | σ(e)(p) 6= p} be finite for each e ∈ E.\n\n<span\
    \ id=\"page-16-1\"></span>The finitary requirement is needed in order to keep\
    \ the language well-defined.\n\nDefinition 28 (Language L f KH ). Language L f\
    \ KH is defined by the grammar that looks like the one in Def. [17](#page-12-0)\
    \ except that (U, e) in the clause [U, e]ϕ here is a pointed hope update model\
    \ with factual change for the language L f KH .\n\n<span id=\"page-16-2\"></span>As\
    \ in the previous section, Def. [28](#page-16-1) is given by mutual recursion\
    \ and from here on all hope update models are hope update models with factual\
    \ change for language L f KH .\n\nDefinition 29 (Semantics). Let U = (E, ϑ, σ,\
    \ K<sup>U</sup> ) be a hope update model, M = (W, π, K, H) ∈ KH, w ∈ W, and e\
    \ ∈ E. Then, the only new clause compared in Def. [18](#page-12-1) is replaced\
    \ by a different update mechanism\n\n$$\nM, w \\models [U, e] \\varphi \\quad\
    \ \\text{iff} \\quad M \\otimes U, (w, e) \\models \\varphi,\n$$\n\nwith M ⊗ U\
    \ = (W<sup>×</sup>, π<sup>⊗</sup>, K<sup>×</sup>, H<sup>×</sup>) with the same\
    \ W<sup>×</sup>, K<sup>×</sup>, and H<sup>×</sup> as in Def. [18](#page-12-1)\
    \ and such that:\n\n$$\nW^{\\times} := W \\times E;\n$$\n  \n\\n\n$$\n(w, e) \\\
    in \\pi^{\\otimes}(p) \\quad \\text{iff} \\quad M, w \\models \\sigma(e)(p);\n\
    $$\n  \n\\n\n$$\n(w, e) \\mathcal{K}_i^{\\times}(v, f) \\quad \\text{iff} \\quad\
    \ w\\mathcal{K}_i v \\text{ and } e\\mathcal{K}_i^U f;\n$$\n  \n\\n\n$$\n(w, e)\
    \ \\mathcal{H}_i^{\\times}(v, f) \\quad \\text{iff} \\quad (w, e) \\mathcal{K}_i^{\\\
    times}(v, f), \\text{ and } M, w \\models \\vartheta_i(e), \\text{ and } M, v\
    \ \\models \\vartheta_i(f).\n$$\n\nThe only difference between Defs. [18](#page-12-1)\
    \ and [29](#page-16-2) is that the clause for the valuation π <sup>×</sup> of\
    \ the former is: (w, e) ∈ π <sup>×</sup>(p) iff w ∈ π(p). In other words, there\
    \ the valuation of facts does not change, and the valuation in the world w is\
    \ carried forward to that in the updated worlds (w, e). Since class KH has no\
    \ restrictions on valuations, it follows from Prop. [19](#page-12-3) that M ⊗\
    \ U ∈ KH whenever M ∈ KH.\n\nTo follow the familiar pattern of reduction axioms\
    \ from KH pub and KH priv, we first need to adapt the composition operation. For\
    \ the composition U;U ′ = (E′′, ϑ′′, σ′′ , K<sup>U</sup>;<sup>U</sup> ′ ) of hope\
    \ update models U = (E, ϑ, σ, K<sup>U</sup> ) and U ′ = (E ′ , ϑ′ , σ′ , K<sup>U</sup>\
    \ ′ ) with factual change, the new parameter σ ′′ needs to be added to Def. [20](#page-12-2)\
    \ (cf. [\\[8\\]](#page-20-16)): for any (e, e′ ),(f, f′ ) ∈ E × E′ ,\n\n$$\nE''\n\
    $$\n  \n\\n\n$$\n\\begin{array}{lll}\\n\\vdots & E \\times E' \\\\\n\\vartheta''_i((e,\
    \ e')) & \\vdots \\\\\n\\vartheta''((e, e'))(p) & \\vdots \\\\\n\\vartheta''((e,\
    \ e'))(p) & \\vdots \\\\\n\\vartheta^{(e)}(p) & \\text{if } \\sigma'(e')(p) \\\
    neq p, \\\\\n\\vartheta^{(e)}(p) & \\text{if } \\sigma'(e')(p) = p \\text{ but\
    \ } \\sigma(e)(p) \\neq p, \\\\\n\\vartheta^{(e)}(p) & \\text{if } \\sigma'(e')(p)\
    \ = p \\text{ but } \\sigma(e)(p) \\neq p, \\\\\n\\vartheta^{(e)}(p) & \\text{if\
    \ } \\sigma'(e')(p) = \\sigma(e)(p) = p\\n\\end{array}\n$$\n\nWith this upgrade\
    \ to the composition of hope update models, the only required change to the axiom\
    \ system KH priv from Def. [22](#page-14-0) is replacing the first equivalence\
    \ with [U, e]p ↔ σ(e)(p):\n\nDefinition 30 (Axiomatization KH <sup>f</sup> ).\
    \ KH <sup>f</sup> extends KH with axioms\n\n$$\n[U, e]\\rho \\leftrightarrow \\\
    sigma(e)(p) \\qquad [U, e] \\neg \\varphi \\leftrightarrow \\neg [U, e] \\varphi\
    \ [U, e] (\\varphi \\wedge \\psi) \\leftrightarrow [U, e] \\varphi \\wedge [U,\
    \ e] \\psi \\qquad [U, e][U', e'] \\varphi \\leftrightarrow \\big[ (U; U'), (e,\
    \ e') \\big] \\varphi [U, e] K_i \\varphi \\leftrightarrow \\bigwedge_{e \\mathcal{K}_i^U\
    \ f} K_i[U, f] \\varphi \\qquad [U, e] H_i \\varphi \\leftrightarrow \\left( \\\
    vartheta_i(e) \\rightarrow \\bigwedge_{e \\mathcal{K}_i^U f} K_i(\\vartheta_i(f)\
    \ \\rightarrow [U, f] \\varphi) \\right)\n$$\n\nwhere ϕ, ψ ∈ L<sup>f</sup> KH\
    \ , (U ′ , e′ ) is a pointed hope update model with factual change, p ∈ Prop,\
    \ i ∈ A, U = (E, ϑ, σ, K<sup>U</sup> ) is a hope update model with factual change,\
    \ and e, f ∈ E.\n\nTheorem 31 (Soundness). For all ϕ ∈ L<sup>f</sup> KH , KH <sup>f</sup>\
    \ ⊢ ϕ implies KH |= ϕ.\n\nProof. For most of the new axioms the proof of Theorem\
    \ [23](#page-14-1) transfers to this case verbatim. To show the validity of [U,\
    \ e][U ′ , e′ ]ϕ ↔ -(U;U ′ ),(e, e′ ) ϕ, the proof follows along the same lines\
    \ by showing that (M ⊗ U) ⊗ U ′ is isomorphic to M ⊗ (U;U ′ ), with the argument\
    \ for the valuations replaced with that from [\\[8,](#page-20-16) Prop. 2.9].\
    \ Finally, it is easy to see that KH |= [U, e]p ↔ σ(e)(p), as M, w |= [U, e]p\
    \ iff M ⊗ U,(w, e) |= p iff (w, e) ∈ π <sup>⊗</sup>(p) iff M, w |= σ(e)(p). ⊓⊔\n\
    \nIn itself it is quite remarkable that the required changes are fairly minimal,\
    \ given the enormously enhanced flexibility in specifying distributed system behavior.\
    \ From this point the techniques used for KH priv apply with barely a change to\
    \ factual change. The same arguments as for Lemma [25](#page-15-0) (for an appropriately\
    \ modified complexity measure) and Theorem [26](#page-15-1) yield the analogous\
    \ statements for L f KH , once again with the admissibility of necessitation rule\
    \ as a corollary:\n\nLemma 32 (Equiexpressivity). Language L f KH is equiexpressive\
    \ with LKH .\n\nTheorem 33 (Soundness and completeness). For all ϕ ∈ L<sup>f</sup>\
    \ KH ,\n\nKH <sup>f</sup> ⊢ ϕ ⇐⇒ KH |= ϕ.\n\n#### 5.2 Applications\n\nThe importance\
    \ of adding factual change to our framework comes from the fact that, in practical\
    \ protocols implementing FDIR mechanisms, agents usually take decisions based\
    \ on what they recorded in their local states. We demonstrate the essentials of\
    \ combined hope updates and state recovery in Example [34,](#page-17-0) which\
    \ combines the variant of self-correction introduced in Example [6](#page-6-0)\
    \ with state recovery needs that would arise in the alternating bit protocol [\\\
    [19\\]](#page-20-17).\n\n<span id=\"page-17-0\"></span>Example 34 (Private self-correction\
    \ with state recovery). The alternating bit protocol (ABP) for transmitting an\
    \ arbitrarily generated stream of consecutive data packets d1, d2, . . . from\
    \ a sender to a receiver over an unreliable communication channel uses messages\
    \ that additionally contain a sequence number consisting of 1 bit only. The latter\
    \ switches from one message to the next, by alternating atomic propositions q<sup>s</sup>\
    \ and q<sup>r</sup> containing the next sequence number to be used for the next\
    \ message generated by the sender resp. receiver side of the channel. In addition,\
    \ the sender maintains atomic proposition ps, using the difference between the\
    \ two to kick-start sending of the next packet. The receiver would not need this\
    \ second bit in the absence of faults. We use p<sup>r</sup> for self-correction,\
    \ however, in the sense that we assume that it provides a reliable backup for\
    \ qr. In the fault-free case, it will be maintained such that the invariant p<sup>r</sup>\
    \ 6= q<sup>r</sup> holds. If the receiver becomes faulty, we assume that its FDIR\
    \ unit supplies the value q<sup>r</sup> needs to be recovered to as ¬pr.\n\nLet\
    \ us describe several consecutive steps of how the ABP should operate in more\
    \ detail with agent s being the sender and agent r the receiver. Suppose agents\
    \ have the values (qs, qr) = (0, 0) and (ps, pr) = (1, 1) of their local variables\
    \ when the sending of data packet d<sup>n</sup> begins. The sending of d<sup>n</sup>\
    \ and the next packet dn+1 happens in six phases (three per packet) ([\\[19\\\
    ]](#page-20-17)), where we describe actions of each agent in term of its local\
    \ variables:\n\n(i) Since q<sup>s</sup> 6= p<sup>s</sup> (here 0 6= 1), sender\
    \ s sets p<sup>s</sup> := q<sup>s</sup> = 0 and generates a message (dn, ps) =\
    \ (dn, 0) to be repeatedly sent to r.\n\nLocal values in this phase are (qs, qr)\
    \ = (0, 0) and (ps, pr) = (0, 1).\n\n(ii) When receiver r receives (dn, qr) =\
    \ (dn, 0), it records dn, generates a message (ack, qr) = (ack, 0) to be repeatedly\
    \ sent back to s, and switches to the next sequence number q<sup>r</sup> := 1\
    \ − q<sup>r</sup> = 1, also updating the backup p<sup>r</sup> := 1 − p<sup>r</sup>\
    \ = 0.\n\nLocal values in this phase are (qs, qr) = (0, 1) and (ps, pr) = (0,\
    \ 0).\n\n<span id=\"page-18-0\"></span>(iii) When sender s receives (ack, ps)\
    \ = (ack, 0), sender switches to the next sequence number q<sup>s</sup> := 1 −\
    \ p<sup>s</sup> = 1 and next data packet dn+1.\n\nLocal values in this phase are\
    \ (qs, qr) = (1, 1) and (ps, pr) = (0, 0).\n\n(iv) Since q<sup>s</sup> 6= p<sup>s</sup>\
    \ (here 1 6= 0), sender s sets p<sup>s</sup> := q<sup>s</sup> = 1 and generates\
    \ a message (dn+1, ps) = (dn+1, 1) to be repeatedly sent to r.\n\nLocal values\
    \ in this phase are (qs, qr) = (1, 1) and (ps, pr) = (1, 0).\n\n(v) When receiver\
    \ r receives (dn+1, qr) = (dn+1, 1), it records dn+1, generates a message (ack,\
    \ qr) = (ack, 1) to be repeatedly sent back to s, and switches to the next sequence\
    \ number q<sup>r</sup> := 1 − q<sup>r</sup> = 0, also updating the backup p<sup>r</sup>\
    \ := 1 − p<sup>r</sup> = 1.\n\nLocal values in this phase are (qs, qr) = (1, 0)\
    \ and (ps, pr) = (1, 1).\n\n(vi) When sender s receives (ack, ps) = (ack, 1),\
    \ sender switches to the next sequence number q<sup>s</sup> := 1 − p<sup>s</sup>\
    \ = 0. Local values in this phase are (qs, qr) = (0, 0) and (ps, pr) = (1, 1).\n\
    \nAt this point, all local variables have returned to their values when s had\
    \ started sending packet dn, and the cycle repeats again and again. Thus, during\
    \ a correct run of the ABP, values of (qs, qr) continuously cycle through (0,\
    \ 0), (0, 1), (1, 1), (1, 0), (0, 0). Note also that, p<sup>r</sup> 6= q<sup>r</sup>\
    \ throughout any correct run of the protocol, enabling to retrieve a correct value\
    \ of q<sup>r</sup> from backup pr. By contrast, p<sup>s</sup> = q<sup>s</sup>\
    \ can happen, creating an asymmetry between sender and receiver.\n\nIf a transient\
    \ fault would flip the value of either q<sup>s</sup> or qr, the ABP can deadlock\
    \ and, therefore, would require correction. For instance, if q<sup>s</sup> flips\
    \ from 1 to 0 at the end of phase [\\(iii\\)](#page-18-0), the condition p<sup>s</sup>\
    \ 6= q<sup>s</sup> for the start of sending dn+1 would never be fulfilled.\n\n\
    Due to the above mentioned invariant p<sup>r</sup> 6= qr, the need for a correction\
    \ of receiver (in case q<sup>r</sup> has accidentally flipped) can be conveniently\
    \ determined by checking whether p<sup>r</sup> = qr, while the correction itself\
    \ can be performed by just setting q<sup>r</sup> := 1 − pr.\n\nTo model this self-correction\
    \ in our logic, we treat boolean variables pr, qr, ps, and q<sup>s</sup> as atomic\
    \ propositions so that p<sup>r</sup> = q<sup>r</sup> becomes p<sup>r</sup> ↔ q<sup>r</sup>\
    \ and q<sup>r</sup> := 1 − p<sup>r</sup> looks like q<sup>r</sup> := ¬pr. Accordingly,\
    \ we model agent r successfully self-correcting and recovering its state based\
    \ on the condition p<sup>r</sup> ↔ qr. At the same time, s is uncertain whether\
    \ r has corrected itself (event scr<sup>p</sup>r=q<sup>r</sup> ) or not (event\
    \ noscr). Again writing ϑ(e) as (ϑa(e), ϑb(e) , this is encoded in the hope update\
    \ model U := (E, ϑ, σ, K<sup>U</sup> ), where:\n\n$$\nE := \\{ scr_{p_r = q_r},\
    \ noscr \\}\n$$\n  \n\\n\n$$\n\\vartheta(scr_{p_r = q_r}) := (\\neg H_s \\bot,\
    \ \\neg H_r \\bot \\lor (p_r \\leftrightarrow q_r))\n$$\n  \n\\n\n$$\n\\vartheta(noscr)\
    \ := (\\neg H_s \\bot, \\neg H_r \\bot)\n$$\n  \n\\n\n$$\n\\vartheta(r) := \\\
    neg p_r\n$$\n  \n\\n\n$$\n\\mathcal{K}_s^U := E \\times E\n$$\n  \n\\n\n$$\n\\\
    mathcal{K}_r^U := \\{ (e, e) \\mid e \\in E \\}\n$$\n\nNote that Hr⊥ is equivalent\
    \ to p<sup>r</sup> ↔ qr, making Hr⊥ locally detectable by r and resulting in ϑ(scrpr=q<sup>r</sup>\
    \ ) = (¬Hs⊥, ⊤). In other words, agent r is guaranteed to become correct whenever\
    \ this update is applied. All atoms for noscr and all atoms other than q<sup>r</sup>\
    \ for scrpr=q<sup>r</sup> remain unchanged by σ. Coding the atoms in each state\
    \ as psqs.prqr, the resulting update is:\n\n![](_page_19_Figure_2.jpeg)\n\nThe\
    \ only change happens in global states **00**.00 and **01**.00 where p<sup>r</sup>\
    \ ↔ q<sup>r</sup> causes the hope update and q<sup>r</sup> is set to be the opposite\
    \ of pr. After the update, we get:\n\n| M, 00.00  = [U, scrpr=qr<br>](¬Hr⊥ ∧ Krqr)\
    \       | r has corrected herself and learned the right value of qr |\n|--------------------------------------------------|-----------------------------------------------------------|\n\
    | M, 00.00  = [U, scrpr=qr<br>]Kr¬Hr⊥              | r is now sure she is correct\
    \                              |\n| M, 00.00  = [U, scrpr=qr<br>](¬Krqs<br>∧ ¬Kr¬qs)\
    \ | r remains unsure regarding qs                             |\n| M, 00.00  =\
    \ [U, scrpr=qr<br>]KbsHr⊥              | s considers possible that r is faulty\
    \                     |\n|                                                  |\
    \                                                           |\n\n### <span id=\"\
    page-19-3\"></span>6 Conclusions and Further Research\n\nWe gave various dynamic\
    \ epistemic semantics for the modeling and analysis of byzantine faulttolerant\
    \ multi-agent systems, expanding a known logic containing knowledge and hope modalities.\
    \ We provided complete axiomatizations for our logics and applied them to fault-detection,\
    \ isolation, and recovery (FDIR) in distributed computing. For future research\
    \ we envision alternative dynamic epistemic update mechanisms, as well as embedding\
    \ our logic into the (temporal epistemic) runsand-systems approach.\n\nAcknowledgments.\
    \ We are grateful for multiple fruitful discussions with and enthusiastic support\
    \ from Giorgio Cignarale, Stephan Felber, Rojo Randrianomentsoa, Hugo Rinc´on\
    \ Galeana, and Thomas Schl¨ogl.\n\n### References\n\n- <span id=\"page-19-1\"\
    ></span>1. J. C. Adams and K. V. S. Ramarao. Distributed diagnosis of byzantine\
    \ processors and links. In Proceedings, The 9th International Conference on Distributed\
    \ Computing Systems: Newport Beach, California, June 5–9, 1989, pages 562–569.\
    \ IEEE, 1989. [doi:10.1109/ICDCS.1989.37989](http://dx.doi.org/10.1109/ICDCS.1989.37989).\n\
    - <span id=\"page-19-5\"></span>2. A. Baltag, L. S. Moss, and S. Solecki. The\
    \ logic of public announcements, common knowledge, and private suspicions. In\
    \ I. Gilboa, editor, Theoretical Aspects of Rationality and Knowledge: Proceedings\
    \ of the Seventh Conference (TARK 1998), pages 43–56. Morgan Kaufmann, 1998. Available\
    \ from: [http://tark.org/proceedings/tark\\\\_jul22\\\\_98/p43-baltag.pdf](http://tark.org/proceedings/tark_jul22_98/p43-baltag.pdf).\n\
    - <span id=\"page-19-6\"></span>3. J. van Benthem, J. van Eijck, and B. Kooi.\
    \ Logics of communication and change. Information and Computation, 204(11):1620–1662,\
    \ November 2006. [doi:10.1016/j.ic.2006.04.006](http://dx.doi.org/10.1016/j.ic.2006.04.006).\n\
    - <span id=\"page-19-4\"></span>4. J. van Benthem and F. Liu. Dynamic logic of\
    \ preference upgrade. Journal of Applied Non-Classical Logics, 17(2):157–182,\
    \ 2007. [doi:10.3166/jancl.17.157-182](http://dx.doi.org/10.3166/jancl.17.157-182).\n\
    - <span id=\"page-19-2\"></span>5. H. van Ditmarsch. Description of game actions.\
    \ Journal of Logic, Language and Information, 11(3):349–365, June 2002. [doi:10.1023/A:1015590229647](http://dx.doi.org/10.1023/A:1015590229647).\n\
    - <span id=\"page-19-0\"></span>6. H. van Ditmarsch, K. Fruzsa, and R. Kuznets.\
    \ A new hope. In D. Fern´andez-Duque, A. Palmigiano, and S. Pinchinat, editors,\
    \ Advances in Modal Logic, volume 14, pages 349–369. College Publications, 2022.\
    \ Available from: <http://www.aiml.net/volumes/volume14/22-vanDitmarsch-Fruzsa-Kuznets.pdf>.\n\
    - <span id=\"page-20-15\"></span>7. H. van Ditmarsch, W. van der Hoek, and B.\
    \ Kooi. Dynamic epistemic logic with assignment. In AAMAS '05: Proceedings of\
    \ the fourth international joint conference on Autonomous agents and multiagent\
    \ systems, pages 141–148. Association for Computing Machinery, 2005. [doi:10.1145/1082473.1082495](http://dx.doi.org/10.1145/1082473.1082495).\n\
    - <span id=\"page-20-16\"></span>8. H. van Ditmarsch and B. Kooi. Semantic results\
    \ for ontic and epistemic change. In G. Bonanno, W. van der Hoek, and M. Wooldridge,\
    \ editors, Logic and the Foundations of Game and Decision Theory (LOFT 7), volume\
    \ 3 of Texts in Logic and Games, pages 87–118. Amsterdam University Press, 2008.\
    \ Available from: <https://www.jstor.org/stable/j.ctt46mz4h.6>.\n- <span id=\"\
    page-20-7\"></span>9. D. Dolev, M. F¨ugger, M. Posch, U. Schmid, A. Steininger,\
    \ and C. Lenzen. Rigorously modeling selfstabilizing fault-tolerant circuits:\
    \ An ultra-robust clocking scheme for systems-on-chip. Journal of Computer and\
    \ System Sciences, 80(4):860–900, June 2014. [doi:10.1016/j.jcss.2014.01.001](http://dx.doi.org/10.1016/j.jcss.2014.01.001).\n\
    - <span id=\"page-20-5\"></span>10. C. Dwork and Y. Moses. Knowledge and common\
    \ knowledge in a Byzantine environment: Crash failures. Information and Computation,\
    \ 88(2):156–186, October 1990. [doi:10.1016/0890-5401\\(90\\)90014-9](http://dx.doi.org/10.1016/0890-5401(90)90014-9).\n\
    - <span id=\"page-20-10\"></span>11. J. van Eijck. DEMO — A demo of epistemic\
    \ modelling. In J. van Benthem, D. Gabbay, and B. L¨owe, editors, Interactive\
    \ Logic: Selected Papers from the 7th Augustus de Morgan Workshop, London, volume\
    \ 1 of Texts in Logic and Games, pages 303–362. Amsterdam University Press, 2007.\
    \ Available from: <https://www.jstor.org/stable/j.ctt45kdbf.15>.\n- <span id=\"\
    page-20-14\"></span>12. E. N. M. Elnozahy, L. Alvisi, Y.-M. Wang, and D. B. Johnson.\
    \ A survey of rollback-recovery protocols in message-passing systems. ACM Computing\
    \ Surveys, 34(3):375–408, September 2002. [doi:10.1145/568522.568525](http://dx.doi.org/10.1145/568522.568525).\n\
    - <span id=\"page-20-9\"></span><span id=\"page-20-0\"></span>13. R. Fagin, J.\
    \ Y. Halpern, Y. Moses, and M. Y. Vardi. Reasoning About Knowledge. MIT Press,\
    \ 1995. [doi:10.7551/mitpress/5803.001.0001](http://dx.doi.org/10.7551/mitpress/5803.001.0001).\n\
    - 14. K. Fruzsa. Hope for epistemic reasoning with faulty agents! In A. Pavlova,\
    \ M. Y. Pedersen, and R. Bernardi, editors, Selected Reflections in Language,\
    \ Logic, and Information: ESSLLI 2019, ESS-LLI 2020 and ESSLLI 2021, Student Sessions,\
    \ Selected Papers, volume 14354 of Lecture Notes in Computer Science, pages 93–108.\
    \ Springer, 2023. [doi:10.1007/978-3-031-50628-4\\\\_6](http://dx.doi.org/10.1007/978-3-031-50628-4_6).\n\
    - <span id=\"page-20-6\"></span>15. K. Fruzsa, R. Kuznets, and U. Schmid. Fire!\
    \ In J. Halpern and A. Perea, editors, Proceedings of the Eighteenth Conference\
    \ on Theoretical Aspects of Rationality and Knowledge, Beijing, China, June 25–27,\
    \ 2021, volume 335 of Electronic Proceedings in Theoretical Computer Science,\
    \ pages 139–153. Open Publishing Association, 2021. [doi:10.4204/EPTCS.335.13](http://dx.doi.org/10.4204/EPTCS.335.13).\n\
    - <span id=\"page-20-8\"></span>16. M. F¨ugger and U. Schmid. Reconciling fault-tolerant\
    \ distributed computing and systems-on-chip. Distributed Computing, 24(6):323–355,\
    \ January 2012. [doi:10.1007/s00446-011-0151-7](http://dx.doi.org/10.1007/s00446-011-0151-7).\n\
    - <span id=\"page-20-11\"></span>17. P. Gammie and R. van der Meyden. MCK: Model\
    \ checking the logic of knowledge. In R. Alur and D. A. Peled, editors, Computer\
    \ Aided Verification: 16th International Conference, CAV 2004, Boston, MA, USA,\
    \ July 2004, Proceedings, volume 3114 of Lecture Notes in Computer Science, pages\
    \ 479–483. Springer, 2004. [doi:10.1007/978-3-540-27813-9\\\\_41](http://dx.doi.org/10.1007/978-3-540-27813-9_41).\n\
    - <span id=\"page-20-1\"></span>18. J. Y. Halpern and Y. Moses. Knowledge and\
    \ common knowledge in a distributed environment. Journal of the ACM, 37(3):549–587,\
    \ July 1990. [doi:10.1145/79147.79161](http://dx.doi.org/10.1145/79147.79161).\n\
    - <span id=\"page-20-17\"></span>19. J. Y. Halpern and L. D. Zuck. A little knowledge\
    \ goes a long way: Knowledge-based derivations and correctness proofs for a family\
    \ of protocols. Journal of the ACM, 39(3):449–478, July 1992. [doi:10.1145/146637.146638](http://dx.doi.org/10.1145/146637.146638).\n\
    - <span id=\"page-20-12\"></span>20. A. Heuerding, G. J¨ager, S. Schwendimann,\
    \ and M. Seyfried. A Logics Workbench. AI Communications, 9(2):53–58, July 1996.\
    \ [doi:10.3233/AIC-1996-9203](http://dx.doi.org/10.3233/AIC-1996-9203).\n- <span\
    \ id=\"page-20-13\"></span>21. R. M. Kieckhafer, C. J. Walter, A. M. Finn, and\
    \ P. M. Thambidurai. The MAFT architecture for distributed fault tolerance. IEEE\
    \ Transactions on Computers, 37(4):398–404, April 1988. [doi:10.1109/12.2183](http://dx.doi.org/10.1109/12.2183).\n\
    - <span id=\"page-20-2\"></span>22. R. Kuznets, L. Prosperi, U. Schmid, and K.\
    \ Fruzsa. Causality and epistemic reasoning in byzantine multi-agent systems.\
    \ In L. S. Moss, editor, Proceedings of the Seventeenth Conference on Theoretical\
    \ Aspects of Rationality and Knowledge, Toulouse, France, 17–19 July 2019, volume\
    \ 297 of Electronic Proceedings in Theoretical Computer Science, pages 293–312.\
    \ Open Publishing Association, 2019. [doi:10.4204/EPTCS.297.19](http://dx.doi.org/10.4204/EPTCS.297.19).\n\
    - <span id=\"page-20-4\"></span>23. R. Kuznets, L. Prosperi, U. Schmid, and K.\
    \ Fruzsa. Epistemic reasoning with byzantine-faulty agents. In A. Herzig and A.\
    \ Popescu, editors, Frontiers of Combining Systems: 12th International Symposium,\
    \ FroCoS 2019, London, UK, September 4–6, 2019, Proceedings, volume 11715 of Lecture\
    \ Notes in Artificial Intelligence, pages 259–276. Springer, 2019. [doi:10.1007/978-3-030-29007-8\\\
    \\_15](http://dx.doi.org/10.1007/978-3-030-29007-8_15).\n- <span id=\"page-20-3\"\
    ></span>24. R. Kuznets, L. Prosperi, U. Schmid, K. Fruzsa, and L. Gr´eaux. Knowledge\
    \ in Byzantine messagepassing systems I: Framework and the causal cone. Technical\
    \ Report TUW-260549, TU Wien, 2019. Available from: [https://publik.tuwien.ac.at/files/publik\\\
    \\_260549.pdf](https://publik.tuwien.ac.at/files/publik_260549.pdf).\n- 22 H.\
    \ van Ditmarsch, K. Fruzsa, R. Kuznets, U. Schmid\n- <span id=\"page-21-9\"></span><span\
    \ id=\"page-21-1\"></span>25. L. Lamport, R. Shostak, and M. Pease. The Byzantine\
    \ Generals Problem. ACM Transactions on Programming Languages and Systems, 4(3):382–401,\
    \ July 1982. [doi:10.1145/357172.357176](http://dx.doi.org/10.1145/357172.357176).\n\
    - 26. H. Mendes, C. Tasson, and M. Herlihy. Distributed computability in Byzantine\
    \ asynchronous systems. In STOC 2014, 46th Annual Symposium on the Theory of Computing:\
    \ 31 May–3 June 2014, New York, New York, USA, pages 704–713. Association for\
    \ Computing Machinery, 2014. [doi:10.1145/2591796.2591853](http://dx.doi.org/10.1145/2591796.2591853).\n\
    - <span id=\"page-21-14\"></span><span id=\"page-21-0\"></span>27. J. C. Mitchell\
    \ and E. Moggi. Kripke-style models for typed lambda calculus. Annals of Pure\
    \ and Applied Logic, 51(1–2):99–124, March 1991. [doi:10.1016/0168-0072\\(91\\\
    )90067-V](http://dx.doi.org/10.1016/0168-0072(91)90067-V).\n- 28. Y. Moses. Relating\
    \ knowledge and coordinated action: The Knowledge of Preconditions principle.\
    \ In R. Ramanujam, editor, Proceedings Fifteenth Conference on Theoretical Aspects\
    \ of Rationality and Knowledge, Carnegie Mellon University, Pittsburgh, USA, June\
    \ 4–6, 2015, volume 215 of Electronic Proceedings in Theoretical Computer Science,\
    \ pages 231–245. Open Publishing Association, 2016. [doi:10.4204/EPTCS.215.17](http://dx.doi.org/10.4204/EPTCS.215.17).\n\
    - <span id=\"page-21-2\"></span>29. A. Pessin and S. Goldberg. The Twin Earth\
    \ Chronicles: Twenty Years of Reflection on Hilary Putnam's \"The Meaning of 'Meaning'\
    \ \". M. E. Sharpe, 1995. [doi:10.4324/9781315284811](http://dx.doi.org/10.4324/9781315284811).\n\
    - <span id=\"page-21-11\"></span>30. D. Powell, J. Arlat, L. Beus-Dukic, A. Bondavalli,\
    \ P. Coppola, A. Fantechi, E. Jenn, C. Rab´ejac, and A. Wellings. GUARDS: A generic\
    \ upgradable architecture for real-time dependable systems. IEEE Transactions\
    \ on Parallel and Distributed Systems, 10(6):580–599, June 1999. [doi:10.1109/71.774908](http://dx.doi.org/10.1109/71.774908).\n\
    - <span id=\"page-21-13\"></span><span id=\"page-21-6\"></span>31. P. Robinson\
    \ and U. Schmid. The Asynchronous Bounded-Cycle model. Theoretical Computer Science,\
    \ 412(40):5580–5601, September 2011. [doi:10.1016/j.tcs.2010.08.001](http://dx.doi.org/10.1016/j.tcs.2010.08.001).\n\
    - 32. J. Rushby. Reconfiguration and transient recovery in state machine architectures.\
    \ In Proceedings of the Twenty-Sixth International Symposium on Fault-Tolerant\
    \ Computing: June 25–27, 1996, Sendai, Japan, pages 6–15. IEEE, 1996. [doi:10.1109/FTCS.1996.534589](http://dx.doi.org/10.1109/FTCS.1996.534589).\n\
    - <span id=\"page-21-4\"></span>33. T. Schl¨ogl and U. Schmid. A sufficient condition\
    \ for gaining belief in byzantine fault-tolerant distributed systems. In R. Verbrugge,\
    \ editor, Proceedings of the Nineteenth conference on Theoretical Aspects of Rationality\
    \ and Knowledge, Oxford, United Kingdom, 28–30th June 2023, volume 379 of Electronic\
    \ Proceedings in Theoretical Computer Science, pages 487–497. Open Publishing\
    \ Association, 2023. [doi:10.4204/EPTCS.379.37](http://dx.doi.org/10.4204/EPTCS.379.37).\n\
    - <span id=\"page-21-3\"></span>34. T. Schl¨ogl, U. Schmid, and R. Kuznets. The\
    \ persistence of false memory: Brain in a vat despite perfect clocks. In T. Uchiya,\
    \ Q. Bai, and I. Mars´a Maestre, editors, PRIMA 2020: Principles and Practice\
    \ of Multi-Agent Systems: 23rd International Conference, Nagoya, Japan, November\
    \ 18–20, 2020, Proceedings, volume 12568 of Lecture Notes in Artificial Intelligence,\
    \ pages 403–411. Springer, 2021. [doi:10.1007/978-3-030-69322-0\\\\_30](http://dx.doi.org/10.1007/978-3-030-69322-0_30).\n\
    - <span id=\"page-21-10\"></span>35. F. B. Schneider. Implementing fault-tolerant\
    \ services using the state machine approach: A tutorial. ACM Computing Surveys,\
    \ 22(4):299–319, December 1990. [doi:10.1145/98163.98167](http://dx.doi.org/10.1145/98163.98167).\n\
    - <span id=\"page-21-5\"></span>36. T. K. Srikanth and S. Toueg. Optimal clock\
    \ synchronization. Journal of the ACM, 34(3):626–645, July 1987. [doi:10.1145/28869.28876](http://dx.doi.org/10.1145/28869.28876).\n\
    - <span id=\"page-21-8\"></span>37. T. K. Srikanth and S. Toueg. Simulating authenticated\
    \ broadcasts to derive simple fault-tolerant algorithms. Distributed Computing,\
    \ 2(2):80–94, June 1987. [doi:10.1007/BF01667080](http://dx.doi.org/10.1007/BF01667080).\n\
    - <span id=\"page-21-12\"></span>38. C. J. Walter, P. Lincoln, and N. Suri. Formally\
    \ verified on-line diagnosis. IEEE Transactions on Software Engineering, 23(11):684–721,\
    \ November 1997. [doi:10.1109/32.637385](http://dx.doi.org/10.1109/32.637385).\n\
    - <span id=\"page-21-7\"></span>39. J. Widder and U. Schmid. The Theta-Model:\
    \ achieving synchrony without clocks. Distributed Computing, 22(1):29–47, April\
    \ 2009. [doi:10.1007/s00446-009-0080-x](http://dx.doi.org/10.1007/s00446-009-0080-x)."
- id: structured_acyclic_nets_all_sets_used_in_the_relational_structures_considered_in_this_paper_are_finite_which_simplifies_some_of_the_definitions_and_results_for_two_sets_x_and_y_x_y_means_that_x_is_a_proper_subset_of_y_i_e_x_y_and_x_6_y_the_disjoint_union_of_x_and_y_is_denoted_by_x_y_and_nonempty_sets_x_1_xk_form_a_partition_of_a_sets_x_if_x_x_1_xk
  title: Structured Acyclic Nets
  abstract: 'The concept of structured occurrence nets is an extension of that of

    occurrence nets which are directed acyclic graphs that represent causality and

    concurrency information concerning a single execution of a distributed system.

    The formalism of structured occurrence nets has been introduced to facilitate

    the portrayal and analysis of the behaviours, and in particular failures, of

    complex evolving systems. Such systems are composed of a large number of

    sub-systems which may proceed concurrently and interact with each other and

    with the external environment while their behaviour is subject to modification

    by other systems. The purpose of this paper is to provide an extension of

    structured occurrence nets to include models built up of acyclic nets rather

    than occurrence nets.'
  url: http://arxiv.org/abs/2401.07308v1
  keywords: ''
  document: "Mohammed Alahmadi, Salma Alharbi, Talal Alharbi, Nadiyah Almutairi, Tuwailaa\
    \ Alshammari, Anirban Bhattacharyya, Maciej Koutny, Bowen Li, and Brian Randell\n\
    \n> School of Computing, Newcastle University Urban Sciences Building, 1 Science\
    \ Square, Newcastle Helix Newcastle upon Tyne, NE4 5TG, United Kingdom January\
    \ 17, 2024\n\nAbstract. The concept of structured occurrence nets is an extension\
    \ of that of occurrence nets which are directed acyclic graphs that represent\
    \ causality and concurrency information concerning a single execution of a distributed\
    \ system. The formalism of structured occurrence nets has been introduced to facilitate\
    \ the portrayal and analysis of the behaviours, and in particular failures, of\
    \ complex evolving systems. Such systems are composed of a large number of sub-systems\
    \ which may proceed concurrently and interact with each other and with the external\
    \ environment while their behaviour is subject to modification by other systems.\
    \ The purpose of this paper is to provide an extension of structured occurrence\
    \ nets to include models built up of acyclic nets rather than occurrence nets.\n\
    \n# 1 Introduction\n\nThe concept of structured occurrence nets [\\[16,](#page-34-0)[20\\\
    ]](#page-34-1) is an extension of that of occurrence nets [\\[11\\]](#page-34-2)\
    \ which are directed acyclic graphs (a subclass of Petri nets) that represent\
    \ causality and concurrency information concerning a single execution of a distributed\
    \ system. The formalism of structured occurrence nets has been introduced to facilitate\
    \ the portrayal and analysis of the behaviours, and in particular failures, of\
    \ complex evolving systems. Examples include a large hardware system which suffers\
    \ component break-downs, reconfigurations and replacements, a large distributed\
    \ system whose software is being continually updated (or patched), a gang of criminals\
    \ whose membership is changing, and an operational railway system that is being\
    \ extended. (In these latter cases we are regarding crimes and accidents as types\
    \ of failure.) The underlying idea of a structured occurrence net is to combine\
    \ multiple related occurrence nets by using various formal relationships (in particular,\
    \ abstractions) in order to express dependencies among the component occurrence\
    \ nets. By means of these relations, a structured occurrence net is able to portray\
    \ a more explicit view of system activity, involving various types of communication\
    \ between subsystems, and of system upgrades, reconfigurations and replacements\
    \ than is possible with an occurrence net, so allowing one to document and exploit\
    \ behavioural knowledge of (actual or envisaged) complex evolving systems.\n\n\
    Communication structured occurrence nets are a basic variant of structured occurrence\
    \ nets that enable the explicit representation of synchronous and asynchronous\
    \ interaction between communicating subsystems. A communication structured occurrence\
    \ net is composed of a set of distinct component occurrence nets representing\
    \ separate\n\nsubsystems. When it is determined that there is a potential for\
    \ an interaction between subsystems, an asynchronous or synchronous communication\
    \ link can be made between events in the different subsystems' occurrence nets\
    \ via a channel/buffer place.\n\nAnother variant of structured occurrence nets,\
    \ behavioural structured occurrence nets, conveys information about the evolution\
    \ of individual systems. They use a two level view to represent an execution history,\
    \ with the lower level providing details of its behaviours during the different\
    \ evolution stages represented in the upper level view. Thus a behavioural structured\
    \ occurrence net gives information about the evolution of an individual system,\
    \ and the phases of the overall activity are used to represent each successive\
    \ stage of the evolution of this system.\n\nThis document extends and systematises\
    \ the ideas contained in [\\[16\\]](#page-34-0), after allowing backward non-determinism\
    \ and forward non-determinism in the representation of the components of a complex\
    \ evolving system. This is achieved by replacing occurrence nets with more general\
    \ acyclic nets. As a result, it leads to communication structured acyclic nets\
    \ and behavioural structured acyclic nets generalising previously introduced models.\n\
    \n# 2 Preliminaries\n\nAll sets used in the relational structures considered in\
    \ this paper are finite which simplifies some of the definitions and results.\
    \ For two sets *X* and *Y*, *X* ⊂ *Y* means that *X* is a proper subset of *Y*,\
    \ i.e., *X* ⊆ *Y* and *X* 6= *Y*. The disjoint union of *X* and *Y* is denoted\
    \ by *X* ⊎*Y*, and nonempty sets *X*1,...,*X<sup>k</sup>* form a partition of\
    \ a sets *X* if *X* = *X*<sup>1</sup> ⊎··· ⊎*X<sup>k</sup>* .\n\nFor a binary\
    \ relation *R*, *xRy* means that (*x*,*y*) ∈ *R*. The *composition* of two binary\
    \ relations, *R* and *Q*, is a binary relation given by *R*◦*Q* , {(*x*,*y*)|\
    \ ∃*z*: *xRz*∧*zQy*}. Moreover, for every *k* ≥ 1, w define:\n\n$$\nR^k \\triangleq\
    \ \\begin{cases} R & \\text{if } k = 1 \\\\ R \\circ R^{k-1} & otherwise \\end{cases}.\n\
    $$\n\nThe first definition introduces notions related to partial orders which\
    \ can be used, e.g., to capture causality is concurrent behaviours.\n\nDefinition\
    \ 1 (relations and orderings). *Let X be a set and R* ⊆ *X* ×*X.*\n\n- *1. id<sup>X</sup>*\
    \ , {(*x*,*x*) | *x* ∈ *X*} *is the* identity *relation on X.*\n- *2. R is* reflexive\
    \ *if id<sup>X</sup>* ⊆ *R.*\n- *3. R is* irreflexive *if R*∩*id<sup>X</sup>*\
    \ = ∅*.*\n- *4. R is* transitive *if R*◦*R* ⊆ *R.*\n- *5.* (*X*,*R*) *is a* partial\
    \ order *if R is irreflexive and transitive.*\n- *6. R*<sup>+</sup> , *R* <sup>1</sup>\
    \ ∪*R* <sup>2</sup> ∪... *is the* transitive closure *of R.*\n\n*7. R is* acyclic\
    \ *if R*<sup>+</sup> ∩*id<sup>X</sup>* = ∅*.* ♦\n\nThe following facts follow\
    \ directly from the definitions.\n\nProposition 1. *Let X be a set and R* ⊆ *X*\
    \ ×*X.*\n\n*1. If* (*X*,*R*) *is a partial order then R is acyclic.*\n\n- *2.\
    \ If R is acyclic then* (*X*,*R* <sup>+</sup>) *is a partial order.*\n- *3. R\
    \ is acyclic iff there are no x*1,...,*xk*(= *x*1)∈*X (k* ≥ 2*) such that x*1*Rx*2,...,*xk*−1*Rx<sup>k</sup>\
    \ .*\n\nRather than using sequences of events to represent possible executions\
    \ of concurrent systems, we will use sequences of sets of events. The following\
    \ definition introduces two useful notions related to such sequences.\n\nDefinition\
    \ 2 (sequence of sets). *Let* <sup>σ</sup> = *X*<sup>1</sup> ...*X<sup>k</sup>\
    \ be a sequence of sets and X be a set.*\n\n- *1.* S <sup>σ</sup> , *X*<sup>1</sup>\
    \ ∪ ··· ∪*X<sup>k</sup> denotes the set of elements* occurring *in* <sup>σ</sup>*.*\n\
    - *2.* <sup>σ</sup>|*<sup>X</sup>* , (*X*<sup>1</sup> ∩*X*)...(*X<sup>k</sup>*\
    \ ∩*X*) *denotes the* restriction *of* <sup>σ</sup> *to the elements of X.*\n\n\
    *3.* <sup>σ</sup> ↾*<sup>X</sup> is obtained from* <sup>σ</sup>|*<sup>X</sup>\
    \ by deleting all the occurrences of the empty set.* ♦\n\n*Example 1.* For <sup>σ</sup>\
    \ = {*a*,*b*}{*a*,*c*}{*d*}, S <sup>σ</sup> = {*a*,*b*,*c*,*d*}, <sup>σ</sup>|{*a*,*b*}\
    \ = {*a*,*b*}{*a*}∅, and <sup>σ</sup> ↾{*a*,*b*}= {*a*,*b*}{*a*}. ♦\n\nWhen defining\
    \ or proving properties of the elements of a set *X* for which we are given an\
    \ acyclic relation *R*, one can apply the principle of mathematical induction.\
    \ Typical patterns are as follows:\n\n### defining property *P<sup>x</sup>* for\
    \ every *x* ∈ *X*\n\nFirst define *P<sup>x</sup>* for every *x* such that {*y*\
    \ | *yRx*} = ∅. Then, for every other *x* ∈ *X*, define *P<sup>x</sup>* assuming\
    \ that *P<sup>x</sup>* has been defined for each element *y* ∈ *X* such that *yR*+*x*.\
    \ proving property *P<sup>x</sup>* for every *x* ∈ *X*\n\nFirst prove *P<sup>x</sup>*\
    \ for every *x* such that {*y* | *yRx*} = ∅. Then, for every other *x* ∈ *X*,\
    \ prove *P<sup>x</sup>* assuming that *P* holds for each element *y* ∈ *X* such\
    \ that *yR*+*x*.\n\n# 3 Acyclic nets\n\nThis section is concerned with Petri nets\
    \ which generalise occurrence nets and can provide a direct support for causality\
    \ analysis.\n\nThe following are intuitive explanations of the main concepts defined\
    \ in this and subsequent sections using terminology based on accident/crime investigations:\n\
    \n#### acyclic net\n\nA basic fragment of 'database' of all facts (both actual\
    \ or hypothetical represented using places, transitions, and arcs linking them)\
    \ accumulated during an investigation. Transitions (events) and places (conditions/local\
    \ states) are related through arrows representing causal and/or temporal dependencies.\
    \ Hence, the representation is required to be acyclic (this is a minimal requirement).\
    \ Acyclic nets can represent alternative ways of interpreting what has happened,\
    \ and so may exhibit (backward and forward) non-determinism.\n\n#### backward\
    \ deterministic acyclic net\n\nAn acyclic net such that for each event it is possible\
    \ to state precisely which other events must have preceded it.\n\n#### occurrence\
    \ net\n\nAn acyclic net providing a complete record of all causal dependencies\
    \ between events involved in a single 'causal history'.\n\n4 Structured Acyclic\
    \ Nets\n\n![](_page_3_Figure_1.jpeg)\n\n<span id=\"page-3-0\"></span>Fig. 1. Acyclic\
    \ nets with initial markings.\n\nDefinition 3 (acyclic net). *An* acyclic net\
    \ *is a triple acnet* = (*P*,*T*,*F*)*, where P and T are disjoint finite sets\
    \ of* places *and* transitions *respectively, and F* ⊆ (*P*×*T*)∪(*T* ×*P*) *is\
    \ the* flow relation *such that:*\n\n- *1. P is nonempty and F is acyclic.*\n\
    - *2. For every t* ∈ *T , there are p*,*q* ∈ *P such that pFt and tFq.*\n\n*Notation:\
    \ AN is the set of all acyclic nets.* ♦\n\nGraphically, places are represented\
    \ by circles, transitions by boxes, and arcs between the nodes (i.e., places and\
    \ transitions) represent the flow relation. If it is important to indicate explicitly\
    \ *acnet*, we denote *P*, *T*, *F* by *Pacnet*, *Tacnet*, *Facnet*, respectively.\n\
    \nIn addition to the acyclicity of *F*, it is required that each event has at\
    \ least one pre-condition (pre-place) and at least one post-condition (post-place).\
    \ Acyclic net can exhibit backward non-determinism (more than one arrow incoming\
    \ to a place) as well as forward non-determinism (more than one arrow outgoing\
    \ from a place).\n\nNotation 1 (direct precedence in acyclic net) *Let acnet be\
    \ an acyclic net. To indicate relationships between different nodes, for all x*\
    \ ∈ *Pacnet* ∪*Tacnet and X* ⊆ *Pacnet* ∪*Tacnet, we denote the* directly preceding\
    \ *and* directly following *nodes as follows:*\n\n$$\n\\begin{aligned}\\n\\bullet_X\
    \ &= \\text{pre}_{acnet}(x) \\triangleq \\{z \\mid zF_{acnet}x\\} & \\bullet_X\
    \ &= \\text{pre}_{acnet}(X) \\triangleq \\bigcup \\{\\bullet z \\mid z \\in X\\\
    } \\\\\nx^{\\bullet} &= \\text{post}_{acnet}(x) \\triangleq \\{z \\mid xF_{acnet}z\\\
    } & X^{\\bullet} &= \\text{post}_{acnet}(X) \\triangleq \\bigcup \\{z^{\\bullet}\
    \ \\mid z \\in X\\}.\\n\\end{aligned}\n$$\n\n*Moreover, the* initial *and* final\
    \ *places are respectively given by:*\n\n$$\nP_{acnet}^{init} \\triangleq \\{\
    \ p \\in P \\mid \\mathbf{^{\\bullet}p} = \\varnothing \\} \\ \\ and \\ \\ P_{acnet}^{fin}\
    \ \\triangleq \\{ p \\in P \\mid p^{\\bullet} = \\varnothing \\} \\ .\n$$\n\n\
    <span id=\"page-4-1\"></span>Note that having the notations like • *x* in addition\
    \ to more explicit pre*acnet*(*x*) helps to keep some of the subsequent formulas\
    \ short.\n\nProposition 2. *Pacnet* = *P init acnet* ⊎post*acnet*(*Tacnet*) =\
    \ *P fin acnet* ⊎pre*acnet*(*Tacnet*)*, for every acyclic net acnet.*\n\n*Proof.*\
    \ It follows directly from the definitions. ⊓⊔\n\n*Example 2.* In Figure [1\\\
    (](#page-3-0)*a*), *acnet*<sup>1</sup> is an acyclic net such that • *<sup>p</sup>*<sup>5</sup>\
    \ <sup>=</sup> pre*acnet*<sup>1</sup> (*p*5) = {*c*,*d*} and *a* • <sup>=</sup>\
    \ post*acnet*<sup>1</sup> (*a*) = {*p*2, *p*3}. Moreover,*P init acnet*1 = {*p*1}\
    \ and *P fin acnet*<sup>1</sup> = {*p*4, *p*5}. ♦\n\n#### 3.1 Subnets of acyclic\
    \ nets\n\n<span id=\"page-4-2\"></span>It is often desirable to analyse substructures\
    \ of records represented by nets where only some of the events are included.\n\
    \nDefinition 4 (subnet of acyclic net). *A triple net* = (*P*,*T*,*F*) *is a*\
    \ subnet *of an acyclic net acnet if* ∅ 6= *P* ⊆ *Pacnet, T* ⊆ *Tacnet, F* = *Facnet*|(*P*×*T*)∪(*T*×*P*)\
    \ *, and, for every t* ∈ *T :*\n\n$$\n\\{p \\mid (p,t) \\in F\\} = \\text{pre}_{\\\
    text{acnet}}(t) \\text{ and } \\{p \\mid (t,p) \\in F\\} = \\text{post}_{\\text{acnet}}(t).\n\
    $$\n\n*Notation: net* ⊆ *acnet.* ♦\n\n<span id=\"page-4-0\"></span>Note that a\
    \ transition included in a subnet retains its pre-places and post-places; in other\
    \ words, it retains its local environment.\n\nProposition 3. *A subnet of an acyclic\
    \ net is also an acyclic net.*\n\n*Proof.* It follows directly from the definitions\
    \ and the fact that a subset of an acyclic relation is also an acyclic relation.\
    \ ⊓⊔\n\n<span id=\"page-4-3\"></span>The next notion captures not only a structural\
    \ inclusion between acyclic nets, but it is also intended to correspond to inclusion\
    \ of the behaviours they capture.\n\nDefinition 5 (co-initial subnet of acyclic\
    \ net). *An acyclic net acnet is a* co-initial subnet *of an acyclic net acnet*′\
    \ *if acnet* ⊆ *acnet*′ *and Pinit acnet* = *P init acnet*′ *. Notation: acnet*\
    \ ⊑ *acnet*′ *.* ♦\n\n<span id=\"page-4-4\"></span>Proposition 4. *Let acnet*\
    \ ⊑ *acnet*′ *be acyclic nets.*\n\n- *1. Pacnet* = *P init acnet*′ ⊎post*acnet*′\
    \ (*Tacnet*)*.*\n- *2. acnet* = *acnet*′ *iff Tacnet* = *Tacnet*′ *.*\n\n*Proof.*\
    \ (1) By Proposition [3,](#page-4-0) *acnet* is an acyclic net, and so, by Proposition\
    \ [2,](#page-4-1) we have *Pacnet* = *P init acnet* ⊎post*acnet*(*Tacnet*). Hence,\
    \ by Definitions [4](#page-4-2) and [5,](#page-4-3) *Pacnet* = *P init acnet*′\
    \ ⊎ post*acnet*′ (*Tacnet*).\n\n(2) The (=⇒) implication is obvious. To show the\
    \ (⇐=) implication, suppose that *Tacnet* = *Tacnet*′ . Then, by part (1) and\
    \ Proposition [2,](#page-4-1)\n\n$$\nP_{acnet} = P_{acnet'}^{init} \\oplus \\\
    text{post}_{acnet'} (T_{acnet}) = P_{acnet'}^{init} \\oplus \\text{post}_{acnet'}\
    \ (T_{acnet'}) = P_{acnet'}.\n$$\n\nMoreover, by Definition [4,](#page-4-2) *Facnet*\
    \ = *Facnet*′ . Hence *acnet* = *acnet*′ . ⊓⊔\n\n#### 3.2 Subclasses of acyclic\
    \ nets\n\nThe next definition introduces acyclic nets which will represent individual\
    \ causal histories.\n\nDefinition 6 (occurrence net). *An* occurrence net *is\
    \ an acyclic net such that* | • *p*| ≤ 1 *and* |*p* • | ≤ 1*, for every place\
    \ p. Notation: ON is the set of all occurrence nets.* ♦\n\nOccurrence nets exhibit\
    \ both backward determinism and forward determinism. We also consider acyclic\
    \ nets where only the forward non-determinism is allowed.\n\nDefinition 7 (backward\
    \ deterministic acyclic net). *A* backward deterministic acyclic net *is an acyclic\
    \ net such that* | • *p*| ≤ 1*, for every place p. Notation: BDAN is he set of\
    \ all backward deterministic acyclic nets.* ♦\n\nIn the literature, backward deterministic\
    \ acyclic nets are sometimes called *nondeterministic occurrence nets* or even\
    \ *occurrence nets* (in which case occurrence nets as defined above are called\
    \ *deterministic occurrence nets*).\n\n*Example 3.* In Figure [1,](#page-3-0)\
    \ *bdanet*<sup>1</sup> is a backward deterministic acyclic net, while *ocnet*<sup>1</sup>\
    \ and *ocnet*<sup>2</sup> are both occurrence nets. ♦\n\n<span id=\"page-5-0\"\
    ></span>Proposition 5. *ON* ⊂ *BDAN* ⊂ *AN.*\n\n*Proof.* The inclusions *ON* ⊆\
    \ *BDAN* ⊆ *AN* follow directly from the definitions. Moreover, in Figure [1,](#page-3-0)\
    \ *acnet*<sup>1</sup> ∈ *AN*\\*BDAN* and *bdanet*<sup>1</sup> ∈ *BDAN*\\ *ON*.\
    \ ⊓⊔\n\n# 4 Step sequence semantics of acyclic nets\n\nWe now introduce notions\
    \ related to the behaviour of acyclic nets. The intuition behind them is as follows:\n\
    \n#### marking\n\nA global state of a possible execution history of the system\
    \ modelled by a net.\n\n### initial and final markings\n\nThere is always a single\
    \ initial global state. In general, there is more than one final global state,\
    \ which corresponds to the fact that a single net may capture alternative execution\
    \ histories.\n\n### step\n\nA set of events which might have occurred simultaneously\
    \ and effected a move from one global state to another.\n\n### enabled step\n\n\
    A step which can be executed at a global state thanks to all its input places\
    \ being present/marked.\n\n#### mixed step sequence\n\nAn alternating sequence\
    \ of global states and executed steps transforming one global state into another.\n\
    \n*d*\n\n![](_page_6_Figure_1.jpeg)\n\n<span id=\"page-6-0\"></span>![](_page_6_Figure_2.jpeg)\n\
    \n(*iv*)\n\n#### reachable marking\n\n(*iii*)\n\nA global state which can be obtained\
    \ by executing a sequence of steps starting from the initial marking.\n\nscenario\n\
    \nAn occurrence net providing a representation of a system history.\n\n*d*\n\n\
    #### well-formed acyclic net\n\nAn acyclic net where each execution history from\
    \ the initial state has an unambiguous interpretation in terms of causality and\
    \ concurrency.\n\n<span id=\"page-6-2\"></span>Definition 8 (step and marking\
    \ of acyclic net). *Let acnet be an acyclic net.*\n\n- *1.* steps(*acnet*) , {*U*\
    \ ∈ P(*Tacnet*) \\ {∅} | ∀*t* 6= *u* ∈ *U* : • *t* ∩ •*u* = ∅} *are the* steps*.*\n\
    - *2.* markings(*acnet*) , P(*Pacnet*) *are the* markings*.*\n- *3. Minit acnet*\
    \ , *P init acnet is the* initial *marking.* ♦\n\nGraphically, markings are indicated\
    \ by black tokens placed inside the corresponding circles.\n\nNote that in a step\
    \ no two transitions can share a pre-place.\n\n*Example 4.* For the acyclic nets\
    \ *acnet*<sup>1</sup> and *bdanet*<sup>1</sup> depicted in Figure [1\\(](#page-3-0)*a*,*b*),\
    \ we have steps(*acnet*1) = steps(*bdanet*1) = {*U* ∈ P({*a*,*b*,*c*,*d*}) \\\
    \ {∅} | *c* ∈/ *U* ∨*d* ∈/ *U*} and *Minit acnet*<sup>1</sup> <sup>=</sup> *<sup>M</sup>init\
    \ bdanet*1 = {*p*1}. ♦\n\n<span id=\"page-6-1\"></span>Definition 9 (enabled and\
    \ executed step of acyclic net). *Let M be a marking of an acyclic net acnet.*\n\
    \n![](_page_7_Figure_1.jpeg)\n\n<span id=\"page-7-0\"></span>Fig. 3. Executing\
    \ mixed step sequence {*p*1}[{*a*}i{*p*2, *p*3}[{*b*, *c*}i {*p*4, *p*5} and showing\
    \ the consecutive snapshots (*i*) → (*ii*) → (*iii*).\n\n- *1.* enabled*acnet*(*M*)\
    \ , {*U* ∈ steps(*acnet*) | •*U* ⊆ *M*} *are the steps* enabled *at M.*\n- *2.\
    \ A step U* ∈ enabled*acnet*(*M*) *can be* executed *and yield M*′ , (*M* ∪*U*\
    \ • ) \\ •*U. Notation: M*[*U*i*acnet M*′ *.* ♦\n\nEnabling a step in a global\
    \ state amounts to having all its pre-places marked. The execution of such a step\
    \ adds tokens to all its post-places and then removes tokens from all its pre-places.\
    \ Note that in the standard Petri net semantics the execution of a step leads\
    \ to *M*′ = (*M* \\ •*U*)∪*U* • , which yields a different result unless •*U*\
    \ ∩*U* • = ∅. However, the latter always holds when the acyclic net is well-formed,\
    \ as defined later in this paper.\n\n<span id=\"page-7-1\"></span>Definition 10\
    \ (mixed step sequence and step sequence of acyclic net). *Let M*0,...,*M<sup>k</sup>\
    \ (k* ≥ 0*) be markings and U*1,...,*U<sup>k</sup> be steps of an acyclic net\
    \ acnet such that we have Mi*−1[*Ui*i*acnet M<sup>i</sup> , for every* 1 ≤ *i*\
    \ ≤ *k.*\n\n*1.* <sup>µ</sup> = *M*0*U*1*M*<sup>1</sup> ...*Mk*−1*UkM<sup>k</sup>\
    \ is a* mixed step sequence from *M*<sup>0</sup> to *M<sup>k</sup> . 2.* <sup>σ</sup>\
    \ = *U*<sup>1</sup> ...*U<sup>k</sup> is a* step sequence from *M*<sup>0</sup>\
    \ to *M<sup>k</sup> .*\n\n*The above two notions are denoted by M*0[µii*acnet\
    \ M<sup>k</sup> and M*0[σi*acnet M<sup>k</sup> , respectively. Moreover, M*0[σi*acnet\
    \ denotes that* <sup>σ</sup> *is a step sequence* enabled *M*0*, and M*0[i*acnet\
    \ M<sup>k</sup> denotes that M<sup>k</sup> is* reachable from *M*0*.* ♦\n\nIf\
    \ *k* = 0 then <sup>µ</sup> = *M*<sup>0</sup> and the corresponding step sequence\
    \ <sup>σ</sup> is the *empty* sequence denoted by λ.\n\nIn the last definition,\
    \ the starting point of an execution is an arbitrary marking. The next definition\
    \ introduces a number of behavioural notions, assuming in each case that the starting\
    \ point of system executions is the default initial marking.\n\n<span id=\"page-8-1\"\
    ></span>Definition 11 (behaviour of acyclic net). *The following sets capture\
    \ various behavioural notions related to step sequences and reachable markings\
    \ of an acyclic net acnet.*\n\n- *1.* sseq(*acnet*) , {<sup>σ</sup> | *Minit acnet*[σi*acnet\
    \ M*} step sequences*. 2.* mixsseq(*acnet*) , {<sup>µ</sup> | *Minit acnet*[µii*acnet\
    \ M*} mixed step sequences*. 3.* maxsseq(*acnet*) , {<sup>σ</sup> ∈ sseq(*acnet*)\
    \ | ¬∃*U* : <sup>σ</sup>*U* ∈ sseq(*acnet*)} maximal step sequences*.*\n- *4.*\
    \ maxmixsseq(*acnet*) , {<sup>µ</sup> ∈ mixsseq(*acnet*) | ¬∃*U*,*M* : <sup>µ</sup>*UM*\
    \ ∈ mixsseq(*acnet*)} maximal mixed step sequences*.*\n- *5.* reachable(*acnet*)\
    \ , {*M* | *Minit acnet*[i*acnet M*} reachable markings*.*\n- *6.* finreachable(*acnet*)\
    \ , {*M* | ∃<sup>σ</sup> ∈ maxsseq(*acnet*) : *Minit acnet*[σi*acnet M*}\n- final\
    \ reachable markings*. 7.* fseq(*acnet*) = {*U*<sup>1</sup> ...*U<sup>k</sup>*\
    \ ∈ sseq(*acnet*) | *k* ≥ 1 =⇒ |*U*1| = ··· = |*U<sup>k</sup>* | = 1} firing sequences*.*\n\
    \n♦\n\nWe can treat individual transitions as singleton steps; for instance, a\
    \ step sequence {*t*}{*u*}{*w*,*v*}{*z*} can be denoted by *tu*{*w*,*v*}*z*.\n\
    \n*Example 5.* The following hold for the acyclic net in Figure [1\\(](#page-3-0)*b*).\n\
    \n- 1. sseq(*bdanet*1) = {λ,*a*,*ab*,*ac*,*ad*,*abc*,*acb*,*abd*,*adb*,*a*{*b*,*c*},*a*{*b*,*d*}}.\n\
    - 2. mixsseq(*bdanet*1) = {{*p*1},{*p*1}*a*{*p*2, *p*3},{*p*1}*a*{*p*2, *p*3}{*b*,*c*}{*p*4,\
    \ *p*5},...}.\n- 3. maxsseq(*bdanet*1) = {*abc*,*acb*,*a*{*b*,*c*},*abd*,*adb*,*a*{*b*,*d*}}.\n\
    - 4. maxmixsseq(*bdanet*1) = {{*p*1}*a*{*p*2, *p*3}{*b*,*c*}{*p*4, *p*5},...}.\n\
    - 5. reachable(*bdanet*1) = {{*p*1},{*p*2, *p*3},{*p*2, *p*5},{*p*2, *p*6},{*p*4,\
    \ *p*3},...}.\n- 6. finreachable(*bdanet*1) = {{*p*4, *p*5},{*p*4, *p*6}}.\n-\
    \ 7. fseq(*bdanet*1) = {λ,*a*,*ab*,*ac*,*ad*,*abc*,*acb*,*abd*,*adb*}.\n\nMoreover,\
    \ Figures [2](#page-6-0) and [3](#page-7-0) show consecutive snapshots of acyclic\
    \ nets involved in mixed step sequences. ♦\n\nThe next result shows that it is\
    \ always possible to arbitrarily serialise an enabled step and, as a result, relate\
    \ the step sequence based semantics and the firing sequence based semantics.\n\
    \n<span id=\"page-8-0\"></span>Proposition 6. *Let acnet be an acyclic net and\
    \ U* = {*t*1,...,*tk*} *be a step enabled at a marking M.*\n\n*1. If U*′ *and\
    \ U*′′ *form a partition of U, then M*[*U* ′*U* ′′i*acnet . 2. M*[{*t*1}...{*tk*}i*acnet\
    \ .*\n\n*Proof.* (1) Clearly, *U* ′ is a step enabled at *M*. Let *M*[*U* ′ i*acnet\
    \ M*′ . We observe that *U* ′′ is enabled at *M*′ which follows from •*U* ∪ •*U*\
    \ ′′ ⊆ *M* (see Definition [9\\(](#page-6-1)1)), •*U* ′ ∩ •*U* ′′ = ∅ (see Definition\
    \ [8\\(](#page-6-2)1)), and Definition [9\\(](#page-6-1)2). Hence *M*[*U* ′*U*\
    \ ′′i*acnet* .\n\n(2) As for *k* = 1 there is nothing to show, suppose that *k*\
    \ > 1. Then *U* ′ = {*t*1} and *U* ′′ = {*t*2,...,*tk*} form a partition of *U*.\
    \ Hence, by part (1), *M*[{*t*1}{*t*2,...,*tk*}i*acnet* . By repeating the same\
    \ argument *k* −1 times, we obtain *M*[{*t*1}...{*tk*}i*acnet* . ⊓⊔\n\n#### 4.1\
    \ Behaviour of subnets of acyclic nets\n\n<span id=\"page-9-1\"></span>The structural\
    \ inclusion of acyclic nets sharing the initial marking implies inclusion of the\
    \ behaviours they generate.\n\nProposition 7. *Let acnet* ⊑ *acnet*′ *be acyclic\
    \ nets. Then f*(*acnet*) ⊆ *f*(*acnet*′ )*, for f* = mixsseq,sseq,reachable,fseq*.*\n\
    \n*Proof.* It suffices to show that mixsseq(*acnet*) ⊆ mixsseq(*acnet*′ ).\n\n\
    Let <sup>µ</sup> = *M*0*U*1*M*<sup>1</sup> ...*Mk*−1*UkM<sup>k</sup>* ∈ mixsseq(*acnet*).\
    \ Then <sup>µ</sup> ∈ mixsseq(*acnet*′ ) which follows from *Minit acnet* = *M*<sup>0</sup>\
    \ = *Minit acnet*′ (see Definition [5\\)](#page-4-3) and, for every 0 ≤ *i* <\
    \ *k*, we have *Mi* [*Ui*+1i*acnet*′ *Mi*+<sup>1</sup> which follows from *M<sup>i</sup>*\
    \ [*Ui*+1i*acnet Mi*+<sup>1</sup> and Definition [4.](#page-4-2) ⊓⊔\n\n<span id=\"\
    page-9-0\"></span>Due to being both backward-deterministic and forward-deterministic,\
    \ occurrence nets exhibit additional useful behavioural properties.\n\nProposition\
    \ 8. *Let* <sup>σ</sup> = *U*<sup>1</sup> ...*U<sup>k</sup> (k* ≥ 0*) be a sequence\
    \ of nonempty sets of transitions of an occurrence net ocnet, and M be a reachable\
    \ marking of ocnet. Moreover, let T* = S σ*.*\n\n*1.* <sup>σ</sup> ∈ sseq(*ocnet*)\
    \ *iff for every* 1 ≤ *i* ≤ *k, U<sup>i</sup>* ∩(*U*<sup>1</sup> ∪ ···∪*Ui*−1)\
    \ = ∅ *and*\n\n$$\n\\bullet(\\bullet U_i)\\subseteq U_1\\cup\\cdots\\cup U_{i-1}\\\
    \ ,\n$$\n\n*where U*<sup>1</sup> ∪ ··· ∪*Ui*−<sup>1</sup> = ∅ *for i* = 1*.*\n\
    \n- *2.* <sup>σ</sup> ∈ sseq(*ocnet*) *implies Minit ocnet*[σi*ocnet*(*Minit ocnet*\
    \ ∪*T* • ) \\ •*T .*\n- *3. Tocnet* = S { S ξ | ξ ∈ sseq(*ocnet*)}*.*\n- *4. M*[*U*i*ocnet\
    \ M*′ *implies U*′ ∈ enabled*ocnet*(*M*′ )*, for every U*′ ∈ enabled*ocnet*(*M*)\
    \ *such that U* ∩*U* ′ = ∅*.*\n- *5.* maxsseq(*ocnet*) = {ξ ∈ sseq(*ocnet*) |\
    \ S ξ = *Tocnet*}*.*\n- *6.* finreachable(*ocnet*) = {*P fin ocnet*}*.*\n- *7.\
    \ If t* ∈ enabled*ocnet*(*M*)*, then t* ∈ enabled*ocnet*(*M*′ ) *and Minit ocnet*[i*ocnet\
    \ M*′ [i*ocnet M, where M*′ = (*P init ocnet* ∪*V* • ) \\ •*V for V* = {*u* ∈\
    \ *Tocnet* | *uF*+*t*}*.*\n\n*Proof.* If follows from the standard properties\
    \ of occurrence nets. ⊓⊔\n\nThat is, an occurrence net is deterministic in the\
    \ sense that each transition has a fixed set of direct or indirect predecessors\
    \ which have to occur first before the transition is executed (see Proposition\
    \ [8\\(](#page-9-0)1,7)), and once it is enabled no other transition can disable\
    \ it (see Proposition [8\\(](#page-9-0)4)). Moreover, all the transitions can\
    \ be executed (see Proposition [8\\(](#page-9-0)3)), the order in which transitions\
    \ are executed does not influence the resulting marking (see Proposition [8\\\
    (](#page-9-0)2)), the maximal step sequences are those which use all the transitions,\
    \ and there is exactly one final marking (see Proposition [8\\(](#page-9-0)6)).\n\
    \n# 5 Causality in acyclic nets\n\nThere is a straightforward way of introducing\
    \ causality in acyclic nets by looking at their *step sequences*. The idea can\
    \ be explained as follows.\n\nLet *t* and *u* be two transitions of an acyclic\
    \ net *acnet*. Then *u* is a *cause* of *t* if, for every step sequence <sup>σ</sup>*U*\
    \ ∈ sseq(*acnet*) such that *t* ∈ *U*, it is the case that *u* occurs in <sup>σ</sup>.\n\
    \nOne can check that if *u* is a cause of *t* in the above sense, then *uF*<sup>+</sup>\
    \ *acnett*. In other words, if *u* is a cause of *t* then there must be a direct\
    \ path from *u* to *t* in the graph of *acnet*. The converse, however, does not\
    \ hold. For instance, Figure [4\\(](#page-10-0)*a*) depicts an acyclic net in\
    \ which there is a directed path from *a* to *c*, but there is also a step sequence\
    \ {*b*}{*c*} in which *c* is not preceded by an occurrence of *a*.\n\nHowever,\
    \ when *acnet* is a backward deterministic acyclic net, then *uF*<sup>+</sup>\
    \ *acnett* implies that *u* is a cause of *t*. This is often referred to as backward\
    \ determinism. Forward determinism is an additional property enjoyed by occurrence\
    \ nets. It means, for example, that an enabled transition cannot be disabled by\
    \ executing another transition. Also, after executing an arbitrary step sequence,\
    \ it is possible to continue the execution until all the transitions have been\
    \ executed.\n\nA conclusion of the above short discussion is that causality can\
    \ be investigated by using purely graph theoretic concepts (in this case, directed\
    \ paths in the graphs of acyclic nets).\n\n![](_page_10_Figure_5.jpeg)\n\n<span\
    \ id=\"page-10-0\"></span>Fig. 4. An acyclic net (*a*) and its two maximal scenarios\
    \ (*b*, *c*), with their initial markings.\n\n# 6 Well-formed acyclic nets\n\n\
    A fundamental consistency criterion applied to acyclic nets is well-formedness.\
    \ Its essence is to ensure an unambiguous representation of causality in behaviours\
    \ they represent. The definition of a well-formed acyclic net is derived from\
    \ the notion of a well-formed step sequence.\n\n<span id=\"page-10-1\"></span>Definition\
    \ 12 (well-formed step sequence of acyclic net). *A step sequence U*<sup>1</sup>\
    \ ...*U<sup>k</sup> of an acyclic net is* well-formed *if the following hold:*\n\
    \n\\n- 1. \n$$\nt^{\\bullet} \\cap u^{\\bullet} = \\emptyset\n$$\n, for every\
    \  $1 \\leq i \\leq k$  and all  $t \\neq u \\in U_i$ .\n\\n- 2.  $U_i^{\\bullet}\
    \ \\cap U_j^{\\bullet} = \\emptyset$ , for all  $1 \\leq i < j \\leq k$ .\n\\\
    n\n\nIn a well-formed step sequence of an acyclic net, no place receives a token\
    \ more than once. It then follows, eg.g., that in such a step sequence no place\
    \ is a pre-place of an executed step more than once, the order of execution of\
    \ transitions does not influence the resulting marking, and each step sequence\
    \ can be sequentialised to a firing sequence.\n\n<span id=\"page-11-0\"></span>Proposition\
    \ 9. *Let* <sup>σ</sup> = *U*<sup>1</sup> ...*U<sup>k</sup> be a well-formed step\
    \ sequence of an acyclic net acnet, and Minit acnet* = *M*0*U*1*M*<sup>1</sup>\
    \ ...*Mk*−1*UkM<sup>k</sup> be the corresponding mixed step sequence. Moreover,\
    \ let T* = S <sup>σ</sup> *and U<sup>i</sup>* = {*t* 1 *i* ,...,*t mi i* }*, for\
    \ every* 1 ≤ *i* ≤ *k.*\n\n*1.* •*U<sup>i</sup>* ∩*U* • *<sup>i</sup>* <sup>=</sup>\
    \ <sup>∅</sup>*, for every* <sup>1</sup> <sup>≤</sup> *<sup>i</sup>* <sup>≤</sup>\
    \ *k. 2.* •*U<sup>i</sup>* ∩ •*U<sup>j</sup>* = ∅ *and U<sup>i</sup>* ∩*U<sup>j</sup>*\
    \ = ∅*, for all* 1 ≤ *i* < *j* ≤ *k. 3. M<sup>k</sup>* = *Minit acnet* ∪*T* •\
    \ \\ •*T . 4. t*<sup>1</sup> 1 ...*t m*1 1 ...*t* 1 *k* ...*t mk <sup>k</sup>*\
    \ ∈ fseq(*acnet*)*. 5.* enabled*acnet*(*Mi*)∩enabled*acnet*(*Mm*) ⊆ enabled*acnet*(*Mj*)*,\
    \ for all* 1 ≤ *i* < *j* < *m* ≤ *n.*\n\n*Proof.* (1) Suppose that *p* ∈ •*U<sup>i</sup>*\
    \ ∩*U* • *i* . Then *p* ∈/ *Minit acnet*, and so there is *j* < *i* such that\
    \ *p* ∈ *U* • *j* , contradicting Definition [12\\(](#page-10-1)2).\n\n(2) *U<sup>i</sup>*\
    \ ∩*U<sup>j</sup>* = ∅ follows from Definition [12\\(](#page-10-1)2).\n\nSuppose\
    \ that *p* ∈ •*U<sup>i</sup>* ∩ •*U<sup>j</sup>* . Then, by Definition [9\\(](#page-6-1)2)\
    \ and part (1), *p* ∈ *Mi*−<sup>1</sup> ∩*Mj*−<sup>1</sup> and *p* ∈/ *M<sup>i</sup>*\
    \ . Thus *p* ∈/ *M*<sup>0</sup> = *Minit acnet* and there are *t* ∈ *U*1∪···∪*Ui*−<sup>1</sup>\
    \ and *u* ∈*Ui*+1∪···∪*Uj*−<sup>1</sup> such that *p* ∈ *t* • ∩*u* • , contradicting\
    \ Definition [12\\(](#page-10-1)2).\n\n(3) If follows from the fact that, for\
    \ a given place *p*, at most one transition *t j i* belongs to • *p* (see Definition\
    \ [12\\)](#page-10-1), at most one transition *t j i* belongs to *p* • (see part\
    \ (2) and Definition [8\\(](#page-6-2)1)), and if *p* ∈/ *Minit acnet* then there\
    \ must exist *t m <sup>l</sup>* ∈ • *p* with *l* < *j*.\n\n(4) Let <sup>τ</sup>*<sup>i</sup>*\
    \ = *t* 1 *i* ...*t mi i* , for every 1 ≤ *i* ≤ *k*. It suffices to observe that\
    \ if 0 ≤ *i* < *k* and <sup>τ</sup><sup>0</sup> ...<sup>τ</sup>*<sup>i</sup>*\
    \ ∈ fseq(*acnet*), where <sup>τ</sup><sup>0</sup> = <sup>λ</sup>, then <sup>τ</sup><sup>0</sup>\
    \ ... <sup>τ</sup>*i*+<sup>1</sup> ∈ fseq(*acnet*). Indeed, since <sup>σ</sup>\
    \ is well-formed, so is <sup>τ</sup><sup>0</sup> ... <sup>τ</sup>*<sup>i</sup>*\
    \ . Hence, by part (3), *M*0[<sup>τ</sup><sup>0</sup> ...<sup>τ</sup>*i*i*acnet\
    \ M<sup>i</sup>* . Thus, by Proposition [6\\(](#page-8-0)2), <sup>τ</sup><sup>0</sup>\
    \ ... <sup>τ</sup>*i*+<sup>1</sup> ∈ fseq(*acnet*).\n\n(5) Suppose that *t* ∈\
    \ enabled*acnet*(*Mi*)∩enabled*acnet*(*Mm*) \\ enabled*acnet*(*Mj*). Then there\
    \ is *p* ∈ • *t* such that *p* ∈ *M<sup>i</sup>* ∩ *M<sup>m</sup>* \\ *M<sup>j</sup>*\
    \ . Hence *p* ∈/ *P init acnet*, *p* ∈ (*U*<sup>1</sup> ∪ ··· ∪*Ui*) • and *p*\
    \ ∈ (*Uj*+<sup>1</sup> ∪ ··· ∪*Um*) • , contradicting Definition [12\\(](#page-10-1)2).\
    \ ⊓⊔\n\nTo develop a sound treatment of causality in an acyclic net, it is required\
    \ that all step sequences are well-formed. Moreover, it is required that a well-formed\
    \ acyclic net has no redundant transitions which can never be executed from the\
    \ initial marking.\n\nDefinition 13 (well-formed acyclic net). *An acyclic net\
    \ is* well-formed *if each transition occurs in at least one step sequence and\
    \ all the step sequences are well-formed. Notation: WFAN is the set of all well-formed\
    \ acyclic nets.* ♦\n\n*Example 6.* The acyclic nets in Figure [1\\(](#page-3-0)*a*,*b*)\
    \ are well-formed, but the acyclic net in Figure [4\\(](#page-10-0)*a*) is not.\n\
    \nThe reason why the acyclic net in Figure [4\\(](#page-10-0)*a*) is not well-formed\
    \ can be explained in terms of *OR-causality* which it exhibits. Intuitively,\
    \ one can execute *a* and *b* first, and then *c*. It is, however, impossible\
    \ to state in such a case whether *c* was caused by *a* or by *b* (we know, by\
    \ looking at Figure [4\\(](#page-10-0)*b*,*c*) that only one of *a* and *b* is\
    \ needed to cause *c*). In the context of an investigation, one would presumably\
    \ attempt to 'repair' the acyclic net in Figure [4\\(](#page-10-0)*a*) to resolve\
    \ the problem. Two possible outcomes of such an attempt are depicted in Figure\
    \ [5.](#page-13-0) ♦\n\nChecking that an acyclic net is well-formed can be done\
    \ by looking just at its firing sequences.\n\nProposition 10. *An acyclic net\
    \ acnet is well-formed iff each transition occurs in at least one firing sequence\
    \ and all the firing sequences are well-formed.*\n\n*Proof.* (=⇒) Since fseq(*acnet*)\
    \ ⊆ sseq(*acnet*), it suffices to show that each transition occurs in at least\
    \ one firing sequence. This, however, follows from *acnet* being wellformed and\
    \ and Proposition [9\\(](#page-11-0)4).\n\n(⇐=) Since fseq(*acnet*) ⊆ sseq(*acnet*),\
    \ it suffices to show that each step sequence is well-formed. If this is not the\
    \ case, then there is *U*<sup>1</sup> ...*U<sup>k</sup>* ∈ sseq(*acnet*) (*k*\
    \ ≥ 1) such that *U*<sup>1</sup> ...*Uk*−<sup>1</sup> is well-formed and *U*<sup>1</sup>\
    \ ...*U<sup>k</sup>* is not well-formed. Let *U<sup>i</sup>* = {*t* 1 *i* ,...,*t\
    \ mi i* }, for every 1 ≤ *i* ≤ *k*. Then, by Propositions [6\\(](#page-8-0)2)\
    \ and [9\\(](#page-11-0)3,4), <sup>τ</sup> = *t* 1 1 ...*t m*1 1 ...*t* 1 *k*\
    \ ...*t mk <sup>k</sup>* ∈ fseq(*acnet*). Hence, since <sup>τ</sup> is well-formed,\
    \ <sup>σ</sup> is also well-formed, yielding a contradiction. ⊓⊔\n\n<span id=\"\
    page-12-0\"></span>Well-formedness is ensured when backward non-determinism is\
    \ not allowed.\n\nProposition 11. *All step sequences of a backward deterministic\
    \ acyclic net are wellformed.*\n\n*Proof.* If the result does not hold then, by\
    \ Propositions [6\\(](#page-8-0)2) and [9\\(](#page-11-0)4), there is *t*<sup>1</sup>\
    \ ...*t<sup>k</sup> t* ∈ fseq(*acnet*) (*k* ≥ 1) such that *t*<sup>1</sup> ...*t<sup>k</sup>*\
    \ is well-formed and *t*<sup>1</sup> ...*t<sup>k</sup> t* is not well-formed.\
    \ Hence there is *i* ≤ *k* such that *t* • *<sup>i</sup>* ∩*t* • 6= ∅. Take any\
    \ *p* ∈ • *t*. Since *acnet* is backward deterministic, *t<sup>i</sup>* = *t*.\
    \ Hence *i* < *k* and there is *i* < *j* ≤ *k* such that *p* ∈ *t* • *j* . As\
    \ *p* ∈/ *Minit acnet* and *p* ∈ • *ti* , there is 1 ≤ *m* < *i* such that *p*\
    \ ∈ *t* • *<sup>m</sup>*. This, however, contradicts*t*<sup>1</sup> ...*t<sup>k</sup>*\
    \ being well-formed. ⊓⊔\n\n<span id=\"page-12-1\"></span>All occurrence nets are\
    \ well-formed.\n\n#### Proposition 12. *ON* ⊂ *WFAN* ⊂ *AN.*\n\n*Proof.* Clearly,\
    \ *WFAN* ⊆ *AN*. Moreover, *ON* ⊆ *WFAN* follows from *ON* ⊆ *BDAN* and Propositions\
    \ [8\\(](#page-9-0)3) and [11.](#page-12-0) Moreover, *bdanet*<sup>1</sup> ∈ *WFAN*\\\
    *ON* in Figure [4,](#page-10-0) and the acyclic net in Figure [4\\(](#page-10-0)*a*)\
    \ is not well-formed. ⊓⊔\n\n# 7 Scenarios in acyclic nets\n\nAn acyclic net may\
    \ exhibit both forward and backward nondeterminism and, as a result, represent\
    \ several different possible execution histories. The role of the next notion\
    \ is to identify structurally all such execution histories which can then be inspected,\
    \ simulated, and analysed.\n\n![](_page_13_Figure_1.jpeg)\n\n<span id=\"page-13-0\"\
    ></span>Fig. 5. Well-formed acyclic nets.\n\nScenarios of an acyclic net are acyclic\
    \ subnets which start at the same initial marking and are both backward and forward\
    \ deterministic. As a result, each scenario represents a distinct execution history\
    \ with clearly determined causal relationships. Scenarios are much more abstract\
    \ than (mixed) step sequences, as one scenario will in general correspond to many\
    \ step sequences.\n\n<span id=\"page-13-1\"></span>Definition 14 (scenario and\
    \ maximal scenario of acyclic net). *A* scenario *of an acyclic net acnet is an\
    \ occurrence net ocnet such that ocnet* ⊑ *acnet. Moreover, ocnet is* maximal\
    \ *if there is no scenario ocnet*′ 6= *ocnet such that ocnet* ⊑ *ocnet*′ ⊑ *acnet.\
    \ Notation:* scenarios(*acnet*) *and* maxscenarios(*acnet*) *are respectively\
    \ the sets of all scenarios and maximal scenarios of acnet.* ♦\n\nIntuitively,\
    \ scenarios represent possible executions (concurrent histories), which are both\
    \ deterministic and consistent with the dependencies implied by the flow relation.\
    \ Maximal scenarios are complete in the sense that they cannot be extended.\n\n\
    Although scenarios represent behaviours of acyclic nets in a different way than\
    \ (mixed) step sequences, there is a close relationship between these two approaches.\
    \ In particular, scenarios do not generate executions which are not generated\
    \ by the original acyclic net.\n\n<span id=\"page-13-4\"></span>Proposition 13.\
    \ S *f*(scenarios(*acnet*)) ⊆ *f*(*acnet*)*, for every acyclic net acnet and f*\
    \ = mixsseq,sseq,reachable,fseq*.*\n\n*Proof.* It follows from Definition [14](#page-13-1)\
    \ and Proposition [7.](#page-9-1) ⊓⊔\n\nThe inclusions in the above result cannot\
    \ be reversed.\n\n*Example 7.* Consider the (non-well-formed) acyclic net *acnet*\
    \ in Figure [4\\(](#page-10-0)*a*) which generates step sequence <sup>σ</sup>\
    \ = {*a*,*b*}{*c*}. It has exactly two maximal scenarios shown in Figure [4\\\
    (](#page-10-0)*b*,*c*), neither of which can execute <sup>σ</sup>. ♦\n\n<span\
    \ id=\"page-13-2\"></span>Definition [14](#page-13-1) introduced scenarios in\
    \ a structural way. An alternative is to do this behaviourally, through well-formed\
    \ step sequences.\n\nDefinition 15 (scenario of well-formed step sequence of acyclic\
    \ net). *The* scenario induced *by a well-formed step sequence* <sup>σ</sup> *of\
    \ an acyclic net acnet is the triple:*\n\n$$\n\\text{scenario}_{\\text{acnet}}(\\\
    sigma) \\triangleq (P, T, F_{\\text{acnet}}|_{(P \\times T) \\cup (T \\times P)})\n\
    $$\n\n<span id=\"page-13-3\"></span>*where T* = S <sup>σ</sup> *and P* = *P init\
    \ acnet* ∪post*acnet*(*T*)*.* ♦ *Example 8.* In Figure [1,](#page-3-0) *ocnet*<sup>1</sup>\
    \ = scenario*acnet*<sup>1</sup> ({*a*}{*b*,*c*}). Note that *ocnet*<sup>1</sup>\
    \ can also be derived as scenario*acnet*<sup>1</sup> ({*a*}{*b*}{*c*}) or scenario*acnet*<sup>1</sup>\
    \ ({*a*}{*c*}{*b*}). ♦\n\n<span id=\"page-14-0\"></span>Scenarios induced by well-formed\
    \ step sequences are also scenarios in the structural sense. Moreover, maximal\
    \ step sequences induce maximal scenarios.\n\nProposition 14. *Let* <sup>σ</sup>\
    \ *be a well-formed step sequence of an acyclic net acnet.*\n\n*1.* scenario*acnet*(σ)\
    \ ∈ scenarios(*acnet*) *and* <sup>σ</sup> ∈ maxsseq(scenario*acnet*(σ))*.*\n\n\
    *2.* <sup>σ</sup> ∈ maxsseq(*acnet*) *implies* scenario*acnet*(σ) ∈ maxscenarios(*acnet*)*.*\n\
    \n*Proof.* Let <sup>σ</sup>, *P*, and *T* be as in Definition [15.](#page-13-2)\
    \ Moreover, let *ocnet* = scenario*acnet*(σ), and <sup>µ</sup> = *M*0*U*1*M*<sup>1</sup>\
    \ ...*Mk*−1*UkM<sup>k</sup>* ∈ mixsseq(*acnet*) be such that <sup>σ</sup> = *U*<sup>1</sup>\
    \ ...*U<sup>k</sup>* .\n\n(1) By Definitions [9,](#page-6-1) [11,](#page-8-1)\
    \ [10,](#page-7-1) and [15,](#page-13-2) we have *P* = *M*<sup>0</sup> ∪ ··· ∪\
    \ *M<sup>k</sup>* and pre*acnet*(*T*) ⊆ *P*. Hence, by Definitions [4](#page-4-2)\
    \ and [5,](#page-4-3) *ocnet* is an acyclic net such that *ocnet* ⊑ *acnet*. Moreover,\
    \ by Definitions [12](#page-10-1) and [8\\(](#page-6-2)1), and Proposition [9\\\
    (](#page-11-0)2), *ocnet* is an occurrence net. Hence *ocnet* ∈ scenarios(*acnet*).\
    \ It then follows from Proposition [8\\(](#page-6-2)1), Definition [10\\(](#page-7-1)1),\
    \ and *ocnet* ∈ *ON* that Proposition [8\\(](#page-9-0)1,5) can be applied to\
    \ conclude that <sup>σ</sup> ∈ maxsseq(scenario*acnet*(σ)).\n\n(2) By part (1),\
    \ *ocnet*∈ scenarios(*acnet*). If *ocnet* ∈/ maxscenarios(*acnet*), then there\
    \ is *ocnet*′ ∈ *ON* such that *ocnet* ⊑ *ocnet*′ ⊑ *acnet* and *T* = *Tocnet*\
    \ ⊂ *Tocnet*′ . By Proposition [7,](#page-9-1) <sup>σ</sup> ∈ sseq(*ocnet*′ ).\
    \ Hence, by Proposition [8\\(](#page-9-0)5), <sup>σ</sup> ∈/ maxsseq(*ocnet*′\
    \ ). This produces a contradiction with <sup>σ</sup> ∈ maxsseq(*acnet*) and Proposition\
    \ [7.](#page-9-1) ⊓⊔\n\nFollowing an observation made in Example [8,](#page-13-3)\
    \ two well-formed step sequences induce the same scenario iff they involve exactly\
    \ the same transitions.\n\nProposition 15. *Let* <sup>σ</sup> *and* <sup>σ</sup>\
    \ ′ *be well-formed step sequences of an acyclic net acnet. Then* scenario*acnet*(σ)\
    \ = scenario*acnet*(<sup>σ</sup> ′ ) *iff* S <sup>σ</sup> = S σ ′ *.*\n\n*Proof.*\
    \ It follows directly from Definition [15.](#page-13-2) ⊓⊔\n\n<span id=\"page-14-1\"\
    ></span>Well-formedness of acyclic nets can be re-phrased in terms of their scenarios.\n\
    \nProposition 16. *The following statements are equivalent, for every acyclic\
    \ net.*\n\n- *1. The acyclic net is well-formed.*\n- *2. Each transition occurs\
    \ in at least one scenario, and each step sequence is a step sequence of at least\
    \ one scenario.*\n- *3. Each transition occurs in at least one scenario, and each\
    \ firing sequence is a firing sequence of at least one scenario.*\n\n*Proof.*\
    \ Let *acnet* be an acyclic net.\n\n(1) =⇒ (2) Suppose that <sup>σ</sup> ∈ sseq(*acnet*).\
    \ Since <sup>σ</sup> is well-formed, by Proposition [14\\(](#page-14-0)1), scenario*acnet*(σ)\
    \ ∈ scenarios(*acnet*) and <sup>σ</sup> ∈ sseq(scenario*acnet*(σ)).\n\nSuppose\
    \ now that *t* ∈ *Tacnet*. Since *acnet* is well-formed, there is <sup>σ</sup>\
    \ ∈ sseq(*acnet*) in which *t* occurs. Moreover, as just shown, <sup>σ</sup> ∈\
    \ sseq(scenario*acnet*(σ)).\n\n(2) =⇒ (3) Obvious.\n\n(3) =⇒ (1) Suppose that\
    \ not all step sequences of *acnet* are well-formed. Then there is <sup>σ</sup>*U*\
    \ ∈ sseq(*acnet*) such that <sup>σ</sup> is well-formed and <sup>σ</sup>*U* is\
    \ not. Hence, by Propositions [6\\(](#page-8-0)2) and [9\\(](#page-11-0)3,4),\
    \ there is a firing sequence ττ ′ ∈ fseq(*acnet*) such that S <sup>σ</sup> = S\
    \ τ and *U* = S τ ′ . Clearly, ττ ′ is not well-formed. On the other hand, there\
    \ is *ocnet* ∈ scenarios(*acnet*) such that ττ ′ ∈ sseq(*ocnet*), contradicting\
    \ Proposition [11.](#page-12-0) ⊓⊔\n\nEach (maximal) step sequence of a well-formed\
    \ acyclic net induces a (maximal) scenario and, conversely, each (maximal) scenario\
    \ is induced by a (maximal) step sequence. Therefore, the structurally and behaviourally\
    \ defined scenarios coincide.\n\n<span id=\"page-15-0\"></span>Proposition 17.\
    \ *Let acnet be a well-formed acyclic net.*\n\n- *1.* scenarios(*acnet*) = scenario*acnet*(sseq(*acnet*))*.*\n\
    - *2.* maxscenarios(*acnet*) = scenario*acnet*(maxsseq(*acnet*))*.*\n\n*Proof.*\
    \ The (⊇) inclusions follow from Proposition [14.](#page-14-0)\n\n(1) To show\
    \ the (⊆) inclusion, suppose that *ocnet* ∈ scenarios(*acnet*), and take any <sup>σ</sup>\
    \ ∈ maxsseq(*ocnet*). By Propositions [8\\(](#page-9-0)5) and [13,](#page-13-4)\
    \ S <sup>σ</sup> = *Tocnet* and <sup>σ</sup> ∈ sseq(*acnet*). Hence scenario*ocnet*(σ)\
    \ = *ocnet* and scenario*ocnet*(σ) = scenario*acnet*(σ). As a result, *ocnet*\
    \ ∈ scenario*acnet*(sseq(*acnet*)).\n\n(2) To show the (⊆) inclusion, suppose\
    \ that *ocnet* ∈ maxscenarios(*acnet*), and take any <sup>σ</sup> ∈ maxsseq(*ocnet*)\
    \ ⊆ sseq(*acnet*). By the proof of part (1), we have *ocnet* ∈ scenario*acnet*(sseq(*acnet*)).\
    \ Suppose that <sup>σ</sup> ∈/ maxsseq(*acnet*). Then there is *t* ∈ *Tacnet*\
    \ such that <sup>σ</sup>*t* ∈ sseq(*acnet*). We then observe that *ocnet* ⊑ scenario*acnet*(σ*t*)\
    \ and *ocnet* 6= scenario*acnet*(σ*t*), contradicting the maximality of *ocnet*.\
    \ ⊓⊔\n\n<span id=\"page-15-1\"></span>Behaviours of acyclic nets correspond to\
    \ the joint behaviour of their scenarios.\n\nProposition 18. *Let acnet be a well-formed\
    \ acyclic net.*\n\n*1. f*(*acnet*) = S *f*(scenarios(*acnet*))*, for f* = sseq,mixsseq,reachable,fseq*.\
    \ 2. f*(*acnet*) = S *f*(maxscenarios(*acnet*))*,*\n\n*for f* = maxsseq,maxmixsseq,finreachable*.*\n\
    \n*Proof.* (1) The (⊇) inclusions follow from Proposition [13.](#page-13-4) The\
    \ (⊆) inclusion for *f* = sseq follows from the second part of Proposition [14\\\
    (](#page-14-0)1). The remaining inclusions follow from this and Definition [5.](#page-4-3)\n\
    \n(2) It suffices to consider *f* = maxsseq.\n\nTo show the (⊆) inclusions, suppose\
    \ that <sup>σ</sup> ∈ maxsseq(*acnet*). Then, by Proposition [14\\(](#page-14-0)2),\
    \ scenario*acnet*(σ) ∈ maxscenarios(*acnet*). Moreover, by Proposition [14\\(](#page-14-0)1),\
    \ <sup>σ</sup> ∈ maxsseq(scenario*acnet*(σ)).\n\nTo show the (⊇) inclusions, suppose\
    \ that *ocnet* ∈ maxscenarios(*acnet*) and <sup>σ</sup> ∈ maxsseq(*ocnet*) ⊆ sseq(*acnet*).\
    \ If <sup>σ</sup> ∈/ maxsseq(*acnet*), then there is *t* ∈ *Tacnet* such that\
    \ <sup>σ</sup> ∈ sseq(*acnet*). Hence *ocnet* ⊑ scenario*acnet*(σ*t*) and *ocnet*\
    \ 6= scenario*acnet*(σ*t*), contradicting the maximality of *ocnet*. ⊓⊔\n\nIn\
    \ well-formed acyclic nets, all parts of their structure are relevant as they\
    \ are covered by the scenarios in a graph-theoretic way.\n\nProposition 19. *Xacnet*\
    \ = S {*Xocnet* | *ocnet* ∈ scenarios(*acnet*)}*, for every well-formed acyclic\
    \ net acnet and X* = *P*,*T*,*F.*\n\n*Proof.* The (⊇) inclusions follow from Definitions\
    \ [4](#page-4-2) and [5.](#page-4-3) The (⊆) inclusions follow from Proposition\
    \ [16](#page-14-1) and Definitions [4](#page-4-2) and [5.](#page-4-3) ⊓⊔\n\nProposition\
    \ 20. scenarios(*acnet*) ⊆ scenarios(*acnet*′ )*, for all acyclic nets acnet and\
    \ acnet*′ *satisfying acnet* ⊑ *acnet*′ *.*\n\n*Proof.* It follows directly from\
    \ the definitions. ⊓⊔\n\nThe next result shows that an occurrence net has exactly\
    \ one maximal scenario (itself), which can be interpreted as saying it is a precise\
    \ representation of a single execution history.\n\nProposition 21. maxscenarios(*ocnet*)\
    \ = {*ocnet*}*, for every occurrence ocnet.*\n\n*Proof.* By Definition [14,](#page-13-1)\
    \ *ocnet* ∈ maxscenarios(*ocnet*).\n\nSuppose that *ocnet*′ ∈ maxscenarios(*ocnet*)\\\
    \ {*ocnet*}. Then, *ocnet*′ ⊑ *ocnet* ⊑ *ocnet* and *ocnet*′ 6= *ocnet*. This,\
    \ however, yields a contradiction with Definition [14.](#page-13-1) ⊓⊔\n\n# 8\
    \ Communication structured acyclic nets\n\nCommunication Structured Acyclic Nets\
    \ (CSA-nets) are a generalisation of Communication Structured Occurrence Nets\
    \ (CSO-nets) introduced and discussed in [\\[20](#page-34-1)[,22](#page-34-3)[,16\\\
    ]](#page-34-0). In [\\[23](#page-34-4)[,14\\]](#page-34-5), CSO-nets were used\
    \ to to deal with cybercrime and major accidents, and [\\[17\\]](#page-34-6) demonstrated\
    \ CSO-nets can be used as a framework for visualising and analysing behaviour\
    \ of complex evolving systems. Other works on CSO-nets were related to provenance\
    \ [\\[19\\]](#page-34-7) and timed behaviours [\\[13\\]](#page-34-8). This section\
    \ introduces nets which generalise CSO-nets by being based on acyclic nets rather\
    \ than occurrence nets.\n\nThe following are intuitive explanations of the main\
    \ concepts:\n\n#### communication structured acyclic net (CSA-net)\n\nA 'database'\
    \ consisting of a number of disjoint acyclic nets which communicate through special\
    \ buffer/channel places. CSA-nets can exhibit backward and forward non-determinism.\
    \ They can contain cycles restricted to the buffer places.\n\n#### buffer place\n\
    \nA place allowing synchronous or asynchronous transfer of tokens. A cycle involving\
    \ only buffer places 'implements' synchronous communication.\n\n#### communication\
    \ structured occurrence net (CSO-net)\n\nA CSA-net providing full and unambiguous\
    \ record of all causal dependencies between the events involved in a single 'causal\
    \ history'.\n\n#### backward deterministic CSA-net (BDCSA-net)\n\nA CSA-net net\
    \ providing unambiguous record of causal dependencies.\n\n#### scenario\n\nA CSO-net\
    \ providing a representation of a system history.\n\n#### well-formed CSA-net\n\
    \nA CSA-net where each execution history from the initial state has an unambiguous\
    \ interpretation in terms of causality and concurrency.\n\n#### projected mixed\
    \ step sequence\n\nA mixed step sequence restricted to the nodes of a component\
    \ acyclic net.\n\n#### projected step sequence\n\nA step sequence restricted to\
    \ the transitions of a component acyclic.\n\n![](_page_17_Figure_7.jpeg)\n\n<span\
    \ id=\"page-17-0\"></span>Fig. 6. Communication structured acyclic nets.\n\n<span\
    \ id=\"page-17-1\"></span>Definition 16 (CSA-net). *A* communication structured\
    \ acyclic net (or CSA-net) *is a tuple csan* = (*acnet*1,...,*acnetn*,*Q*,*W*)\
    \ *(n* ≥ 1*) such that:*\n\n*1. acnet*1,...,*acnet<sup>n</sup> are well-formed\
    \ acyclic nets with disjoint sets of nodes (i.e., places and transitions). We\
    \ also denote:*\n\n| ,<br>Pcsan<br>Pacnet1<br>∪ ··· ∪Pacnetn | ,<br>Qcsan<br>Q\
    \          |                   |\n|-----------------------------------------|--------------------------|-------------------|\n\
    | ,<br>Tcsan<br>Tacnet1<br>∪ ··· ∪Tacnetn | ,<br>Wcsan<br>W          |       \
    \            |\n| ,<br>Fcsan<br>Facnet1<br>∪ ··· ∪Facnetn | ,<br>netcsan,i<br>acneti\
    \ | (for 1 ≤ i ≤ n) . |\n\n- *2. Q is a finite set of* buffer places *disjoint\
    \ from Pcsan* ∪*Tcsan.*\n- *3. W* ⊆ (*Q*×*Tcsan*)∪(*Tcsan* ×*Q*) *is a set of\
    \ arcs.*\n- *4. For every buffer place q:*\n\t- *(a) There is at least one transition\
    \ t such that tW q.*\n\t- *(b) If tW q and qWu then transitions t and u belong\
    \ to different component acyclic nets.*\n\n*Notation: CSAN is the set of all*\
    \ CSA*-nets.* ♦\n\nThat is, in addition to requiring the disjointness of the component\
    \ acyclic nets and the buffer places, it is required that buffer places pass tokens\
    \ between different acyclic nets. Hence, if *n* = 1, then *csan* = (*acnet*1,∅,∅)\
    \ and so the CSA-net *csan* can be identified with its only component acyclic\
    \ net *acnet*<sup>1</sup> (not only structurally, but also syntactically, as will\
    \ be shown later).\n\nNotation 2 (direct precedence in CSA-net) *Let csan* = (*acnet*1,...,*acnetn*,*Q*,*W*)\
    \ *be a* CSA*-net, x* ∈ *Pcsan* ∪*Tcsan* ∪*Qcsan, and X* ⊆ *Pcsan* ∪*Tcsan* ∪*Qcsan.\
    \ Then*\n\n$$\n\\begin{array}{ll}\\n\\operatorname{pre}_{csan}(x) \\triangleq\
    \ \\{ y \\mid yF_{csan}x \\lor yW_{csan}x \\} & \\operatorname{pre}_{csan}(X)\
    \ \\triangleq \\bigcup \\{ \\operatorname{pre}_{csan}(z) \\mid z \\in X \\} \\\
    \\\n\\operatorname{post}_{csan}(x) \\triangleq \\{ y \\mid xF_{csan}y \\lor xW_{csan}y\
    \ \\} & \\operatorname{post}_{csan}(X) \\triangleq \\bigcup \\{ \\operatorname{post}_{csan}(z)\
    \ \\mid z \\in X \\} \\n\\end{array}\n$$\n\n*denote direct predecessors and successors\
    \ of x and X, respectively. Moreover,*\n\n$$\nP_{csan}^{init} \\triangleq P_{acnet_1}^{init}\
    \ \\cup \\cdots \\cup P_{acnet_n}^{init} \\text{ and } P_{csan}^{fin} \\triangleq\
    \ P_{acnet_1}^{fin} \\cup \\cdots \\cup P_{acnet_n}^{fin} \\cup (Q_{csan} \\setminus\
    \ pre_{csan}(T_{csan}))\n$$\n\n*are the* initial *and* final *places of csan,\
    \ respectively.* ♦\n\nNote that no buffer place is an initial place.\n\nProposition\
    \ 22. *Pcsan*⊎*Qcsan* = *P init csan*⊎post*csan* (*Tcsan*) = *P fin csan*⊎pre*csan*\
    \ (*Tcsan*)*, for every* CSA*-net csan.*\n\n*Proof.* It follows directly from\
    \ the definitions. ⊓⊔\n\n*Example 9.* Figure [6\\(](#page-17-0)*a*) depicts a\
    \ CSA-net *csan*<sup>1</sup> such that pre*csan*<sup>1</sup> (*p*4) = {*b*,*d*}\
    \ and post*csan*<sup>1</sup> (*e*) = {*q*1, *p*6}. Moreover, *P init csan*1 =\
    \ {*p*1, *p*5}. ♦\n\n#### 8.1 Subnets in CSA-nets\n\n<span id=\"page-19-0\"></span>The\
    \ next notion captures a structural inclusion between CSA-nets.\n\nDefinition\
    \ 17 (subnet of CSA-net). *Let csan* = (*acnet*1,...,*acnetn*,*Q*,*W*) *and csan*′\
    \ = (*acnet*′ 1 ,...,*acnet*′ *n* ,*Q* ′ ,*W*′ ) *be* CSA*-nets. Then csan is*\
    \ included *in csan*′ *if the following hold:*\n\n*1. acnet<sup>i</sup>* ⊆ *acnet*′\
    \ *i , for every* 1 ≤ *i* ≤ *n. 2. Q* ⊆ *Q* ′ *. 3.* pre*csan* (*t*) = pre*csan*′\
    \ (*t*) *and* post*csan* (*t*) = post*csan*′ (*t*)*, for every t* ∈ *Tcsan.*\n\
    \n*Notation: csan* ⊆ *csan*′ *.* ♦\n\nNote that a transition included in a subnet\
    \ retains its pre-places and post-places, including the buffer places; in other\
    \ words, it retains its local environment.\n\nProposition 23. *Let csan* ⊆ *csan*′\
    \ *be* CSA*-nets. Then Qcsan* ⊆ *Qcsan*′ *and Wcsan* ⊆ *Wcsan*′ *.*\n\n*Proof.*\
    \ It suffices to show *Qcsan* ⊆ *Qcsan*′ . Let *q* ∈ *Qcsan*. By Definition [16\\\
    (](#page-17-1)4a), there is *t* ∈ *Tcsan* such that *tWcsanq*. Hence, by Definition\
    \ [17\\(](#page-19-0)2), *tWcsan*′*q*. Thus *q* ∈ *Qcsan*′ . ⊓⊔\n\n<span id=\"\
    page-19-1\"></span>The next notion captures not only a structural inclusion between\
    \ CSA-nets, but it is also intended to correspond to inclusion of the behaviours\
    \ they capture.\n\nDefinition 18 (co-initial subnet of CSA-net). *A* CSA*-net\
    \ csan is a* co-initial subnet *of a* CSA*-net csan*′ *if csan* ⊆ *csan*′ *and\
    \ Pinit csan* = *P init csan*′ *. Notation: csan* ⊑ *csan*′ *.* ♦\n\nNote that\
    \ if *csan* and *csan*′ are as in Definition [17,](#page-19-0) then *csan* ⊑ *csan*′\
    \ iff *acnet<sup>i</sup>* ⊑ *acnet*′ *i* , for every 1 ≤ *i* ≤ *n*.\n\nProposition\
    \ 24. *Let csan* ⊑ *csan*′ *be* CSA*-nets.*\n\n*1. Pcsan* = *P init csan*′ ⊎post*csan*′\
    \ (*Tcsan*)*. 2. csan* = *csan*′ *iff Tcsan* = *Tcsan*′ *.*\n\n*Proof.* (1) It\
    \ follows from Proposition [4\\(](#page-4-4)1) as well as Definitions [16\\(](#page-17-1)4a)\
    \ and [17\\(](#page-19-0)2).\n\n(2) The (=⇒) implication is obvious, and the (⇐=)\
    \ implication follows from Proposition [4\\(](#page-4-4)2) as well as Definitions\
    \ [16\\(](#page-17-1)4a), [17\\(](#page-19-0)2), and [18.](#page-19-1) ⊓⊔\n\n\
    #### 8.2 Subclasses of CSA-nets\n\nThe next definition introduces CSA-nets representing\
    \ individual causal histories.\n\nDefinition 19 (CSO-net). *A* communication structured\
    \ occurrence net (or CSO-net) *is cson* ∈ *CSAN such that:*\n\n- *1. The component\
    \ acyclic nets belong to ON.*\n- *2.* |pre*cson* (*q*)| = 1 *and* |post*cson*\
    \ (*q*)| ≤ 1*, for every q* ∈ *Qcson.*\n- *3. No place in Pcson belongs to a cycle\
    \ in the graph of Fcson* ∪*Wcson.*\n\nThat is, only cycles involving buffer places\
    \ are allowed. CSO-nets exhibit backward determinism and forward determinism.\n\
    \n*Example 10.* Figure [6\\(](#page-17-0)*b*,*c*,*d*) depict CSO-nets. ♦\n\nWe\
    \ also consider CSA-nets with only forward nondeterminism.\n\nDefinition 20 (BDCSA-net).\
    \ *A* backward deterministic communication structured acyclic net (or BDCSA-net)\
    \ *is bdcsan* ∈ *CSAN such that:*\n\n- *1. The component acyclic nets belong to\
    \ BDAN.*\n- *2.* |pre*bdcsan* (*q*)| = 1*, for every q* ∈ *Qbdcsan.*\n\n*Notation:\
    \ BDCSAN is the set of all* BDCSA*-nets.* ♦\n\nBDCSA-nets exhibit backward determinism,\
    \ but forward determinism is not required.\n\nProposition 25. *CSON* ⊂ *BDCSAN*\
    \ ⊂ *CSAN.*\n\n*Proof.* It follows directly from Proposition [5](#page-5-0) and\
    \ the definitions. ⊓⊔\n\n# 9 Step sequence semantics of CSA-nets\n\nThe intuition\
    \ behind the step sequence semantics of CSA-net is similar as in the case of acyclic\
    \ nets, and so the terminology used will also be similar.\n\nDefinition 21 (step\
    \ and marking of CSA-net). *Let csan be a* CSA*-net.*\n\n- *1.* steps(*csan*)\
    \ , {*U* ∈ P(*Tcsan*) \\ {∅} | ∀*t* 6= *u* ∈ *U* : pre*csan* (*t*)∩pre*csan* (*u*)\
    \ = ∅} *are the* steps*.*\n- *2.* markings(*csan*) , P(*Pcsan* ∪*Qcsan*) *are\
    \ the* markings*.*\n- *3. Minit csan* , *P init csan is the* initial *marking.*\
    \ ♦\n\n*Example 11.* steps(*csan*1) = {*U* ∈ P({*a*,*b*,*c*,*d*,*e*, *f* }) \\\
    \ {∅} | *a* ∈/ *U* ∨*c* ∈/ *U*}, for the CSA-net in Figure [6\\(](#page-17-0)*a*).\
    \ ♦\n\n<span id=\"page-20-0\"></span>Definition 22 (enabled and executed step\
    \ of CSA-net). *Let M be a marking of a* CSA*net csan.*\n\n- *1.* enabled*csan*(*M*)\
    \ , {*U* ∈ steps(*csan*) | pre*csan* (*U*) ⊆ *M* ∪(post*csan* (*U*)∩*Q*)} *are\
    \ the steps* enabled *at M.*\n- *2. A step U* ∈ enabled*csan*(*M*) *can be* executed\
    \ *yielding a new marking*\n\n$$\nM' \\triangleq (M \\cup \\text{post}_{csan}(U))\
    \ \\setminus \\text{pre}_{csan}(U) .\n$$\n\n*Notation: M*[*U*i*csan M*′\n\n*.*\
    \ ♦\n\nEnabling a step in a CSA-net amounts to having all input places belonging\
    \ to the component acyclic nets present/marked in a global state. Moreover, if\
    \ an input buffer place is not present, then it must be an output place of a transition\
    \ belonging to the step. Such a mechanism allows one to sychronise transitions\
    \ coming from different component acyclic nets. The same mechanism of simultaneous\
    \ output to and input from a place is not available within the component acyclic\
    \ nets, and so in Definition [22\\(](#page-20-0)1) we have pre*csan* (*U*) ⊆ *M*\
    \ ∪(post*csan* (*U*)∩*Q*) rather than pre*csan* (*U*) ⊆ *M* ∪post*csan* (*U*).\n\
    \nDefinition 23 (mixed step sequence and step sequence of CSA-net). *Let M*0,...,*M<sup>k</sup>\
    \ (k* ≥ 0*) be markings and U*1,...,*U<sup>k</sup> be steps of a* CSA*-net csan\
    \ such that Mi*−1[*Ui*i*csan M<sup>i</sup> , for every* 1 ≤ *i* ≤ *k.*\n\n*1.*\
    \ <sup>µ</sup> = *M*0*U*1*M*<sup>1</sup> ...*Mk*−1*UkM<sup>k</sup> is a* mixed\
    \ step sequence from *M*<sup>0</sup> to *M<sup>k</sup> . 2.* <sup>σ</sup> = *U*<sup>1</sup>\
    \ ...*U<sup>k</sup> is a* step sequence from *M*<sup>0</sup> to *M<sup>k</sup>\
    \ .*\n\n*The above two notions are denoted by M*0[µii*csan M<sup>k</sup> and M*0[σi*csan\
    \ M<sup>k</sup> , respectively. Moreover, M*0[σi*csan denotes that* <sup>σ</sup>\
    \ *is a step sequence* enabled *M*0*, and M*0[i*csan M<sup>k</sup> denotes that\
    \ M<sup>k</sup> is* reachable from *M*0*.* ♦\n\nIf *k* = 0 then <sup>µ</sup> =\
    \ *M*<sup>0</sup> and the corresponding step sequence <sup>σ</sup> is the *empty*\
    \ sequence denoted by λ.\n\nIn the last definition, the starting point is an arbitrary\
    \ marking. The next definition assumes that the starting point is the default\
    \ initial marking.\n\nDefinition 24 (behaviour of CSA-net). *The following sets\
    \ capture various behavioural notions related to step sequences and reachable\
    \ markings of a* CSA*-net csan.*\n\n*1.* sseq(*csan*) , {<sup>σ</sup> | *Minit\
    \ csan*[σi*csan M*} step sequences*. 2.* mixsseq(*csan*) , {<sup>µ</sup> | *Minit\
    \ csan*[µii*csan M*} mixed step sequences*. 3.* maxsseq(*csan*) , {<sup>σ</sup>\
    \ ∈ sseq(*csan*) | ¬∃*U* : <sup>σ</sup>*U* ∈ sseq(*csan*)} maximal step sequences*.\
    \ 4.* maxmixsseq(*csan*) , {<sup>µ</sup> ∈ mixsseq(*csan*) | ¬∃*U*,*M* : <sup>µ</sup>*UM*\
    \ ∈ mixsseq(*csan*)} maximal mixed step sequences*. 5.* reachable(*csan*) , {*M*\
    \ | *Minit csan*[i*csan M*} reachable markings*. 6.* finreachable(*csan*) , {*M*\
    \ | ∃<sup>σ</sup> ∈ maxsseq(*csan*) : *Minit csan*[σi*csan M*} final reachable\
    \ markings*.* ♦\n\nNote that if a CSA-net has only one component acyclic net,\
    \ *acnet*, then *f*(*csan*) = *f*(*acnet*), for *f* = sseq,mixsseq,maxsseq,reachable,finreachable.\n\
    \n*Example 12.* The following hold for the CSA-net in Figure [6\\(](#page-17-0)*a*).\n\
    \n- 1. sseq(*csan*1) = {λ,{*a*,*e*},{*a*,*e*}*b*,···}.\n- 2. mixsseq(*csan*1)\
    \ = {{*p*1, *p*5},{*p*1, *p*5}{*a*,*e*}{*p*2, *p*6,*q*1},...}.\n- 3. maxsseq(*csan*1)\
    \ = {*ab*,*aeb*,*abe*,{*a*,*e*}*b*,*a*{*b*,*e*},*ec*{*d*, *f* },{*e*,*c*}{*d*,\
    \ *f* }}.\n- 4. maxmixsseq(*csan*1) = {{*p*1, *p*5}{*a*,*e*}{*p*2, *p*6,*q*1}*b*{*p*4,\
    \ *p*6,*q*1},...}.\n- 5. reachable(*csan*1) = {{*p*1, *p*5},{*p*2, *p*6,*q*1},...}.\n\
    \n6. \n$$\n\\text{finreachable}(csan_1) = \\{ \\{p_4, p_6, q_1\\}, \\{p_4, p_7\\\
    } \\}.\n$$\n\nProjecting step sequences and mixed step sequences of a CSA-net\
    \ onto a component acyclic net yields sequences, mixed step sequences and scenarios\
    \ of the latter.\n\nDefinition 25 (projected (mixed) step sequence of CSA-net).\
    \ *Let* <sup>σ</sup> *be a step sequence of a* CSA*-net csan,* µ *be a mixed step\
    \ sequence of csan, and acnet be one of the component acyclic nets of csan.*\n\
    \n- *1.* proj*acnet*(σ) = <sup>σ</sup> ↾*Tacnet .*\n- *2.* proj*acnet*(µ) *is\
    \ obtained from* <sup>µ</sup> ↾*Pacnet*∪*Tacnet by deleting consecutive duplicate\
    \ sets.*\n\n*Example 13.* For *csan*<sup>1</sup> in Figure [6\\(](#page-17-0)*a*),\
    \ proj*acnet*<sup>1</sup> ({*a*,*e*}*b*) = *ab*, proj*acnet*<sup>2</sup> ({*a*,*e*}*b*)\
    \ = *e*, and proj*acnet*<sup>2</sup> ({*p*1, *p*5}*a*{*p*2, *p*5}*b*{*p*4, *p*5})\
    \ = {*p*5}. ♦\n\nProjected step sequences are step sequences of the component\
    \ acyclic nets.\n\nProposition 26. *For every component acyclic net acnet of a*\
    \ CSA*-net csan:*\n\nproj*acnet*(sseq(*csan*)) ⊆ sseq(*acnet*) proj*acnet*(mixsseq(*csan*))\
    \ ⊆ mixsseq(*acnet*) .\n\n*Proof.* It suffices to demonstrate that we have proj*acnet*(µ)\
    \ ∈ mixsseq(*acnet*), where <sup>µ</sup> = *M*0*U*1*M*<sup>1</sup> ...*Mk*−1*UkM<sup>k</sup>*\
    \ . We observe that in such a case the enabledness and calculations of the results\
    \ of step executions in *csan* and *acnet* are fully consistent except that if\
    \ *Ui*∩*Tacnet* = ∅, then *Mi*−1∩*Pacnet* = *M<sup>i</sup>* ∩*Pacnet* (since *acnet*\
    \ is well-formed, this is the only situation that *Mi*−<sup>1</sup> ∩*Pacnet*\
    \ = *M<sup>i</sup>* ∩*Pacnet*). But then the construction of proj*acnet*(µ) then\
    \ deletes multiple neighbouring copies of the same marking. ⊓⊔\n\n#### 9.1 Behaviour\
    \ of subnets of CSA-nets\n\n<span id=\"page-22-0\"></span>The structural inclusion\
    \ of CSA-nets implies the inclusion of the behaviours they generate.\n\nProposition\
    \ 27. *Let csan* ⊑ *csan*′ *be* CSA*-nets. Then we have f*(*csan*) ⊆ *f*(*csan*′\
    \ )*, for f* = mixsseq,sseq,reachable*.*\n\n*Proof.* Similar to the proof of Proposition\
    \ [7.](#page-9-1) ⊓⊔\n\nDue to being both backward-deterministic and forward-deterministic,\
    \ CSO-nets enjoy several useful behavioural properties similar to those satisfied\
    \ by occurrence nets. For example, each CSO-net has a step sequence which uses\
    \ all the transitions. This and other properties are gathered together in the\
    \ next result.\n\nProposition 28. *Let* <sup>σ</sup> =*U*<sup>1</sup> ...*U<sup>k</sup>\
    \ (k* ≥ 0*) be a sequence of nonempty sets of transitions of* CSO*-net cson. Moreover,\
    \ let M be a reachable marking of cson and T* = S σ*.*\n\n*1.* <sup>σ</sup> ∈\
    \ sseq(*cson*) *iff for every* 1 ≤ *i* ≤ *k, U<sup>i</sup>* ∩(*U*<sup>1</sup>\
    \ ∪ ··· ∪*Ui*−1) = ∅ *and*\n\npre*cson* (pre*cson* (*Ui*)) ⊆ *U*<sup>1</sup> ∪\
    \ ···∪*Ui*−<sup>1</sup> ∪*U<sup>i</sup>* ∩pre*cson* (*Q* ∩pre*cson* (*Ui*)) .\n\
    \n- 24 Structured Acyclic Nets\n- *2.* <sup>σ</sup> ∈ sseq(*cson*) *implies Minit\
    \ cson*[σi*cson* (*Minit cson* ∪post*cson* (*T*)) \\ pre*cson* (*T*)*.*\n- *3.\
    \ Tcson* = S { S ξ | ξ ∈ sseq(*cson*)}*.*\n- *4. M*[*U*i*cson M*′ *implies U*′\
    \ ∈ enabled*cson*(*M*′ )*, for every U*′ ∈ enabled*cson*(*M*) *such that U* ∩*U*\
    \ ′ = ∅*.*\n- *5.* maxsseq(*cson*) = {ξ ∈ sseq(*cson*) | S ξ = *Tcson*}*.*\n-\
    \ *6.* finreachable(*cson*) = {*P fin cson*}*.*\n\n*Proof.* If follows from the\
    \ results proved in [\\[16\\]](#page-34-0). ⊓⊔\n\nIn general, the step sequences\
    \ of CSO-nets cannot be fully sequentialised (or linearised) due to the presence\
    \ of synchronous communications which cannot be split. The next definition captures\
    \ this notion formally.\n\nDefinition 26 (syn-cycle). *A* synchronous cycle (or\
    \ syn-cycle) *of a* CSO*-net cson is a maximal set of transitions S* ⊆ *Tcson\
    \ such that, for all t* 6= *u* ∈ *S,* (*t*,*u*) ∈ *W*<sup>+</sup> *cson. The set\
    \ of all sync-cycles is denoted by* syncycles(*cson*)*.* ♦\n\nThe idea behind\
    \ the notion of syn-cycles is to identify 'tight' synchronous communications which\
    \ cannot be executed in stages.\n\n*Example 14.* For *cson*<sup>3</sup> in Figure\
    \ [6\\(](#page-17-0)*d*), syncycles(*cson*3) = {{*c*},{*e*},{*d*, *f* }}. ♦\n\n\
    Syn-cycles are nonempty and form a partition of the set of transitions.\n\nProposition\
    \ 29. syncycles(*cson*) *forms a partition of Tcson, for every* CSO*-net cson.*\n\
    \n*Proof.* If follows from results proved in [\\[16\\]](#page-34-0). ⊓⊔\n\n<span\
    \ id=\"page-23-0\"></span>Each step occurring in a step sequence of a CSO-net\
    \ can be partitioned into syncycles (in a unique way).\n\nProposition 30. *Let\
    \ M be a reachable marking of a* CSO*-net cson and M*[*U*i*cson M*′ *. Then there\
    \ are syn-cycles S*1,...,*S<sup>k</sup>* ∈ syncycles(*cson*) *such that U* = *S*<sup>1</sup>\
    \ ⊎ ··· ⊎*S<sup>k</sup> and M*[*S*<sup>1</sup> ...*Sk*i*cson M*′ *.*\n\n*Proof.*\
    \ If follows from results proved in [\\[16\\]](#page-34-0). ⊓⊔\n\nThis means,\
    \ for example, that all reachable markings of a CSO-net can be generated by executing\
    \ syn-cycles rather than all potential steps.\n\n# 10 Well-formed CSA-nets\n\n\
    A basic consistency criterion applied to CSA-nets is well-formedness. Its essence\
    \ is to ensure a clean representation of causality in behaviours they represent.\
    \ The definition of a well-formed CSA-net is derived from the notion of a well-formed\
    \ step sequence.\n\nDefinition 27 (well-formed step sequence of CSA-net). *A step\
    \ sequence U*<sup>1</sup> ...*U<sup>k</sup> of a* CSA*-net csan is* well-formed\
    \ *if the following hold:*\n\n*1.* post*csan* (*t*)∩post*csan* (*u*) = ∅*, for\
    \ every* 1 ≤ *i* ≤ *k and all t* 6= *u* ∈ *U<sup>i</sup> . 2.* post*csan* (*Ui*)∩post*csan*\
    \ (*Uj*) = ∅*, for all* 1 ≤ *i* < *j* ≤ *k.* ♦\n\nIntuitively, in a well-formed\
    \ step sequence of a CSA-net, no place is filled by a token more than once.\n\n\
    It then follows, e.g., that in a well-formed step sequence, no token is consumed\
    \ more than once, no transition is executed more than once, the order of execution\
    \ of transitions does not influence the resulting marking.\n\nProposition 31.\
    \ *Let* <sup>σ</sup> = *U*<sup>1</sup> ...*U<sup>k</sup> be a well-formed step\
    \ sequence of a* CSA*-net csan, and Minit csan* = *M*0*U*1*M*<sup>1</sup> ...*Mk*−1*UkM<sup>k</sup>\
    \ be the corresponding mixed step sequence. Moreover, let T* = S σ*.*\n\n*1.*\
    \ pre*csan* (*Ui*)∩post*csan* (*Ui*) ⊆ *Qcsan, for every* 1 ≤ *i* ≤ *k. 2.* pre*csan*\
    \ (*Ui*)∩pre*csan* (*Uj*) = ∅ *and U<sup>i</sup>* ∩*U<sup>j</sup>* = ∅*, for all*\
    \ 1 ≤ *i* < *j* ≤ *k. 3. M<sup>k</sup>* = *Minit csan* ∪post*csan* (*T*) \\ pre*csan*\
    \ (*T*)*.*\n\n*Proof.* Similar to the proof of Proposition [9\\(](#page-11-0)1,2,3).\
    \ ⊓⊔\n\nWell-formedness is ensured when backward non-determinism is not allowed.\n\
    \nTo develop a sound treatment of causality in CSA-nets, it is required that all\
    \ step sequences are well-formed. Moreover, it is required that a well-formed\
    \ acyclic nets has no redundant transitions which can never be executed from the\
    \ initial marking.\n\nDefinition 28 (well-formed CSA-net). *A* CSA*-net is* well-formed\
    \ *if each transition occurs in at least one step sequence and all step sequences\
    \ are well-formed. Notation: WFCSAN is the set of all well-formed* CSA*-nets.*\
    \ ♦\n\nIntuitively, the executions of syn-cycles in CSA-nets correspond to the\
    \ executions of individual transitions in acyclic nets.\n\nProposition 32. *All\
    \ step sequences of a* BDCSA*-net are well-formed.*\n\n| Proof. Similar to the\
    \ proof of Proposition 11 using Proposition 30. | ⊓⊔ |\n|---------------------------------------------------------------------|----|\n\
    |---------------------------------------------------------------------|----|\n\
    \nProposition 33. *CSON* ⊂ *BDCSAN* ⊂ *WFCSAN* ⊂ *CSAN.*\n\n*Proof.* If follows\
    \ from Proposition [12.](#page-12-1) ⊓⊔\n\n# 11 Scenarios in CSA-nets\n\nScenarios\
    \ of CSA-net start at the same initial marking and are both backward and forward\
    \ deterministic. As a result, they represent potential executions with clearly\
    \ determined causal relationships. They are also more abstract than (mixed) step\
    \ sequences, as one scenario will in general correspond to many step sequences.\n\
    \n<span id=\"page-24-0\"></span>Definition 29 (scenario and maximal scenario of\
    \ CSA-net). *A* scenario *of a* CSA*-net csan is a* CSO*-net cson such that cson*\
    \ ⊑ *csan. Moreover, cson is* maximal *if there is no scenario cson*′ 6= *cson\
    \ such that cson* ⊑ *cson*′ *.*\n\n*Notation:* scenarios(*csan*) *and* maxscenarios(*csan*)\
    \ *are respectively the sets of all scenarios and maximal scenarios of csan.*\
    \ ♦\n\nIntuitively, scenarios represent possible executions (concurrent histories)\
    \ consistent with the dependencies imposed by the flow relation. This, in particular,\
    \ means that all the transitions have been executed and places marked at some\
    \ point during an execution. Maximal scenarios are complete in the sense that\
    \ they cannot be extended any further.\n\nAlthough scenarios represent behaviours\
    \ of CSA-nets in a different way than step sequences, markings and related notions,\
    \ there is a close relationship between these two approaches. First, we can see\
    \ that scenarios do not generate step sequences nor markings which were not generated\
    \ by the original acyclic net.\n\nProposition 34. S *f*(scenarios(*csan*)) ⊆ *f*(*csan*)*,\
    \ for every well-formed* CSA*-net csan and f* = mixsseq,sseq,reachable*.*\n\n\
    *Proof.* If follows from Definition [29](#page-24-0) and Proposition [27.](#page-22-0)\
    \ ⊓⊔\n\nDefinition 30 (scenario of well-formed step sequence of CSA-net). *Let*\
    \ <sup>σ</sup> *be a wellformed step sequence of a* CSA*-net csan* = (*acnet*1,...,*acnetn*,*Qcsan*,*Wcsan*)*.\
    \ Moreover, let T* = S <sup>σ</sup> *and ocnet<sup>i</sup>* = scenario*acnet<sup>i</sup>*\
    \ (proj*Tacneti* (σ))*, for every* 1 ≤ *i* ≤ *n. Then*\n\n$$\n\\mathrm{scenario}_{csan}(\\\
    sigma) \\triangleq (ocnet_1, \\ldots,ocnet_n, \\mathrm{post}_{csan}(T) \\cap Q_{csan},\
    \ W_{csan}|_{(Q \\times T) \\cup (T \\times Q)})\n$$\n\n*is the* scenario *of\
    \ csan generated by* <sup>σ</sup>*.* ♦\n\nScenarios of well-formed step sequences\
    \ are scenarios in the original structural sense.\n\n#### Proposition 35. *Let*\
    \ <sup>σ</sup> *be a well-formed step sequence of a* CSA*-net csan.*\n\n- *1.*\
    \ scenario*csan*(σ) ∈ scenarios(*csan*) *and* <sup>σ</sup> ∈ maxsseq(scenario*csan*(σ))*.*\n\
    - *2.* <sup>σ</sup> ∈ maxsseq(*csan*) *implies* scenario*csan*(σ) ∈ maxscenarios(*csan*)*.*\n\
    \n*Proof.* Similar to the proof of Proposition [14.](#page-14-0) ⊓⊔\n\nTwo well-formed\
    \ step sequences generate the same scenario iff they execute exactly the same\
    \ transitions.\n\nProposition 36. *Let* <sup>σ</sup> *and* <sup>σ</sup> ′ *be\
    \ well-formed step sequences of a* CSA*-net csan. Then* scenario*csan*(σ) = scenario*csan*(<sup>σ</sup>\
    \ ′ ) *iff* S <sup>σ</sup> = S σ ′ *.*\n\n*Proof.* It follows directly from Definition\
    \ [15.](#page-13-2) ⊓⊔\n\nThe well-formedness of CSA-nets can also be expressed\
    \ in terms of scenarios.\n\nProposition 37. *The following statements are equivalent,\
    \ for every* CSA*-net.*\n\n- *1. The* CSA*-net is well-formed.*\n- *2. Each transition\
    \ occurs in at least one scenario, and each step sequence is a step sequence of\
    \ at least one scenario.*\n\n*Proof.* Similar to the proof of Proposition [16.](#page-14-1)\
    \ ⊓⊔\n\nEach (maximal) step sequence of a well-formed CSA-net generates a (maximal)\
    \ scenario and, conversely, each (maximal) scenario is generated by a (maximal)\
    \ step sequence.\n\nProposition 38. *Let csan be a well-formed* CSA*-net.*\n\n\
    *1.* scenarios(*csan*) = scenario*csan*(sseq(*csan*))*.*\n\n*2.* maxscenarios(*csan*)\
    \ = scenario*csan*(maxsseq(*csan*))*.*\n\n*Proof.* Similar to the proof of Proposition\
    \ [17.](#page-15-0) ⊓⊔\n\nThere is a close correspondence between scenarios and\
    \ step sequences of a wellformed CSA-net *csan*. In particular, the behaviour\
    \ of the CSA-net corresponds to the joint behaviour of its scenarios.\n\n<span\
    \ id=\"page-26-0\"></span>Proposition 39. *Let csan be a well-formed* CSA*-net.*\n\
    \n*1. f*(*csan*) = S *f*(scenarios(*csan*))*, for f* = sseq,mixsseq,reachable*.\
    \ 2. f*(*csan*) = S *f*(maxscenarios(*csan*))*, for f* = maxsseq,maxmixsseq,finreachable*.*\n\
    \n*Proof.* Similar to the proof of Proposition [18.](#page-15-1) ⊓⊔\n\n*Example\
    \ 15.* Consider the CSA-net *csan*<sup>1</sup> in Figure [6\\(](#page-17-0)*a*).\
    \ Then scenario*csan*<sup>1</sup> ({*a*,*e*}) = *cson*1, scenario*csan*<sup>1</sup>\
    \ (*eab*) = *cson*2, and scenario*csan*<sup>1</sup> ({*c*,*e*}{*d*, *f* }) = *cson*3.\
    \ ♦\n\nDefinition 31 (syn-cycle of CSA-net). *The* syn-cycles *of a well-formed*\
    \ CSA*-net csan are given by* syncycles(*csan*) = S {syncycles(*cson*) | *cson*\
    \ ∈ scenarios(*csan*)}*. Notation:* syncycles(*csan*) *is the set of all sync-cycles\
    \ of csan.* ♦\n\n*Example 16.* For *csan*<sup>1</sup> in Figure [6\\(](#page-17-0)*a*),\
    \ syncycles(*cson*3) = {{*a*},{*b*},{*c*},{*e*},{*d*, *f* }}. ♦\n\nEach step occurring\
    \ in a step sequence of a CSA-net can be partitioned into syncycles (in a unique\
    \ way).\n\nProposition 40. *Let M be a reachable marking of a well-formed* CSA*-net\
    \ csan and M*[*U*i*csan M*′ *. Then there are syn-cycles S*1,...,*S<sup>k</sup>*\
    \ ∈ syncycles(*csan*) *such that U* = *S*<sup>1</sup> ⊎ ··· ⊎*S<sup>k</sup> and\
    \ M*[*S*<sup>1</sup> ...*Sk*i*csan M*′ *.*\n\n*Proof.* If follows directly from\
    \ Propositions [30](#page-23-0) and [39.](#page-26-0) ⊓⊔\n\nThis means, for example,\
    \ that all reachable markings of a well-formed CSA-net can be generated by executing\
    \ syn-cycles rather than all the potential steps.\n\nThe next result can be interpreted\
    \ as stating that no part of a well-formed CSA-net is semantically irrelevant.\n\
    \nDefinition 32 (coverability and non-redundancy). *A well-formed* CSA*-net is*\
    \ covered by scenarios *if Xcsan* = S {*Xcson* | *cson* ∈ maxscenarios(*csan*)}*,\
    \ for X* = *P*,*T*,*F*,*Q*,*W. Moreover, csan has* non-redundant transitions *if\
    \ each transition of csan occurs in at least one step sequence.* ♦\n\nProposition\
    \ 41. *Let csan be a well-formed* CSA*-net.*\n\n- *1. csan is covered by scenarios\
    \ iff it has non-redundant transitions.*\n- *2.* CSO*-nets have non-redundant\
    \ transitions.*\n\nThe two ways of capturing the idea that there are no irrelevant\
    \ components in *csan* are equivalent, and CSO-nets have no redundant components.\n\
    \nThe next result shows that an occurrence net has exactly one maximal scenario\
    \ (itself), which can be interpreted as saying it is a precise representation\
    \ of a single execution history.\n\nProposition 42. maxscenarios(*cson*) = {*cson*}*,\
    \ for every* CSO*-net cson.*\n\n*Proof.* By Definitions [5\\(](#page-4-3)1,2)\
    \ and [29\\(](#page-24-0)1), we have *cson* ∈ scenarios(*cson*). Hence, by Definition\
    \ [29\\(](#page-24-0)2), *cson* ∈ maxscenarios(*cson*).\n\nSuppose now that *cson*′\
    \ ∈ maxscenarios(*ocnet*) \\ {*cson*}. Then, we have *cson*′ ⊑ *cson* and *cson*′\
    \ 6= *cson*. This yields a contradiction with Definition [29\\(](#page-24-0)2).\
    \ ⊓⊔\n\n# 12 Behavioural structured acyclic nets\n\nBehavioural Structured Acyclic\
    \ Nets (BSA-nets) extend the model of BSO-nets introduced and discussed in [\\\
    [16,](#page-34-0)[23,](#page-34-4)[22,](#page-34-3)[17,](#page-34-6)[5,](#page-33-0)[19\\\
    ]](#page-34-7). They can be seen as a way of capturing the evolution of CSA-nets,\
    \ by providing a mechanism to abstract parts of a complex activity by another\
    \ (simpler) system. The behaviour in this case is expressed at two levels, namely\
    \ the upper-level and lower-level. The former provides a simple view and hides\
    \ unimportant details of the behaviour, while the latter shows the full details\
    \ of behaviour during different evolution stages.\n\n<span id=\"page-27-0\"></span>Definition\
    \ 33 (BSA-net). *A* behavioural structured acyclic net (or BSA-net) *is a triple\
    \ bsan* , (*lcsan*,*hcsan*,β) *such that:*\n\n*lcsan* = (*lanet*1,...,*lanetn*,*lQ*,*lW*)\
    \ *and hcsan* = (*hanet*1,...,*hanetn*,*hQ*,*hW*)\n\n*are well-formed* CSA*-nets\
    \ (n* ≥ 1*) with disjoint sets of nodes, and*\n\n$$\n\\beta \\subseteq \\bigcup_{i=1}^n\
    \ P_{lanet_i} \\times P_{hanet_i}\n$$\n\n*is a relation satisfying the following,\
    \ for all* 1 ≤ *i* ≤ *n and t* ∈ *Thanet<sup>i</sup> (below* β*<sup>p</sup>* =\
    \ β{*p*} , {*r* | *r*β *p*}*, for every p* ∈ *Phcsan):*\n\n\\n- 1. \n$$\n|M_{hanet_i}^{init}|\
    \ = 1\n$$\n and  $|pre_{hanet_i}(t)| = |post_{hanet_i}(t)| = 1$ .\n\\n- 2.  $\\\
    beta_{M_{hanet_i}^{init}} = M_{hanet_i}^{init}$  and  $\\beta_{pre_{hanet_i}(t)}\
    \ \\left( \\sum_{\\text{landet}_i} \\beta_{post_{hanet_i}(t)} \\right)$ .\n\\\
    n\n\n*Notation: BSAN is the set of all* BSA*-nets.* ♦\n\nIntuitively, *lcsan*\
    \ provides a 'lower-level' view and *hcsan* provides a 'upper-level' of a record\
    \ of system behaviour. The role of β is to identify in the lower-level view the\
    \ divisions of behaviours into 'phases', and each β*<sup>p</sup>* indicates a\
    \ 'boundary' between two consecutive phases.\n\n![](_page_28_Figure_1.jpeg)\n\n\
    <span id=\"page-28-0\"></span>Fig. 7. Behavioural structured acyclic net *bsan*<sup>0</sup>\
    \ with *n* = 1 (i.e., there is one lower-level acyclic net and one upper-level\
    \ acyclic net and so graphically there is no difference between *lcsan* and *lanet*<sup>1</sup>\
    \ as well as between *hcsan* and *hanet*1).\n\nProposition 43. *Let bsan be a*\
    \ BSA*-net as in Definition [33,](#page-27-0) and let* 1 ≤ *i* ≤ *n.*\n\n- *1.*\
    \ reachable(*haneti*) = {{*p*} | *p* ∈ *Phanet<sup>i</sup>* }*.*\n- *2.* |*M*\
    \ ∩*Phanet<sup>i</sup>* | = 1*, for every M* ∈ reachable(*hcsan*)*.*\n- *3.* β*<sup>p</sup>*\
    \ ∈ reachable(*laneti*)*, for every p* ∈ *Phanet<sup>i</sup> .*\n\nThat is, a\
    \ reachable marking of the upper-level CSA-net includes exactly one place from\
    \ each of its component acyclic nets. Moreover, all the boundaries between different\
    \ phases are reachable markings of the lower-level acyclic nets.\n\nA BSA-net\
    \ is underpinned by a CSA-net combining the two different views of a database.\n\
    \nDefinition 34 (CSA-net underlying BSA-net). *Let bsan be a* BSA*-net as in Definition\
    \ [33,](#page-27-0)*\n\ncsan(*bsan*) , (*lanet*1,...,*lanetn*,*hanet*1,...,*hanetn*,*lQ*\
    \ ∪*hQ*,*lW* ∪*hW*) .\n\n*is the* CSA*-net* underlying *bsan.* ♦\n\nProposition\
    \ 44. csan(*bsan*) *is a well-formed* CSA*-net.*\n\n*Proof.* It follows directly\
    \ from the definitions. ⊓⊔\n\n# 13 Semantics of BSA-nets\n\nThe notions concerning\
    \ the structure and semantics of BSA-nets introduced below are based on similar\
    \ notions defined their underlying CSA-nets.\n\nDefinition 35 (notation for BSA-net).\
    \ *Let bsan be a* BSA*-net as in Definition [33.](#page-27-0)*\n\n- *1. Xbsan*\
    \ , *X*csan(*bsan*) *, for X* = *P*,*T*,*F*,*Q*,*W.*\n- *2.* pre*bsan* () , precsan(*bsan*)\
    \ () *and* post*bsan* () , postcsan(*bsan*) ()*.*\n- *3.* steps(*bsan*) , steps(csan(*bsan*))*.*\n\
    - *4.* markings(*bsan*) , markings(csan(*bsan*))*.*\n- *5. Minit bsan* , *Minit*\
    \ csan(*bsan*) *and Mfin bsan* , *M fin* csan(*bsan*) *.* ♦\n\nThe notion of enabled\
    \ step is different. It is based on the phases of lower-level acyclic nets induced\
    \ by the phase boundaries iduced by the relation β.\n\nDefinition 36 (phase and\
    \ phase-consistent marking of BSA-net). *Let bsan be a* BSA*net as in Definition\
    \ [33.](#page-27-0)*\n\n*1. The* phase *of a place p* ∈ *Phanet<sup>i</sup> (*1\
    \ ≤ *i* ≤ *n) is given by:*\n\n$$\n\\text{phase}(p) \\triangleq \\{\\beta_p\\\
    } \\cup \\{M \\mid \\exists t \\in \\text{post}_{hanet_i}(p) : \\beta_p[\\rangle_{lanet_i}\
    \ M[\\rangle_{lanet_i} \\beta_{\\text{post}_{hanet_i}(t)} \\}.\n$$\n\n*2. A marking\
    \ M* ∈ reachable(csan(*bsan*)) *is* phase-consistent *if, for every* 1 ≤ *i* ≤\
    \ *n:*\n\n$$\nM \\cap P_{lanet_i} \\in phase(\\beta_{M \\cap P_{hanet_i}}) .\n\
    $$\n\n*Notation:* phcmarkings(*bsan*) *is the set of all phase-consistent markings.*\
    \ ♦\n\nIntuitively, phase(*p*) is a contiguous 'chunk' of *lanet<sup>i</sup>*\
    \ delimited by the marking corresponding to *p* (start) and all markings (ends)\
    \ corresponding to the places obtained by executing one output transition of *p*\
    \ (such a transition indicates a 'phase change'). All markings in-between belong\
    \ to the delimited phase. Moreover, phase-consistency means that the markings\
    \ of the lower-level acyclic nets belong to the phases corresponding to the markings\
    \ of the upper-level acyclic nets.\n\n*Example 17.* Figure [7](#page-28-0) depicts\
    \ a BSA-net *bsan*0. We have:\n\nphase(\n$$\np_1\n$$\n) = { $\\{r_1, r_2\\}$ ,\
    \ { $r_1, r_5\\}$ , { $r_3, r_2\\}$ , { $r_3, r_5\\}$ , { $r_1, r_8\\}$ , { $r_4,\
    \ r_2\\}$ , { $r_4, r_5\\}$ ,  \n{ $r_4, r_8\\}$ , { $r_7, r_2\\}$ , { $r_7, r_5\\\
    }$ , { $r_7, r_8\\}$ }  \nphase( $p_2$ ) = { $\\{r_3, r_5\\}$ , { $r_3, r_8\\\
    }$ , { $r_3, r_{11}$ }, { $r_6, r_5\\}$ , { $r_6, r_8\\}$ , { $r_6, r_{11}$ },\
    \  \n{ $r_9, r_5\\}$ , { $r_9, r_8\\}$ , { $r_{9}, r_{11}$ }}  \nphase( $p_3$\
    \ ) = { $\\{r_7, r_8\\}$ , { $r_7, r_{11}$ }, { $r_{10}, r_8\\}$ , { $r_{10},\
    \ r_{11}$ }}  \nphase( $p_4$ ) = { $\\{r_9, r_{11}\\}$ }  \nphase( $p_4$ ) = {\
    \ $\\{r_{10}, r_{11}\\}$ .\n\nThe marking {*r*1,*r*11} ∈ reachable(*lanet*1) does\
    \ not belong to any phase of the places of *hanet*1. The marking {*p*1,*r*9,*r*11}\
    \ ∈ reachable(csan(*bsan*)) is not phase-consistent, and the marking {*p*4,*r*9,*r*11}\
    \ ∈ reachable(csan(*bsan*)) is phase-consistent. ♦ The execution semantics of\
    \ BSA-nets is restricted to the phase-consistent markings.\n\nDefinition 37 (enabled\
    \ and executed step of BSA-net). *Let M*,*M*′ ∈ markings(*bsan*) *be markings\
    \ of a* BSA*-net bsan, and U* ∈ steps(*bsan*) *be a step. Then*\n\n$$\nU\\in\\\
    mathsf{enabled}_{bsan}(M)\\quad and\\quad M[U\\rangle_{bsan}M'\n$$\n\n*if M*,*M*′\
    \ ∈ phcmarkings(*bsan*) *and M*[*U*icsan(*bsan*) *M*′ *.* ♦\n\nIntuitively, *bsan*\
    \ is executed in exactly the same way as its underlying CSA-net provided that\
    \ the the markings involved are phase-consistent.\n\nDefinition 38 (mixed step\
    \ sequence and step sequence of BSA-net). *Let bsan be a* BSA*-net and* <sup>µ</sup>\
    \ = *M*0*U*1*M*<sup>1</sup> ...*Mk*−1*UkM<sup>k</sup> (k* ≥ 0*) be a sequence\
    \ such that M*0,...,*M<sup>k</sup>* ∈ markings(*bsan*) *and U*1,...,*U<sup>k</sup>*\
    \ ∈∈ steps(*bsan*)*.*\n\n- *1.* <sup>µ</sup> *is a* mixed step sequence from *M*<sup>0</sup>\
    \ to *M<sup>k</sup> if Mi*−1[*Ui*i*bsan M<sup>i</sup> , for every* 1 ≤ *i* ≤ *k.*\n\
    - *2. If* <sup>µ</sup> *is a mixed step sequence from M*<sup>0</sup> *to M<sup>k</sup>\
    \ , then* <sup>σ</sup> = *U*<sup>1</sup> ...*U<sup>k</sup> is a* step sequence\
    \ from *M*<sup>0</sup> to *M<sup>k</sup> .*\n\n*This is denoted by M*0[µii*bsan\
    \ M<sup>k</sup> and M*0[σi*bsan M<sup>k</sup> , respectively. Also, M*0[i*bsan\
    \ M<sup>k</sup> denotes that M<sup>k</sup> is reachable from M*0*.* ♦\n\nIn the\
    \ last definition, the starting point is an arbitrary marking. The next definition\
    \ assumes that the starting point is the default initial marking.\n\nDefinition\
    \ 39 (behaviour of BSA-net). *The following sets capture various behavioural notions\
    \ related to step sequences and reachable markings of a* BSA*-net bsan.*\n\n*1.*\
    \ sseq(*bsan*) , {<sup>σ</sup> | *Minit bsan*[σi*bsan M*} step sequences*. 2.*\
    \ mixsseq(*bsan*) , {<sup>µ</sup> | *Minit bsan*[µii*bsan M*} mixed step sequences*.\
    \ 3.* maxsseq(*bsan*) , {<sup>σ</sup> ∈ sseq(*bsan*) | ¬∃*U* : <sup>σ</sup>*U*\
    \ ∈ sseq(*bsan*)} maximal step sequences*. 4.* maxmixsseq(*bsan*) , {<sup>µ</sup>\
    \ ∈ mixsseq(*bsan*) | ¬∃*U*,*M* : <sup>µ</sup>*UM* ∈ mixsseq(*bsan*)} maximal\
    \ mixed step sequences*. 5.* reachable(*bsan*) , {*M* | *Minit bsan*[i*bsan M*}\
    \ reachable markings*. 6.* finreachable(*bsan*) , {*M* | ∃<sup>σ</sup> ∈ maxsseq(*bsan*)\
    \ : *Minit bsan*[σi*bsan M*} final reachable markings*.*\n\n♦\n\n*Example 18.*\
    \ A maximal mixed step sequence of the BSA-net depicted in Figure [7](#page-28-0)\
    \ is:\n\n$$\n\\mu = \\{p_1, r_1, r_2\\} \\quad \\{g, k\\} \\quad \\{p_1, r_4,\
    \ r_5\\} \\quad \\{h, l\\} \\quad \\{p_1, r_7, r_8\\} \\quad \\{c, m\\} \\{p_3,\
    \ r_7, r_{11}\\} \\quad \\{j\\} \\quad \\{p_3, r_{10}, r_{11}\\} \\quad \\{d\\\
    } \\quad \\{p_5, r_{10}, r_{11}\\},\n$$\n\nand the corresponding maximal step\
    \ sequence is <sup>σ</sup> = {*g*,*k*}{*h*,*l*}{*c*,*m*}{ *j*}{*d*}. ♦\n\nAs before,\
    \ we single out nets with forward and backward determinism.\n\nDefinition 40 (BSO-net).\
    \ *A* BSA*-net bson* = (*lcson*,*hcson*,β) *is a* behavioural structured occurrence\
    \ net (or BSO-net) *if lcson*,*hcson* ∈ *CSON and there is* <sup>σ</sup> ∈ sseq(*bson*)\
    \ *such that* S <sup>σ</sup> = *Tbson. Notation: BSON is the set of all* BSO*-nets.*\
    \ ♦\n\nNote that in BSO-nets, the upper-level acyclic nets are 'line-like' occurrence\
    \ nets.\n\nAs before, what really matters is to identify in a BSA-net all the\
    \ deterministic behaviours (scenarios).\n\nDefinition 41 (scenario and maximal\
    \ scenario of BSA-net). *Let bsan be a* BSA*-net as in Definition [33.](#page-27-0)*\n\
    \n*1. A* scenario *of bsan is a* BSO*-net bson* = (*lcson*,*hcson*,β ′ ) *such\
    \ that:*\n\n*(a) lcson* ∈ scenarios(*lcsan*) *and hcson* ∈ scenarios(*hcsan*)*.\
    \ (b)* β ′ = β ∩(*Plcson* ×*Phcson*)*.*\n\n*2. A* maximal scenario *of bsan is\
    \ a scenario bson such that there is no scenario bson*′ *satisfying Tbson* ⊂ *Tbson*′\
    \ *.*\n\n*Notation:* scenarios(*bsan*) *and* maxscenarios(*bsan*) *are respectively\
    \ the sets of all scenarios and maximal scenarios of bsan.* ♦\n\n*Example 19.*\
    \ Figure [8](#page-32-0) depicts the only two maximal scenarios of the BSA-net\
    \ in Figure [7.](#page-28-0)\n\n# 14 Well-formed BSA-nets\n\nThe general definition\
    \ of BSA-net given above does not guarantee that the step sequences of *bsan*\
    \ cover all possible scenarios of the lower-level CSA-net. Indeed, in the extreme\
    \ case, we can take *hcsan* which contains no transitions at all, and the resulting\
    \ BSA-net generates then only the empty step sequence. It is therefore crucial\
    \ to identify cases where *bsan* generates at least one step sequence for every\
    \ scenario of *lcsan*. As a result, the definition of a well-formed BSA-net is\
    \ more demanding than the definition of a well-formed CSA-net.\n\nDefinition 42\
    \ (well-formed BSA-net). *A* BSA*-net bsan is* well-formed *if:*\n\n- *1.* sseq(*bsan*)\
    \ = S sseq(scenarios(*bsan*))*.*\n- *2. For every scenario bson* ∈ maxscenarios(*bsan*)*,\
    \ there is* <sup>σ</sup> ∈ maxsseq(*bsan*) *such that* <sup>σ</sup> ↾*Tbson*∈\
    \ maxsseq(*bson*)*.*\n\n*Notation: WFBSAN is the set of all well-formed* BSA*-nets.*\
    \ ♦\n\n![](_page_32_Figure_1.jpeg)\n\n<span id=\"page-32-0\"></span>Fig. 8. Maximal\
    \ scenarios for the BSA-net in Figure [7.](#page-28-0)\n\n# 15 Concluding remarks\n\
    \nThis paper provides formalisation and basic properties for the nine classes\
    \ of nets listed in the diagram below.\n\n| backward & forward det occurrence\
    \ net |                                                           | CSO-net |\
    \ BSO-net |\n|---------------------------------------|-----------------------------------------------------------|---------|---------|\n\
    |                                       | backward det backward det acyclic net\
    \ BDCSA-net BDBSA-net |         |         |\n| no restriction acyclic net    \
    \        |                                                           | CSA-net\
    \ | BSA-net |\n\nThe following are some published works on the topics concerned\
    \ with or related to the material presented above [\\[16](#page-34-0)[,23](#page-34-4)[,8](#page-33-1)[,22](#page-34-3)[,19](#page-34-7)[,18](#page-34-9)[,15,](#page-34-10)[21,](#page-34-11)[20,](#page-34-1)[13,](#page-34-8)[9,](#page-33-2)[5,](#page-33-0)[17,](#page-34-6)[2](#page-33-3)[,1](#page-33-4)[,6](#page-33-5)[,4](#page-33-6)[,10](#page-34-12)[,7](#page-33-7)[,3,](#page-33-8)[12\\\
    ]](#page-34-13).\n\n# <span id=\"page-33-4\"></span>References\n\n- 1. M. Alahmadi.\
    \ Master channel places for communication structured acyclic nets. In M. Köhler-Bussmeier,\
    \ E. Kindler, and H. Rölke, editors, *Proceedings of the International Workshop\
    \ on Petri Nets and Software Engineering 2021 co-located with the 42nd International\
    \ Conference on Application and Theory of Petri Nets and Concurrency (PETRI NETS\
    \ 2021), Paris, France, June 25th, 2021 (due to COVID-19: virtual conference)*,\
    \ volume 2907 of *CEUR Workshop Proceedings*, pages 233–240. CEUR-WS.org, 2021.\n\
    - <span id=\"page-33-3\"></span>2. M. Alahmadi. Parametrisation of csa-nets. In\
    \ M. Köhler-Bussmeier, D. Moldt, and H. Rölke, editors, *Petri Nets and Software\
    \ Engineering 2022 co-located with the 43rd International Conference on Application\
    \ and Theory of Petri Nets and Concurrency (PETRI NETS 2022), Bergen, Norway,\
    \ June 20th, 2022*, volume 3170 of *CEUR Workshop Proceedings*, pages 215–216.\
    \ CEUR-WS.org, 2022.\n- <span id=\"page-33-8\"></span>3. M. Alahmadi. Parameterised\
    \ csa-nets. In M. Köhler-Bussmeier, D. Moldt, and H. Rölke, editors, *Proceedings\
    \ of the 2023 International Workshop on Petri Nets and Software Engineering (PNSE\
    \ 2023) co-located with the 44th International Conference on Application and Theory\
    \ of Petri Nets and Concurrency (PETRI NETS 2023), June 27, 2023, Lisbon, Portugal*,\
    \ volume 3430 of *CEUR Workshop Proceedings*, pages 167–182. CEUR-WS.org, 2023.\n\
    - <span id=\"page-33-6\"></span>4. S. Alharbi. Hierarchical simulation of timed\
    \ behaviours of structured occurrence nets. In M. Köhler-Bussmeier, D. Moldt,\
    \ and H. Rölke, editors, *Proceedings of the 2023 International Workshop on Petri\
    \ Nets and Software Engineering (PNSE 2023) co-located with the 44th International\
    \ Conference on Application and Theory of Petri Nets and Concurrency (PETRI NETS\
    \ 2023), June 27, 2023, Lisbon, Portugal*, volume 3430 of *CEUR Workshop Proceedings*,\
    \ pages 143–166. CEUR-WS.org, 2023.\n- <span id=\"page-33-0\"></span>5. T. Alharbi.\
    \ *Analysing and visualizing big data sets of crime investigations using Structured\
    \ Occurrence Nets*. PhD thesis, University of Newcastle upon Tyne, 2020.\n- <span\
    \ id=\"page-33-5\"></span>6. N. Almutairi. Probabilistic communication structured\
    \ acyclic nets. In M. Köhler-Bussmeier, D. Moldt, and H. Rölke, editors, *Petri\
    \ Nets and Software Engineering 2022 co-located with the 43rd International Conference\
    \ on Application and Theory of Petri Nets and Concurrency (PETRI NETS 2022), Bergen,\
    \ Norway, June 20th, 2022*, volume 3170 of *CEUR Workshop Proceedings*, pages\
    \ 168–187. CEUR-WS.org, 2022.\n- <span id=\"page-33-7\"></span>7. N. Almutairi.\
    \ Probabilistic behavioural acyclic nets. In M. Köhler-Bussmeier, D. Moldt, and\
    \ H. Rölke, editors, *Proceedings of the 2023 International Workshop on Petri\
    \ Nets and Software Engineering (PNSE 2023) co-located with the 44th International\
    \ Conference on Application and Theory of Petri Nets and Concurrency (PETRI NETS\
    \ 2023), June 27, 2023, Lisbon, Portugal*, volume 3430 of *CEUR Workshop Proceedings*.\
    \ CEUR-WS.org, 2023.\n- <span id=\"page-33-1\"></span>8. N. Almutairi and M. Koutny.\
    \ Verification of communication structured acyclic nets using SAT. In M. Köhler-Bussmeier,\
    \ E. Kindler, and H. Rölke, editors, *Proceedings of the International Workshop\
    \ on Petri Nets and Software Engineering 2021 co-located with the 42nd International\
    \ Conference on Application and Theory of Petri Nets and Concurrency (PETRI NETS\
    \ 2021), Paris, France, June 25th, 2021 (due to COVID-19: virtual conference)*,\
    \ volume 2907 of *CEUR Workshop Proceedings*, pages 175–194. CEUR-WS.org, 2021.\n\
    - <span id=\"page-33-2\"></span>9. T. Alshammari. Towards automatic extraction\
    \ of events for SON modelling. In M. Köhler-Bussmeier, D. Moldt, and H. Rölke,\
    \ editors, *Petri Nets and Software Engineering 2022 colocated with the 43rd International\
    \ Conference on Application and Theory of Petri Nets and Concurrency (PETRI NETS\
    \ 2022), Bergen, Norway, June 20th, 2022*, volume 3170 of *CEUR Workshop Proceedings*,\
    \ pages 188–201. CEUR-WS.org, 2022.\n- <span id=\"page-34-12\"></span>10. T. Alshammari.\
    \ Integrating NLP and structured occurrence nets for crime modelling: A pattern-based\
    \ approach. In M. Köhler-Bussmeier, D. Moldt, and H. Rölke, editors, *Proceedings\
    \ of the 2023 International Workshop on Petri Nets and Software Engineering (PNSE\
    \ 2023) co-located with the 44th International Conference on Application and Theory\
    \ of Petri Nets and Concurrency (PETRI NETS 2023), June 27, 2023, Lisbon, Portugal*,\
    \ volume 3430 of *CEUR Workshop Proceedings*. CEUR-WS.org, 2023.\n- <span id=\"\
    page-34-13\"></span><span id=\"page-34-2\"></span>11. E. Best and R. R. Devillers.\
    \ Sequential and concurrent behaviour in petri net theory. *Theor. Comput. Sci.*,\
    \ 55(1):87–136, 1987.\n- <span id=\"page-34-8\"></span>12. A. Bhattacharyya and\
    \ M. Koutny. Confusion-tolerant computation of probability in acyclic nets. *Trans.\
    \ Petri Nets Other Model. Concurr.*, 17:212–245, 2023.\n- 13. A. Bhattacharyya,\
    \ B. Li, and B. Randell. Time in structured occurrence nets. In L. Cabac, L. M.\
    \ Kristensen, and H. Rölke, editors, *Proceedings of the International Workshop\
    \ on Petri Nets and Software Engineering 2016, Toru´n, Poland, June 20-21, 2016*,\
    \ volume 1591 of *CEUR Workshop Proceedings*, pages 35–55. CEUR-WS.org, 2016.\n\
    - <span id=\"page-34-10\"></span><span id=\"page-34-5\"></span>14. R. Bruni, H.\
    \ C. Melgratti, and U. Montanari. Concurrency and probability: Removing confusion,\
    \ compositionally. *CoRR*, abs/1710.04570, 2017.\n- 15. J. Kleijn and M. Koutny.\
    \ Causality in structured occurrence nets. In C. B. Jones and J. L. Lloyd, editors,\
    \ *Dependable and Historic Computing - Essays Dedicated to Brian Randell on the\
    \ Occasion of His 75th Birthday*, volume 6875 of *Lecture Notes in Computer Science*,\
    \ pages 283–297. Springer, 2011.\n- <span id=\"page-34-6\"></span><span id=\"\
    page-34-0\"></span>16. M. Koutny and B. Randell. Structured occurrence nets: A\
    \ formalism for aiding system failure prevention and analysis techniques. *Fundam.\
    \ Inform.*, 97(1-2):41–91, 2009.\n- 17. B. Li. *Visualisation and Analysis of\
    \ Complex Behaviours using Structured Occurrence Nets*. PhD thesis, University\
    \ of Newcastle upon Tyne, United Kingdom, 2017.\n- <span id=\"page-34-9\"></span>18.\
    \ B. Li, B. Randell, A. Bhattacharyya, T. Alharbi, and M. Koutny. Soncraft: A\
    \ tool for construction, simulation, and analysis of structured occurrence nets.\
    \ In *18th International Conference on Application of Concurrency to System Design,\
    \ ACSD 2018, Bratislava, Slovakia, June 25-29, 2018*, pages 70–74. IEEE Computer\
    \ Society, 2018.\n- <span id=\"page-34-7\"></span>19. P. Missier, B. Randell,\
    \ and M. Koutny. Modelling provenance using structured occurrence networks. In\
    \ P. Groth and J. Frew, editors, *Provenance and Annotation of Data and Processes\
    \ - 4th International Provenance and Annotation Workshop, IPAW 2012, Santa Barbara,\
    \ CA, USA, June 19-21, 2012, Revised Selected Papers*, volume 7525 of *Lecture\
    \ Notes in Computer Science*, pages 183–197. Springer, 2012.\n- <span id=\"page-34-1\"\
    ></span>20. B. Randell. Occurrence nets then and now: The path to structured occurrence\
    \ nets. In L. M. Kristensen and L. Petrucci, editors, *Applications and Theory\
    \ of Petri Nets*, pages 1– 16, Berlin, Heidelberg, 2011. Springer Berlin Heidelberg.\n\
    - <span id=\"page-34-11\"></span>21. B. Randell. Incremental construction of structured\
    \ occurrence nets. Technical Report 1384, School of Computing Science, University\
    \ of Newcastle upon Tyne, 2013.\n- <span id=\"page-34-3\"></span>22. B. Randell\
    \ and M. Koutny. Failures: Their definition, modelling and analysis. In C. B.\
    \ Jones, Z. Liu, and J. Woodcock, editors, *Theoretical Aspects of Computing -\
    \ ICTAC 2007, 4th International Colloquium, Macau, China, September 26-28, 2007,\
    \ Proceedings*, volume 4711 of *Lecture Notes in Computer Science*, pages 260–274.\
    \ Springer, 2007.\n- <span id=\"page-34-4\"></span>23. B. Randell and M. Koutny.\
    \ Structured occurrence nets: Incomplete, contradictory and uncertain failure\
    \ evidence. Technical Report 1170, School of Computing Science, University of\
    \ Newcastle upon Tyne, 2009."
- id: semantic_web_technology_for_agent_communication_protocols_idoia_berges_jes_us_berm_udez_alfredo_go_ni_and_arantza_illarramendi
  title: Semantic Web Technology for Agent Communication Protocols
  abstract: 'One relevant aspect in the development of the Semantic Web framework
    is the

    achievement of a real inter-agents communication capability at the semantic

    level. The agents should be able to communicate and understand each other using

    standard communication protocols freely, that is, without needing a laborious
    a

    priori preparation, before the communication takes place. For that setting we

    present in this paper a proposal that promotes to describe standard

    communication protocols using Semantic Web technology (specifically, OWL-DL and

    SWRL). Those protocols are constituted by communication acts. In our proposal

    those communication acts are described as terms that belong to a communication

    acts ontology, that we have developed, called CommOnt. The intended semantics

    associated to the communication acts in the ontology is expressed through

    social commitments that are formalized as fluents in the Event Calculus. In

    summary, OWL-DL reasoners and rule engines help in our proposal for reasoning

    about protocols. We define some comparison relationships (dealing with notions

    of equivalence and specialization) between protocols used by agents from

    different systems.'
  url: http://arxiv.org/abs/2401.11841v1
  keywords: ''
  document: "# Semantic Web Technology for Agent Communication Protocols\n\nIdoia\
    \ Berges<sup>⋆</sup> , Jes´us Berm´udez, Alfredo Go˜ni, and Arantza Illarramendi⋆⋆\n\
    \nUniversity of the Basque Country {iberges003,jesus.bermudez,alfredo,a.illarramendi}@ehu.es\
    \ <http://siul02.si.ehu.es>\n\nAbstract. One relevant aspect in the development\
    \ of the Semantic Web framework is the achievement of a real inter-agents communication\
    \ capability at the semantic level. The agents should be able to communicate and\
    \ understand each other using standard communication protocols freely, that is,\
    \ without needing a laborious a priori preparation, before the communication takes\
    \ place.\n\nFor that setting we present in this paper a proposal that promotes\
    \ to describe standard communication protocols using Semantic Web technology (specifically,\
    \ OWL-DL and SWRL). Those protocols are constituted by communication acts. In\
    \ our proposal those communication acts are described as terms that belong to\
    \ a communication acts ontology, that we have developed, called CommOnt. The intended\
    \ semantics associated to the communication acts in the ontology is expressed\
    \ through social commitments that are formalized as fluents in the Event Calculus.\n\
    \nIn summary, OWL-DL reasoners and rule engines help in our proposal for reasoning\
    \ about protocols. We define some comparison relationships (dealing with notions\
    \ of equivalence and specialization) between protocols used by agents from different\
    \ systems.\n\nKey words: Protocol, Communication acts, agents.\n\n## 1 Introduction\n\
    \nIn the scenario that promotes the emergent Web, administrators of existing Information\
    \ Systems, that belong to nodes distributed along the Internet network, are encouraged\
    \ to provide the functionalities of those systems through agents that represent\
    \ them or through Web Services. The underlying idea is to get a real interoperation\
    \ among those Information Systems in order to enlarge the benefits that users\
    \ can get from the Web by increasing the machine processable tasks.\n\n<sup>⋆</sup>\
    \ The work of Idoia Berges is supported by a grant of the Basque Government.\n\
    \n<sup>⋆⋆</sup> All authors are members of the Interoperable DataBases Group.\
    \ This work is also supported by the University of the Basque Country, Diputaci´on\
    \ Foral de Gipuzkoa (cosupported by the European Social Fund) and the Spanish\
    \ Ministry of Education and Science TIN2007-68091-C02-01.\n\nAlthough agent technology\
    \ and Web Services technology have been developed in a separate way, there exists\
    \ a recent work of several members from both communities trying to consolidate\
    \ their approaches into a common specification describing how to seamlessly interconnect\
    \ FIPA compliant agent systems [\\[1\\]](#page-13-0) with W3C compliant Web Services.\
    \ The purpose of specifying an infrastructure for integrating these two technologies\
    \ is to provide a common means of allowing each to discover and invoke instances\
    \ of the other [\\[2\\]](#page-13-1). Considering the previous approach, in the\
    \ rest of this paper we will only concentrate on inter-agent communication aspects.\n\
    \nCommunication among agents is in general based on the interchange of communication\
    \ acts. However, different Information Systems have incorporated different classes\
    \ of communication acts as their Agent Communication Language (acl) to the point\
    \ that they do not understand each other. Moreover, protocols play a relevant\
    \ role in agents communication. A protocol specifies the rules of interaction\
    \ between agents by restricting the range of allowed follow-up communication acts\
    \ for each agent at any stage during a communicative interaction. It is widely\
    \ recognized the interest of using standard communication protocols.\n\nWe advocate\
    \ so that the administrators of the Information Systems proceed in the following\
    \ way. When they wish to implement the agents that will represent their systems,\
    \ they first select, from a repository of standard protocols (there can exist\
    \ one or more repositories), those protocols that fulfill the goals of their agents.\
    \ Sometimes a single protocol will be sufficient and other times it will be necessary\
    \ to design a protocol as a composition of some other protocols. Next, they can\
    \ customize the selected protocols before they incorporate them to the agents.\
    \ In that setting, when agents of different Information Systems want to interoperate\
    \ it will be relevant to reason about the protocols embedded in the agents in\
    \ order to discover relationships such as equivalence or restriction between them.\
    \ Moreover, once those relationships are discovered both agents can use the same\
    \ protocol by replacing dynamically in one agent the protocol supported by the\
    \ other. Finally, in our opinion it will be desirable to use a formal language\
    \ to represent the protocols.\n\nIn this paper we present a proposal that promotes\
    \ to describe standard communication protocols using Semantic Web Technology (OWL-DL\
    \ and SWRL). In addition, communication acts that take part of the protocols are\
    \ described as terms that belong to a communication acts ontology, that we have\
    \ developed, called CommOnt (see more details about the ontology in [\\[3\\]](#page-13-2)).\
    \ The use of that ontology favours on the one hand, the explicit representation\
    \ of the meaning of the communication acts and on the other hand, the customization\
    \ of existing standard protocols by allowing the use of particular communication\
    \ acts that can be defined as specializations of existing standard communication\
    \ acts.\n\nTerms of the CommOnt ontology are described using OWL-DL and we have\
    \ adopted the so called social approach [\\[4,](#page-13-3)[5\\]](#page-13-4)\
    \ for expressing the intended semantics of the communication acts included in\
    \ the protocols. According to the social approach, when agents interact they become\
    \ involved in social commitments or obligations to each other. Those commitments\
    \ are public, and therefore they are suitable for an objective and verifiable\
    \ semantics of agent interaction. Social commitments can be considered as fluents\
    \ in the Event Calculus, which is a logic-based formalism for representing actions\
    \ and their effects. Fluents are propositions that hold during time intervals.\
    \ A formula in the Event Calculus is associated to a communication act for describing\
    \ its social effects. The set of fluents that hold at a moment describes a state\
    \ of the interaction. DL axioms and Event Calculus formulae apply to different\
    \ facets of communication acts. DL axioms describe static features and are principally\
    \ used for communication act interpretation purposes. Event Calculus formulae\
    \ describe dynamic features, namely the social effects of communication acts,\
    \ and are principally used for communication act operational contexts such as\
    \ supervising conversations.\n\nIn summary the main contributions of the proposal\
    \ presented in this paper are:\n\n- It favours a flexible interoperation among\
    \ agents of different systems by using standard communication protocols described\
    \ through tools promoted by the W3C.\n- It facilitates the customization of those\
    \ standard communication protocols allowing to use communication acts in the protocols\
    \ that belong to specific acl of Information Systems. The particular communication\
    \ acts are described in an ontology.\n- It provides a basis to reason about relationships\
    \ between two protocols in such a way that the following relations can be discovered:\
    \ equivalence or restriction (and also considering a notion of specialization).\
    \ Moreover, notice that our approach allows to get protocols classification in\
    \ terms of the intended semantics of communication acts that appear in the protocols.\n\
    - It allows modeling the communication among agents without regarding only to\
    \ the lower level operational details of how communication acts are interchanged\
    \ but taking also into account the meaning of those acts.\n\nThe rest of the paper\
    \ is organized as follows: Section [2](#page-2-0) provides background on the communication\
    \ ontology, that contains terms corresponding to communication acts that appear\
    \ in the protocols, and on the semantics associated to those acts. Section [3](#page-6-0)\
    \ explains how protocols are described using Semantic Web Technology and presents\
    \ the definitions of the relationships considered between protocols. Section [4](#page-11-0)\
    \ discusses different related works, and conclusions appear in the last section.\n\
    \n# <span id=\"page-2-0\"></span>2 Two basic supports for the proposal: the CommOnt\
    \ Ontology and the representation of the semantics of communication acts\n\nAmong\
    \ the different models proposed for representing protocols one which stands out\
    \ is that of State Transition Systems (STS).\n\nDefinition 1. A State Transition\
    \ System is a tuple (S, s0, L, T , F), where S is a finite set of states, s<sup>0</sup>\
    \ ∈ S is an initial state, L is a finite set of labels, T ⊆ S × L × S is a set\
    \ of transitions and F ⊆ S is a set of final states.\n\nIn our proposal we use\
    \ STS where transitions are labeled with communication act classes described in\
    \ a communication acts ontology called CommOnt. That is to say, the set of labels\
    \ L is a set of class names taken from that ontology. Moreover, as mentioned before,\
    \ the intended semantics associated to the communication acts in the ontology\
    \ is expressed through predicates in the Event Calculus that initiate or terminate\
    \ fluents. In our case, each state is associated to the set of fluents that holds\
    \ at that moment.\n\nIn the following two subsections we present the main features\
    \ of the CommOnt ontology and of the intended semantics associated to communication\
    \ acts, respectively.\n\n#### 2.1 Main features of the CommOnt Ontology\n\nThe\
    \ goal of the CommOnt ontology is to favour the interoperation among agents belonging\
    \ to different Information Systems. The leading categories of that ontology are:\
    \ first, communication acts that are used for interaction by actors and that have\
    \ different purposes and deal with different kinds of contents; and second, contents\
    \ that are the sentences included in the communication acts.\n\nThe main design\
    \ criteria adopted for the communication acts category of the CommOnt ontology\
    \ is to follow the speech acts theory [\\[6\\]](#page-13-5), a linguistic theory\
    \ that is recognized as the principal source of inspiration for designing the\
    \ most familiar standard agent communication languages. Following that theory\
    \ every communication act is the sender's expression of an attitude toward some\
    \ possibly complex proposition. A sender performs a communication act which is\
    \ expressed by a coded message and is directed to a receiver. Therefore, a communication\
    \ act has two main components. First, the attitude of the sender which is called\
    \ the illocutionary force (F), that expresses social interactions such as informing,\
    \ requesting or promising, among others. And second, the propositional content\
    \ (p) which is the subject of what the attitude is about. In CommOnt this F(p)\
    \ framework is followed, and different kinds of illocutionary forces and contents\
    \ leading to different classes of communication acts are supported. More specifically,\
    \ specializations of illocutionary forces that facilitate the absorption of aspects\
    \ of the content into the illocutionary force are considered.\n\nCommOnt is divided\
    \ into three interrelated layers: upper, standards and applications, that group\
    \ communication acts at different levels of abstraction. Classes of the CommOnt\
    \ ontology are described using the Web Ontology Language OWL-DL. Therefore, communication\
    \ acts among agents that commit to CommOnt have an abstract representation as\
    \ individuals of a shared universal class of communication acts.\n\nIn the upper\
    \ layer, according to Searle's speech acts theory, five upper classes of communication\
    \ acts corresponding to Assertives, Directives, Commissives, Expressives and Declaratives\
    \ are specified. But also the top class CommunicationAct[1](#page-4-0) is defined,\
    \ which represents the universal class of communication acts. Every particular\
    \ communication act is an individual of this class. In CommOnt, components of\
    \ a class are represented by properties. The most immediate properties of CommunicationAct\
    \ are the content and the actors who send and receive the communication act. There\
    \ are some other properties related to the context of a communication act such\
    \ as the conversation in which it is inserted or a link to the domain ontology\
    \ that includes the terms used in the content.\n\nA standards layer extends the\
    \ upper layer of the ontology with specific terms that represent classes of communication\
    \ acts of general purpose agent communication languages, like those from KQML\
    \ or FIPA-ACL. Although the semantic framework of those agent communication languages\
    \ may differ from the semantic framework adopted in CommOnt, in our opinion enough\
    \ basic concepts and principles are shared to such an extent that a commitment\
    \ to ontological relationships can be undertaken in the context of the interoperation\
    \ of Information Systems.\n\nWith respect to FIPA-ACL, we can observe that it\
    \ proposes four primitive communicative acts [\\[1\\]](#page-13-0): Confirm, Disconfirm,\
    \ Inform and Request. The terms FIPA-Confirm, FIPA-Disconfirm, FIPA-Inform and\
    \ FIPA-Request are used to respectively represent them as classes in CommOnt.\
    \ Furthermore, the rest of the FIPA communicative acts are derived from those\
    \ mentioned four primitives. Analogously, communication acts from KQML can be\
    \ analyzed and the corresponding terms in CommOnt specified. It is of vital relevance\
    \ for the interoperability aim to be able of specifying ontological relationships\
    \ among classes of different standards.\n\nFinally, it is often the case that\
    \ every single Information System uses a limited collection of communication acts\
    \ that constitute its particular agent communication language. The applications\
    \ layer reflects the terms describing communication acts used in such particular\
    \ Information Systems. The applications layer of the CommOnt ontology provides\
    \ a framework for the description of the nuances of such communication acts. Some\
    \ of those communication acts can be defined as particularizations of existing\
    \ classes in the standards layer and maybe some others as particularizations of\
    \ upper layer classes. Interoperation between agents of two systems using different\
    \ kinds of communication acts will proceed through these upper and standard layer\
    \ classes.\n\nFollowing we show some axioms in the CommOnt ontology. For the presentation\
    \ we prefer a logic notation instead of the more verbose owl/xml syntax.\n\n```\n\
    CommunicationAct ⊑ =1 hasSender.Actor ⊓ ∀hasReceiver.Actor ⊓\n               \
    \    ∀hasContent.Content\n         Request ⊑ Directive ⊓ ∃hasContent.Command\n\
    \          Accept ⊑ Declarative\n      Responsive ⊑ Assertive ⊓ ∃inReplyTo.Request\n\
    ```\n<span id=\"page-4-0\"></span><sup>1</sup> This type style refers to terms\
    \ specified in the ontology.\n\n#### <span id=\"page-5-0\"></span>2.2 Semantics\
    \ associated to Communication Acts\n\nFormal semantics based on mental concepts\
    \ such as beliefs, desires and intentions have been developed for specifying the\
    \ semantics of communication acts. However, they have been criticized on their\
    \ approach [\\[4\\]](#page-13-3) as well as on their analytical difficulties [\\\
    [7\\]](#page-13-6). We have adopted the so called social approach [\\[5,](#page-13-4)[8](#page-13-7)[,9\\\
    ]](#page-13-8) to express the intended semantics of communication acts described\
    \ in the CommOnt ontology. According to the social approach, when agents interact\
    \ they become involved in social commitments or obligations to each other.\n\n\
    Definition 2. A base-level commitment C(x, y, p) is a ternary relation representing\
    \ a commitment made by x (the debtor) to y (the creditor) to bring about a certain\
    \ proposition p.\n\nSometimes an agent accepts a commitment only if a certain\
    \ condition holds or, interestingly, only when a certain commitment is made by\
    \ another agent. This is called a conditional commitment.\n\nDefinition 3. A conditional\
    \ commitment CC(x, y, p, q) is a quaternary relation representing that if the\
    \ condition p is brought out, x will be committed to y to bring about the proposition\
    \ q.\n\nMoreover, the formalism we use for reasoning about commitments is based\
    \ on the Event Calculus. The basic ontology of the Event Calculus comprises actions,\
    \ fluents and time points. It also includes predicates for saying what happens\
    \ when (Happens), for describing the initial situation (Initially), for describing\
    \ the effects of actions (Initiates and Terminates), and for saying what fluents\
    \ hold at what times (HoldsAt). See [\\[10\\]](#page-13-9) for more explanations.\n\
    \nCommitments (base-level and conditional) can be considered fluents, and semantics\
    \ of communication acts can be expressed with predicates. For example:\n\n- Initiates(Request(s,r,P),\
    \ CC(r, s, accept(r,s,P), P), t)\n- A Request from s to r produces the effect\
    \ of generating a conditional commitment expressing that if the receiver r accepts\
    \ the demand, it will be commited to the proposition in the content of the communication\
    \ act.\n- Initiates(Accept(s,r,P), accept(s,r,P), t)\n\t- The sending of an Accept\
    \ produces the effect of generating the accept fluent.\n\nFurthermore, some rules\
    \ are needed to capture the dynamics of commitments. Commitments are a sort of\
    \ fluents typically put in force by communication acts and that become inoperative\
    \ after the appearance of other fluents. In the following rules e(x) represents\
    \ an event caused by x. The first rule declares that when a debtor of a commitment\
    \ that is in force causes an event that initiates the proposition committed, the\
    \ commitment ceases to hold.\n\nRule 1: HoldsAt(C(x, y, p), t) ∧ Happens(e(x),\
    \ t) ∧ Initiates(e(x), p, t) → Terminates(e(x),C(x, y, p), t).\n\nThe second rule\
    \ declares that a conditional commitment that is in force disappears and generates\
    \ a base-level commitment when the announced condition is brought out by the creditor.\n\
    \nRule 2: HoldsAt(CC(x, y, c, p), t) ∧ Happens(e(y), t) ∧ Initiates(e(y), c, t)\
    \ → Initiates(e(y),C(x, y, p), t) ∧ Terminates(e(y),CC(x, y, c, p), t).\n\nFollowing\
    \ we state some predicates that describe the semantics asociated to some of the\
    \ communication acts of the upper level of the CommOnt ontology. This semantics\
    \ is determined by the fluents that are initiated or terminated as a result of\
    \ the sending of a message between agents.\n\n- Initiates(Assertive(s,r,P), P,\
    \ t)\n- Initiates(Commissive(s,r,C,P), CC(s,r,C,P), t)\n- Initiates(Responsive(s,r,P,\
    \ RA), P, t) Terminates(Responsive(s,r,P, RA),C(s,r,RA), t)\n\nEffects of these\
    \ predicates can be encoded with SWRL rules. For instance, the predicate Initiates(Request(s,\
    \ r, P), CC(r, s, accept(r, s, P), P), t) can be encoded as follows:\n\nRequest(x)\
    \ ∧ hasSender(x,s) ∧ hasReceiver(x,r) ∧ hasContent(x,p) ∧ has-Commit(x,c) ∧ isConditionedTo(c,a)\
    \ ∧ atTime(x, t) → initiates(x,c) ∧ has-Debtor(c,r) ∧ hasCreditor(c,s) ∧ hascondition(c,p)\
    \ ∧ Acceptance(a) ∧ hasSignatory(a,r) ∧ hasAddressee(a,s) ∧ hasObject(a,p) ∧ atTime(c,\
    \ t)\n\n## <span id=\"page-6-0\"></span>3 Protocol Description\n\nAs mentioned\
    \ in the introduction, our proposal promotes to describe standard protocols using\
    \ Semantic Web technology. We use STS as models of protocols. More specifically,\
    \ we restrict to deterministic STS (i.e. if (s, l, s ′ ) ∈ T and (s, l, s ′′)\
    \ ∈ T then s ′ = s ′′). In order to represent protocols using OWL-DL, we have\
    \ defined five different classes: Protocol, State, Transition, Fluent and Commitment,\
    \ which respectively represent protocols, states, transitions in protocols, fluents\
    \ and commitments associated to states.\n\nWe model those class descriptions with\
    \ the following guidelines: A state has fluents that hold in that point and transitions\
    \ that go out of it. A transition is labelled by the communication act that is\
    \ sent and is associated to the state that is reached with that transition. A\
    \ fluent has a time stamp that signals the moment it was initiated. An actual\
    \ conversation following a protocol is an individual of the class Protocol. Following\
    \ are some of the ontology axioms:\n\n```\nProtocol ≡ ∃hasInitialState.State ⊓\n\
    \             ∀hasInitialState.State\n     State ≡ ∀hasTransition.Transition ⊓\n\
    \             ∃hasFluent.Fluent ⊓\n             ∀hasFluent.Fluent\nTransition\
    \ ≡ =1 hasCommAct.CommunicationAct ⊓\n             =1.hasNextState.State\nFinalState\
    \ ⊑ State ⊓\n             ∀hasFluent.(Fluent ⊓ ¬Commitment)\n    Fluent ⊑ =1 atTime\n\
    ```\n\n```\nCommitment ⊑ Fluent ⊓ =1 hasDebtor.Actor ⊓\n                     \
    \   =1 hasCreditor.Actor ⊓\n                        =1 hasCondition.Fluent\nConditionalCommitment\
    \ ⊑ Fluent ⊓ =1 hasDebtor.Actor ⊓\n                        =1 hasCreditor.Actor\
    \ ⊓\n                        =1 hasCondition.Fluent ⊓\n                      \
    \  =1 isConditionedTo.Fluent\n```\nThe OWL-DL description of protocols reflects\
    \ their static features and can be used to discover structural relationships between\
    \ protocols. For instance, in Fig. [1](#page-7-0) we show a simple protocol where\
    \ agent A asks for time to agent B. The protocol description appears in the following:\n\
    \n![](_page_7_Figure_3.jpeg)\n\n<span id=\"page-7-0\"></span>Fig. 1. Protocol\
    \ AskTime.\n\n```\nAsktime ≡ Protocol ⊓ ∃hasInitialState.S0\n         S0 ≡ State\
    \ ⊓ ∃hasTransition.T01 ⊓ ∃hasFluent.F0\n         S1 ≡ State ⊓ ∃hasTransition.T12\
    \ ⊓ ∃hasFluent.F1\n         S2 ≡ State ⊓ ∃hasTransition.T23 ⊓ ∃hasFluent.F2\n\
    \         S3 ≡ FinalState ⊓ ∃hasFluent.F3\n        T01 ≡ Transition ⊓ ∃hasCommAct.TimeRequest\
    \ ⊓ ∃hasNextState.S1\n        T12 ≡ Transition ⊓ ∃hasCommAct.TimeAccept ⊓ ∃hasNextState.S2\n\
    \        T23 ≡ Transition ⊓ ∃hasCommAct.TimeInform ⊓ ∃hasNextState.S3\nTimeRequest\
    \ ≡ Request ⊓ =1 hasContent.TimeReq\nTimeAccept ≡ Accept ⊓ =1 hasContent.TimeReq\n\
    TimeInform ≡ Responsive ⊓ =1 hasContent.TimeInfo ⊓ =1 inReplyTo.TimeRequest\n\
    ```\nHowever, dealing only with structural relationships is too rigid if a flexible\
    \ interoperation among agents that use different standard protocols is promoted.\
    \ For that reason, we propose to consider what we call protocol traces.\n\nDefinition\
    \ 4. A protocol trace is a sequence of time stamped fluents sorted in increasing\
    \ order of time stamp.\n\nNotice that protocol traces are defined in terms of\
    \ the semantics of communication acts, not in terms of the communication acts\
    \ themselves; in contrast with many other related works (see section [4\\)](#page-11-0)\
    \ that consider messages as atomic acts without considering their content, neither\
    \ their semantics.\n\nDuring a simulation of a protocol run we apply the SWRL\
    \ rules that encode the semantics of the communication acts (see section [2.2\\\
    )](#page-5-0) appearing in the run. Then, we can consider the sorted set of time\
    \ stamped fluents that hold at a final state of the protocol. That set represents\
    \ the effects of the protocol run. Following we show an example of the application\
    \ of the rules to a run of protocol AskTime in Fig. [1.](#page-7-0)\n\nIn Fig.\
    \ [2](#page-8-0) we show which are the fluents associated to the states of the\
    \ protocol and how they vary as a consequence of the communication acts that are\
    \ sent and the rules described in section [2.2.](#page-5-0) We depart from a situation\
    \ where the set of flu-\n\n![](_page_8_Figure_2.jpeg)\n\n<span id=\"page-8-0\"\
    ></span>Fig. 2. Protocol fluents\n\nents is empty (F0). When the TimeRequest message\
    \ is sent, due to the predicate Initiates(Request(s, r, P), CC(r, s, accept(r,s,P),\
    \ P), t) the conditional commitment CC1 is initiated, which states that if agent\
    \ B accepts to give information about the time, then it will be committed to do\
    \ so; t<sup>1</sup> is the time stamp associated. By convention we sort time stamps\
    \ by their subindexes, that is: t<sup>i</sup> < t<sup>j</sup> if i < j. Then agent\
    \ B agrees to respond by sending the TimeAccept message, and due to the predicate\
    \ Initiates(Accept(s,r,P), accept(s,r,P), t), the fluent accept(B, A, TimeReq)\
    \ is initiated at time t2. At this point, Rule 2 (see section [2.2\\)](#page-5-0)\
    \ can be applied, so CC1 is terminated and the base commitment C1 is initiated\
    \ at time t3. Finally, agent B sends the TimeInform message, and because of the\
    \ predicates Initiates(Responsive(s,r,P, RA), P, t) and Terminates(Responsive(s,r,P,\
    \ RA), C(s,r,RA), t), C1 is terminated and a new fluent, TimeInfo, is initiated\
    \ at time t4. So, at this point we can say that the fluents that hold at the final\
    \ state of the protocol are (accept(B, A, TimeReq), t2) and (TimeInfo, t4).\n\n\
    Then, we say that the protocol trace [(accept(B, A, TimeReq), t2), (TimeInfo,\
    \ t4)] is generated by the protocol. We denote T (A) to the set of all protocol\
    \ traces generated by a protocol A.\n\nNow, we proceed with the definitions of\
    \ relationships between protocols we are considering. Our relationships are not\
    \ structure-based but effect-based. Intuitively, two protocols are equivalent\
    \ if the same effects take place in the same relative order. Runs of a protocol\
    \ are made up of communication acts, and fluents are the effects they leave.\n\
    \nDefinition 5. Protocol A is equivalent to protocol B if T (A) = T (B).\n\nSometimes,\
    \ a protocol is defined by restrictions on the allowable communication acts at\
    \ some states of a more general protocol. In those situations the application\
    \ of those restrictions is reflected in the corresponding effects.\n\nDefinition\
    \ 6. Protocol A is a restriction of protocol B if T (A) ⊂ T (B).\n\nProtocols\
    \ for specific Information Systems may use specialized communication acts. Specialization\
    \ can also be applied also to domain actions that can be represented by specialized\
    \ fluents.\n\nDefinition 7. A protocol trace t is a specialization of a protocol\
    \ trace s, written t≪s, if ∀i. t(i) ⊑ s(i) in an ontology of fluents.\n\nDefinition\
    \ 8. Protocol A is a specialized-equivalent of protocol B if ∀t ∈ T (A). ∃s ∈\
    \ T (B). t≪s and ∀s ∈ T (B). ∃t ∈ T (A). t≪s.\n\nDefinition 9. Protocol A is a\
    \ specialized-restriction of protocol B if ∀t ∈ T (A). ∃s ∈ T (B). t≪s.\n\nNotice\
    \ that all those relationships can be easily discovered by straightforward algorithms\
    \ supported by OWL-DL reasoners. Those reasoners deal with the ontology descriptions\
    \ and rule engines that consider our semantic rules for generating protocol traces.\n\
    \nMoreover, sometimes we may be interested in comparing protocol traces independently\
    \ of time stamps. That is, we may be interested in knowing if a protocol produces\
    \ the same fluents as another, in whatever order. For example, in Fig. [3](#page-9-0)\
    \ we show two protocols that can be used to ask for information related to the\
    \ vital signs temperature and pulse. In fact, for that purpose it is irrelevant\
    \ the order in which the two requests are done.\n\n![](_page_9_Figure_8.jpeg)\n\
    \n<span id=\"page-9-0\"></span>Fig. 3. Specialization of protocols.\n\nIn protocol\
    \ P1 we can find a general protocol, in which agent A makes a request about the\
    \ temperature using the communication act RequestTemp for that purpose. Then,\
    \ agent B accepts and replies with a TempInform message, which is used to give\
    \ information about the temperature. Once agent A receives this information, it\
    \ asks agent B information about the pulse using a RequestPulse. Finally agent\
    \ B accepts and replies with a PulseInform message and the final\n\nstate F is\
    \ reached. On the other hand, in protocol P2 we can find the specific protocol\
    \ used by the agents of a specific system, called Aingeru[2](#page-10-0) , to\
    \ exchange information about vital signs. Protocol P2 may be a specialization\
    \ of an standard protocol. First, agent A asks for the pulse, using the communication\
    \ act A-RequestPulse. Then, agent B accepts and responds to the request using\
    \ the A-PulseInform message. Next, agent A sends a A-RequestTemp message to ask\
    \ about the temperature. Finally, agent B accepts and replies using the A-TempInform\
    \ message and reaches state F'. Following we show the OWL specification for the\
    \ communication acts used in this example.\n\nRequestTemp ≡ Request ⊓ =1 hasContent.TempReq\
    \ AcceptTemp ≡ Accept ⊓ =1 hasContent.TempReq TempInform ≡ Responsive ⊓ =1 hasContent.TempInfo\
    \ ⊓ =1 inReplyTo.RequestTemp RequestPulse ≡ Request ⊓ =1 hasContent.PulseReq AcceptPulse\
    \ ≡ Accept ⊓ =1 hasContent.PulseReq PulseInform ≡ Responsive ⊓ =1 hasContent.PulseInfo\
    \ ⊓ =1 inReplyTo.RequestPulse A-RequestTemp ≡ RequestTemp ⊓ =1 theSystem.Aingeru\
    \ ⊓ =1 hasContent.A-TempReq A-AcceptTemp ≡ AcceptTemp ⊓ =1 theSystem.Aingeru ⊓\
    \ =1 hasContent.A-TempReq A-TempInform ≡ TempInform ⊓ =1 theSystem.Aingeru ⊓ =1\
    \ hasContent.A-TempInfo ⊓ =1 inReplyTo.A-RequestTemp A-RequestPulse ≡ RequestPulse\
    \ ⊓ =1 theSystem.Aingeru ⊓ =1 hasContent.A-PulseReq A-AcceptPulse ≡ AcceptPulse\
    \ ⊓ =1 theSystem.Aingeru ⊓ =1 hasContent.A-PulseReq A-PulseInform ≡ PulseInform\
    \ ⊓ =1 theSystem.Aingeru ⊓ =1 hasContent.A-PulseInfo ⊓ =1 inReplyTo.A-RequestPulse\n\
    \nNotice that every communication act in protocol P2 is a subclass of its counterpart\
    \ in protocol P1 (i.e. A-RequestPulse ⊑ RequestPulse, etc.) and correspondingly\
    \ A-PulseInfo ⊑ PulseInfo, etc., is also satisfied.\n\nThrough a reasoning procedure\
    \ analogous to that explained with the example of the AskTime protocol, we get\
    \ the following sets of protocol traces:\n\nT (P1) = {[(accept(B, A, TempReq),\
    \ t2), (TempInfo, t4), (accept(B, A, PulseReq), t6), (PulseInfo, t8)] }\n\nT (P2)\
    \ = {[(accept(B, A, A-PulseReq), t2), (A-PulseInfo, t4), (accept(B, A, A-TempReq),\
    \ t6), (A-TempInfo, t8)] }\n\nEven if the structure of the protocols is not exactly\
    \ the same, we can relate both protocols by a shallow notion of specialization\
    \ from the following point of view. If we get abstracted from time stamps, we\
    \ can see protocol traces as multi-sets. Let us denote abstract-time(t) to the\
    \ multi-set formed by the fluents appearing in the protocol trace t, without any\
    \ time stamp associated. Now, we define\n\nS(A) = {abstract-time(t)|t ∈ T (A)}\n\
    \nThen, we are in condition to define analogous relationships to the previous\
    \ five, but in a shallow mood.\n\nDefinition 10. 1. Protocol A is shallow-equivalent\
    \ to protocol B if S(A) = S(B).\n\n<span id=\"page-10-0\"></span><sup>2</sup>\
    \ The A- prefix intends to label the AINGERU terminology\n\n- 2. Protocol A is\
    \ a shallow-restriction of protocol B if S(A) ⊂ S(B).\n- 3. A protocol trace t\
    \ is a shallow-specialization of a protocol trace s, written t ≪<sup>s</sup> s,\
    \ if there is a map φ from abstract-time(t) to abstract-time(s) such that ∀f ∈\
    \ abstract-time(t).f ⊑ φ(f) in an ontology of fluents.\n- 4. Protocol A is a shallow-specialized-equivalent\
    \ of protocol B if ∀t ∈ S(A). ∃s ∈ S(B). t ≪<sup>s</sup> s and ∀s ∈ S(B). ∃t ∈\
    \ S(A). t ≪<sup>s</sup> s.\n- 5. Protocol A is a shallow-specialized-restriction\
    \ of protocol B if ∀t ∈ S(A). ∃s ∈ S(B). t ≪<sup>s</sup> s.\n\nFinally, using\
    \ our proposal, we can conclude that protocols P1 and P2 are shallow-specialized-equivalent,\
    \ although they use different communications acts and have different structure.\n\
    \n## <span id=\"page-11-0\"></span>4 Related Works\n\nAmong the different related\
    \ works that we can find in the specialized literature, the closer work is [\\\
    [11\\]](#page-13-10), where protocols are represented as transition systems and\
    \ subsumption and equivalence of protocols are defined with respect to three state\
    \ similarity funtions. We share some goals with that work, but the protocol description\
    \ formalism used by them is not considered in the paper and there is no references\
    \ to how protocol relationships are computed. In contrast, we describe protocols\
    \ with a description logic language and protocol relationships can be computed\
    \ by straightforward algorithms. It is worth mentioning that protocol relationships\
    \ considered in that paper deserve study in our framework.\n\nThe works of [\\\
    [12\\]](#page-13-11) and [\\[13\\]](#page-13-12) are quite similar one to each\
    \ other. Both capture the semantics of communication acts through agents' commitments\
    \ and represent communication protocols using a set of rules that operate on these\
    \ commitments. Moreover those rule sets can be compiled as finite state machines.\
    \ Nevertheless, they do not consider the study of relationships between protocols.\
    \ In addition, in [\\[14\\]](#page-13-13), protocols are also represented with\
    \ a set of rules with terms obtained from an ontology, but their main goal is\
    \ protocol development and, in order to reason about protocol composition, they\
    \ formalize protocols into the π-calculus. Then, equivalence through bisimulation\
    \ is the only process relationship considered. In [\\[15\\]](#page-13-14), they\
    \ also consider commitment protocols; however, their main focus is on combining\
    \ them with considerations of rationality on the enactment of protocols. Our proposal\
    \ could be complemented with their approach.\n\nAn alternative way to describe\
    \ finite state machines with a description logic language is to take advantage\
    \ of the relationship of that logic with Deterministic Propositional Dynamic Logic,\
    \ see [\\[16\\]](#page-13-15) for an example in the context of Web Services composition.\
    \ The approach of that paper is very different in purpose from ours. Their states\
    \ and transitions descriptions are not prepared to be confronted in a comparison.\
    \ In constrast, our state and transition descriptions are carefully modelled as\
    \ class descriptions such that semantics relationships between protocols can be\
    \ captured.\n\nAlso in the context of Web Services, state transition systems are\
    \ used in [\\[17\\]](#page-13-16) for representing dynamic behaviour of services\
    \ and they define some notions of compatibility and substitutability of services\
    \ that can be easily translated to the context of compatibility of protocols.\
    \ Relationships between their compatibility relations and our defined relationships\
    \ deserve study.\n\nIn [\\[18\\]](#page-13-17) protocols are defined as a set\
    \ of permissions and obligations of agents participating in the communication.\
    \ They use an OWL ontology for defining the terms of the specification language,\
    \ but their basic reasoning is made with an ad hoc reasoning engine. We share\
    \ their main goal of defining protocols in a general framework that allows reutilization.\
    \ Nevertheless, they do not consider relationships between protocols.\n\nThe problem\
    \ of determining if an agent's policy is conformant to a protocol is a very important\
    \ one, but we are not treating that topic in this paper. Nevertheless, the topic\
    \ is close to ours and it is worth mentioning the following papers that consider\
    \ different notions of conformance: In [\\[19\\]](#page-14-0), deterministic finite\
    \ state machines are the abstract models for protocols, which are described by\
    \ simple logic-based programs. Three levels of conformance are defined: weak,\
    \ exhaustive and robust. They consider communication acts as atomic actions, in\
    \ contrast to our semantic view. In [\\[20\\]](#page-14-1)a nondeterministic finite\
    \ state automata is used to support a notion of conformance that guarantees interoperabiliy\
    \ among agents conformant to a protocol. Their conformance notion considers the\
    \ branching structure of policies and protocols and applies a simulation-based\
    \ test. Communication acts are considered atomic actions, without considering\
    \ their semantics. In [\\[21\\]](#page-14-2), communication acts semantics is\
    \ described in terms of commitments but it is not used for the conformance notion.\
    \ A third different notion of conformance is defined and, moreover, it is proved\
    \ orthogonal to their proposed notions of coverage and interoperability.\n\nFinally,\
    \ [\\[22\\]](#page-14-3) and [\\[23\\]](#page-14-4) use finite state machines\
    \ and Petri nets, respectively, but without taking into account the meaning of\
    \ the communication acts interchanged, neither considering relationships between\
    \ protocols.\n\n## 5 Conclusions\n\nIncreasing machine-processable tasks in the\
    \ Web is a challenge considered at present. In this line we have presented in\
    \ this paper a proposal that favours the communication among agents that represent\
    \ to different Information Systems accessible through the Web. The main contributions\
    \ of the proposal are:\n\n- The management of the semantics aspects when dealing\
    \ with agent communication protocols.\n- The provision of the possibility of customizing\
    \ standard communication protocols and management of them.\n- The use of standard\
    \ Semantic Web tools to describe protocols.\n- The support for discovering different\
    \ kinds of relationships between protocols.\n\n## <span id=\"page-13-0\"></span>References\n\
    \n- <span id=\"page-13-1\"></span>1. FIPA: FIPA communicative act library specification\
    \ (July 2005) http://www.fipa.org/specs/fipa00037/SC00037J.html.\n- 2. Greenwood,\
    \ D., M.Lyell, A. Mallya, H.S.: The IEEE FIPA approach to integrating software\
    \ agents and web services. In: International Conference on Autonomous Agents and\
    \ Multiagent Systems AAMAS, Hawaii USA (2007) 14–18\n- <span id=\"page-13-2\"\
    ></span>3. Berm´udez, J., Go˜ni, A., Illarramendi, A., Bag¨u´es, M.I.: Interoperation\
    \ among agent-based information systems through a communication acts ontology.\
    \ Inf. Syst. 32(8) (2007) 1121–1144\n- <span id=\"page-13-4\"></span><span id=\"\
    page-13-3\"></span>4. Singh, M.P.: Agent Communication Languages: Rethinking the\
    \ Principles. IEEE Computer 31(12) (December 1998) 40–47\n- <span id=\"page-13-5\"\
    ></span>5. Singh, M.P.: A social semantics for agent communication languages.\
    \ In: Issues in Agent Communication, Springer-Verlag (2000) 31–45\n- <span id=\"\
    page-13-6\"></span>6. Austin, J.L., ed.: How to do things with words. Oxford University\
    \ Press (1962)\n- 7. Wooldridge, M.: Semantic Issues in the Verification of Agent\
    \ Comunication Languages. Journal of Autonomous Agents and Multi-Agent Systems\
    \ 3(1) (February 2000) 9–31\n- <span id=\"page-13-7\"></span>8. Venkatraman, M.,\
    \ Singh, M.P.: Verifying compliance with commitment protocols. Autonomous Agents\
    \ and Multi-Agent Systems 2(3) (1999) 217–236\n- <span id=\"page-13-8\"></span>9.\
    \ Fornara, N., Colombetti, M.: Operational specification of a commitment-based\
    \ agent communication language. In: AAMAS '02: Proceedings of the first international\
    \ joint conference on Autonomous agents and multiagent systems, New York, NY,\
    \ USA, ACM Press (2002) 536–542\n- <span id=\"page-13-9\"></span>10. Shanahan,\
    \ M.: The event calculus explained. Lecture Notes in Computer Science 1600 (1999)\
    \ 409–430\n- <span id=\"page-13-11\"></span><span id=\"page-13-10\"></span>11.\
    \ Mallya, A.U., Singh, M.P.: An algebra for commitment protocols. Autonomous Agents\
    \ and Multi-Agent Systems 14(2) (2007) 143–163\n- 12. Yolum, P., Singh, M.P.:\
    \ Flexible protocol specification and execution: Applying event calculus planning\
    \ using commitments. In: Proceedings of the 1st International Joint Conference\
    \ on Autonomous Agents and MultiAgent Systems (AA-MAS), ACM Press (July 2002)\
    \ 527–534\n- <span id=\"page-13-12\"></span>13. Fornara, N., Colombetti, M.: Defining\
    \ interaction protocols using a commitmentbased agent communication language.\
    \ In: AAMAS '03: Proceedings of the second international joint conference on Autonomous\
    \ agents and multiagent systems, New York, NY, USA, ACM Press (2003) 520–527\n\
    - <span id=\"page-13-13\"></span>14. Desai, N., Mallya, A.U., Chopra, A.K., Singh,\
    \ M.P.: Interaction protocols as design abstractions for business processes. IEEE\
    \ Trans. Softw. Eng. 31(12) (2005) 1015– 1027\n- <span id=\"page-13-14\"></span>15.\
    \ Yolum, P., Singh, M.: Enacting protocols by commitment concession. In: International\
    \ Conference on Autonomous Agents and Multiagent Systems AAMAS, Hawaii USA (2007)\
    \ 116–123\n- <span id=\"page-13-15\"></span>16. Berardi, D., Calvanese, D., Giacomo,\
    \ G.D., Lenzerini, M., Mecella, M.: Automatic service composition based on behavioral\
    \ descriptions. Int. J. Cooperative Inf. Syst. 14(4) (2005) 333–376\n- <span id=\"\
    page-13-16\"></span>17. Bordeaux, L., Sala¨un, G., Berardi, D., Mecella, M.: When\
    \ are two web services compatible? In: TES. (2004) 15–28\n- <span id=\"page-13-17\"\
    ></span>18. Kagal, L., Finin, T.: Modeling conversation policies using permissions\
    \ and obligations. Autonomous Agents and Multi-Agent Systems 14(2) (2007) 187–206\n\
    - <span id=\"page-14-1\"></span><span id=\"page-14-0\"></span>19. Endriss, U.,\
    \ Maudet, N., Sadri, F., Toni, F.: Logic-based agent communication protocols.\
    \ In: Workshop on Agent Communication Languages. (2003) 91–107\n- <span id=\"\
    page-14-2\"></span>20. Baldoni, M., Baroglio, C., Martelli, A., Patti, V.: A priori\
    \ conformance verification for guaranteeing interoperability in open environments.\
    \ In: ICSOC. (2006) 339–351\n- <span id=\"page-14-3\"></span>21. Chopra, A.K.,\
    \ Singh, M.P.: Producing compliant interactions: Conformance, coverage, and interoperability.\
    \ In: DALT. (2006) 1–15\n- 22. d'Inverno, M., Kinny, D., Luck, M.: Interaction\
    \ protocols in agentis. In: In Proceedings of the Third International Conference\
    \ on Multi-Agent Systems (ICMAS98). (1998) 261–268\n- <span id=\"page-14-4\"></span>23.\
    \ Mazouzi, H., Seghrouchni, A.E.F., Haddad, S.: Open protocol design for complex\
    \ interactions in multi-agent systems. In: AAMAS '02: Proceedings of the first\
    \ international joint conference on Autonomous agents and multiagent systems,\
    \ New York, NY, USA, ACM Press (2002) 517–526"
