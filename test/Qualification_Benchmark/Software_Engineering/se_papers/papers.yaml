papers:
- title: Automated Invariant Generation for Solidity Smart Contracts
  abstract: 'Smart contracts are computer programs running on blockchains to automate
    the

    transaction execution between users. The absence of contract specifications

    poses a real challenge to the correctness verification of smart contracts.

    Program invariants are properties that are always preserved throughout the

    execution, which characterize an important aspect of the program behaviors. In

    this paper, we propose a novel invariant generation framework, INVCON+, for

    Solidity smart contracts. INVCON+ extends the existing invariant detector,

    InvCon, to automatically produce verified contract invariants based on both

    dynamic inference and static verification. Unlike INVCON+, InvCon only produces

    likely invariants, which have a high probability to hold, yet are still not

    verified against the contract code. Particularly, INVCON+ is able to infer more

    expressive invariants that capture richer semantic relations of contract code.

    We evaluate INVCON+ on 361 ERC20 and 10 ERC721 real-world contracts, as well as

    common ERC20 vulnerability benchmarks. The experimental results indicate that

    INVCON+ efficiently produces high-quality invariant specifications, which can

    be used to secure smart contracts from common vulnerabilities.'
  url: http://arxiv.org/abs/2401.00650v1
  keywords: Smart contract, invariant detection.
  document: "# Automated Invariant Generation for Solidity Smart Contracts\n\nYe Liu,\
    \ Chengxuan Zhang, Yi Li Nanyang Technological University, Singapore {ye.liu,\
    \ chengxua001, yi li}@ntu.edu.sg\n\n*Abstract*—Smart contracts are computer programs\
    \ running on blockchains to automate the transaction execution between users.\
    \ The absence of contract specifications poses a real challenge to the correctness\
    \ verification of smart contracts. Program invariants are properties that are\
    \ always preserved throughout the execution, which characterize an important aspect\
    \ of the program behaviors. In this paper, we propose a novel invariant generation\
    \ framework, INVCON+, for Solidity smart contracts. INVCON+ extends the existing\
    \ invariant detector, InvCon, to automatically produce *verified* contract invariants\
    \ based on both dynamic inference and static verification. Unlike INVCON+, InvCon\
    \ only produces *likely* invariants, which have a high probability to hold, yet\
    \ are still not verified against the contract code. Particularly, INVCON+ is able\
    \ to infer more expressive invariants that capture richer semantic relations of\
    \ contract code. We evaluate INVCON+ on 361 ERC20 and 10 ERC721 real-world contracts,\
    \ as well as common ERC20 vulnerability benchmarks. The experimental results indicate\
    \ that INVCON+ efficiently produces high-quality invariant specifications, which\
    \ can be used to secure smart contracts from common vulnerabilities.\n\n*Index\
    \ Terms*—Smart contract, invariant detection.\n\n# I. INTRODUCTION\n\nSmart contracts\
    \ are computer programs that operate on blockchain networks. They are used to\
    \ facilitate the management of substantial financial assets and the automated\
    \ execution of agreements among multiple parties who lack inherent trust. Notably,\
    \ blockchain networks such as Ethereum [\\[1\\]](#page-13-0) and BSC [\\[2\\]](#page-13-1)\
    \ are widely recognized as leading platforms supporting smart contracts, with\
    \ applications spanning diverse domains such as supply-chain management, finance,\
    \ energy, games, and digital artworks. While smart contracts hold promise for\
    \ facilitating value transfer among users, those that deviate from their specifications\
    \ may harbor bugs or vulnerabilities. Numerous implementations of ERC20 contracts\
    \ diverge from common expectations, as exemplified by standard non-compliance\
    \ of ERC20 [\\[3\\]](#page-13-2), particularly concerning event emission, balance\
    \ updates, and the transaction fee mechanisms.\n\nEven well-established standard\
    \ ERC20 implementations exhibit inconsistencies [\\[4\\]](#page-13-3). The root\
    \ cause lies in the limited semantic specifications outlined in the ERC20 standard\
    \ proposal document [\\[5\\]](#page-13-4). Take the transfer function as an illustration\
    \ it is designed to move a specified amount of tokens from the sender to the recipient\
    \ while triggering the Transfer event and should throw an error if the sender\
    \ lacks adequate tokens for the transfer. Nevertheless, the ERC20 proposal provides\
    \ only simple textual descriptions of the function, leading to semantic disparities\
    \ across various ERC implementations and even\n\ndifferent versions of the same\
    \ implementation. For instance, the widely used ERC20 implementation from OpenZeppelin\
    \ initially did not permit a return value for the transfer function until a later\
    \ commit,[1](#page-0-0) causing incompatibility issues with renowned tokens like\
    \ BNB, as reported by the reputable security company SECBIT [\\[4\\]](#page-13-3).\
    \ In cases where a contract necessitates checking the return value of an external\
    \ call to a transfer function of ERC20 contracts, even if the transfer is successful,\
    \ it may revert due to the absence of a return value, resulting in compatibility\
    \ problems [\\[6\\]](#page-13-5). However, removing the return value check exposes\
    \ contracts to a potential vulnerability known as the *fake deposit attack* [\\\
    [7\\]](#page-13-6).\n\nEnsuring the correctness of smart contracts poses a significant\
    \ challenge, especially in the absence of contract specifications. On the one\
    \ hand, the documentation for most smart contracts is scant, with even widely\
    \ recognized smart contract libraries like OpenZeppelin [\\[8\\]](#page-13-7),\
    \ [\\[9\\]](#page-13-8) found to have errors and deficiencies in their documentation\
    \ [\\[10\\]](#page-13-9). On the other hand, the absence of contract specifications\
    \ hampers the widespread adoption of formal verification tools in the realm of\
    \ smart contracts. To address this issue, the commercial formal verification company\
    \ Certora[2](#page-0-1) has adopted a crowd sourcing approach—they hosted numerous\
    \ competitions on well-known bug bounty platforms, such as Code4Rena,[3](#page-0-2)\
    \ to engage third-party security experts in the formulation of contract specifications.\
    \ Yet, manual creation of formal specifications for smart contracts remains costly\
    \ and error-prune.\n\nMany automated techniques [\\[11\\]](#page-13-10), [\\[12\\\
    ]](#page-13-11) have been proposed to generate formal specifications in various\
    \ forms to support the testing, verification, and validation of software programs.\
    \ Among them, program invariants, which are enduring properties maintained throughout\
    \ program execution, inherently serve as excellent candidates for enhancing and\
    \ reinforcing program specifications. Program invariants have been used for vulnerability\
    \ detection [\\[13\\]](#page-13-12), conformance checking [\\[3\\]](#page-13-2),\
    \ runtime protection [\\[14\\]](#page-13-13), type checking [\\[15\\]](#page-13-14),\
    \ and formal verification [\\[16\\]](#page-13-15), [\\[17\\]](#page-13-16) for\
    \ smart contracts. Established tools, such as Daikon [\\[11\\]](#page-13-10),\
    \ can identify *likely* program invariants for Java programs through the execution\
    \ of their test cases. The process involves statistically inferring the invariants\
    \ that hold based on predefined templates, while discarding those refuted by the\
    \ data trace records. The complete historical transaction\n\n<span id=\"page-0-0\"\
    ></span><sup>1</sup>https://github.[com/OpenZeppelin/openzeppelin-solidity/commit/](https://github.com/OpenZeppelin/openzeppelin-solidity/commit/6331dd125d8e8429480b2630f49781f3e1ed49cd)\
    \ [6331dd125d8e8429480b2630f49781f3e1ed49cd](https://github.com/OpenZeppelin/openzeppelin-solidity/commit/6331dd125d8e8429480b2630f49781f3e1ed49cd)\n\
    \n<span id=\"page-0-1\"></span><sup>2</sup>https://www.certora.com/\n\n<span id=\"\
    page-0-2\"></span><sup>3</sup>https://code4rena.com/\n\ndata of smart contracts\
    \ is consistently stored on blockchains, encapsulating all execution data since\
    \ contract deployment, serving as a valuable data source for mining invariants.\n\
    \nIn our prior work, INVCON [\\[18\\]](#page-13-17) utilized Daikon to identify\
    \ *likely* invariants for smart contracts, all of which are primitive predicates\
    \ hold throughout the existing transaction histories. Moreover, Liu et al. [\\\
    [19\\]](#page-13-18) employed reinforcement learning to learn contract invariants\
    \ critical to safely performing arithmetic operations, with focus on preventing\
    \ integer overflow and underflow. Despite their usefulness, the correctness of\
    \ such inferred invariants remains unverified. In particular, an invariant which\
    \ holds in past transactions may not always hold in the future—this may be due\
    \ to the limited contract interactions observed in the transaction histories so\
    \ far.\n\nIn this paper, we expand upon INVCON to generate *verified* contract\
    \ invariants utilizing both dynamic inference and static verification. We introduce\
    \ a specialized invariant specification language tailored for Solidity smart contracts\
    \ and propose a novel approach for inferring high-quality verified invariants.\
    \ Specifically, we design a Houdini-like [\\[12\\]](#page-13-11) algorithm to\
    \ generate verified invariants for smart contracts. To address the explosion problem\
    \ in searching for richer invariant candidates, such as implications that prevail\
    \ in ERC20 and ERC721 [\\[20\\]](#page-13-19), [\\[21\\]](#page-13-20), [\\[22\\\
    ]](#page-13-21) specifications, we introduce an iterative and incremental process\
    \ for exploring these candidates on demand. We also apply control- and data-flow\
    \ analyses to eliminate meaningless candidates and further improve the invariant\
    \ generation efficiency. Our approach is implemented as an automated tool called\
    \ INVCON+. Through evaluation on 361 ERC20 contracts and 10 ERC721 real-world\
    \ Solidity contracts, we demonstrate that INVCON+ produces comprehensive contract\
    \ invariant specifications with no false positives. Furthermore, our analysis\
    \ of real-world vulnerable ERC20 contracts underscores the potential of INVCON+\
    \ in safeguarding these contracts through the application of mined invariant specifications.\n\
    \nIn summary, we make the following contributions:\n\n- We introduce a comprehensive\
    \ invariant specification language designed for expressing operational semantics\
    \ in Solidity smart contracts. This language enables logical operations on variables\
    \ of primitive types and commonly used data structures like structs, arrays, and\
    \ mappings in Solidity.\n- We present a unified framework for generating *verified*\
    \ invariants in Solidity smart contracts, combining dynamic invariant detection\
    \ and static invariant verification. Specifically, we develop a custom algorithm\
    \ inspired by the Houdini algorithm to verify invariants for smart contracts and\
    \ introduce an iterative process to derive a richer class of invariants.\n- Our\
    \ proposed approach is implemented in INVCON+, and its effectiveness is evaluated\
    \ on 361 ERC20 contracts and 10 ERC721 contracts, along with vulnerable ERC20\
    \ contracts involving 25 types of vulnerabilities. The results demonstrate that\
    \ INVCON+ can generate high-quality and comprehensive invariant specifications\
    \ for smart contracts. The dataset, raw results, and the prototype used in our\
    \ experiments are available online at: https://sites.google.[com/view/invconplus/.](https://sites.google.com/view/invconplus/)\n\
    \n<span id=\"page-1-1\"></span>a, v ∈ V ariable ::= address | uint | int | string\
    \ | bytes | byte | bool | array | mapping | struct{⃗v} f ∈ F unction ::= func(⃗a)\
    \ {⃗s} s ∈ Statement ::= v | v := e | if (e) {⃗s} else {⃗s}| call(⃗e) | return\
    \ e | require(e) | assert(e) | revert e ∈ Expr ::= v | *const* | e[e] | e.v |\
    \ e ▷◁ e\n\nFig. 1: The core grammar of the Solidity language.\n\nOrganizations.\
    \ The rest of the paper is organized as follows. Section [II](#page-1-0) provides\
    \ the background about smart contracts and invariant inference. Section [III](#page-2-0)\
    \ defines the invariant specification language. Then, Sect. [IV](#page-3-0) introduces\
    \ our invariant generation approach. Section [V](#page-5-0) describes our implementation\
    \ framework, INVCON+, and Sect. [VI](#page-6-0) demonstrates our evaluation results.\
    \ The related work is discussed in Sect. [VII](#page-11-0) and we conclude the\
    \ paper in Sect. [VIII.](#page-12-0)\n\n# II. BACKGROUND\n\n# <span id=\"page-1-0\"\
    ></span>*A. Solidity Smart Contracts*\n\nFigure [1](#page-1-1) presents the foundational\
    \ grammar of the Solidity language, with certain features, such as event emission,\
    \ intentionally excluded for the sake of clarity. Solidity encompasses various\
    \ primitive data types, including integer, string, and Boolean. Distinguishing\
    \ itself from other programming languages like Java, Solidity does not permit\
    \ floating-point numbers and incorporates a distinctive address type. This design\
    \ choice is rooted in the interaction pattern between contracts and blockchain\
    \ users, each possessing a unique address. Moreover, the majority of contracts\
    \ are developed with the primary goal of tokenizing digital assets.\n\nA Solidity\
    \ smart contract comprises a collection of state variables and a set of functions.\
    \ Statements within each function can take the form of variable assignments, conditional\
    \ statements, internal or external function calls, requirement or assertion statements,\
    \ and reversion or return statements. Notably, the *require* and *assert* statements\
    \ can be employed to enforce program invariants at runtime. In the realm of expressions,\
    \ ▷◁ denotes a binary operator encompassing {+, −, ∗, /, >, <, ≥, ≤, =, ̸=, ∧,\
    \ ∨}.\n\nSmart Contract Execution. The execution of a smart contract function\
    \ can be triggered by sending a blockchain transaction to the contract address.\
    \ Typically, each transaction incorporates one or more contract calls, potentially\
    \ leading to alterations in contract state variables unless the transaction undergoes\
    \ a reversion. To ease the discussion in this paper, we model a smart contract\
    \ SC as a tuple (⃗v, ⃗f), where ⃗v is a vector of state variables and ⃗f is a\
    \ list of public functions.\n\nDefinition II.1 (Contract Execution). Let Dom(v)\
    \ be the domain of a variable v and Dom(⃗v) = Q v∈⃗v Dom(v). Then, δ, δ′ ∈ Dom(⃗v)\
    \ represent two reachable contract states. For a function invocation f(⃗a), calling\
    \ function f with parameters values ⃗a, we define its high-level execution semantics\
    \ as a state transition δ f(⃗a) −−−→ δ ′ .\n\n<span id=\"page-2-1\"></span>const\
    \ ∈ Int, Bool, Addr, Str x ∈ FreeVar v ∈ Var e ∈ Expr ::= const | v | *old*(v)\
    \ | len(v) | SumMap(v) | e.x | e[x] | e ▷◁ e p ∈ Predicate ::= ⊥ | e | e =⇒ e\
    \ Statement ::= Requires p | Ensures p | ContractInv p\n\nFig. 2: The invariant\
    \ specification language.\n\nNote that since a contract execution is triggered\
    \ by a transaction recorded into a specific block of the blokchain, the parameter\
    \ values ⃗a also includes implicit transaction and block parameters, e.g., msg.sender\
    \ and block.number.\n\nTransaction Histories. The execution of a smart contract\
    \ is intricately linked to its transaction histories on the blockchain. The transaction\
    \ histories record every contract execution, capturing function calls, state transitions,\
    \ and modification to state variables from the contract deployment onward. It\
    \ encapsulates the evolution of the contract state, reflecting the cumulative\
    \ effect of all transactions. This historical traceability is fundamental for\
    \ auditing, debugging, and understanding the operational dynamics of smart contracts\
    \ on the blockchain.\n\n# *B. Invariant Inference*\n\nIn this paper, we aim to\
    \ mine *contract-level* and *functionlevel* invariant specifications.\n\nDefinition\
    \ II.2 (Function Pre/Post-conditions). Let f be a contract function, and predicates\
    \ p and q be the pre/postconditions of f, respectively, which can be represented\
    \ as a Hoare triple {p}f{q}. Then the following condition should be satisfied.\n\
    \n$$\\forall \\delta, \\forall \\vec{a} \\cdot \\delta \\vdash p \\land \\delta\
    \ \\xrightarrow{f(\\vec{a})} \\delta' \\implies \\delta' \\vdash q \\tag{1}$$\n\
    \nDefinition II.3 (Contract Invariant). Given a smart contract *SC*, its contract\
    \ invariant I is a predicate that must hold for any contract function execution.\
    \ More formally, we have ∀f ∈ SC · {I}f{I}.\n\nInvariant inference techniques\
    \ can be broadly categorized as static and dynamic. Static invariant inference\
    \ (e.g., Houdini [\\[12\\]](#page-13-11)) identifies function pre/post-conditions\
    \ and contract invariants that hold for any program execution. On the other hand,\
    \ dynamic invariant inference (e.g., Daikon [\\[11\\]](#page-13-10)) identifies\
    \ *likely* invariants that hold for specific contract executions (e.g., executions\
    \ of a test case).\n\nLet ∆ denotes a set of program executions {(δ, f(⃗a), δ′\
    \ )}, which bring the contract state from δ to δ ′ . The *likely* function pre/post-conditions\
    \ of f, i.e., {pˆ}f{qˆ}, hold for ∆ if ∀(δ, f(⃗a), δ′ ) ∈ ∆, δ |= ˆp ∧ δ f(⃗a)\
    \ −−−→ δ ′ =⇒ δ ′ |= ˆq. The *likely* contract invariants of a smart contract\
    \ is defined in a similar way, which is omitted here for brevity.\n\n# III. INVARIANT\
    \ SPECIFICATION LANGUAGE\n\n<span id=\"page-2-0\"></span>Figure [2](#page-2-1)\
    \ introduces our invariant specification language designed for Solidity smart\
    \ contracts. The language accommodates variables of four types: integer, Boolean,\
    \ address, and string, encompassing all primitive Solidity types illustrated\n\
    \nin Fig. [1.](#page-1-1) We facilitate two types of variables. The first, denoted\
    \ as v, pertains to function input parameters or contract state variables maintained\
    \ in the persistent storage of the blockchain. The second, denoted as x, is reserved\
    \ for free variables exclusively utilized to index structure members or items\
    \ within arrays and mappings. Each invariant predicate is expressed as either\
    \ a primitive logical expression or an implication expression. Furthermore, valid\
    \ specification statements encompass function-level precondition invariant predicates\
    \ (Requires) and postcondition invariant predicates (Ensures), and contract-level\
    \ invariant predicates (ContractInv).\n\nThe expressions within the language may\
    \ take the form of constants, variables, structure members, array items, and binary\
    \ expressions. The old(·) notation is employed to differentiate between the value\
    \ of a variable before entering the function and its value upon exiting the function,\
    \ while len(·) refers to the array length or mapping size. Additionally, the language\
    \ incorporates the widely used SumMap(·) operator for computing the arithmetic\
    \ sum over mapping items. The notation \"e ▷◁ e\" represents arithmetic or logical\
    \ binary operations, where the operator \"▷◁\" corresponds to the set defined\
    \ in Solidity as shown in Fig. [1.](#page-1-1)\n\nUtilizing this invariant language,\
    \ we can articulate a diverse range of function\n\nand contract invariants. To\
    \ exemplify its application, we present a simple illustration. In Fig. [3,](#page-3-1)\
    \ a basic ERC20 contract is depicted, featuring three state variables—totalSupply,\
    \ balances, allows (standing for allowances)—and a function, transferFrom. The\
    \ purpose of the transferFrom function is to transfer a specified amount of tokens\
    \ from the account addressed at from to another account at to. An extensively\
    \ studied ERC20 contract invariant of this example can be succinctly expressed\
    \ as: \"SumM ap(balances) = totalSupply\". This assertion signifies that the total\
    \ sum of items within the mapping variable balances must be equal to the value\
    \ of totalSupply. Additionally, the function pre/post-conditions can be articulated\
    \ as follows.\n\nRequires ⊥\n\n```\n⃝1 Ensures to ̸= 0 =⇒ allows[from][msg.sender]\
    \ =\n           old(allows[from][msg.sender]) − tokens\n```\n⃝2 Ensures to ̸=\
    \ 0 ∧ from ̸= to =⇒ balance[from] = old(balance[ from]) − tokens ∧ balance[to]\
    \ = old(balance[to]) + tokens\n\n$$\\begin{aligned} \\text{(\\text{\\textquotedblleft}\
    \ measures\\text{ }to} & to \\neq 0 \\land from = to \\implies balance[from] =\
    \ \\\\ & old(balance[from]) \\land balance[to] = old(balance[to]) \\end{aligned}$$\n\
    \nIn this instance, it is straightforward to ascertain that there are no preconditions\
    \ for the transferFrom function, assuming that all function preconditions are\
    \ primitive predicates. The function is characterized by three postconditions.\
    \ The first postcondition ⃝1 specifies that allows will undergo an update (Line\
    \ [11\\)](#page-3-1) when to is a non-zero address. Additionally, in cases where\
    \ from and to represent distinct addresses, the second postcondition ⃝2 dictates\
    \ that the balances should be adjusted accordingly (Lines [12–13\\)](#page-3-1).\
    \ Conversely, when from and to are identical, the last postcondition ⃝3 emphasizes\
    \ that the net effect on balance changes should be nullified. A detailed exploration\
    \ of how these invariants are mined will be provided in Sect. [IV-E.](#page-4-0)\n\
    \n```\n1 contract ERC20 {\n2 // state variables\n3 uint totalSupply;\n4 mapping(address=>uint)\
    \ balances;\n5 mapping(address=>mapping(address=>uint)) allows;\n6 ...\n7 function\
    \ transferFrom(address from, address to,\n   ,→ uint tokens) public returns (bool)\
    \ {\n8 if (to == address(0)){\n9 return false;\n10 }\n11 allows[from][msg.sender]\
    \ =\n     ,→ allows[from][msg.sender].sub(tokens);\n12 balances[from] = balances[from].sub(tokens);\n\
    13 balances[to] = balances[to].add(tokens);\n14 return true;\n15 }\n16 }\n```\n\
    ![](_page_3_Figure_2.jpeg)\n\n# IV. INVARIANT GENERATION APPROACH\n\n<span id=\"\
    page-3-0\"></span>In this section, we present our algorithm for generating verified\
    \ invariants in smart contracts and elaborate on the techniques employed to infer\
    \ implication invariants. For simplicity in presentation, we use the term \"invariants\"\
    \ to collectively denote both function pre/post-conditions and contract invariants\
    \ when explicit characterization is unnecessary.\n\n# *A. Algorithm*\n\nAlgorithm\
    \ [1](#page-3-2) outlines our approach to invariant generation. The algorithm\
    \ takes a smart contract SC , a sequence of contract transactions T, and a set\
    \ of invariant templates Q as input. The output, denoted as Invs, comprises a\
    \ set of *verified* invariants, encompassing both primitive and implication invariants.\n\
    \nIn this algorithm, Invs is initialized as an empty set (Line [1\\)](#page-3-3).\
    \ Subsequently, we initialize a set C that encompasses all potential invariant\
    \ candidates under the given input (Line [2\\)](#page-3-4), similar to Daikon's\
    \ initialization process [\\[11\\]](#page-13-10), which instantiates all the parameterized\
    \ invariant templates with concrete contract state variables and function input\
    \ variables. For example, \"X = Y \" is a binary equation template where X and\
    \ Y are placeholders that can be filled by two concrete variables: v<sup>x</sup>\
    \ and v<sup>y</sup> whenever Dom(vx) ≡ Dom(vy). It is important to note that here\
    \ C excludes implication invariant candidates due to the exponential complexity\
    \ of traversing all implication candidates. Instead, implication invariants will\
    \ be generated on demand. Moreover, the execution trace set ∆ is initialized as\
    \ an empty set (Line [3\\)](#page-3-5).\n\nThe algorithm processes the transaction\
    \ histories to extract corresponding execution traces. For each transaction t<sup>i</sup>\
    \ , the algorithm parses it to extract the invoked function f and parameters values\
    \ ⃗a (Line [5\\)](#page-3-6). Additionally, the old and present contract states\
    \ (i.e., values of the contract state variables), denoted as δ and δ ′ , respectively,\
    \ are recorded. The tuple (δ, f(⃗a), δ ′ ) is added to the execution trace set\
    \ ∆ (Line [6\\)](#page-3-7).\n\nNext, the algorithm executes the dynamic invariant\
    \ detection procedure INVDETECT (Line [8\\)](#page-3-8) to obtain two classes\
    \ of invariant candidates:\n\n- Clikely, likely invariant candidates that hold\
    \ for the entire transaction histories.\n- Cpartial, partially supported invariant\
    \ candidates that hold for a subset of transaction histories.\n\n# Algorithm 1:\
    \ Contract Invariant Inference\n\n```\nInputs : SC = {⃗v, ⃗f}, where each element\
    \ vi ∈ ⃗v is a\n            contract state variable and each element fi ∈ ⃗f is\
    \ a\n            public contract function;\n           : T = {ti|1 ≤ i ≤ n}, where\
    \ each element ti is a\n            contract transaction;\n           : Q, a set\
    \ of invariant templates.\n  Outputs :Invs, a set of verified invariants.\n1 Invs\
    \ := ∅;\n2 C := INITIALIZECANDIDATES(⃗v, ⃗f, Q) ; //primitive\n    candidates\n\
    3 ∆ := ∅ ; //execution trace set\n4 foreach ti ∈ T do\n5 (δ, f(⃗a), δ′\n     \
    \           ) ← PARSE(ti) ;\n6 ∆ ← ∆ ∪ (δ, f(\n                     −→a ), δ′\n\
    \                           );\n7 end foreach\n8 Clikely, Cpartial ←INVDETECT\
    \ (∆, C);\n9 Invs ← STATICINFER(Clikely) ;\n10 Cimp ← FINDIMPLICATIONS(Clikely\
    \ \\ Invs, Cpartial) ;\n   //implication candidates\n11 while Cimp ̸= ∅ do\n12\
    \ Invs ← Invs ∪ STATICINFER(Cimp) ;\n13 Cimp ← WEAKENIMPLICATIONS(Cimp \\ Invs);\n\
    14 end while\n15 return Invs\n```\n<span id=\"page-3-17\"></span><span id=\"page-3-16\"\
    ></span><span id=\"page-3-15\"></span><span id=\"page-3-14\"></span><span id=\"\
    page-3-13\"></span><span id=\"page-3-12\"></span><span id=\"page-3-11\"></span><span\
    \ id=\"page-3-10\"></span><span id=\"page-3-8\"></span><span id=\"page-3-7\"></span>\n\
    $$\\begin{array}{c} \\bot\\\\ C\\_{imp} := \\{ (\\eta \\implies \\tau) \\mid \\\
    eta, \\tau \\in C\\_{likelihood} \\mid Invs \\cup C\\_{partial}, \\eta \\neq \\\
    tau \\} \\end{array} \\text{Int}$$\n\n$$(\\eta \\implies \\tau) \\in C\\_{imp}\
    \ \\qquad \\begin{array}{c} \\forall a \\in vars(\\eta), \\forall b \\in vars(\\\
    tau). \\\\ \\neg dep(a, b) \\end{array} \\qquad \\begin{array}{c} \\text{Delete}\
    \ \\\\ \\neg dep(a, b) \\end{array} \\qquad \\begin{array}{c} \\text{Delete} \\\
    end{array}$$\n\n$$\\begin{array}{c} C\\_{imp} \\leftarrow C\\_{imp} \\mid (\\\
    eta \\implies \\tau) \\end{array} \\qquad \\begin{array}{c} \\text{Delete} \\\
    end{array}$$\n\n$$\\text{Fig. 4: FINDIMPLICATION}$$\n\nSubsequently, a primitive\
    \ invariant inference technique, detailed in Sect. [IV-B,](#page-3-9) is applied\
    \ to infer the standing invariants out of Clikely, and all the verified invariants\
    \ are included in Invs (Line [9\\)](#page-3-10). The unverified likely invariant\
    \ candidates, Clikely \\ Invs, and Cpartial are used to derive implication candidates\
    \ assigned to Cimp (Line [10\\)](#page-3-11) via FINDIMPLICATIONS, which will\
    \ be detailed in Sect. [IV-C.](#page-4-1) Additionally, it is important to note\
    \ that the found implications may not always hold. An iterative process is in\
    \ place to validate these implications (Line [12\\)](#page-3-12) or weaken these\
    \ implications via WEAKENIMPLICATIONS (Line [13\\)](#page-3-13) to identify new\
    \ ones. This iterative process continues until all valid candidates are examined\
    \ (Line [11\\)](#page-3-14). Finally, the algorithm returns Invs, which includes\
    \ all the correctly mined invariants from transaction histories (Line [15\\)](#page-3-15).\n\
    \n# <span id=\"page-3-9\"></span>*B. Primitive Invariant Inference*\n\nAlgorithm\
    \ [2](#page-4-2) illustrates our Houdini-like algorithm to infer verified primitive\
    \ invariants from the candidates mined from contract transaction histories. First,\
    \ we enable all the candidates in SC via contract instrumentation (Line [1\\)](#page-4-3);\
    \ each candidate is explicitly labeled by the added keywords, e.g., ContractInv\
    \ for contract invariant, Requires for function precondition, and Ensures for\
    \ function postcondition. Next, we invoke a modular verifier to statically verify\
    \ these enabled candidates (Line [3\\)](#page-4-4), i.e., verifying each function\
    \ in isolation where all the corresponding candidates are examined against the\
    \ function\n\n$$\\frac{\\bot}{C\\_{imp}^{\\circ} := \\emptyset} \\text{ limit}$$\n\
    \n<span id=\"page-4-9\"></span>(η<sup>1</sup> =⇒ τ ),(η<sup>2</sup> =⇒ τ ) ∈ Cimp\
    \ \\ Invs η<sup>1</sup> ∧ η<sup>2</sup> ̸≡ f alse Append-1 Cˆimp ← Cˆimp ∪ (η<sup>1</sup>\
    \ ∧ η<sup>2</sup> =⇒ τ )\n\n(η =⇒ τ1),(η =⇒ τ2) ∈ Cimp \\ Invs τ<sup>1</sup> ∨\
    \ τ<sup>2</sup> ̸≡ true Append-2 Cˆimp ← Cˆimp ∪ (η =⇒ τ<sup>1</sup> ∨ τ2)\n\n\
    Fig. 5: WEAKENIMPLICATIONS.\n\n# Algorithm 2: STATICINFER(Candidates)\n\n<span\
    \ id=\"page-4-7\"></span><span id=\"page-4-6\"></span><span id=\"page-4-4\"></span><span\
    \ id=\"page-4-3\"></span><span id=\"page-4-2\"></span>\n\n| 1 Instrument SC to\
    \ enable each candidate from Candidates; |  |  |  |  |\n|-----------------------------------------------------------|--|--|--|--|\n\
    | 2 while true do                                           |  |  |  |  |\n| result\
    \ = MODULARVERIFY(SC) ;                              |  |  |  |  |\n| if result\
    \ = CORRECT then<br>4                             |  |  |  |  |\n| return enabled\
    \ candidates ; //verified<br>5               |  |  |  |  |\n| invariants     \
    \                                           |  |  |  |  |\n| else if result =\
    \ INCORRECT due to failed candidate c<br>6 |  |  |  |  |\n| then             \
    \                                         |  |  |  |  |\n| disable c in SC;<br>7\
    \                                     |  |  |  |  |\n| else<br>8             \
    \                                    |  |  |  |  |\n| raise Error ; //INCORRECT\
    \ due to failed<br>9              |  |  |  |  |\n| assertion in SC           \
    \                                |  |  |  |  |\n| end if<br>10               \
    \                               |  |  |  |  |\n| 11 end while                \
    \                              |  |  |  |  |\n|                              \
    \                             |  |  |  |  |\n\n<span id=\"page-4-8\"></span><span\
    \ id=\"page-4-5\"></span>implementation. When there is a failed invariant candidate\
    \ c violating the verification condition, c will be disabled in SC (Line [7\\\
    )](#page-4-5). This process will continue until all the enabled candidates are\
    \ verified successfully (Line [4\\)](#page-4-6) and then returned (Line [5\\)](#page-4-7).\
    \ Particularly, whenever there is a failed assertion in SC, i.e., a violated condition\
    \ e in the assert(e) statement, the algorithm terminates with an error raised\
    \ (Line [9\\)](#page-4-8). This happens in Solidity contracts, because assert(e)\
    \ is often misused to replace require(e) that enforces program requirements due\
    \ to their similar effects on transaction reversion. For smart contracts without\
    \ failed assertions, the verified invariants is a maximal subset of the candidates\
    \ whose conjunction is an inductive invariant.\n\n# <span id=\"page-4-1\"></span>*C.\
    \ Implication Invariant Inference*\n\nFigures [4](#page-3-16) and [5](#page-4-9)\
    \ illustrate the two procedures for identifying implication candidates, respectively.\
    \ In Fig. [4,](#page-3-16) FINDIMPLICA-TIONS employs two straightforward inference\
    \ rules. The first rule explores all the potential implication candidates from\
    \ the unverified likely invariants Clikely \\ Invs and partial invariant candidates\
    \ Cpartial, including them in Cimp. An implication invariant takes the form of\
    \ η =⇒ τ , where η and τ comes from the existing the unverified and partial invariant\
    \ candidates.\n\nHowever, not all of the implication candidates constructed this\
    \ way are relevant in terms of the contract semantics. An implication can possibly\
    \ hold (i.e., relevant) if its precondition and postcondition align with the data/control-flow\
    \ of the contracts, and irrelevant implications should be discarded. The notation\
    \ vars(p) represents variables appearing in an invariant predicate p; for instance,\
    \ vars(p) = {from, to} when p is \"from ̸= to\". Additionally, dep(a, b) denotes\
    \ whether variable a depends on variable b in terms of control-flow or data-flow\
    \ in smart contract functions. To determine the valid implications, we leverage\
    \ the well-known static analysis tool Slither [\\[23\\]](#page-13-22) to trace\
    \ data-flow and control-flow in smart contract functions. Therefore, in Fig. [4,](#page-3-16)\
    \ a *Delete* rule is applied to eliminate implications that do not adhere to the\
    \ data-flow and controlflow relationship. This rule is iteratively applied until\
    \ no further implications can be eliminated.\n\nSome implication candidates may\
    \ be too strong and cannot be proved. Figure [5](#page-4-9) illustrates how we\
    \ derive a weaker set of implication candidates Cˆ imp from those unverified implication\
    \ candidates denoted as Cimp \\ Invs. In Fig. [5,](#page-4-9) WEAKENIMPLICATIONS\
    \ comprises three inference rules. It initially sets Cˆ imp to an empty set. Then\
    \ the rules *Append-1* and *Append-2* generate weaker implications by combing\
    \ two unverified implication candidates. In essence, η<sup>1</sup> ∧ η<sup>2</sup>\
    \ =⇒ τ is weaker than either η<sup>1</sup> =⇒ τ or η<sup>2</sup> =⇒ τ . Similarly,\
    \ η =⇒ τ<sup>1</sup> ∨ τ<sup>2</sup> is weaker than both η =⇒ τ<sup>1</sup> and\
    \ η =⇒ τ2. To eliminate useless implications that are tautologies, we impose restrictions\
    \ on the original implications, such as η<sup>1</sup> ∧ η<sup>2</sup> ̸≡ false\
    \ and τ<sup>1</sup> ∨ τ<sup>2</sup> ̸≡ true. It is evident that the weaker implications\
    \ are also relevant as they satisfy the same control/data-flow dependencies as\
    \ the original ones.\n\n# *D. Termination*\n\nThe termination of Alg. [1](#page-3-2)\
    \ can be ensured by the fact that INVCON+ can only produce a finite set of primitive\
    \ invariant predicates. The conclusion regarding the termination of Alg. [1](#page-3-2)\
    \ hinges on whether the loop (Lines [11](#page-3-14)[-14\\)](#page-3-17) comes\
    \ to an end. In each iteration of the loop, we possess at least one implication\
    \ candidate, constructed by WEAKENIMPLICATIONS (refer to Sect. [IV-C\\)](#page-4-1).\
    \ Regarding WEAKENIMPLICATIONS, it consistently generates weaker implication candidates\
    \ than the previous ones, utilizing conjunctions over premises or disjunctions\
    \ over consequences. Assuming INVDETECT yields n primitive invariant predicates\
    \ Clikely ∪ Cpartial = {p1, . . . , pn}, then the weakest implication will be\
    \ at least as strong as p<sup>1</sup> ∧ · · · ∧ p<sup>n</sup> =⇒ p<sup>1</sup>\
    \ ∨ · · · ∨ pn. Consequently, the loop will finish in no more than 2 × n iterations,\
    \ establishing the termination of this algorithm.\n\n# <span id=\"page-4-0\"></span>*E.\
    \ Running Example*\n\nWe illustrate our algorithm using the example presented\
    \ in Fig. [3.](#page-3-1) The details regarding our transaction parsing and invariant\
    \ detection will be elaborated in Sect. [V.](#page-5-0) For the sake of simplicity\
    \ in the illustration, assume that we have already acquired a set of likely and\
    \ partially supported invariants through invariant detection on the transaction\
    \ histories. In Table [I,](#page-6-1) the invariants labeled with ✓ are successfully\
    \ verified by the static verifier, while the ones with ✗ are unverified. In Step\
    \ ⃝1 , we perform a Houdini-like static inference on these detected invariant\
    \ candidates. Consequently, three likely invariants are verified, excluding to\
    \ ̸= 0. In the subsequent step (Step ⃝2 ), nine additional implication invariant\
    \ candidates are generated from the previously unverified likely invariants and\
    \ partially supported invariants, according to the rules in FINDIMPLICATIONS (see\
    \ Fig. [4\\)](#page-3-16). However, after the modular verification, only one implication\
    \ is confirmed. Furthermore, we weaken these unverified implication invariants\
    \ in Step ⃝3\n\n<span id=\"page-5-1\"></span>![](_page_5_Figure_0.jpeg)\n\nFig.\
    \ 6: The architecture overview of INVCON+.\n\nusing WEAKENIMPLICATIONS (see Fig.\
    \ [5\\)](#page-4-9) to derive four new implication candidates for further validation.\
    \ Eventually, all the invariants listed in Sect. [III](#page-2-0) are successfully\
    \ recovered (in a logically equivalent form). Moreover, two other invariants,\
    \ balances[to] ≥ old(balances[to]) and balances[from] ≤ old(balances[from]), are\
    \ verified, which provide additional insights on how the balances of the sender\
    \ and the receiver should change when transferFrom is called, beyond the standard\
    \ specifications.\n\n# V. IMPLEMENTATION\n\n# <span id=\"page-5-0\"></span>*A.\
    \ Overview*\n\nFigure [6](#page-5-1) demonstrates the high-level architecture\
    \ of IN-VCON+, our automated invariant detection tool for Solidity smart contracts.\
    \ The inputs to INVCON+ include a set of historical transactions and the corresponding\
    \ contract source code, while its output is a collection of smart contract invariant\
    \ specifications or the accordingly annotated contract code. INVCON+ comprises\
    \ four modules: (1) a *data parser* that decodes contract code and transaction\
    \ histories to extract concrete execution trace set; (2) a *dynamic invariant\
    \ detector* that generates a set of likely and partially supported invariants;\
    \ (3) a *modular invariant verifier* and an *implication learner* that verify\
    \ and learn contract invariants, respectively; and (4) a *suppressor* that simplifies\
    \ the results by removing redundant invariants. Notably, the implication learner\
    \ has already been detailed in Sect. [IV-C.](#page-4-1)\n\n# *B. Data Parser*\n\
    \nGiven a contract, we first collect all of its historical transactions. For each\
    \ transaction, we decode the specific function input based on the contract's Application\
    \ Binary Interface (ABI), and we interpret the transaction output in accordance\
    \ with the contract's storage layout specifications. This layout dictates where\
    \ each state variable is stored in the blockchain database. For instance, as shown\
    \ in Fig. [1,](#page-1-1) the first declared state variable totalSupply is stored\
    \ at the first slot (0x0) in the contract's blockchain database.\n\nThe input\
    \ of a contract transaction is represented as a tuple *(sender, function, parameters)*,\
    \ which encapsulates the transaction's sender, the invoked function's name, and\
    \ the corresponding input parameters. Conversely, the transaction's output\n\n\
    is denoted as *(status, storageChanges)*. Here, *status* signifies the transaction's\
    \ success or failure, while *storageChanges* details the alterations in the contract's\
    \ storage across various slots. By aligning storage slots with the contract's\
    \ storage layout, one can effectively interpret these storage modifications as\
    \ changes in the values of the contract's state variables. Employing the previously\
    \ described preprocessing technique enables the extraction of a sequence of data\
    \ triples (i.e., execution traces). These triples consist of the actual values\
    \ of state variables and function input variables at the point of function entry,\
    \ as well as the most recent values of state variables at the point of function\
    \ exit. It is important to note that any misrecognition of variables can lead\
    \ to incorrect invariant results. We have implemented measures to ensure the accuracy\
    \ of variable recognition. For state variables of primitive types, we directly\
    \ ascertain their values, as the storage layout for these variables remains constant\
    \ during runtime. In the case of non-primitive, dynamic state variables, to reduce\
    \ computational cost, we initially utilize the known variable values to hypothesize\
    \ a correlation between the altered storage slots and the dynamic state variables.\
    \ However, if this approach fails to produce an accurate mapping, it becomes necessary\
    \ to replay the entire transaction. This replay process enables us to track the\
    \ comprehensive execution information, including storage modifications, thus allowing\
    \ for the accurate determination of the correct mapping.\n\n# *C. Dynamic Invariant\
    \ Detector*\n\nThe effectiveness of dynamic invariant detection largely depends\
    \ on the diversity and scale of the customized invariant templates used. In our\
    \ methodology, these invariant templates are required to conform to the invariant\
    \ specification language outlined in Fig. [2.](#page-2-1) However, it is both\
    \ impossible and impractical to cover every conceivable invariant template. Our\
    \ approach, akin to that of INVCON [\\[18\\]](#page-13-17), limits the scope to\
    \ unary, binary, and ternary invariant templates. Unlike INVCON, our templates\
    \ are specifically designed for Solidity smart contracts, which are predominantly\
    \ used for financial applications. These contracts often entail intricate scientific\
    \ computations on scalar variables. Furthermore, Solidity features an array of\
    \ complex data structures, such as *mapping* and *struct*. To effectively infer\
    \ invariants related to these structures, we have incorporated several derivation\
    \ templates, such as *MemberItem* and *MappingItem*, which facilitate access to\
    \ elements within these data structures. Additionally, drawing inspiration from\
    \ the significance of balance invariants as highlighted by Wang et al. [\\[24\\\
    ]](#page-13-23), we have introduced a *SumMap* derivation template. This template\
    \ is specifically designed to aggregate the values contained within a mapping\
    \ variable.\n\nDynamic invariant detection employs a statistical methodology to\
    \ generate *likely* primitive invariants with a certain degree of statistical\
    \ confidence. Contrasting with the approach of IN-VCON, our method retains invariants\
    \ that are refuted by certain transactions in the final results. This is because\
    \ less stringent forms of these invariants, expressed as implications, may still\
    \ hold true for certain contracts. Both the likely invariants and the falsified\
    \ ones constitute a high-quality set of primitive\n\n<span id=\"page-6-1\"></span>\n\
    \n| Step | Invariants                                                        \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                       |                                    \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                     |  |  |\n|------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--|--|\n\
    | ⃝1   | Likely Contract Invariants:<br>totalSupply = SumMap(balances) ✓<br>Likely\
    \ Function Pre/post-conditions:<br>to ̸=0 ✗<br>balances[to] ≥ old(balances[to])\
    \ ✓<br>balances[from] ≤ old(balances[from]) ✓                                \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                              | Partially Supported Function Pre/post-conditions:<br>from\
    \ ̸= to<br>from = to<br>balances[from] = old(balances[from]) - tokens<br>balances[to]\
    \ = old(balances[to]) + tokens<br>allows[from][msg.sender] = old(allows[from][msg.sender])\
    \ - tokens<br>balances[from] = old(balances[from])<br>balances[to] = old(balances[to])\
    \ |  |  |\n| ⃝2   | Implication Invariant Candidates:<br>to ̸=0 =⇒ allows[from][msg.sender]\
    \ = old(allows[from][msg.sender]) - tokens ✓<br>to ̸=0 =⇒ balances[from] = old(balances[from])\
    \ - tokens ✗<br>to ̸=0 =⇒ balances[to] = old(balances[to]) + tokens ✗<br>to ̸=0\
    \ =⇒ balances[from] = old(balances[from] ✗<br>to ̸=0 =⇒ balances[to] = old(balances[to])\
    \ ✗<br>from ̸=to =⇒ balances[from] = old(balances[from]) - tokens ✗<br>from ̸=to\
    \ =⇒ balances[to] = old(balances[to]) + tokens ✗<br>from = to =⇒ balances[from]\
    \ = old(balances[from] ✗<br>from = to =⇒ balances[to] = old(balances[to]) ✗ |\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \             |  |  |\n| ⃝3   | Weakened Implication Invariant Candidates:<br>to\
    \ ̸=0 ∧ from ̸=to =⇒ balances[from] = old(balances[from]) - tokens ✓<br>to ̸=0\
    \ ∧ from ̸=to =⇒ balances[to] = old(balances[to]) + tokens ✓<br>to ̸=0 ∧ from\
    \ = to =⇒ balances[from] = old(balances[from]) ✓<br>to ̸=0 ∧ from = to =⇒ balances[to]\
    \ = old(balances[to]) ✓                                                      \
    \                                                                            \
    \                                                                            \
    \                                               |                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                             |  |  |\n\nTABLE\
    \ I: Illustration example of invariant verification.\n\npredicates. Each of these\
    \ predicates has been empirically verified through historical transaction data\
    \ of smart contracts. In our evaluation setting, each valid primitive invariant\
    \ must be supported by at least three historical transactions.\n\n# *D. Modular\
    \ Invariant Verifier*\n\nThe Houdini algorithm [\\[12\\]](#page-13-11) is a widely\
    \ recognized technique commonly used in program annotation and validation processes.\
    \ Its primary objective is to automatically generate invariant annotations from\
    \ a group of candidates. To adapt Houdini algorithm for Solidity contracts, we\
    \ initially instrument the contracts with the mined invariants. This entails converting\
    \ the invariants into a compatible format and then embedding them into the contract.\
    \ The annotations are strategically placed at the beginning of functions to align\
    \ with their specific names and arguments. Subsequently, we transform the instrumented\
    \ contracts into *Boogie* [\\[25\\]](#page-13-24) programs, leveraging the existing\
    \ formal verification tool VeriSol [\\[26\\]](#page-13-25) for Solidity smart\
    \ contracts. We have refined the Boogie translator in VeriSol to better accommodate\
    \ contracts with inheritance and polymorphism features. For instance, the original\
    \ translator lacked support for unnamed parent contract calls using the \"super\"\
    \ keyword in Solidity, and it did not handle function overloading where a contract\
    \ includes multiple functions with the same name. We have enhanced its translation\
    \ rules to effectively translate these complex contracts into Boogie programs.\
    \ Finally, we utilize Boogie's own Houdini modular verifier to infer among the\
    \ aforementioned invariant annotations, resulting in a set of verified invariants.\n\
    \n# *E. Suppressor*\n\nAn invariant is deemed redundant if it can be derived from\
    \ another invariant. The invariants verified by INVCON+ may contain such redundancies.\
    \ Instead of eliminating redundancies in the dynamically detected invariants (as\
    \ what Daikon [\\[11\\]](#page-13-10) does), we only remove redundancies from\
    \ the invariants that are successfully verified. This design leaves more choices\
    \ to the implication learner, when synthesizing implication invariants. Among\
    \ the verified invariants, we utilize the Z3 solver [\\[27\\]](#page-13-26) to\
    \ determine if one invariant predicate can be deduced from another. Following\
    \ this analysis, we retain only the strongest invariant predicates in our final\
    \ results.\n\n# VI. EVALUATION\n\n<span id=\"page-6-0\"></span>In this section,\
    \ we evaluate INVCON+ to answer the following research questions:\n\n- 1) RQ1:\
    \ How effectively does INVCON+ generate invariants for smart contracts?\n- 2)\
    \ RQ2: How does the length of transaction histories used affect the performance\
    \ of INVCON+?\n- 3) RQ3: How effective are the invariants detected by IN-VCON+\
    \ in preventing real-world security attacks?\n\n# *A. Methodology*\n\nBenchmark.\
    \ To answer RQ1 and RQ2, we collected real-world smart contracts implementing\
    \ the most popular ERC20 and ERC721 standards, which have been studied extensively\
    \ in previous works [\\[3\\]](#page-13-2), [\\[4\\]](#page-13-3), [\\[14\\]](#page-13-13),\
    \ [\\[28\\]](#page-13-27), [\\[29\\]](#page-13-28). The most important reason\
    \ of choosing smart contracts implementing common standards is that their invariant\
    \ specifications are better understood, making it easier to obtain the ground\
    \ truth. First, we queried the public Ethereum ETL dataset hosted on the Google\
    \ BigQuery platform [\\[30\\]](#page-13-29) and then identified 13,116 contract\
    \ addresses flagged as ERC20 deployed between 2021 and 2022. Then, we identified\
    \ 2,689 ERC721 contract addresses deployed between 2020 and 2022. To facilitate\
    \ our analysis, we kept only open-source contracts written in Solidity versions\
    \ ranging between 0.5.0 and 0.5.17, which are currently supported by VERISOL.\
    \ Finally, we obtained 361 ERC20 contracts and 10\n\nERC721 contracts for the\
    \ experimental evaluation, where each contract has at least 50 historical transactions\
    \ as of June 2023.\n\nTo establish the ground truth for ERC20 and ERC721 contract\
    \ specifications and ensure the included invariants are comprehensive, we investigated\
    \ multiple external sources. These include the formal specifications referenced\
    \ in the existing literature [\\[4\\]](#page-13-3), [\\[14\\]](#page-13-13), popular\
    \ smart contract libraries, such as OpenZeppelin [\\[8\\]](#page-13-7), and online\
    \ documentations provided by smart contract formal verification companies. We\
    \ list the collected ERC20 and ERC721 invariant specifications in Table [II](#page-8-0)\
    \ and Table [III,](#page-8-1) respectively. These specifications are mainly based\
    \ on Certora [\\[20\\]](#page-13-19), [\\[21\\]](#page-13-20), [\\[31\\]](#page-13-30),\
    \ KEVM [\\[22\\]](#page-13-21), [\\[28\\]](#page-13-27), and OpenZeppelin API\
    \ documentations [\\[32\\]](#page-13-31), [\\[33\\]](#page-13-32). We analyzed\
    \ each of the collected invariants and manually translated it into our own specification\
    \ language (C.f. Fig. [2\\)](#page-2-1), which is a straightforward exercise in\
    \ most cases. We categorized these invariant specification into contract invariants,\
    \ function preconditions and postconditions in Tables [II](#page-8-0) and [III.](#page-8-1)\
    \ The functions listed in each table are the most commonly used standard functions\
    \ for ERC20 and ERC721 contracts. Some specifications documented in external sources\
    \ were omitted, e.g., \"Emitting a Transfer event\" for the transfer function,\
    \ because the particular language features are not supported by our specification\
    \ language.\n\nEvaluation Metrics. We use two evaluation metrics to evaluate INVCON+\
    \ on the ERC20 and ERC721 contracts. Particularly, we use Precision and RecallERC20\
    \ (RecallERC721) to measure the effectiveness of the generated invariants, denoted\
    \ as Xproved. We denote the ground truth invariants (e.g., ERC20) as Y . Formally,\n\
    \n$$\\text{Precision} = \\frac{|X\\_{\\text{provided}}|}{|X|},\\tag{2}$$\n\n$$\\\
    mathbf{Recall}\\_{\\text{ERC20}}(\\mathbf{Recall}\\_{\\text{ERC21}}) = \\frac{|X\\\
    _{\\text{provided}} \\cap Y|}{|Y|}, \\qquad \\text{(3)}$$\n\nwhere *precision*\
    \ refers to the proportion of the generated invariants which are correct and *recall*\
    \ is the proportion of the ground truth invariants which can be successfully generated.\
    \ Since the contract execution trace set ∆ from transaction histories may only\
    \ contain a subset of functions invocations, i.e., some functions are never invoked.\
    \ For a fair comparison, let Y ⇂ ∆ represent the ground truth invariants for the\
    \ functions appeared in the histories, and we use the adjusted recall in our experiments:\
    \ <sup>|</sup>Xproved∩<sup>Y</sup> <sup>|</sup> |Y ⇂∆| .\n\nNote that although\
    \ the ground truth invariants are derived based on multiple external sources and\
    \ widely deemed to be standard, they may still be incomplete, as there are infinitely\
    \ many correct invariants in theory. The purpose of collecting the ground truth\
    \ invariants is to include the list of common expectations that are needed for\
    \ contract safety and reliability. On the other hand, certain smart contracts\
    \ may not faithfully implement the ERC standards, and as a result, either some\
    \ ground-truth invariants may not hold for them or they satisfy additional invariants\
    \ not included in the ground truth. Nevertheless, an ideal invariant generation\
    \ tool should be able to recover as many ground-truth invariants as possible,\
    \ and meanwhile, recover other relevant invariants that are correct\n\nand useful\
    \ in describing unique smart contract behaviors.\n\n# *B. Experiment Setup*\n\n\
    All the experiments were conducted on a desktop computer with the Ubuntu 20.04\
    \ OS, an Intel Core Xeon 3.50GHx processor, and 32GB of RAM. To facilitate the\
    \ evaluation, we have crawled and cached all transaction histories in advance\
    \ for the contracts used in our experiments.\n\n# *C. RQ1: Effectiveness of Invariant\
    \ Generation*\n\nBaseline. To evaluate the performance of INVCON+, we used INVCON\
    \ as our baseline. INVCON uses Daikon as the back-end invariant detection engine\
    \ and more implementation details can be found in the previous work [\\[18\\]](#page-13-17).\
    \ To the best of our knowledge, Cider [\\[19\\]](#page-13-18) is the only automated\
    \ invariant generation tool for smart contracts besides INVCON. We have contacted\
    \ the authors of Cider to obtain a copy of the tool,[4](#page-7-0) but failed\
    \ to set it up. We will discuss and compare with this work in Sect. [VII.](#page-11-0)\n\
    \nAdditionally, we compared INVCON+ with its two variants: INVCON+ *Naive*, which\
    \ performs only dynamic invariant detection tailored to Solidity contracts, and\
    \ INVCON+ *Primitive*, which employs the Houdini algorithm to generate verified\
    \ invariants based only on dynamically detected invariant candidates.\n\nResults.\
    \ Table [IV](#page-8-2) presents the comparison results for 361 ERC20 contracts,\
    \ with a constraint of utilizing a maximum of 200 transactions per contract. The\
    \ first column displays the names of the tools, while the second column enumerates\
    \ the averaged number of invariants generated by each respective tool per contract.\
    \ The middle two columns showcase the overall Precision and RecallERC20 scores,\
    \ and the last column provides the averaged time usage for each tool.\n\nINVCON+\
    \ achieves the highest recall score, reaching 0.80, and generates approximately\
    \ 46 invariants per contract, all of which are successfully verified by VeriSol.\
    \ Notably, INVCON performs the least favorably in terms of the invariants generated,\
    \ even when compared with INVCON+ *Naive*. Specifically, INVCON produces the second-highest\
    \ number of invariants, yet its recall score is significantly lower than that\
    \ of INVCON+ *Naive*, while maintaining a similar precision score of less than\
    \ 0.1. The poor performance is primarily attributed to the fact that INVCON's\
    \ underlying invariant detection engine, Daikon, supports only Boolean, integer/float,\
    \ and string types native to Java. Consequently, the *address* type (20 bytes\
    \ long) in the Solidity language cannot be seamlessly converted into a Java integer\
    \ (8 bytes long). Its conversion to the Java string type discards semantic information,\
    \ rendering the straightforward production of common invariants (e.g., a1, a2\
    \ in Table [II\\)](#page-8-0) unattainable for INVCON. Additionally, Daikon employs\
    \ floating-point operations in arithmetic invariant templates (e.g., linear equation\
    \ templates), which is not allowed in the Solidity semantics, leading to incorrect\
    \ invariants for b6, b10 in Table [II.](#page-8-0)\n\nINVCON+ *Primitive* exhibits\
    \ a slightly lower recall score than INVCON+ *Naive*, because some ground truth\
    \ invariants\n\n<span id=\"page-7-0\"></span><sup>4</sup>https://github.[com/UCSB-PLSE/Cider](https://github.com/UCSB-PLSE/Cider)\n\
    \n| TABLE II: Common ERC20 Invariants. |\n|------------------------------------|\n\
    |------------------------------------|\n\n<span id=\"page-8-0\"></span>\n\n| Categories\
    \                             | Preconditions                                \
    \                                                                            \
    \                                                              | Postconditions\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                              |  |\n|----------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--|\n\
    | transfer(to, amount)                   | [a1] msg.sender ̸= 0<br>[a2] to ̸=\
    \ address(0)<br>[a3] amount ≥ 0<br>[a4] amount ≤ balances[msg.sender]<br>[a5]\
    \ balances[to] + amount ≤ MAXVALUE                                        | [b1]\
    \ to ̸= msg.sender<br>=⇒<br>balances[msg.sender] =<br>old(balances[msg.sender])\
    \ - amount<br>[b2] to ̸= msg.sender =⇒ balances[to] = old(balances[to]) + amount<br>[b3]\
    \ to = msg.sender =⇒ balances[to] = old(balances[to])<br>[b4] to = msg.sender\
    \ =⇒ balances[msg.sender] = old(balances[msg.sender])<br>[b5] totalSupply = old(totalSupply)\
    \                                            |  |\n| transferFrom (from, to,<br>amount)\
    \     | [a6] from ̸= address(0)<br>[a7] to ̸= address(0)<br>[a8] amount ≥ 0<br>[a9]\
    \ amount ≤ balances[from]<br>[a10] amt ≤ allowed[from][msg.sender]<br>[a11] balances[to]\
    \ + amount ≤ MAXVALUE | [b6] allowed[from][msg.sender] = old(allowed[from][msg.sender])\
    \ - amount<br>[b7] from ̸= to =⇒ balances[from] = old(balances[from]) - amount<br>[b8]\
    \ from ̸= to =⇒ balances[to] = old(balances[to]) + amount<br>[b9] from = to =⇒\
    \ balances[from] = old(balances[from])<br>[b10] allowed[from][msg.sender] = old(allowed[from][msg.sender])\
    \ - amount<br>[b11] totalSupply = old(totalSupply) |  |\n| approve(spender,<br>amount)\
    \            | [a12] amount ≥ 0<br>[a13] spender ̸= address(0)               \
    \                                                                            \
    \                                             | [b12] allowed[msg.sender][spender]\
    \ = amount<br>[b13] totalSupply = old(totalSupply)                           \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                          |  |\n| increaseAllowance(<br>spender,\
    \ amount) | [a14] spender ̸= address(0)<br>[a15] amount ≥ 0<br>[a16] allowed[msg.sender][spender]\
    \ + amount ≤<br>MAXVALUE                                                     \
    \                      | [b14] allowed[msg.sender][spender] = old(allowed[msg.sender][spender])\
    \ +<br>amount<br>[b15] totalSupply = old(totalSupply)                        \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \      |  |\n| decreaseAllowance(<br>spender, amount) | [a17] spender ̸= address(0)<br>[a18]\
    \ amount ≥ 0<br>[a19] allowed[msg.sender][spender] ≥ amount                  \
    \                                                                       | [b16]\
    \ allowed[msg.sender][spender] = old(allowed[msg.sender][spender]) -<br>amount<br>[b17]\
    \ totalSupply = old(totalSupply)                                             \
    \                                                                            \
    \                                                                            \
    \                                                             |  |\n| mint(account,\
    \ amount)                  | [a20] account ̸= address(0)<br>[a21] amount ≥ 0<br>[a22]\
    \ balances[account] + amount ≤ MAXVALUE                                      \
    \                                                   | [b18] balances[account]\
    \ = old(balances[account]) + amount<br>[b19] totalSupply = old(totalSupply) +\
    \ amount                                                                     \
    \                                                                            \
    \                                                                            \
    \                                                     |  |\n| burn(from, amount)\
    \                     | [a23] from ̸= address(0)<br>[a24] amount ≥ 0<br>[a25]\
    \ balances[from] ≥ amount                                                    \
    \                                                      | [b20] balances[from]\
    \ = old(balances[from]) - amount<br>[b21] totalSupply = old(totalSupply) + amount\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                    |  |\n| pause()         \
    \                       | [a26] paused = false                               \
    \                                                                            \
    \                                                        | [b22] paused = true\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                         |  |\n| unpause()  \
    \                            | [a27] paused = true                           \
    \                                                                            \
    \                                                             | [b23] paused =\
    \ false                                                                      \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                              |  |\n| Contract\
    \ Invariant                     | [c1] totalSupply = SumMap(balances)        \
    \                                                                            \
    \                                                                |           \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                  |  |\n\n# TABLE\
    \ III: Common ERC721 Invariants.\n\n<span id=\"page-8-1\"></span>\n\n| Categories\
    \                                    | Preconditions                         \
    \                                                                            \
    \                                                                            \
    \                   | Postconditions                                         \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            |\
    \  |\n|-----------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--|\n\
    | (safe)-<br>transferFrom(from,<br>to, tokenId) | [a28] from =<br>tokenOwner[tokenId]<br>[a29]\
    \ from ̸= address(0)<br>[a30] to ̸= address(0)<br>[a31] (msg.sender = from ∨ msg.sender\
    \ =<br>tokenApprovals[tokenId] ∨<br>operatorApprovals[from][msg.sender] = true)\
    \ | [b24] from ̸= to =⇒<br>ownedTokensCount[from] = old(<br>ownedToken<br>sCount[from])\
    \ - 1<br>[b25] from ̸= to<br>=⇒<br>ownedTokensCount[to] = old(<br>ownedToken<br>sCount[to])\
    \ + 1<br>[b26] from = to =⇒<br>ownedTokensCount[from] = old(<br>ownedToken<br>sCount[from])<br>[b27]\
    \ from = to<br>=⇒<br>ownedTokensCount[to] = old(<br>ownedToken<br>sCount[to])<br>[b28]<br>tokenOwner[tokenId]\
    \ = to<br>[b29]<br>tokenApprovals[tokenId] = address(0) |  |\n| approve(to, tokenId)\
    \                          | tokenOwner[tokenId] ̸= address(0)<br>[a32]<br>tokenOwner[tokenId]\
    \ ∨<br>[a33] (msg.sender =<br>operatorApprovals[ tokenOwner[tokenId] ][msg.sender]<br>=\
    \ true)                                                    | [b30]<br>tokenApprovals[tokenId]\
    \ = to                                                                       \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                       |  |\n| setApproveForAll(<br>operator,<br>approved)  \
    \ | [a34] operator ̸= msg.sender                                             \
    \                                                                            \
    \                                                            | [b31]<br>operatorApprovals[msg.sender][operator]\
    \ =<br>approved                                                              \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \       |  |\n| Contract Invariant                            | [c2] len( tokenOwner)\
    \ = SumMap( ownerTokenCount)                                                 \
    \                                                                            \
    \                                    |                                       \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                 |  |\n\n<span id=\"page-8-2\"></span>\n\n| TABLE IV: The comparison\
    \ results on ERC20 contracts. |  |  |  |  |\n|------------------------------------------------------|--|--|--|--|\n\
    |------------------------------------------------------|--|--|--|--|\n\n| Tool\
    \              | #Inv   | Prec. | RecERC20 | Avg.time (s) |\n|-------------------|--------|-------|----------|--------------|\n\
    | INVCON            | 413.23 | 0.095 | 0.19     | 13.99        |\n| INVCON+ Naive\
    \     | 480.89 | 0.094 | 0.63     | 15.25        |\n| INVCON+ Primitive | 22.49\
    \  | 1.000 | 0.61     | 20.57        |\n| INVCON+           | 46.12  | 1.000 |\
    \ 0.80     | 250.25       |\n\nthat are inferred as likely invariants by INVCON+\
    \ *Naive* may not be verified by INVCON+ *Primitive*. This may be due to contract\
    \ implementations slightly deviating from the standard. For example, many ERC20\
    \ tokens do not enforce the precondition a2 of the transfer function in Table\
    \ [II,](#page-8-0) because transferring token to zero address could be used to\
    \ implement the token burning functionality. The verified invariants are a more\
    \ accurate reflection of the actual contract implementations, compared with the\
    \ likely invariants. Leveraging an algorithm capable of producing implications\
    \ that widely exist in ERC20 invariants (C.f. Table [II\\)](#page-8-0), INVCON+\
    \ outperforms all the baseline tools, yielding 100% precise invariant results.\n\
    \nRegarding the time usage, it is unsurprising that INVCON+ takes the most time,\
    \ whereas INVCON and INVCON+ *Naive* finish the fastest. In our experiments, we\
    \ observed that the static inference process consumes the majority of the time,\
    \ constituting nearly 53% of the overall time usage, as depicted in Fig. [9.](#page-10-0)\
    \ This is primarily due to the iterative application of static inference until\
    \ no more implication candidates are\n\n```\n1 /** @dev Creates `amount` tokens\
    \ and assigns them to\n  ,→ `account`,\n2 * increasing the total supply.\n3 *\
    \ Requirements\n4 * - `to` cannot be the zero address.*/\n5 function _mint(address\
    \ account, uint256 amount) internal\n  ,→ {\n6 require(account != address(0),\
    \ \"ERC20: mint to the zero\n   ,→ address\");\n7 _totalSupply = _totalSupply.add(amount);\n\
    8 _balances[account] = _balances[account].add(amount);\n9 _balances[Account] =\
    \ _totalSupply/100;\n10 }\n```\nFig. 7: TokenMintERC20Token contract violating\
    \ c1.\n\n<span id=\"page-9-2\"></span>TABLE V: The mutation testing results on\
    \ ERC20 contracts against the verified invariants by INVCON+.\n\n| Categories\
    \              | approve      | transfer     | transferFrom |\n|-------------------------|--------------|--------------|--------------|\n\
    | No. total mutants       | 1,539        | 1,141        | 297          |\n| No.\
    \ killed mutants      | 998 (64.8 %) | 624 (54.6 %) | 101 (34.0 %) |\n| P1. Contract\
    \ invariants | 245 (24.5 %) | 344 (55.1 %) | 55 (54.4 %)  |\n| P2. Function pre/post\
    \   | 763 (76.4 %) | 465 (74.5 %) | 61 (60.4 %)  |\n| P3. ERC20 standard     \
    \ | 751 (75.2 %) | 266 (42.6 %) | 43 (42.5 %)  |\n| P4. Non-ERC20 standard  |\
    \ 995 (99.7 %) | 601 (96.3 %) | 98 (97.0 %)  |\n\nprovided. Moreover, implication\
    \ invariants generated in later iterations tend to be more intricate, resulting\
    \ in more complicated SMT formulas which take more time to solve. To enhance the\
    \ efficiency of INVCON+, we recommend capping the iterations used in the verification\
    \ process to four; under such a setting, INVCON+ demonstrates an averaged time\
    \ savings of one minute in the entire verification process without compromising\
    \ the quality of resulting invariants.\n\nAdditionally, we investigated further\
    \ on the contracts for which INVCON+ generated additional invariants deviating\
    \ from the ground-truth ones. Many of these contracts are found to be non-compliant\
    \ with ERC20 specifications. As illustrated in Fig. [7,](#page-9-0) we examined\
    \ a real-world contract, TokenMintERC20Token[5](#page-9-1) , where the mint function\
    \ deviates from the contract invariant c1—the sum of account balances always equals\
    \ to the total supply—indicating noncompliance with the standard. This discrepancy\
    \ arises because only 1% of the total supply tokens have been distributed to the\
    \ Account (Line [9\\)](#page-9-0).\n\nInvariant Quality. Furthermore, to assess\
    \ the significance of the invariants generated by INVCON+, we conducted mutation\
    \ testing on the same benchmark and computed the corresponding mutation scores\
    \ against these invariants. Table [V](#page-9-2) presents the mutation testing\
    \ results on ERC20 contracts, specifically focusing on the three most important\
    \ functions: *approve*, *transfer*, and *transferFrom*. We introduced six mutation\
    \ operators, such as *binary/unary-op-mutation* and *require-mutation*, along\
    \ with the others, based on the mutation generator Gambit [\\[34\\]](#page-13-33)\
    \ developed by Certora.[6](#page-9-3) This mutation-based approach was also adopted\
    \ by Certora to evaluate the quality of smart contract specifications.[7](#page-9-4)\
    \ In total, we generated 1, 539, 1, 141, and 297 mutants for *approve*, *transfer*,\
    \ and *transferFrom*, respectively. Table [V](#page-9-2) shows that 64.8 %, 54.6\
    \ %, and 34.0 % mutants of\n\n```\n1 function _transfer(address sender, address\
    \ recipient,\n  ,→ uint256 amount) internal {\n2 require(sender!=address(0), \"\
    zero address\");\n3 require(recipient!=address(0), \"zero address\");\n4\n5 _balances[sender]=_balances[sender].sub(amount);\n\
    6 _balances[recipient]=_balances[recipient].add(amount);\n7 emit Transfer(sender,\
    \ recipient, amount);\n8 }\n9 function _approve(address owner, address spender,\n\
    \  ,→ uint256 value) internal {\n10 require(owner!=address(0), \"zero address\"\
    );\n11 require(spender!=address(0), \"zero address\");\n12\n13 _allowances[owner][spender]\
    \ = value;\n14 emit Approval(owner, spender, value);\n15 }\n16\n17 function transferFrom(address\
    \ sender, address recipient,\n  ,→ uint256 amount) public returns (bool) {\n18\
    \ _transfer(sender, recipient, amount);\n19 _approve(sender, msg.sender,\n   ,→\
    \ _allowances[sender][msg.sender].sub(amount));\n20 return true;\n21 }\n```\n\
    Fig. 8: Illustration of the overprotected *transferFrom* function.\n\napprove,\
    \ transfer, and transferFrom are successfully killed, respectively.\n\nTo delve\
    \ into those killed mutants, in Table [V,](#page-9-2) we use P1, P2, P3, and P4\
    \ to denote different types of invariants and the corresponding rows show the\
    \ number of killed mutants by these invariants. Although the contract invariants\
    \ (P1) accounts for 24.5 % to 54,4 % of the killed mutants, function pre/post-conditions\
    \ (P2) demonstrate a more substantial impact occupying at most 76.4 % of the killed\
    \ mutants. Moreover, non-ERC20 standard invariants successfully eliminate nearly\
    \ the entire set (96 % more) of the total killed mutants. In contrast, ERC20 standard\
    \ invariants eliminate a smaller set of mutants. This suggests that the invariants\
    \ generated by INVCON+ capture richer program semantics, contributing to a more\
    \ comprehensive set of invariant specifications for smart contracts.\n\nInterestingly,\
    \ Table [V](#page-9-2) reveals that only 34% of mutants related to the *transferFrom*\
    \ function are successfully eliminated. Upon investigation, we discovered that\
    \ *transferFrom* is overprotected, where one of its function-level preconditions\
    \ is redundant. Figure [8](#page-9-5) depicts a common implementation of *transferFrom*,\
    \ facilitating token transfer on behalf of the token owner through two internal\
    \ functions, *transfer* and *approve*. This design rationale primarily aims at\
    \ direct code reuse for the other two public functions, *transfer* and *approve*.\
    \ However, in the *transferFrom* function, both requirements (Line [2](#page-9-5)\
    \ and Line [10\\)](#page-9-5) check if the *sender* parameter is a zero address.\
    \ Consequently, mutations on either Line [2](#page-9-5) or Line [10](#page-9-5)\
    \ do not diminish the requirements that *transferFrom* should adhere to, resulting\
    \ in a low mutation score for *transferFrom*. It is noteworthy that redundant\
    \ requirements in smart contracts lead to higher gas consumption during transaction\
    \ execution and should be minimized whenever possible.\n\nInvariant Crowdsourcing.\
    \ Less popular smart contracts may have scarce transaction histories. For example,\
    \ many ERC721 contract instances may not have enough transactions to infer high-quality\
    \ invariants. Each contract instance can slightly deviate from the standard specifications,\
    \ therefore, we\n\n<span id=\"page-9-3\"></span><span id=\"page-9-1\"></span><sup>5</sup>https://etherscan.[io/address/0x62c23c5f75940c2275dd3cb9300289dd30992e59](https://etherscan.io/address/0x62c23c5f75940c2275dd3cb9300289dd30992e59)\
    \ <sup>6</sup>https://www.certora.com/\n\n<span id=\"page-9-4\"></span><sup>7</sup>https://docs.certora.com/en/latest/docs/gambit/index.html\n\
    \n<span id=\"page-10-1\"></span>TABLE VI: ERC721 invariants generated by INVCON+.\n\
    \n| Category                | Preconditions   | Postconditions               \
    \     |\n|-------------------------|-----------------|-----------------------------------|\n\
    | (safe)-<br>transferFrom | [a28, a29, a30] | [b24, b25, b26, b27, b28,<br>b29]\
    \ |\n| approve                 | [a32]           | [b30]                     \
    \        |\n| setApproveForAll        | [a34]           | [b31]              \
    \               |\n| Contract Invariant      |                 | [c2]        \
    \                      |\n|                         |                 |      \
    \                             |\n\n<span id=\"page-10-0\"></span>![](_page_10_Figure_3.jpeg)\n\
    \nFig. 9: The time usage by different components of INVCON+.\n\nhypothesize that\
    \ reverse engineering invariants from a single contract and its limited transaction\
    \ histories is inferior to that from multiple contracts. We validate this hypothesize\
    \ on a set of 10 ERC721 contracts, restricting the evaluation to at most 200 transactions\
    \ per contract. The objective is to examine IN-VCON+'s effectiveness in recovering\
    \ the ground truth invariants listed in Table [III](#page-8-1) by combining invariant\
    \ results from multiple contracts. Notably, to achieve meaningful combination,\
    \ every invariant result will be normalized according to a universal ERC721 definition\
    \ on the name of state variables and the name of function input variables.\n\n\
    Table [VI](#page-10-1) presents the combined invariant results from all ERC721\
    \ contracts. It demonstrates that INVCON+ successfully recovers the contract invariants,\
    \ all postconditions, and nearly all preconditions except a31 and a33, which contain\
    \ disjunctions over predicates. Consequently, the combination of invariant results\
    \ from multiple contracts significantly improves the overall recall rate (14/16).\n\
    \nAnswer to RQ1: INVCON+ is able to reverse engineer standard invariant specifications\
    \ from contract transaction histories and takes no more than five minutes per\
    \ contract. Additionally, the uncommon invariants generated for ERC20 contracts\
    \ capture important program semantics beyond the established standards. Moreover,\
    \ the evaluation on ERC721 contracts demonstrates the advantage to mine common\
    \ invariants from multiple contracts and their transaction histories.\n\n# *D.\
    \ RQ2: Impact of Transaction Histories*\n\nThe length of the transaction histories\
    \ used can influence the effectiveness of INVCON+. To investigate this impact,\
    \ we selected the top 10 ERC20 contracts with the longest transaction histories,\
    \ ensuring that all the chosen contracts have a history of at least 10,000 transactions.\
    \ In evaluating the influence of transaction history length, we employed the earliest\
    \ 4,000\n\n<span id=\"page-10-2\"></span>![](_page_10_Figure_10.jpeg)\n\nFig.\
    \ 10: The averaged number of invariants generated with different number of transactions.\n\
    \n<span id=\"page-10-3\"></span>![](_page_10_Figure_12.jpeg)\n\nFig. 11: The averaged\
    \ ERC20 recall score of the invariant results generated with different number\
    \ of transactions.\n\ntransactions and divided them into 20 groups, each subsequent\
    \ group having 200 more transactions than the previous one.\n\nWe utilized INVCON+\
    \ *Primitive* as the baseline and compared with it on the number of verified invariants\
    \ and the corresponding recall score. Additionally, to explore the effect of applying\
    \ the detected partially supported invariant candidates, which hold for a subset\
    \ of the transaction histories, we compared INVCON+ with a variant, INVCON+ *w/o\
    \ Partial*, that does not use these partial candidates. In this experiment, we\
    \ considered the ground truth invariants from the functions which are observed\
    \ in the earliest 4,000 transactions, when computing the recall score, i.e., RecallERC20.\n\
    \nFigure [10](#page-10-2) illustrates the number of verified invariants per contract\
    \ corresponding to the use of different transaction history lengths. The impact\
    \ of transaction history size on the number of verified invariants is evident,\
    \ with INVCON+ generating the most invariants, followed by INVCON+ INVCON+ *w/o\
    \ Partial*. This demonstrates that the partially supported invariant candidates,\
    \ although do not hold on their own, may be useful in constructing richer implication\
    \ invariants. By incorporating partial invariant candidates, INVCON+ captures\
    \ subtle contract behaviors more effectively, resulting in more comprehensive\
    \ invariant specifications—approximately two times and one time more than INVCON+\
    \ *w/o Partial* and INVCON+ *Primitive*, respectively.\n\nIn Fig. [11,](#page-10-3)\
    \ the recall score of invariant results is presented for varying transaction history\
    \ lengths. Clearly, all recall scores increase with longer transaction histories,\
    \ as more function invocations are observed. Notably, INVCON+ achieves a higher\
    \ recall score compared to the baselines. The figure also indicates a more significant\
    \ gain in recall score from 200 to 400 transactions, with negligible gains after\
    \ 400, 1,000, and 2,200 transactions for INVCON+ *Primitive*, INVCON+ *w/o Partial*,\
    \ and INVCON+, respectively. This observed difference suggests that INVCON+ has\
    \ a higher chance of capturing more comprehensive invariant specifications with\
    \ increased transaction histories. Additionally, to effectively apply INVCON+,\
    \ it is recommended to use around 2,000 transactions for invariant detection.\n\
    \nAnswer to RQ2: The scale of transaction histories affect the invariant results\
    \ of INVCON+, while longer histories empower INVCON+ to generate more comprehensive\
    \ invariant specifications.\n\n# *E. RQ3: Application in Securing Smart Contracts*\n\
    \nThe invariants generated by INVCON+ capture the key semantics of smart contracts\
    \ under normal executions, which may serve as a basis for formal contract specifications.\
    \ Highquality contract specifications have been shown to be effective in securing\
    \ smart contracts through runtime validation [\\[14\\]](#page-13-13) and static\
    \ verification [\\[26\\]](#page-13-25). To answer RQ3, we evaluated INVCON+ on\
    \ a set of benchmark contracts from SECBIT [\\[35\\]](#page-13-34), which contains\
    \ 25 types of vulnerabilities in real-world ERC20 contracts exposed to security\
    \ attacks that have resulted in significant financial losses.\n\nTable [VII](#page-12-1)\
    \ provides an overview of the verification results for the evaluated ERC20 contracts,\
    \ categorized by vulnerability types. It contains information about the overall\
    \ count of vulnerabilities and the effectiveness of our generated invariants in\
    \ detecting them. The benchmark contracts used in our evaluation encompass 9 instances\
    \ of integer overflow vulnerabilities and 16 other vulnerability types. However,\
    \ certain vulnerabilities are beyond the scope of formal specifications, such\
    \ as v14, v21, and v24 which are related to constructor naming, v15 and v16 which\
    \ are associated with different Solidity versions, and v23 which pertains to function\
    \ visibility. We focused on the remaining 18 types of vulnerabilities. Note that\
    \ some of the vulnerabilities identified are beyond the specifications outlined\
    \ in the ERC20 standard (see Table [II\\)](#page-8-0) and they can only be detected\
    \ using richer customized specifications.\n\nFor each of vulnerability types,\
    \ we evaluated the verification results of the invariants generated by INVCON+\
    \ on the corresponding benchmark contracts. We selected the top three contracts\
    \ with the highest occurrence of each vulnerability type and assessed whether\
    \ the invariants detected by INVCON+ could prevent the corresponding attacks on\
    \ these contracts. The results are shown in Table [VII.](#page-12-1) We found\
    \ that INVCON+ was able to detect all overflow vulnerabilities in the benchmark\
    \ contracts. For instance, Fig. [12](#page-11-1) demonstrated that INVCON+ detected\
    \ the integer overflow vulnerability (CVE-2018-10299) in the *batchTransfer* function\
    \ of the BEC contract. This\n\n```\n1 function batchTransfer(address[] _receivers,\n\
    \      uint256 _value) public whenNotPaused returns\n      (bool) {\n  ,→\n  ,→\n\
    2 uint cnt = _receivers.length;\n3 uint256 amount = uint256(cnt) * _value;\n4\
    \ require(cnt > 0 && cnt <= 20);\n5 require(_value > 0 && balances[msg.sender]\
    \ >=\n  ,→ amount);\n6\n7 [msg.sender] = balances[msg.sender].sub(amount);\n8\
    \ for (uint i = 0; i < cnt; i++) {\n9 balances[_receivers[i]] =\n  ,→ balances[_receivers[i]].add(_value);\n\
    10 Transfer(msg.sender, _receivers[i], _value);\n11 }\n12 return true;\n13 }\n\
    ```\nFig. 12: batchTransfer function in BEC contract.\n\nvulnerability is caused\
    \ by the unchecked multiplication of cnt and value in Line [3.](#page-11-1) If\
    \ an attacker calls batchTransfer with a large cnt value, the unsigned integer\
    \ amount will overflow, potentially allowing the attacker to receive more tokens\
    \ than intended. However, such a transaction would violate invariant c1 in Table\
    \ [II,](#page-8-0) as the totalSupply would no longer equal to the sum of all\
    \ balances. Thus, such an attack can be effectively prevented, if the generated\
    \ invariants are enforced for each function execution.\n\nINVCON+ is unable to\
    \ detect some remarkable mistakes that totally deviate from programmer expectations.\
    \ For example, v11 is a vulnerability that allows any party to halt the token\
    \ transfer process. This issue arises from the modification of the onlyFromWallet\
    \ modifier, wherein \"==\" was mistakenly replaced with \"!=\". Consequently,\
    \ anyone other than walletAddress can arbitrarily invoke the two permissioned\
    \ functions: enableTokenTransfer and disableTokenTransfer. INVCON+ failed to detect\
    \ this vulnerability for two primary reasons. First, the onlyFromWallet function\
    \ is not specified in the ERC20 standard, preventing the application of the existing\
    \ invariant templates. Second, the contract histories contain many irregular behaviors\
    \ exploiting these functions, hindering INVCON+ from inferring correct invariants\
    \ related to onlyFromWallet.\n\nAnswer to RQ3: INVCON+ is able to detect invariants\
    \ that are useful for preventing real-world smart contract vulnerabilities. Enforcing\
    \ invariants in contract executions may ensure the security and reliability of\
    \ smart contracts.\n\n# VII. RELATED WORK\n\n<span id=\"page-11-0\"></span>The\
    \ related works can be broadly categorized into smart contract security analysis\
    \ and invariant inference.\n\n# *A. Smart Contract Security Analysis*\n\nThe security\
    \ analysis primarily focuses on detecting smart contract vulnerabilities. Common\
    \ vulnerabilities in smart contracts include integer overflow/underflow [\\[36\\\
    ]](#page-13-35), reentrancy [\\[37\\]](#page-13-36), and dangerous delegatecall\
    \ operations [\\[38\\]](#page-13-37). For instance, in 2017, the Parity wallet\
    \ contract was hacked due to missing protection for the delegatecall operation,\
    \ a feature that allows\n\n<span id=\"page-12-1\"></span>\n\n| ID  | Vulnerability\
    \ Types                           | Total | Detected |\n|-----|-----------------------------------------------|-------|----------|\n\
    | v1  | batchTransfer-overflow                        | 13    | Yes      |\n|\
    \ v2  | totalsupply-overflow                          | 521   | Yes      |\n|\
    \ v3  | verify-invalid-by-overflow                    | 2     | Yes      |\n|\
    \ v4  | owner-control-sell-price-for<br>overflow      | 1     | Yes      |\n|\
    \ v5  | owner-overweight-token-by<br>overflow         | 9     | Yes      |\n|\
    \ v6  | owner-decrease-balance-by-mint<br>by-overflow | 487   | Yes      |\n|\
    \ v7  | excess-allocation-by-overflow                 | 1     | Yes      |\n|\
    \ v8  | excess-mint-token-by-overflow                 | 9     | Yes      |\n|\
    \ v9  | excess-buy-token-by-overflow                  | 4     | Yes      |\n|\
    \ v10 | verify-reverse-in-transferFrom                | 79    | Yes      |\n|\
    \ v11 | pauseTransfer-anyone                          | 1     | No       |\n|\
    \ v12 | transferProxy-keccak256                       | 10    | Yes      |\n|\
    \ v13 | approveProxy-keccak256                        | 10    | Yes      |\n|\
    \ v14 | constructor-case-insensitive                  | 4     | N/A      |\n|\
    \ v15 | custom-fallback-bypass-ds-auth                | 1     | N/A      |\n|\
    \ v16 | custom-call-abuse                             | 144   | N/A      |\n|\
    \ v17 | setowner-anyone                               | 3     | Yes      |\n|\
    \ v18 | allowAnyone                                   | 4     | Yes      |\n|\
    \ v19 | approve-with-balance-verify                   | 18    | Yes      |\n|\
    \ v20 | check-effect-inconsistency                    | 1     | Yes      |\n|\
    \ v21 | constructor-mistyping                         | 4     | N/A      |\n|\
    \ v22 | fake-burn                                     | 2     | Yes      |\n|\
    \ v23 | getToken-anyone                               | 3     | N/A      |\n|\
    \ v24 | constructor-naming-error                      | 1     | N/A      |\n\n\
    one contract to securely delegate part of its functionality to another contract.\
    \ As a result, the attacker gained control of the wallet and stole 150,000 ETH,\
    \ valued at approximately \\$30 million USD at the time.\n\nThese common vulnerabilities\
    \ have been extensively studied in [\\[13\\]](#page-13-12), [\\[39\\]](#page-13-38),\
    \ [\\[40\\]](#page-13-39), [\\[41\\]](#page-13-40), [\\[42\\]](#page-13-41), [\\\
    [43\\]](#page-13-42), [\\[44\\]](#page-13-43), [\\[45\\]](#page-14-0), [\\[46\\\
    ]](#page-14-1), [\\[47\\]](#page-14-2), [\\[48\\]](#page-14-3), [\\[49\\]](#page-14-4),\
    \ [\\[50\\]](#page-14-5). Most static analysis tools, such as Slither [\\[23\\\
    ]](#page-13-22), Securify [\\[42\\]](#page-13-41), Zeus [\\[47\\]](#page-14-2),\
    \ and Ethainter [\\[40\\]](#page-13-39), utilize controlflow, data-flow, or taint-flow\
    \ analysis for vulnerability detection, usually achieving a high recall but low\
    \ precision rate. In contrast, the others [\\[45\\]](#page-14-0), [\\[46\\]](#page-14-1),\
    \ [\\[51\\]](#page-14-6) use symbolic execution for program path exploration to\
    \ identify contract vulnerabilities, along with a higher precision but lower recall\
    \ rate. There are also formal verification tools for ensuring the correctness\
    \ of functional properties [\\[16\\]](#page-13-15), [\\[17\\]](#page-13-16), [\\\
    [52\\]](#page-14-7), and workflow policy [\\[26\\]](#page-13-25) in smart contracts.\
    \ The dynamic analyses [\\[48\\]](#page-14-3), [\\[50\\]](#page-14-5), [\\[53\\\
    ]](#page-14-8), [\\[54\\]](#page-14-9), [\\[55\\]](#page-14-10) perform random\
    \ or model-based testing on smart contracts and then check execution result against\
    \ predefined oracles for finding a wide range of vulnerabilities. Although these\
    \ tools have been proven effective in detecting common vulnerabilities, unfortunately,\
    \ Zhang et al. [\\[56\\]](#page-14-11) found that only 20.5% of realworld smart\
    \ contract bugs can be successfully detected by state-of-the-art tools. This is\
    \ because the existing tools use simple, generic, and hard-coded security patterns\
    \ or oracles, which are ineffective to recognize subtle logic bugs on specific\
    \ contracts.\n\nBecause there is no one-for-all patterns or oracles for identifying\
    \ contract logic bugs, most valued Web3 projects hire third-party security auditing\
    \ companies to manually review their contracts. Despite undergoing costly code\
    \ auditing, numerous projects still fall victim to security breaches [\\[57\\\
    ]](#page-14-12). In our opinion, one root cause is that contract developers and\
    \ the corresponding auditors may have divergent expectations on smart contracts,\
    \ which are not easy to pinpoint without sufficient contract specifications. Therefore,\
    \ apart from enhancing existing security tools, the invariants generated by INVCON+\
    \ can reinforce contract specifications to mitigate the incompleteness and inaccuracy\
    \ issues of automated verification and contract auditing.\n\n# *B. Invariant Inference*\n\
    \nThe static and dynamic invariant inference have been wellstudied for traditional\
    \ programs. ESC/Java [\\[58\\]](#page-14-13) is a wellknown static checking tool\
    \ for Java programs. It leverages invariant annotations to define properties in\
    \ the code, improving the precision of static checking. ESC/Java's emphasis on\
    \ invariants helps developers express expectations precisely, allowing potential\
    \ issues to be detected early in development. Daikon [\\[11\\]](#page-13-10) is\
    \ a well-known dynamic invariant detection tool to automatically infer likely\
    \ invariants from program executions. Daikon takes program execution traces as\
    \ input, which are typically obtained through testing. These execution traces\
    \ consist of sequences of program states and variable values observed during the\
    \ program's runtime. InvCon [\\[18\\]](#page-13-17) was the first tool that generates\
    \ *likely* invariants for smart contracts. With Daikon as the back-end invariant\
    \ detection engine, InvCon implemented an intermediary input transformer that\
    \ coverts historic contract transactions to the compatible data trace files accepted\
    \ by Daikon. In addition, some invariant templates are customized to support unique\
    \ Solidity features, e.g., MappingItem.\n\nThere also exist other works related\
    \ to invariant generation for smart contracts. SolType [\\[15\\]](#page-13-14)\
    \ is a type checking tool for Solidity smart contracts. It enables developers\
    \ to add refinement type annotations to smart contracts, incorporating static\
    \ analysis to prove that arithmetic operations are safe from integer overflows\
    \ or underflows. SolType can infer useful type annotations, but they are limited\
    \ to only contract-level invariants related to arithmetic operation. Using SolType\
    \ as a verifier to learn a policy, Cider [\\[19\\]](#page-13-18) applys deep reinforcement\
    \ learning to automatically learn contract invariants. The learned contract invariants\
    \ are mainly used to guard arithmetic operations in smart contracts to avoid integer\
    \ overflows and underflows. However, the correctness of the learned contract invariants\
    \ is still not formally verified.\n\nDistinguished from the aforementioned works,\
    \ INVCON+ is the first to implement a unified invariant generation framework for\
    \ Solidity contracts encompassing techniques from both dynamic detection and static\
    \ inference, where the the generated invariants are verified against the contract\
    \ code.\n\n# VIII. CONCLUSION\n\n<span id=\"page-12-0\"></span>We have presented\
    \ INVCON+, a novel invariant generation framework for Solidity smart contracts\
    \ where the invariants result from the integration between dynamic invariant detection\
    \ and static inference. Because implication invariants are important to capture\
    \ more fine-grained program semantics of smart contracts, INVCON+ devises an iterative\
    \ process to\n\nrepeat the generation and verification of implications to overcome\
    \ its combination explosion problem. We have evaluated INVCON+ on real-world ERC20\
    \ and ERC721 contracts and demonstrated that INVCON+ is able to achieve good recall\
    \ to recover common specifications. In addition, the experiments on mutation testing\
    \ and vulnerable benchmark contracts have shown that the invariant specifications\
    \ generated are effective to exclude program mistakes and make contracts secure\
    \ from vulnerabilities.\n\n# REFERENCES\n\n- <span id=\"page-13-0\"></span>[1]\
    \ G. Wood, \"Ethereum: A secure decentralised generalised transaction ledger,\"\
    \ *Ethereum project yellow paper*, vol. 151, pp. 1–32, 2014.\n- <span id=\"page-13-1\"\
    ></span>[2] \"Binance Smart Chain,\" https://docs.binance.[org/smart-chain/guides/bsc](https://docs.binance.org/smart-chain/guides/bsc-intro.html)intro.[html,](https://docs.binance.org/smart-chain/guides/bsc-intro.html)\
    \ 2020, introduction of Binance Smart Chain.\n- <span id=\"page-13-2\"></span>[3]\
    \ T. Chen, Y. Zhang, Z. Li, X. Luo, T. Wang, R. Cao, X. Xiao, and X. Zhang, \"\
    Tokenscope: Automatically detecting inconsistent behaviors of cryptocurrency tokens\
    \ in Ethereum,\" in *Proceedings of the 2019 ACM SIGSAC conference on computer\
    \ and communications security*, 2019, pp. 1503–1520.\n- <span id=\"page-13-3\"\
    ></span>[4] H.-A. Moon and S. Park, \"Conformance evaluation of the top-100 Ethereum\
    \ token smart contracts with Ethereum Request for Comment-20 functional specifications,\"\
    \ *IET Software*, vol. 16, no. 2, pp. 233–249, 2022.\n- <span id=\"page-13-4\"\
    ></span>[5] \"EIP-20: A standard interface for tokens,\" [https://eips](https://eips.ethereum.org/EIPS/eip-20).ethereum.org/EIPS/\
    \ [eip-20,](https://eips.ethereum.org/EIPS/eip-20) 2015.\n- <span id=\"page-13-5\"\
    ></span>[6] Y. Guo, *An Incompatibility in Ethereum Smart Contract Threatening\
    \ dApp Ecosystem*, 2018. [Online]. Available: https://medium.loopring.[io/an-incompatibility-in-smart-contract](https://medium.loopring.io/an-incompatibility-in-smart-contract-threatening-dapp-ecosystem-72b8ca5db4da)[threatening-dapp-ecosystem-72b8ca5db4da](https://medium.loopring.io/an-incompatibility-in-smart-contract-threatening-dapp-ecosystem-72b8ca5db4da)\n\
    - <span id=\"page-13-6\"></span>[7] A. Hui, \"Ethereum tokens worth \\$1b vulnerable\
    \ to 'Fake Deposit Attack',\" 2020. [Online]. Available: https://www.coindesk.[com/tech/2020/08/25/](https://www.coindesk.com/tech/2020/08/25/ethereum-tokens-worth-1b-vulnerable-to-fake-deposit-attack/)\
    \ [ethereum-tokens-worth-1b-vulnerable-to-fake-deposit-attack/](https://www.coindesk.com/tech/2020/08/25/ethereum-tokens-worth-1b-vulnerable-to-fake-deposit-attack/)\n\
    - <span id=\"page-13-7\"></span>[8] \"OpenZeppelin,\" https://github.[com/OpenZeppelin/openzeppelin](https://github.com/OpenZeppelin/openzeppelin-contracts)[contracts,](https://github.com/OpenZeppelin/openzeppelin-contracts)\
    \ 2022, openZeppelin contracts.\n- <span id=\"page-13-8\"></span>[9] \"Inconsistency\
    \ between the code and the doc of VestingWallet.release,\" https://github.[com/OpenZeppelin/openzeppelin-contracts/](https://github.com/OpenZeppelin/openzeppelin-contracts/issues/3368)\
    \ [issues/3368,](https://github.com/OpenZeppelin/openzeppelin-contracts/issues/3368)\
    \ 2022.\n- <span id=\"page-13-9\"></span>[10] C. Zhu, Y. Liu, X. Wu, and Y. Li,\
    \ \"Identifying Solidity smart contract API documentation errors,\" in *Proceedings\
    \ of the 37th IEEE/ACM International Conference on Automated Software Engineering\
    \ (ASE)*, Oct. 2022.\n- <span id=\"page-13-10\"></span>[11] \"Daikon,\" http://plse.cs.washington.[edu/daikon/,](http://plse.cs.washington.edu/daikon/)\
    \ 2021, the Daikon invariant detector.\n- <span id=\"page-13-11\"></span>[12]\
    \ C. Flanagan and K. R. M. Leino, \"Houdini, an annotation assistant for esc/java,\"\
    \ in *International Symposium of Formal Methods Europe*. Springer, 2001, pp. 500–517.\n\
    - <span id=\"page-13-12\"></span>[13] H. Wang, Y. Liu, Y. Li, S.-W. Lin, C. Artho,\
    \ L. Ma, and Y. Liu, \"Oracle-supported dynamic exploit generation for smart contracts,\"\
    \ *IEEE Transactions on Dependable and Secure Computing*, 2020.\n- <span id=\"\
    page-13-13\"></span>[14] A. Li, J. A. Choi, and F. Long, \"Securing smart contract\
    \ with runtime validation,\" in *Proceedings of the 41st ACM SIGPLAN Conference\
    \ on Programming Language Design and Implementation*, 2020, pp. 438–453.\n- <span\
    \ id=\"page-13-14\"></span>[15] B. Tan, B. Mariano, S. K. Lahiri, I. Dillig, and\
    \ Y. Feng, \"Soltype: refinement types for arithmetic overflow in solidity,\"\
    \ *Proceedings of the ACM on Programming Languages*, vol. 6, no. POPL, pp. 1–29,\
    \ 2022.\n- <span id=\"page-13-15\"></span>[16] S. So, M. Lee, J. Park, H. Lee,\
    \ and H. Oh, \"VeriSmart: A highly precise safety verifier for Ethereum smart\
    \ contracts,\" in *2020 IEEE Symposium on Security and Privacy (SP)*. IEEE, 2020,\
    \ pp. 1678–1694.\n- <span id=\"page-13-16\"></span>[17] A. Hajdu and D. Jovanovi\
    \ ´ c, \"solc-verify: A modular verifier for solidity ´ smart contracts,\" in\
    \ *Verified Software. Theories, Tools, and Experiments: 11th International Conference,\
    \ VSTTE 2019, New York City, NY, USA, July 13–14, 2019, Revised Selected Papers\
    \ 11*. Springer, 2020, pp. 161–179.\n- <span id=\"page-13-17\"></span>[18] Y.\
    \ Liu and Y. Li, \"Invcon: A dynamic invariant detector for ethereum smart contracts,\"\
    \ in *Proceedings of the 37th IEEE/ACM International Conference on Automated Software\
    \ Engineering*, 2022, pp. 1–4.\n- <span id=\"page-13-18\"></span>[19] J. Liu,\
    \ Y. Chen, B. Tan, I. Dillig, and Y. Feng, \"Learning contract invariants using\
    \ reinforcement learning,\" in *Proceedings of the 37th IEEE/ACM International\
    \ Conference on Automated Software Engineering*, 2022, pp. 1–11.\n- <span id=\"\
    page-13-19\"></span>[20] \"Openzeppelin erc20 contract specifications.\" [Online].\
    \ Available: https://github.[com/OpenZeppelin/openzeppelin-contracts/blob/](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/certora/specs/ERC20.spec)\
    \ [master/certora/specs/ERC20](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/certora/specs/ERC20.spec).spec\n\
    - <span id=\"page-13-20\"></span>[21] \"Openzeppelin erc721 contract specifications.\"\
    \ [Online]. Available: https://github.[com/OpenZeppelin/openzeppelin-contracts/blob/](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/certora/specs/ERC721.spec)\
    \ [master/certora/specs/ERC721](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/certora/specs/ERC721.spec).spec\n\
    - <span id=\"page-13-21\"></span>[22] G. Ros,u, \"ERC20-K: Formal Executable Specification\
    \ of ERC20,\" Mar. 2023, original-date: 2017-11-20T22:28:46Z. [Online]. Available:\
    \ https://github.[com/runtimeverification/erc20-semantics](https://github.com/runtimeverification/erc20-semantics)\n\
    - <span id=\"page-13-22\"></span>[23] \"Slither,\" https://github.[com/crytic/slither,](https://github.com/crytic/slither)\
    \ 2021, the Solidity Source Analyzer.\n- <span id=\"page-13-23\"></span>[24] H.\
    \ Wang, Y. Li, S.-W. Lin, L. Ma, and Y. Liu, \"VULTRON: Catching vulnerable smart\
    \ contracts once and for all,\" in *Proceedings of the 41st International Conference\
    \ on Software Engineering: New Ideas and Emerging Results (ICSE-NIER)*. IEEE Press,\
    \ 5 2019, pp. 1–4.\n- <span id=\"page-13-24\"></span>[25] M. Barnett, B.-Y. E.\
    \ Chang, R. DeLine, B. Jacobs, and K. R. M. Leino, \"Boogie: A modular reusable\
    \ verifier for object-oriented programs,\" in *Formal Methods for Components and\
    \ Objects: 4th International Symposium, FMCO 2005, Amsterdam, The Netherlands,\
    \ November 1-4, 2005, Revised Lectures 4*. Springer, 2006, pp. 364–387.\n- <span\
    \ id=\"page-13-25\"></span>[26] Y. Wang, S. K. Lahiri, S. Chen, R. Pan, I. Dillig,\
    \ C. Born, and I. Naseer, \"Formal specification and verification of smart contracts\
    \ for Azure blockchain,\" *arXiv preprint arXiv:1812.08829*, 2018.\n- <span id=\"\
    page-13-26\"></span>[27] M. Research, \"Z3,\" https://github.[com/Z3Prover/z3,](https://github.com/Z3Prover/z3)\
    \ 2022, accessed: December 15, 2023.\n- <span id=\"page-13-27\"></span>[28] E.\
    \ Hildenbrandt, M. Saxena, N. Rodrigues, X. Zhu, P. Daian, D. Guth, B. Moore,\
    \ D. Park, Y. Zhang, A. Stefanescu *et al.*, \"KEVM: A complete formal semantics\
    \ of the Ethereum virtual machine,\" in *2018 IEEE 31st Computer Security Foundations\
    \ Symposium (CSF)*. IEEE, 2018, pp. 204–217.\n- <span id=\"page-13-28\"></span>[29]\
    \ X. Li, C. Su, Y. Xiong, W. Huang, and W. Wang, \"Formal verification of bnb\
    \ smart contract,\" in *2019 5th International Conference on Big Data Computing\
    \ and Communications (BIGCOM)*. IEEE, 2019, pp. 74–78.\n- <span id=\"page-13-29\"\
    ></span>[30] E. ETL, \"Ethereum in BigQuery: a public dataset for smart contract\
    \ analytics,\" https://cloud.google.[com/blog/products/data-analytics/ethereum](https://cloud.google.com/blog/products/data-analytics/ethereum-bigquery-public-dataset-smart-contract-analytics)[bigquery-public-dataset-smart-contract-analytics,](https://cloud.google.com/blog/products/data-analytics/ethereum-bigquery-public-dataset-smart-contract-analytics)\
    \ 2017.\n- <span id=\"page-13-30\"></span>[31] \"Openzeppelin pausable contract\
    \ specifications.\" [Online]. Available: https://github.[com/OpenZeppelin/openzeppelin-contracts/blob/](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/certora/specs/Pausable.spec)\
    \ [master/certora/specs/Pausable](https://github.com/OpenZeppelin/openzeppelin-contracts/blob/master/certora/specs/Pausable.spec).spec\n\
    - <span id=\"page-13-31\"></span>[32] OpenZeppelin, \"ERC 20 - OpenZeppelin Docs.\"\
    \ [Online]. Available: https://docs.openzeppelin.com/contracts/3.[x/api/token/ERC20](https://docs.openzeppelin.com/contracts/3.x/api/token/ERC20)\n\
    - <span id=\"page-13-32\"></span>[33] \"ERC 721 - OpenZeppelin Docs.\" [Online].\
    \ Available: [https:](https://docs.openzeppelin.com/contracts/2.x/api/token/ERC721)\
    \ //docs.openzeppelin.com/contracts/2.[x/api/token/ERC721](https://docs.openzeppelin.com/contracts/2.x/api/token/ERC721)\n\
    - <span id=\"page-13-33\"></span>[34] Certora, \"Gambit: Mutant generation for\
    \ Solidity,\" [https://github](https://github.com/Certora/gambit).com/ [Certora/gambit,](https://github.com/Certora/gambit)\
    \ 2022, accessed: December 9, 2023.\n- <span id=\"page-13-34\"></span>[35] S.\
    \ Labs, \"sec-bit/awesome-buggy-erc20-tokens: A Collection of Vulnerabilities\
    \ in ERC20 Smart Contracts With Tokens Affected,\" Aug. 2018. [Online]. Available:\
    \ https://github.[com/sec-bit/awesome-buggy](https://github.com/sec-bit/awesome-buggy-erc20-tokens)[erc20-tokens](https://github.com/sec-bit/awesome-buggy-erc20-tokens)\n\
    - <span id=\"page-13-35\"></span>[36] Blockchain-Projects, \"Overflow attack in\
    \ Ethereum smart contracts,\" https://blockchain-projects.readthedocs.io/overflow.html,\
    \ 2020.\n- <span id=\"page-13-36\"></span>[37] D. Siegel, *Understanding The DAO\
    \ Attack*, 2016. [Online]. Available: https://www.coindesk.[com/understanding-dao-hack-journalists](https://www.coindesk.com/understanding-dao-hack-journalists)\n\
    - <span id=\"page-13-37\"></span>[38] P. Santiago, *The Parity Wallet Hack Explained*,\
    \ 2017. [Online]. Available: https://blog.openzeppelin.[com/on-the-parity-wallet-multisig](https://blog.openzeppelin.com/on-the-parity-wallet-multisig-hack-405a8c12e8f7/)[hack-405a8c12e8f7/](https://blog.openzeppelin.com/on-the-parity-wallet-multisig-hack-405a8c12e8f7/)\n\
    - <span id=\"page-13-38\"></span>[39] J. Feist, G. Grieco, and A. Groce, \"Slither:\
    \ A static analysis framework for smart contracts,\" in *2019 IEEE/ACM 2nd International\
    \ Workshop on Emerging Trends in Software Engineering for Blockchain (WETSEB)*.\
    \ IEEE, 2019, pp. 8–15.\n- <span id=\"page-13-39\"></span>[40] L. Brent, N. Grech,\
    \ S. Lagouvardos, B. Scholz, and Y. Smaragdakis, \"Ethainter: a smart contract\
    \ security analyzer for composite vulnerabilities,\" in *Proceedings of the 41st\
    \ ACM SIGPLAN Conference on Programming Language Design and Implementation*, 2020,\
    \ pp. 454–469.\n- <span id=\"page-13-40\"></span>[41] S. Tikhomirov, E. Voskresenskaya,\
    \ I. Ivanitskiy, R. Takhaviev, E. Marchenko, and Y. Alexandrov, \"Smartcheck:\
    \ Static analysis of Ethereum smart contracts,\" in *Proceedings of the 1st International\
    \ Workshop on Emerging Trends in Software Engineering for Blockchain*, 2018, pp.\
    \ 9–16.\n- <span id=\"page-13-41\"></span>[42] *Securify*, Sofware Reliability\
    \ Lab, 2019. [Online]. Available: [https:](https://securify.ch/) [//securify](https://securify.ch/).ch/\n\
    - <span id=\"page-13-42\"></span>[43] Y. Feng, E. Torlak, and R. Bodik, \"Precise\
    \ Attack Synthesis for Smart Contracts,\" *arXiv preprint arXiv:1902.06067*, 2019.\n\
    - <span id=\"page-13-43\"></span>[44] L. Luu, D.-H. Chu, H. Olickel, P. Saxena,\
    \ and A. Hobor, \"Making smart contracts smarter,\" in *Proceedings of the 2016\
    \ ACM SIGSAC conference on computer and communications security*. ACM, 2016, pp.\
    \ 254–269.\n- <span id=\"page-14-0\"></span>[45] \"Manticore,\" https://github\
    \ .[com/trailofbits/manticore,](https://github.com/trailofbits/manticore) 2019,\
    \ symbolic Execution Tool for Smart Contracts.\n- <span id=\"page-14-1\"></span>[46]\
    \ \"Mythril,\" https://github .[com/ConsenSys/mythril,](https://github.com/ConsenSys/mythril)\
    \ 2019, a Security Analysis Tool for EVM Bytecode.\n- <span id=\"page-14-2\"></span>[47]\
    \ S. Kalra, S. Goel, M. Dhawan, and S. Sharma, \"Zeus: Analyzing safety of smart\
    \ contracts,\" in *Ndss*, 2018, pp. 1–12.\n- <span id=\"page-14-3\"></span>[48]\
    \ B. Jiang, Y. Liu, and W. Chan, \"Contractfuzzer: Fuzzing smart contracts for\
    \ vulnerability detection,\" in *Proceedings of the 33rd ACM/IEEE International\
    \ Conference on Automated Software Engineering*. ACM, 2018, pp. 259–269.\n- <span\
    \ id=\"page-14-4\"></span>[49] V. Wustholz and M. Christakis, \"Harvey: A greybox\
    \ fuzzer for smart ¨ contracts,\" in *Proceedings of the 28th ACM Joint Meeting\
    \ on European Software Engineering Conference and Symposium on the Foundations\
    \ of Software Engineering*, 2020, pp. 1398–1409.\n- <span id=\"page-14-5\"></span>[50]\
    \ *Echidna*, Trail of Bits, 2019. [Online]. Available: [https://github](https://github.com/trailofbits/echidna)\
    \ .com/ [trailofbits/echidna](https://github.com/trailofbits/echidna)\n- <span\
    \ id=\"page-14-6\"></span>[51] \"Oyente,\" https://github .[com/melonproject/oyente,](https://github.com/melonproject/oyente)\
    \ 2019, an Analysis Tool for Smart Contracts.\n- <span id=\"page-14-7\"></span>[52]\
    \ A. Permenev, D. Dimitrov, P. Tsankov, D. Drachsler-Cohen, and M. Vechev, \"\
    Verx: Safety verification of smart contracts,\" in *2020 IEEE symposium on security\
    \ and privacy (SP)*. IEEE, 2020, pp. 1661–1677.\n- <span id=\"page-14-8\"></span>[53]\
    \ H. Wang, Y. Liu, Y. Li, S.-W. Lin, C. Artho, L. Ma, and Y. Liu, \"Oracle-supported\
    \ dynamic exploit generation for smart contracts,\" *IEEE Transactions on Dependable\
    \ and Secure Computing*, 2020.\n- <span id=\"page-14-9\"></span>[54] T. D. Nguyen,\
    \ L. H. Pham, J. Sun, Y. Lin, and Q. T. Minh, \"sfuzz: An efficient adaptive fuzzer\
    \ for solidity smart contracts,\" in *Proceedings of the ACM/IEEE 42nd International\
    \ Conference on Software Engineering* , 2020, pp. 778–788.\n- <span id=\"page-14-10\"\
    ></span>[55] Y. Liu, Y. Li, S.-W. Lin, and C. Artho, \"Finding permission bugs\
    \ in smart contracts with role mining,\" in *Proceedings of the 31st ACM SIGSOFT\
    \ International Symposium on Software Testing and Analysis (ISSTA)*. New York,\
    \ NY, USA: ACM, Jul. 2022, pp. 716–727.\n- <span id=\"page-14-11\"></span>[56]\
    \ Z. Zhang, B. Zhang, W. Xu, and Z. Lin, \"Demystifying exploitable bugs in smart\
    \ contracts.\" ICSE, 2023.\n- <span id=\"page-14-12\"></span>[57] Sayfer, \"3\
    \ Hacks an Audit Could Not Find,\" [https://sayfer](https://sayfer.io/blog/3-hacks-an-audit-could-not-find/)\
    \ .io/blog/3 [hacks-an-audit-could-not-find/,](https://sayfer.io/blog/3-hacks-an-audit-could-not-find/)\
    \ 2023, accessed: December 18, 2023.\n- <span id=\"page-14-13\"></span>[58] C.\
    \ Flanagan, K. R. M. Leino, M. Lillibridge, G. Nelson, J. B. Saxe, and R. Stata,\
    \ \"Extended static checking for java,\" in *Proceedings of the ACM SIGPLAN 2002\
    \ Conference on Programming language design and implementation*, 2002, pp. 234–245."
- title: "Fixing Your Own Smells: Adding a Mistake-Based Familiarisation Step When\n\
    \  Teaching Code Refactoring"
  abstract: 'Programming problems can be solved in a multitude of functionally correct

    ways, but the quality of these solutions (e.g. readability, maintainability)

    can vary immensely. When code quality is poor, symptoms emerge in the form of

    ''code smells'', which are specific negative characteristics (e.g. duplicate

    code) that can be resolved by applying refactoring patterns. Many undergraduate

    computing curricula train students on this software engineering practice, often

    doing so via exercises on unfamiliar instructor-provided code. Our observation,

    however, is that this makes it harder for novices to internalise refactoring as

    part of their own development practices. In this paper, we propose a new

    approach to teaching refactoring, in which students must first complete a

    programming exercise constrained to ensure they will produce a code smell. This

    simple intervention is based on the idea that learning refactoring is easier if

    students are familiar with the code (having built it), that it brings

    refactoring closer to their regular development practice, and that it presents

    a powerful opportunity to learn from a ''mistake''. We designed and conducted
    a

    study with 35 novice undergraduates in which they completed various refactoring

    exercises alternately taught using a traditional and our ''mistake-based''

    approach, finding that students were significantly more effective and confident

    at completing exercises using the latter.'
  url: http://arxiv.org/abs/2401.01011v1
  keywords: ''
  document: '# Fixing Your Own Smells: Adding a Mistake-Based Familiarisation Step
    When Teaching Code Refactoring


    [Ivan Tan](https://orcid.org/0009-0001-6300-5445) Singapore Management University
    Singapore ivantan@smu.edu.sg


    ABSTRACT


    Programming problems can be solved in a multitude of functionally correct ways,
    but the quality of these solutions (e.g. readability, maintainability) can vary
    immensely. When code quality is poor, symptoms emerge in the form of ''code smells'',
    which are specific negative characteristics (e.g. duplicate code) that can be
    resolved by applying refactoring patterns. Many undergraduate computing curricula
    train students on this software engineering practice, often doing so via exercises
    on unfamiliar instructor-provided code. Our observation, however, is that this
    makes it harder for novices to internalise refactoring as part of their own development
    practices. In this paper, we propose a new approach to teaching refactoring, in
    which students must first complete a programming exercise constrained to ensure
    they will produce a code smell. This simple intervention is based on the idea
    that learning refactoring is easier if students are familiar with the code (having
    built it), that it brings refactoring closer to their regular development practice,
    and that it presents a powerful opportunity to learn from a ''mistake''. We designed
    and conducted a study with 35 novice undergraduates in which they completed various
    refactoring exercises alternately taught using a traditional and our ''mistake-based''
    approach, finding that students were significantly more effective and confident
    at completing exercises using the latter.


    # CCS CONCEPTS


    • Social and professional topics → Computing education; • Software and its engineering
    → Maintaining software.


    ## KEYWORDS


    Refactoring, code smells, code quality, software maintenance, software engineering,
    mistake-based learning, undergraduate course


    #### ACM Reference Format:


    Ivan Tan and Christopher M. Poskitt. 2024. Fixing Your Own Smells: Adding a Mistake-Based
    Familiarisation Step When Teaching Code Refactoring. In Proceedings of the 55th
    ACM Technical Symposium on Computer Science Education V. 1 (SIGCSE 2024), March
    20–23, 2024, Portland, OR, USA. ACM, New York, NY, USA, [7](#page-6-0) pages.<https://doi.org/10.1145/3626252.3630856>


    ![](_page_0_Picture_10.jpeg)


    [This work is licensed under a Creative Commons Attribution](https://creativecommons.org/licenses/by/4.0/)
    [International 4.0 License.](https://creativecommons.org/licenses/by/4.0/)


    SIGCSE 2024, March 20–23, 2024, Portland, OR, USA © 2024 Copyright held by the
    owner/author(s). ACM ISBN 979-8-4007-0423-9/24/03. <https://doi.org/10.1145/3626252.3630856>


    [Christopher M. Poskitt](https://orcid.org/0000-0002-9376-2471) Singapore Management
    University Singapore cposkitt@smu.edu.sg


    #### 1 INTRODUCTION


    Given any reasonably complex programming problem, there will be a multitude of
    functionally correct implementations that solve it. Two solutions that always
    generate the intended outputs, however, are not always equally good. Students
    are exposed to this fact early when they compare the performance of alternative
    solutions using recursion vs. iteration, or quicksort vs. bogosort [\[13\]](#page-6-1).
    Runtime performance, however, is not the only way that two solutions can differ:
    their code quality can vary immensely too. ''Code quality'' encompasses non-functional
    structural properties that arise from good engineering practices, e.g. readability
    and maintainability [\[7,](#page-6-2) [26\]](#page-6-3). In particular, a high-quality
    codebase is said to exhibit high cohesion and low coupling [\[20\]](#page-6-4):
    functionally related elements are grouped together in modules, and those modules
    are sufficiently independent such that implementation changes in one should not
    cause another to inexplicably break. When these principles are violated, concrete
    symptoms can emerge in the form of code smells [\[28\]](#page-6-5), which are
    characteristics (e.g. the presence of duplicate code) that may indicate deeper
    problems. In order to remove smells and improve code quality, software engineers
    apply refactoring patterns that produce functionally equivalent but ''odourless''
    code [\[10\]](#page-6-6).


    In undergraduate computing curricula, refactoring is typically introduced in software
    engineering modules taken after learning the fundamentals of programming. A traditional
    delivery of the topic might teach a few examples of code smells, some corresponding
    refactoring patterns, and then challenge the students to apply them to some functionally
    correct (but smelly) instructor-provided code. These exercises can be facilitated
    in a classroom or as part of an interactive online tutoring system [\[19\]](#page-6-7).
    While this mode of delivery has many advantages—the provided code is already working
    and simply needs refactoring—our own experiences have suggested that using instructor-provided
    code can make it harder for novices to internalise the concept into their own
    development practices. This is because refactoring is introduced as a standalone
    exercise on someone else''s code, rather than introducing it as a regular activity
    to be undertaken in any project they are developing.


    In this paper, we propose a new approach to teaching code refactoring that embeds
    the concept as part of a multi-step exercise. Students are first tasked to complete
    a programming exercise that is designed to ensure they will unwittingly produce
    smelly (but functionally correct) code. The goal of this step is not to ''bait''
    students, but to ensure that they are familiar with the code to be refactored.
    Following this, they are taught to identify the smell that is present, and how
    to refactor it towards an odourless solution. This simple intervention is based
    on three key ideas: (1) that learning refactoring is simpler if students are already
    familiar with the targeted code, having written it themselves; (2) that the approach


    aligns and embeds refactoring as part of their own coding practice; and (3) that
    ''mistakes''—in our case, induced code smells—present effective learning opportunities
    [\[6\]](#page-6-8).


    To assess the efficacy of this intervention, we conducted a study with 35 novice
    undergradate students. We asked them to complete two groups of refactoring exercises
    for which the code smells were alternately taught using our ''mistake-based''
    familiarisation approach or a traditional one. We found that our approach led
    to significantly higher code smell identification and refactoring success rates,
    suggesting that students are able to apply the concepts more effectively. The
    results encourage us to further explore mistake-based teaching approaches in other
    computing courses, e.g. improving the learning opportunities in security courses
    by demonstrating the presence of security flaws in student code [\[25\]](#page-6-9).


    #### 2 RELATED WORK


    In an ITiCSE''17 working group report, Börstler et al. [\[7\]](#page-6-2) analysed
    interviews with 34 students, educators, and developers on their perceptions of
    code quality. They found that code quality was mostly understood in terms of indicators
    such as ''readability'', which are measures that code smells would score poorly
    against. Notably, their interviewees ranked ''education'' lowest as the source
    they used most for learning about code quality, suggesting that undergraduate
    programmes can discuss the topic more thoroughly. Effenberger and Pelánek [\[8\]](#page-6-10)
    buttress this point through their analysis of 114,000 functionally correct solutions
    in their introductory programming class, finding most of them to contain quality
    defects.


    Bezerra et al. [\[4\]](#page-6-11) conducted a study on the perceptions and challenges
    of undergraduate students when teaching code quality through code smell refactoring.
    They highlighted a number of benefits, such as an improvement in problem solving
    and interpersonal skills, as well as a number of difficulties such as the fact
    that refactoring code can lead to new smells to further refactor. They also observed
    that students found it more complicated to refactor smells when they struggled
    to interpret the source code—a problem our approach attempts to address by having
    students construct the code first in our familiarisation step.


    Various techniques have been proposed for teaching code refactoring to undergraduates.
    For instance, Haendler et al. [\[16\]](#page-6-12) developed an interactive web-based
    tutor in which smelly code is visualised in UML (''as-is'') and students are challenged
    to refactor it towards a targeted design (''to-be''). The web-based tutor of Keuning
    et al. [\[18,](#page-6-13) [19\]](#page-6-7) allows students to request feedback
    which is generated based on some predefined rules provided by teachers, e.g. rewrite
    steps. In contrast, Haendler and Neumann [\[15\]](#page-6-14) proposed designing
    ''serious games'' for teaching refactoring. Students are presented with larger
    real-world code artefacts that are functionally correct but smelly, and are challenged
    to refactor them competitively. Izu et al. [\[17\]](#page-6-15) provide rules
    for simplifying conditional statements and some practice tasks to help students
    understand how to apply them. In all these examples, smelly code is provided to
    students: our approach differs in that students build the smelly code, and thus
    can learn about refactoring using code that they are more familiar with.


    Several existing tools can help to automatically identify smells [\[9\]](#page-6-16)
    and assess the quality of code submitted in programming assignments. Hyperstyle
    [\[5\]](#page-6-17), for example, integrates code analysis tools


    into online educational platforms to provide feedback on readability, complexity,
    and patterns of repeated mistakes. Prokic et al. [\[24\]](#page-6-18) integrate
    AI-based code quality assessment algorithms to identify issues as the code is
    written. Our approach is similar in that we focus on the code the student is writing,
    but differs in that we induce a code smell intentionally to create a learning
    opportunity.


    Many studies have demonstrated the effectiveness of learning from mistakes. Borasi
    [\[6\]](#page-6-8) suggests that mistakes can be capitalised as a learning opportunity
    (or as ''springboards'' for inquiry). Papert [\[23\]](#page-6-19) views code debugging
    as such a learning opportunity, and our hypothesis is simply that these opportunities
    can be extended to mistakes in code quality too. Ginat [\[11\]](#page-6-20) used
    erroneous solutions as a means to teach algorithm design: students would be introduced
    to an algorithm containing a common error, and would falsify inputs to trigger
    creative reasoning. Ouh and Irawan [\[22\]](#page-6-21) propose an experiential
    model for teaching software architecture, in which students undertake activities
    that simulate practical risks, helping them to learn how to identify, analyse,
    and resolve such risks in their own architectural solutions. Shar et al. [\[25\]](#page-6-9)
    demonstrated the value of security to web development students by introducing
    them to security scanners, and using them to uncover exploitable code in their
    own projects. Griffin [\[12\]](#page-6-22) highlights the controversy of intentionally
    incorporating errors, but argues that cognitive psychology theories support the
    idea that intentional errors can promote learning. Our work differs in that we
    focus on refactoring, and that a specific code quality ''mistake'' is induced
    in the familiarisation exercise (rather than provided directly by the instructor).


    #### 3 KEY PROBLEMS & RESEARCH QUESTIONS


    Our context is Singapore Management University, where code smells and refactoring
    have been taught in a software engineering module taken by all undergraduate Information
    Systems students. The delivery of this content has previously been ''traditional'',
    in that students were introduced to some key code smells [\[10\]](#page-6-6) and
    refactoring patterns [\[1\]](#page-6-23), then were challenged to address the
    former using the latter in some simple instructor-crafted exercises.


    We observed two key problems in this style of teaching. First, especially for
    novice students, using instructor-provided code for refactoring exercises posed
    a familiarity barrier (KP1). The issue we found was that for code beyond the very
    simplest, some students would struggle at the very first hurdle—familiarisation—and
    this would distract them from the primary learning objectives concerning smells
    and refactoring. Second, we observed that students treated these as isolated exercises
    and were not gaining the confidence to apply refactoring to their own code (KP2).


    Our proposed ''mistake-based'' intervention is inspired by the aforementioned
    works on learning from mistakes [\[6,](#page-6-8) [11,](#page-6-20) [12,](#page-6-22)
    [22,](#page-6-21) [23,](#page-6-19) [25\]](#page-6-9), as well as Abid et al.
    [\[3\]](#page-6-24), who observed benefits from asking students to ''enhance''
    (add features to) existing code before asking them to refactor it. In particular,
    rather than teach refactoring using instructor-provided code, we propose to first
    task students with completing a programming exercise that is designed to induce
    code that contains specific smells. The idea is to ensure that students fully
    understand the code to be refactored (having written it themselves) and thus can
    separate out code familiarisation from code smell analysis in their learning.
    Our intention is not to ''bait'' students: we


    Adding a Mistake-Based Familiarisation Step When Teaching Code Refactoring SIGCSE
    2024, March 20–23, 2024, Portland, OR, USA


    <span id="page-2-0"></span>![](_page_2_Figure_1.jpeg)


    Figure 1: High-level overview of the experiment protocol: participants are randomly
    allocated into two flows (A or B), and apply the two approaches to different code
    smell groups


    see this step as analogous to, for example, a programming exercise that first
    solves for specific inputs before guiding students to solve for all inputs, e.g.
    by replacing conditionals with a loop.


    The overall goal of this paper is to experimentally establish whether our ''mistake-based''
    approach to teaching refactoring solves our key problems (KP1, KP2). To guide
    our experiment design, we refined our goal to three research questions (RQs):


    - RQ1: Which method results in a higher success rate for refactoring exercises?

    - RQ2: Which method did students prefer and find more effective?

    - RQ3: How confident are students at being able to identify code smells in the
    future?


    RQ1 considers whether the introduction of a mistake-based familiarisation step
    helps students to complete refactoring exercises, thus addressing KP1. RQ2 considers
    the students'' subjective views, i.e. which of the methods do they prefer and
    find more effective. Finally, RQ3 addresses KP2, and considers whether students
    are confident that they can apply their refactoring skills in the future.


    #### 4 METHODOLOGY


    In this section, we describe the experiment design, pre-/post-surveys, and participants
    of our study.


    # 4.1 Experiment Design


    Figure [1](#page-2-0) presents a high-level overview of our experimental protocol,
    the detailed steps of which we describe in the following. (The full set of exercises
    is also provided in our supplementary material [\[2\]](#page-6-25).) First, we
    defined two groups of code smells (three smells per group). Group 1 contained
    Long Method, Long Parameter List, and Duplicate Code, whereas Group 2 contained
    Data Clumps, Large Class, and Primitive Obsession [\[10\]](#page-6-6). These were
    selected based on our expertise to ensure a roughly similar balance of difficulty
    and technical complexity between the two groups.


    For each group, we prepared: (1) a Python programming exercise with a template
    designed to induce some smelly code; and (2) the smelly code the exercise is designed
    to induce. Each exercise was set at a novice difficulty, given that the focus
    of the study was on code smells and not coding competency. Group 1''s exercise,
    for example, involved designing an object-oriented class for a sandwich shop (including,
    for example, a method for computing profit). Listing [1](#page-2-1) shows a snippet
    of the provided template (note that Lines [11–17](#page-2-0)


    <span id="page-2-1"></span>


    |    | 1 class Sandwich: |                                                            |  |

    |----|-------------------|------------------------------------------------------------|--|

    | 2  |                   | def __init__(self):                                        |  |

    | 3  |                   | pass                                                       |  |

    | 4  |                   |                                                            |  |

    | 5  |                   | def calculate_profit(self, name, num_sold, recipe,
    price): |  |

    | 6  |                   | profit = 0 # compute this below                            |  |

    | 7  |                   | cost = 0 # add ingredient costs to this                    |  |

    | 8  |                   | discount = 1 # change to 0.8 if num_sold >= 10             |  |

    | 9  |                   |                                                            |  |

    | 10 |                   | # ENTER YOUR CODE BELOW                                    |  |

    | 11 |                   | for ingredient in recipe:                                  |  |

    | 12 |                   | cost += ingredient_cost[ingredient]                        |  |

    | 13 |                   | if num_sold >= 10:                                         |  |

    | 14 |                   | discount = 0.8                                             |  |

    | 15 |                   | price_per_sandwich = price * discount                      |  |

    | 16 |                   | profit_per_sandwich = price_per_sandwich - cost            |  |

    | 17 |                   | profit = num_sold * profit_per_sandwich                    |  |

    | 18 |                   | # ENTER YOUR CODE ABOVE                                    |  |

    | 19 |                   |                                                            |  |

    | 20 |                   | return round(profit, 2)                                    |  |


    Listing 1: Coding exercise snippet. Lines [11–17](#page-2-0) show an example of
    the ''smelly'' code (long method) we expect the exercise to induce, and are blank
    in the mistake-based approach


    are blank in the mistake-based approach; this is the ''smelly'' code we expect
    to induce). The template''s pre-defined methods and parameter lists are designed
    to ensure solutions are largely similar (and in fact, the Long Parameter List
    code smell is guaranteed).


    The study was conducted on a one-to-one basis with a research assistant: apart
    from conducting a briefing and pre-study survey (Section [4.2\)](#page-3-0), the
    research assistant also provided oral instructions at all times. Each student
    was randomly allocated into one of two flows: A or B. Students in flow A were
    asked to apply the traditional approach to the Group 1 smells, followed by the
    mistake-based approach to the Group 2 smells. Students in flow B, however, applied
    the mistake-based approach to Group 1 and the traditional approach to Group 2.
    The specific steps of the approaches are described below.


    For the traditional approach, we asked students to watch some short videos we
    produced [\[2\]](#page-6-25) that explain the code smells relevant to the Group
    using (different) instructor-provided code. Each video introduces a specific code
    smell, explains why it occurs, why it should be refactored, how to refactor it,
    and then provides an example using instructor-provided code snippets. This content
    is conveyed in under four minutes so that the videos remain bite-sized and engaging
    for the participants [\[14\]](#page-6-26). Afterwards, the research assistant
    provided the students with smelly code for the Group directly (e.g. Listing [1](#page-2-1)
    including Lines [11–17\)](#page-2-0). In other words, the participants were asked
    to refactor instructor-provided smelly code based on what they learnt from the
    videos.


    For the mistake-based approach, students were first asked to complete the (smell-inducing)
    programming exercise for Group 1 or 2 based on the template we provided (e.g.
    Listing [1](#page-2-1) excluding Lines [11–17\)](#page-2-0). Again, the exercise
    and template were constrained to ensure that specific code smells from the given
    Group would emerge in the students'' solutions. In the event that a student struggled,
    the research assistant would provide hints to guide them towards the ''smelly''
    solution, so as to ensure that the next part of the experiment would be able to
    carry on. (We remark that hints were only provided in this familiarisation step,
    and not the refactoring exercise, which was the focus of the experiment.) Following
    the coding exercise, the research assistant would provide a brief explanation
    of the code


    <span id="page-3-1"></span>


    | Q1. Do you think your knowledge of code refactoring has improved? (Y/N)                 |

    |-----------------------------------------------------------------------------------------|

    | Q2. How familiar are you with the concept of code refactoring? (Likert)                 |

    | Q3a. How confident are you in identifying code smells from Group 1? (Likert)            |

    | Q3b. How confident are you in identifying code smells from Group 2? (Likert)            |

    | Q4a. How confident are you in refactoring identified code smells from Group
    1? (Likert) |

    | Q4b. How confident are you in refactoring identified code smells from Group
    2? (Likert) |

    | Q5a. Do you understand the videos for the traditional method? (Y/N)                     |

    | Q5b. Did you understand the content covered in the mistake-based approach? (Y/N)        |

    | Q6. How effective was the traditional method? (Likert)                                  |

    | Q7. How effective was the mistake-based approach? (Likert)                              |

    | Q8. Which method did you prefer? (Traditional/Mistake-based/No preference)              |

    | Q9. What did you like/dislike about the traditional method? (Open)                      |

    | Q10. What did you like/dislike about the mistake-based approach? (Open)                 |


    Figure 2: Post-experiment survey (Likert scales are 7-point)


    smells relevant to the Group (following the script used in the videos from the
    traditional approach), before asking the student to identify the smells in their
    own code. For any smells the student failed to identify, the research assistant
    would record this before showing the student what they missed. Finally, the research
    assistant gave another a brief oral explanation on the relevant refactoring patterns
    (again, following the video script), before asking the student to apply them where
    relevant to their own smelly code.


    In both approaches, the research assistant recorded the number of smells identified
    and resolved by the participants. They did not provide any help in identifying
    or resolving the smells until the participant indicated that they were finished.
    To earn a point for code smell identification, they had to name the correct smell
    and locate where it was occurring. For unidentified smells, these were highlighted
    by the research assistant to the students (with no point awarded), so that the
    refactoring part of the experiment could carry on. To earn a point for resolving
    a smell, the refactored code had to remain correct (buggy misconceptions [\[21\]](#page-6-27)
    did not count) and the smell had to be removed to be considered successful. Partial
    marks were not given for partial fixes. At the end of the experiment, any unresolved
    smells were explained to the students by the research assistant for the participant''s
    learning.


    #### <span id="page-3-0"></span>4.2 Pre- and Post-Surveys


    Prior to the experiment, we used a pre-study survey to collect some basic demographic
    information (e.g. gender, year of study), as well as the pre-university institution
    they studied at (as some involve significant practical programming lessons). We
    also asked them to rate their proficiency in Python, code smells, and code refactoring
    using Likert scales of 1–7 (based on the suggestion of [\[27\]](#page-6-28)).


    After the experiment, participants were asked to complete a poststudy survey (Figure
    [2\)](#page-3-1) to determine whether they perceived an improvement in their confidence
    to identify and resolve code smells. The final questions involved free text responses
    to collect some qualitative assessments from the participants. All Likert scales
    consisted of 7 points, where 1 indicates least confidence/effectiveness, 4 is
    neutral, and 7 indicates most confidence/effectiveness.


    <span id="page-3-2"></span>![](_page_3_Figure_8.jpeg)


    Figure 3: Number of code smells identified (out of 3)


    ## 4.3 Participants


    We recruited 35 undergraduate Information Systems students from our institution.
    Among these students, 30 were in the first or second year of their Bachelor''s
    degree, whereas the others were in their third or final years; 17 reported their
    gender as female with the remaining 18 reporting as male. Given that refactoring
    is only taught towards the end of their degrees, the vast majority of the participants
    can be considered novices in this topic. This was further confirmed by the pre-study
    survey, in which the majority of them rated their familiarity with refactoring
    as either 1 or 2 (out of 7), while proficiency in Python varied from 1 to 5 (out
    of 7), with most falling in the lower range (1 to 3).


    #### 5 RESULTS & ANALYSIS


    In this section, we will analyse the results gathered from the experiments in
    accordance to the research questions defined.


    In conducting our analysis, we primarily employed the Wilcoxon signed-rank test.
    The test was used as the key point was the difference between the two methods
    for each paired measurement (one participant), so that we could obtain a p-value
    to interpret against our null and alternative hypotheses. Whether it was comparing
    success rates, confidence, or effectiveness, they were all based on comparing
    the two different methods: traditional or mistake-based.


    #### 5.1 RQ1: Refactoring Success Rates


    For RQ1, we evaluated the success rates for the refactoring exercises, based on
    the methods that were used to teach the student. For each participant, four values
    were collected: (1) number of code smells identified when taught with the traditional
    method; (2) number of code smells refactored when taught with the traditional
    method; (3) number of code smells identified when taught with the mistake-based
    method; and (4) number of code smells refactored when taught with the mistake-based
    method. Wilcoxon signedranked tests were then conducted to compare the means of
    the variables: one for identification across the two methods, and one for refactoring
    across the two methods. The null hypothesis is that there is no significant difference
    in the success rates between the two methods, with the alternative hypothesis
    being that there is.


    We begin with the code smell identification rate between the two methods. Students
    were evaluated against a possible three code smells to be identified for each
    method, and only received the point if they were able to correctly identify what
    the code smell was and where it was located. Figure [3](#page-3-2) shows a comparison
    of the code smell identification success rates between the two methods. We can
    see that for the mistake-based method, most students were able to identify all
    three code smells, whereas only a few were able


    #### Adding a Mistake-Based Familiarisation Step When Teaching Code Refactoring
    SIGCSE 2024, March 20–23, 2024, Portland, OR, USA


    <span id="page-4-0"></span>![](_page_4_Figure_1.jpeg)


    Figure 4: Number of code smells successfully refactored (out of a possible 3)


    to do so for the traditional method. The average number of code smells identified
    for the mistake-based method was 2.93 (out of 3), whereas it was 1.9 for the traditional
    method. The median for the mistake-based method was 3 (out of 3), whereas it was
    2 for the traditional method. The test returned a p-value of 3.2017e-06, and thus
    we accept the alternative hypothesis that there is a significant difference between
    the identification rates for the two methods.


    Next, we look at the refactoring success rates. Similar to identification, students
    were evaluated out of a possible three code smells to be refactored for each method.
    They would only get the point if they were able to refactor the code smell and
    still maintain the function''s logic. For refactoring, the average number of code
    smells for the mistake-based method was 2.23 (out of 3), whereas it was 1 for
    the traditional method. The median for the mistake-based method was 2 (out of
    3), whereas it was 1 for the traditional method. Figure [4](#page-4-0) shows that
    for the mistake-based method, participants could refactor more code smells in
    general. The test returned a pvalue of 1.880441e-05, and thus we accept that there
    is a significant difference between the refactoring rates for the two methods.


    To conclude the statistical analysis for RQ1, we can say that the mistake-based
    method was able to generate a higher success rate for both code smell identification
    and refactoring. For code smells learnt with the mistake-based method, students
    were able to achieve a higher success rate than those learnt with the traditional
    method. We believe that this is because the mistake-based approach removed the
    familiarity barrier for the exercises.


    #### 5.2 RQ2: Preferred Method


    For RQ2, we used the post-study survey to establish which of the methods the students
    preferred learning with, and which they perceived to be more effective. First,
    out of the 35 participants, 34 said that they preferred the mistake-based method,
    with the remaining participant having no preference.


    Next, we want to find out which method the students perceived to be more effective.
    Using Q6 and Q7 (Figure [2\)](#page-3-1), we were able to gather quantitative
    data on a scale of 1–7 for the effectiveness ratings for both methods. Again,
    our null hypothesis is that there is no significant difference between the effectiveness
    ratings for the two methods, whereas our alternative hypothesis is that there
    is.


    From the histograms (Figure [5\)](#page-4-1), we can see that the effectiveness
    rating for the traditional method is generally on the lower side, with its peak
    being a 4 (out of 7). On the other hand, the mistake-based methods scored better
    in general. The mistake-based method was able to get an average of 5.5 (out of
    7), whereas the traditional approach obtained an average of 3.17. The median for


    <span id="page-4-1"></span>![](_page_4_Figure_10.jpeg)


    Figure 5: How effective the students found the traditional vs. mistake-based approaches
    (7-point Likert)


    <span id="page-4-2"></span>![](_page_4_Figure_12.jpeg)


    Figure 6: Confidence identifying code smells before and after the study (7-point
    Likert)


    the mistake-based method was 5.5 (out of 7), whereas the traditional method obtained
    a median of 3. With a p-value of 2.188529e-06, we thus accept the alternative
    hypothesis that there is a significant difference between the effectiveness ratings.


    For RQ2, it appears that the preferred method in terms of effectiveness was the
    mistake-based method. Based on our qualitative feedback from students (Q9 and
    Q10), we found out that they liked it more as it was a step-by-step approach,
    and they could digest the code as they built it. Highlighting their mistakes was
    also crucial: students shared that it helped them understand the concept more.


    #### 5.3 RQ3: Confidence at Refactoring


    For RQ3, we are interested in two things. Firstly, whether the students were more
    confident in identifying code smells after the experiment. Secondly, and most
    importantly, we want to establish whether they are more confident at identifying/resolving
    code smells learnt using the mistake-based or traditional method.


    First, we look at the change in students'' confidence before and after the experiment.
    Data was obtained using pre- and post-study survey questions which required students
    to rate their confidence on a scale of 1–7. Our null hypothesis was that there
    is no significant difference between the confidence levels before and after the
    experiment, with the alternative hypothesis being that there is one.


    We can see on the histograms (see Figure [6\)](#page-4-2) that there is a general
    increase in confidence after the experiment as compared to before. The average
    rating before was 1.6, which increased to an average of 3.6 after the experiment
    was conducted. Before the experiment, the median confidence was 1, and after the
    test, it increased to 3.5. The test returned a p-value of 1.597915e-06, allowing
    us to accept the alternative hypothesis, concluding that there is a difference
    between the confidence levels before and after the experiment.


    Next, we want to evaluate whether students are more confident in identifying smells
    that they learnt using the mistake-based method versus those learnt using the
    traditional method. Similar to


    #### SIGCSE 2024, March 20–23, 2024, Portland, OR, USA Ivan Tan and Christopher
    M. Poskitt


    <span id="page-5-0"></span>![](_page_5_Figure_1.jpeg)


    Figure 7: Confidence identifying code smells learnt using the traditional vs.
    mistake-based approach (7-point Likert)


    RQ2, we will be using the identification confidence ratings that the students
    provided in our surveys. Our null hypothesis is that there is no significant difference
    between the confidence levels between the two methods, with the alternative being
    that there is.


    From the histograms (see Figure [7\)](#page-5-0), we can observe that for the
    smells covered by the traditional method, the identification confidence level
    was lower than for the mistake-based method. The average identification confidence
    level was 3.83 (out of 7) for the mistake-based method, but only 2.63 for the
    traditional method. The median for the mistake-based method was 4 (out of 7),
    whereas the median for the traditional method was 2. With a p-value of 2.161186e-06,
    and we thus accept our alternative hypothesis that there is a significant difference
    between the identification confidence levels for code smells learnt for each method.


    We note an increase in the students'' confidence in identifying code smells, particularly
    for those that they learnt using the mistakebased method. We believe, again, that
    this is due to removing the familiarity barrier, allowing them to focus their
    learning entirely on refactoring instead of code comprehension.


    #### 5.4 Threats to Validity


    Finally, we remark on some threats to the validity of our results. First, the
    study was limited to undergraduates from a single institution. It is possible
    that the results may not generalise due to differences in curricula, student profiles,
    and pedagogy.


    Second, the exercises were designed around specific groupings of code smells and
    refactorings. It is possible that the results will not apply to refactorings beyond
    those covered, or to groupings of smells/refactorings that do not maintain our
    difficulty balance.


    Finally, to strive for objectivity in our evaluation, we used absolute values
    (0 or 1) to denote whether a student was successful in identifying or refactoring
    a certain code smell. This might not be fully accurate, especially for refactoring,
    as there could be partially acceptable answers that we simply counted as 0. For
    example, credit was not awarded for being able to correctly identify a code smell''s
    location if the participant could not also name it.


    #### 6 REFLECTIONS


    Some of the participants provided additional feedback at the end of the study.
    A participant shared that the mistake-based approach was very similar to their
    experience of learning mathematics, where they would learn certain concepts better
    after getting the questions wrong first. Another participant shared that they
    were inspired by the mistake-based approach, and would use it in their community


    service project involving teaching coding to secondary school children: they joked
    about asking the students to manually print "Hello World!" 20 times before introducing
    for-loops to them. One participant also likened the experience to their internship
    at a startup, where one of their first code commits went through heavy code refactoring
    by their colleague, teaching them a "lesson they would never forget". It was encouraging
    to hear these anecdotes, and it helped to validate our approach in ways we did
    not expect.


    While this study has conveyed the potential value of a mistakebased methodology,
    challenges remain for practitioners to apply it in a classroom setting. When setting
    the coding exercises in our study, we found it difficult to create questions where
    there was a balance between right and wrong, with just enough space and opportunity
    for a student to commit a smell that we were expecting. If the question''s design
    was too narrow, it would have been too obvious. On the other hand, if the question''s
    design was too broad, we would be getting mistakes that are irrelevant to the
    learning objectives. Through a lot of iterations and trials, we were able to achieve
    a balance for this study, but in terms of using this approach in the classroom,
    this would be an important point for educators to consider. Further research could
    potentially try to find ways to automate or use AI in generating these exercises.


    #### 7 CONCLUSION & FUTURE WORK


    In this paper, we proposed an approach to teaching refactoring that incorporates
    a ''mistake-based'' familiarisation step. In other words, rather than refactor
    unfamiliar instructor-provided code, students complete a programming exercise
    that leads to smelly (but familiar) code for them to refactor instead. This simple
    intervention is based on the idea that: (1) students will learn refactoring more
    effectively if they are already familiar with the targeted code, having built
    it; (2) it shows them refactoring isn''t just about fixing other people''s code,
    but can be incorporated into their own development practice; and (3) it aligns
    with the well-understood notion that ''mistakes'' provide a strong opportunity
    for learning. We presented a study comparing our mistake-based teaching approach
    with a traditional one, finding that students were significantly more effective
    and confident at completing exercises.


    This teaching methodology could potentially be used for other software engineering
    courses, and this is something that we are eager to test as well. For instance,
    in a basic SQL / database management course, it might be useful for students to
    see the wrong results returned or erroneous merged tables created, allowing them
    to understand what was wrong with their query from the mistakes they made. Similarly,
    in a web development course, the importance of securing web applications could
    be conveyed to students by subjecting their code to various security scanners
    and highlighting any vulnerabilities [\[25\]](#page-6-9).


    #### ACKNOWLEDGEMENTS


    We are grateful to the anonymous referees for their helpful feedback on drafts
    of this paper. We are also grateful to Sun Jun and Ouh Eng Lieh for their helpful
    comments during the ''UResearch'' programme at SMU. Thanks, finally, to the many
    students who kindly spent some time to participate in this study.


    <span id="page-6-0"></span>Adding a Mistake-Based Familiarisation Step When Teaching
    Code Refactoring SIGCSE 2024, March 20–23, 2024, Portland, OR, USA


    #### REFERENCES


    - <span id="page-6-23"></span>[1] 2023. Refactoring: clean your code. [https://refactoring.guru/refactoring.](https://refactoring.guru/refactoring)
    Accessed: December 2023.

    - <span id="page-6-25"></span>[2] 2023. Supplementary Materials: Exercises and
    Videos. [https://sites.google.com/](https://sites.google.com/view/fixingyourownsmells/home)
    [view/fixingyourownsmells/home.](https://sites.google.com/view/fixingyourownsmells/home)

    - <span id="page-6-24"></span>[3] Shamsa Abid, Hamid Abdul Basit, and Naveed Arshad.
    2015. Reflections on Teaching Refactoring: A Tale of Two Projects. In ITiCSE.
    ACM, 225–230.

    - <span id="page-6-11"></span>[4] Carla Bezerra, Humberto Damasceno, and João
    Teixeira. 2022. Perceptions and Difficulties of Software Engineering Students
    in Code Smells Refactoring. In VEM. SBC, 41–45.

    - <span id="page-6-17"></span>[5] Anastasiia Birillo, Ilya Vlasov, Artyom Burylov,
    Vitalii Selishchev, Artyom Goncharov, Elena Tikhomirova, Nikolay Vyahhi, and Timofey
    Bryksin. 2022. Hyperstyle: A Tool for Assessing the Code Quality of Solutions
    to Programming Assignments. In SIGCSE (1). ACM, 307–313.

    - <span id="page-6-8"></span>[6] Raffaella Borasi. 1994. Capitalizing on Errors
    as "Springboards for Inquiry": A Teaching Experiment. J. Res. Math. Educ. 25,
    2 (1994), 166 – 208.

    - <span id="page-6-2"></span>[7] Jürgen Börstler, Harald Störrle, Daniel Toll,
    Jelle van Assema, Rodrigo Duran, Sara Hooshangi, Johan Jeuring, Hieke Keuning,
    Carsten Kleiner, and Bonnie K. MacKellar. 2017. "I know it when I see it": Perceptions
    of Code Quality. In ITiCSE. ACM, 389.

    - <span id="page-6-10"></span>[8] Tomás Effenberger and Radek Pelánek. 2022. Code
    Quality Defects across Introductory Programming Topics. In SIGCSE (1). ACM, 941–947.

    - <span id="page-6-16"></span>[9] Eduardo Fernandes, Johnatan Oliveira, Gustavo
    Vale, Thanis Paiva, and Eduardo Figueiredo. 2016. A review-based comparative study
    of bad smell detection tools. In EASE. ACM, 18:1–18:12.

    - <span id="page-6-6"></span>[10] Martin Fowler. 2018. Refactoring - Improving
    the Design of Existing Code (2nd ed.). Addison-Wesley.

    - <span id="page-6-20"></span>[11] David Ginat. 2008. Learning from wrong and
    creative algorithm design. In SIGCSE. ACM, 26–30.

    - <span id="page-6-22"></span>[12] Jean M. Griffin. 2019. Designing Intentional
    Bugs for Learning. In UKICER. ACM, 5:1–5:7.

    - <span id="page-6-1"></span>[13] Hermann Gruber, Markus Holzer, and Oliver Ruepp.
    2007. Sorting the Slow Way: An Analysis of Perversely Awful Randomized Sorting
    Algorithms. In FUN (Lecture Notes in Computer Science, Vol. 4475). Springer, 183–197.

    - <span id="page-6-26"></span>[14] Philip J. Guo, Juho Kim, and Rob Rubin. 2014.
    How video production affects student engagement: an empirical study of MOOC videos.
    In L@S. ACM, 41–50.

    - <span id="page-6-14"></span>[15] Thorsten Haendler and Gustaf Neumann. 2019.
    Serious Refactoring Games. In HICSS. ScholarSpace, 1–10.

    - <span id="page-6-12"></span>[16] Thorsten Haendler, Gustaf Neumann, and Fiodor
    Smirnov. 2019. RefacTutor: An Interactive Tutoring System for Software Refactoring.
    In CSEDU (Selected Papers) (Communications in Computer and Information Science,
    Vol. 1220). Springer, 236–261.

    - <span id="page-6-15"></span>[17] Cruz Izu, Paul Denny, and Sayoni Roy. 2022.
    A Resource to Support Novices Refactoring Conditional Statements. In ITiCSE (1).
    ACM, 344–350.

    - <span id="page-6-13"></span>[18] Hieke Keuning, Bastiaan Heeren, and Johan Jeuring.
    2020. Student Refactoring Behaviour in a Programming Tutor. In Koli Calling. ACM,
    4:1–4:10.

    - <span id="page-6-7"></span>[19] Hieke Keuning, Bastiaan Heeren, and Johan Jeuring.
    2021. A Tutoring System to Learn Code Refactoring. In SIGCSE. ACM, 562–568.

    - <span id="page-6-4"></span>[20] Bertrand Meyer. 1997. Object-Oriented Software
    Construction (2nd ed.). Prentice-Hall.

    - <span id="page-6-27"></span>[21] Eduardo Oliveira, Hieke Keuning, and Johan
    Jeuring. 2023. Student Code Refactoring Misconceptions. In ITiCSE (1). ACM, 19–25.

    - <span id="page-6-21"></span>[22] Eng Lieh Ouh and Yunghans Irawan. 2018. Exploring
    Experiential Learning Model and Risk Management Process for an Undergraduate Software
    Architecture Course. In FIE. IEEE, 1–9.

    - <span id="page-6-19"></span>[23] Seymour Papert. 1980. Mindstorms: Children,
    computers and powerful ideas. Harvester.

    - <span id="page-6-18"></span>[24] Simona Prokic, Katarina-Glorija Grujic, Nikola
    Luburic, Jelena Slivka, Aleksandar Kovacevic, Dragan Vidakovic, and Goran Sladic.
    2021. Clean Code and Design Educational Tool. In MIPRO. IEEE, 1601–1606.

    - <span id="page-6-9"></span>[25] Lwin Khin Shar, Christopher M. Poskitt, Kyong
    Jin Shim, and Li Ying Leonard Wong. 2022. XSS for the Masses: Integrating Security
    in a Web Programming Course using a Security Scanner. In ITiCSE (1). ACM, 463–469.

    - <span id="page-6-3"></span>[26] Ian Sommerville. 2015. Software Engineering
    (10th ed.). Pearson.

    - <span id="page-6-28"></span>[27] Hamed Taherdoost. 2019. What is the best response
    scale for survey and questionnaire design; review of different lengths of rating
    scale/attitude scale/Likert scale. International Journal of Academic Research
    in Management (2019), 1–10.

    - <span id="page-6-5"></span>[28] Michele Tufano, Fabio Palomba, Gabriele Bavota,
    Rocco Oliveto, Massimiliano Di Penta, Andrea De Lucia, and Denys Poshyvanyk. 2015.
    When and Why Your Code Starts to Smell Bad. In ICSE (1). IEEE Computer Society,
    403–414.'
- title: 'PTE: Axiomatic Semantics based Compiler Testing'
  abstract: 'The correctness of a compiler affects the correctness of every program

    written in the language, and thus must be thoroughly evaluated. Existing

    automatic compiler testing methods however either rely on weak oracles (e.g.,
    a

    program behaves the same if only dead code is modified), or require substantial

    initial effort (e.g., having a complete operational language semantics). While

    the former prevents a comprehensive correctness evaluation, the latter makes

    those methods irrelevant in practice. In this work, we propose an axiomatic

    semantics based approach for testing compilers, called PTE. The idea is to

    incrementally develop a set of ``axioms'''' capturing anecdotes of the language

    semantics in the form of \emph{(\textbf{p}recondition, \textbf{t}ransformation,

    \textbf{e}xpectation) triples, which allows us to test the compiler

    automatically.} Such axioms are written in the same language whose compiler is

    under test, and can be developed either based on the language specification, or

    by generalizing the bug reports. PTE has been applied to a newly developed

    compiler (i.e., Cangjie) and a mature compiler (i.e., Java), and successfully

    identified 42 implementation bugs and 9 potential language design issues.'
  url: http://arxiv.org/abs/2401.01036v1
  keywords: ''
  document: "# PTE: Axiomatic Semantics based Compiler Testing\n\nGuoliang Dong gldong@smu.edu.sg\
    \ Singapore Management University Singapore, Singapore\n\nJun Sun junsun@smu.edu.sg\
    \ Singapore Management University Singapore, Singapore\n\nRichard Schumi rschumi@smu.edu.sg\
    \ Singapore Management University Singapore, Singapore\n\nBased on the testing\
    \ oracle, existing compiler testing approaches can be roughly categorized into\
    \ three groups. The first group contains approaches that aim to maintain a comprehensive\
    \ test suite [\\[9,](#page-10-4) [18,](#page-10-5) [34\\]](#page-10-3). This is\
    \ certainly necessary, although it is hardly sufficient since covering every aspect\
    \ of the compiler correctness (e.g., the language semantics) would require a huge\
    \ number of test cases. Creating and maintaining such a test suite is challenging,\
    \ especially for evolving languages. The second group contains approaches that\
    \ aim to automatically test the compiler based on certain properties of the language\
    \ semantics [\\[4\\]](#page-10-6). One noticeable example is EMI [\\[14\\]](#page-10-1),\
    \ which is based on the property that altering 'dead code' (i.e., part of the\
    \ program that is not reachable given certain program input) should not alter\
    \ program behaviors. While these approaches are shown to be effective in discovering\
    \ compiler bugs [\\[5\\]](#page-10-7), they are often limited to simple algebraic\
    \ properties. This means that they are far from comprehensively evaluating the\
    \ correct implementation of the language semantics. The third group contains those\
    \ heroic efforts which aim to fully specify the (operational) semantics of a language\
    \ and then evaluate the compiler's correctness accordingly [\\[2,](#page-10-8)\
    \ [13,](#page-10-9) [16\\]](#page-10-10). While such approaches offer a way of\
    \ systematically and comprehensively evaluating the correctness of the compiler,\
    \ their adaptation in practice is hindered by the massive initial effort required\
    \ to formalize the language semantics and the daunting task of maintaining the\
    \ semantics subsequently. In this work, we aim to develop a compiler testing approach\
    \ with the following objectives. First, it must be able to evaluate the compiler's\
    \ correctness comprehensively. Second, it must not require a huge initial effort,\
    \ and it must be relatively easy to maintain so that it can keep up with language\
    \ updates. We thus propose an axiomatic semantics based approach called PTE (that\
    \ stands for precondition, transformation, and expectation) for testing compilers.\
    \ The key idea behind PTE is to incrementally develop a set of axiomatic semantic\
    \ rules which are used to systematically test the target compiler. Each axiomatic\
    \ semantic rule is in the form of a triple (precondition, transformation, expectation),\
    \ where precondition specifies when the rule applies, transformation describes\
    \ a transformation of a program, and expectation specifies the expected outcome\
    \ of executing the transformed program. For example, the PTE rule in Table [1](#page-1-0)\
    \ captures the Liskov Substitution Principle [\\[17\\]](#page-10-11) for object-orientation,\
    \ which is often adopted as a language design principle. Each rule is implemented\
    \ as a program in the language whose compiler is being tested. It is thus not\
    \ necessary to learn a new language or notation. The actual implementation of\
    \ a rule\n\nBo Wang wangbo\\_cs@bjtu.edu.cn Beijing Jiaotong University Beijing,\
    \ China\n\nXinyu Wang wangxinyu@zju.edu.cn Shanghai Institute for Advanced Study\
    \ of Zhejiang University Shanghai, China\n\n## ABSTRACT\n\nThe correctness of\
    \ a compiler affects the correctness of every program written in the language,\
    \ and thus must be thoroughly evaluated. Existing automatic compiler testing methods\
    \ however either rely on weak oracles (e.g., a program behaves the same if only\
    \ dead code is modified), or require substantial initial effort (e.g., having\
    \ a complete operational language semantics). While the former prevents a comprehensive\
    \ correctness evaluation, the latter makes those methods irrelevant in practice.\
    \ In this work, we propose an axiomatic semantics based approach for testing compilers,\
    \ called PTE. The idea is to incrementally develop a set of \"axioms\" capturing\
    \ anecdotes of the language semantics in the form of (precondition, transformation,\
    \ expectation) triples, which allows us to test the compiler automatically. Such\
    \ axioms are written in the same language whose compiler is under test, and can\
    \ be developed either based on the language specification, or by generalizing\
    \ the bug reports. PTE has been applied to a newly developed compiler (i.e., Cangjie)\
    \ and a mature compiler (i.e., Java), and successfully identified 42 implementation\
    \ bugs and 9 potential language design issues.\n\n### KEYWORDS\n\nCompiler testing,\
    \ language semantics, automated testing\n\n#### ACM Reference Format:\n\nGuoliang\
    \ Dong, Jun Sun, Richard Schumi, Bo Wang, and Xinyu Wang. 2024. PTE: Axiomatic\
    \ Semantics based Compiler Testing. In Proceedings of ACM Conference (Conference'17).\
    \ ACM, New York, NY, USA, [12](#page-11-0) pages. <https://doi.org/10.1145/nnnnnnn.nnnnnnn>\n\
    \n### 1 INTRODUCTION\n\nA bug in a compiler potentially renders all programs written\
    \ in the language problematic. It is thus highly desirable that we have a systematic\
    \ and scalable way of evaluating the correctness of compilers. The challenge of\
    \ effective compiler testing [\\[3,](#page-10-0) [14,](#page-10-1) [32,](#page-10-2)\
    \ [34\\]](#page-10-3) is however enormous. A modern programming language often\
    \ has many features which may evolve through time. That is, the compiler not only\
    \ has to handle the complicated language semantics correctly, but also must keep\
    \ up with the constant language updates. In addition, for efficiency reasons,\
    \ a compiler is often teeming with various optimization options, which must be\
    \ kept consistent with the evolving language semantics. All of this makes the\
    \ task of evaluating the correctness of a compiler highly nontrivial.\n\n####\
    \ <span id=\"page-1-0\"></span>Table 1: PTE rule 1: 'Liskov Substitution Principle'\n\
    \n| of type \U0001D446\U0001D462\U0001D45D<br>and |\n|--------------------|\n\
    |                    |\n\n| a class \U0001D446\U0001D462\U0001D44F |  | that is\
    \ a subclass of \U0001D446\U0001D462\U0001D45D. |  |\n|-------------|--|----------------------------|--|\n\
    |             |  |                            |  |\n\n- T Replace <sup>1</sup>\
    \ with an object <sup>2</sup> of type .\n- E The program behavior remains the\
    \ same.\n\nmay have to resolve multiple details. For instance, for the high-level\
    \ rule shown in Table [1,](#page-1-0) <sup>2</sup> and <sup>1</sup> must have\
    \ the same values for the shared (static and instance) variables. Furthermore,\
    \ we must define the meaning of \"the program behavior is the same\".\n\nGiven\
    \ the implementation of a rule as well as a test suite for the compiler, PTE automatically\
    \ identifies test cases which satisfy the precondition; transforms the program\
    \ according to the transformation, and checks whether the expectation is met by\
    \ compiling and executing the transformed test cases with the target compiler.\n\
    \nWhile it is not hard to imagine that many such rules can be developed, in practice\
    \ it is important to answer the question of how we can systematically develop,\
    \ as well as maintain, a repository of such rules. We propose two ways of developing\
    \ the rules. First, they can be built based on the language specification (written\
    \ in natural languages). It is our observation that existing language specifications\
    \ often contain 'PTE rules' informally. For instance, here are some examples from\
    \ the Java specification.\n\n- \"The enhanced for statement is equivalent to a\
    \ basic for statement of the form: ...\"\n- \"It is a compile-time error if final\
    \ appears more than once as a modifier for each variable declared in a resource\
    \ specification.\"\n\nThe former can be understood as a PTE rule whose transformation\
    \ is to de-sugar an enhanced for-statement to a basic one with the expectation\
    \ of program equivalence. The latter can be turned into a PTE rule whose transformation\
    \ is to introduce an extra final modifier with the expectation of a compile-time\
    \ error.\n\nSecond, we propose to incrementally build up the rule repository based\
    \ on compiler bug fixes. We observed that it is often possible to develop PTE\
    \ rules that generalize compiler bug fixes (see Section [2\\)](#page-1-1). Having\
    \ such a way of developing and maintaining a rule repository is extremely important\
    \ in practice, as it is more than a one-off effort with diminishing effect, but\
    \ rather a way of systematically and incrementally approximating a language's\
    \ semantics.\n\nTo evaluate the feasibility and effectiveness of our approach,\
    \ we have applied PTE to two programming languages, i.e., Cangjie and Java. These\
    \ languages are chosen as representatives of a newly developed and a mature language.\
    \ The experimental results show that PTE finds not only compiler bugs, but also\
    \ potential issues regarding language design. In a short period of five months,\
    \ we have defined and implemented dozens of PTE rules, and identified 40 unique\
    \ bugs/issues in Cangjie and 11 bugs/issues in Java. Most of them (2 issues in\
    \ Cangjie and 3 issues in Java to be concluded) have been confirmed by the respective\
    \ compiler team and 23 bugs in Cangjie have been fixed. While more PTE semantics\
    \ rules are being developed continuously, we believe this result has successfully\
    \ demonstrated the effectiveness of our approach. In fact, PTE has now been adopted\
    \ by the Cangjie team who are working with us on building and maintaining the\
    \ PTE rules repository.\n\nTo sum up, we make the following technical contributions.\
    \ First, we propose a novel, and importantly, practical compiler testing approach\
    \ based on axiomatic semantics rules. Secondly, we define a set of PTE rules for\
    \ Cangjie and Java and demonstrate their effectiveness by identifying previously\
    \ unknown compiler bugs.\n\n### <span id=\"page-1-1\"></span>2 ILLUSTRATIVE EXAMPLES\n\
    \nBackground. Cangjie is a programming language that was newly developed by a\
    \ leading global IT company, and it is currently undergoing rapid development.\
    \ While the compiler team maintains a manually-written test suite (with about\
    \ 20000 test cases), there is still a demand to comprehensively evaluate the correctness\
    \ of the compiler. The idea of developing a formal language semantics (similarly\
    \ as for the Solidity and the Java compiler [\\[2,](#page-10-8) [13\\]](#page-10-9))\
    \ and a corresponding testing engine was proposed, but rejected due to the huge\
    \ initial effort as well as the fact that it is almost impossible for the semantics\
    \ to keep up with the rapid language development. While multiple existing compiler\
    \ testing techniques from the literature have been applied, such as EMI [\\[14\\\
    ]](#page-10-1) and SynFuzz [\\[37\\]](#page-10-12), it is observed that such techniques\
    \ often have a diminishing effect, i.e., they are able to find some bugs initially\
    \ but soon become ineffective. More importantly, it is generally agreed upon by\
    \ the testing team that many aspects of the language semantics are yet to be tested.\n\
    \nWe propose PTE as a complementary way of testing the compiler. A set of rules\
    \ in the form of (precondition, transformation, expectation) triples are gradually\
    \ developed, where precondition is the condition under which the rule applies,\
    \ transformation specifies how a program is transformed, and expectation is the\
    \ expected outcome (e.g., the program finishes in the same program state or the\
    \ same error is produced). These rules are gradually developed in two ways. One\
    \ is based on the language specification (in both Chinese and English). The other\
    \ is based on bugs that were raised and fixed, which are documented in the compiler\
    \ project repository. That is, we examine each reported bug and see whether a\
    \ rule can be developed to prevent such or similar issues in a generalized way.\n\
    \nThese rules are implemented in the form of a Cangjie program, utilizing existing\
    \ facilities such as macros and a library for abstract syntax tree (AST) analysis\
    \ (see Section [3\\)](#page-2-0). We show how PTE works using two example rules,\
    \ one derived from the language specification and one from a bug report. We remark\
    \ that all the bugs discussed below were discovered by our approach, i.e., they\
    \ were not detected by existing approaches including manual testing and multiple\
    \ automatic compiler testing methods.\n\nPTE rules from language specification.\
    \ The Cangjie language specification [\\[26\\]](#page-10-13) includes a program\
    \ (see below) with a variable initialization using a conditional expression.\n\
    \nlet num = 8; let r = if (num > 0) { 1 } else { 0 }\n\nThis example gave us the\
    \ idea that we can always replace a literal value with a conditional expression\
    \ that is equivalent to the literal. We thus formulate a PTE rule shown in Table\
    \ [2,](#page-2-1) which states that, for an assignment, the value of the variable\
    \ should remain unchanged if we rewrite the expression on the right side of '='\
    \ as a constant conditional expression whose result is always .\n\nThis PTE rule\
    \ is implemented using existing Cangjie facilities (i.e., macros) and systematically\
    \ applied to a suite of 5641 test cases for the Cangjie compiler. Out of which,\
    \ 190 fail. After examining\n\n#### <span id=\"page-2-1\"></span>Table 2: PTE\
    \ rule 2: the conditional expression identity rule\n\n| P | The program has a\
    \ statement which is either an assign         |\n|---|---------------------------------------------------------------|\n\
    |   | ment or a variable declaration with an initialization.        |\n| T | Replace\
    \ the \U0001D463<br>on the right of '=' with if(true){\U0001D463}else{\U0001D463\
    }, |\n|   | where \U0001D463<br>can be a variable, literal, or expression.   \
    \      |\n| E | The program remains compilable and behaves the same.         \
    \ |\n\n```\n1 // var b =\"\" is Bool\n2 var b = if(true){\"\" is Bool}else{\"\"\
    \ is Bool}\n3 main(): Int64 {\n4 println(b)\n5 return 0\n6 }\n```\n#### <span\
    \ id=\"page-2-3\"></span>Figure 1: The test case to which the rule in Table [2](#page-2-1)\
    \ is applied\n\nTable 3: A Cangjie bug report [\\[27\\]](#page-10-14)\n\n| Title\
    \       | Unexpected \"{}\" when using \"toTokens()\"      |\n|-------------|----------------------------------------------|\n\
    | Description | Unexpected \"{}\" when using \"toTokens()\" func |\n|        \
    \     | tion to obtain tokens from an AST node of an |\n|             | interface\
    \ which has an abstract property.    |\n| Steps of Re | 1 main():Unit{       \
    \                        |\n| production  | let input = quote(interface A{ prop<br>2\
    \     |\n|             | let a:Int64})                                |\n|   \
    \          | let nodeA = parseInterfaceDecl(input)<br>3   |\n|             | println(nodeA.toTokens())<br>4\
    \               |\n|             |                                           \
    \   |\n| Expected    | interface A { prop let a: Int64 }            |\n| Actual\
    \      | interface A { prop let a: Int64{} }          |\n\nthe failures manually,\
    \ multiple bugs are identified. Figure [1](#page-2-2) shows a simplified Cangjie\
    \ program where the original code snippet is highlighted in red and the corresponding\
    \ transformed code (after applying the rule) is marked in green. The transformed\
    \ program is expected to be equivalent to the original one. However, compiling\
    \ it triggers a crash. The error message says \"Internal Compiler Error: Semantic\
    \ error(s) in IR.\", indicating that the compiler fails to generate a valid intermediate\
    \ representation. This issue has been reported, confirmed and fixed in the Cangjie\
    \ version 0.37.2.\n\nWhile it is not hard to find anecdotes from the language\
    \ specification to develop PTE rules, in practice, the testing team is constantly\
    \ worried about whether sufficiently many PTE rules have been developed, which\
    \ is a relevant but challenging question. To answer it, we would have to check\
    \ if the axiomatic semantics is equivalent to the operational language semantics,\
    \ but this cannot be done without first developing the complete operational semantics.\
    \ A practical answer is that we can often develop new PTE rules based on bug reports,\
    \ as we illustrate below.\n\nPTE rules from bug reports. Table [3](#page-2-3)\
    \ summarizes a bug reported from the Cangjie's forum. The bug affects multiple\
    \ functions in the Cangjie core library which are designed to construct an AST\
    \ from a Cangjie program and transform it into tokens. The bug report shows a\
    \ failed test case, where an interface A is declared with an abstract property\
    \ a. Two built-in functions quote and parseInterfaceDecl are then used to construct\
    \ the AST node, which is transformed\n\n#### <span id=\"page-2-4\"></span>Table\
    \ 4: PTE rule 3: the toTokens-parse inverse rule\n\n- P The program has a statement\
    \ node.toTokens() where node is a variable or literal.\n- T Replace the statement\
    \ with parse(node.toTokens()).toTokens() where parse is a parsing function in\
    \ Cangjie.\n- E The program remains compilable and behaves the same.\n\ninto tokens\
    \ using the toTokens() function. The output is different from what is expected,\
    \ and importantly, not a compilable Cangjie program. The cause of the bug is that\
    \ a property defined in the above syntax is de-sugared during parsing to have\
    \ an empty getter and setter declaration, represented as \"{}\" internally.\n\n\
    This bug is fixed in Cangjie version 0.37.2. Based on this bug, we formulate a\
    \ generalized PTE rule (shown in Table [4\\)](#page-2-4), which intuitively says\
    \ that parsing a Cangjie program (in the form of tokens) and then generating the\
    \ tokens would give us back a compilable program which is equivalent to the original\
    \ tokens. We remark that this rule is not mentioned in the language specification\
    \ or the documentation. Nonetheless, such a rule is expected to be satisfied in\
    \ many scenarios. For instance, the toTokens() function might be used for implementing\
    \ code instrumentation (for various static or dynamic code analysis tasks), in\
    \ which case, the un-instrumented part of the program is expected to be unchanged.\n\
    \nThis PTE rule is applied to 5641 test cases for Cangjie. Out of which, 186 fail.\
    \ After examining the failures manually, multiple bugs are identified. Figure\
    \ [2](#page-3-0) shows one of the programs that produced a fault. The transformation\
    \ takes place at Lines 8 and 13, where the variable n is replaced with parseExpr(n.toTokens()).\
    \ Executing the transformed program results in a compile-time error, i.e., a violation\
    \ of the expectation. The AST of an if-expression consists of two parts, i.e.,\
    \ one or more if-blocks and one optional else-block. Our PTE rule is applied to\
    \ both Line 8 (the if-block) and Line 13 (the else-block). An error occurs at\
    \ Line 13 for the else-block when the program is compiled. The error message,\
    \ \"error: [libast]: Parsing Error in ParseExpr\", implies that the type of the\
    \ else-block node (obtained by expr.getElseBranch() at Line 10) is different from\
    \ the type of the if-block node though they should be the same. This bug is fixed\
    \ in version 0.37.2. In fact, this one PTE rule allowed us to identify 8 bugs\
    \ in total. Furthermore, it is agreed upon that this rule should be applied for\
    \ future versions of the compiler since de-sugaring may be applied to newly designed\
    \ language features.\n\n### <span id=\"page-2-0\"></span>3 OUR APPROACH\n\nIn\
    \ this section, we introduce how PTE is designed and realized. All the examples\
    \ and discussions in this section are based on our implementation in Cangjie,\
    \ although it should be clear that the approach naturally extends to other languages\
    \ such as Java.\n\n### 3.1 Overall Design\n\nThe overarching design principle\
    \ of PTE is that it should be easy to apply. Having witnessed the difficulties\
    \ of promoting (any kind of) formal notations and modeling in practice time and\
    \ time again, we decide to design PTE such that a user does not need to learn\
    \ any new language or notation to get started. Rather it should be possible to\
    \ entirely rely on existing facilities provided by the language and\n\nConference'17,\
    \ July 2017, Washington, DC, USA Guoliang Dong, Jun Sun, Richard Schumi, Bo Wang,\
    \ and Xinyu Wang\n\n```\n1 main(){\n2 let input=quote(\n3 if ( x == \"e\" ) {\
    \ return true } else { return false }\n4 )\n5 let expr=parseIfExpr(input)\n6 for\
    \ (n in expr.getIfBody()){\n7 //n.toTokens().dump()\n8 parseExpr(n.toTokens()).toTokens().dump()\n\
    9 }\n10 match (expr.getElseBranch()) {\n11 case Some(n) =>\n12 //n.toTokens().dump()\n\
    13 parseExpr(n.toTokens()).toTokens().dump()\n14 case None => ()\n15 }\n16 return\
    \ 0\n17 }\n```\nFigure 2: The test case to which the rule is applied\n\nthe compiler.\
    \ Furthermore, it should be possible to design and implement the rules incrementally\
    \ and independently, i.e., a rule does not need to rely on other rules to work\
    \ and it is not necessary to consider whether rules are overlapping or are complete.\
    \ The reason is that we would like to accumulate a large number of PTE rules over\
    \ time (so that PTE has a lasting effect) and it would be impossible to keep track\
    \ of all the rules. Lastly, it should be easy to design and implement new rules\
    \ or modify existing rules whenever a new language feature is introduced or the\
    \ semantics of an existing feature is modified. An overview of PTE's simple design\
    \ is shown in Figure [3,](#page-3-1) which consists of three main components,\
    \ i.e., an existing test suite for the compiler, a set of PTE rules and a test\
    \ engine that takes and . In practice, such a test suite is often available, e.g.,\
    \ the OpenJDK test suite for Java contains over 10000 test cases [\\[22\\]](#page-10-15)\
    \ and the test suite for Cangjie contains about 20000 test cases. In the following,\
    \ we describe the other two components in detail.\n\n### 3.2 PTE Rules\n\nThe\
    \ core part of PTE is a repository of PTE rules, each of which implements the\
    \ following interface.\n\n```\ninterface PTERule {\n   func precondition (program:\
    \ Tokens) : Bool\n   func transformation (program: Tokens) : Tokens\n   prop let\
    \ expectations: ArrayList<Expectation>\n}\n```\nA PTE rule has three parts, i.e.,\
    \ a precondition, a transformation and an expectation, which we describe in detail\
    \ in the following.\n\nPrecondition. The precondition of a PTE rule determines\
    \ if a rule is applicable to a program. It takes the form of a program written\
    \ in the same language whose compiler is under test. The input of precondition\
    \ is a program (which has the type of Tokens in Cangjie) and the output is either\
    \ true or false. The precondition is usually implemented using existing meta-programming\
    \ facilities. Note that different programming languages have varying degrees of\
    \ support for meta-programming. Some programming languages provide built-in features\
    \ specifically designed for meta-programming,\n\n<span id=\"page-3-1\"></span>![](_page_3_Figure_10.jpeg)\n\
    \nFigure 3: Overview of PTE\n\nwhereas others require more advanced techniques\
    \ to achieve similar results. For example, C++ uses templates to generate code\
    \ at compile time, while Java relies on reflection to manipulate objects at runtime.\
    \ Fortunately, Cangjie is designed explicitly with meta-programming in mind and\
    \ offer macros that allow developers to manipulate code at compile time. Often,\
    \ the precondition of a PTE rule determines whether a PTE rule should be applied\
    \ on the input program by checking whether the input program contains certain\
    \ programming features. We refer readers to the Appendix for a detailed example\
    \ on the implementation of one PTE rule.\n\nTransformation. Similarly, the transformation\
    \ of a PTE rule takes the form of a program written in the language whose compiler\
    \ is to be tested, and it is also based on existing facilities for metaprogramming.\
    \ The input of the program is a test program and the output is a transformed program.\
    \ How the transformation is done is always specific to each PTE rule.\n\nWe take\
    \ the implementation of the transformation of the PTE rule shown in Table [2](#page-2-1)\
    \ as an example. Given a program, we first convert it to an AST node, and then\
    \ enumerate every one of its child AST nodes and replace the right side part of\
    \ '=' in the assignment expression or variable declaration with the conditional\
    \ expression. For a more complicated example, the transformation function of the\
    \ PTE rule shown in Table [1](#page-1-0) would depend on additional information,\
    \ e.g., which classes are defined in the program and the inheritance relationship\
    \ among these classes.\n\nExpectation. The expectation of a PTE rule describes\
    \ the expected behavior of the transformed program. Note that since a PTE rule\
    \ is supposed to be applicable to any program satisfying the precondition, the\
    \ expectation thus is mostly program-agnostic. In our work, we define different\
    \ expectations for different stages of program compilation and execution, as shown\
    \ in Figure [4.](#page-4-0)\n\nDuring compilation, we distinguish two kinds of\
    \ expectations, i.e., and . The former means that the program successfully compiles\
    \ without any compile-time error, whereas the latter can be further detailed with\
    \ specific compiletime errors. For instance, because Cangjie is designed to be\
    \ strongtyped, assigning a String expression to a Boolean-typed variable is expected\
    \ to cause a . Note that a compiler crash is never an expectation and thus would\
    \ fail any expectation. During execution, we distinguish two expectations, i.e.,\n\
    \n<span id=\"page-4-0\"></span>\n\n![](_page_4_Figure_1.jpeg)\n\nFigure 4: Different\
    \ types of expectations\n\n<span id=\"page-4-1\"></span>\n\n| Algorithm 1: PTE\
    \ testing                |                                            |  |  |\
    \  |\n|-----------------------------------------|--------------------------------------------|--|--|--|\n\
    | 1 for each test program \U0001D4610<br>∈ \U0001D447<br>do |                \
    \                            |  |  |  |\n| 2                                 \
    \      | for each rule \U0001D45F<br>∈ \U0001D445<br>do               |  |  |\
    \  |\n| 3                                       | if \U0001D45F .\U0001D45D\U0001D45F\
    \U0001D452\U0001D450\U0001D45C\U0001D45B\U0001D451\U0001D456\U0001D461\U0001D456\
    \U0001D45C\U0001D45B(\U0001D4610)<br>then             |  |  |  |\n| 4        \
    \                               | let \U0001D4611<br>be \U0001D45F .\U0001D461\
    \U0001D45F\U0001D44E\U0001D45B\U0001D460 \U0001D453 \U0001D45C\U0001D45F\U0001D45A\
    \U0001D44E\U0001D461\U0001D456\U0001D45C\U0001D45B(\U0001D4610);      |  |  |\
    \  |\n| 5                                       | \U0001D450ℎ\U0001D452\U0001D450\
    \U0001D458\U0001D438\U0001D465\U0001D45D\U0001D452\U0001D450\U0001D461\U0001D44E\
    \U0001D461\U0001D456\U0001D45C\U0001D45B(\U0001D45F .\U0001D452\U0001D465\U0001D45D\
    \U0001D452\U0001D450\U0001D461\U0001D44E\U0001D461\U0001D456\U0001D45C\U0001D45B\
    \U0001D460, \U0001D4610, \U0001D4611); |  |  |  |\n|                         \
    \                |                                            |  |  |  |\n\nand\
    \ . The former means that the program successfully executes without any error,\
    \ whereas the latter captures the expected runtime errors. For instance, we expect\
    \ a whenever something is divided by zero. Exactly what kinds of compile-time\
    \ and runtime errors are supported depends on the standardized error handling\
    \ mechanism of the compiler. Lastly, we allow expectations that capture the relationship\
    \ between the program before and after the transformation. For instance, means\
    \ that the program before and after the transformation has the same behavior,\
    \ i.e., either both compilable and executable and having the same variable valuations\
    \ (as well as user-output) at the end of the program execution, or resulting in\
    \ the same compile-time error or runtime error.\n\nThe expectations are implemented\
    \ in Cangjie as an enum type. The default expectation is . All three PTE rules\
    \ shown in the Tables [1,](#page-1-0) [2](#page-2-1) and [4](#page-2-4) have the\
    \ expectation of . Generally, each PTE rule is allowed to declare an array of\
    \ expectations, which offers some flexibility in defining 'imprecise' PTE rules.\
    \ That is, ideally, a compiler tester should know precisely what the expected\
    \ behavior of the compiler is when given a program. However, in practice, it might\
    \ not be easy and it might simply be convenient to write PTE rules that have multiple\
    \ expectations. For instance, a rule may state that for any program containing\
    \ an Int64-typed variable , introducing the code x-=1; x++ somewhere in the program\
    \ after is initialized should either result in an equivalent program or an ArithmeticOverflowError\
    \ (since Cangjie is designed to conduct runtime overflow check for safety).\n\n\
    ### <span id=\"page-4-3\"></span>3.3 Testing with PTE Rules\n\nGiven a test suite\
    \ and a set of PTE rules , a test engine decides how to apply the rules to the\
    \ test suite. Algorithm [1](#page-4-1) shows a simple\n\n<span id=\"page-4-2\"\
    ></span>\n\n|   | 1 open class Super { public var s1: UInt32 = 1 } |  |  |  |\
    \  |  |\n|---|--------------------------------------------------|--|--|--|--|--|\n\
    |   | 2 class Base <: Super {                          |  |  |  |  |  |\n| 3 |\
    \ public var b1: UInt32 = 2                        |  |  |  |  |  |\n| 4 | //\
    \ public var obj: Super = Super()               |  |  |  |  |  |\n| 5 | public\
    \ var obj: Super                            |  |  |  |  |  |\n| 6 | init(){<br>obj\
    \ = Base()<br>}                     |  |  |  |  |  |\n\n7 }\n\n# Figure 5: An\
    \ example of applying multiple rules\n\ntesting algorithm which applies each PTE\
    \ rule to every test case in one-by-one. The function ℎ takes the program before\
    \ and after the transformation and checks whether the expectation is met according\
    \ to the value of the property expectations. For instance, if the expectation\
    \ of the PTE rule is Equiv, the test engine compiles and executes both the original\
    \ program and the transformed program independently, records the information such\
    \ as the output message and exit code for both programs, and compares them to\
    \ determine if they are equivalent. If there are multiple expectations, we check\
    \ each expectation one by one. As long as one of them is satisfied, it is considered\
    \ that the expectation is satisfied.\n\nIt is also possible and sometimes necessary\
    \ to apply multiple PTE rules on the same test case. A practical example for this\
    \ is that a compiler often applies multiple optimizations to generate more efficient\
    \ executable code (e.g., the O3 option of GCC combines many optimizations). Given\
    \ that each such optimization can be naturally encoded as a PTE rule (with the\
    \ expectation Equiv), our approach thus offers a way of checking whether applying\
    \ multiple optimizations is safe or not. To test multiple PTE rules, we simply\
    \ take a program and then apply the PTE rules one by one. That is, we first check\
    \ whether the precondition of the first rule is satisfied, apply the transformation\
    \ if it is, and then check whether the expectation is met. Afterwards, we apply\
    \ the second rule based on the transformed program, and so on. We remark that\
    \ this may also provide us with insights such as whether certain PTE rules are\
    \ exclusive, i.e., applying a certain sequence of rules always renders certain\
    \ rules inapplicable.\n\nFigure [5](#page-4-2) shows an example which reveals\
    \ a bug in the Cangjie compiler by applying two PTE rules. One is the rule shown\
    \ in Table [1,](#page-1-0) i.e., whose transformation replaces an object of class\
    \ Super with an object of its subclass Base. The other is a rule which says that\
    \ having a member variable initialized in the constructor (i.e., init()) or in\
    \ the containing class should be the same. As shown in Figure [5,](#page-4-2)\
    \ after applying both rules, the program is transformed such that Line 4 becomes\
    \ Line 5 to 6. It turns out that the program before the transformation results\
    \ in a StackOverflowError whereas the transformed program results in a compile-time\
    \ error (i.e., circular dependency), which violates the Equiv expectation.\n\n\
    ### <span id=\"page-4-4\"></span>3.4 Developing and Maintaining PTE Rules\n\n\
    So far, we aim to convince readers that all it takes to apply PTE is to develop\
    \ one PTE rule at a time, which is true except that developing and maintaining\
    \ PTE rules could be non-trivial in practice. Such difficulties can however often\
    \ be overcome by \"compromising\" the preciseness of the rule. In the following,\
    \ we illustrate the complications in developing and maintaining PTE rules through\
    \ examples.\n\nConference'17, July 2017, Washington, DC, USA Guoliang Dong, Jun\
    \ Sun, Richard Schumi, Bo Wang, and Xinyu Wang\n\n<span id=\"page-5-0\"></span>![](_page_5_Figure_2.jpeg)\n\
    \nFigure 6: Violations of the Liskov Substitution Principle\n\nDeveloping PTE\
    \ rules could be non-trivial. For instance, the rule shown in Table [1](#page-1-0)\
    \ is one of the guiding principles of Cangjie, which says that objects of a superclass\
    \ should be replaceable with objects of its subclasses. Implementing such a rule\
    \ for automatic compiler testing is however non-trivial as multiple critical details\
    \ are missing from such a general description. For instance, how do we construct\
    \ a corresponding instance of the subclass if additional state variables are needed?\
    \ In our work, we develop an imperfect implementation of the rule (see Figure\
    \ [13](#page-11-1) in Appendix for details). Intuitively, if there is an expression\
    \ of the form obj. () where obj matches a class which has at least one qualified\
    \ subclass, we then replace the base function name with the name of the subclass.\
    \ A subclass is considered qualified if its constructor's signature matches the\
    \ signature of the superclass. Note that a variety of additional information is\
    \ required for the rule's implementation, i.e., we first traverse the program\
    \ to obtain all the classes and their inheritance relationships, and then try\
    \ to infer the type of the arguments in all constructor calls. For simplicity,\
    \ we do not consider the scenario where additional state variables are required\
    \ to instantiate the subclass. We assume that only the subclass whose constructor\
    \ matches the superclass's constructor call can substitute the superclass. The\
    \ expectation is set to be Equiv.\n\nThe rule is then systematically and automatically\
    \ applied to a suite of 5641 test programs for the Cangjie compiler, 26 of which\
    \ fail. After examining the failures manually, they are classified into three\
    \ groups based on the underlying reasons for the failure. Figure [6](#page-5-0)\
    \ shows one example from each group. In particular, Figure [6a](#page-5-0) shows\
    \ a representative case (among 11 cases) where the failure is caused by polymorphism.\
    \ The subclass C2 overrides the method f1 of superclass C1 and because f1 returns\
    \ a different value in the two classes, a failure of the equivalence check occurs.\
    \ Such failures are not considered bugs (but rather a design choice of many languages).\
    \ Figure [6b](#page-5-0) shows one of the two failures that are due to the fact\
    \ that Cangjie does not support the array covariance. In particular, array covariance\
    \ allows assigning an array of a subtype to a variable of an array type of its\
    \ supertype, which is supported by many popular object-oriented languages, such\
    \ as Java, C++ and C#. After reporting this failure to the Cangjie team, we were\
    \ informed that it is a\n\n<span id=\"page-5-1\"></span> public override prop\
    \ let expectations:Array<Expectation>{ 2 get(){ //let equiv = Expectation(Equiv)\
    \ let executable = Expectation(Executable) let circurlarE =Expectation(CircularDependencyError)\
    \ let mismatchedE =Expectation(IncompatiableTypeError) return [executable,circurlarE,mismatchedE]\
    \ 8 } 9 }\n\nFigure 7: The refined expectations for the rule in Table [1](#page-1-0)\n\
    \ndesign choice due to potential type safety concerns. The remaining 13 failures\
    \ are due to a circular dependency, as exemplified in Figure [6c.](#page-5-0)\
    \ Originally, variable obj is initialized to be an instance of the superclass.\
    \ After applying the PTE rule and transforming the program, the variable is initialized\
    \ to be an instance of the subclass, resulting in a circular dependency. The circular\
    \ dependency in this case occurs because the initialization of class Base depends\
    \ on itself. This circular dependency escapes the compiler check somehow and incurs\
    \ a StackOverflowError during runtime. As discussed in Section [3.3,](#page-4-3)\
    \ combining this rule with another rule allows us to reveal a bug in the compiler.\n\
    \nGiven the above 'false alarms', the test engineer must refine the PTE rule to\
    \ avoid generating the same failures, e.g., by strengthening the precondition\
    \ and adjusting how the transformation is done or weakening the expectation to\
    \ cover such false alarms. For instance, to avoid the first group of failures,\
    \ we need to check if an invoked called function (e.g, f1()) is overwritten by\
    \ the subclass using the precondition. Instead of strengthening the precondition\
    \ using three conditions (i.e., one for each group of the failures), we can alternatively\
    \ weaken the expectation, which is often easier in practice. Figure [7](#page-5-1)\
    \ shows the amended expectations. That is, we replace the Equiv with a relaxed\
    \ one, i.e., Executable, to eliminate the false alarms caused by the polymorphism.\
    \ Furthermore, we add two new expectations CircularDependencyError and IncompatiableTypeError\
    \ to eliminate the false alarms caused by the circular dependency and the lack\
    \ of support for array covariance.\n\nWe remark that developing PTE rules is an\
    \ iterative process in general. An initial implementation of a PTE rule would\
    \ often be imperfect, e.g., it would result in multiple false alarms due to corner\
    \ cases that are overlooked. These false alarms then serve as valuable references\
    \ for refining the PTE rule and the implementation. Afterwards, we often re-run\
    \ the PTE rule and analyze the reported failures, and refine the PTE rule further\
    \ if necessary.\n\nMaintaining PTE rules could be nontrivial. Ideally, PTE should\
    \ be applied systematically such that over time a comprehensive set of rules are\
    \ developed. To make it happen, we must be able to systematically maintain the\
    \ rules so that they remain correct and applicable through language evolution.\
    \ This is particularly relevant for newly developed languages such as Cangjie\
    \ which constantly introduces new features or updates existing features, and not\
    \ unimportant for mature languages such as Java. If a new language feature is\
    \ introduced, our experience is that typically we can develop multiple new PTE\
    \ rules to capture the axiomatic\n\nsemantics of the new language feature. If\
    \ however an existing feature is amended, identifying and updating those relevant\
    \ rules that have become invalid may not be easy, as going through all the rules\
    \ each time is impractical. In practice, however, this problem is manageable.\
    \ Typically, whenever an existing language feature is amended, new test cases\
    \ which reflect the correct concrete program behavior are introduced into the\
    \ test suite, or some existing test cases are adjusted. Running those rules that\
    \ have become invalid on these test cases will most likely result in failures,\
    \ which makes it easy to identify and update such rules. For instance, PTE was\
    \ initially implemented for Cangjie 0.34.3. Since then, Cangjie has evolved to\
    \ 0.39.4 (i.e., the latest version at the time of writing), and many changes have\
    \ been introduced. When we run PTE developed for Cangjie 0.34.3 on Cangjie 0.39.4,\
    \ about 55 failures occur due to language changes. The causes of these errors\
    \ are quickly identified (e.g., the 'let' keyword is not needed when declaring\
    \ a property, shadowing a function parameter with a local variable in the function\
    \ is no longer allowed, and some built-in functions are no longer available) and\
    \ the relevant rules are fixed within an hour.\n\n### 4 IMPLEMENTATION AND EVALUATION\n\
    \nIn this section, we present details of our experiments on applying PTE in practice.\
    \ We have evaluated PTE for two compilers, one for Cangjie and one for Java (version\
    \ 20). Based on the support for macros and the built-in AST library of Cangjie\
    \ (and with the help of the Eclipse Java development tools (JDT) core library\
    \ [\\[8\\]](#page-10-16)), PTE is implemented with approximately 7500 lines of\
    \ code for Cangjie and about 3000 lines for Java. Note that the Cangjie implementation\
    \ additionally provides a range of APIs to facilitate developing PTE rules, and\
    \ streamlines the testing.\n\nIn the following, we report our experiences on applying\
    \ PTE to Cangjie and Java, by focusing on the following research questions: RQ1)\
    \ How effective is PTE in finding compiler bugs? RQ2) Which types of bugs can\
    \ PTE find? RQ3) How much effort is needed to apply PTE in practice? All the experiments\
    \ are conducted on a laptop equipped with 11th Gen Intel(R) Core(TM) i7-1165G7@2.80GHz\
    \ and 32 GB RAM, running Ubuntu 22.04.2 LTS (64 bit).\n\n### 4.1 Applying PTE\
    \ for Cangjie\n\nFor Cangjie, a set of 40 PTE rules are defined and then applied\
    \ to test the compiler. In the following, we present the experimental results\
    \ and answer the above-mentioned research questions. For a baseline analysis,\
    \ we compare PTE with three approaches that have been recently developed for Cangjie,\
    \ i.e., CJSmith, SynFuzz [\\[37\\]](#page-10-12) and MetaFuzz [\\[37\\]](#page-10-12),\
    \ which are shown to be more effective than previous approaches such as AFL [\\\
    [35\\]](#page-10-17). These three approaches are based on different techniques.\
    \ In particular, CJSmith, which follows the idea of Csmith [\\[34\\]](#page-10-3),\
    \ is provided by the Cangjie team, and it automatically generates random test\
    \ cases according to the Cangjie grammar. SynFuzz is a test case synthesis technique\
    \ which synthesizes test cases by inserting code snippets into a randomly selected\
    \ seed program. MetaFuzz is inspired by the approach known as EMI (i.e., equivalence\
    \ modulo inputs [\\[14\\]](#page-10-1)) and generates test cases by performing\
    \ semantic-preserving transformations on existing test cases. We remark that for\
    \ CJSmith and SynFuzz, the test oracle is whether a generated test case causes\
    \ a compiler crash,\n\n| Table 5: Bug finding statistics |  |\n|---------------------------------|--|\n\
    |---------------------------------|--|\n\n<span id=\"page-6-0\"></span>\n\n| Approach\
    \ | #Test Cases | #Bugs | Time (Hours) |  |  |\n|----------|-------------|-------|--------------|--|--|\n\
    | PTE      | 225640      | 34∗   | 59.3         |  |  |\n| CJSmith  | 905949 \
    \     | 0     | 72           |  |  |\n| SynFuzz  | 30525       | 0     | 72  \
    \         |  |  |\n| MetaFuzz | 41120       | 3     | 72           |  |  |\n|\
    \          |             |       |              |  |  |\n\n∗ potential design\
    \ issues are not included, which are shown in Table [6](#page-7-0)\n\nwhereas\
    \ the test oracle of MetaFuzz is whether a mutated test case produces the same\
    \ output as its original counterpart. Note that except CJSmith (which generates\
    \ test cases from scratch), SynFuzz, MetaFuzz and PTE require a suite of seed\
    \ programs. We first run all the manually crafted test cases developed by the\
    \ Cangjie team, and then keep those which pass the tests as the seed programs.\
    \ There are a total of 5641 seed programs. The toolkit of both SynFuzz and MetaFuzz\
    \ requires the seed programs to be in a specific format, and it can randomly generate\
    \ such seed programs. For a fair comparison, we use this toolkit to generate an\
    \ equal number of seed programs, i.e., 5641, in the required format, and then\
    \ take them as the seed programs for SynFuzz and MetaFuzz.\n\nRQ1: How effective\
    \ is PTE in finding bugs in Cangjie? To answer this question, we run the test\
    \ engine using the approach depicted in Section [3.3](#page-4-3) systematically\
    \ with the 40 PTE rules and with a timeout of 72 hours (the maximum testing time\
    \ used in work [\\[37\\]](#page-10-12)) on Cangjie 0.34.3 which is the latest\
    \ version at the time. The same timeout and version of Cangjie are used for both\
    \ PTE and the baseline approaches.\n\nThe results are summarized in Table [5.](#page-6-0)\
    \ Our approach identified 34 (confirmed) unique bugs, all of which were previously\
    \ unknown (we also found 6 potential design issues, which will be discussed in\
    \ RQ2). At the time of writing, 23 of them have been fixed by the Cangjie team.\
    \ The remaining bugs will be fixed in a future version. In contrast, MetaFuzz\
    \ only identified three bugs, and the remaining two baselines, i.e, CJSmith and\
    \ SynFuzz fail to identify any bugs. Although MetaFuzz identified three bugs,\
    \ we were unable to reproduce them in the later version (Cangjie 0.35.6). It is\
    \ possible that these bugs were fixed as a side-effect of the version iteration.\n\
    \nThere are multiple reasons why these approaches fail to effectively identify\
    \ bugs. First, the biggest reason is perhaps that CJSmith, SynFuzz and MetaFuzz\
    \ had been previously applied and those bugs had already been fixed. While it\
    \ is true that these approaches may have been successful in the beginning, it\
    \ certainly shows their diminishing effect, i.e., these approaches have a one-time\
    \ benefit. Furthermore, if we refer to the effectiveness of these approaches when\
    \ they were applied for the first time (i.e., reported in [\\[37\\]](#page-10-12)),\
    \ we observed that when applying CJSmith, SynFuzz, and MetaFuzz to the Cangjie\
    \ compiler of version 0.24.5, a total of 15, 53, and 39 crashes/inconsistencies\
    \ were identified, respectively. However, when these approaches were applied to\
    \ the Cangjie compiler of version 0.26.1, the numbers of crashes/inconsistencies\
    \ dropped significantly to 9, 35 and 24, respectively. Note that not every crash/inconsistency\
    \ is a unique bug, i.e., a total of 11 confirmed and unique bugs were found as\
    \ reported in [\\[37\\]](#page-10-12). Second, we observe that many test cases\
    \ generated by SynFuzz and MetaFuzz are invalid. A close investigation shows that\
    \ it is because these two approaches are implemented for an early version of Cangjie,\
    \ i.e., version 0.26.1.\n\n<span id=\"page-7-0\"></span>Table 6: Different types\
    \ of bugs found in Cangjie and Java\n\n| Type                         | #Cangjie\
    \ | #Java |\n|------------------------------|----------|-------|\n| Compiler crash\
    \               | 2        | 0     |\n| Miscompilation               | 1     \
    \   | 0     |\n| Problematic error messages   | 4        | 7     |\n| Inconsistent\
    \ error detection | 1        | 1     |\n| Bugs in core libraries       | 26  \
    \     | 0     |\n| Potential design issues      | 6        | 3     |\n\nSince\
    \ the Cangjie grammar undergoes substantial changes from version 0.26.1 to version\
    \ 0.34.3, and more importantly, SynFuzz and MetaFuzz are highly coupled with Cangjie\
    \ syntax, maintaining these approaches (i.e., so that they can be applied for\
    \ newer versions) is highly nontrivial. In comparison, PTE is more decoupled from\
    \ the Cangjie syntax (i.e., it relies on the PTE rules, the tests and the AST\
    \ library) and is easier to maintain. As long as the AST library is updated, the\
    \ changes required to update PTE are minimal. For example, from version 0.34.3\
    \ to the latest version 0.39.4, only a few minor modifications are required, as\
    \ discussed in Section [3.4.](#page-4-4)\n\nTable [5](#page-6-0) also shows the\
    \ number of test cases generated by CJSmith, SynFuzz and MetaFuzz. We can observe\
    \ that CJSmith generated the highest number of test cases, reaching 905949, but\
    \ found no bugs. On the other hand, SynFuzz and MetaFuzz were less efficient,\
    \ i.e., only generating 30525 and 41129 test cases, respectively, within 72 hours.\
    \ In contrast, PTE generated 225640 (i.e., 5641 test cases × 40 rules) test cases\
    \ within about 59 hours.\n\nTo have a fair comparison with CJSmith, SynFuzz and\
    \ MetaFuzz, we conduct an additional experiment on applying PTE to Cangjie 0.24.5.\
    \ Due to the significant syntax and semantics change between version 0.24.5 and\
    \ 0.34.3, we are only able to apply 10 of the PTE rules on Cangjie 0.24.5. With\
    \ only 10 PTE rules, we identified 63 bugs, including 10 compiler crashes (reporting\
    \ 'Segmentation fault' or 'CodeGen Error') and 3 miscompilations. We further analyze\
    \ whether the bugs that we found in Cangjie 0.24.5 and that in 0.34.3 overlap.\
    \ The results show that nearly 53% (18 out of 34) bugs are newly discovered in\
    \ Cangjie 0.34.3. In contrast, the baseline approaches only identified three bugs\
    \ in Cangjie 0.34.3. Our experience is that we are typically able to find new\
    \ bugs once we introduce new PTE rules. This result shows that PTE will have a\
    \ lasting effect if we continue to introduce new PTE rules, e.g., based on bug\
    \ reports.\n\nRQ2: Which types of bugs can PTE find in Cangjie? To answer this\
    \ question, we categorize our findings into different categories in Table [6.](#page-7-0)\
    \ A compiler crash happens during compilation and produces an error message such\
    \ as \"Internal Compiler Error\". A miscompilation occurs if the compiler generates\
    \ incorrect machine code, which either produces an incorrect execution result\
    \ or causes a program crash with an error which is not related to the program\
    \ itself. Figure [8](#page-7-1) shows such an example where the resulting machine\
    \ code crashes with a segmentation fault. The original code at Line 2 is transformed\
    \ to the code at Line 3 by the PTE rule shown in Table [2.](#page-2-1) Note that\
    \ this bug and the bug shown in Figure [1](#page-2-2) are different as they have\
    \ different causes and fixes, even though they were detected by the same PTE rule.\n\
    \nConference'17, July 2017, Washington, DC, USA Guoliang Dong, Jun Sun, Richard\
    \ Schumi, Bo Wang, and Xinyu Wang\n\n<span id=\"page-7-1\"></span>\n\n|      |\
    \ 1 public struct Test {                                            | F unhandled\
    \ signal. sig: 11, siginfo:                     |\n|------|-------------------------------------------------------------------|-----------------------------------------------------------|\n\
    | 2    | //static var x=(1,0.1,true,'a',\"a\")                               |\
    \ 0x5620cff428b0, context:                                  |\n| 3    | static\
    \ var x=if(true)(1,0.1,true,'a',\"a\")else(1,0.1,true,'a',\"a\") | 0x5620cff42780,\
    \ mutator's<br>mutatorPage: 0x7fa9a9f47000, |\n| 4    | public func getX() { Test.x\
    \ }                                     | si_addr: 0x8!                      \
    \                       |\n| 5 }  |                                          \
    \                         | F unhandled signal. sig: 6, siginfo:             \
    \         |\n|      | 6 main(){                                              \
    \           | 0x5620cff41330, context:                                  |\n| 7\
    \    | var (a_,b_,c_,d_,e_) = Test().getX()                              | 0x5620cff41200,\
    \ mutator's                                 |\n|      | 8 println(\"after:\\${a_},\\\
    ${b_},\\${c_},\\${d_},\\${e_}\")             | mutatorPage: 0x7fa9a9f47000,  \
    \                            |\n| 9    | return 0                            \
    \                              | si_addr: 0x3ea000c8b53!                     \
    \              |\n| 10 } |                                                   \
    \                | Aborted                                                   |\n\
    |      | (a) The test case                                                 | (b)\
    \ The error message                                     |\n\nFigure 8: An example\
    \ revealing the bug of miscompilation\n\n<span id=\"page-7-2\"></span>1 main()\
    \ { 2 // var ipmask=Array<Array<UInt8»([Array<UInt8>([255, 0, 0, 0]), Array<UInt8>([255,\
    \ 255, 0, 0])]) 3 var ipmask = Array<Array<UInt64»([Array<UInt64>([255, 0, 0,\
    \ 0]), Array<UInt64>([255, 255, 0, 0])]) 4 for( i in 0 .. ipmask.size ){ var ipmask\
    \ = IPMask(ipmask[i])} 5 }\n\nerror: invalid subscript operator [] on type 'Struct-Array<Struct-Array<UInt64»'\n\
    \n#### Figure 9: An example showing problematic error message\n\nCompiler error\
    \ messages are intended to help developers identify and fix issues in their code\
    \ by providing meaningful information about the whereabouts and nature of errors.\
    \ A problematic error message is one that is misleading or excessive, which makes\
    \ it difficult for developers to identify and resolve the issue in the program.\
    \ Figure [9](#page-7-2) shows such an example. In this example, the array ipmask\
    \ initially holds elements of type UInt8 (Line 2) and is transformed to the array\
    \ which holds elements of type UInt64 by the rule (Line 3). Error messages such\
    \ as mismatched types are expected. However, the actual error message points the\
    \ finger wrongly. It accuses an invalid subscript of the array ipmask, whereas\
    \ the subscript itself is valid and not the cause of the problem. This issue has\
    \ been reported to the Cangjie team, and has been confirmed and fixed. The next\
    \ category 'inconsistent error detection' refers to a situation when a compiler\
    \ behaves differently on equivalent programs in terms of bug detection. One such\
    \ example has been shown in Figure [5.](#page-4-2) The original test case has\
    \ a circular dependency problem since the initialization of the class Base depends\
    \ on itself. This circular dependency escapes the check of the compiler and incurs\
    \ a StackOverflowError during runtime. However, after moving the initialization\
    \ into the constructor, the compiler successfully detects the issue and generates\
    \ a compile-time error.\n\nMany of the detected bugs are in the Cangjie core library.\
    \ These bugs range from minor issues that cause unexpected behavior to critical\
    \ bugs that may lead to crashes or vulnerabilities. The following code reveals\
    \ one such bug in the library for type conversion.\n\n#### let count=Int64(Float64.tryParse(0.toString()).getOrThrow())\n\
    \nThe test case containing the above statement can be successfully compiled but\
    \ encounters a NoneValueException during runtime. The cause is that the function\
    \ Float64.tryParse() returns None when converting string 0 to a number of Float64\
    \ type. The PTE rule involved in discovering the bug transforms an Integer to\
    \ a String, then converts the String to a floating-point number, and finally converts\
    \ the floating-point number back to an Integer. The precondition of this rule\
    \ is that there exists an integer literal value which is assigned\n\nPTE: Axiomatic\
    \ Semantics based Compiler Testing Conference'17, July 2017, Washington, DC, USA\n\
    \n<span id=\"page-8-0\"></span>![](_page_8_Figure_1.jpeg)\n\nFigure 10: A potential\
    \ design issue\n\nto a variable of type Int64, and the expectation is that the\
    \ resulting integer value remains unchanged.\n\nBesides implementation bugs, PTE\
    \ also allows us to discover a number of potential design issues regarding the\
    \ core libraries or the language itself. These flaws can result in inconvenience\
    \ and confusion for Cangjie programmers, even though they may not be regarded\
    \ as bugs. One example is that the exponentiation operation in Cangjie does not\
    \ support negative exponent, which is an issue identified by the following transformed\
    \ test program.\n\n#### let p=Int64.parse(2.toString())\\*\\*Int64.parse(18.toString())\n\
    \nWhile there are reasons why it is designed so, negative exponents are a fundamental\
    \ mathematical concept and are useful in various applications. Furthermore, it\
    \ is supported by many programming languages such as Java and C++. Another example,\
    \ as shown in Figure [10,](#page-8-0) is that Cangjie lacks the ability to trace\
    \ where a default implementation of a function in an interface is from. That is,\
    \ if a class implements two interfaces, both of which inherits the same default\
    \ function implementation from some common ancestor (i.e., another interface),\
    \ a compile-time error occurs. The response from the Cangjie is that it is a design\
    \ choice for now, i.e., Cangjie does not maintain the information on where a default\
    \ implementation is from and has no way to check whether two implementations are\
    \ in fact from the same source. The downside of such a design choice is that the\
    \ programmers are forced to supply a new implementation which is likely a redundant\
    \ copy of the same implementation. We thus consider such a design choice questionable\
    \ and should be amended in the future.\n\nRQ3: How much effort is needed to apply\
    \ PTE for Cangjie? The effort required to apply PTE consists of multiple parts,\
    \ e.g., manual efforts for implementing PTE rules and analyzing the testing results,\
    \ and the computational resources for executing PTE.\n\nThe time of developing\
    \ PTE rules depends on the complexity of the rules and the facilities available\
    \ for meta-programming. Empirically, the time for developing a PTE rule varies\
    \ from 30 minutes to several hours using our framework. Most of the manual effort\
    \ comes from implementing and refining the transformation function of the PTE\
    \ rule. For Cangjie, the transformations could be developed with build-in macros,\
    \ and most of the rules (38 out of 40) are implemented with fewer than 100 lines\
    \ of code. Unfortunately, Java does not support such macros, and hence an external\
    \ AST processing library is required as we explain in Section [4.2.](#page-8-1)\n\
    \nIn total, it took 5 months to develop PTE for Cangjie, which includes time spent\
    \ on learning Cangjie, developing the framework, designing/implementing rules\
    \ based on the Cangjie language specification and its bug repository, and analyzing\
    \ the results. Note that once the framework is developed, adding new rules can\
    \ be done efficiently. The Cangjie testing team managed to develop 30 rules in\
    \ 3 days after PTE was adopted. The time to analyze the testing results varies\
    \ depending on the nature and complexity of the issue. In our experience, most\
    \ of the bugs are quickly identified and confirmed, whereas library/language design\
    \ issues typically take much more time (sometimes multiple meetings spanning over\
    \ weeks) to conclude.\n\nRegarding the computational resources for executing PTE,\
    \ PTE can be run with a standard laptop or desktop computer. In our experiments,\
    \ the average time is about 1.48 hours for each PTE rule (given the 5641 test\
    \ programs). The total testing time for all PTE rules is about 59.3 hours. In\
    \ contrast to alternative approaches such as CJSmith and SynFuzz which require\
    \ a manually-specified timeout, PTE finishes when the test engine finishes all\
    \ the test programs. Furthermore, we can systematically measure the coverage of\
    \ the PTE rules, which provides some test adequacy measure.\n\n### <span id=\"\
    page-8-1\"></span>4.2 Applying PTE for Java\n\nIn the following, we discuss our\
    \ (brief) experiment on testing the Java 20 compiler with PTE.\n\nRQ1: How effective\
    \ is PTE in finding bugs in Java? Since Java is a mature language, most of its\
    \ core language features have been intensively tested with various testing techniques\
    \ and also manually by the large user base. We thus focus on the newly introduced\
    \ features (i.e., preview or incubator features) in the latest Java version and\
    \ develop 20 PTE rules based on the documentation. One such example is pattern\
    \ matching for a switch or record patterns [\\[24\\]](#page-10-18). We take those\
    \ relevant tests in the openJDK test suite [\\[22\\]](#page-10-15) as seed programs.\
    \ Note that although openJDK consists of thousands of tests, most of them are\
    \ considered irrelevant since our PTE rules are concerned with the newly introduced\
    \ features. In the end, the PTE rules are applied to a range between 5 and 484\
    \ seed programs, depending on the type of the PTE rule. We run the 20 PTE rules\
    \ with the relevant seed programs as illustrated in Algorithm [1.](#page-4-1)\n\
    \nWe implement the PTE rules for Java by using an external library for AST parsing\
    \ and modifying, i.e., the Eclipse Java development tools (JDT) core library which\
    \ supports the latest Java version. Most of the effort in implementing PTE for\
    \ Java is on realizing the AST modification with the JDT library, which takes\
    \ hours to days depending on the complexity of the PTE rule. The average time\
    \ on testing all the test cases is about 32min for each PTE rule.\n\nIn total,\
    \ we found 11 issues and bugs that were previously unknown. We reported the bugs\
    \ to the Java bug database and eight of them have been confirmed (and will be\
    \ fixed).\n\nRQ2: What types of bugs can PTE find in Java? The types of bugs that\
    \ we found for Java are summarized in the last of column of Table [6.](#page-7-0)\
    \ Seven bugs (bug ID: 8311136, 8308642, 8311135, 8308638, 8313437, 8313543, and\
    \ 8313622) are related to problematic or misleading error messages. For example\
    \ (bug ID: 8308642), for the new switch feature with pattern matching, there occurs\
    \ an unhelpful error message when a break statement is forgotten (see Figure [14](#page-11-2)\
    \ in\n\n```\n1 Integer i = 5;\n2 switch (i) {\n3 case 1 −> System.out.println(\"\
    Case 1!\");\n4 case Integer i1 when i1 < 0 −> System.out.println(\"Case 2!\");\n\
    5 case 42 −> System.out.println(\"Case 3!\");\n6 default −> System.out.println(\"\
    Default Case\");\n7 }\n```\n#### Figure 11: An example of wrong Java error message\n\
    \nAppendix). The error states \"illegal fall-through to a pattern\", which is\
    \ unhelpful considering that most developers are not familiar with the fall-through\
    \ behavior of a switch statement. Moreover, they may not know that the fall-through\
    \ behavior is not allowed in the new pattern matching feature of Java 20. A more\
    \ helpful error message should rather state that there is a missing break statement.\
    \ The PTE rule that helped to find this bug is the one that introduces new redundant\
    \ switch cases. Even though such error message related bugs might seem trivial,\
    \ we believe it is important to fix them since they can cause a huge waste of\
    \ debugging effort.\n\nWe also found a case (bug ID: 8308636) of supposedly equivalent\
    \ programs resulting in different compilation results. This bug is shown in Figure\
    \ [11](#page-9-0) which includes a switch statement with the new guarded pattern\
    \ feature [\\[23\\]](#page-10-19). The switch statement contains normal static\
    \ cases, like case 1, and guarded pattern cases, like the second case. For this\
    \ example, the Java compiler produces an error with the message \"case label is\
    \ dominated by a preceding case label\" for the third case, even though it is\
    \ not the case. This error occurs due to an arbitrary design choice that requires\
    \ static cases before pattern cases. Even if we agree with this design choice,\
    \ the error message is unhelpful (and wrong) as a developer would not know about\
    \ the required order of cases.\n\nWe also found potential design issues with Java\
    \ (bug ID: 8311134, 8308640, and 8311132). For example, for record classes, which\
    \ are simple lightweight classes for storing data, we discover that a final modifier\
    \ can be added, although it is redundant. This is because records are final by\
    \ default, i.e., a record class cannot be extended. Allowing a final modifier\
    \ may confuse developers, who might think that records without this modifier are\
    \ extensible.\n\n### 5 RELATED WORK\n\nCompiler testing is a research topic that\
    \ has attracted considerable interests. Broadly speaking, all approaches can be\
    \ understood based on three key questions, i.e., the test case generation problem\
    \ [\\[11\\]](#page-10-20), the oracle problem [\\[1\\]](#page-10-21), and the\
    \ test adequacy problem [\\[40\\]](#page-10-22). For test generation, one common\
    \ approach is to manually build and maintain a test suite. Major compiler projects\
    \ like GCC, LLVM, and OpenJDK have their own manually created test suites [\\\
    [9,](#page-10-4) [22\\]](#page-10-15). These suites are designed to validate the\
    \ compilers' functionality, correctness, and performance. However, relying solely\
    \ on manually built test suites is insufficient. Achieving comprehensive coverage\
    \ would require an overwhelming number of test cases, posing significant challenges\
    \ in terms of creating and maintaining such test suites.\n\nResearchers have explored\
    \ the automatic generation of compiler test cases. Two popular categories of approaches\
    \ are grammarbased approaches [\\[10,](#page-10-23) [28\\]](#page-10-24) and mutation-based\
    \ approaches [\\[25,](#page-10-25) [31\\]](#page-10-26). Grammar-based approaches\
    \ typically start with a fixed code fragment, acting as a template or placeholder,\
    \ and then use grammar rules to generate the remaining parts of the program. Csmith\
    \ [\\[34\\]](#page-10-3) is\n\na well-known grammar-based tool based on a subset\
    \ of the C grammar. It generates programs that cover a significant portion of\
    \ C language features while avoiding undefined and unspecified behaviors. Sirer\
    \ et al. [\\[30\\]](#page-10-27) propose test generation for JVM using production\
    \ grammars. Some grammar-based approaches generate test cases solely based on\
    \ the language grammar. For example, Purdom [\\[28\\]](#page-10-24) proposed a\
    \ sentence generator that traverses the productions of a set of context-free grammar\
    \ rules. Zelenov and Zelenova [\\[36\\]](#page-10-28) present a method for producing\
    \ test cases using a BNF grammar and a coverage criteria based on the target compiler's\
    \ syntax analyzer.\n\nMutation-based approaches generate programs by modifying\
    \ existing test cases. For instance, LangFuzz [\\[12\\]](#page-10-29) takes a\
    \ seed program and randomly replaces some non-terminals in the program with code\
    \ fragments of the same type from a large code fragments pool. Another approach\
    \ named JavaTailor [\\[38\\]](#page-10-30) mutates existing test cases to increase\
    \ JVM code coverage. JavaTailor extracts various code fragments from historical\
    \ bug-revealing test programs and randomly inserts them into the seed programs.\
    \ EMI [\\[14\\]](#page-10-1) focuses on the 'dead code' of the seed program, mutating\
    \ an input program by deleting, inserting, or modifying unexecuted code.\n\nWith\
    \ a collection of automatically generated test cases, the test oracle in compiler\
    \ testing varies depending on the test case generation approach used. One popular\
    \ approach is differential testing [\\[15,](#page-10-31) [20,](#page-10-32) [21\\\
    ]](#page-10-33), which aims to identify potential bugs by comparing the results\
    \ of compiling and executing the same test case with different compilers or different\
    \ optimization levels within a single compiler. For example, in the case of Csmith,\
    \ each generated test case computes and prints a checksum of the non-pointer global\
    \ variables, allowing the detection of discrepancies among different compilers.\
    \ Note that differential testing typically requires at least one mature and well-established\
    \ compiler for the same language as a reference. However, this approach may not\
    \ be directly applicable to newly developed programming languages, like Cangjie,\
    \ where a mature compiler may not yet exist.\n\nAnother approach to address the\
    \ test oracle problem is metamorphic testing [\\[4,](#page-10-6) [29,](#page-10-34)\
    \ [39\\]](#page-10-35). Metamorphic testing focuses on defining metamorphic relations\
    \ that specify how changes in the input program should affect the output. EMI\
    \ serves as a typical example of metamorphic testing. The mutated programs generated\
    \ by EMI are expected to produce equivalent results to their original counterparts\
    \ when executed with a given set of test inputs. Bugs can be detected by comparing\
    \ the results of the mutated program and its original counterpart. Donaldson et\
    \ al. [\\[6,](#page-10-36) [7\\]](#page-10-37) introduced a metamorphic testing\
    \ approach for graphics shader compilers that includes semantics-preserving mutations\
    \ (e.g., like variable type replacement, expression reordering, or control flow\
    \ wrapping) that affects code executed during testing. There are also similar\
    \ metamorphic testing approaches [\\[19,](#page-10-38) [33\\]](#page-10-39) for\
    \ deep learning compilers.\n\nOur approach can certainly benefit from existing\
    \ approaches on compiler test generation such as grammar-based ones. The primary\
    \ aim of our approach is to solve the test oracle problem. In particular, our\
    \ approach falls under the category of metamorphic testing. However, unlike existing\
    \ metamorphic testing approaches that typically focus on a single metamorphic\
    \ relation, our approach provides a practical way for users to define metamorphic\
    \ relations in the form of PTE rules. The diversity of these metamorphic relations\
    \ enables us to uncover a broader range of language semantics and potential\n\n\
    bugs. Our approach can be argued to be more general, i.e., it is designed to work\
    \ with all types of compilers (not just domain specific ones), it supports transformations\
    \ that are not semantic-preserving, and it decouples the oracle (i.e., the PTE\
    \ rules) from the testing algorithm. Lastly, all the existing approaches mentioned\
    \ earlier do not specifically address the test adequacy problem. In contrast,\
    \ our approach has the potential capability to address this problem. Theoretically,\
    \ if our PTE rules cover all the semantics of the target language, we can claim\
    \ that our approach is testing sufficiently. In the future, we aim to explore\
    \ ways of measuring and approximating the coverage of language semantics based\
    \ on the test cases and PTE rules, and further develop ways of improving such\
    \ coverage through test generation.\n\n### 6 CONCLUSION\n\nIn this work, we propose\
    \ a new approach for compiler testing called PTE. The idea is to incrementally\
    \ develop a set of axiomatic semantic rules in the form of (precondition, transformation,\
    \ expectation), which subsequently are used to systematically test the target\
    \ compiler. We applied our approach to two compilers, i.e., the Cangjie compiler\
    \ and the Java compiler. Within a few months, we have identified 42 confirmed,\
    \ unique bugs as well as 9 potential design issues in Cangjie and Java.\n\n###\
    \ REFERENCES\n\n- <span id=\"page-10-21\"></span>[1] Earl T Barr, Mark Harman,\
    \ Phil McMinn, Muzammil Shahbaz, and Shin Yoo. 2014. The oracle problem in software\
    \ testing: A survey. IEEE transactions on software engineering 41, 5 (2014), 507–525.\n\
    - <span id=\"page-10-8\"></span>[2] Denis Bogdanas and Grigore Rosu. 2015. K-Java:\
    \ A Complete Semantics of Java. In Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT\
    \ Symposium on Principles of Programming Languages, POPL 2015, Mumbai, India,\
    \ January 15-17, 2015, Sriram K. Rajamani and David Walker (Eds.). ACM, 445–456.\n\
    - <span id=\"page-10-0\"></span>[3] Junjie Chen, Jibesh Patra, Michael Pradel,\
    \ Yingfei Xiong, Hongyu Zhang, Dan Hao, and Lu Zhang. 2021. A Survey of Compiler\
    \ Testing. ACM Comput. Surv. 53, 1 (2021), 4:1–4:36.<https://doi.org/10.1145/3363562>\n\
    - <span id=\"page-10-6\"></span>[4] Tsong Yueh Chen, S. C. Cheung, and Siu-Ming\
    \ Yiu. 2020. Metamorphic Testing: A New Approach for Generating Next Test Cases.\
    \ CoRR abs/2002.12543 (2020).\n- <span id=\"page-10-7\"></span>[5] Tsong Yueh\
    \ Chen, Fei-Ching Kuo, Huai Liu, Pak-Lok Poon, Dave Towey, TH Tse, and Zhi Quan\
    \ Zhou. 2018. Metamorphic testing: A review of challenges and opportunities. ACM\
    \ Computing Surveys (CSUR) 51, 1 (2018), 1–27.\n- <span id=\"page-10-36\"></span>[6]\
    \ Alastair F. Donaldson, Hugues Evrard, Andrei Lascu, and Paul Thomson. 2017.\
    \ Automated testing of graphics shader compilers. Proc. ACM Program. Lang. 1,\
    \ OOPSLA (2017), 93:1–93:29.<https://doi.org/10.1145/3133917>\n- <span id=\"page-10-37\"\
    ></span>[7] Alastair F. Donaldson, Hugues Evrard, and Paul Thomson. 2020. Putting\
    \ Randomized Compiler Testing into Production (Experience Report). In 34th European\
    \ Conference on Object-Oriented Programming, ECOOP 2020, November 15-17, 2020,\
    \ Berlin, Germany (Virtual Conference) (LIPIcs, Vol. 166), Robert Hirschfeld and\
    \ Tobias Pape (Eds.). Schloss Dagstuhl - Leibniz-Zentrum für Informatik, 22:1–22:29.\
    \ <https://doi.org/10.4230/LIPICS.ECOOP.2020.22>\n- <span id=\"page-10-16\"></span>[8]\
    \ Eclipse. 2023. [https://github.com/eclipse-jdt/eclipse.jdt.core.](https://github.com/eclipse-jdt/eclipse.jdt.core)\
    \ Accessed Jun 26, 2023.\n- <span id=\"page-10-4\"></span>[9] GCC. 2023. 7 Testsuites.\
    \ [https://gcc.gnu.org/onlinedocs/gccint/Testsuites.html.](https://gcc.gnu.org/onlinedocs/gccint/Testsuites.html)\
    \ Accessed Jun 26, 2023.\n- <span id=\"page-10-23\"></span>[10] Hai-Feng Guo and\
    \ Zongyan Qiu. 2013. Automatic grammar-based test generation. In IFIP International\
    \ Conference on Testing Software and Systems. Springer, 17–32.\n- <span id=\"\
    page-10-20\"></span>[11] Kenneth V. Hanford. 1970. Automatic generation of test\
    \ cases. IBM Systems Journal 9, 4 (1970), 242–257.\n- <span id=\"page-10-29\"\
    ></span>[12] Christian Holler, Kim Herzig, Andreas Zeller, et al. 2012. Fuzzing\
    \ with Code Fragments.. In USENIX Security Symposium. 445–458.\n- <span id=\"\
    page-10-9\"></span>[13] Jiao Jiao, Shuanglong Kan, Shang-Wei Lin, David Sanán,\
    \ Yang Liu, and Jun Sun. 2020. Semantic Understanding of Smart Contracts: Executable\
    \ Operational Semantics of Solidity. In 2020 IEEE Symposium on Security and Privacy,\
    \ SP 2020, San Francisco, CA, USA, May 18-21, 2020. IEEE, 1695–1712.\n- <span\
    \ id=\"page-10-1\"></span>[14] Vu Le, Mehrdad Afshari, and Zhendong Su. 2014.\
    \ Compiler validation via equivalence modulo inputs. In ACM SIGPLAN Conference\
    \ on Programming Language Design and Implementation, PLDI '14, Edinburgh, United\
    \ Kingdom - June 09 - 11, 2014, Michael F. P. O'Boyle and Keshav Pingali (Eds.).\
    \ ACM, 216–226. <https://doi.org/10.1145/2594291.2594334>\n- <span id=\"page-10-31\"\
    ></span>[15] Vu Le, Chengnian Sun, and Zhendong Su. 2015. Randomized stress-testing\
    \ of linktime optimizers. In Proceedings of the 2015 international symposium on\
    \ software testing and analysis. 327–337.\n- <span id=\"page-10-10\"></span>[16]\
    \ Xavier Leroy, Sandrine Blazy, Daniel Kästner, Bernhard Schommer, Markus Pister,\
    \ and Christian Ferdinand. 2016. CompCert-a formally verified optimizing compiler.\
    \ In ERTS 2016: Embedded Real Time Software and Systems, 8th European Congress.\n\
    - <span id=\"page-10-11\"></span>[17] Barbara Liskov. 1987. Keynote address-data\
    \ abstraction and hierarchy. In Addendum to the proceedings on Object-oriented\
    \ programming systems, languages and applications (Addendum). 17–34.\n- <span\
    \ id=\"page-10-5\"></span>[18] LLVM. 2023. test-suite. [https://github.com/llvm/llvm-test-suite.git.](https://github.com/llvm/llvm-test-suite.git)\
    \ Accessed Jun 26, 2023.\n- <span id=\"page-10-38\"></span>[19] Haoyang Ma, Qingchao\
    \ Shen, Yongqiang Tian, Junjie Chen, and Shing-Chi Cheung. 2023. Fuzzing Deep\
    \ Learning Compilers with HirGen. In Proceedings of the 32nd ACM SIGSOFT International\
    \ Symposium on Software Testing and Analysis, ISSTA 2023, Seattle, WA, USA, July\
    \ 17-21, 2023, René Just and Gordon Fraser (Eds.). ACM, 248–260.<https://doi.org/10.1145/3597926.3598053>\n\
    - <span id=\"page-10-32\"></span>[20] William M McKeeman. 1998. Differential testing\
    \ for software. Digital Technical Journal 10, 1 (1998), 100–107.\n- <span id=\"\
    page-10-33\"></span>[21] Georg Ofenbeck, Tiark Rompf, and Markus Püschel. 2016.\
    \ RandIR: differential testing for embedded compilers. In Proceedings of the 2016\
    \ 7th ACM SIGPLAN Symposium on Scala. 21–30.\n- <span id=\"page-10-15\"></span>[22]\
    \ OpenJDK. 2023. test-suite. [https://openjdk.org/projects/code-tools/jtreg/intro.](https://openjdk.org/projects/code-tools/jtreg/intro.html)\
    \ [html.](https://openjdk.org/projects/code-tools/jtreg/intro.html) Accessed Jun\
    \ 26, 2023.\n- <span id=\"page-10-19\"></span><span id=\"page-10-18\"></span>[23]\
    \ OpenJDK. 2023. test-suite. [https://openjdk.org/jeps/406.](https://openjdk.org/jeps/406)\
    \ Accessed Jun 26, 2023. [24] Oracle. 2023. [https://www.oracle.com/java/technologies/javase/20-relnote-](https://www.oracle.com/java/technologies/javase/20-relnote-issues.html)\n\
    - <span id=\"page-10-25\"></span>[issues.html.](https://www.oracle.com/java/technologies/javase/20-relnote-issues.html)\
    \ Accessed Jun 26, 2023. [25] Mike Papadakis, Marinos Kintis, Jie Zhang, Yue Jia,\
    \ Yves Le Traon, and Mark Harman. 2019. Mutation testing advances: an analysis\
    \ and survey. In Advances in Computers. Vol. 112. Elsevier, 275–378.\n- <span\
    \ id=\"page-10-13\"></span>[26] PLLab. 2023. [https://gitee.com/HW-PLLab/cangjie/tree/master/docs/llvm.](https://gitee.com/HW-PLLab/cangjie/tree/master/docs/llvm)\
    \ Accessed Jun 26, 2023.\n- <span id=\"page-10-14\"></span>[27] PLLab. 2023. [https://e.gitee.com/HW-PLLab-pro/issues/list?issue=I6F8S6.](https://e.gitee.com/HW-PLLab-pro/issues/list?issue=I6F8S6)\
    \ Accessed Jun 26, 2023.\n- <span id=\"page-10-24\"></span>[28] Paul Purdom. 1972.\
    \ A sentence generator for testing parsers. BIT Numerical Mathematics 12 (1972),\
    \ 366–375.\n- <span id=\"page-10-34\"></span>[29] Sergio Segura, Gordon Fraser,\
    \ Ana B Sanchez, and Antonio Ruiz-Cortés. 2016. A survey on metamorphic testing.\
    \ IEEE Transactions on software engineering 42, 9 (2016), 805–824.\n- <span id=\"\
    page-10-27\"></span>[30] Emin Gün Sirer and Brian N Bershad. 1999. Using production\
    \ grammars in software testing. ACM SIGPLAN Notices 35, 1 (1999), 1–13.\n- <span\
    \ id=\"page-10-26\"></span>[31] Chengnian Sun, Vu Le, and Zhendong Su. 2016. Finding\
    \ compiler bugs via live code mutation. In Proceedings of the 2016 ACM SIGPLAN\
    \ International Conference on Object-Oriented Programming, Systems, Languages,\
    \ and Applications, OOPSLA 2016, part of SPLASH 2016, Amsterdam, The Netherlands,\
    \ October 30 - November 4, 2016, Eelco Visser and Yannis Smaragdakis (Eds.). ACM,\
    \ 849–863.\n- <span id=\"page-10-2\"></span>[32] Chengnian Sun, Vu Le, Qirun Zhang,\
    \ and Zhendong Su. 2016. Toward understanding compiler bugs in GCC and LLVM. In\
    \ Proceedings of the 25th International Symposium on Software Testing and Analysis,\
    \ ISSTA 2016, Saarbrücken, Germany, July 18-20, 2016, Andreas Zeller and Abhik\
    \ Roychoudhury (Eds.). ACM, 294–305.\n- <span id=\"page-10-39\"></span>[33] Dongwei\
    \ Xiao, Zhibo Liu, Yuanyuan Yuan, Qi Pang, and Shuai Wang. 2022. Metamorphic Testing\
    \ of Deep Learning Compilers. Proc. ACM Meas. Anal. Comput. Syst. 6, 1 (2022),\
    \ 15:1–15:28.<https://doi.org/10.1145/3508035>\n- <span id=\"page-10-3\"></span>[34]\
    \ Xuejun Yang, Yang Chen, Eric Eide, and John Regehr. 2011. Finding and understanding\
    \ bugs in C compilers. In Proceedings of the 32nd ACM SIGPLAN conference on Programming\
    \ language design and implementation. 283–294.\n- <span id=\"page-10-17\"></span>[35]\
    \ Michal Zalewski. 2017. American fuzzy lop.\n- <span id=\"page-10-28\"></span>[36]\
    \ Sergey Zelenov and Sophia Zelenova. 2006. Automated generation of positive and\
    \ negative tests for parsers. In Formal Approaches to Software Testing: 5th International\
    \ Workshop, FATES 2005, Edinburgh, UK, July 11, 2005, Revised Selected Papers\
    \ 5. Springer, 187–202.\n- <span id=\"page-10-12\"></span>[37] Yingquan Zhao,\
    \ Junjie Chen, Ruifeng Fu, Haojie Ye, and Zan Wang. 2023. Testing the Compiler\
    \ for a New-born Programming Language: An Industrial Case Study (Experience Paper).\
    \ In The 32nd International Symposium on Software Testing and Analysis.\n- <span\
    \ id=\"page-10-30\"></span>[38] Yingquan Zhao, Zan Wang, Junjie Chen, Mengdi Liu,\
    \ Mingyuan Wu, Yuqun Zhang, and Lingming Zhang. 2022. History-driven test program\
    \ synthesis for JVM testing. In Proceedings of the 44th International Conference\
    \ on Software Engineering. 1133–1144.\n- <span id=\"page-10-35\"></span>[39] Zhi\
    \ Quan Zhou, DH Huang, TH Tse, Zongyuan Yang, Haitao Huang, and TY Chen. 2004.\
    \ Metamorphic testing and its applications. In Proceedings of the 8th International\
    \ Symposium on Future Software Technology (ISFST 2004). Software Engineers Association\
    \ Xian, China, 346–351.\n- <span id=\"page-10-22\"></span>[40] Hong Zhu, Patrick\
    \ AV Hall, and John HR May. 1997. Software unit test coverage and adequacy. Acm\
    \ computing surveys (csur) 29, 4 (1997), 366–427.\n\n<span id=\"page-11-0\"></span>\n\
    \n<span id=\"page-11-1\"></span> class LiskovPTE <: PTERule{ public override func\
    \ precondition(tokens:Tokens): Bool {...} public override prop let expectations:\
    \ Array<Expectation> { ... } func replaceBaseName(srcExpr: CallExpr, oldBaseName:\
    \ String, newBaseName: String) { let baseName = Token(TokenKind.IDENTIFIER, newBaseName)\
    \ var newExpr = Tokens() for (tk in srcExpr.toTokens()) { if (tk.value == oldBaseName)\
    \ { newExpr += baseName } else { newExpr += tk } } return parseCallExpr(newExpr)\
    \ } public override func transformation(tokens:Tokens): Tokens{ let inheritRelations:\
    \ HashMap<String, HashSet<String>> = getInheritRelations(tokens) let classesInfoList:\
    \ HashMap<String, ClassInfo> = getClassInfoList(tokens) let argTypeMap: HashMap<String,\
    \ String> = getArgTypeMap(tokens) let topNode = parseFile(tokens) let nodes =\
    \ getAllNodesInTree(topNode) for (i in 0..nodes.size) { let node = nodes[i] if\
    \ (node is CallExpr) { let expr = node.asCallExpr() let callName = expr.getBaseFunc().toTokens()[0].value\
    \ if (inheritRelations.contains(callName)) { let currentCallArgs = parseArgs(expr,\
    \ argTypeMap) let children = tinheritRelations[callName] let candidateSubClassList\
    \ = ArrayList<ClassInfo>() for (childName in children) { let child = this.classesInfoList[childName]\
    \ if (isQualifiedSubClass(child, currentCallArgs)) { candidateSubClassList.append(child)\
    \ } } if (candidateSubClassList.size != 0){ let subClass = shuffle(candidateSubClassList)[0]\
    \ let newCallExpr=this.replaceBaseName(expr, callName, subClass.name) nodes[i]\
    \ = newCallExpr } } } } return toTokens(nodes) } }\n\n#### Figure 13: The implementation\
    \ of the Liskov Substitution Principle rule's transformation\n\n<span id=\"page-11-2\"\
    ></span> Object o = null; switch(o){ case null: System.out.println(\"null\");\
    \ case Integer i: System.out.println(\"int: \"+i); break; case Short s: System.out.println(\"\
    short: \"+s); break; default: System.out.println(\"default\"); }\n\nFigure 14:\
    \ Example Java program that produces an unhelpful error message.\n\n### APPENDIX\n\
    \n### 1) Additional Examples for Cangjie\n\nFigure [12](#page-11-3) shows the\
    \ implementation of the PTE rule shown in Table [2,](#page-2-1) based on the built-in\
    \ AST library of Cangjie. To determine if there exists an assignment expression\
    \ or a variable declaration with initialization, we enumerate each AST node of\
    \ the program one by one. \"getAllNodesInTree\" is a function used to extract\
    \ all the sub-nodes. If an AST node is either 'AssignExpr' (i.e., the AST node\
    \ type of assignment expression) or 'VarDecl' (i.e., the AST node type of variable\
    \ declaration), we return 'true'. Note that in the latter case, we further check\
    \ whether the declared variable is initialized. Given that there could be dozens\
    \ of thousands of test cases in and thousands of PTE rules, it is important that\
    \ the precondition is designed such that it is fail-fast. Furthermore, some preconditions\
    \ could be much more complicated than the example shown above. For instance, the\
    \ implementation of the 'Liskov Substitution Principle' rule requires extracting\
    \ multiple nodes from the AST to implement the precondition. Concretely, we extract\
    \ the name of constructors (as well as their signatures) of each class and the\
    \ inheritance relation between different classes.\n\n<span id=\"page-11-3\"></span>\
    \ public class EqConditioanlExprStd <: PTERule{ public override func precondition(tokens:Tokens):\
    \ Bool { let topNode = parseFile(tokens) let nodes = getAllNodesInTree(topNode)\
    \ for (node in nodes) { if (node is AssignExpr) { return true } if (node is VarDecl)\
    \ { let ve = decomposeVarDecl(decl) if (ve.contains(\"initlzr\")){ return true\
    \ } } } return false } public override func transformation(tokens:Tokens): Tokens\
    \ { let topNode = parseFile(tokens) let nodes = getAllNodesInTree(topNode) for\
    \ (i in 0..nodes.size) { let node = nodes[i] if (node is AssignExpr) { let leftRef\
    \ = expr.getLeftValue().toTokens() let rV = expr.getRightExpr().toTokens() nodes[i]\
    \ = parseAssignExpr(quote(\\$leftRef=if(true){\\$(rV)}else{\\$(rV)})) } if (node\
    \ is VarDecl) { ... } } return toTokens(nodes) } public override prop let expectations:\
    \ Array<Expectation> { get(){ return [Expectation(Equiv)] } } }\n\nFigure 12:\
    \ The implementation of the rule shown in Table [2](#page-2-1)\n\n### 2) Additional\
    \ Examples for Java\n\nFigure [14](#page-11-2) shows an example of Java program\
    \ that produces an unhelpful error message."
- title: "Learning in the Wild: Towards Leveraging Unlabeled Data for Effectively\n\
    \  Tuning Pre-trained Code Models"
  abstract: 'Pre-trained code models have recently achieved substantial improvements
    in

    many code intelligence tasks. These models are first pre-trained on large-scale

    unlabeled datasets in a task-agnostic manner using self-supervised learning,

    and then fine-tuned on labeled datasets in downstream tasks. However, the

    labeled datasets are usually limited in size (i.e., human intensive efforts),

    which may hinder the performance of pre-trained code models in specific tasks.

    To mitigate this, one possible solution is to leverage the large-scale

    unlabeled data in the tuning stage by pseudo-labeling. However, directly

    employing the pseudo-labeled data can bring a large amount of noise, i.e.,

    incorrect labels, leading to suboptimal performance. How to effectively

    leverage the noisy pseudo-labeled data is a challenging yet under-explored

    problem.In this paper, we propose a novel approach named HINT to improve

    pre-trained code models with large-scale unlabeled datasets by better utilizing

    the pseudo-labeled data. HINT includes two main modules: HybrId pseudo-labeled

    data selection and Noise-tolerant Training. In the hybrid pseudo-data selection

    module, considering the robustness issue, apart from directly measuring the

    quality of pseudo labels through training loss, we further propose to employ a

    retrieval-based method to filter low-quality pseudo-labeled data. The

    noise-tolerant training module aims to further mitigate the influence of errors

    in pseudo labels by training the model with a noise-tolerant loss function and

    by regularizing the consistency of model predictions.The experimental results

    show that HINT can better leverage those unlabeled data in a task-specific way

    and provide complementary benefits for pre-trained models, e.g., improving the

    best baseline model by 15.33%, 16.50%, and 8.98% on code summarization, defect

    detection, and assertion generation, respectively.'
  url: http://arxiv.org/abs/2401.01060v1
  keywords: ''
  document: "# Learning in the Wild: Towards Leveraging Unlabeled Data for Effectively\
    \ Tuning Pre-trained Code Models\n\nShuzheng Gao The Chinese University of Hong\
    \ Kong Hong Kong, China szgao23@cse.cuhk.edu.hk\n\n> Li Li Beihang university\
    \ Beijing, China lilicoding@ieee.org\n\nWenxin Mao Harbin Institute of Technology\
    \ Shenzhen, China maowx5519@mails.jlu.edu.cn\n\nXing Hu, Xin Xia Zhejiang university\
    \ Zhejiang, China xinghu@zju.edu.cn,xin.xia@acm.org\n\nCuiyun Gao<sup>∗</sup>\
    \ Harbin Institute of Technology Shenzhen, China gaocuiyun@hit.edu.cn\n\nMichael\
    \ R. Lyu The Chinese University of Hong Kong Hong Kong, China lyu@cse.cuhk.edu.hk\n\
    \n## ABSTRACT\n\nPre-trained code models have recently achieved substantial improvements\
    \ in many code intelligence tasks. These models are first pre-trained on large-scale\
    \ unlabeled datasets in a task-agnostic manner using self-supervised learning,\
    \ and then fine-tuned on labeled datasets in downstream tasks. However, the labeled\
    \ datasets are usually limited in size (i.e., human intensive efforts), which\
    \ may hinder the performance of pre-trained code models in specific tasks. To\
    \ mitigate this, one possible solution is to leverage the large-scale unlabeled\
    \ data in the tuning stage by pseudo-labeling, i.e., generating pseudo labels\
    \ for unlabeled data and further training the pre-trained code models with the\
    \ pseudo-labeled data. However, directly employing the pseudo-labeled data can\
    \ bring a large amount of noise, i.e., incorrect labels, leading to suboptimal\
    \ performance. How to effectively leverage the noisy pseudo-labeled data is a\
    \ challenging yet under-explored problem.\n\nIn this paper, we propose a novel\
    \ approach named HINT to improve pre-trained code models with large-scale unlabeled\
    \ datasets by better utilizing the pseudo-labeled data. HINT includes two main\
    \ modules: HybrId pseudo-labeled data selection and Noise-tolerant Training. In\
    \ the hybrid pseudo-data selection module, considering the robustness issue, apart\
    \ from directly measuring the quality of pseudo labels through training loss,\
    \ we propose to further employ a retrieval-based method to filter low-quality\
    \ pseudo-labeled data. The noise-tolerant training module aims to further mitigate\
    \ the influence of errors in pseudo labels by training the model with a noise-tolerant\
    \ loss function and by regularizing the consistency of model predictions. We evaluate\
    \ the effectiveness of HINT on three popular code intelligence tasks, including\
    \ code summarization, defect detection, and assertion generation. We build our\
    \ method on top of three popular open-source pre-trained code models. The\n\n\
    ICSE '24, April 14–20, 2024, Singapore, Singapore\n\n© 2023 Association for Computing\
    \ Machinery.\n\nACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . \\$15.00\n\n<https://doi.org/10.1145/nnnnnnn.nnnnnnn>\n\
    \nexperimental results show that HINT can better leverage those unlabeled data\
    \ in a task-specific way and provide complementary benefits for pre-trained models,\
    \ e.g., improving the best baseline model by 15.33%, 16.50%, and 8.98% on code\
    \ summarization, defect detection, and assertion generation, respectively.\n\n\
    ### CCS CONCEPTS\n\n#### • Software and its engineering → Software development\
    \ techniques;\n\n#### ACM Reference Format:\n\nShuzheng Gao, Wenxin Mao, Cuiyun\
    \ Gao, Li Li, Xing Hu, Xin Xia, and Michael R. Lyu. 2023. Learning in the Wild:\
    \ Towards Leveraging Unlabeled Data for Effectively Tuning Pre-trained Code Models.\
    \ In Proceedings of the 46th International Conference on Software Engineering\
    \ (ICSE '24), April 14–20, 2024, Lisbon, Portugal. ACM, New York, NY, USA, [13](#page-12-0)\
    \ pages. [https://doi.org/](https://doi.org/10.1145/nnnnnnn.nnnnnnn) [10.1145/nnnnnnn.nnnnnnn](https://doi.org/10.1145/nnnnnnn.nnnnnnn)\n\
    \n### 1 INTRODUCTION\n\nRecently, code intelligence has become a popular research\
    \ field in software engineering. It aims at improving developers' productivity\
    \ by providing real-time coding assistance and suggestions for them [\\[9,](#page-11-0)\
    \ [28\\]](#page-11-1). The advent of deep learning techniques, especially pretraining\
    \ techniques [\\[12,](#page-11-2) [54\\]](#page-12-1), has significantly advanced\
    \ progress in this area. Different from previous supervised learning methods that\
    \ train the model from scratch [\\[1,](#page-10-0) [72\\]](#page-12-2), these\
    \ pre-trained code models are first pre-trained on large-scale unlabeled datasets\
    \ using selfsupervised learning tasks and then fine-tuned on labeled datasets\
    \ in downstream tasks. For example, Masked Language Modeling (MLM) is one of the\
    \ most popular self-supervised pre-training tasks and is used in many pre-trained\
    \ code models such as CodeBERT [\\[14\\]](#page-11-3) and GraphCodeBERT [\\[21\\\
    ]](#page-11-4). It works by training the models to predict the masked tokens based\
    \ on the context of surrounding words. Since this process does not require human\
    \ annotation, it can be applied on large-scale unlabeled datasets, enabling the\
    \ models to acquire a vast amount of general programming knowledge. Equipped with\
    \ this ability, these pre-trained code models achieve state-of-the-art performance\
    \ on a variety of code intelligence tasks, such as code summarization and defect\
    \ detection [\\[14,](#page-11-3) [17,](#page-11-5) [20,](#page-11-6) [21\\]](#page-11-4).\n\
    \nDespite the promising results, deep learning models are known to be data-hungry\
    \ and the size of labeled datasets in downstream tasks is important for the performance\
    \ of pre-trained models [\\[23,](#page-11-7) [66\\]](#page-12-3). However, the\
    \ sizes of labeled datasets in downstream tasks are\n\n<sup>∗</sup>Corresponding\
    \ author. The author is also affiliated with Peng Cheng Laboratory and Guangdong\
    \ Provincial Key Laboratory of Novel Security Intelligence Technologies.\n\nPermission\
    \ to make digital or hard copies of all or part of this work for personal or classroom\
    \ use is granted without fee provided that copies are not made or distributed\
    \ for profit or commercial advantage and that copies bear this notice and the\
    \ full citation on the first page. Copyrights for components of this work owned\
    \ by others than ACM must be honored. Abstracting with credit is permitted. To\
    \ copy otherwise, or republish, to post on servers or to redistribute to lists,\
    \ requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.\n\
    \nusually limited due to two main reasons. On one hand, the datasets crawled from\
    \ open-source websites like Github or Stackoverflow are small in size and of low\
    \ quality. For example, as mentioned in the literature [\\[31\\]](#page-11-8),\
    \ only 6.8% JavaScript code snippets from popular GitHub repositories contain\
    \ corresponding comments, making only a few of them usable for tasks like code\
    \ summarization. Furthermore, recent studies have revealed that the quality of\
    \ existing crawled datasets is also quite poor [\\[11,](#page-11-9) [57,](#page-12-4)\
    \ [58\\]](#page-12-5). For example, as indicated in a recent work [\\[57\\]](#page-12-4),\
    \ over 40% of data in the widely-used code summarization datasets contain various\
    \ types of noise. On the other hand, due to the requirement of domain expert knowledge,\
    \ the annotation cost of code intelligence tasks is higher than other tasks in\
    \ natural language processing or computer vision, such as sentiment analysis and\
    \ image classification [\\[60\\]](#page-12-6). With insufficient annotated data\
    \ in downstream tasks, the performance of pre-trained code models is limited.\n\
    \nOne possible solution to this problem is to leverage the largescale unlabeled\
    \ data in the tuning stage by pseudo-labeling. Pseudolabeling first trains a base\
    \ model on the limited labeled dataset, which subsequently serves as a teacher\
    \ model to annotate the unlabeled dataset [\\[34,](#page-11-10) [40,](#page-11-11)\
    \ [48\\]](#page-12-7). The pseudo-labeled dataset is then merged with the original\
    \ labeled dataset to help improve the training of a new student model. By replacing\
    \ the teacher model with the stronger student model, the above process can be\
    \ iterated multiple times, aiming at improving the models themselves. This technique\
    \ leverages the unlabeled data in a task-specific way and has shown promising\
    \ results in tasks such as image classification [\\[40\\]](#page-11-11) and dialog\
    \ systems [\\[48\\]](#page-12-7). Although pseudo-labeling can enrich the labeled\
    \ dataset, directly employing the pseudo-labeled data can bring a large amount\
    \ of noise [\\[48\\]](#page-12-7). For example, as shown in Figure [1](#page-1-0)\
    \ (a), the pseudo-labeled summary of the top code snippet is not a meaningful\
    \ sentence and contains redundant tokens. Training with such noisy pseudo labels\
    \ may amplify the incorrect knowledge in the teacher model and ultimately degrades\
    \ the model's performance. However, identifying and removing noisy pseudo labels\
    \ is non-trivial due to the complex semantic of source code. Besides, it is difficult\
    \ and impractical to ensure that the filtered dataset is noise-free [\\[64,](#page-12-8)\
    \ [74\\]](#page-12-9). Therefore, how to effectively leverage the noisy pseudo-labeled\
    \ data and enable the model to be noise-tolerant for code intelligence tasks is\
    \ of vital importance, yet under-explored.\n\nIn this paper, we propose HINT with\
    \ two main components, i.e., the HybrId pseudo-labeled data selection module and\
    \ the Noisetolerant Training module. First, in the hybrid pseudo-labeled data\
    \ selection module, we propose to combine the training loss of the teacher model\
    \ and a retrieval-based method for removing the lowquality data. Specifically,\
    \ we filter out pseudo-labeled samples that present high training loss or low\
    \ label similarity with the retrieved similar training sample. To further mitigate\
    \ the influence of data noise on model performance, we propose a noise-tolerant\
    \ training objective that includes a noise-tolerant symmetric loss function and\
    \ a consistency regularization of model predictions. To evaluate the performance\
    \ of HINT, we conduct experiments on three popular code intelligence tasks including\
    \ code summarization, defect detection, and assertion generation. Following previous\
    \ work [\\[18,](#page-11-12) [51,](#page-12-10) [63\\]](#page-12-11), we build\
    \ our method on top of three popular open-source pretrained models: CodeBERT [\\\
    [14\\]](#page-11-3), CodeT5 [\\[65\\]](#page-12-12), and UniXcoder [\\[20\\]](#page-11-6).\n\
    \n<span id=\"page-1-0\"></span>![](_page_1_Figure_3.jpeg)\n\n(a) A Python example\
    \ of low-quality pseudo-labeled data (top).\n\n![](_page_1_Figure_5.jpeg)\n\n\
    (b) A Java example of high-quality pseudo-labeled data (top).\n\nFigure 1: Examples\
    \ in the code summarization task for illustrating the motivation of the hybrid\
    \ pseudo-labeled data selection method, which indicates the loss-based data selection\
    \ strategy alone may incorrectly measure the quality of pseudo labels.\n\nExtensive\
    \ experiments demonstrate that HINT can consistently improve the performance of\
    \ pre-trained code models on these code intelligence tasks. For example, HINT\
    \ improves UniXcoder by 15.33%, 16.50%, and 8.98% in terms of BLEU-4, F1, and\
    \ EM on code summarization, defect detection, and assertion generation, respectively,\
    \ indicating that our proposed HINT method can provide complementary benefits\
    \ for the pre-trained code models.\n\nIn summary, the main contributions of this\
    \ work are as follows:\n\n- (1) To the best of our knowledge, we are the first\
    \ to leverage the large-scale unlabeled data in a task-specific way in the turning\
    \ phase for code intelligence tasks.\n- (2) We propose HINT, a novel framework\
    \ to leverage large-scale unlabeled data for effectively tuning pre-trained code\
    \ models. It first selects high-quality pseudo-labeled data in a hybrid way and\
    \ then improves the model's tolerance to noisy data in the training process.\n\
    - (3) Extensive experiments on three tasks demonstrate that our method can be\
    \ built on top of a range of existing strong pretrained models and consistently\
    \ improve their performance on many downstream tasks.\n\n<span id=\"page-2-0\"\
    ></span>![](_page_2_Figure_0.jpeg)\n\nFigure 2: The overview of HINT.\n\n# 2 PROPOSED\
    \ APPROACH\n\n### 2.1 Problem Setup and Overview\n\nIn this section, we explicate\
    \ the detailed design of HINT. Formally, in code intelligence tasks such as code\
    \ summarization, we have a set of source codes and summaries . Let = {( , )} =1\
    \ denotes the labeled training dataset, where ∈ , ∈ and denotes the size of .\
    \ Let = { } =1 denote the large unlabeled dataset, where denotes the size of and\
    \ > in general. Our goal is to learn a model : ↦→ from both and that can well\
    \ predict the label of input in the test set.\n\nThe overall framework of HINT\
    \ is shown in Figure [2.](#page-2-0) We first train a teacher model on the original\
    \ labeled dataset and 1 use the teacher model to generate pseudo labels for the\
    \ unlabeled dataset. Then, 2 a hybrid pseudo-labeled data selection method that\
    \ contains loss-based selection and retrieval-based selection is proposed to filter\
    \ the code with low-quality pseudo labels (introduced in Section [2.2\\)](#page-2-1).\
    \ For further mitigating the influence of noise in pseudo labels during model\
    \ training, we propose 3 a noise-tolerant training strategy that trains the student\
    \ model with noise-tolerant symmetric cross entropy loss and consistency regularization\
    \ (introduced in Section [2.3\\)](#page-3-0). The above procedure can be iterated\
    \ multiple times, enabling the models to be self-improved (introduced in Section\
    \ [2.4\\)](#page-4-0). The algorithm is shown in Algorithm [1.](#page-3-1)\n\n\
    ## <span id=\"page-2-1\"></span>2.2 Hybrid Pseudo-labeled Data Selection\n\nOnce\
    \ we get a trained teacher model F , we use it to generate pseudo labels for unlabeled\
    \ dataset , producing a pseudo labeled dataset = {( ,ˆ )} =1 . The pseudo-labeled\
    \ data cannot be employed directly, since they may contain substantial noise and\
    \ impact the model performance. Previous studies in machine learning [\\[22,](#page-11-13)\
    \ [30\\]](#page-11-14) mainly employ loss-based selection by filtering the data\
    \ with high training loss based on the insight that neural models can well distinguish\
    \ the quality of each sample (i.e., noisy data are generally associated with higher\
    \ training loss). However, code intelligence\n\nmodels are known to suffer from\
    \ the robustness issue [\\[25\\]](#page-11-15), so solely relying on the model\
    \ training loss for noise filtering is ineffective. For the example in Figure\
    \ [1](#page-1-0) (a), we can observe that although the quality of this generated\
    \ summary is pretty poor, its loss is low in value. Specifically, when comparing\
    \ the loss of all the pseudolabeled data, it exhibits a lower loss than 83% of\
    \ the pseudo-labeled data. Besides, in Figure [1](#page-1-0) (b), the generated\
    \ pseudo summary can well describe the meaning of checking the equivalence of\
    \ two objects in the Java code snippet but its training loss value is relatively\
    \ high, i.e., surpassing 52% of the pseudo-labeled data.\n\nConsidering that code\
    \ reuse is widespread in software development [\\[35,](#page-11-16) [37\\]](#page-11-17),\
    \ apart from the loss-based selection, we propose to further select high-quality\
    \ data through a retrieval-based method. As shown in Figure [1,](#page-1-0) by\
    \ comparing the pseudo-labeled summaries and retrieved summaries, we can systematically\
    \ identify the pseudolabeled data in Figure [1](#page-1-0) (b) as a high-quality\
    \ sample and filter the low-quality pseudo-labeled data in Figure [1](#page-1-0)\
    \ (a). Specifically, in the retrieval-based selection, for each unlabeled data\
    \ , we first use the widely-used BM-25 method [\\[44\\]](#page-11-18) to retrieve\
    \ the most similar code in the labeled training set. Then we propose to compare\
    \ the similarities of and and their corresponding pseudo label ˆ and groud truth\
    \ label through normalized edit distance:\n\n$$NED(\\mathbf{x}, y) = \\begin{cases}\
    \ \\begin{array}{c} \\frac{edit\\\\_distance(\\mathbf{x}, y)}{||\\mathbf{x}||}\
    \ \\\\ \\end{array} & \\text{if } \\mathbf{x}, y \\in sequence \\end{array} \\\
    qquad (1)$$\n\nwhere ||.|| denotes the length of the sequence and I{.} is an indicator\
    \ function that returns 1 if the condition is true and 0 otherwise. Specifically,\
    \ if both ( , ) and (ˆ , ) are not higher than the threshold , we consider this\
    \ sample ( ,ˆ ) as a correctly predicted sample and add it to the selected dataset\
    \ . On the contrary, if ( , ) is lower than while (ˆ , ) is above 1 − , we choose\
    \ to filter it as it has a higher probability of being a noisy data (Line 9-11\
    \ in Algorithm [1\\)](#page-3-1). Here is a hyperparameter\n\n<span id=\"page-3-1\"\
    ></span>Algorithm 1 Algorithm of HINT\n\nInput: labeled dataset , unlabeled dataset\
    \ , threshold of edit distance , the threshold in loss-based selection , code\
    \ transformation function , iteration number Output: neural model F 1: Train the\
    \ teacher model F on 2: for each in do 3: Generate pseudo data for using F 4:\
    \ Calculate the loss of samples in using F 5: TK ← samples with the least top\
    \ % loss value in 6: ← ∅ 7: for each sample { , ′ } in do 8: Retrieve the most\
    \ similar sample ( , ) from 9: if ( , ) ≤ ∧ ( , ′ ) ≤ then 10: .insert({ , ′ })\
    \ 11: else if ( , ) ≤ ∧ ( , ′ ) ≥ 1 − then 12: continue 13: else if F ( , ′ )\
    \ ∈ TK then 14: .insert({ , ′ }) 15: end if 16: end for 17: ← ∪ 18: Train the\
    \ student model F with dataset and transformation function through Equation [4](#page-4-1)\
    \ 19: F ← F 20: end for\n\n```\n21: return model F\n```\nto control the filtering\
    \ threshold. For samples that cannot be decided by the retrieval-based selection,\
    \ we first calculate the training loss of each pseudo-labeled data by re-feeding\
    \ each code into the teacher model F and using the generated pseudo label ˆ as\
    \ the ground-truth label. We then select the top % data with the lowest loss values\
    \ among all pseudo-labeled data and add them to (Line 4-5, 13-14 in Algorithm\
    \ [1\\)](#page-3-1). Finally, we obtain a dataset = ( ,ˆ ) ′ =1 containing high-quality\
    \ pseudo-labeled data. The dataset is employed to train the student model, together\
    \ with the labeled dataset .\n\n### <span id=\"page-3-0\"></span>2.3 Noise-tolerant\
    \ Training\n\nDespite the dedicated data selection effort, it is still difficult\
    \ and impractical to ensure that the selected samples are noise-free. Besides,\
    \ the pseudo-labeled samples with minor noise are not completely harmful and can\
    \ also provide rich information for model training. For example, as shown in Figure\
    \ [3,](#page-3-2) the assertion statement generated by the teacher model mistakenly\
    \ predicts the assertion type as \"assertionEquals\". If we directly use it as\
    \ ground truth to train the model, the model may be misled. Nevertheless, this\
    \ sample still contains much valuable information since the predictions on other\
    \ positions such as the parameters are correct. Therefore, instead of directly\
    \ discarding these samples with a more strict filtering process, we propose to\
    \ leverage the pseudo-labeled data with noise-tolerant loss function and consistency\
    \ regularization during model training.\n\n<span id=\"page-3-2\"></span>![](_page_3_Figure_6.jpeg)\n\
    \norg**.**junit**.**Assert**.assertEquals**(value,adapter.getPreserved(\"prop\"\
    ))\n\n#### Figure 3: An example of a pseudo label with a minor error.\n\nNoise-tolerant\
    \ Loss Function: Previous studies [\\[64,](#page-12-8) [74\\]](#page-12-9) have\
    \ found that the widely-used cross entropy (CE) loss function is sensitive to\
    \ noisy training data. Specifically, the coefficient in the gradient of the CE\
    \ loss function − 1 ( ; ) ∇ ( ; ) assigns larger weights to samples with higher\
    \ loss and smaller weights to samples with lower loss. Since noisy data often\
    \ obtain a high training loss in the training process [\\[22,](#page-11-13) [30\\\
    ]](#page-11-14), models trained with CE loss easily focus on those noisy data\
    \ and tend to be misled. However, the reweighting coefficient in the gradient\
    \ of CE is also beneficial for model training. Directly removing it as −∇ ( ;\
    \ ) might bring the slow convergence problem [\\[74\\]](#page-12-9). To deal with\
    \ this problem, we propose to employ the Symmetric Cross Entropy loss (SCE) [\\\
    [64\\]](#page-12-8):\n\n<span id=\"page-3-3\"></span>\n$$l\\_{\\text{score}}(\\\
    mathbf{x}, \\mathbf{y}) = -\\sum\\_{c=1}^{C} (p(c|\\mathbf{x}\\_{l}) \\log(q(c|\\\
    mathbf{x})) + q(c|\\mathbf{x}\\_{l}) \\log(p(c|\\mathbf{x}))), \\tag{2}$$\n\n\
    where (|) is the prediction of the model and (|) is the corresponding ground truth\
    \ label in the dataset. denotes the number of classes in the classification task\
    \ or the size of vocabulary in the generation task. The former item represents\
    \ the CE loss, while the latter item corresponds to the Reverse Cross Entropy\
    \ (RCE) [\\[64\\]](#page-12-8) which assigns the same weights for all samples,\
    \ i.e., −∇ ( ; ). Note that log (|) is 0 for the ground truth class and the same\
    \ negative value for other classes. Based on the relation ( ∗ |) = 1 − Í =1,≠\
    \ <sup>∗</sup> (|) where <sup>∗</sup> denotes the ground class, we can achieve\
    \ the above result. In this way, the student model is less likely to be influenced\
    \ by minor errors in pseudo labels.\n\nConsistency Regularization: According to\
    \ Equation [2,](#page-3-3) the noise-tolerant loss relies on the quality of pseudo\
    \ labels. Considering that such supervision signals from pseudo labels might be\
    \ noisy and unreliable, we further propose to add consistency regularization between\
    \ predictions of the original code and the transformed code. It could enrich the\
    \ supervision signals and provide the student model with a more reliable objective\
    \ function without manual labels. Specifically, given a code snippet , we first\
    \ apply a code transformation function (·) and obtain the transformed input ().\
    \ Then, the consistency regularization is applied to align the distributions of\
    \ the predictions F () and F (()):\n\n$$dl\\_{cr} = KL(\\mathcal{F}\\_{\\mathfrak{s}}(\\\
    mathbf{x}) || \\mathcal{F}\\_{\\mathfrak{s}}(\\operatorname{ct}(\\mathbf{x})))\
    \ + KL(\\mathcal{F}\\_{\\mathfrak{s}}(\\operatorname{ct}(\\mathbf{x})) || \\mathcal{F}\\\
    _{\\mathfrak{s}}(\\mathbf{x})),\\tag{3}$$\n\nwhere (·||·) denotes the Kullback-Leibler\
    \ Divergence [\\[38\\]](#page-11-19). For generation tasks, we approximate it\
    \ by the average value per token. For code transformation methods, we follow previous\
    \ work [\\[56\\]](#page-12-13)\n\nand employ four effective transformation methods,\
    \ including Dynamic Masking, Dynamic Replacement, Dynamic Replacement of Specified\
    \ Type, and Dynamic Masking of Specified Type. For each sample, we randomly select\
    \ one transformation function in each epoch. Different from previous task-agnostic\
    \ contrastive learning pre-training methods that only focus on aligning the representation\
    \ of code and transformed code [\\[20,](#page-11-6) [33\\]](#page-11-20), our\
    \ method directly constrains the prediction F () and F (()) of code and transformed\
    \ code on downstream tasks and regularizes them in a task-specific way.\n\nFinally,\
    \ HINT trains the student model by combining the noisetolerant loss function and\
    \ consistency regularization as follows:\n\n$$I = \\sum\\_{(\\mathbf{x}, \\mathbf{y})\
    \ \\in D \\cup S} \\{ \\left. l\\_{\\text{sec}}(\\mathbf{x}, \\mathbf{y}) + l\\\
    _{\\text{sec}}(\\text{ct}(\\mathbf{x}), \\mathbf{y}) + \\mu \\cdot l\\_{\\text{cr}}\
    \ \\right\\}, \\tag{4}$$\n\n<span id=\"page-4-1\"></span>where is a hyperparameter\
    \ to balance the training signals from pseudo labels and the consistency regularization.\n\
    \n### <span id=\"page-4-0\"></span>2.4 Iterative Training\n\nBased on the aforementioned\
    \ process, we can obtain a student model that has better performance than the\
    \ teacher model. Then, we can build upon this student model and repeat the process\
    \ described above to further boost the models themselves ( 1 → 2 → 3 → 1 ). Specifically,\
    \ at the end of each iteration, the student model substitutes the teacher model,\
    \ which is then employed to generate pseudo labels for the unlabeled dataset in\
    \ the subsequent iteration. In general, the better the base model, the higher\
    \ the quality of the pseudo labels. In this way, the student model in the next\
    \ iteration is more likely to be trained on pseudo-labeled data with higher quality\
    \ and thus achieves better performance. We follow previous work [\\[47,](#page-12-14)\
    \ [48\\]](#page-12-7) and reinitialize the new student model from the pre-trained\
    \ code models in every iteration. After all iterations, the student model in the\
    \ last iteration will be used as the final model for predictions on the test set.\n\
    \n### 3 EXPERIMENTAL SETUP\n\n### 3.1 Research Questions\n\nAs we claimed above,\
    \ HINT is a generic framework that works without imposing specific assumptions\
    \ regarding data distribution, underlying models, or task characteristics, except\
    \ for the requirement that the input needs to be in the form of code. To validate\
    \ the generalizability of HINT, we propose to evaluate the performance of HINT\
    \ on a variety of pre-trained code models and three semi-supervised code intelligence\
    \ tasks with code as input. As for the data distribution, we also evaluate the\
    \ performance of HINT on cross-domain scenarios that do not have sufficient training\
    \ data and may present data distribution gap between training and unlabeled data.\
    \ Furthermore, we also explore the effectiveness of each component in HINT and\
    \ the influence of hyperparameters on its performance. In summary, we evaluate\
    \ HINT by addressing the following four research questions:\n\n- RQ1: How much\
    \ improvement can HINT provide to existing pre-trained code models?\n- RQ2: What\
    \ is the impact of each component on the performance of HINT?\n\nRQ3: How well\
    \ does HINT perform in cross-domain scenarios? RQ4: How does HINT's performance\
    \ vary under different parameter settings?\n\n### 3.2 Evaluation Tasks\n\nWe conduct\
    \ experiments on three representative code intelligence tasks: code summarization,\
    \ defect detection, and assertion generation, for covering different task types,\
    \ i.e., Code → Text, Code → Label, and Code → Code. Due to the space limitation,\
    \ we provide a more detailed description of evaluation metrics and statistics\
    \ of the benchmark datasets in our replication packages [\\[26\\]](#page-11-21).\n\
    \n3.2.1 Code Summarization. Code Summarization aims to generate useful comments\
    \ for a given code snippet. It can help alleviate the developers' cognitive efforts\
    \ in comprehending programs [\\[7,](#page-11-22) [19\\]](#page-11-23).\n\nDatasets.\
    \ In this study, we conduct experiments on two popular benchmark datasets JCSD\
    \ and PCSD, which contain Java and Python source code, respectively. The JCSD\
    \ dataset we used is publicly released by Hu et al. [\\[27\\]](#page-11-24), which\
    \ contains 87,136 pairs of Java methods and comments collected from 9,714 GitHub\
    \ repositories. The PCSD dataset comprises 92,545 functions with their respective\
    \ documentation, which is originally collected by Barone et al. [\\[3\\]](#page-10-1)\
    \ and later processed by Wei et al. [\\[69\\]](#page-12-15). For our experiments,\
    \ we directly used the benchmark datasets released by previous studies [\\[1,](#page-10-0)\
    \ [27\\]](#page-11-24), in which the datasets are divided into training, validation,\
    \ and test sets in a ratio of 8 : 1 : 1 and 6 : 2 : 2 for Java and Python, respectively.\
    \ As reported in previous work [\\[49,](#page-12-16) [55\\]](#page-12-17), there\
    \ are duplicated data in the training and test set of the JCSD dataset. Therefore,\
    \ following them, we remove the test samples that also appear in the training\
    \ or validation set and finally get a deduplicated test set with 6,489 samples.\
    \ Since there has been no dataset for the evaluation of code intelligence tasks\
    \ in a semi-supervised setting, we propose to simulate it by extending existing\
    \ datasets. Specifically, following previous studies [\\[36,](#page-11-25) [48\\\
    ]](#page-12-7), we randomly dividing the initial training data into two subsets:\
    \ labeled training data and an unlabeled dataset, with the ratio of 9:1.\n\nMetrics.\
    \ For code summarization, we follow previous work [\\[1,](#page-10-0) [16,](#page-11-26)\
    \ [49\\]](#page-12-16) and use four popular metrics BLEU-4 [\\[53\\]](#page-12-18),\
    \ ROUGE-L [\\[43\\]](#page-11-27), METEOR [\\[2\\]](#page-10-2), and CIDEr [\\\
    [61\\]](#page-12-19) for evaluation.\n\n3.2.2 Defect Detection. Defect detection\
    \ aims at identifying the vulnerabilities in the given program, which is crucial\
    \ to defend a software system from cyberattack [\\[13,](#page-11-28) [75\\]](#page-12-20).\n\
    \nDatasets. In our experiments, we utilize the widely-used Big-Vul dataset created\
    \ by Fan et al. [\\[13\\]](#page-11-28). This dataset contains 188,636 C/C++ code\
    \ snippets sourced from more than 300 GitHub projects dating from 2002 to 2019\
    \ in Common Vulnerabilities and Exposures (CVE) database. Following previous studies\
    \ [\\[13\\]](#page-11-28), we partition the dataset into training, validation,\
    \ and test sets with a ratio of 8:1:1. Same with code summarization, we also further\
    \ construct the labeled training data and unlabeled data by dividing the original\
    \ training set of Big-Vul with a ratio of 1:9.\n\nMetrics. We follow previous\
    \ work [\\[41,](#page-11-29) [75\\]](#page-12-20) and evaluate the results by\
    \ Precision (P), Recall (R), and F1.\n\n3.2.3 Assertion Generation. Assertion\
    \ Generation is the task of automatically generating meaningful assert statements\
    \ for unit\n\n| Approach  |            | JCSD   |         |        |       | PCSD\
    \   |         |        |       |\n|-----------|------------|--------|---------|--------|-------|--------|---------|--------|-------|\n\
    |           |            | BLEU-4 | ROUGE-L | METEOR | CIDEr | BLEU-4 | ROUGE-L\
    \ | METEOR | CIDEr |\n|           | Base model | 13.30  | 26.75   | 8.10   | 0.58\
    \  | 17.94  | 32.35   | 9.79   | 0.59  |\n| CodeBERT  | +HINT(1)   | 14.58* |\
    \ 29.06*  | 8.74*  | 0.69* | 18.81* | 34.18*  | 10.52* | 0.69* |\n|          \
    \ | +HINT(5)   | 14.64* | 29.00*  | 8.87*  | 0.71* | 18.86* | 34.25*  | 10.87*\
    \ | 0.72* |\n| CodeT5    | Base model | 16.67  | 34.28   | 11.39  | 1.05  | 21.13\
    \  | 40.27   | 15.69  | 1.22  |\n|           | +HINT(1)   | 18.32* | 35.49*  |\
    \ 12.36* | 1.22* | 22.33* | 41.42*  | 16.31* | 1.35* |\n|           | +HINT(5)\
    \   | 18.48* | 35.63*  | 12.29* | 1.24* | 22.55* | 41.67*  | 16.21* | 1.36* |\n\
    |           | Base model | 17.16  | 32.56   | 11.05  | 1.11  | 22.42  | 35.84\
    \   | 15.38  | 1.31  |\n| UniXcoder | +HINT(1)   | 18.90* | 35.16*  | 12.38* |\
    \ 1.28* | 23.77* | 41.67*  | 16.64* | 1.48* |\n|           | +HINT(5)   | 19.79*\
    \ | 35.83*  | 13.12* | 1.36* | 23.98* | 41.93*  | 16.83* | 1.50* |\n\n<span id=\"\
    page-5-0\"></span>Table 1: Experimental results on code summarization. \"\\*\"\
    \ denotes statistical significance in comparison to the base models (i.e., two-sided\
    \ -test with -value< 0.01).\n\ntests. It can reduce the manual efforts in writing\
    \ test cases and facilitate faster detection and diagnosis of software failures\
    \ [\\[46,](#page-12-21) [73\\]](#page-12-22).\n\nDatasets. For assertion generation,\
    \ we follow previous work [\\[46,](#page-12-21) [73\\]](#page-12-22) and use the\
    \ ATLAS dataset [\\[68\\]](#page-12-23). It contains 188,154 real-world test assertions\
    \ obtained from open-source projects in GitHub. The dataset is composed of eight\
    \ categories of assertions, and each sample in ATLAS is comprised of a focal method\
    \ and a test method which serve as the context for generating a single assertion\
    \ for the given test method. We use the original partition of ATLAS and split\
    \ it into three subsets: training, validation, and test, in an 8:1:1 ratio. The\
    \ construction of an unlabeled dataset for assertion generation is also the same\
    \ as the above two tasks. We randomly extract 90% of the training data for the\
    \ construction of the unlabeled dataset and use the remaining data as the labeled\
    \ dataset.\n\nMetrics. We follow previous work [\\[50,](#page-12-24) [73\\]](#page-12-22)\
    \ in this field and use Exact Match (EM), Longest Common Subsequence (LCS), and\
    \ Edit Distance (ED) as evaluation metrics.\n\n### 3.3 Baselines\n\nWe evaluate\
    \ the performance of HINT by building it on the top of three popular open-source\
    \ pre-trained code models, namely CodeBERT [\\[14\\]](#page-11-3), CodeT5 [\\\
    [65\\]](#page-12-12), and UniXcoder [\\[20\\]](#page-11-6). CodeBERT is a representative\
    \ pre-trained code model that is pre-trained with six programming languages and\
    \ uses Masked Language Modeling and Replace Token Detection as pre-trained tasks.\
    \ CodeT5 is a sequence-to-sequence pre-trained model which involves two coderelated\
    \ pre-training objectives: identifier tagging and masked identifier prediction.\
    \ It achieves state-of-the-art performance in many sequence generation tasks.\
    \ UniXcoder is a unified cross-modal pre-trained model which incorporates code\
    \ semantic and syntax information from AST. It is pre-trained with two new pre-training\
    \ tasks multi-modal contrastive learning and cross-modal generation to learn code\
    \ fragment representation. These models are all pretrained on CodeSearchNet [\\\
    [31\\]](#page-11-8) and CodeT5 is also pre-trained with C/CSharp code snippets\
    \ from BigQuery [\\[4\\]](#page-11-30).\n\n### 3.4 Implementation Details\n\n\
    We reproduce the results of all pre-trained models based on the official repositories\
    \ released by the model authors. In order to facilitate a fair comparison, we\
    \ ensure that the hyperparameters\n\nsuch as training epochs and learning rates\
    \ for the models with and without HINT are exactly the same. In our experiments,\
    \ we set and to 0.5 and 0.4, respectively. The maximum iteration is set to five.\
    \ To determine the percentage of selected samples, we tune the threshold in 10,\
    \ 15, 20, 25, 30, or 35 and select the best results for different datasets. Our\
    \ rationale for hyperparameter selection is discussed in Section [4.3.](#page-7-0)\
    \ When applying our pseudo-labeled data selection methods to the classification\
    \ task, we conduct Algorithm [1](#page-3-1) for each class respectively and balance\
    \ the class distribution by random down-sampling [\\[5\\]](#page-11-31). All the\
    \ experiments are conducted on an Ubuntu 20.04 server with an Intel Xeon Platinum\
    \ 8276 CPU, and 4 Nvidia Tesla A100 GPUs which have 40 GB graphic memory.\n\n\
    ### 4 EXPERIMENTAL RESULTS\n\n### 4.1 RQ1: Performance Evaluation\n\nIn this section,\
    \ we evaluate the effectiveness of HINT on three code intelligence tasks including\
    \ code summarization, defect detection, and assertion generation. We present the\
    \ results of HINT on the first iteration and the best results of HINT on all the\
    \ five iterations, namely HINT(1) and HINT(5). The results are displayed in Table\
    \ [1-](#page-5-0)[3.](#page-6-0) HINT consistently improves three pre-train code\
    \ models on all the tasks and metrics. In particular, HINT achieves 15.33%, 16.50%,\
    \ and 8.98% improvements in BLEU-4, F1, and EM over the best pretrained model\
    \ UniXcoder on the three datasets, respectively. We detail the results on each\
    \ task respectively as below.\n\nCode Summarization. As shown in Table [1,](#page-5-0)\
    \ HINT can significantly improve the performance of different existing pre-trained\
    \ code models on all datasets and metrics even with only one iteration. For example,\
    \ HINT(1) improves the BLEU-4 score of CodeT5 by 9.90% and 5.68% on two datasets,\
    \ respectively. Meanwhile, compared with the most powerful pre-trained model UniXcoder,\
    \ HINT(1) can still achieve consistent improvement, e.g., improving UniXcoder\
    \ on JCSD dataset by 10.14%, 12.04%, 7.99%, and 15.32% with respect to BLEU-4,\
    \ METEOR, ROUGE-L, and CIDEr, respectively. This indicates that HINT is effective\
    \ in leveraging the unlabeled data and benefits the strong task-agnostic pre-trained\
    \ code models in the downstream tasks.\n\nDefect Detection. Table [2](#page-6-1)\
    \ presents the results of defect detection. We can observe consistent improvement\
    \ on overall performance as in the defect detection task: HINT(5) improves the\
    \ F1 of\n\n<span id=\"page-6-1\"></span>Table 2: Experimental results on defect\
    \ detection. Statistical significance is not applicable to these metrics [\\[10\\\
    ]](#page-11-32).\n\n| Approach  |            | Precision | Recall | F1    |  |\n\
    |-----------|------------|-----------|--------|-------|--|\n|           | Base\
    \ model | 29.64     | 17.63  | 22.11 |  |\n| CodeBERT  | +HINT(1)   | 30.81  \
    \   | 21.52  | 25.34 |  |\n|           | +HINT(5)   | 32.09     | 22.36  | 26.35\
    \ |  |\n|           | Base model | 31.38     | 20.32  | 24.66 |  |\n| CodeT5 \
    \   | +HINT(1)   | 36.79     | 22.36  | 27.81 |  |\n|           | +HINT(5)   |\
    \ 37.66     | 22.36  | 28.06 |  |\n|           | Base model | 31.30     | 17.63\
    \  | 22.55 |  |\n| UniXcoder | +HINT(1)   | 33.28     | 20.96  | 25.73 |  |\n\
    |           | +HINT(5)   | 32.04     | 22.26  | 26.27 |  |\n\n<span id=\"page-6-0\"\
    ></span>Table 3: Experimental results on assertion generation. \"\\*\" denotes\
    \ statistical significance in comparison to the base models (i.e., two-sided -test\
    \ with -value< 0.01).\n\n| Approach  |            | EM     | LCS    | ED     |\n\
    |-----------|------------|--------|--------|--------|\n|           | Base model\
    \ | 31.82  | 65.99  | 21.68  |\n| CodeBERT  | +HINT(1)   | 37.75* | 69.46* | 19.05*\
    \ |\n|           | +HINT(5)   | 38.58* | 69.48* | 19.20* |\n|           | Base\
    \ model | 43.64  | 72.56  | 20.30  |\n| CodeT5    | +HINT(1)   | 46.53* | 74.32*\
    \ | 18.47* |\n|           | +HINT(5)   | 47.66* | 75.22* | 18.17* |\n|       \
    \    | Base model | 43.64  | 72.67  | 17.82  |\n| UniXcoder | +HINT(1)   | 47.13*\
    \ | 74.72* | 16.61* |\n|           | +HINT(5)   | 47.56* | 74.76* | 16.21* |\n\
    \nthree pre-trained models by 19.18%, 13.79%, and 16.50%, respectively. This indicates\
    \ that HINT can help pre-trained models to capture the patterns of vulnerable\
    \ code snippets. Besides, by comparing the results of HINT(1) and HINT(5), we\
    \ can also observe that after multiple iterations, HINT can achieve better performance,\
    \ e.g., improving HINT(1) by 2.10% F1 in average on UniXcoder.\n\nAssertion Generation.\
    \ For assertion generation, as shown in Table [3,](#page-6-0) we can observe that\
    \ HINT can improve all baseline pretrained models by a large margin. On average,\
    \ HINT(1) and HINT(5) improve the EM of these models by 11.09% and 13.14%, respectively.\
    \ Specifically, on CodeBERT, HINT(5) improves its baseline by 21.24%, 5.29%, and\
    \ 11.44% in terms of EM, LCS, and ED, respectively. This indicates that the ability\
    \ to better utilize the unlabeled data of HINT is also beneficial to generate\
    \ accurate assertion statements.\n\nAnswer to RQ1: HINT consistently improves\
    \ three pre-trained code models on all tasks and metrics, indicating its effectiveness\
    \ in leveraging unlabeled data for the pre-trained code models.\n\n### 4.2 RQ2:\
    \ Ablation Study\n\nIn this section, we explore the contribution of the hybrid\
    \ pseudolabeled data selection and the noise-tolerant training modules proposed\
    \ in HINT. We use UniXcoder as the base model since it shows the best performance\
    \ in the first research question. Besides, considering the time and resource limitation\
    \ of multiple iterations, we use HINT with one iteration for the following experiments.\
    \ Due to the\n\npage limit, we only present the results on Java in this paper\
    \ for code summarization, with results for other languages and pre-trained models\
    \ presented on our GitHub repository [\\[26\\]](#page-11-21).\n\n4.2.1 Impact\
    \ of hybrid pseudo-labeled data selection. We compare HINT with four other data\
    \ selection methods including Random selection, HINT w/o retrieval-based selection,\
    \ HINT w/o loss-based selection, and HINT w/o data selection. In HINT w/o loss-based\
    \ selection and HINT w/o retrieval-based selection, we validate the effectiveness\
    \ of two methods in hybrid pseudo-labeled data selection respectively. In HINT\
    \ w/o data selection, we remove the whole data selection process and directly\
    \ use all the generated pseudolabeled data, which aims at verifying the benefit\
    \ of data selection. In Random selection, we randomly select a subset from pseudo-labeled\
    \ data that has the same size as the subset selected by HINT. This is usually\
    \ used in controlled experiments to eliminate the potential confounding effect\
    \ of dataset size [\\[57\\]](#page-12-4). The experimental results are presented\
    \ in Table [4.](#page-7-1)\n\nLoss-based selection. We conduct this experiment\
    \ by removing the loss-based selection (Line 4-5, 13-14 in Algorithm [1\\)](#page-3-1).\
    \ From Table [4,](#page-7-1) we can observe that, without loss-based selection,\
    \ the performance of HINT decreases consistently on all the tasks. Specifically,\
    \ removing this component leads to an obvious decrease in defect detection, with\
    \ the decrease at 19.26%, 11.02%, and 14.42% regarding Precision, Recall, and\
    \ F1, respectively. This demonstrates the benefits of removing the noisy data\
    \ by the training loss.\n\nRetrieval-based selection. We conduct this experiment\
    \ by removing the retrieval-based selection (Line 9-11 in Algorithm [1\\)](#page-3-1).\
    \ As can be seen in Table [4,](#page-7-1) excluding the retrieval-based selection\
    \ process leads to a consistent drop in all tasks and metrics. The results demonstrate\
    \ the effectiveness of involving the retrievalbased strategy for data selection.\n\
    \nData selection and Random selection. As shown in Table [4,](#page-7-1) the model\
    \ suffers from a large degradation after removing the data selection procedure.\
    \ Specifically, on defect detection, the F1 of using all pseudo-labeled data is\
    \ only 22.29, much lower than the results of our method, i.e., 25.73. The performance\
    \ of random selection is even worse. For example, on assertion generation, random\
    \ selection has a decrease of 3.95%, 1.43%, and 2.95% with respect to EM, LCS,\
    \ and ED, respectively, indicating the importance of the data selection process\
    \ in HINT. This also demonstrates that directly using pseudo-labeling cannot achieve\
    \ promising results on code intelligence tasks.\n\n4.2.2 Impact of noise-tolerant\
    \ training. In this section, we validate the effectiveness of two components of\
    \ the noise-tolerant training module, i.e., noise-tolerant loss function and consistency\
    \ regularization.\n\nNoise-tolerant loss function. We conduct this experiment\
    \ by removing the noise tolerant loss in Equation [4,](#page-4-1) i.e., directly\
    \ using the cross entropy loss. From Table [4,](#page-7-1) we can observe that\
    \ removing the noise-tolerant loss results in a performance decrease in the vast\
    \ majority of cases. For example, on defect detection, HINT without the noise-tolerant\
    \ loss suffers from a decrease of 4.47% in terms of F1. This shows the importance\
    \ of using noise-tolerant loss to mitigate the negative impact of errors in pseudo\
    \ labels on the model performance.\n\nConsistency regularization. We conduct this\
    \ experiment by removing the noise tolerant loss in Equation [4,](#page-4-1) i.e.,\
    \ only use the first\n\n<span id=\"page-7-1\"></span>\n\n| Approach          \
    \              | Code Summarization |         |        |       | Defect Detection\
    \ |        |       | Assertion Generation |       |       |\n|---------------------------------|--------------------|---------|--------|-------|------------------|--------|-------|----------------------|-------|-------|\n\
    |                                 | BLEU-4             | ROUGE-L | METEOR | CIDEr\
    \ | Precision        | Recall | F1    | EM                   | LCS   | ED    |\n\
    | UniXcoder+HINT                  | 18.90              | 35.16   | 12.38  | 1.28\
    \  | 33.28            | 20.96  | 25.73 | 47.13                | 74.72 | 16.61\
    \ |\n| Random selection                | 18.34              | 34.11   | 11.70\
    \  | 1.23  | 34.39            | 16.14  | 21.97 | 45.27                | 73.65\
    \ | 17.10 |\n| -w/o loss-based selection       | 18.54              | 34.09  \
    \ | 12.34  | 1.24  | 26.87            | 18.65  | 22.02 | 45.55               \
    \ | 73.96 | 17.10 |\n| -w/o retrieval-based selection  | 18.71              |\
    \ 34.91   | 12.21  | 1.26  | 32.33            | 19.94  | 24.67 | 45.03       \
    \         | 73.50 | 17.16 |\n| -w/o data selection             | 18.27       \
    \       | 34.44   | 12.03  | 1.21  | 34.71            | 16.42  | 22.29 | 47.03\
    \                | 74.64 | 16.65 |\n| -w/o noise tolerant loss        | 18.93\
    \              | 34.96   | 12.26  | 1.29  | 33.02            | 19.57  | 24.58\
    \ | 46.64                | 74.46 | 16.56 |\n| -w/o consistency regularization\
    \ | 18.78              | 35.03   | 12.40  | 1.27  | 33.82            | 19.29 \
    \ | 24.57 | 46.81                | 74.55 | 16.70 |\n\nTable 4: Ablation study\
    \ of HINT. Best and second best results are marked in bold and underline respectively.\n\
    \n<span id=\"page-7-2\"></span>Table 5: Experimental results on cross-domain scenario.\
    \ \"\\*\" denotes statistical significance in comparison to the base models (i.e.,\
    \ two-sided -test with -value< 0.01).\n\n|                |        | Python →\
    \ Java |        |       | Java → Python |         |        |       |\n|----------------|--------|---------------|--------|-------|---------------|---------|--------|-------|\n\
    | Approach       | BLEU-4 | ROUGE-L       | METEOR | CIDEr | BLEU-4        | ROUGE-L\
    \ | METEOR | CIDEr |\n| CodeBERT       | 9.98   | 20.01         | 4.99   | 0.21\
    \  | 12.65         | 22.35   | 7.02   | 0.25  |\n| CodeBERT+HINT  | 13.82* | 27.71*\
    \        | 8.10*  | 0.60* | 16.14*        | 30.33*  | 9.89*  | 0.58* |\n| CodeT5\
    \         | 7.75   | 12.55         | 7.12   | 0.29  | 14.81         | 30.59  \
    \ | 9.66   | 0.84  |\n| CodeT5+HINT    | 14.09* | 22.51*        | 9.28*  | 0.88*\
    \ | 16.85*        | 33.70*  | 10.77* | 1.07* |\n| UniXcoder      | 12.68  | 26.03\
    \         | 8.33   | 0.66  | 13.18         | 20.94   | 10.70  | 0.64  |\n| UniXcoder+HINT\
    \ | 16.33* | 32.22*        | 10.54* | 1.03* | 17.26*        | 28.28*  | 13.14*\
    \ | 0.97* |\n\nterm in Equation [4.](#page-4-1) As can be seen in Table [4,](#page-7-1)\
    \ removing the adaptive regularization also leads to a drop in most tasks and\
    \ metrics. Specifically, removing consistency regularization leads to a decrease\
    \ of 0.63%, 4.51%, and 0.68% on three tasks regarding BLEU-4, F1, and EM, respectively,\
    \ indicating the effectiveness of providing reliable training objectives for leveraging\
    \ the pseudo-labeled data.\n\nAnswer to RQ2: All components in hybrid pseudo-labeled\
    \ data selection module and noise-tolerant training module demonstrate a positive\
    \ effect on the performance of HINT.\n\n### <span id=\"page-7-0\"></span>4.3 RQ3:\
    \ Evaluation on Cross-domain Scenario\n\nIn some programming languages, there\
    \ is often a shortage of training data. For the data-limited scenarios, transfer\
    \ learning is a popular solution which transfers the knowledge of similar domains\
    \ with sufficient data to the target domains [\\[42,](#page-11-33) [62\\]](#page-12-25).\
    \ In this section, we conduct experiments to study the effectiveness of HINT in\
    \ crossdomain scenarios, in which the model is trained on the source domain and\
    \ tested on the target domain with a different programming language. We use the\
    \ code summarization task for evaluation as it contains two kinds of programming\
    \ language. Specifically, we first train a model on the Java/Python dataset as\
    \ the source domain and then evaluate its performance on the test set of the other\
    \ (Python/Java) dataset as the target domain. As shown in Table [5,](#page-7-2)\
    \ HINT can improve the performance of pre-trained code models in the cross-domain\
    \ scenario by a large margin. Specifically, HINT improves the BLEU-4 score of\
    \ UniXcoder by 28.79% and 30.96% on Java to Python and Python to Java, respectively,\
    \ indicating that HINT can effectively utilize the knowledge in those unlabeled\
    \ data\n\n<span id=\"page-7-3\"></span>![](_page_7_Figure_8.jpeg)\n\nFigure 4:\
    \ Parameter analysis on threshold .\n\nby pseudo-labeling. This also shows HINT's\
    \ ability to enhance pretrained code models in new programming languages, regardless\
    \ of any disparities in their data distributions.\n\nAnswer to RQ3: HINT can substantially\
    \ boost the performance of pre-trained code models in cross-domain scenarios where\
    \ no annotated data exist in the target domain.\n\ncoder).\n\n<span id=\"page-8-0\"\
    ></span>![](_page_8_Figure_0.jpeg)\n\nFigure 6: Performance on each Iteration.\n\
    \n### 4.4 RQ4: Parameter Analysis\n\nIn this section, we study the impact of four\
    \ parameters on the performance of HINT, including the threshold in loss-based\
    \ data selection, the edit distance threshold in retrieval-based data selection,\
    \ the weight of consistency regularization , and the iteration number . Due to\
    \ the page limitation, we only present the results of UniXcoder and JCSD dataset\
    \ for and on code summarization, with results for other languages and pre-trained\
    \ models presented on our GitHub repository [\\[26\\]](#page-11-21).\n\nThe threshold\
    \ in loss-based data selection. We conduct experiments to evaluate how HINT performs\
    \ under different thresholds, i.e., 10%, 15%, 20%, 25%, 30%, and 35%. The larger\
    \ the is set to, the more the pseudo labeled samples will be selected. As shown\
    \ in Figure [4,](#page-7-3) the model performance shows a similar trend along\
    \ with the increase of on all pre-trained code models and tasks. HINT first increases\
    \ and achieves its peak, and then sharply descends with a larger . Larger has\
    \ the risk of involving more noisy data while smaller might be too strict and\
    \ filter many high-quality samples. Besides, we can find that the optimal value\
    \ of for different models and tasks varies a lot. For example, on code summarization,\n\
    \n0 0.25 0.5 0.75 1 0 0.25 0.5 0.75 1 UniXcoder achieves the best performance\
    \ when is set to 25%, while the optimal value for CodeBERT is 10%. We suggest\
    \ that it is because the capability of the base model on each task is different.\
    \ Specifically, the performance of UniXcoder on code summarization is very strong,\
    \ i.e. achieving 17.16 BLEU-4 on the Java dataset, while for CodeBERT, its performance\
    \ on the Java dataset is only 13.30. The poorer the performance of the based model\
    \ is, the lower the quality of pseudo-labeled data is. Therefore, when applying\
    \ HINT on different pre-trained code models, a relatively larger can be used on\
    \ a stronger base model and vice versa.\n\n<span id=\"page-8-1\"></span>0 0.25\
    \ 0.5 0.75 1 (a) Analysis of the parameter t(b) Analysis of the parameter μ The\
    \ edit distance threshold . We study the effect of , as introduced in Section\
    \ [2.3,](#page-3-0) by varying it from 0.2 to 0.5. As shown in Figure [5](#page-8-0)\
    \ (a), for both defect detection and assertion generation, HINT achieves the best\
    \ performance when is set to 0.4. Larger or lower values do not give better results.\
    \ On code summarization, setting to 0.5 only performs slightly better than 0.4.\
    \ This indicates that setting to 0.4 is more appropriate for HINT. Thus, we set\
    \ to 0.4 in this work.\n\n 0 1 2 3 4 5 6 The consistency regularization weight\
    \ . To study the impact of in HINT, we vary it from 0 to 1 and show the results\
    \ in Figure [5](#page-8-0) (b). Larger tends to give a stronger regularization\
    \ to the model. For both defect detection and assertion generation, HINT achieves\
    \ the best performance when is set to 0.5. However, on code summarization, increasing\
    \ leads to a decrease in performance. Therefore, we set to 0.5 to enable HINT\
    \ to produce relatively better results on different tasks.\n\n0 1 2 3 4 5 6 The\
    \ iteration number . We evaluate the performance of HINT on different iterations\
    \ by setting the maximum iteration to six, and present the results in Figure [6.](#page-8-1)\
    \ Iteration 0 represents the baseline results that do not use HINT. From the results,\
    \ we can observe that HINT can get better results with the growth of iterations\
    \ and achieves the peak at around the fifth iteration, indicating that HINT can\
    \ achieve self-improvement by leveraging the unlabeled data.\n\n> Answer to RQ4:\
    \ Different settings of hyperparameters can influence the performance of HINT\
    \ on different tasks. Our hyperparameter settings achieve relatively better results.\n\
    \n### 5 DISCUSSION\n\n### 5.1 What Makes HINT Work?\n\n5.1.1 HINT can better utilize\
    \ the unlabeled data for downstream tasks. To better understand how pseudo-labeling\
    \ benefits pre-trained code models, we give two examples in Figure [7](#page-9-0)\
    \ and Figure [8.](#page-9-1) The case in Figure [7](#page-9-0) shows a Java code\
    \ snippet with summaries generated by UniXcoder and UniXcoder+HINT. From the example,\
    \ we can see that the summary generated by UniXcoder only contains a simple description\
    \ without a detailed introduction to the parameters. HINT can avoid this problem\
    \ and give a more precise prediction since it can learn from more ⟨unlabeled data,\
    \ pseudo label⟩ pairs that have a similar summary pattern. We also present another\
    \ case in the assertion generation task in Figure [8.](#page-9-1) The assertion\
    \ statement generated by UniXcoder mistakenly predicts the assertion type as \"\
    assertionTrue\" since it does not learn the meaning of \"empty\" well. However,\
    \ since UniXcoder+HINT uses the code snippet in Figure [8](#page-9-1) as training\
    \ data which has the same assertion\n\ntypes as this test sample, it can correctly\
    \ predict the assertion type in Figure [8.](#page-9-1)\n\n5.1.2 HINT can select\
    \ pseudo-labeled data with higher quality. Another advantage of HINT comes from\
    \ our data selection process. HINT can select high-quality pseudo labels for model\
    \ training. As shown in Figure [1](#page-1-0) and [2,](#page-2-0) HINT identifies\
    \ low-quality pseudo-labeled data by employing both the implicit loss-based selection\
    \ and explicit retrieval-based selection. To further validate this, we calculate\
    \ the edit distance of the pseudo labels generated by UniXcoder to the ground\
    \ truth labels of the unlabeled dataset, and use the average distance on the whole\
    \ selected dataset to measure the quality of our selected dataset. Specifically,\
    \ on JCSD the average edit distance of all pseudo labels without filtering is\
    \ 53.70, which is much higher than the dataset selected by HINT, i.e., 37.16.\
    \ The results on assertion generation are the same. HINT achieves an average edit\
    \ distance of 5.34 while the average edit distance of all pseudo labels is 17.86.\
    \ This further shows that HINT can filter noisy data and select pseudo-labeled\
    \ data with higher quality for model training.\n\n### 5.2 Limitation of HINT\n\
    \nTo gain a deeper understanding of HINT's behavior and limitations, we further\
    \ investigate cases where HINT fails to make accurate predictions and conclude\
    \ two possible limitations of HINT.\n\nThe first limitation pertains to HINT's\
    \ inability to introduce additional knowledge and rectify factual knowledge errors.\
    \ From the example in the above Figure [9,](#page-10-3) UniXcoder misinterprets\
    \ the term \"bucket\\_acl\" as the name of a bucket and fails to rectify this\
    \ misunderstanding even after additional training on pseudo-labeled data. This\
    \ shows that without external feedback HINT is hard to identify and rectify the\
    \ problem on factual knowledge, which also aligns with recent findings on the\
    \ limited self-correction ability of large language models [\\[29\\]](#page-11-34).\
    \ To potentially alleviate this limitation, integrating factual knowledge into\
    \ pre-trained code models via the interaction with a knowledge base or search\
    \ engine could be further studied.\n\nThe second limitation of HINT is the reliance\
    \ on the capacity of the base model. HINT aims at autonomously synthesizing more\
    \ labeled data for model training. However, when the base model lacks sufficient\
    \ capacity, the benefits of additional training data are diminished. As depicted\
    \ in the Figure [10,](#page-10-4) despite the presence of training sample in the\
    \ pseudo-labeled data illustrating the usage of \"assertEquals\", UniXcoder still\
    \ fails to learn this and erroneously generates \"assertThat\" for the given function.\
    \ We attribute this limitation to the inherent constraints of the model's capacity\
    \ and believe that it could be mitigated by using more advanced pretrained code\
    \ models.\n\n# 5.3 Threats to Validity\n\nWe identify four main threats to validity\
    \ of our study:\n\n- (1) The selection of code intelligence tasks. We evaluate\
    \ HINT on three commonly-used code intelligence tasks: code summarization, defect\
    \ detection, and assertion generation. We aim to expand the validation of HINT\
    \ in the future by testing it on more code intelligence tasks.\n- (2) The selection\
    \ of pre-trained code models. In this paper, we select three popular open-source\
    \ pre-trained code\n\n<span id=\"page-9-0\"></span>![](_page_9_Figure_10.jpeg)\n\
    \nFigure 7: Case study on the code summarization task. The green texts highlight\
    \ the similar part between the prediction of UniXcoder+HINT and pseudo-labeled\
    \ summary.\n\n<span id=\"page-9-1\"></span>![](_page_9_Figure_12.jpeg)\n\nFigure\
    \ 8: Case study on the assertion generation task. The red and green texts highlight\
    \ the difference in predictions made by UniXcoder and UniXcoder+HINT.\n\nmodels\
    \ CodeBERT, CodeT5, and UniXcoder for evaluation. These models are all representative\
    \ and have shown state-ofthe-art performance on benchmarks [\\[20,](#page-11-6)\
    \ [65\\]](#page-12-12). Recent studies propose pre-trained models with much larger\
    \ sizes such as ChatGPT [\\[6\\]](#page-11-35) and GPT-4 [\\[52\\]](#page-12-26)\
    \ which also show impressive programming ability. However, since the weight of\
    \ these models is not publicly available, we cannot evaluate our framework on\
    \ those large language models. Besides, our framework is flexible and easy to\
    \ be applied to different pre-trained code models.\n\n(3) The selection of languages.\
    \ The datasets that we choose in experiments only contain two kinds of languages,\
    \ i.e., Java and Python. They are both popular languages. Additionally, our method\
    \ is language-agnostic and can be easily adapted to other programming languages.\n\
    \n```\n# Code from the test set:\ndef print_bucket_acl_for_user(bucket_name, user_email):\n\
    \ storage_client = storage.Client()\n bucket = storage_client.bucket(bucket_name)\n\
    \ bucket.acl.reload()\n roles = bucket.acl.user(user_email).get_roles()\n print\
    \ roles\nSummary generated by Unixcoder:\nprint the current users name for the\
    \ specified user.\nSummary generated by Unixcoder+HINT:\nprints the name for the\
    \ specified bucket and user.\nGround truth summary:\n```\nprints out a buckets\
    \ access control list for a given user.\n\nFigure 9: Error case on the code summarization\
    \ task.\n\n<span id=\"page-10-4\"></span>\n\n| Focal-test<br>from<br>test<br>set:<br>testIdAccessor(){<br>java.lang.Long<br>id<br>=<br>3L;<br>instance.setId(id);<br>\"\
    <AssertPlaceHolder>\";}<br>getId(){<br>return<br>id;<br>}                    \
    \  |  |\n|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--|\n\
    | Assertion<br>generated<br>by<br>Unixcoder+HINT:<br>org.junit.Assert.assertThat(id,<br>instance.getId());<br>Ground<br>truth<br>assertion:<br>org.junit.Assert.assertEquals(id,<br>instance.getId());\
    \ |  |\n| Focal-test<br>from<br>Unlable<br>dataset:<br>testGetName(){<br>java.lang.String<br>id<br>=<br>\"\
    id\";<br>togglePanelItem.setId(id);<br>\"<AssertPlaceHolder>\";}<br>getId(){<br>return<br>id;<br>}\
    \       |  |\n| Generated<br>pseudo<br>label:<br>org.junit.Assert.assertEquals(id,<br>togglePanelItem.getId());\
    \                                                                            \
    \                          |  |\n\n#### Figure 10: Error case on the assertion\
    \ generation task.\n\n(4) The limitation of selected metrics. We evaluate HINT\
    \ using a variety of commonly used metrics for different tasks. However, these\
    \ metrics are mainly used for evaluating accuracy and may not reflect other evaluation\
    \ aspects such as the diversity of generated code summaries. In the future, we\
    \ plan to conduct human studies to provide a more comprehensive evaluation.\n\n\
    ### 6 RELATED WORK\n\n### 6.1 Code Intelligence\n\nIn this section, we introduce\
    \ related neural code models in three tasks that are covered in our work, including\
    \ both non-pre-trained code models and pre-trained code models,\n\n6.1.1 Non-pre-trained\
    \ code models. Iyer et al. [\\[32\\]](#page-11-36) formulate code summarization\
    \ as a neural machine translation (NMT) problem and propose CODE-NN to translate\
    \ code snippets to code summaries. For better utilizing code structure information,\
    \ many works [\\[15,](#page-11-37) [39\\]](#page-11-38) in code summarization\
    \ also incorporate code-related graphs and GNN to boost performance. Recent studies\
    \ [\\[59,](#page-12-27) [70\\]](#page-12-28) further incorporate various code\
    \ structure information into the Transformer model and achieve promising performance.\
    \ As for vulnerability detection, many deep learning-based methods [\\[41,](#page-11-29)\
    \ [75\\]](#page-12-20) are proposed. For example, Devign [\\[75\\]](#page-12-20)\
    \ is proposed to learn the various vulnerability characteristics with a composite\
    \ code property graph and graph neural network. IVDetect [\\[41\\]](#page-11-29)\
    \ uses the program dependency graph and feature attention GCN to detect vulnerabilities\
    \ in the code. In assertion generation, recent studies adopt the T5 transformer\n\
    \nmodel and achieve promising results [\\[45,](#page-12-29) [46\\]](#page-12-21).\
    \ Yu et al. [\\[73\\]](#page-12-22) further involve information retrieval to generate\
    \ more accurate assertion statements.\n\n6.1.2 Pre-trained code models. Recently,\
    \ a series of pre-trained code models [\\[14,](#page-11-3) [21,](#page-11-4) [65\\\
    ]](#page-12-12) are proposed and achieve state-of-theart performance on various\
    \ code intelligence tasks such as code summarization and defect detection. CodeBERT\
    \ [\\[14\\]](#page-11-3) is a pioneer work that is pre-trained with six programming\
    \ languages and uses Masked Language Modeling and Replace Token Detection as pretrained\
    \ tasks. CodeT5 [\\[65\\]](#page-12-12) is a sequence-to-sequence pre-trained\
    \ model which involves two code-related pre-training objectives: identifier tagging\
    \ and masked identifier prediction. UniXcoder [\\[20\\]](#page-11-6) is a unified\
    \ cross-modal pre-trained model which incorporates code semantic and syntax information\
    \ from AST.\n\n### 6.2 Pseudo-labeling\n\nPseudo-labeling is one of the most widely-used\
    \ semi-supervised learning methods. It has been applied to different kinds of\
    \ tasks such as image classification [\\[40,](#page-11-11) [71\\]](#page-12-30),\
    \ machine translation [\\[24,](#page-11-39) [34\\]](#page-11-10), and dialog systems\
    \ [\\[48\\]](#page-12-7). To further boost the performance of selftraining in\
    \ sequence generation tasks, He et al. [\\[24\\]](#page-11-39) and Mi et al. [\\\
    [48\\]](#page-12-7) explore the data augmentation technique and use random noise\
    \ or gradient-based data augmentation to improve the generalization of the student\
    \ model. Another line of work [\\[8,](#page-11-40) [34,](#page-11-10) [67\\]](#page-12-31)\
    \ focus on the data selection procedure and propose to select highquality pseudo\
    \ labeled data based on the uncertainty or the model confidence, respectively.\
    \ However, these methods mainly filter the pseudo-labeled data only with training\
    \ loss and do not take the noisy data problem into consideration. Different from\
    \ them, we propose a hybrid data selection method with the training loss and a\
    \ retrieval-based method based on the code reuse. Additionally, we also propose\
    \ a noise-tolerant training module to further mitigate the influence of noise\
    \ on model performance.\n\n### 7 CONCLUSION\n\nIn this paper, we investigate leveraging\
    \ large-scale unlabeled datasets for effectively tuning pre-trained code models\
    \ by pseudo-labeling. We propose a method called HINT which consists of two main\
    \ components, the hybrid pseudo-labeled data selection module and the noise-tolerant\
    \ training module. Extensive experiments on three code intelligence tasks show\
    \ that HINT can be built on a variety of pre-trained models and provide complementary\
    \ benefits for them. Our replication package including our source code, experimental\
    \ data, and detailed experiment results is at [\\[26\\]](#page-11-21).\n\n###\
    \ REFERENCES\n\n- <span id=\"page-10-0\"></span>[1] Wasi Uddin Ahmad, Saikat Chakraborty,\
    \ Baishakhi Ray, and Kai-Wei Chang. 2020. A Transformer-based Approach for Source\
    \ Code Summarization. In Proceedings of the 58th Annual Meeting of the Association\
    \ for Computational Linguistics, ACL 2020. Association for Computational Linguistics,\
    \ 4998–5007.\n- <span id=\"page-10-2\"></span>[2] Satanjeev Banerjee and Alon\
    \ Lavie. 2005. METEOR: An Automatic Metric for MT Evaluation with Improved Correlation\
    \ with Human Judgments. In Proceedings of the Workshop on Intrinsic and Extrinsic\
    \ Evaluation Measures for Machine Translation and/or Summarization@ACL 2005, Ann\
    \ Arbor, Michigan, USA, June 29, 2005. Association for Computational Linguistics,\
    \ 65–72.\n- <span id=\"page-10-1\"></span>[3] Antonio Valerio Miceli Barone and\
    \ Rico Sennrich. 2017. A parallel corpus of Python functions and documentation\
    \ strings for automated code documentation and code generation. arXiv preprint\
    \ arXiv:1707.02275 (2017).\n- <span id=\"page-11-30\"></span>[4] BigQuery. 2022.\
    \ BigQuery. [https://console.cloud.google.com/marketplace/details/](https://console.cloud.google.com/marketplace/details/github/github-repos)\
    \ [github/github-repos.](https://console.cloud.google.com/marketplace/details/github/github-repos)\n\
    - <span id=\"page-11-31\"></span>[5] Christopher M Bishop and Nasser M Nasrabadi.\
    \ 2006. Pattern recognition and machine learning. Vol. 4. Springer.\n- <span id=\"\
    page-11-35\"></span>[6] ChatGPT. 2022. ChatGPT. [https://openai.com/blog/chatgpt.](https://openai.com/blog/chatgpt)\n\
    - <span id=\"page-11-22\"></span>[7] Jie-Cherng Chen and Sun-Jen Huang. 2009.\
    \ An empirical analysis of the impact of software development problem factors\
    \ on software maintainability. J. Syst. Softw. 82, 6 (2009), 981–992.\n- <span\
    \ id=\"page-11-40\"></span>[8] Yiming Chen, Yan Zhang, Chen Zhang, Grandee Lee,\
    \ Ran Cheng, and Haizhou Li. 2021. Revisiting Self-training for Few-shot Learning\
    \ of Language Model. In Proceedings of the 2021 Conference on Empirical Methods\
    \ in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican\
    \ Republic, 7-11 November, 2021. Association for Computational Linguistics, 9125–9135.\n\
    - <span id=\"page-11-0\"></span>[9] Matteo Ciniselli, Luca Pascarella, Emad Aghajani,\
    \ Simone Scalabrino, Rocco Oliveto, and Gabriele Bavota. 2023. Source Code Recommender\
    \ Systems: The Practitioners' Perspective. In 45th IEEE/ACM International Conference\
    \ on Software Engineering, ICSE 2023, Melbourne, Australia, May 14-20, 2023. IEEE,\
    \ 2161–2172.\n- <span id=\"page-11-32\"></span>[10] William Jay Conover. 1999.\
    \ Practical nonparametric statistics. Vol. 350. john wiley & sons.\n- <span id=\"\
    page-11-9\"></span>[11] Roland Croft, Muhammad Ali Babar, and M. Mehdi Kholoosi.\
    \ 2023. Data Quality for Software Vulnerability Datasets. In 45th IEEE/ACM International\
    \ Conference on Software Engineering, ICSE 2023, Melbourne, Australia, May 14-20,\
    \ 2023. IEEE, 121–133.\n- <span id=\"page-11-2\"></span>[12] Jacob Devlin, Ming-Wei\
    \ Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep\
    \ Bidirectional Transformers for Language Understanding. In Proceedings of the\
    \ 2019 Conference of the North American Chapter of the Association for Computational\
    \ Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA,\
    \ June 2-7, 2019, Volume 1 (Long and Short Papers). Association for Computational\
    \ Linguistics, 4171–4186.\n- <span id=\"page-11-28\"></span>[13] Jiahao Fan, Yi\
    \ Li, Shaohua Wang, and Tien N. Nguyen. 2020. A C/C++ Code Vulnerability Dataset\
    \ with Code Changes and CVE Summaries. In MSR '20: 17th International Conference\
    \ on Mining Software Repositories, Seoul, Republic of Korea, 29-30 June, 2020.\
    \ ACM, 508–512.\n- <span id=\"page-11-3\"></span>[14] Zhangyin Feng, Daya Guo,\
    \ Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting\
    \ Liu, Daxin Jiang, and Ming Zhou. 2020. CodeBERT: A Pre-Trained Model for Programming\
    \ and Natural Languages. In Findings of the Association for Computational Linguistics:\
    \ EMNLP 2020 (Findings of ACL, Vol. EMNLP 2020). Association for Computational\
    \ Linguistics, 1536–1547.\n- <span id=\"page-11-37\"></span>[15] Patrick Fernandes,\
    \ Miltiadis Allamanis, and Marc Brockschmidt. 2019. Structured Neural Summarization.\
    \ In 7th International Conference on Learning Representations, ICLR 2019, New\
    \ Orleans, LA, USA, May 6-9, 2019. OpenReview.net.\n- <span id=\"page-11-26\"\
    ></span>[16] Shuzheng Gao, Cuiyun Gao, Yulan He, Jichuan Zeng, Lunyiu Nie, Xin\
    \ Xia, and Michael R. Lyu. 2023. Code Structure-Guided Transformer for Source\
    \ Code Summarization. ACM Trans. Softw. Eng. Methodol. 32, 1 (2023), 23:1–23:32.\n\
    - <span id=\"page-11-5\"></span>[17] Shuzheng Gao, Xin-Cheng Wen, Cuiyun Gao,\
    \ Wenxuan Wang, Hongyu Zhang, and Michael R. Lyu. 2023. What Makes Good In-Context\
    \ Demonstrations for Code Intelligence Tasks with LLMs?. In 38th IEEE/ACM International\
    \ Conference on Automated Software Engineering, ASE 2023, Luxembourg, September\
    \ 11-15, 2023. IEEE, 761–773.\n- <span id=\"page-11-12\"></span>[18] Shuzheng\
    \ Gao, Hongyu Zhang, Cuiyun Gao, and Chaozheng Wang. 2023. Keeping Pace with Ever-Increasing\
    \ Data: Towards Continual Learning of Code Intelligence Models. In 45th IEEE/ACM\
    \ International Conference on Software Engineering, ICSE 2023, Melbourne, Australia,\
    \ May 14-20, 2023. IEEE, 30–42.\n- <span id=\"page-11-23\"></span>[19] Golara\
    \ Garousi, Vahid Garousi-Yusifoglu, Günther Ruhe, Junji Zhi, Mahmood Moussavi,\
    \ and Brian Smith. 2015. Usage and usefulness of technical software documentation:\
    \ An industrial case study. Inf. Softw. Technol. 57 (2015), 664–682.\n- <span\
    \ id=\"page-11-6\"></span>[20] Daya Guo, Shuai Lu, Nan Duan, Yanlin Wang, Ming\
    \ Zhou, and Jian Yin. 2022. UniXcoder: Unified Cross-Modal Pre-training for Code\
    \ Representation. In Proceedings of the 60th Annual Meeting of the Association\
    \ for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland,\
    \ May 22-27, 2022. Association for Computational Linguistics, 7212–7225.\n- <span\
    \ id=\"page-11-4\"></span>[21] Daya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu\
    \ Tang, Shujie Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele\
    \ Tufano, Shao Kun Deng, Colin B. Clement, Dawn Drain, Neel Sundaresan, Jian Yin,\
    \ Daxin Jiang, and Ming Zhou. 2021. GraphCodeBERT: Pre-training Code Representations\
    \ with Data Flow. In 9th International Conference on Learning Representations,\
    \ ICLR 2021. OpenReview.net.\n- <span id=\"page-11-13\"></span>[22] Bo Han, Quanming\
    \ Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor W. Tsang, and Masashi Sugiyama.\
    \ 2018. Co-teaching: Robust training of deep neural networks with extremely noisy\
    \ labels. In Advances in Neural Information Processing Systems 31: Annual Conference\
    \ on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018,\
    \ Montréal, Canada. 8536–8546.\n- <span id=\"page-11-7\"></span>[23] Xu Han, Zhengyan\
    \ Zhang, Ning Ding, Yuxian Gu, Xiao Liu, Yuqi Huo, Jiezhong Qiu, Yuan Yao, Ao\
    \ Zhang, Liang Zhang, Wentao Han, Minlie Huang, Qin Jin, Yanyan Lan, Yang Liu,\
    \ Zhiyuan Liu, Zhiwu Lu, Xipeng Qiu, Ruihua Song, Jie Tang, Ji-Rong Wen, Jinhui\
    \ Yuan, Wayne Xin Zhao, and Jun Zhu. 2021. Pre-trained models: Past, present and\
    \ future. AI Open 2 (2021), 225–250.\n- <span id=\"page-11-39\"></span>[24] Junxian\
    \ He, Jiatao Gu, Jiajun Shen, and Marc'Aurelio Ranzato. 2020. Revisiting Self-Training\
    \ for Neural Sequence Generation. In 8th International Conference on Learning\
    \ Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.\n\
    - <span id=\"page-11-15\"></span>[25] Jordan Henkel, Goutham Ramakrishnan, Zi\
    \ Wang, Aws Albarghouthi, Somesh Jha, and Thomas W. Reps. 2022. Semantic Robustness\
    \ of Models of Source Code. In IEEE International Conference on Software Analysis,\
    \ Evolution and Reengineering, SANER 2022, Honolulu, HI, USA, March 15-18, 2022.\
    \ IEEE, 526–537.\n- <span id=\"page-11-21\"></span>[26] HINT. 2023. Replication\
    \ package of HINT. [https://github.com/shuzhenggao/](https://github.com/shuzhenggao/HINT)\
    \ [HINT.](https://github.com/shuzhenggao/HINT)\n- <span id=\"page-11-24\"></span>[27]\
    \ Xing Hu, Ge Li, Xin Xia, David Lo, Shuai Lu, and Zhi Jin. 2018. Summarizing\
    \ Source Code with Transferred API Knowledge. In Proceedings of the Twenty-Seventh\
    \ International Joint Conference on Artificial Intelligence, IJCAI 2018, July\
    \ 13-19, 2018, Stockholm, Sweden. ijcai.org, 2269–2275.\n- <span id=\"page-11-1\"\
    ></span>[28] Xing Hu, Xin Xia, David Lo, Zhiyuan Wan, Qiuyuan Chen, and Thomas\
    \ Zimmermann. 2022. Practitioners' Expectations on Automated Code Comment Generation.\
    \ In 44th IEEE/ACM 44th International Conference on Software Engineering, ICSE\
    \ 2022, Pittsburgh, PA, USA, May 25-27, 2022. ACM, 1693–1705.\n- <span id=\"page-11-34\"\
    ></span>[29] Jie Huang, Xinyun Chen, Swaroop Mishra, Huaixiu Steven Zheng, Adams\
    \ Wei Yu, Xinying Song, and Denny Zhou. 2023. Large Language Models Cannot Self-Correct\
    \ Reasoning Yet. CoRR abs/2310.01798 (2023).\n- <span id=\"page-11-14\"></span>[30]\
    \ Jinchi Huang, Lie Qu, Rongfei Jia, and Binqiang Zhao. 2019. O2U-Net: A Simple\
    \ Noisy Label Detection Approach for Deep Neural Networks. In 2019 IEEE/CVF International\
    \ Conference on Computer Vision, ICCV 2019, Seoul, Korea (South), October 27 -\
    \ November 2, 2019. IEEE, 3325–3333.\n- <span id=\"page-11-8\"></span>[31] Hamel\
    \ Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, and Marc Brockschmidt.\
    \ 2019. CodeSearchNet Challenge: Evaluating the State of Semantic Code Search.\
    \ CoRR abs/1909.09436 (2019).\n- <span id=\"page-11-36\"></span>[32] Srinivasan\
    \ Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. 2016. Summarizing\
    \ Source Code using a Neural Attention Model. In Proceedings of the 54th Annual\
    \ Meeting of the Association for Computational Linguistics, ACL 2016. The Association\
    \ for Computer Linguistics.\n- <span id=\"page-11-20\"></span>[33] Paras Jain,\
    \ Ajay Jain, Tianjun Zhang, Pieter Abbeel, Joseph Gonzalez, and Ion Stoica. 2021.\
    \ Contrastive Code Representation Learning. In Proceedings of the 2021 Conference\
    \ on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event\
    \ / Punta Cana, Dominican Republic, 7-11 November, 2021. Association for Computational\
    \ Linguistics, 5954–5971.\n- <span id=\"page-11-10\"></span>[34] Wenxiang Jiao,\
    \ Xing Wang, Zhaopeng Tu, Shuming Shi, Michael R. Lyu, and Irwin King. 2021. Self-Training\
    \ Sampling with Monolingual Data Uncertainty for Neural Machine Translation. In\
    \ Proceedings of the 59th Annual Meeting of the Association for Computational\
    \ Linguistics and the 11th International Joint Conference on Natural Language\
    \ Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August\
    \ 1-6, 2021. Association for Computational Linguistics, 2840–2850.\n- <span id=\"\
    page-11-16\"></span>[35] Toshihiro Kamiya, Shinji Kusumoto, and Katsuro Inoue.\
    \ 2002. CCFinder: A Multilinguistic Token-Based Code Clone Detection System for\
    \ Large Scale Source Code. IEEE Trans. Software Eng. 28, 7 (2002), 654–670.\n\
    - <span id=\"page-11-25\"></span>[36] Pei Ke, Haozhe Ji, Zhenyu Yang, Yi Huang,\
    \ Junlan Feng, Xiaoyan Zhu, and Minlie Huang. 2022. Curriculum-Based Self-Training\
    \ Makes Better Few-Shot Learners for Data-to-Text Generation. In Proceedings of\
    \ the Thirty-First International Joint Conference on Artificial Intelligence,\
    \ IJCAI 2022, Vienna, Austria, 23-29 July 2022. ijcai.org, 4178–4184.\n- <span\
    \ id=\"page-11-17\"></span>[37] Miryung Kim, Vibha Sazawal, David Notkin, and\
    \ Gail C. Murphy. 2005. An empirical study of code clone genealogies. In Proceedings\
    \ of the 10th European Software Engineering Conference held jointly with 13th\
    \ ACM SIGSOFT International Symposium on Foundations of Software Engineering,\
    \ 2005, Lisbon, Portugal, September 5-9, 2005. ACM, 187–196.\n- <span id=\"page-11-19\"\
    ></span>[38] Solomon Kullback. 1997. Information theory and statistics. Courier\
    \ Corporation.\n- <span id=\"page-11-38\"></span>[39] Alexander LeClair, Sakib\
    \ Haque, Lingfei Wu, and Collin McMillan. 2020. Improved Code Summarization via\
    \ a Graph Neural Network. In ICPC '20: 28th International Conference on Program\
    \ Comprehension, Seoul, Republic of Korea, July 13-15, 2020. ACM, 184–195.\n-\
    \ <span id=\"page-11-11\"></span>[40] Dong-Hyun Lee et al. 2013. Pseudo-label:\
    \ The simple and efficient semisupervised learning method for deep neural networks.\
    \ In Workshop on challenges in representation learning, ICML, Vol. 3. 896.\n-\
    \ <span id=\"page-11-29\"></span>[41] Yi Li, Shaohua Wang, and Tien N. Nguyen.\
    \ 2021. Vulnerability detection with fine-grained interpretations. In ESEC/FSE\
    \ '21: 29th ACM Joint European Software Engineering Conference and Symposium on\
    \ the Foundations of Software Engineering, Athens, Greece, August 23-28, 2021.\
    \ ACM, 292–303.\n- <span id=\"page-11-33\"></span>[42] Zhiming Li, Xiaofei Xie,\
    \ Haoliang Li, Zhengzi Xu, Yi Li, and Yang Liu. 2022. Cross-lingual transfer learning\
    \ for statistical type inference. In ISSTA '22: 31st ACM SIGSOFT International\
    \ Symposium on Software Testing and Analysis, Virtual Event, South Korea, July\
    \ 18 - 22, 2022. ACM, 239–250.\n- <span id=\"page-11-27\"></span>[43] Chin-Yew\
    \ Lin. 2004. ROUGE: A Package for Automatic Evaluation of Summaries. In Text Summarization\
    \ Branches Out. Association for Computational Linguistics, Barcelona, Spain, 74–81.\n\
    - <span id=\"page-11-18\"></span>[44] Christopher D Manning. 2009. An introduction\
    \ to information retrieval. Cambridge university press.\n- <span id=\"page-12-29\"\
    ></span><span id=\"page-12-0\"></span>[45] Antonio Mastropaolo, Nathan Cooper,\
    \ David Nader Palacio, Simone Scalabrino, Denys Poshyvanyk, Rocco Oliveto, and\
    \ Gabriele Bavota. 2022. Using Transfer Learning for Code-Related Tasks. IEEE\
    \ Transactions on Software Engineering (2022).\n- <span id=\"page-12-21\"></span>[46]\
    \ Antonio Mastropaolo, Simone Scalabrino, Nathan Cooper, David Nader Palacio,\
    \ Denys Poshyvanyk, Rocco Oliveto, and Gabriele Bavota. 2021. Studying the usage\
    \ of text-to-text transfer transformer to support code-related tasks. In 2021\
    \ IEEE/ACM 43rd International Conference on Software Engineering (ICSE). IEEE,\
    \ 336–347.\n- <span id=\"page-12-14\"></span>[47] Fei Mi, Liangwei Chen, Mengjie\
    \ Zhao, Minlie Huang, and Boi Faltings. 2020. Continual Learning for Natural Language\
    \ Generation in Task-oriented Dialog Systems. In Findings of the Association for\
    \ Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020 (Findings\
    \ of ACL, Vol. EMNLP 2020). Association for Computational Linguistics, 3461–3474.\n\
    - <span id=\"page-12-7\"></span>[48] Fei Mi, Wanhao Zhou, Lingjing Kong, Fengyu\
    \ Cai, Minlie Huang, and Boi Faltings. 2021. Self-training Improves Pre-training\
    \ for Few-shot Learning in Task-oriented Dialog Systems. In Proceedings of the\
    \ 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021,\
    \ Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021. Association\
    \ for Computational Linguistics, 1887– 1898.\n- <span id=\"page-12-16\"></span>[49]\
    \ Fangwen Mu, Xiao Chen, Lin Shi, Song Wang, and Qing Wang. 2022. Automatic Comment\
    \ Generation via Multi-Pass Deliberation. In 37th IEEE/ACM International Conference\
    \ on Automated Software Engineering, ASE 2022, Rochester, MI, USA, October 10-14,\
    \ 2022. ACM, 14:1–14:12.\n- <span id=\"page-12-24\"></span>[50] Noor Nashid, Mifta\
    \ Sintaha, and Ali Mesbah. 2023. Retrieval-Based Prompt Selection for Code-Related\
    \ Few-Shot Learning. (2023).\n- <span id=\"page-12-10\"></span>[51] Changan Niu,\
    \ Chuanyi Li, Vincent Ng, Dongxiao Chen, Jidong Ge, and Bin Luo. 2023. An Empirical\
    \ Comparison of Pre-Trained Models of Source Code. In 45th IEEE/ACM International\
    \ Conference on Software Engineering, ICSE 2023, Melbourne, Australia, May 14-20,\
    \ 2023. IEEE, 2136–2148.\n- <span id=\"page-12-26\"></span>[52] OpenAI. 2023.\
    \ GPT-4 Technical Report. CoRR abs/2303.08774 (2023).\n- <span id=\"page-12-18\"\
    ></span>[53] Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.\
    \ Bleu: a Method for Automatic Evaluation of Machine Translation. In Proceedings\
    \ of the 40th Annual Meeting of the Association for Computational Linguistics,\
    \ July 6-12, 2002, Philadelphia, PA, USA. ACL, 311–318.\n- <span id=\"page-12-1\"\
    ></span>[54] Alec Radford, Karthik Narasimhan, Tim Salimans, Ilya Sutskever, et\
    \ al. 2018. Improving language understanding by generative pre-training. (2018).\n\
    - <span id=\"page-12-17\"></span>[55] Ensheng Shi, Yanlin Wang, Lun Du, Junjie\
    \ Chen, Shi Han, Hongyu Zhang, Dongmei Zhang, and Hongbin Sun. 2022. On the Evaluation\
    \ of Neural Code Summarization. In 44th IEEE/ACM 44th International Conference\
    \ on Software Engineering, ICSE 2022, Pittsburgh, PA, USA, May 25-27, 2022. ACM,\
    \ 1597–1608.\n- <span id=\"page-12-13\"></span>[56] Ensheng Shi, Yanlin Wang,\
    \ Wenchao Gu, Lun Du, Hongyu Zhang, Shi Han, Dongmei Zhang, and Hongbin Sun. 2023.\
    \ CoCoSoDa: Effective Contrastive Learning for Code Search. In 45th IEEE/ACM International\
    \ Conference on Software Engineering, ICSE 2023, Melbourne, Australia, May 14-20,\
    \ 2023. IEEE, 2198–2210.\n- <span id=\"page-12-4\"></span>[57] Lin Shi, Fangwen\
    \ Mu, Xiao Chen, Song Wang, Junjie Wang, Ye Yang, Ge Li, Xin Xia, and Qing Wang.\
    \ 2022. Are we building on the rock? on the importance of data preprocessing for\
    \ code summarization. In Proceedings of the 30th ACM Joint European Software Engineering\
    \ Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE\
    \ 2022, Singapore, Singapore, November 14-18, 2022. ACM, 107–119.\n- <span id=\"\
    page-12-5\"></span>[58] Zhensu Sun, Li Li, Yan Liu, Xiaoning Du, and Li Li. 2022.\
    \ On the Importance of Building High-quality Training Datasets for Neural Code\
    \ Search. In 44th IEEE/ACM 44th International Conference on Software Engineering,\
    \ ICSE 2022, Pittsburgh, PA, USA, May 25-27, 2022. ACM, 1609–1620.\n- <span id=\"\
    page-12-27\"></span>[59] Ze Tang, Xiaoyu Shen, Chuanyi Li, Jidong Ge, Liguo Huang,\
    \ Zheling Zhu, and Bin Luo. 2022. AST-Trans: Code Summarization with Efficient\
    \ Tree-Structured Attention. In 44th IEEE/ACM 44th International Conference on\
    \ Software Engineering, ICSE 2022, Pittsburgh, PA, USA, May 25-27, 2022. IEEE,\
    \ 150–162.\n- <span id=\"page-12-6\"></span>[60] Amazon Mechanical Turk. 2023.\
    \ Amazon Mechanical Turk. [https://www.mturk.](https://www.mturk.com/) [com/.](https://www.mturk.com/)\n\
    - <span id=\"page-12-19\"></span>[61] Ramakrishna Vedantam, C. Lawrence Zitnick,\
    \ and Devi Parikh. 2015. CIDEr: Consensus-based image description evaluation.\
    \ In IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2015, Boston,\
    \ MA, USA, June 7-12, 2015. IEEE Computer Society, 4566–4575.\n- <span id=\"page-12-25\"\
    ></span>[62] Chaozheng Wang, Yuanhang Yang, Cuiyun Gao, Yun Peng, Hongyu Zhang,\
    \ and Michael R. Lyu. 2022. No more fine-tuning? an experimental evaluation of\
    \ prompt tuning in code intelligence. In Proceedings of the 30th ACM Joint European\
    \ Software Engineering Conference and Symposium on the Foundations of Software\
    \ Engineering, ESEC/FSE 2022, Singapore, Singapore, November 14-18, 2022. ACM,\
    \ 382–394.\n- <span id=\"page-12-11\"></span>[63] Deze Wang, Boxing Chen, Shanshan\
    \ Li, Wei Luo, Shaoliang Peng, Wei Dong, and Xiangke Liao. 2023. One Adapter for\
    \ All Programming Languages? Adapter Tuning for Code Search and Summarization.\
    \ In 45th IEEE/ACM International Conference on Software Engineering, ICSE 2023,\
    \ Melbourne, Australia, May 14-20, 2023. IEEE, 5–16.\n- <span id=\"page-12-8\"\
    ></span>[64] Yisen Wang, Xingjun Ma, Zaiyi Chen, Yuan Luo, Jinfeng Yi, and James\
    \ Bailey. 2019. Symmetric Cross Entropy for Robust Learning With Noisy Labels.\
    \ In 2019\n\nIEEE/CVF International Conference on Computer Vision, ICCV 2019,\
    \ Seoul, Korea (South), October 27 - November 2, 2019. IEEE, 322–330.\n\n- <span\
    \ id=\"page-12-12\"></span>[65] Yue Wang, Weishi Wang, Shafiq R. Joty, and Steven\
    \ C. H. Hoi. 2021. CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder\
    \ Models for Code Understanding and Generation. In Proceedings of the 2021 Conference\
    \ on Empirical Methods in Natural Language Processing, EMNLP 2021. Association\
    \ for Computational Linguistics, 8696–8708.\n- <span id=\"page-12-3\"></span>[66]\
    \ Yaqing Wang, Quanming Yao, James T. Kwok, and Lionel M. Ni. 2021. Generalizing\
    \ from a Few Examples: A Survey on Few-shot Learning. ACM Comput. Surv. 53, 3\
    \ (2021), 63:1–63:34.\n- <span id=\"page-12-31\"></span>[67] Zhongyuan Wang, Yixuan\
    \ Wang, Shaolei Wang, and Wanxiang Che. 2022. Adaptive Unsupervised Self-training\
    \ for Disfluency Detection. In Proceedings of the 29th International Conference\
    \ on Computational Linguistics, COLING 2022, Gyeongju, Republic of Korea, October\
    \ 12-17, 2022. International Committee on Computational Linguistics, 7209–7218.\n\
    - <span id=\"page-12-23\"></span>[68] Cody Watson, Michele Tufano, Kevin Moran,\
    \ Gabriele Bavota, and Denys Poshyvanyk. 2020. On learning meaningful assert statements\
    \ for unit test cases. In Proceedings of the ACM/IEEE 42nd International Conference\
    \ on Software Engineering. 1398–1409.\n- <span id=\"page-12-15\"></span>[69] Bolin\
    \ Wei, Yongmin Li, Ge Li, Xin Xia, and Zhi Jin. 2020. Retrieve and Refine: Exemplar-based\
    \ Neural Comment Generation. In 35th IEEE/ACM International Conference on Automated\
    \ Software Engineering, ASE 2020, Melbourne, Australia, September 21-25, 2020.\
    \ IEEE, 349–360.\n- <span id=\"page-12-28\"></span>[70] Hongqiu Wu, Hai Zhao,\
    \ and Min Zhang. 2021. Code Summarization with Structure-induced Transformer.\
    \ In Findings of the Association for Computational Linguistics: ACL/IJCNLP 2021,\
    \ Online Event, August 1-6, 2021 (Findings of ACL, Vol. ACL/IJCNLP 2021). Association\
    \ for Computational Linguistics, 1078–1090.\n- <span id=\"page-12-30\"></span>[71]\
    \ Qizhe Xie, Minh-Thang Luong, Eduard H. Hovy, and Quoc V. Le. 2020. Self-Training\
    \ With Noisy Student Improves ImageNet Classification. In 2020 IEEE/CVF Conference\
    \ on Computer Vision and Pattern Recognition, CVPR 2020, Seattle, WA, USA, June\
    \ 13-19, 2020. Computer Vision Foundation / IEEE, 10684–10695.\n- <span id=\"\
    page-12-2\"></span>[72] Pengcheng Yin and Graham Neubig. 2017. A Syntactic Neural\
    \ Model for General-Purpose Code Generation. In Proceedings of the 55th Annual\
    \ Meeting of the Association for Computational Linguistics, ACL 2017, Vancouver,\
    \ Canada, July 30 - August 4, Volume 1: Long Papers. Association for Computational\
    \ Linguistics, 440–450.\n- <span id=\"page-12-22\"></span>[73] Hao Yu, Yiling\
    \ Lou, Ke Sun, Dezhi Ran, Tao Xie, Dan Hao, Ying Li, Ge Li, and Qianxiang Wang.\
    \ 2022. Automated Assertion Generation via Information Retrieval and Its Integration\
    \ with Deep learning. In 44th IEEE/ACM 44th International Conference on Software\
    \ Engineering, ICSE 2022, Pittsburgh, PA, USA, May 25-27, 2022. ACM, 163–174.\n\
    - <span id=\"page-12-9\"></span>[74] Zhilu Zhang and Mert R. Sabuncu. 2018. Generalized\
    \ Cross Entropy Loss for Training Deep Neural Networks with Noisy Labels. In Advances\
    \ in Neural Information Processing Systems 31: Annual Conference on Neural Information\
    \ Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montréal, Canada.\
    \ 8792–8802.\n- <span id=\"page-12-20\"></span>[75] Yaqin Zhou, Shangqing Liu,\
    \ Jing Kai Siow, Xiaoning Du, and Yang Liu. 2019. Devign: Effective Vulnerability\
    \ Identification by Learning Comprehensive Program Semantics via Graph Neural\
    \ Networks. In Advances in Neural Information Processing Systems 32: Annual Conference\
    \ on Neural Information Processing Systems 2019, NeurIPS 2019. 10197–10207."
- title: Experimenting a New Programming Practice with LLMs
  abstract: 'The recent development on large language models makes automatically

    constructing small programs possible. It thus has the potential to free

    software engineers from low-level coding and allow us to focus on the perhaps

    more interesting parts of software development, such as requirement engineering

    and system testing. In this project, we develop a prototype named AISD

    (AI-aided Software Development), which is capable of taking high-level

    (potentially vague) user requirements as inputs, generates detailed use cases,

    prototype system designs, and subsequently system implementation. Different

    from existing attempts, AISD is designed to keep the user in the loop, i.e., by

    repeatedly taking user feedback on use cases, high-level system designs, and

    prototype implementations through system testing. AISD has been evaluated with

    a novel benchmark of non-trivial software projects. The experimental results

    suggest that it might be possible to imagine a future where software

    engineering is reduced to requirement engineering and system testing only.'
  url: http://arxiv.org/abs/2401.01062v1
  keywords: ''
  document: '# Experimenting a New Programming Practice with LLMs


    Simiao Zhang<sup>∗</sup> smzhang@stu.ecnu.edu.cn East China Normal University
    Shanghai, China


    Jun Sun junsun@smu.edu.sg Singapore Management University Singapore, Singapore


    Jiaping Wang<sup>∗</sup> 51265902031@stu.ecnu.edu.cn East China Normal University
    Shanghai, China


    Yueling Zhang ylzhang@sei.ecnu.edu.cn East China Normal University Shanghai, China


    Guoliang Dong gldong@smu.edu.sg Singapore Management University Singapore, Singapore


    Geguang Pu ggpu@sei.ecnu.edu.cn East China Normal University Shanghai, China


    # ABSTRACT


    The recent development on large language models makes automatically constructing
    small programs possible. It thus has the potential to free software engineers
    from low-level coding and allow us to focus on the perhaps more interesting parts
    of software development, such as requirement engineering and system testing. In
    this project, we develop a prototype named AISD (AI-aided Software Development),
    which is capable of taking high-level (potentially vague) user requirements as
    inputs, generates detailed use cases, prototype system designs, and subsequently
    system implementation. Different from existing attempts, AISD is designed to keep
    the user in the loop, i.e., by repeatedly taking user feedback on use cases, high-level
    system designs, and prototype implementations through system testing. AISD has
    been evaluated with a novel benchmark of non-trivial software projects. The experimental
    results suggest that it might be possible to imagine a future where software engineering
    is reduced to requirement engineering and system testing only.


    ## KEYWORDS


    Requirement engineering, system testing, large language model, code generation


    ## 1 INTRODUCTION


    Large language models (LLMs), i.e., transformer-based language models with a huge
    number of parameters, have shown remarkable performance in natural language understanding
    as well as solving complex problems thanks to their emergent abilities [\[38\]](#page-10-0).
    In particular, their abilities of instruction following, step-by-step reasoning,
    and in-context learning have led to many applications in a variety of domains,
    including code generation [\[37\]](#page-10-1). That is, given a description of
    a low-level simple coding task, LLMs such as GPT are capable of synthesizing programs
    automatically, often correctly too [\[5,](#page-10-2) [23,](#page-10-3) [29\]](#page-10-4).
    Thus, it gives us a glint of hope that one day LLMs might free us from manually
    low-level coding.


    In fact, a few recent projects attempted the ambitious goal of replacing programmers
    with LLMs. Li et al. [\[24\]](#page-10-5) propose an end-toend software development
    framework known as ChatDev, which mimics the classical waterfall model and breaks
    down the software development process into four stages, i.e., designing, coding,
    testing, and documenting. That is, given a high-level rather vague requirement,
    ChatDev leverages multiple LLM-based virtual roles


    to generate detailed requirements, design and implementation in


    that sequence through rounds of conversions. MetaGPT [\[13\]](#page-10-6) adopts
    a similar idea and further standardizes each LLM-based agent''s output to guide
    the other agents in the subsequent tasks. For instance, during the design phase,
    MetaGPT generates Product Requirements Documents (PRDs) with a standardized structure
    to coordinate the subsequent development process. While these attempts are shown
    to improve the underlying LLM''s performance to certain extent, they often fail
    when the software project is non-trivial [\[31\]](#page-10-7).


    This is hardly surprising as, even for experienced human programmers, it is infeasible
    to complete a complex software based on vague high-level requirements. This is
    precisely why requirement engineering and system testing play vital roles in the
    software development process, and software development processes such as rapid
    prototyping and agile methods value user feedback during system development highly.
    Requirement engineering and system testing are essential for eliciting the expectations
    of endusers and stakeholders, ensuring that the delivered software aligns with
    their expectations. Requirement engineering is a complex and multifaceted process,
    and no human beings can produce flawless requirement specifications in a single
    attempt. However, the abovementioned approaches conduct requirement analysis only
    lightly and the identified requirements are directly passed on to the coding phase,
    depriving users of the opportunity to validate and modify the automatically generated
    requirements and implementation.


    At the same time, it is perhaps fair to say that requirement engineering in the
    traditional programming paradigm failed to achieve its promises to some extent
    as well as it may often be disconnected from system implementation as the project
    development progresses, e.g., the requirement and corresponding system design
    documents often are not properly maintained along with the system implementation.
    One fundamental reason is that there is limited ways of obtaining timely feedback
    from system designers and programmers (since a software project often lasts months
    or even years). With the help of LLMs, we can potentially shorten the development
    time significantly, allow users to test/validate prototype implementations "instantaneously",
    collect user feedback (e.g., in the form of failed test cases or updated requirements)
    timely and refine the implementation accordingly. In other words, we can make
    requirement engineering more relevant and effective by timely testing the implementation.


    In this work, we experiment with a novel AI-powered software development framework
    called AISD. AISD distinguishes itself from existing approaches in two aspects.
    Firstly, AISD is designed to


    <sup>\*</sup>These authors contributed equally to this work


    Corresponding author


    engage users throughout the software development process, especially during the
    requirement analysis, high-level system design and system validation phase. Secondly,
    AISD adheres to the philosophy that less is more when engaging the human developers.
    Specifically, when presented with a vague requirement, AISD generates a requirement
    document (e.g., use cases) capturing only the core functions required by the system
    and one system design document describing which source files should be built,
    and seeks user-feedback. With the user-feedback, these documents are updated accordingly.
    Note that due to the limited attention span of the LLMs [\[32\]](#page-10-8) (and
    humans too), both documents are designed to be simple but friendly for humans
    and LLMs, which we will show in Section [3.](#page-2-0) Subsequently, AISD decomposes
    the system design into low-level coding tasks and completes them systematically
    and automatically. Once a prototype is implemented (i.e., the resultant system
    passes the unit testing and basic system testing), users are engaged to validate
    the system to check whether their requirements are met. If any failures are identified,
    the implementation, the design and/or the requirements are updated accordingly
    to construct another prototype. This iterative process continues until the users
    accept the product.


    AISD has been implemented as a self-contained toolkit. Considering that existing
    benchmarks, e.g., HumanEval [\[5\]](#page-10-2), MBPP [\[3\]](#page-10-9) and
    CAMEL [\[18\]](#page-10-10) are not suitable for evaluating the capability of
    the LLM-based software development frameworks (all of them either are limited
    to simple function-level implementation tasks or lack detailed requirements specifications
    for system-level implementation tasks), we have developed a novel benchmark named
    CAASD (Capability Assessment of Automatic Software Development). Each task of
    CAASD is equipped with a list of reference use cases depicting the system requirements.
    The reference use cases are used to evaluate the quality and completeness of a
    system implementation. We have compared AISD with two state-of-the-art baselines
    Chat-Dev [\[24\]](#page-10-5) and MetaGPT [\[13\]](#page-10-6) on CAASD. The experimental
    results demonstrate that AISD achieves the highest pass rate while using the fewest
    tokens. On average, AISD achieves an impressive pass rate of 75.2%. Relative to
    these two baselines, there are improvements of 133.5% and 501.6% respectively.
    Moreover, it reduces the number of tokens consumed from at least 28734 to 21993.
    These experimental results provide compelling evidence for the importance of user
    engagement in AI-aided software development.


    In summary, we make the following contributions.


    - We introduce AISD, an AI-aided software development framework that is designed
    to keep users engaged through requirement engineering and system testing.

    - We build a novel benchmark named CAASD for objectively assessing the capabilities
    of various AI-aided software development systems. To the best of our knowledge,
    this is the first benchmark that offers criteria for assessing how well a software
    development task is completed.

    - We conduct a comprehensive evaluation of AISD using the benchmark. The results
    underscore the critical role of human engagement during AI-powered software development.
    These results suggest a potential future where software engineering may be streamlined
    to focus primarily on requirement engineering.


    The remainders of the paper are organized as follows. Section [2](#page-1-0) reviews
    some essential backgrounds. Section [3](#page-2-0) presents the detailed design
    of AISD. Section [4](#page-6-0) presents details on our experiments of applying
    AISD as well as two baselines to the CAASD benchmark. Section [5](#page-9-0) reviews
    related work and Section [6](#page-10-11) concludes.


    ## <span id="page-1-0"></span>2 PRELIMINARIES


    In this section, we review relevant backgrounds on LLMs and prompt engineering.


    ## 2.1 Large Language Models


    LLMs to pre-trained language models [\[26\]](#page-10-12) that have a heightened
    number of parameters, often in the range of tens or even thousands of billions
    [\[37\]](#page-10-1). LLMs, exemplified by models like GPT-3 [\[9\]](#page-10-13)
    and PaLM [\[6\]](#page-10-14), outperform smaller-scale counterparts like BERT
    [\[15\]](#page-10-15) and GPT-2 [\[27\]](#page-10-16) by not only achieving substantial
    performance improvements but also demonstrating emergent abilities. These emergent
    abilities, including in-context learning [\[7\]](#page-10-17), instruction following
    [\[36\]](#page-10-18), and step-by-step reasoning [\[16\]](#page-10-19), endow
    LLMs with the capability to tackle complex tasks.


    A prominent application showcasing the prowess of LLMs is ChatGPT, a significant
    chatbot that can complete various tasks from emulating human-like responses to
    aiding in debugging and writing programs. Such capabilities allow LLMs to potentially
    revolutionize many domains, with potential applications in software development
    and beyond. In this work, we utilize LLMs to experiment a new programming practice.


    ## 2.2 Prompt Engineering


    Prompt engineering is the practice of effectively exploiting and harnessing abilities
    of LLMs by optimizing prompts in a manner that LLMs can comprehend and interpret
    [\[22,](#page-10-20) [25\]](#page-10-21). A prompt is typically natural language
    text instructing how LLMs perform a task and specifying the desired output format.
    Prompt engineering is often based on the emergent abilities. That is, users can
    adopt certain prompt templates to have LLMs tackle complex and interesting tasks.
    In the following, we briefly introduce two prompting engineering techniques used
    in this work.


    Few-shot prompting. Few-shot prompting serves as a method to facilitate in-context
    learning by incorporating demonstrations within the prompt [\[4\]](#page-10-22).
    These demonstrations guide the model towards improved performance, acting as a
    form of conditioning for generating responses in subsequent examples. Figure [1a](#page-2-1)
    showcases an example of few-shot prompting. This example is from the work of Brown
    et al. [\[4\]](#page-10-22), the goal of which is to create a sentence using the
    given word. We can observe that the model completes this task successfully based
    on a single example. In this work, we use few-shot prompting to steer LLMs to
    outputs with certain format.


    Chain-of-thought. Chain-of-thought (CoT) prompting [\[35\]](#page-10-23) is mainly
    based on the "step-by-step reasoning" ability (one of the emergent abilities)
    of LLMs. It is often combined with few-shot prompting to perform intricate tasks
    that require reasoning. In the prompt, users often need to demonstrate how they
    approach a similar task step by step. Figure [1b](#page-2-1) is an example adapted
    from work [\[16\]](#page-10-19). In this example, the prompt exemplifies the calculation
    process, and the output indeed correctly follows it. Recently, Kojima


    <span id="page-2-1"></span>A "whatpu" is a small, furry animal native to Tanzania.
    An example of a sentence that uses the word whatpu is: We were traveling in Africa
    and we saw these very cute whatpus. To do a "farduddle" means to jump up and down
    really


    fast. An example of a sentence that uses the word farduddle is:


    (Output) When we won the game, we all started to farduddle in celebration.


    Q: Roger has 5 balls. He buys 2 more cans of balls. Each can has 3 balls. How
    many balls does he have now? A: Roger started with 5 balls. 2 cans of 3 tennis
    balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11 Q: I had 23 apples.
    If I used 20 to make lunch and bought 6 more, how many apples do I have?


    (Output) You started with 23 apples. You used 20 to make lunch. So you had 23
    - 20 = 3. They bought 6 more apples, so you have 3 + 6 = 9. The answer is 9.


    #### (a) Few-shot prompting


    #### (b) Few-shot CoT prompting


    <span id="page-2-2"></span>![](_page_2_Figure_9.jpeg)


    ### Figure 1: Examples of different prompting techniques


    Figure 2: Overview of AISD


    et al. proposed zero-shot CoT prompting. Instead of exemplifying how to approach
    a task through examples, zero-shot CoT prompting simply adds "Let''s think step
    by step" after the question. In this work, we adopt the zero-shot CoT prompting
    in our prompts to improve outputs of LLMs.


    ## 2.3 LLM-based Autonomous Agent


    An LLM-based autonomous agent is a system that employs an LLM as its core controller
    to automatically plan tasks, make decisions, adopt actions, and reflect and update
    results. Technically, an LLMbased autonomous agent consists of four modules [\[34\]](#page-10-24):
    profiling module, memory module, planning module and action module.


    The profiling module specifies the role of the agent by writing the related profile
    in the prompt, potentially inducing LLMs to produce response with the role''s
    expertise. Different roles indicate different responsibilities for agents. For
    example, in the software development scenario, we may designate an agent as a
    programmer, focusing primarily on coding. The memory module is used to store past
    observations, decisions and actions, facilitating future actions. The planning
    module simulates the process that humans follow to handle a complex task. That
    is, this module focuses on breaking down a complex task to a series of simple
    and manageable subtasks. The action module is responsible for executing the agent''s
    decisions (i.e., the decomposed subtasks). Note that the action module


    directly interacts with the environment, i.e., using external tools. LLM agents
    provide a flexible way to accomplish intricate tasks. Note that LLM agents have
    varying levels of autonomy, and some LLM agents may only have some of the four
    modules. Depending on the capabilities granted during the design phase, agents
    can exhibit self-directed behaviors ranging from purely reactive to highly proactive.
    In our work, AISD is mainly built with multiple communicative agents [\[18\]](#page-10-10),
    which complete their work through conversation with each other and human developers.


    ## <span id="page-2-0"></span>3 OUR APPROACH


    In this section, we present the design of AISD and its interaction with users.
    Figure [2](#page-2-2) provides an overview of the overall workflow, where the
    tasks highlighted in green are the ones that rely on human-interaction. Starting
    with an initial idea, AISD firstly refines the task and generates a set of use
    cases to capture the core functions required by the desired system. Instead of
    immediately proceeding to the follow-up procedure, AISD interacts with the user
    to review and modify the generated use cases to ensure they properly convey the
    user''s requirements. Once the user agrees to proceed, AISD produces a simple
    but LLM-and-human friendly system design. Note that humans can also revise the
    high-level system design as they do for use cases, but in practice, the revision
    of system design requires some expertise, which may be not


    - <span id="page-3-0"></span>1. User can input the characteristics of iris flowers.

    - 2. User can submit the input data to the neural network classifier

    - 3. User can obtain the classification results.

    - 4. User can view the classification results in JSON format.

    - 1. User can input the characteristics of iris flowers.

    - 2. User can submit the input data to the neural network classifier

    - 3. User can obtain the classification results.

    - 4. User can view the classification results on a board.

    - 1. User can input the characteristics of iris flowers. The input includes four
    characteristics: "Sepal-LengthCm", "SepalWidthCm", "PetalLengthCm", and "PetalWidthCm".

    - 2. User can submit the input data to the neural network classifier

    - 3. User can obtain the classification result.

    - 4. User can view the classification name of the iris flower on the board. The
    result should be the species name.


    (a) Use cases directly generated by ChatGPT


    (b) The revised use cases based on human review


    (c) The revised use cases based on manual testing


    ### Figure 3: Use cases evolution of the task "A tool for classifying iris flowers"


    suitable for ordinary users. We thus highlight this phase with light green indicating
    that human engagement in this phase is optional. After that, AISD implements the
    system automatically according to the design. Following implementation, AISD iteratively
    tests and refines the system. There are two types of testing. One is the automation
    testing and the other is the manual testing. When errors occur during automation
    testing, the error messages are used as feedback to guide the bug fixing automatically.
    Dashed lines in Figure [2](#page-2-2) indicate that an iterative process is involved,
    and the red dashed lines indicate that humans are involved in the respective iteration.
    That is, AISD iteratively performs automation testing and bug fixing. To prevent
    AISD from getting stuck in this iteration (e.g., a bug that cannot be fixed by
    LLMs), AISD allows the user to set a maximum number of iteration times. After
    automation testing, unlike existing approaches that often terminate after code
    generation [\[18\]](#page-10-10) or automation testing [\[13,](#page-10-6) [24\]](#page-10-5),
    in AISD, the user is asked to test the resultant system manually. If a test failure
    occurs, different actions are taken according to the nature of the failure. Specifically,
    if there are any error messages reported during testing, these error messages
    are provided as input to the bug fixing module. Otherwise, the user may add or
    refine the use cases and instruct AISD to repeat the subsequent procedures (e.g.,
    in the case of that some system requirement was missing or is revised (as often
    is the case in practice)). In the following, we introduce the details of each
    step.


    ## 3.1 Use Cases Generation


    Use cases play a crucial role in the software development. They are helpful in
    identifying, clarifying, and understanding the functional requirements of a system
    from a user''s perspective. When implementing a desired system with LLMs, use
    cases can be integrated into specific prompts to articulate the concrete functions
    that should be implemented. Once a system is delivered, use cases can also serve
    as a means to validate whether the system meets the stack-holders'' requirements.


    In the traditional software development process, use cases are typically derived
    from a general idea by requirements engineers. While some works, such as MetaGPT,
    show that LLMs can generate well-documented use cases in certain scenarios, we
    argue that


    involving stakeholders in the derivation of use cases is crucial due to the vagueness
    and incompleteness of requirements in the initial stage, particularly when tackling
    complex tasks. That is, automatically generated use cases may fail to clearly
    and correctly convey the functional requirements of the system. However, on the
    other hand, directly writing out the detailed use cases manually from scratch
    is usually challenging and burdensome for users. Therefore, to alleviate the burden
    the user bears and avoid fully relying on outputs of LLMs, AISD initially generates
    a "draft" of use cases using LLMs with the prompt shown in Figure [4,](#page-4-0)
    and then asks the user to review (and revises if necessary) the generated use
    cases. Note that each prompt used in AISD consists of two parts: the system message
    and the user message. The system message is used for role assignment and thus
    induces LLMs to produce response with the role''s expertise. The user message
    is used for task specification. Once the use cases are deemed acceptable, the
    user then instructs AISD to proceed with these use cases.


    For example, a user intends to develop a tool for identifying various species
    of iris. The user inputs the task "develop a neural network classifier tool that
    allows users to input the characteristics of iris flowers and obtain classification
    results" to AISD. AISD then generates an initial version of use cases as shown
    in Figure [3a.](#page-3-0) Although most of the use cases are acceptable, the
    last use case fails to capture the correct requirement as the user would like
    to view the result on a graphic interface, instead of in a JSON file. Consequently,
    the user revises the use case to align it with the desired requirement, as shown
    in Figure [3b](#page-3-0) where the revision is highlighted with red color. This
    use case review and refinement process may repeat multiple times if necessary
    until the user is happy with the resultant use cases. After that, the user instructs
    AISD to proceed.


    ## <span id="page-3-1"></span>3.2 System Designing


    System design serves as a blueprint for implementing a system. The standard system
    design process is complex, involving the design of architecture, components, modules,
    interfaces, and data to meet specified requirements [\[8\]](#page-10-25). Typically,
    this process generates numerous documents at different levels of abstraction.
    While these


    #### <span id="page-4-0"></span>System Message:


    You are a Product Manager. You have extensive experience in designing products
    and translating complex technical requirements into clear, user-centric scenarios.


    #### User Message:


    According to the user''s task listed below: Task: "{task}". You should write down
    the use cases required by this task. Output in JSON format. The format is:


    { "1": "User can view the GUI." }


    #### <span id="page-4-1"></span>Figure 4: Prompts used in use cases generation
    phase


    #### System Message:


    You are a software architect. According to the user''s task and use cases, you
    will write the system design. List only key code files (no more than 6 files),
    ALWAYS start with the "main" file. Don''t list multi-level files. Output in JSON
    format. The format is: {"main.py": "This is the main file of ...", } User Message:
    Task: {task} Use Cases: {use\_cases}


    #### Figure 5: Prompts used for system designing


    documents are beneficial for developers to understand and implement the desired
    system, our experience suggests that they are unsuitable for instructing LLMs
    to code accordingly due to two challenges. Firstly, LLMs struggle when processing
    comprehensive system design documents that exceed their token limit. Secondly,
    the intricate and overwhelming information in these documents often distracts
    LLMs from focusing on the core task—implementing functional requirements. To address
    these challenges, we propose a simplified system design approach that produces
    documents more suitable for LLM-based software development. Specifically, we generate
    only one document based on use cases. This document outlines the source files
    the desired system should have and the functions each file should implement.


    Concretely, in the designing phase, AISD receives the initial task and the use
    cases accepted by the user. It utilizes the prompts shown in Figure [5](#page-4-1)
    to instruct LLMs in generating a list of source file names along with their corresponding
    descriptions. The system message in this prompt is designed by incorporating the
    ideas of role-playing [\[17\]](#page-10-26) and few-shot learning [\[4\]](#page-10-22)
    which we believe can enhance the quality of the outputs. Specifically, we have
    LLMs simulate the role of a software architect, tasking them with generating responses
    that are not only specific but also aligned with the given context. To facilitate
    the follow-up procedures, the outputs are expected to be in JSON format. To this
    end, we provide an output example in the prompt to demonstrate the expected outputs
    following the idea of few-shot learning.


    <span id="page-4-2"></span>"main.py": "This is the main file of the neural network
    classifier tool.",


    "classifier.py": "This file contains the implementation of the machine learning
    classification algorithm.", "gui.py": "This file provides the graphical user interface


    for users to enter iris characteristics and view classification results.",


    "utils.py": "This file contains utility functions used in the system."


    #### Figure 6: Example of the system design in AISD


    Figure [6](#page-4-2) presents an example of the system design based on the revised
    use cases shown in Figure [3b.](#page-3-0) The system design is articulated through
    four Python source files, each accompanied by a concise explanation detailing
    its functions. We remark that this form of system design is simple yet LLMs-friendly,
    enabling LLMs to focus more on tractable sub-tasks by reducing irrelevant information.


    We remark that the system design involves a certain level of expertise, which
    poses challenges for ordinary users to review and modify it. Specifically, users
    often need to possess a deep understanding of programming languages and have some
    development experience to assess the reasonability of each module in the presented
    system design, as well as to ensure that all modules can form a complete system.
    Nevertheless, we enable users to determine if the generated system design is acceptable
    and opt to revise it, particularly when interacting with professional users.


    ## 3.3 Coding and Automatic Testing


    The code generation in AISD is an automatic and iterative process. With the system
    design generated previously, AISD prompts LLMs to produce all the required source
    files at once, tests the resultant system, and refines the source code according
    to the testing outcome.


    Prompts used to generate source code are shown in Figure [7.](#page-5-0) In the
    system prompt, we set the LLM to be a skilled programmer with experience in various
    programming languages. In the user prompt, we provide the initial task along with
    the outputs of each previous phase, i.e., use cases and system design. We then
    explain what LLMs should complete. Note that involving the task description and
    the corresponding use cases in the prompt is necessary, as these two types of
    information help LLMs retain the user''s requirements, guiding them to code accordingly.


    Instead of generating each code file separately (i.e., one code file in one chat
    session), the LLM is asked to complete all the coding tasks in one chat session.
    Typically, different source files collaborate to form the complete system, indicating
    that these files are interdependent. In practice, when generating code for interconnected
    modules in separate chat sessions, the system might encounter the challenge of
    "robbing Peter to pay Paul" as generating one file without considering the entire
    system can inadvertently result in a failure. This is because the generated code
    files may not


    #### <span id="page-5-0"></span>System Message:


    You are a Programmer. You have extensive computing and coding experience in many
    programming languages and platforms, such as Python.


    #### User Message:


    The user''s task, use cases and original system designs are listed below:


    Task: "{task}".


    Use Cases: "{use\_cases}".


    System Design: "{system\_design}".


    You have to complete the task through an executable software with multiple files
    implemented via Python.


    To satisfy the new user''s demands, you should write files and make sure that
    every detail of the architecture is, in the end, implemented as code. The software
    should be equipped with graphical user interface (GUI) so that user can visually
    and graphically use it; so you must choose a GUI framework (e.g., in Python, you
    can implement GUI via tkinter, Pygame, Flexx, PyGUI, etc,). Think step by step
    and reason yourself to the right decisions to make sure we get it right. You will
    output the content of each file including complete code. Each file must strictly
    follow a markdown code block format, where the following tokens must be replaced
    such that "FILENAME" is the lowercase file name including the file extension,
    "LANGUAGE" in the programming language, "DOCSTRING" is a string literal specified
    in source code that is used to document a specific segment of code, and "CODE"
    is


    the original code: FILENAME LANGUAGE ''''''DOCSTRING'''''' CODE You will start
    with the "main" file, then go to the ones that are imported by that file, and
    so on. Please note that the code should be fully functional. Ensure to implement
    all functions. No placeholders (such as ''pass'' in Python).


    ### Figure 7: Prompts used for code generation


    coordinate with each other. Thus, in AISD, we instruct LLMs to generate all code
    files in one chat session, ensuring that the resultant files can work closely
    together, thereby reducing potential bugs in the system. Note that due to the
    hallucination of LLMs, there may exist some unimplemented functions (e.g., the
    function body just has a ''pass'' keyword in Python) and missing import packages
    in the resultant implementation. To remedy this, once the source code is generated,
    AISD employs LLMs to refine the source code, identifying and addressing these
    potential issues.


    Limited by the capability of LLMs, the resultant implementation may still contain
    bugs even after automatic refinement with LLMs. Therefore, we introduce an automatic
    testing phase before the system is presented for human testing. During the automatic
    testing, AISD sequentially performs two different types of testing: unit testing,
    and system testing. For the unit testing, AISD generates a set of unit tests for
    each function, automatically runs them and records the results. Failure tests
    and the corresponding code are provided to LLMs for code refinement. Once all
    unit tests pass, AISD proceeds to the system testing, checking if the system can
    correctly start execution as a complete system. If errors occur during startup,
    AISD instructs LLMs to refine the code according to the error messages. Note that
    each testing is iterative, and the whole automation testing is implemented as
    an agent capable of automatically performing two kinds of testing and deciding
    when each testing stops. Additionally, we allow users to set a maximum number
    of iterations for each testing to prevent endless refinement.


    We take an example to showcase how AISD automatically refines the generated system
    through basic system testing. This example is observed when performing the development
    task "Airplane War Game". Specifically, when AISD executes "python main.py" for
    the system testing, an error occurs. The error message is shown in


    Figure [8a](#page-6-1) which suggests that a function is used wrongly. Subsequently,
    AISD employs the prompt shown in Figure [8b](#page-6-1) to instruct the LLM to
    fix the error accordingly. Note that the two placeholders "code" and "message"
    in that prompt are automatically replaced with the source code of the entire system
    implementation and the error message obtained at runtime.


    ## 3.4 System Validation


    Passing the unit testing and being executable do not necessarily mean that the
    generated system is acceptable from the perspective of stakeholders. The main
    reason is that the automatic testing, as depicted earlier, is unable to verify
    if the functional requirements are satisfied, especially when the initial set
    of use cases may be still incomplete or wrong according to the actual user expectation,
    or the system is built with a graphic user interface (for which there will be
    typically a lot of details that may not be what the user wants). For example,
    the use case "User can view the classification results on a board" in Figure [3b](#page-3-0)
    directly requires the user''s feedback. In this case, it is challenging to assess
    whether this requirement is satisfied without human engagement.


    To ensure that the generated system aligns with the user''s requirements, it is
    essential to involve the user in validating the system. Specifically, when the
    generated system passes the automatic testing, the user is required to manually
    test the system according to the use cases generated previously. If the requirement
    depicted by a use case is not satisfied, the user is then required to revise the
    description of the use case or instruct AISD to revise the source code. Concretely,
    if the user fails to validate a use case but no errors occur when validating it,
    the user then revises the description of the use case to make it more detailed
    and instructs AISD to start from the system designing phase again. In case of
    errors reported, the user then provides the error message and instructs AISD to
    fix


    <span id="page-6-1"></span>Experimenting a New Programming Practice with LLMs
    Conference''17, July 2017, Washington, DC, USA


    Traceback (most recent call last): File "main.py", line 3, in <module> game.start\_game()
    File "game.py", line 21, in start\_game player.handle\_input(player\_airplane,
    bullets) TypeError: handle\_input() missing 1 required positional argument: ''canvas''


    #### (a) Error message when running ''python main.py''


    ### System Message:


    Please review the source code. Identify and fix the issues listed below. Think
    step by step. First, analyze the reason why errors are increasing. Second, write
    the entire code files, ensuring that the format matches that of the Source Code.
    Each file must strictly follow a markdown code block format, where the following
    tokens must be replaced such that "FILENAME" is the lowercase file name including
    the file extension, "LAN-GUAGE" in the programming language, "DOCSTRING" is a
    string literal specified in source code that is used to document a specific segment
    of code, and "CODE" is the original code: FILENAME LANGUAGE ''''''DOC-STRING''''''
    CODE You will start with the "main" file, then go to the ones that are imported
    by that file, and so on. Please note that the code should be fully functional.
    Ensure to implement all functions. No placeholders (such as "pass" in Python).


    User Message: Source Code: {code} Problem: {message}


    #### (b) Prompts used for fixing runtime bugs


    #### Figure 8: Example of automatic testing


    the bug accordingly. Lastly, the user can also choose to introduce new use cases
    (i.e., new requirements), which is often the case in practice. The user can repeat
    this process until all the use cases pass the testing.


    We present an example showcasing how the user collaborates with AISD in this phase.
    Figure [9a](#page-6-2) shows the resultant system based on the use cases presented
    in Figure [3b.](#page-3-0) However, this system does not meet the user''s expectations.
    Firstly, there is only one input box with no prompts on how to enter the iris''s
    characteristics. Secondly, the classification result is presented as a number,
    which is hard for users to understand. The second issue is interesting which exposes
    that humans and LLMs may have different understandings about the same expression,
    e.g., "Use can view the classification result". While users indeed can "view"
    the classification result, they generally expect the tool to directly present
    what species the input iris is, instead of a cryptic number (though it may correspond
    to a specific iris species). Therefore, we revise the use cases to add some details.
    The revised version is shown in Figure [3c.](#page-3-0) Subsequently, we instruct
    AISD to proceed with the updated use cases. After a series of steps as described
    previously, the resultant system aligns perfectly with our requirements, as shown
    in Figure [9b.](#page-6-2)


    <span id="page-6-2"></span>![](_page_6_Figure_11.jpeg)


    (b) The resultant system after manual testing


    Figure 9: Comparison of the resultant system before and after manual testing


    # <span id="page-6-0"></span>4 EXPERIMENTS


    We have implemented AISD as a self-contained toolkit based on LLMs, comprising
    approximately 2058 lines of source code written in Python 3.7. Our implementation
    as well as the benchmark used in this work are available at [\[1\]](#page-10-27).
    In the following, we conduct multiple experiments to address the following research
    questions:


    - RQ1: How effective is AISD in developing software?

    - RQ2: Does the human engagement matter?

    - RQ3: How much user involvement is needed for AISD to work effectively?


    RQ1 aims to evaluate the effectiveness of AISD in completing development tasks.
    RQ2 further conducts an ablation study to verify if human engagement does contribute
    to the effectiveness of AISD. Finally, RQ3 analyzes the number of user interactions
    required by AISD when performing a software development task.


    # 4.1 Experimental setup


    Assessment benchmark. We have manually constructed a benchmark named CAASD (Capability
    Assessment of Automatic Software Development) to assess the capabilities of various
    AIaided software development systems, which we consider to be another contribution
    of this work.


    Note that existing benchmarks are not suitable for evaluating the capability of
    the AI-aided software development system. This is because benchmarks like HumanEval
    [\[5\]](#page-10-2), MBPP [\[3\]](#page-10-9) and CAMEL [\[18\]](#page-10-10)
    either consist of simple function-level coding tasks or lack relatively objective
    criteria to assess the level of task completion. The former essentially reflects
    the capability of the LLM itself (since LLMs are effective for solving such tasks),
    while the latter hinders an objective assessment of task


    completion. To address the problem of lacking a benchmark for evaluating LLM-based
    automatic software development systems, we propose the CAASD benchmark which contains
    72 software development tasks collected from multiple sources and from multiple
    domains such as small games, personal websites, and various other applications.
    On average, the implementation of each task in CAASD requires approximately 240
    lines of code, based on the analysis of open-source implementations of similar
    tasks [\[10](#page-10-28)[–12\]](#page-10-29). Each test case in CASSD consists
    of four fields, i.e., a task ID, a task name, a task prompt and a list of reference
    use cases. Particularly, the task prompt describes the task to complete (i.e.,
    a high-level often vague system requirement) and is provided as input to various
    AI-aided software development systems. The reference use cases of each task depict
    the essential functional requirements of a system. We remark that these reference
    use cases serve as a means to objectively assess the task completion, details
    of which will be elaborated in Section [4.2.](#page-7-0)


    Baselines. We compare AISD with two state-of-the-art baselines, namely ChatDev
    [\[24\]](#page-10-5) and MetaGPT [\[13\]](#page-10-6). ChatDev divides the development
    process into four phases (i.e., designing, coding, testing, and documenting),
    and assigns two virtual roles to solve the corresponding subtask at each phase
    by multi-turn discussions. The two roles stop discussing only when they reach
    a consensus that the subtask has been successfully accomplished. MetaGPT also
    decomposes a general development task into several subtasks, but differs from
    ChatDev in two aspects. First, when solving each subtask, MetaGPT adopts only
    one virtual role (e.g., a product manager) to address the subtask. Second, MetaGPT
    incorporates the idea of human Standardized Operating Procedures (SOPs) and mandates
    each role to produce standardized outputs, facilitating knowledge sharing across
    different modules.


    We conducted all experiments based on ChatGPT [1](#page-7-1) with version "gpt3.5-turbo-16k".
    For ChatDev, we utilize the settings outlined in [\[24\]](#page-10-5), whereas
    for the MetaGPT, we adopt the default settings of the open-sourced implementation[2](#page-7-2)
    as the paper [\[13\]](#page-10-6) contains insufficient details of the experimental
    settings. Following the settings in ChatDev, we allowed up to 5 turns for both
    automation testing and manual testing in AISD, and selected the best as the final
    outcome among the systems generated from all turns.


    ## <span id="page-7-0"></span>4.2 Research Questions


    RQ1: How effective is AISD in developing software? To answer this question, we
    applied AISD and the two baselines to solve the tasks of the CAASD benchmark systematically,
    and then reported the pass rate of the tasks and costs for each approach. The
    "costs" here refers to the overall count of tokens consumed by LLMs to accomplish
    a task, encompassing both input tokens and output tokens. The pass rate for each
    task is calculated using the following formula:


    Pass rate = #Passed Use Cases #Total Use Cases


    where #Total Use Cases is the total number of the reference use cases of a task
    in CAASD, and #Passed Use Cases denotes the number of reference use cases which
    pass the manual testing. Specifically,


    <span id="page-7-2"></span>


    <span id="page-7-3"></span>![](_page_7_Figure_11.jpeg)


    Figure 10: The performance of three AI-aided software development systems on CAASD
    benchmark


    we manually inspect reference use cases of the corresponding task one by one by
    running the generated system. The value of #Passed Use Cases is then obtained
    by counting the number of successfully passed use cases.


    2https://github.com/geekan/MetaGPT(v0.3.0) **AISD ChatDev MetaGPT 0.0** The results
    are summarized in Figure [10.](#page-7-3) We observe that our approach, i.e.,
    AISD achieved an impressive 75.2% pass rate while maintaining an average token
    consumption of just 21993 tokens per task. In contrast, ChatDev has a pass rate
    of 32.2% and consumes an average of 28734 tokens per task, and MetaGPT performs
    even worse with a pass rate of only 12.5% and an average token cost of 37136 per
    task. It is worth noting that both MetaGPT and ChatDev have a cost that is over
    1.3 times higher than that of AISD. The significant improvement of AISD over ChatDev
    may be attributed to the human engagement in its design (which we will systematically
    analyze in RQ2). MetaGPT is dramatically less effective compared to AISD and ChatDev,
    although it is not surprising. The reason is that MetaGPT feeds too much complex
    information to LLMs, leading to difficulties for LLMs to understand the tasks.
    For example, before the coding phase, MetaGPT generates a standard PRD (Product
    Requirements Document), including "Product Goals", "User Stories", "Competitive
    Analysis", "Competitive Quadrant Chart" (in the form of mermaid[3](#page-7-4)
    code), "Requirement Analysis", "Requirement Pool". In the coding phase, the PRD
    with this rich information is directly used as a part of prompt to instruct LLMs,
    which may result in cognitive overload for LLMs. The results from MetaGPT further
    reinforce the point that we highlighted in Section [3.2](#page-3-1) (i.e., intricate
    and overwhelming information potentially distracts LLMs), ultimately undermining
    their ability to comprehend and complete core tasks. Additionally, among the three
    frameworks, AISD consumed the fewest tokens, while MetaGPT consumed the most,
    indicating that AISD is not only effective but also efficient.


    Answer to RQ1: AISD significantly improves the use cases pass rate with lower
    costs compared to existing baselines.


    ### RQ2: Does the human engagement matter?


    <span id="page-7-1"></span><sup>1</sup>https://openai.com/blog/introducing-chatgpt-and-whisper-apis


    <span id="page-7-4"></span><sup>3</sup>https://github.com/mermaid-js/mermaid


    <span id="page-8-0"></span>![](_page_8_Figure_1.jpeg)


    Figure 11: Pass rate of AISD with and without human engagement over CAASD benchmark.


    To address this question, we applied AISD to the CAASD benchmark again but omitted
    the human engagement in all phases. That is, we skipped the manual revision in
    the use cases generation and the entire manual testing phase. Note that we conducted
    5 trials for each task, and selected the best pass rate among the 5 trials as
    the pass rate of the task. We compared the results obtained without human engagement
    to those with human engagement.


    Figure [11](#page-8-0) illustrates the pass rate of AISD with and without human
    engagement over CAASD benchmark. The x-axis represents the ID of each task, ranging
    from 1 to 72. For each task, the pass rate with human engagement is denoted by
    a red point, and the pass rate without human engagement is denoted by a blue point.
    The green point indicates that there is an overlap of a blue point and a red point.
    The green horizontal line and the red horizontal line represent the average pass
    rate of each group, respectively. Observing the data, the average pass rate of
    AISD with human engagement (i.e., about 75.2%) is approximately 51.1 percentage
    higher than that of the AISD without human engagement (i.e., about 24.1%). It
    is worth noting that a concentration of 47.2% orange points is evident at the
    bottom (i.e., 0% pass rate), contrasting with only 5.6% of blue points at the
    same level. These findings suggest that human engagement not only enhances the
    overall use case pass rate of the generated system implementation, but also underscores
    the significance of human involvement in handling tasks that prove challenging
    when relying solely on the power of LLMs. In the next research question, we will
    conduct a more in-depth analysis of the influence of human involvement on the
    use case pass rate.


    Answer to RQ2: Engaging users during requirement analysis and system testing effectively
    bridges the gap between the generated system and users'' expectation, especially
    in handling challenging tasks.


    RQ3: How many times of user involvement are needed in AISD? In AISD, users mainly
    engage in two distinct phases. The first involves use case generation, and the
    second entails manual testing. In the former phase, users are required to review
    the generated use cases and revise them if necessary until they are deemed to


    <span id="page-8-1"></span>Table 1: The instances of revisions achieving the final
    pass rate using AISD.


    | ℎ1                               | ℎ2 | #Task | Avg. Pass Rate (%) | Total Revisions
    |

    |----------------------------------|----|-------|--------------------|-----------------|

    | 0                                | 0  | 1     | 100%               | 0               |

    | 0                                | 1  | 1     | 100%               | 1               |

    | 0                                | 2  | 0     | -                  | -               |

    | 0                                | 3  | 0     | -                  | -               |

    | 0                                | 4  | 0     | -                  | -               |

    | 0                                | 5  | 0     | -                  | -               |

    | 1                                | 0  | 14    | 68.57%             | 1               |

    | 1                                | 1  | 8     | 81.44%             | 2               |

    | 1                                | 2  | 12    | 85.42%             | 3               |

    | 1                                | 3  | 11    | 86.68%             | 4               |

    | 1                                | 4  | 9     | 86.89%             | 5               |

    | 1                                | 5  | 16    | 52.59%             | 6               |

    | Average times of manual revision |    |       |                    | 3.5             |


    <span id="page-8-2"></span>![](_page_8_Figure_10.jpeg)


    Figure 12: The pass rate with different numbers of human interactions (ℎ2)


    be acceptable. In the latter phase, users participate in an iterative process
    wherein they assess the use cases by executing the resultant system, and they
    may subsequently revise the use cases or prompt LLMs to address bugs. Consequently,
    users are involved in the entire development process at least twice, even if they
    choose not to revise the use cases or perform bug fixing based on error messages.
    To show the required manual efforts using AISD more specifically, we counted the
    times of manual revision in both use cases generation and the manual testing phases
    for each development task. In this context, "manual revision" refers to the manual
    adjustment of use cases or the prompt for fixing bugs.


    Table [1](#page-8-1) shows the manual revisions involved in completing development
    tasks with AISD. In this table, ℎ<sup>1</sup> denotes the times that a human revises
    use cases during the use case generation phase, ℎ<sup>2</sup> denotes the times
    that a human revises use cases or prompts LLMs to fix bugs during the manual testing
    phase, ''#Task'' is the number of tasks each of which undergoes ℎ<sup>1</sup>
    revisions during the use case generation phase and ℎ<sup>2</sup> revisions during
    the manual testing phase, ''Avg. Pass Rate'' indicates the average pass rate achieved
    by tasks of each group, and ''Total Revisions'' denotes the total times of manual
    revisions of each task, which is the sum of ℎ<sup>1</sup> and ℎ2. Note that ℎ<sup>1</sup>
    is either 0, indicating no modifications, or 1, indicating there


    are manual revisions during the use case generation phase. Note that all modifications
    are treated as one revision since there is no iteration during this phase. The
    value of ℎ<sup>2</sup> ranges from 0 to 5, as we allow a maximum of 5 iterations
    during the manual testing phase in this work.


    We can observe that AISD requires approximately four revisions on average. For
    over half of the tasks (47 out of 72), AISD achieves the best pass rate within
    four rounds of manual revision. Note that only one task out of the total 72 tasks
    attains a 100% pass rate without any manual revisions, and 70 tasks (where ℎ<sup>1</sup>
    equals 1) demonstrate the need for user involvement in revising the generated
    use cases (i.e., the generated use cases look implausible and thus need manual
    modifications). These findings underscore a substantial disparity between use
    cases generated by LLMs and user expectations, emphasizing the essential role
    of human engagement in successfully completing development tasks.


    We further analyze how the pass rate varies with the increasing number of human
    revisions. Figure [12](#page-8-2) displays changes in key statistical measures
    of pass rate as ℎ<sup>2</sup> increments through a boxand-whisker plot with observations.
    The numbers in red are the counts of minimum and maximum points. Note that the
    pass rate in this figure is obtained based on the resultant system after ℎ2-th
    revision. In general, with the rise in ℎ2, the median pass rate and the percentiles
    (i.e., 25th and 75th) gradually rise, and tasks attaining a 100% pass rate (depicted
    by blue points at the top) become more concentrated. The median pass rate even
    reaches 100% when ℎ<sup>2</sup> > 3. These findings, to some extent, rule out
    the possibility that the pass rate improvement is solely a result of the uncertainty
    of LLMs. We also observe that when increasing ℎ2, there are still some tasks for
    which the pass rate remains 0%. This is not surprising. First, the quality of
    the revision depends on both the user''s proficiency and the task''s complexity.
    When handling particularly complex tasks, it becomes challenging for users to
    discern the required functions of the system, hindering their ability to revise
    use cases effectively. Additionally, some use cases surpass the capabilities of
    LLMs. For instance, in the development task "Voice Assistant", users expected
    that the desired system can understand what they said, and respond correctly.
    The system delivered by AISD however can only record the voice of users, even
    after rounds of prompting.


    Answer to RQ3: In general, increasing user interactions leads to a higher pass
    rate of use cases. However, for some complex tasks, additional interactions may
    yield limited results due to LLMs'' constraints. Our practical guideline is thus
    to continue interacting with AISD until users struggle to improve the generated
    use cases, and no runtime error occurs.


    ## <span id="page-9-0"></span>5 RELATED WORK


    This work is closely related to existing approaches on automatic code generation.
    Automatic code generation is a hot topic in natural language processing community.
    Before the emergence of large neural network models, the works on this topic can
    be categorized into two groups. One primarily focuses on traditional techniques
    from both rule-based and statistical natural language processing, while the other
    is related to neural networks.


    In the early stages, researchers primarily employ heuristic rules or expert systems
    to synthesize program. Jha et al. [\[14\]](#page-10-30) propose an approach to
    automatically synthesize loop-free programs based on a combination of oracle-guided
    learning from examples and constraint-based synthesis from components using satisfiability
    modulo theories (SMT) solvers. Allamanis and Sutton [\[2\]](#page-10-31) propose
    to extract code idioms from a corpus of idiomatic software projects by nonparametric
    Bayesian probabilistic tree substitution grammars. Raychev et al. [\[28\]](#page-10-32)
    synthesize code completions by identifying the highest-ranked sentences with a
    statistical language model. However, these approaches have limitations in scalability
    and are confined to simple scenarios. For example, they struggle to generate a
    complete program from scratch according to a natural language description.


    Subsequently, with the rise of deep learning, neural networks including convolutional
    neural networks (CNNs) [\[19\]](#page-10-33) and various recurrent neural networks
    (RNNs) [\[21\]](#page-10-34) are widely adopted to approach the natural-language-to-code
    task. Ling et al. [\[20\]](#page-10-35) treat the code generation task as a sequence-to-sequence
    problem, and then propose an LSTM-based neural network architecture to generate
    code from natural language. Sun et al. [\[30\]](#page-10-36) design a grammar-based
    structural CNN to generate a program by predicting the grammar rules of the programming
    language. Although these works achieve significant improvement in flexibility
    and scalability, they still exhibit poor generalization ability due to limited
    language understanding.


    After the introduction of the Transformer [\[33\]](#page-10-37), numerous large
    language models (LLMs) have been proposed and have demonstrated impressive results
    in automatic code generation. For example, Codex [\[5\]](#page-10-2) can solve
    72.31% of challenging Python programming problems created by humans. We remark
    that while LLMs exhibit remarkable proficiency in programming, instructing them
    directly to complete complex software development tasks is challenging. In response,
    researchers have put forth a series of LLM-based multiagent frameworks to automatically
    generate software with an initial idea.


    Li et al. [\[18\]](#page-10-10) propose role-playing, a communicative agent framework,
    to complete a task (not limited to software development tasks) by having three
    agents communicate with each other. Specifically, when the human user specifies
    a task to implement, a task specifier agent specifies a role to play for the assistant
    agent and user agent respectively, and then the two roles engage in conversation
    to complete the task. ChatDev [\[24\]](#page-10-5) divides the development process
    into four stages: designing, coding, testing, and documenting. Each stage involves
    a group of agents to solve a distinct subtask, such as deciding the software modality
    and programming language at the designing phase. Note that the subtask of each
    stage is further decomposed into atomic subtasks, each of which is addressed by
    two agents engaging in conversation. Inspired by the human workflows, MetaGPT
    incorporates Standardized Operating Procedures (SOPs) into their framework to
    coordinate agents. MetaGPT also mirrors the waterfall model and breaks down the
    development process into several phases. The main difference is that each agent
    in MetaGPT solves a subtask independently and produces standardized action outputs
    for knowledge sharing. We remark that these existing frameworks exclude humans
    from the development


    Experimenting a New Programming Practice with LLMs Conference''17, July 2017,
    Washington, DC, USA


    process, and relying solely on the abilities of LLMs may undermine their effectiveness
    when facing complex tasks.


    ## <span id="page-10-11"></span>6 CONCLUSION


    In this work, we present an AI-powered software development framework. Different
    from existing approaches, our framework is designed to keep users lightly engaged
    when solving a complex task, emphasizing the importance of human-engaged requirement
    analysis and system validation. To objectively assess the capabilities of completing
    software development tasks, we have built a novel benchmark, each task of which
    is equipped with a list of use cases for reference during assessment. The evaluation
    results demonstrate that our framework significantly improves the task pass rate
    while consuming fewer tokens.


    ## REFERENCES


    - <span id="page-10-27"></span>[1] AISD. 2023. [https://drive.google.com/drive/folders/](
    https://drive.google.com/drive/folders/1i0UWqy1K4WwaCLnb7yhyQfV8UqjdXSkl?usp=sharing)
    [1i0UWqy1K4WwaCLnb7yhyQfV8UqjdXSkl?usp=sharing.]( https://drive.google.com/drive/folders/1i0UWqy1K4WwaCLnb7yhyQfV8UqjdXSkl?usp=sharing)
    Accessed Dec 15, 2023.

    - <span id="page-10-31"></span>[2] Miltiadis Allamanis and Charles Sutton. 2014.
    Mining idioms from source code. In Proceedings of the 22nd acm sigsoft international
    symposium on foundations of software engineering. 472–483.

    - <span id="page-10-9"></span>[3] Jacob Austin, Augustus Odena, Maxwell Nye, Maarten
    Bosma, Henryk Michalewski, David Dohan, Ellen Jiang, Carrie Cai, Michael Terry,
    Quoc Le, et al. 2021. Program synthesis with large language models. arXiv preprint
    arXiv:2108.07732 (2021).

    - <span id="page-10-22"></span>[4] Tom Brown, Benjamin Mann, Nick Ryder, Melanie
    Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam,
    Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners.
    Advances in neural information processing systems 33 (2020), 1877–1901.

    - <span id="page-10-2"></span>[5] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming
    Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda,
    Nicholas Joseph, Greg Brockman, et al. 2021. Evaluating large language models
    trained on code. arXiv preprint arXiv:2107.03374 (2021).

    - <span id="page-10-14"></span>[6] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,
    Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles
    Sutton, Sebastian Gehrmann, et al. 2023. Palm: Scaling language modeling with
    pathways. Journal of Machine Learning Research 24, 240 (2023), 1–113.

    - <span id="page-10-17"></span>[7] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng,
    Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022. A survey
    for in-context learning. arXiv preprint arXiv:2301.00234 (2022).

    - <span id="page-10-25"></span>[8] A. Ferrari and A. Sangiovanni-Vincentelli.
    1999. System design: traditional concepts and new paradigms. In Proceedings 1999
    IEEE International Conference on Computer Design: VLSI in Computers and Processors
    (Cat. No.99CB37040). 2–12. <https://doi.org/10.1109/ICCD.1999.808256>

    - <span id="page-10-13"></span>[9] Luciano Floridi and Massimo Chiriatti. 2020.
    GPT-3: Its nature, scope, limits, and consequences. Minds and Machines 30 (2020),
    681–694.

    - <span id="page-10-28"></span>[10] Geeksforgeeks. 2023. [https://www.geeksforgeeks.org/track-objects-with](https://www.geeksforgeeks.org/track-objects-with-camshift-using-opencv/?ref=lbp
    )[camshift-using-opencv/?ref=lbp.](https://www.geeksforgeeks.org/track-objects-with-camshift-using-opencv/?ref=lbp
    ) Accessed Dec 15, 2023.

    - [11] Github. 2022. [https://https://github.com/CharlesPikachu/Games/tree/master.](https://https://github.com/CharlesPikachu/Games/tree/master
    ) Accessed Dec 15, 2023.

    - <span id="page-10-29"></span>[12] Github. 2023. [https://github.com/OpenBMB/ChatDev/blob/main/Contribution.](https://github.com/OpenBMB/ChatDev/blob/main/Contribution.md
    ) [md.](https://github.com/OpenBMB/ChatDev/blob/main/Contribution.md ) Accessed
    Dec 15, 2023.

    - <span id="page-10-6"></span>[13] Sirui Hong, Xiawu Zheng, Jonathan Chen, Yuheng
    Cheng, Ceyao Zhang, Zili Wang, Steven Ka Shing Yau, Zijuan Lin, Liyang Zhou, Chenyu
    Ran, et al. 2023. Metagpt: Meta programming for multi-agent collaborative framework.
    arXiv preprint arXiv:2308.00352 (2023).

    - <span id="page-10-30"></span>[14] Susmit Jha, Sumit Gulwani, Sanjit A Seshia,
    and Ashish Tiwari. 2010. Oracleguided component-based program synthesis. In Proceedings
    of the 32nd ACM/IEEE International Conference on Software Engineering-Volume 1.
    215–224.

    - <span id="page-10-15"></span>[15] Jacob Devlin Ming-Wei Chang Kenton and Lee
    Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers
    for language understanding. In Proceedings of naacL-HLT, Vol. 1. 2.

    - <span id="page-10-19"></span>[16] Takeshi Kojima, Shixiang Shane Gu, Machel
    Reid, Yutaka Matsuo, and Yusuke Iwasawa. 2022. Large language models are zero-shot
    reasoners. Advances in neural information processing systems 35 (2022), 22199–22213.

    - <span id="page-10-26"></span>[17] Aobo Kong, Shiwan Zhao, Hao Chen, Qicheng
    Li, Yong Qin, Ruiqi Sun, and Xin Zhou. 2023. Better zero-shot reasoning with role-play
    prompting. arXiv preprint arXiv:2308.07702 (2023).

    - <span id="page-10-10"></span>[18] Guohao Li, Hasan Abed Al Kader Hammoud, Hani
    Itani, Dmitrii Khizbullin, and Bernard Ghanem. 2023. Camel: Communicative agents
    for" mind" exploration of


    large scale language model society. arXiv preprint arXiv:2303.17760 (2023).


    - <span id="page-10-33"></span>[19] Zewen Li, Fan Liu, Wenjie Yang, Shouheng Peng,
    and Jun Zhou. 2021. A survey of convolutional neural networks: analysis, applications,
    and prospects. IEEE transactions on neural networks and learning systems (2021).

    - <span id="page-10-35"></span>[20] Wang Ling, Phil Blunsom, Edward Grefenstette,
    Karl Moritz Hermann, Tomáš Kočiský, Fumin Wang, and Andrew Senior. 2016. Latent
    Predictor Networks for Code Generation. In Proceedings of the 54th Annual Meeting
    of the Association for Computational Linguistics (Volume 1: Long Papers), Katrin
    Erk and Noah A. Smith (Eds.). Association for Computational Linguistics, Berlin,
    Germany, 599–609. <https://doi.org/10.18653/v1/P16-1057>

    - <span id="page-10-34"></span>[21] Zachary C Lipton, John Berkowitz, and Charles
    Elkan. 2015. A critical review of recurrent neural networks for sequence learning.
    arXiv preprint arXiv:1506.00019 (2015).

    - <span id="page-10-20"></span>[22] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao
    Jiang, Hiroaki Hayashi, and Graham Neubig. 2023. Pre-train, prompt, and predict:
    A systematic survey of prompting methods in natural language processing. Comput.
    Surveys 55, 9 (2023), 1–35.

    - <span id="page-10-3"></span>[23] Ansong Ni, Pengcheng Yin, Yilun Zhao, Martin
    Riddell, Troy Feng, Rui Shen, Stephen Yin, Ye Liu, Semih Yavuz, Caiming Xiong,
    et al. 2023. L2CEval: Evaluating Language-to-Code Generation Capabilities of Large
    Language Models. arXiv preprint arXiv:2309.17446 (2023).

    - <span id="page-10-5"></span>[24] Chen Qian, Xin Cong, Cheng Yang, Weize Chen,
    Yusheng Su, Juyuan Xu, Zhiyuan Liu, and Maosong Sun. 2023. Communicative agents
    for software development. arXiv preprint arXiv:2307.07924 (2023).

    - <span id="page-10-21"></span>[25] Shuofei Qiao, Yixin Ou, Ningyu Zhang, Xiang
    Chen, Yunzhi Yao, Shumin Deng, Chuanqi Tan, Fei Huang, and Huajun Chen. 2022.
    Reasoning with language model prompting: A survey. arXiv preprint arXiv:2212.09597
    (2022).

    - <span id="page-10-12"></span>[26] Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan
    Shao, Ning Dai, and Xuanjing Huang. 2020. Pre-trained models for natural language
    processing: A survey. Science China Technological Sciences 63, 10 (2020), 1872–1897.

    - <span id="page-10-16"></span>[27] Alec Radford, Jeffrey Wu, Rewon Child, David
    Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised
    multitask learners. OpenAI blog 1, 8 (2019), 9.

    - <span id="page-10-32"></span>[28] Veselin Raychev, Martin Vechev, and Eran Yahav.
    2014. Code completion with statistical language models. In Proceedings of the
    35th ACM SIGPLAN conference on programming language design and implementation.
    419–428.

    - <span id="page-10-4"></span>[29] Baptiste Roziere, Jonas Gehring, Fabian Gloeckle,
    Sten Sootla, Itai Gat, Xiaoqing Ellen Tan, Yossi Adi, Jingyu Liu, Tal Remez, Jérémy
    Rapin, et al. 2023. Code llama: Open foundation models for code. arXiv preprint
    arXiv:2308.12950 (2023).

    - <span id="page-10-36"></span>[30] Zeyu Sun, Qihao Zhu, Lili Mou, Yingfei Xiong,
    Ge Li, and Lu Zhang. 2019. A grammar-based structural cnn decoder for code generation.
    In Proceedings of the AAAI conference on artificial intelligence, Vol. 33. 7055–7062.

    - <span id="page-10-7"></span>[31] Samdyuti Suri, Sankar Narayan Das, Kapil Singi,
    Kuntal Dey, Vibhu Saujanya Sharma, and Vikrant Kaulgud. 2023. Software Engineering
    Using Autonomous Agents: Are We There Yet?. In 2023 38th IEEE/ACM International
    Conference on Automated Software Engineering (ASE). IEEE Computer Society, 1855–1857.

    - <span id="page-10-8"></span>[32] Haoye Tian, Weiqi Lu, Tsz On Li, Xunzhu Tang,
    Shing-Chi Cheung, Jacques Klein, and Tegawendé F Bissyandé. 2023. Is ChatGPT the
    Ultimate Programming Assistant–How far is it? arXiv preprint arXiv:2304.11938
    (2023).

    - <span id="page-10-37"></span>[33] Ashish Vaswani, Noam Shazeer, Niki Parmar,
    Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.
    2017. Attention is all you need. Advances in neural information processing systems
    30 (2017).

    - <span id="page-10-24"></span>[34] Lei Wang, Chen Ma, Xueyang Feng, Zeyu Zhang,
    Hao Yang, Jingsen Zhang, Zhiyuan Chen, Jiakai Tang, Xu Chen, Yankai Lin, et al.
    2023. A survey on large language model based autonomous agents. arXiv preprint
    arXiv:2308.11432 (2023).

    - <span id="page-10-23"></span>[35] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten
    Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. 2022. Chain-of-thought prompting
    elicits reasoning in large language models. Advances in Neural Information Processing
    Systems 35 (2022), 24824–24837.

    - <span id="page-10-18"></span>[36] Zhiyuan Zeng, Jiatong Yu, Tianyu Gao, Yu Meng,
    Tanya Goyal, and Danqi Chen. 2023. Evaluating large language models at evaluating
    instruction following. arXiv preprint arXiv:2310.07641 (2023).

    - <span id="page-10-1"></span>[37] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi
    Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min, Beichen Zhang, Junjie Zhang, Zican
    Dong, et al. 2023. A survey of large language models. arXiv preprint arXiv:2303.18223
    (2023).

    - <span id="page-10-0"></span>[38] Barret Zoph, Colin Raffel, Dale Schuurmans,
    Dani Yogatama, Denny Zhou, Don Metzler, Ed H. Chi, Jason Wei, Jeff Dean, Liam
    B. Fedus, Maarten Paul Bosma, Oriol Vinyals, Percy Liang, Sebastian Borgeaud,
    Tatsunori B. Hashimoto, and Yi Tay. 2022. Emergent abilities of large language
    models. TMLR (2022).'
- title: "Applying Bayesian Data Analysis for Causal Inference about Requirements\n\
    \  Quality: A Controlled Experiment"
  abstract: 'It is commonly accepted that the quality of requirements specifications

    impacts subsequent software engineering activities. However, we still lack

    empirical evidence to support organizations in deciding whether their

    requirements are good enough or impede subsequent activities. We aim to

    contribute empirical evidence to the effect that requirements quality defects

    have on a software engineering activity that depends on this requirement. We

    conduct a controlled experiment in which 25 participants from industry and

    university generate domain models from four natural language requirements

    containing different quality defects. We evaluate the resulting models using

    both frequentist and Bayesian data analysis. Contrary to our expectations, our

    results show that the use of passive voice only has a minor impact on the

    resulting domain models. The use of ambiguous pronouns, however, shows a strong

    effect on various properties of the resulting domain models. Most notably,

    ambiguous pronouns lead to incorrect associations in domain models. Despite

    being equally advised against by literature and frequentist methods, the

    Bayesian data analysis shows that the two investigated quality defects have

    vastly different impacts on software engineering activities and, hence, deserve

    different levels of attention. Our employed method can be further utilized by

    researchers to improve reliable, detailed empirical evidence on requirements

    quality.'
  url: http://arxiv.org/abs/2401.01154v4
  keywords: ''
  document: "# Applying Bayesian Data Analysis for Causal Inference about Requirements\
    \ Quality: A Controlled Experiment\n\nJulian Frattini · Davide Fucci · Richard\
    \ Torkar · Lloyd Montgomery · Michael Unterkalmsteiner · Jannik Fischbach · Daniel\
    \ Mendez\n\nReceived: date / Accepted: date\n\nAbstract It is commonly accepted\
    \ that the quality of requirements specifications impacts subsequent software\
    \ engineering activities. However, we still lack empirical evidence to support\
    \ organizations in deciding whether their requirements are good enough or impede\
    \ subsequent activities. We aim to contribute empirical evidence to the effect\
    \ that requirements quality defects have on a software engineering activity that\
    \ depends on this requirement. We conduct a controlled experiment in which 25\
    \ participants from industry and university generate domain models from four natural\
    \ language requirements containing different quality defects. We evaluate the\
    \ resulting models using both frequentist and Bayesian data analysis. Contrary\
    \ to our expectations, our results show that the use of passive voice only has\
    \ a minor impact on the resulting domain models. The use of ambiguous pronouns,\
    \ however, shows a strong effect on various properties of the resulting domain\
    \ models. Most no-\n\nR. Torkar\n\nChalmers and University of Gothenburg, 41756\
    \ G¨oteborg, Sweden Stellenbosch Institute for Advanced Study (STIAS), Stellenbosch,\
    \ South Africa E-mail: richard.torkar@gu.se\n\nL. Montgomery University of Hamburg,\
    \ Mittelweg 177, 20148 Hamburg, Germany E-mail: lloyd.montgomery@uni-hamburg.de\n\
    \nJ. Fischbach Netlight Consulting GmbH, Prannerstraße 4, 80333 M¨unchen, Germany\
    \ E-mail: jannik.fischbach@netlight.com\n\nJ. Fischbach, D. Mendez fortiss GmbH,\
    \ Guerickestraße 25, 80805 M¨unchen, Germany E-mail: {lastname}@fortiss.org\n\n\
    - This version of the article has been accepted for publication, after peer review\
    \ (when applicable) but is not the Version of Record and does not reflect post-acceptance\
    \ improvements, or any corrections. The Version of Record is available online\
    \ at: <http://dx.doi.org/10.1007/s10664-024-10582-1>\n\nJ. Frattini, D. Fucci,\
    \ M. Unterkalmsteiner, and D. Mendez\n\nBlekinge Institute of Technology, Valhallav¨agen\
    \ 1, 37140 Karlskrona, Sweden\n\nE-mail: {firstname}.{lastname}@bth.se\n\ntably,\
    \ ambiguous pronouns lead to incorrect associations in domain models. Despite\
    \ being equally advised against by literature and frequentist methods, the Bayesian\
    \ data analysis shows that the two investigated quality defects have vastly different\
    \ impacts on software engineering activities and, hence, deserve different levels\
    \ of attention. Our employed method can be further utilized by researchers to\
    \ improve reliable, detailed empirical evidence on requirements quality.\n\nKeywords\
    \ Requirements Engineering · Requirements Quality · Experiment · Replication ·\
    \ Bayesian Data Analysis\n\n# 1 Introduction\n\nSoftware requirements specify\
    \ the needs and constraints that stakeholders impose on a desired system. Software\
    \ requirements specifications (SRS), the explicit manifestation of requirements\
    \ as an artifact [\\[78\\]](#page-47-0), serve as input for various subsequent\
    \ software engineering (SE) activities, such as deriving a software architecture,\
    \ implementing features, or generating test cases [\\[79\\]](#page-47-1). As a\
    \ consequence, the quality of an SRS impacts the quality of requirements-dependent\
    \ activities [\\[37,](#page-45-0) [38,](#page-45-1) [48\\]](#page-46-0). A quality\
    \ defect in an SRS—for example, an ambiguous formulation—can cause differing interpretations\
    \ and result in the design and implementation of a solution that does not meet\
    \ the stakeholders' needs [\\[77\\]](#page-47-2). The inherent complexity of natural\
    \ language (NL), which is most commonly used for specifying requirements [\\[43\\\
    ]](#page-46-1), aggravates this challenge further. Since quality defects are understood\
    \ to scale in cost for removal [\\[9\\]](#page-44-0), organizations are interested\
    \ in identifying and removing these defects as early as possible [\\[80\\]](#page-48-0).\n\
    \nWithin the requirements engineering (RE) research domain, the field of requirements\
    \ quality research aims to meet this challenge [\\[80\\]](#page-48-0). Requirements\
    \ quality research has already identified several attributes of requirements quality\
    \ [\\[80\\]](#page-48-0) (e.g., unambiguity, completeness, consistency) and proposes\
    \ quality factors, i.e., requirements writing rules (e.g., the use of passive\
    \ voice being associated with bad quality [\\[36\\]](#page-45-2)) as well as tools\
    \ that automatically detect alleged quality defects [\\[35\\]](#page-45-3). However,\
    \ existing approaches fall short in at least three regards [\\[48\\]](#page-46-0):\
    \ i) only a fraction of publications provide empirical evidence that would demonstrate\
    \ the impact of quality defects [\\[80\\]](#page-48-0), ii) the few empirical\
    \ studies that do so largely ignore potentially confounding context factors [\\\
    [65,](#page-47-3) [81\\]](#page-48-1), and iii) the analyses conducted in existing\
    \ publications do not go beyond binary insights (i.e., a quality factor does have\
    \ an impact or it does not) [\\[25,](#page-45-4) [36\\]](#page-45-2). These gaps\
    \ have impeded the adoption of requirements quality research in practice [\\[43\\\
    ]](#page-46-1).\n\nIn this article, we aim to address the above-mentioned shortcomings\
    \ by i) conducting a controlled experiment with 25 participants simulating a requirementsdependent\
    \ activity (i.e., domain modeling) using four natural-language requirements as\
    \ input. The experiment contributes empirical evidence on the impact of two commonly\
    \ researched quality factors passive voice [\\[36\\]](#page-45-2) and ambiguous\
    \ pronouns [\\[31\\]](#page-45-5). The investigation of the impact of passive\
    \ voice is\n\na conceptual replication [\\[2\\]](#page-44-1) of the only controlled\
    \ experiment studying the impact of passive voice on domain modeling [\\[36\\\
    ]](#page-45-2) known to us. Therefore, our experiment also strengthens the robustness\
    \ of their conclusions by providing diagnostic evidence [\\[83\\]](#page-48-2).\
    \ Further, we ii) collect data about relevant context factors such as experience\
    \ in software engineering (SE) and RE, domain knowledge, and task experience,\
    \ and integrate these data in our data analysis. Finally, we iii) contrast the\
    \ state-of-the-art frequentist data analysis (FDA) with Bayesian data analysis\
    \ (BDA), which entails both a causal framework and Bayesian modeling for statistical\
    \ causal inference [\\[76\\]](#page-47-4). The latter has recently been popularized\
    \ in SE research [\\[52\\]](#page-46-2) since it generates more nuanced empirical\
    \ insights. Our study is categorized as a laboratory experiment in a contrived\
    \ setting [\\[104\\]](#page-49-0), isolating the effect of the selected quality\
    \ factors of interest. The causal inference of their impact contributes to our\
    \ long-term goal of providing an empirically grounded understanding of the impact\
    \ of requirements quality. This will support organizations in assessing their\
    \ requirements and detecting relevant quality defects early.\n\nThis paper makes\
    \ the following contributions:\n\n- 1. a controlled experiment investigating the\
    \ impact of requirements quality;\n- 2. a conceptual replication of the only controlled\
    \ experiment investigating the impact of passive voice [\\[36\\]](#page-45-2);\n\
    - 3. the application of BDA to requirements quality research, which is among the\
    \ first of its kind in RE; and\n- 4. an archived replication package containing\
    \ all supplementary material, including protocols and guidelines for data collection\
    \ and extraction, the raw data, analysis scripts, figures, and results [\\[46\\\
    ]](#page-46-3).\n\nThe remainder of this manuscript is organized as follows. Section\
    \ [2](#page-2-0) introduces relevant related work. We present our research method\
    \ in Section [3](#page-9-0) and the results in Section [4.](#page-28-0) We discuss\
    \ these results in Section [5](#page-36-0) before concluding our manuscript in\
    \ Section [6.](#page-43-0)\n\n# <span id=\"page-2-0\"></span>2 Background\n\n\
    Section [2.1](#page-2-1) introduces the research domain of this work by summarizing\
    \ existing research on requirements quality. Section [2.2](#page-8-0) motivates\
    \ BDA—the statistical tool employed in this work—by explaining its adoption in\
    \ SE research.\n\n# <span id=\"page-2-1\"></span>2.1 Requirements Quality\n\n\
    Section [2.1.1](#page-3-0) introduces the general area of requirements quality\
    \ research and Section [2.1.2](#page-3-1) presents two research directions within.\
    \ Section [2.1.3](#page-6-0) summarizes the three major shortcomings that currently\
    \ challenge requirements quality research.\n\n# <span id=\"page-3-0\"></span>2.1.1\
    \ Requirements Quality Research\n\nIt is commonly accepted that the quality of\
    \ requirements specifications impacts subsequent SE activities, which depend on\
    \ these specifications [\\[38,](#page-45-1) [48\\]](#page-46-0). Quality defects\
    \ in requirements specifications may, therefore, ultimately cause budget overrun\
    \ [\\[91\\]](#page-48-3) or even project failure [\\[77\\]](#page-47-2). Two further\
    \ factors aggravate the effect. Firstly, natural language (NL), which is inherently\
    \ ambiguous and, hence, prone to quality defects, remains the most commonly used\
    \ syntax to specify requirements [\\[45,](#page-46-4) [109\\]](#page-49-1). Secondly,\
    \ the cost of removing quality defects scales the longer they remain undetected\
    \ [\\[9\\]](#page-44-0). For example, clarifying an ambiguous requirements specification\
    \ takes comparatively less effort than reimplementing a faulty implementation\
    \ based on the ambiguous specification. However, it requires detecting the ambiguity\
    \ and predicting that the ambiguity potentially causes the implementation to become\
    \ faulty before it happens. These circumstances necessitate managing the quality\
    \ of requirements specifications to detect and remove requirements quality defects\
    \ preemptively.\n\nRequirements quality research seeks answers to this need [\\\
    [80\\]](#page-48-0). One main driver of this research is requirements quality\
    \ factors [\\[49\\]](#page-46-5), i.e., metrics that can be evaluated on NL requirements\
    \ specifications to determine quality defects. For example, the voice of an NL\
    \ sentence (active or passive) is considered a quality factor, as the use of passive\
    \ voice is associated with bad requirements quality due to potential omission\
    \ of information [\\[36\\]](#page-45-2). Automatic detection techniques using\
    \ natural language processing (NLP) [\\[116\\]](#page-49-2) can automatically\
    \ evaluate quality factors to detect defects in NL requirements specifications\
    \ [\\[35\\]](#page-45-3).\n\n# <span id=\"page-3-1\"></span>2.1.2 Existing Research\
    \ on Passive Voice and Ambiguous Pronouns\n\nWe present two examples of commonly\
    \ researched requirements quality factors in the following sections.\n\nPassive\
    \ Voice One commonly researched requirements quality factor is using passive voice\
    \ in natural language requirements specifications. A sentence in passive voice\
    \ elevates the semantic patient rather than the semantic agent of the main verb\
    \ to the grammatical subject [\\[85\\]](#page-48-4). For example, in the passive\
    \ voice sentence \"Web-based displays of the most current ASPERA-3 data shall\
    \ be provided for public view.\", the patient of the providing process the \"\
    web-based displays\"—becomes the grammatical subject of the sentence. Even though\
    \ passive voice sentences may still contain the semantic agent (e.g., \"Web-based\
    \ displays of the most current ASPERA-3 data shall be provided for public view\
    \ by a front-end.\"), writers often omit it intentionally or unintentionally [\\\
    [73\\]](#page-47-5). Figure [1](#page-4-0) visualizes the omission of the semantic\
    \ agent in this exemplary requirement specification.\n\nOmitting the semantic\
    \ agent of a sentence in a passive voice formulation obscures critical information\
    \ in a requirements specification. Hence, requirements quality guidelines advise\
    \ against using passive voice [\\[94\\]](#page-48-5). However, while\n\n<span\
    \ id=\"page-4-0\"></span>![](_page_4_Figure_1.jpeg)\n\nFig. 1: Formalization of\
    \ a requirements specification R2 using passive voice\n\nseveral guidelines advise\
    \ against the use of passive voice based on the theoretical argument of information\
    \ omission presented above [\\[57,](#page-46-6) [58,](#page-46-7) [61,](#page-47-6)\
    \ [72,](#page-47-7) [94\\]](#page-48-5), only two papers investigate whether passive\
    \ voice has an actual impact on requirements quality: Krisch et al. let domain\
    \ experts rate active and passive voice requirements as either problematic or\
    \ unproblematic. They concluded that most passive voice requirements were unproblematic\
    \ as the surrounding context information compensated the omission of the semantic\
    \ agent of the sentence [\\[73\\]](#page-47-5). Femmer et al. conducted an empirical\
    \ investigation of the impact of the use of passive voice in requirements specification\
    \ on the domain modeling activity in a controlled experiment. They concluded that\
    \ passive voice only causes missing relationships from the domain model, but not\
    \ missing actors or entities as initially assumed [\\[36\\]](#page-45-2). The\
    \ limited evidence for the harmfulness of using passive voice in requirements\
    \ specifications [\\[36,](#page-45-2)[73\\]](#page-47-5) stands in stark contrast\
    \ to the amount of tools and approaches proposed to automatically detect quality\
    \ defects by identifying the use of passive voice [\\[27,](#page-45-6)[35,](#page-45-3)[38,](#page-45-1)[40,](#page-45-7)[57,](#page-46-6)[61,](#page-47-6)[71,](#page-47-8)[72,](#page-47-7)[86,](#page-48-6)[95,](#page-48-7)[103\\\
    ]](#page-49-3).\n\nAmbiguous Pronouns The inherent ambiguity of natural language\
    \ [\\[93\\]](#page-48-8) poses several challenges for requirements specifications\
    \ using natural language [\\[4,](#page-44-2)[84\\]](#page-48-9). One commonly\
    \ researched requirements quality factor related to ambiguity is the use of ambiguous\
    \ pronouns, which is a type of referential ambiguity [\\[8\\]](#page-44-3). An\
    \ ambiguous pronoun exhibits anaphoric ambiguity, that \"occurs when a pronoun\
    \ can plausibly refer to different entities and thus be interpreted differently\
    \ by different readers\" [\\[31\\]](#page-45-5). For example, in the requirements\
    \ specification \"The data processing unit stores telemetric data for scientific\
    \ evaluation; therefore, it needs to comply with the FAIR principles of data storage.\"\
    , the pronoun it could syntactically refer to the \"data processing unit\", the\
    \ \"telemetric data\",\n\n<span id=\"page-5-0\"></span>![](_page_5_Figure_1.jpeg)\n\
    \nFig. 2: Formalization of a requirements specification R3 using an ambiguous\
    \ pronoun\n\nor the \"scientific evaluation.\" Figure [2](#page-5-0) visualizes\
    \ how a reader can resolve the reference.\n\nTo avoid deviating interpretations\
    \ of a requirements specification, established requirements quality guidelines\
    \ advise against the use of ambiguous pronouns [\\[94\\]](#page-48-5) at the expense\
    \ of conciseness. However, the number of publications proposing tools and algorithms\
    \ to automatically identify and resolve ambiguous pronouns [\\[20,](#page-45-8)[31](#page-45-5)[–33,](#page-45-9)[68,](#page-47-9)[98,](#page-48-10)[100,](#page-48-11)[114,](#page-49-4)[115\\\
    ]](#page-49-5) significantly outweighs the singular publication that actually\
    \ has empirically investigated the effect of ambiguous pronouns. Kamsties et al.\
    \ investigated the effects of formalizing requirements, which included evaluating\
    \ the propagation of ambiguous pronouns from NL into more formal specifications\
    \ [\\[67\\]](#page-47-10). Their experiment involving students revealed that 20-37%\
    \ of all ambiguous pronouns were incorrectly resolved while formalizing NL requirements\
    \ specifications. While Kamsties et al. concluded that requirements formalization\
    \ does not sufficiently resolve ambiguities, these results also support the assumption\
    \ that ambiguous pronouns propagate into subsequent artifacts depending on the\
    \ requirements specifications. On the contrary, the scarce empirical work on the\
    \ effect of ambiguity in general (not specifically ambiguous pronouns) agrees\
    \ that ambiguity has a negligible effect on downstream software engineering activities\
    \ [\\[15,](#page-44-4) [91\\]](#page-48-3). Other than these empirical contributions,\
    \ the aforementioned publications proposing solutions rather than investigating\
    \ the relevance of the problem refer to deontic guidelines [\\[5,](#page-44-5)[94\\\
    ]](#page-48-5), anecdotal evidence about ambiguity in general [\\[11,](#page-44-6)[21,](#page-45-10)[39,](#page-45-11)[42\\\
    ]](#page-46-8), or—in very rare cases—cognitive science theory [\\[93\\]](#page-48-8).\n\
    \n# <span id=\"page-6-0\"></span>2.1.3 Shortcomings in Requirements Quality Research\n\
    \nThe previous examples highlight at least three shortcomings from which requirements\
    \ quality research suffers.\n\nLack of empirical evidence First, the relevance\
    \ of quality factors like passive voice or ambiguous pronouns is rarely determined\
    \ empirically [\\[48\\]](#page-46-0). Scientific contributions proposing solutions\
    \ (i.e., detecting or removing quality defects) outweigh those investigating the\
    \ actual extent of the assumed problem. Without knowledge about this extent, it\
    \ remains unclear whether a proposed solution addresses a problem that is actually\
    \ relevant to practice.\n\nPrevious systematic research has come to the same conclusion.\
    \ For example, in a previous systematic study, we determined that the effect of\
    \ quality defects is determined empirically in only 18% of the publications included\
    \ in our sample [\\[48\\]](#page-46-0). Bano et al. found only two publications\
    \ within their sample of 28 studies that empirically investigated the importance\
    \ of ambiguity detection [\\[4\\]](#page-44-2). Montgomery et al. systematically\
    \ investigated empirical research on requirements quality research and also concluded\
    \ that most studies focus on improving requirements quality (i.e., detecting and\
    \ removing defects) rather than defining or evaluating it (i.e., understanding\
    \ the actual effect) [\\[80\\]](#page-48-0). Instead, most requirements quality\
    \ publications draw on anecdotal evidence and unproven hypotheses [\\[48\\]](#page-46-0).\
    \ This lack of empirical evidence undermines the trust in requirements quality\
    \ research and hinders its adoption in practice [\\[34,](#page-45-12)[43,](#page-46-1)[90\\\
    ]](#page-48-12).\n\nLack of context Second, existing research mostly ignores the\
    \ influence of context factors on the effect of quality defects [\\[48\\]](#page-46-0).\
    \ Context factors encompass all human and organizational factors influencing the\
    \ downstream SE activities involving requirements specification [\\[89\\]](#page-48-13).\
    \ For example, the domain experience of a stakeholder or the process model used\
    \ during development may mediate the effect of ambiguity in requirements specifications\
    \ [\\[91\\]](#page-48-3).\n\nRequirements quality research has acknowledged the\
    \ relevance of context factors to requirements quality [\\[65,](#page-47-3)[81\\\
    ]](#page-48-1). Recent propositions have advocated for a shift away from the unrealistic\
    \ goal of developing a one-size-fits-all solution to requirements quality and,\
    \ instead, moving towards more context-sensitive research [\\[12,](#page-44-7)[77\\\
    ]](#page-47-2). However, this initiative has shown little effect in requirements\
    \ quality research so far [\\[48\\]](#page-46-0).\n\nLack of detailed projections\
    \ Third, the few empirical contributions to requirements quality research limit\
    \ their insights to categorical projections, i.e., the evaluation of a quality\
    \ factor on a requirements specification (e.g., using passive voice or not using\
    \ passive voice) are projected on a categorical scale (e.g., good quality or bad\
    \ quality). Most commonly, the categorical output space consists of two [\\[25\\\
    ]](#page-45-4) (impact or no impact) or three [\\[37\\]](#page-45-0) (positive\
    \ impact, no impact, or negative impact) categories. This simplification inhibits\
    \ a nuanced comparison of different quality factors. On an absolute scale, a quality\
    \ factor\n\n<span id=\"page-7-0\"></span>![](_page_7_Figure_1.jpeg)\n\nFig. 3:\
    \ Reduced version of the activity-based Requirements Quality Theory [\\[48\\]](#page-46-0)\n\
    \nhaving an impact does not automatically entail that this impact is significant\
    \ and warrants resources for detection and mitigation. On a relative scale, two\
    \ quality factors that have an impact are impossible to compare to allocate resources\
    \ towards the more significant one. Consequently, even empirical contributions\
    \ to the field of requirements quality lack sophisticated insights that would\
    \ support organizations in determining and dealing with relevant quality factors\
    \ to control during the RE phase.\n\n# Requirements Quality Research Gaps\n\n\
    Requirements quality research suffers from (1) a lack of empirical evidence about\
    \ the relevance of quality factors, (2) a lack of contextsensitivity, and (3)\
    \ evaluations of impact that are more fine-grained than categorical.\n\n# 2.1.4\
    \ Requirements Quality Theory\n\nBased on the identification of the above-mentioned\
    \ shortcomings, we have developed a requirements quality theory in previous research\
    \ [\\[48\\]](#page-46-0). This theory frames requirements quality as the impact\
    \ that properties of requirements specifications (called the quality factors)\
    \ in combination with context factors have on the properties (called attributes)\
    \ of activities that use these specifications as input. Figure [3](#page-7-0)\
    \ visualizes the requirements quality theory.\n\nThe requirements quality theory\
    \ facilitates overcoming the aforementioned shortcomings. Because the RQT makes\
    \ the quality of a requirements specification dependent on its impact on subsequent\
    \ activities, it demands empirical evidence about this impact before claiming\
    \ that a quality factor reflects actual requirements quality. The inclusion of\
    \ context factors in the definition of requirements quality mandates context-sensitivity.\
    \ The abstraction of the impact concept allows for more advanced relationships\
    \ between specifications and impacted activities than just the categorical type.\n\
    \nHowever, while the requirements quality research draws on mature software quality\
    \ research [\\[25,](#page-45-4) [110\\]](#page-49-6), it has not been actively\
    \ used yet. Even the predecessor of the theory [\\[37\\]](#page-45-0) was explicitly\
    \ ignored in follow-up research by its authors due to the complexity of its implementation\
    \ [\\[35\\]](#page-45-3). The work presented in this manuscript constitutes the\
    \ first application of the theory known to the authors.\n\n# <span id=\"page-8-0\"\
    ></span>2.2 Bayesian data analysis in software engineering\n\nIn recent years,\
    \ SE research has adopted Bayesian data analysis (BDA) for statistical causal\
    \ inference. BDA signifies a departure from frequentist methods like null-hypothesis\
    \ significance testing (NHST), the previous state-of-the-art in terms of inferential\
    \ statistics in SE research. NHST determines whether there is a \"statistically\
    \ significant\" difference between two or more distributions. Observations of\
    \ a dependent variable are stratified by an independent variable to obtain a binary\
    \ answer of whether or not different values of the independent variable correlate\
    \ with different distributions of the dependent variable.\n\nOpposed to that,\
    \ BDA encourages the use of causal frameworks [\\[76\\]](#page-47-4). These frameworks\
    \ make causal assumptions explicit [\\[29\\]](#page-45-13) and allow reasoning\
    \ about causally relevant variables [\\[87,](#page-48-14) [88\\]](#page-48-15).\
    \ Furthermore, BDA abstains from reducing complex variable distributions to binary\
    \ inference [\\[76\\]](#page-47-4). Instead, dependent variables are expressed\
    \ as a probability distribution, which preserves the natural uncertainty with\
    \ which any variable is determined. Similarly, the impact of any independent variable\
    \ on the dependent variable is expressed in terms of a probability distribution.\
    \ Using Bayes' Theorem, these assigned prior probability distributions are updated\
    \ with observed data to obtain a posterior probability distribution [\\[52\\]](#page-46-2).\
    \ Given the observed data, these posterior probability distributions model the\
    \ most likely impact of variable values. BDA methods are becoming widely adopted\
    \ also due to the modern computational power enabling Markov Chain Monte Carlo\
    \ (MCMC) randomized algorithms [\\[13\\]](#page-44-8), tools like Stan [\\[17\\\
    ]](#page-44-9), and libraries like rethinking [\\[76\\]](#page-47-4) and brms\
    \ [\\[16\\]](#page-44-10).\n\nWhile BDA is associated with a much steeper learning\
    \ curve than frequentist methods, it offers several advantages.\n\n- 1. BDA is\
    \ not based on the unsound probabilistic extension of the modus tollens like frequentist\
    \ hypothesis testing. The modus tollens (P → Q, ¬Q ∴ ¬P, or if P implies Q and\
    \ Q is false, then P must also be false) applies to propositional, Boolean logic,\
    \ but not when inferring from probabilities [\\[52\\]](#page-46-2).\n- 2. BDA\
    \ provides more complex insights than point-wise comparisons. Although BDA lacks\
    \ out-of-the-box statistical methods like frequentists' ttests that are simple\
    \ to apply, its results reflect the uncertainty of the data, the influence of\
    \ context, and they can be interpreted more intuitively.\n\n3. The causal framework\
    \ entailed by BDA makes causal assumptions explicit. The Bayesian workflow [\\\
    [56\\]](#page-46-9) makes any hypothesis of causal relations explicit. Analyses\
    \ become more transparent, and competing causal assumptions are easier to assess.\n\
    \nFuria et al. [\\[52\\]](#page-46-2), and Torkar et al. [\\[106\\]](#page-49-7)\
    \ advocate for the adoption of BDA in software engineering research by discussing\
    \ its advantages over the frequentist counterpart and mitigating its steep learning\
    \ curve with extensive demonstrations [\\[53\\]](#page-46-10). SE researchers\
    \ have begun to apply BDA in various evaluations. Previous studies have used BDA\
    \ to model bug-fixing time in open source software projects [\\[108\\]](#page-49-8),\
    \ to confirm the broken window theory in SE [\\[74\\]](#page-47-11), to investigate\
    \ gender differences in personality traits of software engineers [\\[96\\]](#page-48-16),\
    \ and to understand data-driven decision making practices [\\[105\\]](#page-49-9).\
    \ In the area of requirements engineering, BDA has been used to evaluate the effect\
    \ of obsolete requirements on software estimation [\\[60\\]](#page-47-12) and\
    \ to compare requirements prioritization criteria [\\[7\\]](#page-44-11).\n\n\
    # <span id=\"page-9-0\"></span>3 Method\n\nWe conducted a controlled experiment\
    \ that investigates the impact of requirements quality on a software engineering\
    \ activity. Our goal is both to (1) contribute empirical evidence to the effect\
    \ of quality defects and (2) compare the inferential capabilities of frequentist\
    \ (FDA) with Bayesian (BDA) statistics. Part of our experiment contributes a conceptual\
    \ replication [\\[2\\]](#page-44-1) of the study conducted and reported by Femmer\
    \ et al. [\\[36\\]](#page-45-2) and re-analyzed by us [\\[47\\]](#page-46-11),\
    \ as a subset of our hypotheses overlaps with theirs and our study contributes\
    \ diagnostic evidence for their claims [\\[83\\]](#page-48-2). Therefore, we report\
    \ the design of the experiment with emphasis on the replication following the\
    \ guidelines by Carver [\\[19\\]](#page-45-14).\n\n# 3.1 Goals\n\nWe formulate\
    \ our goal using the goal-question metric approach [\\[113\\]](#page-49-10). We\
    \ aim to characterize the impact of passive sentences and sentences using ambiguous\
    \ pronouns in requirements on domain modeling with respect to the quality of the\
    \ created domain model artifacts from the point of view of software engineers\
    \ in the context of an analysis of requirements from an industrial project. In\
    \ this definition, software engineer includes all roles that work with requirements\
    \ specifications, including software developers, requirements engineers, business\
    \ analysts, managers, and more. We derive the following research questions from\
    \ our goal:\n\n– RQ1: Do quality defects in NL requirements specifications harm\
    \ the domain modeling activity?\n\n- RQ1.1: Does the use of passive voice in NL\
    \ requirements specifications harm the duration, completeness, conciseness, and\
    \ correctness of the domain modeling activity?\n- RQ1.2: Does the use of ambiguous\
    \ pronouns in NL requirements specifications harm the duration, completeness,\
    \ conciseness, and correctness of the domain modeling activity?\n- RQ1.3: Does\
    \ the combined use of passive voice and ambiguous pronouns in NL requirements\
    \ specifications harm the duration, completeness, conciseness, and correctness\
    \ of the domain modeling activity?\n- RQ2: Do context factors influence the domain\
    \ modeling activity?\n\t- RQ2.1: Do context factors harm the domain modeling activity?\n\
    \t- RQ2.2: Do context factors mediate the impact of quality defects on the domain\
    \ modeling activity?\n\nRQ1 is dedicated to the main relationship of interest\
    \ between quality defects and an affected activity. RQ1.1 aligns with the research\
    \ question driving the original study [\\[36\\]](#page-45-2), which makes this\
    \ part of our study a conceptual replication. RQ1.2 extends the scope of the investigation\
    \ of quality factors with ambiguous pronouns. RQ1.3 investigates the interaction\
    \ between the two quality factors. RQ2 adds a context-sensitive perspective to\
    \ the relationship. RQ2.1 focuses on the direct effect that context factors have\
    \ on the affected activity. RQ2.2 investigates whether context factors mediate\
    \ the effect of quality defects on the activity.\n\n# 3.2 Original Experiment\n\
    \nThe original study [\\[36\\]](#page-45-2) addresses the research question \"\
    Is the use of passive sentences in requirements harmful for domain modeling?\"\
    \ The authors involved 15 university students from different study programs (2\
    \ B.Sc., 8 M.Sc., 4 Ph.D., one unknown) in a controlled randomized experiment\
    \ with a parallel design [\\[113\\]](#page-49-10). Each participant was assigned\
    \ to one of two groups and received seven requirements that were formulated either\
    \ using active or passive voice. The experimental task was to derive a domain\
    \ model from each requirement that contains all relevant actors, domain objects,\
    \ and associations between them. The study material and results are available\
    \ online.[1](#page-10-0)\n\nFor the dependent variable, the authors calculated\
    \ the number of missing domain model elements (i.e., actors, objects, and associations).\
    \ Although the authors also recorded context variables such as a categorical assessment\
    \ of general knowledge in SE and RE, these were not used in the analysis. The\
    \ analysis followed a frequentist approach performing a null-hypothesis significance\
    \ test for each of the three domain model elements to determine whether a statistically\
    \ significant difference between the experimental groups exists. The study shows\
    \ a statistically significant difference in the number of identified associations\
    \ but not in the number of actors or objects. The authors conclude\n\n<span id=\"\
    page-10-0\"></span><sup>1</sup> <https://doi.org/10.5281/zenodo.7499290>\n\nthat\
    \ the commonly assumed impact of passive voice on missing domain model actors\
    \ is actually negligible, but passive voice impedes the understanding of the relationships\
    \ between entities in the requirements specification.\n\n# 3.3 Reanalysis\n\n\
    The original study by Femmer et al. analyzed its data under simplified assumptions.\
    \ Among these is the assumption that the three dependent variables (number of\
    \ missing actors, objects, and associations) only depend on the main factor (use\
    \ of active or passive voice). We challenged this assumption in a reanalysis of\
    \ the original data [\\[47\\]](#page-46-11) for the following reasons:\n\n- 1.\
    \ In a small-scale experiment employing a parallel design, there is no measure\
    \ to control subject variability [\\[107\\]](#page-49-11), such that context factors\
    \ like experience or skill might affect the dependent variables.\n- 2. Missing\
    \ an actor or object in the domain model (i.e., a node) necessarily causes an\
    \ association to be missed (i.e., an edge that would have connected these nodes).\n\
    \nFigure [4a](#page-12-0) visualizes the causal assumptions of the original experiment\
    \ [\\[36\\]](#page-45-2) as a directed acyclic graph [\\[29\\]](#page-45-13) (the\
    \ syntax of which is further explained in Section [3.4.10\\)](#page-22-0) and\
    \ Figure [4b](#page-12-0) shows the revision in scope of the reanalysis [\\[47\\\
    ]](#page-46-11). The revision includes (1) two context factors that were already\
    \ recorded but not used in the original experiment, and (2) two causal relations\
    \ between the response variables.\n\nWe performed a re-analysis, i.e., an independent\
    \ analysis of the same data using a different statistical model [\\[59\\]](#page-47-13),\
    \ which is sometimes referred to as a test of robustness [\\[83\\]](#page-48-2).\
    \ During this re-analysis, we replaced the NHSTs with regression models that include\
    \ context factors and the affecting response variables in the case of missing\
    \ associations.\n\nThe results of this re-analysis agree with the original study\
    \ in that the effect of passive voice on the number of missing actors and objects\
    \ is negligible. However, the re-analysis disagrees with the original study regarding\
    \ the effect of passive voice on the number of missing associations. The re-analysis\
    \ determined that passive voice slightly increases the number of missing associations\
    \ (βpv = 0.7). Still, the confidence interval of this effect (CIpv = (−0.56, 1.90))\
    \ intersects 0 and is, therefore, not significant. On the other hand, the effect\
    \ of missing objects on missing associations was significant (βact = 1.12, CIact\
    \ = (0.32, 1.96)). The re-analysis did not find a significant effect of the available\
    \ context variables on the response variables. Our re-analysis concludes that\
    \ the effect of passive voice on the domain modeling activity is less significant\
    \ than originally assumed [\\[47\\]](#page-46-11).\n\n<span id=\"page-12-0\"></span>![](_page_12_Figure_1.jpeg)\n\
    \nFig. 4: Causal assumptions about the impact of passive voice\n\n# 3.4 Our Experiment\n\
    \nThe reanalysis [\\[47\\]](#page-46-11) of the study by Femmer et al. [\\[36\\\
    ]](#page-45-2) did improve the conclusion validity of the results but failed to\
    \ address other shortcomings. For example, the subject variability still threatened\
    \ the internal validity of the results due to the parallel design of the experiment\
    \ [\\[107\\]](#page-49-11), and the context factors were limited to those recorded\
    \ during the original study. Hence, we used their study as inspiration for our\
    \ own presented in this paper and aimed to improve upon the research design. During\
    \ the preparation of our study, we conferred with the authors of the original\
    \ study and made the following changes to the original study.\n\n- Experimental\
    \ design: We employ a factorial crossover instead of a parallel design, which\
    \ minimizes the risk of confounding (i.e., each participant acts as their own\
    \ control) while requiring a smaller sample [\\[107\\]](#page-49-11).\n- Independent\
    \ variables: This study investigates—in addition to using passive voice—the impact\
    \ of ambiguous pronouns in requirements specifications and their combined usage\
    \ to extend the range of requirements quality defects.\n- Dependent variables:\
    \ We merged two types of elements in the domain model (the nodes of the model,\
    \ i.e., actors and objects) into a single type entity because they represent the\
    \ same concept in the domain model (nodes) [\\[36\\]](#page-45-2) and the distribution\
    \ in our experimental objects is heavily skewed (16/17 entities are objects).\
    \ Furthermore, we increased the dependent variables by additionally evaluating\
    \ the number of superfluous enti-\n\nties, the number of wrong associations, and\
    \ the duration for creating the domain model.\n\n- Sampling strategy: We sample\
    \ from both students and practitioners of software engineering to more accurately\
    \ represent the target population of software engineers. This change aims at increasing\
    \ the external validity of our results [\\[3\\]](#page-44-12).\n- Instrumentation:\
    \ The participants performed the experimental task online using a web-based application\
    \ rather than offline using pen and paper. This allows for more flexibility in\
    \ reaching industry participants [\\[3\\]](#page-44-12).\n- Context factors: To\
    \ obtain a richer understanding of the impact of quality defects, we included\
    \ seven additional context factors. This change made it necessary to extend the\
    \ questionnaire used in the original study to collect demographic information\
    \ from the participants.\n- Experimental object: We sampled the objects from a\
    \ data set of industrial requirements specifications [\\[41\\]](#page-46-12) rather\
    \ than from a requirements specification written in a student project [\\[36\\\
    ]](#page-45-2) to increase the realism of the experimental task [\\[102\\]](#page-49-12).\n\
    - Analysis: The crossover design produces paired data as opposed to the unpaired\
    \ data of the original experiment, which changes the appropriate hypothesis test\
    \ [\\[107\\]](#page-49-11) (Mann-Whitney U test in the original study vs. Wilcoxon\
    \ signed-rank test in this study). In addition, we extend the original FDA by\
    \ performing a Bonferroni correction to deal with family-wise error rate when\
    \ testing multiple hypotheses [\\[6\\]](#page-44-13). Furthermore, we additionally\
    \ analyze the data using BDA.\n\nOur experiment differs from the original experiment\
    \ [\\[36\\]](#page-45-2) in all elements [\\[59\\]](#page-47-13). However, because\
    \ a subset of our hypotheses aligns with their hypotheses, part of our study counts\
    \ as a conceptual replication [\\[2\\]](#page-44-1) since it contributes diagnostic\
    \ evidence for the original claims [\\[83\\]](#page-48-2). In the rest of this\
    \ subsection, we report the design of our experiment following the guidelines\
    \ by Jedlitschka et al. [\\[64\\]](#page-47-14).\n\n# 3.4.1 Experimental Task\n\
    \nWe simulate the use of a requirements specification by subjecting participants\
    \ to a requirements processing activity, i.e., a common task representing the\
    \ use of requirements [\\[36\\]](#page-45-2). In particular, we present four single-sentence,\
    \ natural language requirements to the participants and request them to derive\
    \ a domain model for each of them. Figure [5](#page-14-0) visualizes the expected\
    \ domain model for the requirement \"Every research object is represented in a\
    \ JSON-LD format and stored in a document database if it contains a CC license.\"\
    \ which contains both of the two seeded quality defects. These defects result\
    \ in the following challenges according to literature [\\[94\\]](#page-48-5):\n\
    \n1. The verb in passive voice omits an important entity of the requirement; i.e.,\
    \ that the data processing unit stores the research object in a document database\
    \ (Label 1 in Figure [5\\)](#page-14-0).\n\n<span id=\"page-14-0\"></span>![](_page_14_Figure_1.jpeg)\n\
    \nFig. 5: Domain modeling task example for requirement 4.\n\n2. The ambiguous\
    \ pronoun \"it\" can syntactically be connected to several preceding noun phrases\
    \ (\"Every research object\", \"JSON-LD format\", and \"a document database\"\
    \ or the implicit \"Data Processing Unit\") by a reader but semantically only\
    \ applies to the research object (Label 2 in Figure [5\\)](#page-14-0).\n\nThe\
    \ goal of the experimental task is to derive a semantically correct domain model\
    \ from the natural language requirement which includes identifying all entities\
    \ (including the implicit ones) and connecting these entities correctly (including\
    \ those derived from syntactically vague associations).\n\nThe selection of dependent\
    \ variables was driven by the activity-based requirements quality theory [\\[37,](#page-45-0)\
    \ [48\\]](#page-46-0). Accordingly, requirements quality is measured by the effect\
    \ that quality factors have on the relevant attributes of requirements-dependent\
    \ activity. We selected the following dependent variables representing the relevant\
    \ attributes of the domain-modeling activity with the given motivation:\n\n- Duration:\
    \ the longer the domain modeling task takes, the more expensive it is.\n- Number\
    \ of missing entities: entities missing from the domain model produce potential\
    \ cost for failing to involve the respective actor or object.\n- Number of superfluous\
    \ entities: entities added to the domain model but not implied by the requirement\
    \ unnecessarily constrain the solution space.\n- Number of missing associations:\
    \ associations missing from the domain model produce a potential cost for failing\
    \ to identify a dependency between two entities.\n\n– Number of wrong associations:\
    \ associations connecting two entities that establish an unnecessary dependency\
    \ between them while neglecting an actual dependency.\n\nWe characterize the domain\
    \ modeling activity in terms of immediacy (duration), completeness (missing entities\
    \ and associations), conciseness (superfluous entities), and correctness (wrong\
    \ associations).\n\n# 3.4.2 Hypotheses\n\nThe three independent variables ind\
    \ ∈ {P V, AP,PVAP} (passive voice, ambiguous pronoun, and the coexistence of passive\
    \ voice and ambiguous pronoun) and the five dependent variables dep ∈ {D, E−,\
    \ E+, A−, A<sup>×</sup>} (duration, missing entities, superfluous entities, missing\
    \ associations, wrong associations) define our 15 null hypotheses as follows.\n\
    \n$$\\sum\\_{i \\text{ind} \\in \\{PV, AP, PVAP\\}} \\sum\\_{dep \\in \\{D, E^-,\
    \ E^+, A^-, A^\\times\\}} H\\_0^{ind \\to dep}$$\n\n\"There is no difference in\
    \ {dep} of the domain models based on requirements specifications containing no\
    \ quality defect and requirements specifications containing {ind}.\"\n\nTo capture\
    \ the context of the experiment, we collected factors based on related work [\\\
    [65,](#page-47-3) [81,](#page-48-1) [89\\]](#page-48-13), including the experience\
    \ of a practitioner regarding software and requirements engineering, but also\
    \ in SE roles and in the modeling task itself. Additionally, we assume that the\
    \ practitioners' education and domain knowledge influence the dependent variables.\
    \ Table [1](#page-16-0) summarizes the variables involved in this study.\n\nThe\
    \ variables in Table [1](#page-16-0) do not include a participant type that distinguishes\
    \ students from practitioners. While including such a variable is common practice\
    \ in SE research [\\[10\\]](#page-44-14), meta-research on the eligibility of\
    \ students as experiment participants suggests that the labels student or practitioner\
    \ are merely a proxy for levels of more meaningful factors like domain knowledge\
    \ and experience [\\[97\\]](#page-48-17). Additionally, the line between students\
    \ and practitioners becomes increasingly blurred as students more commonly gather\
    \ industrial experience before or during their studies [\\[18\\]](#page-45-15).\
    \ Consequently, we subsume the participant type variable by the causally more\
    \ meaningful and fine-grained variables of experience, education, domain knowledge,\
    \ and formal modeling training. We compared two models—one using the binary distinction\
    \ and one using the more fine-grained variables—and determined that the latter\
    \ outperforms the former in predictive power, even though only slightly. This\
    \ confirms to us that the variables we used are at least as expressive as the\
    \ binary participant type variable.\n\n# 3.4.3 Experimental Design\n\nOur experimental\
    \ design includes one factor (RQD) representing the alleged quality defect seeded\
    \ in a requirements specification. This main factor con-\n\n| dependent).   |\n\
    |---------------|\n| and           |\n| context,      |\n| (independent, |\n|\
    \               |\n| study<br>the  |\n| of            |\n|               |\n|\
    \ Variables     |\n| 1:            |\n| Table         |\n\n<span id=\"page-16-0\"\
    ></span>\n\n| Variable                              | Name             | Type\
    \ | Description                                                              \
    \                                                                            \
    \                                  | type<br>Data | Range                    \
    \                                                                            \
    \                            |\n|---------------------------------------|------------------|------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|--------------|----------------------------------------------------------------------------------------------------------------------------------|\n\
    | Defect<br>Requirements<br>Quality     | RQD              | ind  | ambiguous<br>an<br>voice,<br>passive<br>in<br>verb<br>both<br>a<br>or<br>of<br>pronoun,<br>use<br>The\
    \                                                                            \
    \      | categorical  | PVAP}<br>AP,<br>PV,<br>{none,                        \
    \                                                                            |\n\
    | in<br>Experience<br>SE                | exp.se           | con  | engineering<br>software<br>in<br>experience<br>of<br>Years\
    \                                                                            \
    \                                                 | count        | N         \
    \                                                                            \
    \                                           |\n| in<br>Experience<br>RE      \
    \          | exp.re           | con  | engineering<br>requirements<br>in<br>experience<br>of<br>Years\
    \                                                                            \
    \                                             | count        | N             \
    \                                                                            \
    \                                       |\n| Education                       \
    \      | edu              | con  | degree<br>acquired<br>Highest             \
    \                                                                            \
    \                                                                 | ordinal  \
    \    | product<br>Ph.D.}<br>M.Sc.,<br>engineer,<br>B.Sc.,<br>{requirements<br>School,<br>{High\
    \                                          |\n| role<br>Primary              \
    \         | role             | con  | profes<br>of<br>years<br>most<br>the<br>with<br>experience<br>Role<br>SE-related<br>sional\
    \                                                                            \
    \                 | categorical  | developer,<br>man<br>trainer,<br>architect,<br>engineer,<br>none}<br>software<br>quality<br>other,<br>owner,<br>tester,<br>ager,\
    \ |\n| experi<br>Task<br>ence                | exp.task         | con  | modeling<br>domain<br>of<br>task<br>the<br>with<br>Experience\
    \                                                                            \
    \                                              | ordinal      | of<br>time,<br>to<br>time<br>from<br>rarely,<br>{never,<br>ten}\
    \                                                                  |\n| model<br>training<br>Formal<br>ing\
    \    | formal           | con  | modeling<br>domain<br>in<br>training<br>Formal\
    \                                                                            \
    \                                                             | categorical  |\
    \ {true,false}                                                               \
    \                                                      |\n| {domain}<br>knowledge<br>Domain<br>in\
    \ | {domain}<br>dom. | con  | aeronau-<br>{telemetry,<br>science}<br>∈<br>domain<br>open<br>the<br>databases,<br>of<br>Knowledge<br>tics,\
    \                                                                            |\
    \ ordinal      | {1,2,3,4,5}                                                 \
    \                                                                     |\n| experi<br>Tool<br>ence\
    \                | tool             | con  | modeling<br>for<br>Docs<br>Google<br>using<br>with<br>Experience\
    \                                                                            \
    \                                           | ordinal      | often}<br>time,<br>to<br>time<br>from<br>rarely,<br>{none,\
    \                                                                       |\n| Duration\
    \                              | D                | dep  | com<br>requirement<br>to<br>participant<br>one<br>on<br>the<br>task<br>took<br>experimental<br>it<br>minutes<br>of<br>the<br>Number<br>plete\
    \                                           | count        | N               \
    \                                                                            \
    \                                     |\n| entities<br>Missing               \
    \    | E−               | dep  | sub<br>the<br>from<br>missing<br>entities<br>model<br>relevant<br>domain<br>of<br>Number<br>mitted\
    \                                                                            \
    \         | count        | Eexpected]<br>[0,                                 \
    \                                                                            \
    \   |\n| en<br>Superfluous<br>tities           | +<br>E           | dep  | the<br>in<br>included<br>entities<br>model<br>relevant<br>domain<br>not<br>of<br>submitted<br>Number\
    \                                                                            \
    \       | count        | N                                                   \
    \                                                                            \
    \ |\n| associ<br>Missing<br>ations           | A−               | dep  | submit<br>the<br>from<br>missing<br>associations<br>model<br>domain<br>of<br>Number<br>ted\
    \                                                                            \
    \                 | count        | Aexpected]<br>[0,                         \
    \                                                                            \
    \           |\n| associa<br>Wrong<br>tions             | A×               | dep\
    \  | or<br>implied<br>source<br>than<br>the<br>entity<br>either<br>different<br>where<br>associations<br>a<br>is<br>requirement<br>edge<br>the<br>of<br>of<br>Number<br>the<br>target<br>by\
    \ | count        | Afound]<br>[0,                                            \
    \                                                                       |\n\n\
    <span id=\"page-17-0\"></span>\n\n| Variable    | Description                \
    \    | Data type   | Range                  |\n|-------------|--------------------------------|-------------|------------------------|\n\
    | Period      | Index of the experimental pe   | ordinal     | [1; 4]        \
    \         |\n|             | riod in which the data was ob  |             |  \
    \                      |\n|             | tained                         |   \
    \          |                        |\n| Sequence    | Order in which a participants\
    \  | categorical | {1234, 1243, , 4321}   |\n|             | received the treatments\
    \        |             |                        |\n| Carryover   | Interaction\
    \ between the period | categorical | {1 × none, 1 × P V , , |\n| effect      |\
    \ and the treatment              |             | 4 × P V AP }           |\n| Subject\
    \     | Index of a participant         | categorical | {1, 2, , 25}          \
    \ |\n| variability |                                |             |          \
    \              |\n\nTable 2: Variables of the study (experimental design factors)\n\
    \ntains four treatments: a control one (no defects) and three experimental ones\
    \ (passive voice (PV), ambiguous pronoun (AP), and both (PVAP)).\n\nGiven our\
    \ sampling strategy involving industry practitioners, which are difficult to recruit\
    \ for controlled experiments [\\[102\\]](#page-49-12), we anticipated a moderate\
    \ sample size of participants. Consequently, we opted for a crossover design [\\\
    [107\\]](#page-49-11) instead of a parallel design, i.e., we apply every treatment\
    \ to all subjects instead of distributing the subjects among the treatments. Previously,\
    \ Kitchenham et al. advised against the use of crossover designs [\\[70\\]](#page-47-15).\
    \ Mainly, the validity of crossover design experiments is challenged by the following\
    \ confounding factors:\n\n- 1. the period in which a treatment is applied to a\
    \ subject, as certain periods may influence the dependent variables (e.g., participants\
    \ may mature and perform increasingly better the more often they perform the experimental\
    \ task subsequently);\n- 2. the sequence in which the treatments are applied to\
    \ a subject, as certain sequences may have a beneficial effect on a dependent\
    \ variable (e.g., there might be an optimal sequence to apply the treatments in);\n\
    - 3. the effect from a previous treatment may carry over to the period when applying\
    \ a subsequent treatment [\\[107\\]](#page-49-11); and\n- 4. the subject variability,\
    \ as software engineering tasks are highly dependent on the skill of involved\
    \ individuals [\\[92\\]](#page-48-18).\n\nHowever, recent adoptions of best practices\
    \ from other disciplines made this design applicable to SE research without compromising\
    \ the validity of the results [\\[51,](#page-46-13) [107\\]](#page-49-11). The\
    \ threats to validity can be mitigated during design and analysis [\\[107\\]](#page-49-11)\
    \ by (1) randomizing the order of treatments and (2) including the independent\
    \ variables' period, sequence, the interaction between them (representing the\
    \ carryover effect), and subject variability in the analysis. Consequently, we\
    \ consider the experimental design variables listed in Table [2](#page-17-0) in\
    \ addition to the variables listed in Table [1.](#page-16-0)\n\nWhen controlling\
    \ the threats to validity, the crossover design provides two benefits. Firstly,\
    \ it requires fewer participants, as an experiment with n<sup>p</sup> participants\
    \ and n<sup>t</sup> treatments yields np×n<sup>t</sup> observations instead of\
    \ only n<sup>p</sup> [\\[113\\]](#page-49-10). Secondly, it accounts for subject\
    \ variability, as the dependent variables can be measured in relation to the average\
    \ response of each subject instead of the average response of each treatment group\
    \ [\\[70\\]](#page-47-15). Therefore, each subject acts as its own control and\
    \ mitigates within-subject variability.\n\nEach experimental session contained\
    \ four main periods in which we applied one treatment to the subject. We randomized\
    \ the order of treatment application to disperse the confounding sequence and\
    \ carryover effect [\\[14,](#page-44-15) [107\\]](#page-49-11). This resulted\
    \ in 24 unique sequences of treatment application (nt! = 24) and, consequently,\
    \ 24 experimental groups. The experiment was single-blinded—i.e., the participants\
    \ did not know the requirements' sequence, but the researchers did.\n\n# <span\
    \ id=\"page-18-0\"></span>3.4.4 Objects\n\nThe experimental object consisted of\
    \ four English, single-sentence NL requirements specifications R1-R4. An additional\
    \ warm-up object (R0) preceded the actual experimental objects, adding a fifth\
    \ experimental period to each session. It was only used to familiarize the participants\
    \ with the experimental task and tool and was not considered in the data analysis.\
    \ The four experimental objects were manually seeded with defects corresponding\
    \ to our four treatments: one requirement containing none of the two faults, one\
    \ containing a verb in passive voice, one containing an ambiguous pronoun, and\
    \ one containing both a verb in passive voice and an ambiguous pronoun. The requirements'\
    \ mean length is 17.8 words (sd=4).\n\nThe first author derived the experimental\
    \ objects from the requirements specification of the Mars Express ASPERA-3 Processing\
    \ and Archiving Facility (APAF), a real-world specification from the PuRE data\
    \ set [\\[41\\]](#page-46-12). From this requirements specification, the first\
    \ author selected five single-sentence natural language requirements and modified\
    \ them to ensure two defect-free requirements (one warm-up object R<sup>0</sup>\
    \ and one for the defect-free baseline R1) and three objects with the respective\
    \ defects (R2-R4). The second author reviewed and adjusted the selected objects.\n\
    \n# <span id=\"page-18-1\"></span>3.4.5 Subjects\n\nThe target population of interest\
    \ consists of people involved in software engineering who work with requirements\
    \ specifications. We used a non-probability sampling approach based on a mix of\
    \ purposive and convenience sampling [\\[3\\]](#page-44-12). In particular, we\
    \ wanted to select participants who are diverse in terms of the context variables\
    \ as determined in Table [1,](#page-16-0) including their experience, education,\
    \ and software engineering roles. We approached both students participating in\
    \ RE courses at our respective institutions and practitioners in our collaborators'\
    \ network to purposefully diversify the experience and education of our sample.\
    \ For all other demographic context factors (e.g., SE roles) we had to rely on\
    \ convenience sampling.\n\nWe approached 52 potential candidates (32 practitioners\
    \ and 20 students), and 27 candidates (19 & 8) agreed to participate in the experiment\
    \ (response\n\n<span id=\"page-19-0\"></span>![](_page_19_Figure_1.jpeg)\n\nFig.\
    \ 6: Distribution of SE and RE experience.\n\n<span id=\"page-19-1\"></span>![](_page_19_Figure_3.jpeg)\n\
    \nFig. 7: Distribution of knowledge in the four relevant domains.\n\nrate of 52%).\
    \ Two students did not show up to the agreed time slot. Our final sample includes\
    \ 19 practitioners from six different companies and six students from two universities.\
    \ Participation in the experiment was entirely voluntary and not compensated.\
    \ The number of participants (n<sup>p</sup> = 25) exceeded the number of experimental\
    \ sequences (nt! = 24) such that we had at least one subject per experimental\
    \ group and evenly dispersed any confounding sequence or carryover effect [\\\
    [107\\]](#page-49-11).\n\nFigure [6](#page-19-0) shows the distribution of experiment\
    \ subjects' experience in SE and RE in years. which is widespread in our sample.\
    \ Among the 25 participants, the reported primary roles are developer (10), architect\
    \ (6), requirements engineer (5), manager (1), and no prior professional role\
    \ (3). Students who have not yet had a professional software engineering role\
    \ constitute this last group. The distribution covers many SE-relevant roles but\
    \ excludes others, such as testers or product owners.\n\nAmong the 25 participants,\
    \ 5 reported a high school degree as their level of education, 8 a Bachelor's\
    \ degree, and 12 a Master's degree. No participant reported a Ph.D. degree as\
    \ their highest degree of education. Figure [7](#page-19-1) visualizes the distribution\
    \ of the participant's experience in the four domains[2](#page-19-2) that contribute\
    \ semantic knowledge to understanding the requirements: aeronautics, telemetry,\
    \ databases, and open source. For the latter two, results are balanced across\
    \ the different knowledge levels, while the former two confirm our assumption\
    \ that all participants had a low-level knowledge of aeronautics and telemetry\
    \ systems.\n\nThe experiment tool—the Google Draw plugin within the Google Document\
    \ was unknown to most (18 never used it, 6 rarely, and 1 from time to time).\n\
    \n<span id=\"page-19-2\"></span><sup>2</sup> Domain does not exclusively mean\
    \ application domain, but rather any coherent ontology related to a specific topic.\n\
    \nA total of 16 participants (64%) report having received a form of training in\
    \ the modeling activity. The modeling experience (never: 1, rarely: 11, from time\
    \ to time: 10, often: 3) resembles a normal distribution. We did not discard data\
    \ from participants who reported having no modeling experience or formal training\
    \ in modeling given that our experiment included both comprehensive instructions\
    \ and a warm-up phase as described in Section [3.4.4.](#page-18-0)\n\nGiven the\
    \ distribution of responses in these context variables, we disqualified the following\
    \ predictors: aeronautics domain knowledge, telemetry domain knowledge, and experience\
    \ with the experiment tool. These variables are not sufficiently distributed in\
    \ our sample of study participants, i.e., several categories of these variables\
    \ are underrepresented. Consequently, they are unable to effectively block the\
    \ influence of that variable on the dependent variable [\\[113\\]](#page-49-10).\n\
    \n# 3.4.6 Instrumentation\n\nWe used a Google Docs document[3](#page-20-0) for\
    \ the task and a Google Form questionnaire[4](#page-20-1) to collect demographic\
    \ information. The Google Docs document lent itself to the task due to its accessibility\
    \ and its simple modeling tool with the embedded Google Drawings. The modeling\
    \ tool represented the optimal trade-off between complexity—as neither previous\
    \ knowledge nor additional software was necessary to conduct the experimental\
    \ task—and suitability—as it contains all elements relevant to the domain modeling\
    \ task (i.e., nodes for entities and edges for associations). This main study\
    \ document explained the experimental task, an example of the domain modeling\
    \ task, and a short context description of the system from its original requirements\
    \ specification [\\[41\\]](#page-46-12).\n\nWe created a survey questionnaire\
    \ to collect demographic information relevant to the experiment using Google Forms.\
    \ All participants could answer the survey only after completing the task to avoid\
    \ fatiguing effects. At the beginning of the questionnaire, participants entered\
    \ their assigned participant ID (PID), such that we could connect their response\
    \ to the experimental task to their response to the questionnaire without storing\
    \ any personal data. The questions were designed to collect all relevant independent\
    \ variables listed in Table [1.](#page-16-0)\n\nWe piloted the experiment in a\
    \ session with two Ph.D. students in SE. We clarified the instruction text and\
    \ task descriptions based on the collected feedback.\n\n# 3.4.7 Data Collection\
    \ Procedure\n\nWe scheduled a one-hour session according to the availability of\
    \ the participants. Because of differing schedules and time zones, we scheduled\
    \ 16 sessions with up to three participants simultaneously. We conducted the sessions\
    \ between 2023-04-03 and 2023-04-17.\n\n<span id=\"page-20-0\"></span><sup>3</sup>\
    \ <https://www.google.de/intl/en/docs/about/>\n\n<span id=\"page-20-1\"></span><sup>4</sup>\
    \ <https://www.google.com/forms/about/>\n\nEach session started with the first\
    \ author explaining the general procedure of the experiment and obtaining consent\
    \ to evaluate and disclose the anonymized data. No participant refused this consent\
    \ and all data points could be included in the data evaluation procedure. Then,\
    \ participants were instructed to read the prepared document in order and complete\
    \ the contained tasks. The document contained all descriptions of the task such\
    \ that all participants received the same instructions. The first author oversaw\
    \ all sessions to address technical difficulties and recorded the minutes each\
    \ participant spent per period. Ten minutes were estimated per period, but participants\
    \ were free to allocate their time. In case participants took longer than the\
    \ scheduled one hour, they completed the task in as much time as they required.\
    \ Once the task was complete, participants also filled in the questionnaire to\
    \ provide demographic information on context variables.\n\n# 3.4.8 Data Preparation\n\
    \nTo evaluate the collected data, we created a code book that characterizes issues\
    \ in domain models. We developed detection rules for each dependent variable of\
    \ the resulting product—i.e., missing entity, superfluous entity, missing association,\
    \ and wrong association—and summarized them in a guideline (available in our replication\
    \ package [\\[46\\]](#page-46-3)). Then, the first author manually evaluated the\
    \ resulting domain models of each participant using this guideline and recorded\
    \ all detected issues.\n\nThe result of the coding process was a table where one\
    \ row represents the evaluation of one domain model. Given n<sup>p</sup> = 25\
    \ participants and n<sup>r</sup> = 4 requirements, we ended up with n<sup>p</sup>\
    \ × n<sup>r</sup> = 100 data points. Each data point contained the number of issues\
    \ of each of the four types that occurred in the respective domain model. Finally,\
    \ we standardized numerical variables in the demographic data for easier processing.\n\
    \nTo assess the reliability of the rating, the fourth author of the paper independently\
    \ recorded issues of three randomly selected participant responses, yielding an\
    \ overlap of twelve ratings. Since each domain model can contain an arbitrary\
    \ number of issues of each type, but our dependent variables only model the number\
    \ of times that an issue type occurred, we consider each rating of a domain model\
    \ as a vector of dimensions equal to the number of issue types. We then calculated\
    \ the inter-rater agreement of the same domain model using the Spearman rank correlation\
    \ between the vectors. The average cosine similarity is 77.0% and represents substantial\
    \ agreement. The two raters discussed the remaining disagreement and concluded\
    \ that they represented acceptable variance in the interpretation of participants'\
    \ responses.\n\n# 3.4.9 Frequentist Data Analysis\n\nWe performed a frequentist\
    \ data analysis of the experimental data as in the original experiment [\\[36\\\
    ]](#page-45-2). Since the factor is categorical, all dependent variables are continuous,\
    \ and our samples are dependent, our statistical method of choice falls between\
    \ the parametric paired t-test [\\[62\\]](#page-47-16) or the non-parametric Wilcoxon\
    \ signed-rank test [\\[112\\]](#page-49-13) based on the distribution of the variables,\
    \ which we evaluated using the Shapiro-Wilk test results [\\[99\\]](#page-48-19).\n\
    \nWe reject a null hypothesis if the resulting p-value of a two-tailed statistical\
    \ test is lower than the significance level α. To account for type I errors when\
    \ performing multiple hypotheses tests targeting the same independent variable,\
    \ we apply the Bonferroni correction [\\[6\\]](#page-44-13): we considered α ′\
    \ = α <sup>m</sup> where α = 0.05 and m is the number of hypotheses tested for\
    \ each value of the independent variable. For our five families of hypotheses\
    \ α ′ = 0.05 <sup>5</sup> = 0.01.\n\nAdditionally, we report the effect size [\\\
    [28\\]](#page-45-16) using Cohen's D for the paired student t-test [\\[24\\]](#page-45-17)\
    \ and the matched-pairs rank biserial correlation coefficient for Wilcoxon signed-rank\
    \ test [\\[69\\]](#page-47-17).\n\n# <span id=\"page-22-0\"></span>3.4.10 Bayesian\
    \ Data Analysis\n\nWe apply Bayesian data analysis with Pearl's framework for\
    \ causal inference [\\[88\\]](#page-48-15) to complement the frequentist data\
    \ analysis [\\[52\\]](#page-46-2). Given the limited adoption of Bayesian data\
    \ analysis in software engineering research [\\[52](#page-46-2)[–54\\]](#page-46-14),\
    \ we complement this method section with a running example for understandability.\
    \ In this running example, we illustrate the methodological steps of Bayesian\
    \ data analysis for the hypothesis that requirements quality defects influence\
    \ the number of wrong associations in a resulting domain model.\n\nThree steps\
    \ [\\[101\\]](#page-49-14), which are the major steps of Pearl's original model\
    \ of causal statistical inference [\\[88\\]](#page-48-15), comprise the analysis.\
    \ We explain each step in the following paragraphs.\n\nModeling In the modeling\
    \ step, we make our causal assumptions about the underlying effect explicit in\
    \ a graphical causal model. The graphical causal model takes the form of a directed\
    \ acyclic graph (DAG) in which nodes represent variables and directed edges represent\
    \ causal effects [\\[29\\]](#page-45-13). Our DAG contains four groups of variables:\n\
    \n- 1. Treatment: The independent variable that represents the requirements quality\
    \ defect present in the requirement.\n- 2. Context factors: The independent variables\
    \ that represent the properties of the participants.\n- 3. Experimental design\
    \ factors: The independent variables that represent all factors of the crossover\
    \ experiment design influencing the response variables [\\[107\\]](#page-49-11).\n\
    - 4. Response variables: The dependent variables.\n\nThe effect of the treatments\
    \ on the response variables is the subject of the analysis. By including both\
    \ context and confounding factors, their influence is factored out from the treatments'\
    \ causal effect on the response variables. Consequently, the effect of interest\
    \ can be isolated from any confounding factor included in the DAG. We assume causal\
    \ relations—represented by edges in the DAG—between every independent (treatment,\
    \ context, and confounding) and\n\n<span id=\"page-23-0\"></span>![](_page_23_Figure_1.jpeg)\n\
    \nFig. 8: DAG for the analysis of wrong associations\n\nthe dependent variables.\
    \ Additionally, independent variables may influence other independent variables.\n\
    \nFigure [8](#page-23-0) shows the DAG of the running example. The treatment,\
    \ response variable, and context factors correspond to the study variables as\
    \ outlined in Table [1.](#page-16-0) The experimental design variables correspond\
    \ to the factors listed in Table [2.](#page-17-0) The experimental period blocks\
    \ the learning effect, i.e., the influence on the response variable caused by\
    \ repeatedly performing the task. The duration blocks the time effect, i.e., the\
    \ influence on the response variable caused by the amount of time that a participant\
    \ took for each instance of the task. Note that the factor tool experience listed\
    \ in Table [1](#page-16-0) is missing from the DAG since we excluded it as explained\
    \ in Section [3.4.5.](#page-18-1) Note that the factor sequence listed in Table\
    \ [2](#page-17-0) is missing from the DAG since it is confounded with subject\
    \ variability (further explained in Section [5.4.1\\)](#page-40-0).\n\nThe DAG\
    \ does not visualize the interaction effects we assume between two independent\
    \ variables. An interaction effect occurs when the influence of one independent\
    \ variable on the dependent variable depends on the value of another independent\
    \ variable [\\[76\\]](#page-47-4). Visualizations of interaction effects in DAGs\
    \ have been proposed [\\[82\\]](#page-48-20) but are not common practice. In the\
    \ running example, we assume two interaction effects via the following hypotheses:\n\
    \n- 1. requirements quality \\* domain knowledge: domain knowledge can compensate\
    \ the effect of requirements quality defects [\\[93\\]](#page-48-8)\n- 2. requirements\
    \ quality \\* period carryover effect [\\[107\\]](#page-49-11): the effect of\
    \ a treatment may be influenced by the treatments applied in previous periods\n\
    \nIdentification Including an independent variable Z that has an assumed causal\
    \ effect on both the treatment X (i.e., Z → X) and the outcome Y (i.e., Z → Y\
    \ ) opens a non-causal path (i.e., X ← Z → Y ) from the treatment to the outcome\
    \ [\\[87\\]](#page-48-14). This so-called backdoor path introduces spurious associations.\
    \ Consequently, blindly moving forward with all variables may harm the causal\
    \ analysis. Instead, the so-called adjustment set of variables needs to be selected\
    \ [\\[76\\]](#page-47-4) in the identification step. A series of four criteria\
    \ [\\[76\\]](#page-47-4) allows to make an informed selection of variables to\
    \ include in the final estimation step. This way, we avoid variable bias like\
    \ colliders which confound the causal effect between the treatment and the response\
    \ variable.\n\nIn the running example, we assume the following causal relation\
    \ between independent variables. The more experience a participant has in SE or\
    \ RE, the more likely it is that they have acquired respective domain knowledge\
    \ (experience in SE/RE → domain knowledge). We need to consider this relationship\
    \ in the next step to avoid attributing impact to the wrong independent variable.\
    \ For instance, in the running example, we need to distinguish whether experience\
    \ in SE/RE has a direct influence on wrong association or whether it just influences\
    \ domain knowledge, which influences the response variable.\n\nBecause we employ\
    \ an experiment as our research method and fully control the treatment, there\
    \ is no influence of any other independent variable on the treatment variable.\n\
    \nEstimation In the estimation step, we perform a regression analysis. The regression\
    \ analysis results in estimates of the response variable depending on the values\
    \ of the independent variables. The result of the regression analysis is a Bayesian\
    \ model trained with empirical data. The model provides the magnitude and sign\
    \ of the effect that each independent variable has on the dependent response variable.\n\
    \nThe estimation step begins by selecting a distribution type (likelihood) that\
    \ represents the dependent response variable [\\[56\\]](#page-46-9). We select\
    \ the distribution type based on the maximum entropy criterion [\\[63\\]](#page-47-18)\
    \ and ontological assumptions. This means we select the least restrictive distribution\
    \ that fulfills all ontological assumptions about the variables' properties.\n\
    \nIn our running example, the response variable is a count of wrong associations\
    \ in a domain model. Consequently, the distribution must be discrete and only\
    \ allow positive numbers or zero. Additionally, the response variable is bounded\
    \ by the number of expected associations of the domain model, i.e., the number\
    \ of associations in the sample solution, since a participant can only connect\
    \ as many associations wrongly in the model as there were associations expected.\
    \ Any associations added beyond the expected associations count as superfluous\
    \ associations, a different response variable. Consequently, we represent the\
    \ response variable with a Binomial distribution. The following formula encodes\
    \ that the number of wrong associations in one domain model i (E × i ) is distributed\
    \ as a Binomial distribution with the number of trials equal to the number of\
    \ expected associations (E) and a probability p<sup>i</sup> ∈ [0, 1] of getting\
    \ one association wrong.\n\n#### E × <sup>i</sup> ∼ Binomial(E, pi)\n\nThis formula\
    \ assumes that the event—connecting one association wrong is independent, i.e.,\
    \ one wrong association does not influence the success of any other association.\n\
    \nIn the next step, we define the parameter that determines the response variable\
    \ distribution (in the running example: pi) in relation to the predictors selected\
    \ in the identification step. The following formula shows a simplified version\
    \ of this parameter definition (excluding most of the previously mentioned predictors\
    \ in Table [1](#page-16-0) for brevity).\n\n$$logit(p\\_i) = \\alpha + \\alpha\\\
    _{PID} + \\beta\\_{RQD}^T \\times RQD\\_i + \\beta\\_{SE} \\times exp.se\\_i$$\n\
    \nThe logit operator scales the parameter p<sup>i</sup> to a range of [0, 1] since\
    \ the probability parameter of the Binomial distribution only accepts this range\
    \ of values [\\[26,](#page-45-18) [76\\]](#page-47-4). The parameter p<sup>i</sup>\
    \ is, in this example, determined by the following predictors:\n\n- 1. Intercept\
    \ (α): the grand mean of connecting an association wrongly, i.e., the baseline\
    \ challenge of getting an association wrong.\n- 2. Group-level intercept (αP ID,\
    \ where the results of one participant represent one group): the participant-specific\
    \ mean of connecting an association wrongly, i.e., the within-subject variability\
    \ of response variables [\\[107\\]](#page-49-11) modeled via partial pooling [\\\
    [30\\]](#page-45-19)\n- 3. Treatment (RQDi): the influence of a requirements quality\
    \ defect on the probability of connecting an association wrong (as an offset from\
    \ the grand mean).\n- 4. Software Engineering Experience (exp.sei): the influence\
    \ of the subject's software engineering experience on the probability of connecting\
    \ an association wrong (as an offset from the grand mean).\n\nThe variables RQD<sup>i</sup>\
    \ and exp.se<sup>i</sup> contain the values recorded during instance i of conducting\
    \ the experimental task and are each prefixed with coefficients β T RQD and βSE.\
    \ These coefficients are Gaussian probability distributions that represent the\
    \ magnitude and direction of the influence that the variable values have on the\
    \ parameter p<sup>i</sup> and, therefore, on the distribution of the response\
    \ variable. The mean µ of the coefficient represents the average effect of the\
    \ variable on the parameter p<sup>i</sup> , and the standard deviation σ encodes\
    \ the variation around this average effect. A standard deviation of σ = 0 would\
    \ mean that the variable has a deterministic effect of strength µ on p<sup>i</sup>\
    \ and, therefore, the distribution of the response variable. In reality, this\
    \ is highly unrealistic. Hence, the standard deviation captures the uncertainty\
    \ of the effect of a variable on p<sup>i</sup> .\n\nSpecial cases of variables\
    \ are the intercepts α and αP ID, which are probability distributions without\
    \ any variable and, hence, represent the predictorindependent general and participant-specific\
    \ probability of connecting an association wrong. In the beginning, we assign\
    \ probability distributions spread\n\n<span id=\"page-26-0\"></span>![](_page_26_Figure_1.jpeg)\n\
    \nFig. 9: Predictive checks with prior and updated posterior coefficient distributions\n\
    \naround µ = 0 (β T RQD ∼ Normal(0, 0.5)), so-called uninformative priors, to\
    \ these coefficients. These distributions encode our prior beliefs about the influence\
    \ of the respective predictor, i.e., that it is yet unknown whether the predictor\
    \ has a positive (µ > 0) or negative (µ < 0) influence on p<sup>i</sup> . Only\
    \ where previous evidence for the impact of a predictor on the response variable\
    \ exists, we select more informative priors. For example, the experiment by Femmer\
    \ et al. [\\[36\\]](#page-45-2) indicates that missing entities and missing associations\
    \ are in general rare, which we represent in our priors by selecting α ∼ Normal(−1,\
    \ 0.5) for the intercept.\n\nWe assess the feasibility of the selected prior distributions\
    \ via prior predictive checks [\\[111\\]](#page-49-15). During this check, we\
    \ sample only from the priors, i.e., we predict the response variable given the\
    \ recorded data of independent variables and the prior probability distributions\
    \ of the predictor coefficients. Figure [9](#page-26-0) visualizes the result\
    \ of the prior predictive check. The grey bars represent the actual observed distribution\
    \ of the response variable. For example, 75 domain models contained zero wrong\
    \ associations. The distribution of predicted values for the response variable\
    \ (cyan whisker plots) encompasses the actual observed distribution of the response\
    \ variable. This confirms that the actually observed distribution is approximately\
    \ determined by the uninformative prior distributions.\n\nUpon confirmation of\
    \ the priors' feasibility, we train the Bayesian models with the data recorded\
    \ during the experiment. We conducted the analysis using the brms library [\\\
    [16\\]](#page-44-10) in R. Hamiltonian Monte Carlo Markov Chains (MCMC) [\\[13\\\
    ]](#page-44-8) update the coefficient distributions based on the empirical data.\
    \ During this process, the parameters of the coefficient distributions are adjusted\
    \ to better reflect the response variable based on the predictor variable values.\n\
    \nAfter the training process, we perform posterior predictive checks, which work\
    \ similarly to the prior predictive check but use the updated posterior coefficient\
    \ distributions instead of the prior distributions. Figure [9](#page-26-0) also\
    \ visualizes the posterior predictive check for the running example. The distribution\
    \ of the predicted values (red whisker plots) still encompasses the actually observed\
    \ distribution of the response variable but has narrowed around these values.\
    \ This indicates that the posterior distributions encode the influence of the\
    \ predictor variables more accurately than the prior distributions, i.e., that\
    \ the model has successfully gained predictive power during the training process.\n\
    \nTo overcome the problem mentioned in the identification step, i.e., attributing\
    \ impact to the wrong predictor, we train additional models per response variable\
    \ to test for conditional independence [\\[76\\]](#page-47-4). For example, to\
    \ determine the correct causal relationship between the two independent variables\
    \ experience in SE, domain knowledge, and the dependent variable, we train two\
    \ additional models where each one misses one of the two variables [\\[54\\]](#page-46-14).\
    \ After training, we compare the posterior distributions of the remaining parameter\
    \ coefficients. If a posterior distribution significantly moves from |µ| > 0 towards\
    \ µ = 0 when including a variable, then the response variable is independent of\
    \ that variable when conditioning on the included variable. The model does not\
    \ gain any further information from the variable with µ ≃ 0, and its causal relation\
    \ is disputed. If the posterior distribution does not deviate significantly when\
    \ including another variable, its causal impact is confirmed.\n\nFinally, we perform\
    \ a stratified posterior prediction to answer our research questions. To this\
    \ end, we construct a synthetic data set with four data points, one for each value\
    \ of the main factor variable (i.e., baseline, PV, AP, PVAP). We fix all other\
    \ independent variables at representative values—i.e., the mean for continuous\
    \ and the mode for discrete variables. Then, we sampled 6, 000 predictions for\
    \ each of the four data points. This isolates the effect of the treatment but\
    \ maintains the uncertainty of the influence of every independent variable encoded\
    \ in the standard deviation of every predictor coefficient and, hence, more accurately\
    \ describes the causal relationship between the treatment and the outcome. We\
    \ compare the 6, 000 predictions of each of the three treatments (PV, AP, PVAP)\
    \ with the 6, 000 predictions from the baseline (no defect) and count how often\
    \ the treatment causes a higher, equal, or lower outcome variable. We scale these\
    \ values to percentages to summarize the effect of the treatment on the outcome\
    \ variable. This evaluation avoids a point-wise reduction of the results and comparison\
    \ to an arbitrary significance level as customary in frequentist analyses [\\\
    [60\\]](#page-47-12). Rather than providing a binary answer to the hypotheses,\
    \ we present the more informative distribution of results. However, for the sake\
    \ of reporting, we consider the distribution of the duration variable skewed if\
    \ the two percentages differ from the mean (50%) by 10% each and consider the\
    \ other distributions skewed if the two percentages differ by 10% from each other.\n\
    \nAdditionally, we plot the marginal effect of selected independent variables\
    \ to visualize their isolated impact on the response variable. The isolated impact\
    \ reveals how context and confounding factors influence the response variable.\
    \ This includes visualizing the carryover effect, i.e., the interaction between\
    \ the treatment and the period.\n\n# <span id=\"page-28-0\"></span>4 Results\n\
    \nSection [4.1](#page-28-1) shows the results of the frequentist and Section [4.2](#page-29-0)\
    \ the results of the Bayesian data analysis. Section [4.3](#page-34-0) compares\
    \ the part of our results that contributes a conceptual replication to the original\
    \ study. Section [4.4](#page-35-0) compares the results from our FDA to the results\
    \ from our BDA.\n\n# <span id=\"page-28-1\"></span>4.1 Frequentist Data Analysis\n\
    \nTable [3](#page-28-2) shows the mean and median values of the response variables\
    \ similar to how they are reported by Femmer et al. [\\[36\\]](#page-45-2). Note\
    \ that the results are not directly comparable to those in the original study\
    \ as both our experimental objects and treatments varied.\n\n<span id=\"page-28-2\"\
    ></span>Table 3: Mean and median response variable values (reported as mean/median\
    \ in each cell)\n\n| Defect | Duration<br>D | Missing<br>Entities<br>E− | Superfluous<br>Entities<br>E+\
    \ | Missing<br>Associa<br>tions A− | Wrong As<br>sociations<br>A× |\n|--------|---------------|---------------------------|-------------------------------|--------------------------------|------------------------------|\n\
    | none   | 7.38/6.5      | 0.23/0                    | 0.5/0                 \
    \        | 0.38/0                         | 0.08/0                       |\n|\
    \ PV     | 6.88/7        | 0.81/1                    | 0.42/0                \
    \        | 0.81/1                         | 0.62/0                       |\n|\
    \ AP     | 7.12/6        | 1.23/1                    | 0.96/0.5              \
    \        | 1.12/1                         | 0.54/0.5                     |\n|\
    \ PVAP   | 7.96/7        | 1.27/1                    | 0.46/0                \
    \        | 1.38/1                         | 0.38/0                       |\n\n\
    Table [4](#page-29-1) lists the results of our frequentist data analysis and relates\
    \ them to the results from the original study [\\[36\\]](#page-45-2).\n\nThe frequentist\
    \ data analysis suggests rejecting the following hypotheses and, therefore, proposes\
    \ the following effects as statistically significant (with α ′ = 0.01):\n\n- 1.\
    \ HP V <sup>→</sup><sup>E</sup> − 0 : passive voice impacts the number of missing\
    \ entities\n- 2. HAP→<sup>E</sup> − 0 : ambiguous pronouns impacts the number\
    \ of missing entities\n- 3. HPVAP→<sup>E</sup> − 0 : the co-occurrence of passive\
    \ voice and ambiguous pronouns impacts the number of missing entities\n\n| Outcome\
    \               | Treatment |      | Original [36] |      |        |         \
    \          |       |\n|-----------------------|-----------|------|---------------|------|--------|-------------------|-------|\n\
    |                       |           | p    | CI            | ES   | p      | Replication<br>CI\
    \ | ES    |\n|                       | PV        |      |               |    \
    \  | 0.67   | (−0.4, 0.7)       | -0.13 |\n| Duration              | AP      \
    \  |      |               |      | 0.86   | (−0.7, 0.86)      | 0.01  |\n|   \
    \                    | PVAP      |      |               |      | 0.49   | (−0.5,\
    \ 0.25)      | 0.14  |\n| Missing               | PV        | 0.10 | (0, ∞)  \
    \      | 0.39 |        |                   |       |\n| Actors               \
    \ |           |      |               |      |        |                   |   \
    \    |\n| Missing               | PV        | 0.25 | (−1, ∞)       | 0.25 |  \
    \      |                   |       |\n| Objects               |           |  \
    \    |               |      |        |                   |       |\n| Missing\
    \               | PV        |      |               |      | ≪ 0.01 | (−1, 0) \
    \          | -0.79 |\n| Entities              | AP        |      |           \
    \    |      | ≪ 0.01 | (−1.5, 0)         | -0.93 |\n|                       |\
    \ PVAP      |      |               |      | ≪ 0.01 | (−2, 0)           | -0.81\
    \ |\n| Superfluous           | PV        |      |               |      | 0.64\
    \   | (−0.5, 0)         | 0.14  |\n| Entities              | AP        |     \
    \ |               |      | 0.19   | (−2.5, 0)         | -0.41 |\n|           \
    \            | PVAP      |      |               |      | 0.62   | (−1, 1)    \
    \       | 0.15  |\n| Missing               | PV        | 0.02 | (1, ∞)       \
    \ | 0.75 | 0.025  | (−1, 0)           | -0.58 |\n| Associations          | AP\
    \        |      |               |      | ≪ 0.01 | (−2, −1.5)        | -0.87 |\n\
    |                       | PVAP      |      |               |      | ≪ 0.01 | (−2,\
    \ −1)          | -0.84 |\n| Wrong<br>Associations | PV        |      |       \
    \        |      | 1.0    | (0, 0)            | 0.0   |\n|                    \
    \   | AP        |      |               |      | ≪ 0.01 | (−1, 0)           | -0.85\
    \ |\n|                       | PVAP      |      |               |      | 0.052\
    \  | (−1.5, 0)         | -0.67 |\n\n<span id=\"page-29-1\"></span>Table 4: Results\
    \ of frequentist analysis including the p-value of the hypothesis test (p), confidence\
    \ interval (CI), and effect size (ES). Statistically significant results in bold\
    \ (original study α = 0.05, this experiment α ′ = 0.01).\n\n- 4. HAP→<sup>A</sup>\
    \ − 0 : ambiguous pronouns impact the number of missing associations\n- 5. HPVAP→<sup>A</sup>\
    \ − 0 : the co-occurrence of passive voice and ambiguous pronouns impacts the\
    \ number of missing associations\n\n6. HAP→<sup>A</sup> × 0 : ambiguous pronouns\
    \ impact the number of wrong associations The associated effect size is considered\
    \ large [\\[23\\]](#page-45-20) in all cases.\n\n# <span id=\"page-29-0\"></span>4.2\
    \ Bayesian Data Analysis\n\nThis section follows the methodology described in\
    \ Section [3.4.10](#page-22-0) by presenting the DAG in Section [4.2.1,](#page-29-2)\
    \ posterior predictions in Section [4.2.2,](#page-31-0) and marginal plots in\
    \ Section [4.2.3.](#page-32-0)\n\n# <span id=\"page-29-2\"></span>4.2.1 Causal\
    \ Model and Adjustment Set\n\nFigure [10](#page-30-0) visualizes the DAG that\
    \ graphically models our causal assumptions. It is an extension of Figure [8,](#page-23-0)\
    \ the running example, including all five dependent variables. To preserve the\
    \ readability of the DAG, we introduce a distributor node. This node substitutes\
    \ the connections from the source of every incoming edge to the target of every\
    \ outgoing edge.\n\nThe edges represent the same causal reasoning as presented\
    \ in the running example in Section [3.4.10.](#page-22-0) We assume that all independent\
    \ variables (treatments, context factors, and experimental design factors) have\
    \ an impact on\n\n<span id=\"page-30-0\"></span>![](_page_30_Figure_1.jpeg)\n\n\
    Fig. 10: Directed acyclic graph visualizing all causal assumptions\n\nall dependent\
    \ variables. The impact of the requirements quality defect (the three treatments)\
    \ is the relationship of interest in our analyses. In addition to the already\
    \ described impact of experience in SE on domain knowledge, we assume the following\
    \ causal relationships:\n\n- 1. Duration impacts all other dependent variables:\
    \ Since we did not constrain the time for each period, different amounts of minutes\
    \ taken for each object may influence the results. Taking a longer time for one\
    \ domain model may reduce the amount of defects in the final model.\n- 2. Missing\
    \ entities impact missing associations: If an entity is missing from the domain\
    \ model, any association involving that entity will also be missing (as already\
    \ supported by our re-analysis [\\[47\\]](#page-46-11)).\n\nEqually notable are\
    \ the non-existing associations between nodes, especially between context factors.\
    \ In our DAG, we only assume an impact of experience in SE/RE on domain knowledge\
    \ (as explained in Section [3.4.10\\)](#page-22-0). We do not assume, for example,\
    \ a causal relation between education and experience in SE/RE as higher levels\
    \ of education do not entail more industrial experience or vice versa. Similarly,\
    \ we assume education to be independent of domain knowledge as most educational\
    \ programs known to us are domain-independent. The resulting set of associations\
    \ visualized in Figure [10](#page-30-0) corresponds to the authors' shared beliefs\
    \ that warrant assuming causal relationships between two variables. While we do\
    \ not expect every reader to share these beliefs, we hope that the explicit and\
    \ transparent documentation of our assumptions invites constructive, iterative\
    \ improvements by challenging them via empirical investigations.\n\nThe DAG from\
    \ the running example in Figure [8](#page-23-0) lists the variable duration as\
    \ an independent variable, while the final DAG in Figure [10](#page-30-0) lists\
    \ it as a response variable. The variable duration takes on two distinct roles\
    \ depending on the current analysis. In the case where the analysis targets the\
    \ effects on the duration, it is the sole response variable. In all other cases,\
    \ it is an independent variable.\n\nIn the second step in the statistical causal\
    \ inference [\\[101\\]](#page-49-14), the identification step, we found the adjustment\
    \ set to include all variables for prediction. To discern the impact of independent\
    \ variables with causal relations among them, we developed comparison models in\
    \ which certain variables were excluded. The comparison showed that the exclusion\
    \ did not change the estimations of the coefficient distributions. Hence, we assume\
    \ all causal relationships are feasible and evaluate the full model, including\
    \ all eligible variables as predictors.\n\n# <span id=\"page-31-0\"></span>4.2.2\
    \ Posterior Predictions\n\nBased on maximum entropy [\\[63\\]](#page-47-18), we\
    \ model the five response variables using the following probability distributions.\
    \ The duration is centered around the global mean, therefore, we model it with\
    \ a Gaussian distribution around µ = 0. The number of superfluous entities is\
    \ an unbounded count with an index of dispersion of about 1.5, hence, we model\
    \ it as a negative binomial distribution. Missing entities, missing associations,\
    \ and wrong associations are bounded counts and, hence, modeled as Binomial distributions.\
    \ Table [5](#page-31-1) contains the result of the predictions from the posterior\
    \ distributions. Each cell contains the resulting likelihood that the occurrence\
    \ of a factor causes fewer or more issues of the respective outcome compared to\
    \ the baseline of no quality defects[5](#page-31-2) . The larger the difference\
    \ between the likelihood of more (+) than fewer (−) issues, the stronger the effect\
    \ of that factor on the outcome. If the likelihood of more (+) issues outweighs\
    \ the likelihood of fewer (−) issues, the factor has a negative effect. If the\
    \ two values are similar, then the factor has no clear effect on the outcome.\n\
    \n<span id=\"page-31-1\"></span>Table 5: Likelihood that a treatment produces\
    \ fewer (−) or more (+) occurrences of the respective outcome variable.\n\n| Outcome\
    \              | PV    |       | AP    |       | PVAP  |       |\n|----------------------|-------|-------|-------|-------|-------|-------|\n\
    |                      | -     | +     | -     | +     | -     | +     |\n| Duration\
    \             | 57.2% | 42.8% | 51.7% | 48.3% | 44.8% | 55.2% |\n| Missing entities\
    \     | 29.6% | 32.5% | 24.7% | 40.1% | 27.4% | 35.6% |\n| Superfluous entities\
    \ | 26.6% | 22.5% | 22.5% | 33.3% | 26.4% | 24.6% |\n| Missing associations |\
    \ 25.0% | 45.0% | 20.2% | 51.2% | 22.2% | 49.4% |\n| Wrong associations   | 10.5%\
    \ | 11.5% | 5.2%  | 44.6% | 6.9%  | 31.5% |\n\n<span id=\"page-31-2\"></span><sup>5</sup>\
    \ The remaining cases (100% − less − more) are omitted from the table\n\nFor example,\
    \ the first two cells in the second row of Table [5](#page-31-1) state that using\
    \ passive voice causes fewer missing entities in 29.6% and more missing entities\
    \ in 32.5% of all cases. In the remaining 37.9% of all cases, passive voice causes\
    \ neither more nor fewer missing entities. Given this balance, the effect of passive\
    \ voice on missing entities is unclear, and there is not enough evidence to reject\
    \ HP V <sup>→</sup><sup>E</sup> − 0 .\n\n# Result of Posterior Predictions\n\n\
    The following effects are likely given the skewed distribution of posterior predictions:\
    \ passive voice, ambiguous pronouns, and their cooccurrence cause an increasing\
    \ number of missing associations. Ambiguous pronouns cause an increasing number\
    \ of wrong associations. Ambiguous pronouns cause an increasing number of missing\
    \ and superfluous.\n\nWe use an arbitrary threshold of 10% to report notable results\
    \ in textual form. Refer to Table [5](#page-31-1) for the actual, more fine-grained\
    \ results.\n\n# <span id=\"page-32-0\"></span>4.2.3 Marginal and Conditional Effects\n\
    \nMarginal plots visualize the isolated effect of specific predictors when fixing\
    \ all other predictors to representative values. In the following, we present\
    \ selected marginal plots that show the effects of interest. The remaining plots\
    \ can be found in our replication package.\n\nMissing entities impact missing\
    \ associations Figure [11](#page-33-0) visualizes the effect of the number of\
    \ missing entities on the number of missing associations. The y-axis represents\
    \ the expected value of missing entities over multiple attempts with a trial size\
    \ of one. Hence, it corresponds to the likelihood of missing one entity.\n\nThe\
    \ plot supports the assumption that missing an entity promotes missing an association,\
    \ which the original experiment did not consider and instead attributed the missing\
    \ associations fully to the use of passive voice [\\[36\\]](#page-45-2). In fact,\
    \ the strength of the effect of passive voice on missing associations (µ P V RQT\
    \ = 0.38) is similar to the strength of the effect of missing entities on missing\
    \ associations (µE<sup>−</sup> = 0.40). However, the uncertainty of the impact\
    \ of passive voice (σ P V RQT = 0.32) is higher than that of missing entities\
    \ (σE<sup>−</sup> = 0.09). This means that the effect of missing entities on missing\
    \ associations is much more reliable than the effect of passive voice on missing\
    \ associations.\n\nImpact of duration Figure [12](#page-33-1) visualizes the impact\
    \ of relative duration (i.e., deviation in duration from the overall average time\
    \ of creating a domain model in minutes) on the two response variables superfluous\
    \ entities and wrong associations. The red estimate shows that the longer a participant\
    \ took to generate a domain model (relative duration > 0), the more likely they\
    \ were to introduce\n\n<span id=\"page-33-0\"></span>![](_page_33_Figure_1.jpeg)\n\
    \nFig. 11: Impact of missing entities on missing associations.\n\n<span id=\"\
    page-33-1\"></span>![](_page_33_Figure_3.jpeg)\n\nFig. 12: Impact of relative\
    \ duration on the number of superfluous entities and wrong associations\n\nsuperfluous\
    \ entities. The cyan estimate shows that the shorter time a participant took to\
    \ generate a domain model (relative duration < 0), the more likely they were to\
    \ connect an association wrongly.\n\nImpact of previous training in modeling Figure\
    \ [13](#page-34-1) visualizes the impact of prior formal training in modeling\
    \ on the number of wrong associations in a domain model. A participant with prior\
    \ formal training (formal = T RUE) shows a slightly lower likelihood of connecting\
    \ associations wrongly. The overlapping confidence intervals do, however, indicate\
    \ a strong variance of the effect.\n\nImpact of remaining context factors None\
    \ of the remaining context factors has a stronger effect on any of the response\
    \ variables than the previously\n\n<span id=\"page-34-1\"></span>![](_page_34_Figure_1.jpeg)\n\
    \nFig. 13: Marginal effect of prior formal training in modeling on the number\
    \ of wrong associations\n\nmentioned impact visualized in Figure [13.](#page-34-1)\
    \ This means that the other context factors are neither notable (µ > 0.4) nor\
    \ significant (σ < µ). The replication package contains a detailed summary of\
    \ all coefficients.\n\nInteraction between domain knowledge and the treatment\
    \ Conditional plots visualize interaction effects between two predictors. Figure\
    \ [14](#page-35-1) visualizes the interaction effect between domain knowledge\
    \ about open source and the treatment on the number of wrong associations. The\
    \ figure shows that the impact of ambiguous pronouns (cyan whisker plots) on the\
    \ response variable number of wrong associations diminishes the greater the domain\
    \ knowledge about open source. For the co-occurrence of ambiguous pronouns and\
    \ passive voice (purple whisker plots), the effect is less pronounced but symmetrical,\
    \ i.e., the factor has the strongest impact on the response variable when the\
    \ domain knowledge is medium. However, the effect contains high uncertainty when\
    \ the treatment involves ambiguous pronouns, represented by the large and overlapping\
    \ confidence intervals (cyan and purple whiskers in Figure [14\\)](#page-35-1).\
    \ The collected data does not suffice to support the significance of this effect.\n\
    \n# Result of Marginal and Conditional Effects\n\nMost context factors do not\
    \ show a significant impact on either the response variables directly or mediate\
    \ the effect of quality defects. The few context factors that do show an impact\
    \ are not significant.\n\n# <span id=\"page-34-0\"></span>4.3 Comparison of original\
    \ with our Study Results\n\nFor the part of our study that serves as a conceptual\
    \ replication, we compare the results of the original study [\\[36\\]](#page-45-2)\
    \ and its re-analysis [\\[47\\]](#page-46-11) with our results [\\[19\\]](#page-45-14).\
    \ Regarding HP V <sup>→</sup><sup>E</sup> − 0 , we obtain conflicting results\
    \ from the FDA\n\n<span id=\"page-35-1\"></span>![](_page_35_Figure_1.jpeg)\n\n\
    ![](_page_35_Figure_2.jpeg)\n\nas we reject the null hypothesis while the original\
    \ study does not, but consistent results from the BDA, as the distribution of\
    \ the posterior prediction of missing entities is balanced. We obtain conflicting\
    \ results for HP V <sup>→</sup><sup>A</sup> − 0 from the FDA as we cannot reject\
    \ it as in the original study. Our BDA suggests that passive voice has a slight\
    \ impact on the number of missing associations (25.5% less and 45.0% more likely\
    \ to miss an association). The result of the BDA does not suppose an effect as\
    \ strong as the original study, but it does agree with the re-analysis of the\
    \ original study [\\[47\\]](#page-46-11) on a slight impact. Overall, the results\
    \ of our BDA agree with the reanalyzed results of the original study. The variation\
    \ of study elements (e.g., experimental subjects and objects) [\\[59\\]](#page-47-13)\
    \ increases the replicability space within the generalizability space [\\[83\\\
    ]](#page-48-2) and identifies those elements as non-influential [\\[66\\]](#page-47-19)\
    \ to the original claim.\n\n# Comparison of Studies\n\nThe results of the frequentist\
    \ analyses of the original and our study differ. However, the more thorough Bayesian\
    \ data analysis agrees with the properly re-analyzed original results. Due to\
    \ the variation of several elements of our study from the original study, the\
    \ conceptual replication extends the external validity of the original claim that\
    \ passive voice has only a slight impact on the domain modeling activity.\n\n\
    # <span id=\"page-35-0\"></span>4.4 Comparison of FDA with BDA Results\n\nSecondly,\
    \ we compare the results of our frequentist data analysis with the results of\
    \ our Bayesian data analysis. We obtain consistent results [\\[19\\]](#page-45-14)\
    \ for H RQD∈{P V,AP,P V AP }→D 0 . Neither the frequentist nor Bayesian analysis\
    \ suggests an impact of the treatment on the relative duration to create a domain\
    \ model. −\n\nThe frequentist analysis rejects H RQD∈{P V,AP,PVAP}→E 0 , while\
    \ the Bayesian analysis remains more cautious. The posterior predictions in Table\
    \ [5](#page-31-1) show a tendency towards the treatment having an impact, but\
    \ with large uncertainty. Additionally, marginal plots of the Bayesian analysis\
    \ reveal that the primary role, experience with domain modeling, and education\
    \ impact the dependent variable. Both analyses agree that H RQD∈{P V,AP,PVAP}→E\
    \ + 0 cannot be rejected, though the Bayesian analysis attributes a tendency of\
    \ causing superfluous entities to ambiguous pronouns.\n\nThe frequentist analysis\
    \ suggests to reject H RQD∈{AP,PVAP}→A − 0 , i.e., ambiguous pronouns and their\
    \ coexistence with passive voice influence the number of missing associations.\
    \ The Bayesian analysis again shows a tendency towards an impact but retains its\
    \ uncertainty about the effect. Marginal plots instead emphasize the influence\
    \ of missing entities on the response variable.\n\nThe analyses agree on the impact\
    \ of ambiguous pronouns on the number of wrong associations and suggest to reject\
    \ H RQD∈{AP,PVAP}→A × 0 . Both the large effect size and the skewed distribution\
    \ of posterior predictions support the existence of a causal effect of ambiguous\
    \ pronouns on wrong associations in a domain model.\n\n# Comparison of Analysis\
    \ Methods\n\nThe results of our frequentist analysis differ from our Bayesian\
    \ analysis: the Bayesian data analysis remains more cautious about several effects\
    \ suggested by the frequentist analysis. The extended casual model attributes\
    \ part of the effect on the response variable on other independent variables than\
    \ the treatment.\n\n# <span id=\"page-36-0\"></span>5 Discussion\n\nSection [5.1](#page-36-1)\
    \ answers the research questions. Section [5.2](#page-37-0) discusses implications\
    \ for requirements quality practice and Section [5.3](#page-38-0) for requirements\
    \ quality research. Section [5.4](#page-40-1) presents the threats to validity.\n\
    \n# <span id=\"page-36-1\"></span>5.1 Answers to research questions\n\n# 5.1.1\
    \ Answer to RQ1\n\nRQ1.1: Impact of passive voice. Using passive voice in natural\
    \ language requirements specifications has a slightly negative effect on the domain\
    \ modeling activity regarding missing associations. This finding aligns with the\
    \ conclusions drawn by the original study by Femmer et al. [\\[36,](#page-45-2)\
    \ [47\\]](#page-46-11). However, the Bayesian data analysis emphasizes that both\
    \ context factors, and especially the number of missing entities, have a significant\
    \ impact on the number of missing associations as well. Overall, these results\
    \ support the claim that passive voice can have a negative impact in specific\
    \ cases but is overall not a significant factor in subsequent activities depending\
    \ on the requirement [\\[36,](#page-45-2) [73\\]](#page-47-5).\n\nRQ1.2: Impact\
    \ of ambiguous pronouns. The use of ambiguous pronouns has a strong effect on\
    \ the number of wrong associations in the resulting domain model. Additionally,\
    \ using ambiguous pronouns has a slight negative effect on the number of missing\
    \ and superfluous entities and missing associations. This confirms the risk of\
    \ using ambiguous pronouns that have been mainly hypothesized in previous research\
    \ [\\[31\\]](#page-45-5) and explains the focus on ambiguity in requirements quality\
    \ research [\\[80\\]](#page-48-0). An ambiguous pronoun in a requirements specification\
    \ has a 44.6% chance of causing a wrongly connected association in the domain\
    \ model, limiting the model's correctness and propagating risk to further activities.\n\
    \nRQ1.3: Combined impact. The co-occurrence of passive voice and ambiguous pronouns\
    \ has a strong effect on the number of wrong associations. Additionally, it has\
    \ a slight effect on the number of missing entities and associations. The impact\
    \ correlates with but never exceeds the effect of pure, ambiguous pronouns. This\
    \ supports the assumption that passive voice does not create any further impact\
    \ in addition to the effect of ambiguous pronouns.\n\n# 5.1.2 Answer to RQ2\n\n\
    RQ2.1: Impact of context factors. Only a small number of context factors included\
    \ in the study show a notable effect on the response variables. The duration of\
    \ the domain modeling activity confirms assumed patterns: taking shorter than\
    \ average increases the chance of missing elements or connecting associations\
    \ wrongly, taking longer time than average increases the chance of adding superfluous\
    \ entities. Prior formal training in modeling shows a slight yet not significant\
    \ positive effect.\n\nRQ2.2: Mediation of context factors. The interaction effect\
    \ between domain knowledge and the treatment shows that higher domain knowledge\
    \ can mitigate the negative effect of quality defects on response variables. In\
    \ particular: higher domain knowledge reduces the chance of connecting associations\
    \ incorrectly. While the effect still exhibits a large variance, this hints at\
    \ the possibility of compensating quality defects with domain knowledge.\n\n#\
    \ <span id=\"page-37-0\"></span>5.2 Implications for Requirements Quality Practice\n\
    \nThe presented results indicate that the negative impact of two requirements\
    \ quality defects can differ significantly. When allocating resources toward detecting\
    \ and removing specific quality defects from requirements specifications, organizations\
    \ can make informed decisions based on the calculated impact of the respective\
    \ quality factor. In our case, we recommend explicitly detecting and resolving\
    \ ambiguous pronouns, while passive voice is not critical enough to deserve dedicated\
    \ attention. This aligns with the common perception in requirements quality research\
    \ that ambiguity receives the most attention [\\[80\\]](#page-48-0) while using\
    \ passive voice rarely has a tangible impact [\\[73\\]](#page-47-5). By filtering\
    \ requirements writing guidelines for quality factors that have a measurable effect,\
    \ we expect greater acceptance of requirements quality assessment tools in practice\
    \ [\\[44,](#page-46-15) [90\\]](#page-48-12).\n\nAdditionally, measuring the effect\
    \ of a quality defect on the relevant attributes of activities that use these\
    \ requirements allows quantifying it economically [\\[48\\]](#page-46-0). While\
    \ the cost of a quality defect is hard to determine, a company can quantify the\
    \ cost of activities' attributes like increased duration. This economic perspective\
    \ provides additional decision support for companies when assessing whether it\
    \ is worth detecting and removing a specific quality defect [\\[65\\]](#page-47-3).\n\
    \nFinally, the potential influence of context factors on the impact of quality\
    \ defects on affected activities may incentivize organizations to invest in developing\
    \ these factors. For example, improving domain knowledge and providing formal\
    \ modeling training may compensate for quality defects.\n\n# <span id=\"page-38-0\"\
    ></span>5.3 Implications for Requirements Quality Research\n\nEmploying Bayesian\
    \ data analysis to investigate the impact of requirements quality defects provides\
    \ sophisticated and sensitive insights necessary to propel requirements quality\
    \ research [\\[48\\]](#page-46-0). The result of the analysis models both the\
    \ direction and strength of an impacting factor while retaining information about\
    \ its certainty. These insights go beyond the point-wise comparison and binary\
    \ result of frequentist analyses [\\[52\\]](#page-46-2). The frequentist analysis\
    \ fails to compare the impact of quality defects on the response variables, as\
    \ even the calculated effect sizes are similar (0.79 < |ES| < 0.93). The Bayesian\
    \ data analysis, on the other hand, clearly shows that some effects are much stronger\
    \ (e.g., HAP→<sup>A</sup> × 0 ) than others (e.g., HP V <sup>→</sup><sup>A</sup>\
    \ − 0 ). Still, the BDA relies on the causal model expressed in a DAG, statistical\
    \ assumptions about variable types and their independence, and the validity of\
    \ constructs. Therefore, the results obtained via BDA cannot be seen as more valid\
    \ by design. However, the BDA is more transparent and allows critical debate—e.g.,\
    \ about the causal assumptions underlying our analysis in Figure [10—](#page-30-0)which\
    \ facilitates the incremental improvement of empirical studies.\n\nIncluding context\
    \ factors in the prediction allows comparing the impact of requirements quality\
    \ with the impact of human and process factors, revealing which causes changes\
    \ in the response variable. These context factors can also represent the properties\
    \ of non-human agents like generative artificial intelligence (GenAI) models which\
    \ are increasingly employed for RE tasks. Involving context factors like the version\
    \ number of a GenAI model, its parameters, its context window, and other factors\
    \ in empirical studies resembling our approach will allow to investigate which\
    \ configurations of these models excel at performing their RE task.\n\nAbandoning\
    \ simple NHSTs for identifying relevant factors of requirements quality and instead\
    \ opting for a proper framework for causal inference like BDA will increase the\
    \ likelihood of solving problems with practical relevance [\\[44\\]](#page-46-15)\
    \ that justify subsequent tool development [\\[50\\]](#page-46-16). Empirical\
    \ studies with explicit causal assumptions (e.g., visualized as DAGs) and sophisticated\
    \ analyses will produce context-sensitive evidence that can be synthesized in\
    \ the common framework of the requirements quality theory [\\[48\\]](#page-46-0).\
    \ The continuous synthesis of evidence from individual studies in this common\
    \ framework will produce more reliable and generalizable conclusions [\\[1,](#page-44-16)\
    \ [22\\]](#page-45-21) and effectively address the lack of empirical insights\
    \ in requirements quality research [\\[80\\]](#page-48-0).\n\nUsing a controlled\
    \ experiment benefits the investigation of the quality factor [\\[36\\]](#page-45-2).\
    \ The DAG shown in Figure [10](#page-30-0) visualizes this control, as no other\
    \ factor influences the treatment in question. This eliminates spurious associations\
    \ that could confuse the results [\\[76\\]](#page-47-4). On the other hand, the\
    \ cost of conducting a controlled experiment—especially with participants from\
    \ industry—cannot be neglected [\\[102\\]](#page-49-12). Luckily, statistical\
    \ causal inference via Bayesian data analysis works equally well with observational\
    \ data, as shown by Furia et al. [\\[54\\]](#page-46-14).\n\nFinally, Bayesian\
    \ data analysis allows for incremental improvement of empirical inquiry regarding\
    \ requirements quality. The causal assumptions that the DAG makes explicit can\
    \ be reviewed, discussed, and updated to inform future empirical methods. Insights\
    \ derived from Bayesian data analysis can be used as prior knowledge in subsequent\
    \ analyses, just as we sensibly used previous results [\\[36\\]](#page-45-2) to\
    \ inform our priors.\n\nWorth noting is that our comparison between FDA and BDA\
    \ conflates the use of causal frameworks with advanced Bayesian statistics. An\
    \ FDA can also employ causal frameworks that mitigate parts of the shortcomings\
    \ mentioned in Section [2.2,](#page-8-0) as previously shown by Furia et al. [\\\
    [54\\]](#page-46-14). However, frequentist approaches tend to limit their analyses\
    \ to the treatment and the response variable, disregarding potential context [\\\
    [81\\]](#page-48-1) or experimental design factors [\\[107\\]](#page-49-11). BDA,\
    \ on the other hand, entails the use of an explicit causal framework [\\[76,](#page-47-4)\
    \ [87\\]](#page-48-14), which is why we support the recommendation of abandoning\
    \ FDA for BDA in SE research [\\[52,](#page-46-2) [106\\]](#page-49-7).\n\n# Implications\n\
    \nQuality defects in requirements specifications have a varying impact on affected\
    \ activities that depend on them. Context factors may compensate for this impact\
    \ but require better metrics to quantify them. Bayesian data analysis provides\
    \ more fine-grained insights into these effects than frequentist methods.\n\n\
    # <span id=\"page-40-1\"></span>5.4 Threats to Validity\n\nWe present and discuss\
    \ threats that could affect our study based on the guidelines by Wohlin et al.\
    \ [\\[113\\]](#page-49-10) and extended by the guideline by Vegas et al. [\\[107\\\
    ]](#page-49-11) for the specific threats caused by the use of a crossover design.\
    \ The threats to validity are prioritized, considering our work focuses on replicating\
    \ the first study testing a causal theory predicting the impact of requirements\
    \ quality factors on downstream development tasks.\n\n# <span id=\"page-40-0\"\
    ></span>5.4.1 Internal validity\n\nOur design and the blind nature of the experiment\
    \ avoid the threat to selectionmaturation interaction. Nevertheless, the new settings\
    \ (i.e., online asynchronous experiment) may have caused a diffusion or imitation\
    \ of treatments—i.e., information may have been exchanged among the participants.\
    \ The experiment supervisor monitored the participants to prevent their communication\
    \ with each other and asked them not to distribute the experimental task and materials.\
    \ We acknowledge that selection can bias our sample as volunteers are generally\
    \ more motivated to perform in an experimental task [\\[3\\]](#page-44-12).\n\n\
    The crossover design emits additional threats to validity [\\[107\\]](#page-49-11).\
    \ We mitigate the learning by practice effect—i.e., participants getting better\
    \ when repeating the experimental task—in three ways: Firstly, we disperse the\
    \ learning effect evenly at design time by randomizing the sequences of treatments.\
    \ Secondly, we include a warm-up object to get participants used to the task and\
    \ tool but exclude that data from the analysis. Thirdly, we include the period\
    \ variable as a predictor to factor out the learning effect during the analysis.\
    \ We avoid the threat of copying by prohibiting communication among participants\
    \ and using experimental objects where solutions cannot be copied from one task\
    \ to another.\n\nThe threat of optimal sequence describes the risk that there\
    \ is a sequence in which the treatment is applied, which optimizes the participants'\
    \ performance in deriving domain models. We cannot block this threat at analysis\
    \ time as the sequence and participant IDs are highly correlated. This is because\
    \ we could in all but one case—assign only one participant (n<sup>p</sup> = 25)\
    \ to each sequence (n<sup>s</sup> = nr! = 4! = 24). Because of this strong correlation,\
    \ the Bayesian model is incapable of distinguishing between the impact of the\
    \ sequence (βseq) from the within-participant variance (αP ID) [\\[107\\]](#page-49-11).\
    \ More participants per sequence would have been necessary to block the threat\
    \ of an optimal sequence, but these were unavailable to us.\n\nFinally, we address\
    \ the threat of carryover—i.e., the change of the impact caused by the period\
    \ in which the treatment was applied—at analysis time by including the term period∗treatment\
    \ in the predictors. This way, the carryover effect is factored out from the impact\
    \ of the treatment and analyzable from the posterior distributions.\n\n# 5.4.2\
    \ Conclusion validity\n\nWe addressed the reliability of measures threat by creating\
    \ and disclosing evaluation guidelines and peer-reviewing the extraction of the\
    \ dependent variables from the collected domain models. Despite the acceptable\
    \ inter-rater agreement score, an in-depth qualitative evaluation of the remaining\
    \ disagreements may be beneficial to further improve the evaluation instrument\
    \ and, therefore, the reliability of the results. We addressed the random heterogeneity\
    \ of the subjects by a design in which each participant acts as their own control\
    \ group.\n\nMoreover, we focused on including and analyzing context variables\
    \ related to the participants' experience. Our sample of participants is not representative\
    \ of all context factors. Consequently, our Bayesian data analysis cannot identify\
    \ all causal effects of some context factors. However, by including them in the\
    \ causal considerations, the effect of the factors is isolated from the potential\
    \ confounding variables [\\[74\\]](#page-47-11).\n\nThe conclusion validity of\
    \ our study is strengthened by applying two different data analysis approaches\
    \ and comparing their results. The data analysis suffers from the threat of low\
    \ statistical power when it comes to evaluating interaction effects, as reliably\
    \ identifying them requires a larger sample size [\\[55\\]](#page-46-17). We limit\
    \ the number of interaction effects considered in our models and discuss the uncertainty\
    \ around the coefficient estimates to minimize this threat.\n\nThe analysis can\
    \ suffer from violated assumptions of statistical tests. Modeling the number of\
    \ missing entities and associations as binomial distributions implies the independence\
    \ of each event, i.e., that each missing entity and association is independent\
    \ of all other missing entities and associations. While we did not observe any\
    \ cascading, i.e., dependent, defects, their independence remains only assumed.\n\
    \n# 5.4.3 Construct validity\n\nOur study can suffer from mono-operation bias\
    \ as we focus only on a subset of quality factors that can potentially exist [\\\
    [49,](#page-46-5) [80\\]](#page-48-0). Nevertheless, our goal with this replication\
    \ is to extend the initial quality factor of passive voice reported by Femmer\
    \ et al. [\\[36\\]](#page-45-2) to a second one—ambiguous pronouns—which is widespread\
    \ as indicated by the literature [\\[49,](#page-46-5) [80\\]](#page-48-0).\n\n\
    Similarly, a confounding of constructs and level of constructs could influence\
    \ the outcomes of our study, for example, the presence of several ambiguous pronouns\
    \ or passive voice sentences rather than their binary presence or absence from\
    \ a specification. Further replications, focusing on improving construct validity,\
    \ should include several levels of each treatment.\n\nMono-method bias is a potential\
    \ threat to construct validity—i.e., we measured the dependent variables using\
    \ a single type of measurement, inspired by the original study. However, the measurements\
    \ were based on a pre-defined protocol and peer-reviewed. Our study may result\
    \ in a restricted generalizability across constructs since the presence or absence\
    \ of the different quality factors could result in side effects for other interesting\
    \ outcomes we did not measure (e.g., comprehensibility or maintainability of the\
    \ specification).\n\nAmong the social threats to construct validity, we acknowledge\
    \ that hypothesis guessing may have taken place since the participants could try\
    \ to guess the concrete goal of the experimental task based on the invitation\
    \ text and material provided during the sessions. Nevertheless, we used the same\
    \ text and phrasing to invite all participants and the same material during the\
    \ experimental task. Evaluation apprehension could have played a role since some\
    \ participants are students at the authors' institution. However, students did\
    \ not receive rewards (e.g., extra grade points) for participating in the experiment,\
    \ and they received their course grades before the start of the experiment.\n\n\
    Moreover, our study can suffer from an inadequate preoperational explication of\
    \ constructs as we did not validate our context factors. For example, we are unable\
    \ to provide any proof that the self-reported number of years spent in RE adequately\
    \ represents the latent variable of experience in RE beyond educated guesses and\
    \ relying on comparable practices in our scientific community [\\[10\\]](#page-44-14).\
    \ To improve the construct validity, separate studies investigating the adequacy\
    \ of these measurements in representing their constructs are necessary. This particularly\
    \ impacts our decision to replace the binary distinction of participants by type\
    \ (students versus practitioners) with more fine-grained variables like experience\
    \ and domain knowledge. While our study supports the feasibility of this step\
    \ on an analytical level, we cannot prove its validity on a conceptual level.\
    \ We encourage investigating the feasibility of variables to represent individual\
    \ skills to improve the construct validity of studies considering this impact\
    \ [\\[97\\]](#page-48-17).\n\nFinally, a variable of the selected population that\
    \ may interact with the treatment that we did not analyze is the language skill\
    \ of participants. Arguably, skills in the English language influence the ability\
    \ to comprehend and process the experimental objects and, therefore, may impact\
    \ the response variables. We were unable to measure this variable properly given\
    \ that all participants scored the same on the Common European Framework of Reference\
    \ for Languages (CEFR) [\\[75\\]](#page-47-20) (i.e., non-native, fluent English\
    \ speakers). While the threat is minimized in our study due to the comparable\
    \ language level of participants, future studies should develop measurement instruments\
    \ for this construct and involve this variable in such causal queries.\n\n# 5.4.4\
    \ External validity\n\nThe main threat to the external validity of this study\
    \ is the interaction of setting and treatment as the size and the complexity of\
    \ the selected specifications, despite being sampled from a real-world data set,\
    \ might not be representative of the industrial practice. Using Google Docs as\
    \ the modeling tool is not fully representative of real-world practices. Given\
    \ that it was appropriate and sufficient for the experimental task, however, renders\
    \ this as an opportunity for improving the realism of the experiment in future\
    \ studies rather than a threat to validity.\n\nThere may be the threat of interaction\
    \ of selection and treatment, as some participants reported no modeling experience\
    \ or training. These deficiencies might influence the results and render a subset\
    \ of the participants as nonrepresentative of our target population. We attempted\
    \ to mitigate this threat via comprehensive instructions and including a warm-up\
    \ phase in the experiment.\n\n# <span id=\"page-43-0\"></span>6 Conclusion\n\n\
    Requirements quality research lacks empirical evidence and research strategies\
    \ to advance beyond proposing and following normative rules with unclear impact\
    \ [\\[49\\]](#page-46-5) to better understanding and solving problems relevant\
    \ to practice [\\[43,](#page-46-1) [44\\]](#page-46-15). In the scope of our study,\
    \ we conducted a controlled experiment on the impact of requirements quality defects\
    \ on subsequent activities. We demonstrated a method of evaluating data collected\
    \ through a controlled experiment using a crossover design with Bayesian data\
    \ analysis. We showed the impact (1) of requirements quality defects varies and\
    \ (2) may be mediated by context and confounding factors. The part of our study\
    \ that serves as a conceptual replication strengthens the claims of the re-analyzed\
    \ original study [\\[36,](#page-45-2) [47\\]](#page-46-11) that passive voice\
    \ only has a slight impact on missing associations from domain models.\n\nWe can\
    \ confidently support the recommendation of SE researchers to adopt Bayesian data\
    \ analysis to improve causal reasoning and inference [\\[52,](#page-46-2) [53,](#page-46-10)\
    \ [106\\]](#page-49-7), which will propel requirements quality research. This\
    \ shift requires focusing on problems such as scrutinizing the explicit causal\
    \ assumptions of a DAG, visualizing requirements quality impact, evolving prior\
    \ knowledge about their impact, and comparing models concerning their predictive\
    \ power.\n\nWe envision that adopting sophisticated statistical tools like Bayesian\
    \ data analysis and the focus of empirical studies on investigating the impact\
    \ of requirements quality defects will steer requirements quality research in\
    \ a relevant and effective direction. Explicit causal assumptions and sophisticated\
    \ data analyses will produce empirical evidence which can be more easily synthesized\
    \ to more reliable and generalizable conclusions [\\[22\\]](#page-45-21) in a\
    \ common framework [\\[48\\]](#page-46-0). We hope that the documentation of this\
    \ study inspires fellow researchers to adopt our method and tools for replication.\n\
    \nAcknowledgements This work was supported by the KKS foundation through the S.E.R.T.\
    \ Research Profile project at Blekinge Institute of Technology. We are deeply\
    \ grateful to Parisa Yousefi from Ericsson AB for recruiting practitioners to\
    \ the experiment. We further thank the reviewers for their tremendous effort that\
    \ significantly improved this manuscript.\n\n# Conflict of interest\n\nThe authors\
    \ declare that they have no conflict of interest.\n\n# Data Availability Statement\n\
    \nAll supplementary material, including protocols and guidelines for data collection\
    \ and extraction, the raw data, analysis scripts, figures, and results, are available\
    \ in our replication package [\\[46\\]](#page-46-3). The replication package is\
    \ available on GitHub at <https://github.com/JulianFrattini/rqi-proto> and archived\
    \ on Zenodo at <https://doi.org/10.5281/zenodo.10423666>.\n\n# References\n\n\
    - <span id=\"page-44-16\"></span>1. Badampudi, D., Wohlin, C., Gorschek, T.: Contextualizing\
    \ research evidence through knowledge translation in software engineering. In:\
    \ Proceedings of the 23rd International Conference on Evaluation and Assessment\
    \ in Software Engineering, pp. 306–311 (2019)\n- <span id=\"page-44-1\"></span>2.\
    \ Baldassarre, M.T., Carver, J., Dieste, O., Juristo, N.: Replication types: Towards\
    \ a shared taxonomy. In: Proceedings of the 18th International Conference on Evaluation\
    \ and Assessment in Software Engineering, pp. 1–4 (2014)\n- <span id=\"page-44-12\"\
    ></span>3. Baltes, S., Ralph, P.: Sampling in software engineering research: A\
    \ critical review and guidelines. Empirical Software Engineering 27(4), 94 (2022)\n\
    - <span id=\"page-44-2\"></span>4. Bano, M.: Addressing the challenges of requirements\
    \ ambiguity: A review of empirical literature. In: 2015 IEEE Fifth International\
    \ Workshop on Empirical Requirements Engineering (EmpiRE), pp. 21–24. IEEE (2015)\n\
    - <span id=\"page-44-5\"></span>5. Belev, G.: Guidelines for specification development.\
    \ In: Proceedings., Annual Reliability and Maintainability Symposium, pp. 15–21.\
    \ IEEE (1989)\n- <span id=\"page-44-13\"></span>6. Benjamini, Y., Hochberg, Y.:\
    \ Controlling the false discovery rate: A practical and powerful approach to multiple\
    \ testing. Journal of the Royal statistical society: series B (Methodological)\
    \ 57(1), 289–300 (1995)\n- <span id=\"page-44-11\"></span>7. Berntsson Svensson,\
    \ R., Torkar, R.: Not all requirements prioritization criteria are equal at all\
    \ times: A quantitative analysis. Journal of Systems and Software 209, 111909\
    \ (2024). DOI 10.1016/j.jss.2023.111909\n- <span id=\"page-44-3\"></span>8. Berry,\
    \ D.M., Kamsties, E.: Ambiguity in requirements specification. In: Perspectives\
    \ on software requirements, pp. 7–44. Springer (2004)\n- <span id=\"page-44-0\"\
    ></span>9. Boehm, B.W.: Software engineering economics. IEEE transactions on Software\
    \ Engineering SE-10(1), 4–21 (1984)\n- <span id=\"page-44-14\"></span>10. Bogner,\
    \ J., Kotstein, S., Pfaff, T.: Do restful api design rules have an impact on the\
    \ understandability of web apis? Empirical software engineering 28(6), 132 (2023)\n\
    - <span id=\"page-44-6\"></span>11. Boyd, S., Zowghi, D., Farroukh, A.: Measuring\
    \ the expressiveness of a constrained natural language: An empirical study. In:\
    \ 13th IEEE International Conference on Requirements Engineering (RE'05), pp.\
    \ 339–349. IEEE (2005)\n- <span id=\"page-44-7\"></span>12. Briand, L., Bianculli,\
    \ D., Nejati, S., Pastore, F., Sabetzadeh, M.: The case for contextdriven software\
    \ engineering research: Generalizability is overrated. IEEE Software 34(5), 72–75\
    \ (2017)\n- <span id=\"page-44-8\"></span>13. Brooks, S., Gelman, A., Jones, G.,\
    \ Meng, X.L.: Handbook of Markov Chain Monte Carlo. CRC press (2011)\n- <span\
    \ id=\"page-44-15\"></span>14. Brown Jr, B.W.: The crossover experiment for clinical\
    \ trials. Biometrics pp. 69–79 (1980)\n- <span id=\"page-44-4\"></span>15. de\
    \ Bruijn, F., Dekkers, H.L.: Ambiguity in natural language software requirements:\
    \ A case study. In: Requirements Engineering: Foundation for Software Quality:\
    \ 16th International Working Conference, REFSQ 2010, Essen, Germany, June 30–July\
    \ 2, 2010. Proceedings 16, pp. 233–247. Springer (2010)\n- <span id=\"page-44-10\"\
    ></span>16. B¨urkner, P.C.: brms: An R package for Bayesian multilevel models\
    \ using Stan. Journal of statistical software 80, 1–28 (2017)\n- <span id=\"page-44-9\"\
    ></span>17. Carpenter, B., Gelman, A., Hoffman, M.D., Lee, D., Goodrich, B., Betancourt,\
    \ M., Brubaker, M., Guo, J., Li, P., Riddell, A.: Stan: A probabilistic programming\
    \ language. Journal of statistical software 76(1) (2017)\n- <span id=\"page-45-15\"\
    ></span>18. Carver, J., Jaccheri, L., Morasca, S., Shull, F.: Issues in using\
    \ students in empirical studies in software engineering education. In: Proceedings.\
    \ 5th international workshop on enterprise networking and computing in healthcare\
    \ industry (IEEE Cat. No. 03EX717), pp. 239–249. IEEE (2004)\n- <span id=\"page-45-14\"\
    ></span>19. Carver, J.C.: Towards reporting guidelines for experimental replications:\
    \ A proposal. In: 1st international workshop on replication in empirical software\
    \ engineering, vol. 1, pp. 1–4 (2010)\n- <span id=\"page-45-8\"></span>20. Chantree,\
    \ F., Nuseibeh, B., De Roeck, A., Willis, A.: Identifying nocuous ambiguities\
    \ in natural language requirements. In: 14th IEEE International Requirements Engineering\
    \ Conference (RE'06), pp. 59–68. IEEE (2006)\n- <span id=\"page-45-10\"></span>21.\
    \ Christel, M.G., Kang, K.C.: Issues in requirements elicitation (1992)\n- <span\
    \ id=\"page-45-21\"></span>22. Ciolkowski, M., M¨unch, J.: Accumulation and presentation\
    \ of empirical evidence: problems and challenges. ACM SIGSOFT Software Engineering\
    \ Notes 30(4), 1–3 (2005)\n- <span id=\"page-45-20\"></span>23. Cohen, B.H.: Explaining\
    \ psychological statistics. John Wiley & Sons (2008)\n- <span id=\"page-45-17\"\
    ></span>24. Cohen, J.: Statistical power analysis for the behavioral sciences.\
    \ Academic press (1969)\n- <span id=\"page-45-4\"></span>25. Deissenboeck, F.,\
    \ Wagner, S., Pizka, M., Teuchert, S., Girard, J.F.: An activity-based quality\
    \ model for maintainability. In: 2007 IEEE International Conference on Software\
    \ Maintenance, pp. 184–193. IEEE (2007)\n- <span id=\"page-45-18\"></span>26.\
    \ Demaris, A.: Logit modeling: Practical applications. 86. Sage (1992)\n- <span\
    \ id=\"page-45-6\"></span>27. Drechsler, R., Soeken, M., Wille, R.: Automated\
    \ and quality-driven requirements engineering. In: 2014 IEEE/ACM International\
    \ Conference on Computer-Aided Design (ICCAD), pp. 586–590. IEEE (2014)\n- <span\
    \ id=\"page-45-16\"></span>28. Dyb˚a, T., Kampenes, V.B., Sjøberg, D.I.: A systematic\
    \ review of statistical power in software engineering experiments. Information\
    \ and Software Technology 48(8), 745– 755 (2006)\n- <span id=\"page-45-13\"></span>29.\
    \ Elwert, F.: Graphical causal models. In: Handbook of causal analysis for social\
    \ research, pp. 245–273. Springer (2013)\n- <span id=\"page-45-19\"></span>30.\
    \ Ernst, N.A.: Bayesian hierarchical modelling for tailoring metric thresholds.\
    \ In: Proceedings of the 15th international conference on mining software repositories,\
    \ pp. 587– 591 (2018). DOI 10.1145/3196398.3196443\n- <span id=\"page-45-5\"></span>31.\
    \ Ezzini, S., Abualhaija, S., Arora, C., Sabetzadeh, M.: Automated handling of\
    \ anaphoric ambiguity in requirements: A multi-solution study. In: Proceedings\
    \ of the 44th International Conference on Software Engineering, pp. 187–199 (2022)\n\
    - 32. Ezzini, S., Abualhaija, S., Arora, C., Sabetzadeh, M.: TAPHSIR: towards\
    \ AnaPHoric ambiguity detection and ReSolution in requirements. In: Proceedings\
    \ of the 30th ACM Joint European Software Engineering Conference and Symposium\
    \ on the Foundations of Software Engineering, pp. 1677–1681 (2022)\n- <span id=\"\
    page-45-9\"></span>33. Ezzini, S., Abualhaija, S., Arora, C., Sabetzadeh, M.,\
    \ Briand, L.C.: Using domainspecific corpora for improved handling of ambiguity\
    \ in requirements. In: 2021 IEEE/ACM 43rd International Conference on Software\
    \ Engineering (ICSE), pp. 1485– 1497. IEEE (2021)\n- <span id=\"page-45-12\"></span>34.\
    \ Femmer, H.: Requirements quality defect detection with the qualicen requirements\
    \ scout. In: REFSQ Workshops (2018)\n- <span id=\"page-45-3\"></span>35. Femmer,\
    \ H., Fern´andez, D.M., Wagner, S., Eder, S.: Rapid quality assurance with requirements\
    \ smells. Journal of Systems and Software 123, 190–213 (2017)\n- <span id=\"page-45-2\"\
    ></span>36. Femmer, H., Kuˇcera, J., Vetr`o, A.: On the impact of passive voice\
    \ requirements on domain modelling. In: Proceedings of the 8th ACM/IEEE International\
    \ Symposium on Empirical Software Engineering and Measurement, pp. 1–4 (2014)\n\
    - <span id=\"page-45-0\"></span>37. Femmer, H., Mund, J., Fern´andez, D.M.: It's\
    \ the activities, stupid! A new perspective on re quality. In: 2015 IEEE/ACM 2nd\
    \ International Workshop on Requirements Engineering and Testing, pp. 13–19. IEEE\
    \ (2015)\n- <span id=\"page-45-1\"></span>38. Femmer, H., Vogelsang, A.: Requirements\
    \ quality is quality in use. IEEE Software 36(3), 83–91 (2018)\n- <span id=\"\
    page-45-11\"></span>39. Ferrari, A., Esuli, A.: An NLP approach for cross-domain\
    \ ambiguity detection in requirements engineering. Automated Software Engineering\
    \ 26(3), 559–598 (2019)\n- <span id=\"page-45-7\"></span>40. Ferrari, A., Gori,\
    \ G., Rosadini, B., Trotta, I., Bacherini, S., Fantechi, A., Gnesi, S.: Detecting\
    \ requirements defects with NLP patterns: An industrial experience in the railway\
    \ domain. Empirical Software Engineering 23, 3684–3733 (2018)\n- <span id=\"page-46-12\"\
    ></span>41. Ferrari, A., Spagnolo, G.O., Gnesi, S.: Pure: A dataset of public\
    \ requirements documents. In: 2017 IEEE 25th International Requirements Engineering\
    \ Conference (RE), pp. 502–505. IEEE (2017)\n- <span id=\"page-46-8\"></span>42.\
    \ Firesmith, D.: Common requirements problems, their negative consequences, and\
    \ the industry best practices to help solve them. J. Object Technol. 6(1), 17–33\
    \ (2007)\n- <span id=\"page-46-1\"></span>43. Franch, X., Fern´andez, D.M., Oriol,\
    \ M., Vogelsang, A., Heldal, R., Knauss, E., Travassos, G.H., Carver, J.C., Dieste,\
    \ O., Zimmermann, T.: How do practitioners perceive the relevance of requirements\
    \ engineering research? An ongoing study. In: 2017 IEEE 25th International Requirements\
    \ Engineering Conference (RE), pp. 382–387. IEEE (2017)\n- <span id=\"page-46-15\"\
    ></span>44. Franch, X., Mendez, D., Vogelsang, A., Heldal, R., Knauss, E., Oriol,\
    \ M., Travassos, G., Carver, J.C., Zimmermann, T.: How do practitioners perceive\
    \ the relevance of requirements engineering research? IEEE Transactions on Software\
    \ Engineering (2020)\n- <span id=\"page-46-4\"></span>45. Franch, X., Palomares,\
    \ C., Quer, C., Chatzipetrou, P., Gorschek, T.: The state-ofpractice in requirements\
    \ specification: an extended interview study at 12 companies. Requirements Engineering\
    \ pp. 1–33 (2023). DOI 10.1007/s00766-023-00399-7\n- <span id=\"page-46-3\"></span>46.\
    \ Frattini, J.: Replication package for the \"applying bayesian data analysis\
    \ for causal inference about requirements quality: a controlled experiment\".\
    \ [https://zenodo.org/](https://zenodo.org/doi/10.5281/zenodo.10423665) [doi/10.5281/zenodo.10423665](https://zenodo.org/doi/10.5281/zenodo.10423665)\
    \ (2024). Accessed: 2024-06-21\n- <span id=\"page-46-11\"></span>47. Frattini,\
    \ J., Fucci, D., Torkar, R., Mendez, D.: A second look at the impact of passive\
    \ voice requirements on domain modeling: Bayesian reanalysis of an experiment.\
    \ In: International Workshop on Methodological Issues with Empirical Studies in\
    \ Software Engineering (WSESE'24) (2024)\n- <span id=\"page-46-0\"></span>48.\
    \ Frattini, J., Montgomery, L., Fischbach, J., Mendez, D., Fucci, D., Unterkalmsteiner,\
    \ M.: Requirements quality research: A harmonized theory, evaluation, and roadmap.\
    \ Requirements Engineering pp. 1–14 (2023)\n- <span id=\"page-46-5\"></span>49.\
    \ Frattini, J., Montgomery, L., Fischbach, J., Unterkalmsteiner, M., Mendez, D.,\
    \ Fucci, D.: A live extensible ontology of quality factors for textual requirements.\
    \ In: 2022 IEEE 30th International Requirements Engineering Conference (RE), pp.\
    \ 274–280. IEEE (2022)\n- <span id=\"page-46-16\"></span>50. Frattini, J., Unterkalmsteiner,\
    \ M., Fucci, D., Mendez, D.: NLP4RE Tools: Classification, Overview, and Management.\
    \ Springer International Publishing (2024)\n- <span id=\"page-46-13\"></span>51.\
    \ Fucci, D., Scanniello, G., Romano, S., Shepperd, M., Sigweni, B., Uyaguari,\
    \ F., Turhan, B., Juristo, N., Oivo, M.: An external replication on the effects\
    \ of test-driven development using a multi-site blind analysis approach. In: Proceedings\
    \ of the 10th ACM/IEEE International Symposium on Empirical Software Engineering\
    \ and Measurement, ESEM '16. Association for Computing Machinery, New York, NY,\
    \ USA (2016). DOI 10.1145/2961111.2962592. URL [https://doi.org/10.1145/2961111.](https://doi.org/10.1145/2961111.2962592)\
    \ [2962592](https://doi.org/10.1145/2961111.2962592)\n- <span id=\"page-46-2\"\
    ></span>52. Furia, C.A., Feldt, R., Torkar, R.: Bayesian data analysis in empirical\
    \ software engineering research. IEEE Transactions on Software Engineering 47(9),\
    \ 1786–1810 (2019)\n- <span id=\"page-46-10\"></span>53. Furia, C.A., Torkar,\
    \ R., Feldt, R.: Applying Bayesian analysis guidelines to empirical software engineering\
    \ data: The case of programming languages and code quality. ACM Transactions on\
    \ Software Engineering and Methodology (TOSEM) 31(3), 1–38 (2022)\n- <span id=\"\
    page-46-14\"></span>54. Furia, C.A., Torkar, R., Feldt, R.: Towards causal analysis\
    \ of empirical software engineering data: The impact of programming languages\
    \ on coding competitions. ACM Transactions on Software Engineering and Methodology\
    \ 33(1) (2023). DOI 10.1145/3611667\n- <span id=\"page-46-17\"></span>55. Gelman,\
    \ A.: You need 16 times the sample size to estimate an interaction than to estimate\
    \ a main effect. <https://statmodeling.stat.columbia.edu/2018/03/15/need16/>.\
    \ Accessed: 2023-11-24\n- <span id=\"page-46-9\"></span>56. Gelman, A., Vehtari,\
    \ A., Simpson, D., Margossian, C.C., Carpenter, B., Yao, Y., Kennedy, L., Gabry,\
    \ J., B¨urkner, P.C., Modr´ak, M.: Bayesian workflow. arXiv preprint arXiv:2011.01808\
    \ (2020)\n- <span id=\"page-46-6\"></span>57. G´enova, G., Fuentes, J.M., Llorens,\
    \ J., Hurtado, O., Moreno, V.: A framework to measure and improve the quality\
    \ of textual requirements. Requirements engineering 18, 25–41 (2013)\n- <span\
    \ id=\"page-46-7\"></span>58. Gleich, B., Creighton, O., Kof, L.: Ambiguity detection:\
    \ Towards a tool explaining ambiguity sources. In: Requirements Engineering: Foundation\
    \ for Software Quality:\n\n16th International Working Conference, REFSQ 2010,\
    \ Essen, Germany, June 30–July 2, 2010. Proceedings 16, pp. 218–232. Springer\
    \ (2010)\n\n- <span id=\"page-47-13\"></span>59. G´omez, O.S., Juristo, N., Vegas,\
    \ S.: Replications types in experimental disciplines. In: Proceedings of the 2010\
    \ ACM-IEEE international symposium on empirical software engineering and measurement,\
    \ pp. 1–10 (2010)\n- <span id=\"page-47-12\"></span>60. Gren, L., Berntsson Svensson,\
    \ R.: Is it possible to disregard obsolete requirements? a family of experiments\
    \ in software effort estimation. Requirements Engineering 26(3), 459–480 (2021)\n\
    - <span id=\"page-47-6\"></span>61. Hasso, H., Dembach, M., Geppert, H., Toews,\
    \ D.: Detection of defective requirements using rule-based scripts. In: REFSQ\
    \ Workshops (2019)\n- <span id=\"page-47-16\"></span>62. Hsu, H., Lachenbruch,\
    \ P.A.: Paired t test. Wiley StatsRef: statistics reference online (2014)\n- <span\
    \ id=\"page-47-18\"></span>63. Jaynes, E.T.: Probability theory: The logic of\
    \ science. Cambridge University Press, Cambridge (2003)\n- <span id=\"page-47-14\"\
    ></span>64. Jedlitschka, A., Ciolkowski, M., Pfahl, D.: Reporting experiments\
    \ in software engineering. Guide to advanced empirical software engineering pp.\
    \ 201–228 (2008)\n- <span id=\"page-47-3\"></span>65. Juergens, E., Deissenboeck,\
    \ F.: How much is a clone. In: Proceedings of the 4th International Workshop on\
    \ Software Quality and Maintainability, pp. 79–88 (2010)\n- <span id=\"page-47-19\"\
    ></span>66. Juristo, N., Vegas, S.: The role of non-exact replications in software\
    \ engineering experiments. Empirical Software Engineering 16, 295–324 (2011)\n\
    - <span id=\"page-47-10\"></span>67. Kamsties, E., von Knethen, A., Philipps,\
    \ J.: An empirical investigation of requirements specification languages: Detecting\
    \ defects while formalizing requirements. In: Information Modeling Methods and\
    \ Methodologies: Advanced Topics in Database Research, pp. 125–147. IGI Global\
    \ (2005)\n- <span id=\"page-47-9\"></span>68. Kamsties, E., Peach, B.: Taming\
    \ ambiguity in natural language requirements. In: Proceedings of the Thirteenth\
    \ international conference on Software and Systems Engineering and Applications,\
    \ vol. 1315 (2000)\n- <span id=\"page-47-17\"></span>69. King, B.M., Rosopa, P.J.,\
    \ Minium, E.W.: Statistical reasoning in the behavioral sciences. John Wiley &\
    \ Sons (2018)\n- <span id=\"page-47-15\"></span>70. Kitchenham, B., Fry, J., Linkman,\
    \ S.: The case against cross-over designs in software engineering. In: Eleventh\
    \ annual international workshop on software technology and engineering practice,\
    \ pp. 65–67. IEEE (2003)\n- <span id=\"page-47-8\"></span>71. Knauss, E., Schneider,\
    \ K., Stapel, K.: Learning to write better requirements through heuristic critiques.\
    \ In: 2009 17th IEEE International Requirements Engineering Conference, pp. 387–388.\
    \ IEEE (2009)\n- <span id=\"page-47-7\"></span>72. Kof, L.: Treatment of passive\
    \ voice and conjunctions in use case documents. In: Natural Language Processing\
    \ and Information Systems: 12th International Conference on Applications of Natural\
    \ Language to Information Systems, NLDB 2007, Paris, France, June 27-29, 2007.\
    \ Proceedings 12, pp. 181–192. Springer (2007)\n- <span id=\"page-47-5\"></span>73.\
    \ Krisch, J., Houdek, F.: The myth of bad passive voice and weak words an empirical\
    \ investigation in the automotive industry. In: 2015 IEEE 23rd International Requirements\
    \ Engineering Conference (RE), pp. 344–351. IEEE (2015)\n- <span id=\"page-47-11\"\
    ></span>74. Lev´en, W., Broman, H., Besker, T., Torkar, R.: The Broken Windows\
    \ Theory applies to technical debt. arXiv preprint arXiv:2209.01549 (2022)\n-\
    \ <span id=\"page-47-20\"></span>75. Martyniuk, W.: Common european framework\
    \ of reference for languages: Learning, teaching, assessment (cefr)–a synopsis.\
    \ In: Annual meeting of the consortium for language teaching and learning cornell\
    \ university. Concil of Europe, Language policy division. https://rm. coe. int/16802fc1bf\
    \ (2006)\n- <span id=\"page-47-4\"></span>76. McElreath, R.: Statistical rethinking:\
    \ A Bayesian course with examples in R and Stan. CRC press (2020)\n- <span id=\"\
    page-47-2\"></span>77. M´endez, D., Wagner, S., Kalinowski, M., Felderer, M.,\
    \ Mafra, P., Vetr`o, A., Conte, T., Christiansson, M.T., Greer, D., Lassenius,\
    \ C., et al.: Naming the pain in requirements engineering: Contemporary problems,\
    \ causes, and effects in practice. Empirical software engineering 22, 2298–2338\
    \ (2017)\n- <span id=\"page-47-0\"></span>78. M´endez Fern´andez, D., B¨ohm, W.,\
    \ Vogelsang, A., Mund, J., Broy, M., Kuhrmann, M., Weyer, T.: Artefacts in software\
    \ engineering: A fundamental positioning. Software & Systems Modeling 18, 2777–2786\
    \ (2019)\n- <span id=\"page-47-1\"></span>79. M´endez Fern´andez, D., Penzenstadler,\
    \ B.: Artefact-based requirements engineering: the AMDiRE approach. Requirements\
    \ Engineering 20, 405–434 (2015)\n- <span id=\"page-48-0\"></span>80. Montgomery,\
    \ L., Fucci, D., Bouraffa, A., Scholz, L., Maalej, W.: Empirical research on requirements\
    \ quality: A systematic mapping study. Requirements Engineering 27(2), 183–209\
    \ (2022)\n- <span id=\"page-48-1\"></span>81. Mund, J., Fernandez, D.M., Femmer,\
    \ H., Eckhardt, J.: Does quality of requirements specifications matter? Combined\
    \ results of two empirical studies. In: 2015 ACM/IEEE International Symposium\
    \ on Empirical Software Engineering and Measurement (ESEM), pp. 1–10. IEEE (2015)\n\
    - <span id=\"page-48-20\"></span>82. Nilsson, A., Bonander, C., Str¨omberg, U.,\
    \ Bj¨ork, J.: A directed acyclic graph for interactions. International Journal\
    \ of Epidemiology 50(2), 613–619 (2021)\n- <span id=\"page-48-2\"></span>83. Nosek,\
    \ B.A., Errington, T.M.: What is replication? PLoS biology 18(3), e3000691 (2020)\n\
    - <span id=\"page-48-9\"></span>84. Nuseibeh, B., Easterbrook, S.: Requirements\
    \ engineering: A roadmap. In: Proceedings of the Conference on the Future of Software\
    \ Engineering, pp. 35–46 (2000)\n- <span id=\"page-48-4\"></span>85. O'Grady,\
    \ W., Archibald, J., Aronoff, M., Rees-Miller, J.: Contemporary Linguistics: An\
    \ Introduction. Bedford/St. Martin's, Boston (2001)\n- <span id=\"page-48-6\"\
    ></span>86. Parra, E., Dimou, C., Llorens, J., Moreno, V., Fraga, A.: A methodology\
    \ for the classification of quality of requirements using machine learning techniques.\
    \ Information and Software Technology 67, 180–195 (2015)\n- <span id=\"page-48-14\"\
    ></span>87. Pearl, J.: From Bayesian networks to causal networks. In: Mathematical\
    \ models for handling partial knowledge in artificial intelligence, pp. 157–182.\
    \ Springer (1995)\n- <span id=\"page-48-15\"></span>88. Pearl, J., Glymour, M.,\
    \ Jewell, N.P.: Causal inference in statistics: A primer. John Wiley & Sons (2016)\n\
    - <span id=\"page-48-13\"></span>89. Petersen, K., Wohlin, C.: Context in industrial\
    \ software engineering research. In: 2009 3rd International Symposium on Empirical\
    \ Software Engineering and Measurement, pp. 401–404. IEEE (2009)\n- <span id=\"\
    page-48-12\"></span>90. Phalp, K.T., Vincent, J., Cox, K.: Assessing the quality\
    \ of use case descriptions. Software Quality Journal 15(1), 69–97 (2007)\n- <span\
    \ id=\"page-48-3\"></span>91. Philippo, E.J., Heijstek, W., Kruiswijk, B., Chaudron,\
    \ M.R., Berry, D.M.: Requirement ambiguity not as important as expected—results\
    \ of an empirical evaluation. In: Requirements Engineering: Foundation for Software\
    \ Quality: 19th International Working Conference, REFSQ 2013, Essen, Germany,\
    \ April 8-11, 2013. Proceedings 19, pp. 65–79. Springer (2013)\n- <span id=\"\
    page-48-18\"></span>92. Pickard, L.M., Kitchenham, B.A., Jones, P.W.: Combining\
    \ empirical results in software engineering. Information and software technology\
    \ 40(14), 811–821 (1998)\n- <span id=\"page-48-8\"></span>93. Poesio, M.: Semantic\
    \ ambiguity and perceived ambiguity. In: K. van Deemter, S. Peters (eds.) Semantic\
    \ Ambiguity and Underspecification. Center for the Study of Language and Inf,\
    \ United Kingdom (1996). DOI 10.48550/arXiv.cmp-lg/9505034\n- <span id=\"page-48-5\"\
    ></span>94. Pohl, K.: Requirements engineering fundamentals: A study guide for\
    \ the certified professional for requirements engineering exam-foundation level-IREB\
    \ compliant. Rocky Nook, Inc. (2016)\n- <span id=\"page-48-7\"></span>95. Rosadini,\
    \ B., Ferrari, A., Gori, G., Fantechi, A., Gnesi, S., Trotta, I., Bacherini, S.:\
    \ Using NLP to detect requirements defects: An industrial experience in the railway\
    \ domain. In: Requirements Engineering: Foundation for Software Quality: 23rd\
    \ International Working Conference, REFSQ 2017, Essen, Germany, February 27–March\
    \ 2, 2017, Proceedings 23, pp. 344–360. Springer (2017)\n- <span id=\"page-48-16\"\
    ></span>96. Russo, D., Stol, K.J.: Gender differences in personality traits of\
    \ software engineers. IEEE Transactions on Software Engineering 48(3), 819–834\
    \ (2020)\n- <span id=\"page-48-17\"></span>97. Salman, I., Misirli, A.T., Juristo,\
    \ N.: Are students representatives of professionals in software engineering experiments?\
    \ In: 2015 IEEE/ACM 37th IEEE international conference on software engineering,\
    \ vol. 1, pp. 666–676. IEEE (2015)\n- <span id=\"page-48-10\"></span>98. Shah,\
    \ U.S., Jinwala, D.C.: Resolving ambiguity in natural language specification to\
    \ generate UML diagrams for requirements specification. International Journal\
    \ of Software Engineering, Technology and Applications 1(2-4), 308–334 (2015)\n\
    - <span id=\"page-48-19\"></span>99. Shapiro, S.S., Wilk, M.B.: An analysis of\
    \ variance test for normality (complete samples). Biometrika 52(3/4), 591–611\
    \ (1965)\n- <span id=\"page-48-11\"></span>100. Sharma, R., Sharma, N., Biswas,\
    \ K.: Machine learning for detecting pronominal anaphora ambiguity in NL requirements.\
    \ In: 2016 4th Intl Conf on Applied Computing and Information Technology/3rd Intl\
    \ Conf on Computational Science/Intelligence and\n\nApplied Informatics/1st Intl\
    \ Conf on Big Data, Cloud Computing, Data Science & Engineering (ACIT-CSII-BCD),\
    \ pp. 177–182. IEEE (2016)\n\n- <span id=\"page-49-14\"></span>101. Siebert, J.:\
    \ Applications of statistical causal inference in software engineering. Information\
    \ and Software Technology p. 107198 (2023)\n- <span id=\"page-49-12\"></span>102.\
    \ Sjøberg, D.I., Anda, B., Arisholm, E., Dyb˚a, T., Jørgensen, M., Karahasanovi´c,\
    \ A., Vok´aˇc, M.: Challenges and recommendations when increasing the realism\
    \ of controlled software engineering experiments. In: Empirical Methods and Studies\
    \ in Software Engineering: Experiences from ESERNET, pp. 24–38. Springer (2003).\
    \ DOI 10.1007/ 978-3-540-45143-3 3\n- <span id=\"page-49-3\"></span>103. Soeken,\
    \ M., Abdessaied, N., Allahyari-Abhari, A., Buzo, A., Musat, L., Pelz, G., Drechsler,\
    \ R.: Quality assessment for requirements based on natural language processing.\
    \ In: Forum on Specification and Design Languages. Proceedings. Citeseer (2014)\n\
    - <span id=\"page-49-0\"></span>104. Stol, K.J., Fitzgerald, B.: The ABC of software\
    \ engineering research. ACM Transactions on Software Engineering and Methodology\
    \ (TOSEM) 27(3), 1–51 (2018)\n- <span id=\"page-49-9\"></span>105. Svensson, R.B.,\
    \ Feldt, R., Torkar, R.: The unfulfilled potential of data-driven decision making\
    \ in agile software development. In: Agile Processes in Software Engineering and\
    \ Extreme Programming: 20th International Conference, XP 2019, Montr´eal, QC,\
    \ Canada, May 21–25, 2019, Proceedings 20, pp. 69–85. Springer (2019)\n- <span\
    \ id=\"page-49-7\"></span>106. Torkar, R., Feldt, R., Furia, C.A.: Bayesian data\
    \ analysis in empirical software engineering: The case of missing data, pp. 289–324.\
    \ Springer International Publishing, Cham (2020). DOI 10.1007/978-3-030-32489-6\
    \ 11\n- <span id=\"page-49-11\"></span>107. Vegas, S., Apa, C., Juristo, N.: Crossover\
    \ designs in software engineering experiments: Benefits and perils. IEEE Transactions\
    \ on Software Engineering 42(2), 120–135 (2015). DOI 10.1109/TSE.2015.2467378\n\
    - <span id=\"page-49-8\"></span>108. Vieira, R., Mesquita, D., Mattos, C.L., Britto,\
    \ R., Rocha, L., Gomes, J.: Bayesian analysis of bug-fixing time using report\
    \ data. In: Proceedings of the 16th ACM/IEEE International Symposium on Empirical\
    \ Software Engineering and Measurement, pp. 57–68 (2022)\n- <span id=\"page-49-1\"\
    ></span>109. Wagner, S., Fern´andez, D.M., Felderer, M., Vetr`o, A., Kalinowski,\
    \ M., Wieringa, R., Pfahl, D., Conte, T., Christiansson, M.T., Greer, D., et al.:\
    \ Status quo in requirements engineering: A theory and a global family of surveys.\
    \ ACM Transactions on Software Engineering and Methodology (TOSEM) 28(2), 1–48\
    \ (2019)\n- <span id=\"page-49-6\"></span>110. Wagner, S., Lochmann, K., Heinemann,\
    \ L., Kl¨as, M., Trendowicz, A., Pl¨osch, R., Seidi, A., Goeb, A., Streit, J.:\
    \ The Quamoco product quality modelling and assessment approach. In: 2012 34th\
    \ International Conference on Software Engineering (ICSE), pp. 1133–1142. IEEE\
    \ (2012)\n- <span id=\"page-49-15\"></span>111. Wesner, J.S., Pomeranz, J.P.:\
    \ Choosing priors in Bayesian ecological models by simulating from the prior predictive\
    \ distribution. Ecosphere 12(9), e03739 (2021)\n- <span id=\"page-49-13\"></span>112.\
    \ Wilcoxon, F.: Individual comparisons by ranking methods. biom bull 1 (6): 80–83\
    \ (1945)\n- <span id=\"page-49-10\"></span>113. Wohlin, C., Runeson, P., H¨ost,\
    \ M., Ohlsson, M.C., Regnell, B., Wessl´en, A.: Experimentation in software engineering.\
    \ Springer Science & Business Media (2012)\n- <span id=\"page-49-4\"></span>114.\
    \ Yang, H., De Roeck, A., Gervasi, V., Willis, A., Nuseibeh, B.: Extending nocuous\
    \ ambiguity analysis for anaphora in natural language requirements. In: 2010 18th\
    \ IEEE International Requirements Engineering Conference, pp. 25–34. IEEE (2010)\n\
    - <span id=\"page-49-5\"></span>115. Yang, H., De Roeck, A., Gervasi, V., Willis,\
    \ A., Nuseibeh, B.: Analysing anaphoric ambiguity in natural language requirements.\
    \ Requirements engineering 16, 163–189 (2011)\n- <span id=\"page-49-2\"></span>116.\
    \ Zhao, L., Alhoshan, W., Ferrari, A., Letsholo, K.J., Ajagbe, M.A., Chioasca,\
    \ E.V., Batista-Navarro, R.T.: Natural language processing for requirements engineering:\
    \ A systematic mapping study. ACM Computing Surveys (CSUR) 54(3), 1–41 (2021)"
- title: "Flexible Control Flow Graph Alignment for Delivering Data-Driven\n  Feedback\
    \ to Novice Programming Learners"
  abstract: 'Supporting learners in introductory programming assignments at scale
    is a

    necessity. This support includes automated feedback on what learners did

    incorrectly. Existing approaches cast the problem as automatically repairing

    learners'' incorrect programs extrapolating the data from an existing correct

    program from other learners. However, such approaches are limited because they

    only compare programs with similar control flow and order of statements. A

    potentially valuable set of repair feedback from flexible comparisons is thus

    missing. In this paper, we present several modifications to CLARA, a

    data-driven automated repair approach that is open source, to deal with

    real-world introductory programs. We extend CLARA''s abstract syntax tree

    processor to handle common introductory programming constructs. Additionally,

    we propose a flexible alignment algorithm over control flow graphs where we

    enrich nodes with semantic annotations extracted from programs using operations

    and calls. Using this alignment, we modify an incorrect program''s control flow

    graph to match the correct programs to apply CLARA''s original repair process.

    We evaluate our approach against a baseline on the twenty most popular

    programming problems in Codeforces. Our results indicate that flexible

    alignment has a significantly higher percentage of successful repairs at 46%

    compared to 5% for baseline CLARA. Our implementation is available at

    https://github.com/towhidabsar/clara.'
  url: http://arxiv.org/abs/2401.01416v1
  keywords: ''
  document: "# Flexible Control Flow Graph Alignment for Delivering Data-Driven Feedback\
    \ to Novice Programming Learners\n\nMd Towhidul Absar Chowdhury<sup>a</sup> ,\
    \ Maheen Riaz Contractor<sup>a</sup> , Carlos R. Rivero<sup>a</sup>\n\n> <sup>a</sup>Rochester\
    \ Institute of Technology, One Lomb Memorial Dr., Rochester, 14623, NY, USA\n\n\
    ### Abstract\n\nSupporting learners in introductory programming assignments at\
    \ scale is a necessity. This support includes automated feedback on what learners\
    \ did incorrectly. Existing approaches cast the problem as automatically repairing\
    \ learners' incorrect programs extrapolating the data from an existing correct\
    \ program from other learners. However, such approaches are limited because they\
    \ only compare programs with similar control flow and order of statements. A potentially\
    \ valuable set of repair feedback from flexible comparisons is thus missing. In\
    \ this paper, we present several modifications to CLARA, a data-driven automated\
    \ repair approach that is open source, to deal with real-world introductory programs.\
    \ We extend CLARA's abstract syntax tree processor to handle common introductory\
    \ programming constructs. Additionally, we propose a flexible alignment algorithm\
    \ over control flow graphs where we enrich nodes with semantic annotations extracted\
    \ from programs using operations and calls. Using this alignment, we modify an\
    \ incorrect program's control flow graph to match correct programs to apply CLARA's\
    \ original repair process. We evaluate our approach against a baseline on the\
    \ twenty most popular programming problems in Codeforces. Our results indicate\
    \ that flexible alignment has a significantly higher percentage of successful\
    \ repairs at 46% compared to 5% for baseline CLARA. Our implementation is available\
    \ at <https://github.com/towhidabsar/clara>.\n\nKeywords: Automated Program Repair,\
    \ Control Flow Graph,\n\nEmail addresses: mac9908@rit.edu (Md Towhidul Absar Chowdhury),\
    \ mc1927@rit.edu (Maheen Riaz Contractor), crr@cs.rit.edu (Carlos R. Rivero)\n\
    \n### 1. Introduction\n\nThe worldwide interest in computer science has originated\
    \ an unprecedented growth in the number of novice programming learners in both\
    \ traditional and online settings [\\[1–](#page-44-0)[4\\]](#page-45-0). In the\
    \ latter case, the number of novices taking programming Massive Open Online Courses\
    \ and/or practicing using programming online judges has scaled to millions [\\\
    [5,](#page-45-1) [6\\]](#page-45-2). One of the main challenges in the aforementioned\
    \ context is supporting novice programming learners at scale [\\[7\\]](#page-45-3),\
    \ which typically consists of delivering feedback explaining what and why they\
    \ did incorrectly in their programs [\\[8\\]](#page-45-4). Note that, different\
    \ than traditional settings, online programming settings often have a large proportion\
    \ of novice learners with a variety of backgrounds, who usually tend to need a\
    \ more direct level of feedback and assistance [\\[9\\]](#page-45-5). A common\
    \ practice to address such a challenge is to rely on functional tests; however,\
    \ feedback generated based solely on test cases does not sufficiently support\
    \ novice learners [\\[7,](#page-45-3) [10\\]](#page-45-6).\n\nCurrent approaches\
    \ cast the problem of delivering feedback to novices at scale as automatically\
    \ repairing their incorrect programs [\\[3,](#page-44-1) [7,](#page-45-3) [10–](#page-45-6)[13\\\
    ]](#page-45-7). Note that, similar to existing approaches, we consider a program\
    \ to be correct if it passes a number of predefined test cases [\\[3,](#page-44-1)\
    \ [10\\]](#page-45-6); otherwise, it is incorrect. Once a repair is found, it\
    \ can be used to determine pieces of feedback to deliver to learners [\\[7\\]](#page-45-3).\
    \ Non-data-driven approaches aim to find repairs by mutating incorrect programs\
    \ until they are correct, i.e., they pass all test cases [\\[14\\]](#page-45-8).\
    \ Data-driven approaches exploit the fact that repairs can be found in existing\
    \ correct programs and extrapolated to a given incorrect program [\\[3\\]](#page-44-1).\
    \ This paper focuses on the latter since, in a given programming assignment, there\
    \ is usually a variety of correct programs provided by other learners that can\
    \ be exploited to repair incorrect programs [\\[3,](#page-44-1) [10,](#page-45-6)\
    \ [12,](#page-45-9) [13\\]](#page-45-7).\n\nThe \"search, align and repair\" [\\\
    [3\\]](#page-44-1) framework consists of the following steps: 1) Given an incorrect\
    \ program p<sup>i</sup> , search for a correct program p<sup>c</sup> that may\
    \ be useful to repair p<sup>i</sup> ; 2) Align p<sup>i</sup> with respect to p<sup>c</sup>\
    \ to identify discrepancies and potential modifications in order to repair p<sup>i</sup>\
    \ ; and 3) Apply those modifications to p<sup>i</sup> until the resulting program\
    \ p ′ <sup>i</sup> passes all test cases. Current approaches instantiating the\
    \ \"search, align and repair\" framework use rigid comparisons to align incorrect\
    \ and correct programs, i.e., they require the programs to have the same or very\
    \ similar control flows (conditions and loops), and they are affected by the order\
    \ of program statements [\\[3,](#page-44-1) [10,](#page-45-6) [12,](#page-45-9)\
    \ [13\\]](#page-45-7). As a result, such approaches may miss a potentially valuable\
    \ set of correct programs that can repair incorrect programs using flexible program\
    \ comparisons.\n\nIn this paper, we focus on CLARA [\\[10\\]](#page-45-6), a \"\
    search, align and repair\" approach that is open source. We first adapt the original\
    \ implementation of CLARA to support introductory programming assignments. This\
    \ adaption involves non-trivial modifications to the parser and interpreter to\
    \ support various constructs, such as print to and read from the console, import\
    \ statements, built-in Python functions, and more. After these modifications,\
    \ we also need to adapt the alignment and repair processes. Based on these foundations,\
    \ we propose a flexible alignment algorithm that relies on control flow graphs.\
    \ It exploits the semantic information (operations and calls) to annotate the\
    \ graphs, and their topology information (edges, i.e., True and False transitions).\
    \ In order to evaluate the proposed algorithm, we create a dataset of incorrect\
    \ and correct programs for the twenty most popular programming problems in the\
    \ Codeforces online platform. Then, using the dataset, we execute CLARA's baseline\
    \ repair process and our flexible alignment repair to compare both the quantitative\
    \ and qualitative performance of the proposed technique. Furthermore, we include\
    \ another \"search, align and repair\" approach, Sarfgen [\\[3\\]](#page-44-1),\
    \ by utilizing a similar process as our flexible alignment, but enforcing a high\
    \ similarity between compared programs. This simulates the rigidity in program\
    \ comparisons applied by Sarfgen. Note that Sarfgen is not publicly available;\
    \ therefore, we needed to simulate it.\n\nTwo short versions of this paper have\
    \ been published elsewhere [\\[15,](#page-46-0) [16\\]](#page-46-1). In this paper,\
    \ we describe in detail all the modifications that we made to CLARA, and how the\
    \ parser and interpreter were updated. We also present our flexible alignment\
    \ algorithm as well as the changes made to the programs at hand after an alignment\
    \ is computed. These changes are necessary in order to apply CLARA's repair process.\
    \ Finally, we have significantly expanded our experiments to show the performance\
    \ of our modifications over twenty real-world introductory programming assignments.\
    \ We have made the implementation of this version of CLARA and our experimental\
    \ dataset publicly available.[1](#page-2-0)\n\n<span id=\"page-2-0\"></span><sup>1</sup><https://github.com/towhidabsar/clara>\
    \ The fundamental contributions of this pa-\n\nThe paper is organized as follows:\
    \ Section [2](#page-3-0) summarizes previous approaches and ours; Section [3](#page-6-0)\
    \ introduces CLARA's parser, interpreter, aligner and repairer; Sections [4](#page-14-0)\
    \ and [5](#page-19-0) describe our modifications to the parser and interpreter,\
    \ and aligner and repairer of CLARA's original implementation, respectively; Section\
    \ [6](#page-21-0) presents our flexible alignment approach and the necessary modifications\
    \ to CLARA's repairer; Section [7](#page-30-0) discusses our experimental results;\
    \ Section [8](#page-41-0) presents the related work; and Section [9](#page-43-0)\
    \ presents our conclusions and future work.\n\n### <span id=\"page-3-0\"></span>2.\
    \ Overview\n\nWe consider CLARA [\\[10\\]](#page-45-6), Refazer [\\[13\\]](#page-45-7),\
    \ Sarfgen [\\[3\\]](#page-44-1), and sk p [\\[12\\]](#page-45-9) the state of\
    \ the art in searching, aligning and repairing programs. CLARA and Sarfgen compare\
    \ variable traces between an incorrect and a correct programs that share the same\
    \ control statements like if or while. Refazer uses pairs of incorrect/correct\
    \ program samples to learn transformation rules, which aid a program synthesizer\
    \ to transform incorrect into correct programs. Finally, sk p uses partial fragments\
    \ of contiguous statements to train a neural network to predict possible repairs.\n\
    \nIn the alignment step, these approaches compare an incorrect program with respect\
    \ to a correct program based on rigid schemes, which limits their repair potential.\
    \ To illustrate our claim, we use the Python programs presented in Figure [1,](#page-4-0)\
    \ which aim to compute the minimum value in an array and the sum of all its elements,\
    \ and print both minimum and sum values to console. Note that the values of the\
    \ input array are assumed to be always less or equal than 100. In Sarfgen, an\
    \ incorrect program will be only repaired if its control statements match with\
    \ the control statements of an existing correct program. This is a hard constraint\
    \ since: a) It requires a correct program with the same control statements to\
    \ exist, and b) Such a correct program may not \"naturally\" exist. For instance,\
    \ the control statements of\n\nper are as follows: 1) Many of the modifications\
    \ we made to CLARA's parser and interpreter for Python programs also apply to\
    \ other programming languages like C and Java; 2) Both our flexible alignment\
    \ and model recreation algorithms can be used by any \"search, align and repair\"\
    \ approach based on control flow graphs and program expressions; 3) Our dataset\
    \ is one of the very few publicly-available datasets in the context of real-world\
    \ introductory programming assignments; 4) Our threshold-based solution to simulate\
    \ other alignment approaches is useful when existing approaches are not publicly\
    \ available.\n\n<span id=\"page-4-8\"></span><span id=\"page-4-7\"></span><span\
    \ id=\"page-4-6\"></span><span id=\"page-4-5\"></span><span id=\"page-4-4\"></span><span\
    \ id=\"page-4-3\"></span><span id=\"page-4-2\"></span><span id=\"page-4-1\"></span><span\
    \ id=\"page-4-0\"></span>![](_page_4_Figure_0.jpeg)\n\n<span id=\"page-4-10\"\
    ></span><span id=\"page-4-9\"></span>Figure 1: Correct and incorrect programs,\
    \ edits of abstract syntax trees derived from the programs and code fragments\n\
    \nthe correct program in Figure [1a](#page-4-3) do not match with the incorrect\
    \ program in Figure [1b;](#page-4-4) in order to match, the correct program should\
    \ \"artificially\" contain an if statement before or after line [8,](#page-4-5)\
    \ and such a statement should not modify the final output of the program. CLARA\
    \ relaxes these constraints such that, outside loop statements, both programs\
    \ can have different control statements, but they need to have the same inside\
    \ loops. This relaxation still forces a correct program with the same loop signature\
    \ to exist.\n\nRefazer exploits the tree edit distance between two programs to\
    \ find discrepancies between them; however, the tree edit distance between two\
    \ equivalent abstract syntax trees with different order of statements implies\
    \ multiple edits. For example, Figure [1c](#page-4-6) shows an excerpt of the\
    \ edits to transform the abstract syntax tree of the correct into the incorrect\
    \ program in our example, which implies removing and adding full subtrees; however,\
    \ only two edits would be necessary, i.e., changing \"<\" by \">\" and removing\
    \ the subtree formed by lines [9–](#page-4-7)[10](#page-4-8) in Figure [1b.](#page-4-4)\
    \ In sk p, different order of statements result in different partial fragments,\
    \ so additional correct programs will be required to train the program repairer.\
    \ For instance, Figure [1d](#page-4-9) shows a fragment extracted from the correct\
    \ program; however, the incorrect program will only be fixed by a fragment like\
    \ the one in Figure [1e.](#page-4-10)\n\nWe propose an alignment step based on\
    \ flexible alignment of control flow graphs. The first step consists of transforming\
    \ programs into control flow graphs that encode the True and False transitions\
    \ of the program at hand. For instance, the while loop in Figure [1a](#page-4-3)\
    \ (line [4\\)](#page-4-1) is encoded by three nodes in the graph: the guard, the\
    \ body and the end of the loop. There are transitions (edges) between these nodes.\
    \ For example, a True transition between the guard and the body encodes that the\
    \ guard is fulfilled, so the body is executed. These nodes are further annotated\
    \ with semantic labels. For example, the guard of the loop contains the following\
    \ labels: cond, indicating it is a Boolean condition, Lt, because there is a less\
    \ than operator, and len, which corresponds to the len call. We apply flexible\
    \ graph alignment over two (correct and incorrect) control flow graphs G<sup>C</sup>\
    \ and G<sup>I</sup> . Assume a given permutation of nodes ϕ such that every node\
    \ u<sup>i</sup> ∈ G<sup>C</sup> corresponds to a node v<sup>j</sup> ∈ G<sup>I</sup>\
    \ , i.e., ϕ(ui) = v<sup>j</sup> . We compute the similarity of ϕ as the similarity\
    \ between the labels of u<sup>i</sup> and v<sup>j</sup> (semantic similarity),\
    \ and the transitions (edges) outgoing from u<sup>i</sup> and v<sup>j</sup> (topology\
    \ similarity). We select the permutation with lowest similarity as the best alignment.\n\
    \n<span id=\"page-6-1\"></span>![](_page_6_Figure_0.jpeg)\n\nFigure 2: CLARA's\
    \ workflow: each program is translated into a model. Both models are aligned.\
    \ If they match, the repairer and the interpreter exchange model and trace information\
    \ using a test case until the incorrect program's model passes such test case.\n\
    \n### <span id=\"page-6-0\"></span>3. Introduction to CLARA [\\[10\\]](#page-45-6)\n\
    \nThe automated CLustering And program RepAir tool, CLARA [\\[10\\]](#page-45-6),\
    \ was first introduced in 2016. CLARA helps provide feedback to students in introductory\
    \ programming assignments. Even though CLARA supports C++, Java and Python, we\
    \ focus on the latter in this paper. Figure [2](#page-6-1) presents CLARA's workflow.\
    \ The abstract syntax tree processor receives each correct and incorrect programs\
    \ as input, parses them, and creates two models, one for each program. These models\
    \ are aligned: if a match is found, the repairer uses it as well as a test case\
    \ to find potential errors and fix them. Error detection is achieved by comparing\
    \ variable traces between the correct and incorrect programs.\n\n### 3.1. Models,\
    \ processing and interpreting\n\nBefore performing any repairs, CLARA creates\
    \ models for every input program. CLARA exploits Python's ast module, which is\
    \ a standard library that helps generate abstract syntax trees from Python source\
    \ code and manipulate them. An abstract syntax tree is a graphical representation\
    \ of a piece of source code containing nodes, where every node represents a language\
    \ construct or operation like If, Return and Import [\\[17\\]](#page-46-2). CLARA\
    \ traverses the returned abstract syntax tree, node by node, and creates a model.\
    \ For every part of the abstract syntax tree, such as FunctionDef (function definition),\
    \ Expr (expression) or Call (function call), there is a different processing function\
    \ that has a different representation in the model.\n\nFunctions and locations.\
    \ The entire model consists of one program containing multiple functions. Each\
    \ function is partitioned based on its control flow information. Control flow\
    \ information captures the order in which statements are evaluated. An example\
    \ of a control flow statement is an If statement, as it adds a new possible path\
    \ for the program to take. Locations, a construct in CLARA's model, represent\
    \ control flow information. Each function thus contains multiple locations. Locations\
    \ contain expressions and are created based on branching control flow statements\
    \ like If, While or For statements. Other statements like function calls or sequencing\
    \ of statements are not involved in location creation. As a result, if a function\
    \ contains no branching control flow statements, it will only contain a single\
    \ location. Locations also contain information about which location to go to next,\
    \ called transitions. There are two types of transitions, True and False. A True\
    \ transition contains the following location to go to if the conditional expression\
    \ inside the location evaluates to true. A False transition contains the location\
    \ to visit next if the expression inside the location evaluates to false.\n\n\
    However, it is possible to have expressions inside a location that do not evaluate\
    \ to a Boolean value, in which case, they will always go to a specific location.\
    \ For example, transitioning back to the program body after executing a Then or\
    \ an Else branch within an If statement. In this case, these are always True transitions.\
    \ To maintain consistency, these locations also have True and False transitions,\
    \ but the False transition always points to None, and the True transition always\
    \ points to the next location.\n\nExpressions. CLARA contains three types of expressions\
    \ as follows, where the names between parentheses refer to CLARA's naming convention:\
    \ variables (Var), operators (Op), and constants (Const). A Const can be a string,\
    \ byte, number, or a name constant. A Var represents variables and, therefore,\
    \ only comprises strings. An Op is the most complex type of expression as it encompasses\
    \ all computations involving any type of operation, such as creating a list, set\
    \ or tuple, and computations involving comparisons, if conditions, or binary operations.\
    \ Every Op comprises two components, the name of the operation and the arguments\
    \ it has to operate on. Depending on the type of operation, Op can contain a different\
    \ number of arguments. For example, the GetElement operator entails getting an\
    \ element from a list, dictionary or set, and contains two arguments: the object\
    \ it needs to get the element from and the element index. SetInit, which creates\
    \ a set, has multiple arguments as each argument is an element inside the set.\n\
    \nAll types of control flow statements are also operators. However, while processing\
    \ those statements, CLARA makes changes to the model. As men-\n\n```\n1 a = [5\
    \ , 6]\n2 b , c = a\n3 b += 1\n4 b += c\n5\n6 for i in a:\n7 c += i\n```\nFigure\
    \ 3: Sample Python source code\n\ntioned earlier, processing control flow statements\
    \ results in the addition of new locations to the model. The number of locations\
    \ is different for each control flow statement. If the program contains an If\
    \ statement, three or four locations will be added: one for the condition of the\
    \ statement, another for the expressions inside the Then branch, one for the expressions\
    \ after the statement, and, finally, another for the expressions inside the Else\
    \ branch. The latter location is optional as we do not always have an Else branch\
    \ accompanying the Then branch. However, CLARA recursively applies the following\
    \ optimization to improve program comparison: an If statement that has no loops\
    \ within is translated into a ternary operator. As a result, this statement is\
    \ embedded in its parent and does not add any new nodes to the control flow graph.\
    \ On the other hand, loops always result in the addition of three locations, corresponding\
    \ to the guard, body, and the statements after the loop.\n\nCLARA restricts its\
    \ models by requiring a variable to appear only once on the left side of an expression\
    \ per location. This restriction entails inspecting all the declarations of a\
    \ particular variable and nesting the declarations in the last use of the variable.\
    \ Hence, during the repair step, where variable traces are compared between models,\
    \ there is only one value per location, making the comparison deterministic.\n\
    \nExample of a model. Figures [3](#page-8-0) and [4](#page-9-0) present an example\
    \ of Python source code and its corresponding model. This model is the pretty-printed\
    \ version created by CLARA to help improve readability. Since the source code\
    \ contains a For loop, the model contains four locations. The True and False transitions\
    \ are shown at the bottom of each location and indicate how to traverse the model.\
    \ For example, if \\$cond in location 2 evaluates to true, we transition to location\
    \ 4. If it evaluates to false, we transition to location 3. ind#0 corresponds\
    \ to the index of the loop, i, and iter#0 corresponds to\n\n<span id=\"page-9-0\"\
    ></span>Loc 1 (around the beginning of function main)\n\n```\n−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\n\
    \ a := ListInit(5, 6)\n c := GetElement(a', 1)\n b := AssAdd(AssAdd(GetElement(a',\
    \ 0), 1), c')\n iter#0 := a'\n ind#0 := 0\n−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\n\
    \ True −> 2, False −> None\nLoc 2 (the condition of the 'for' loop at line 6)\n\
    −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\n $cond := Lt(ind#0, len(iter#0))\n−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\n\
    \ True −> 4, False −> 3\nLoc 3 (∗after∗ the 'for' loop starting at line 6)\n−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\n\
    −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\n True −> None, False −> None\nLoc 4 (inside\
    \ the body of the 'for' loop beginning at line 7)\n−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\n\
    \ i := GetElement(iter#0, ind#0)\n ind#0 := Add(ind#0, 1)\n```\n\n```\nc := AssAdd(c,\
    \ i')\n```\n−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\n\nTrue −> 2, False −> None\n\n\
    Figure 4: Model generated by CLARA for the program in Figure [3](#page-8-0)\n\n\
    the value we are iterating over, a. CLARA internally creates both variables for\
    \ every loop. As it can be seen in the source code, b appears on the left side\
    \ of an expression three times (lines [2,](#page-8-1) [3](#page-8-2) and [4\\\
    )](#page-8-3), but in the model, it only appears once in location 1. All three\
    \ uses are nested inside one expression: b := AssAdd(AssAdd(GetElement(a ′ , 0),\
    \ 1), c ′ ). The other expressions correspond to the other operations before the\
    \ loop. Whenever CLARA uses a variable defined earlier in an expression, it converts\
    \ it to a different variable rather than using the original variable. For example,\
    \ a becomes a ′ . CLARA uses this notation (prime) to determine whether a variable\
    \ is being defined or used.\n\nSince CLARA relies on program execution and variable\
    \ traces, it exploits a Python interpreter that helps execute models. The interpreter\
    \ visits each expression in the model and recursively executes it, since an expression\
    \ can contain other nested expressions. For example, the expression b := AssAdd(AssAdd(GetElement(a\
    \ ′ , 0), 1), c ′ ) evaluates from the innermost expression, GetElement(a ′ ,\
    \ 0), until the most external expression. The interpreter contains functions for\
    \ every type of operator, in this case, AssAdd and GetElement, annotated with\
    \ the word execute as a prefix for each function. Therefore, while evaluating\
    \ the previous expression, CLARA first executes GetElement(a ′ , 0), which translates\
    \ to getting the element of a at index 0, invoking the function execute GetElement().\
    \ It then evaluates AssAdd(..., 1) that increments the result by 1 using execute\
    \ AssAdd(), and so on.\n\n### 3.2. Single function alignment and program repair\n\
    \nTo find an alignment between two programs, CLARA creates models for each of\
    \ them. If the control flow of both models is the same, for every variable in\
    \ one model, it finds a matching with a corresponding variable in the other model\
    \ based on variable tracing. The process consists of comparing values of variables\
    \ at each location of the program trace. If the matching variables hold the same\
    \ values at every point in the trace, the two programs are aligned. Single program\
    \ repair is performed between two programs, where one is a correct program and\
    \ the other is incorrect. The repair process starts by creating models for each\
    \ program and aligning them as described above. Additionally, CLARA requires the\
    \ programs to have at least one function and the same number of functions overall\
    \ in the programs being compared. These functions must also have the same names\
    \ and cannot be nested. These features determine the structure of the programs.\
    \ If there is a difference in the structure of the programs, CLARA throws a structure\
    \ mismatch error and does not run.\n\n### Algorithm 1: Align\n\n<span id=\"page-11-2\"\
    ></span><span id=\"page-11-1\"></span>in : G<sup>C</sup> = (U , E) control flow\
    \ graph (correct program); u ∈ U ; G<sup>I</sup> = (V , F) control flow graph\
    \ (incorrect program); v ∈ V in/out: ϕ : U → V program alignment out : Whether\
    \ there is an alignment <sup>1</sup> // If u and/or v are in ϕ, they must be mapped\
    \ to each other. <sup>2</sup> if u ∈ dom ϕ ∨ v ∈ ran ϕ then <sup>3</sup> return\
    \ ϕ(u) = v <sup>4</sup> end <sup>5</sup> // Add u and v to ϕ. <sup>6</sup> ϕ(u)\
    \ ← v <sup>7</sup> // u ′ and u ′′ (v ′ and v ′′) are the neighbors of u (v).\
    \ <sup>8</sup> Let {u True −−→ u ′ , u False −−−→ u ′′} ⊆ E, {v True −−→ v ′ ,\
    \ v False −−−→ v ′′} ⊆ F <sup>9</sup> // Align u and v neighbors. <sup>10</sup>\
    \ return Align(G<sup>C</sup> , u ′ , G<sup>I</sup> , v ′ , ϕ) ∧ Align(G<sup>C</sup>\
    \ , u ′′ , G<sup>I</sup> , v ′′, ϕ)\n\n<span id=\"page-11-4\"></span><span id=\"\
    page-11-3\"></span><span id=\"page-11-0\"></span>Algorithm [1](#page-11-0) corresponds\
    \ to CLARA's program alignment based on the control flow graphs (locations) of\
    \ the programs at hand. The algorithm receives two control flow graphs, G<sup>C</sup>\
    \ = (U , E) and G<sup>I</sup> = (V , F), where U and V are sets of locations,\
    \ and E and F are sets of transitions, and two locations u ∈ U and v ∈ V , respectively.\
    \ In the initial call, u and v are the entry points of both programs. The algorithm\
    \ receives ϕ, which determines the current mapping of U locations into V locations,\
    \ i.e., the alignment between the graphs. It outputs whether or not there is an\
    \ alignment between the graphs. If any of the locations is present in ϕ, it returns\
    \ whether they are both mapped (lines [2–](#page-11-1)[3\\)](#page-11-2). Note\
    \ that, if they are mapped, there is a match; otherwise, either u or v are mapped\
    \ to a different location and, therefore, there is a mismatch. If u and v are\
    \ not in ϕ, they are added to ϕ (line [6\\)](#page-11-3), and their neighbors\
    \ are recursively inspected (line [10\\)](#page-11-4).\n\nCLARA exploits ϕ during\
    \ the repair process. For every variable in one location of the correct program,\
    \ CLARA aims to match such variable in the corresponding location of the incorrect\
    \ program. Due to CLARA's modeling, a variable can only have one expression per\
    \ location, ensuring it can only hold one value. This makes the comparison with\
    \ other variables possible. During the repair process, a mapping of a variable\
    \ only deals with its specific expression and the expression it is mapped to.\
    \ While mapping a variable from the correct program, every variable in the incorrect\
    \ program is compared, whether or not it has already been mapped. Two variables\
    \ are declared a match if their corresponding expressions evaluate to the same\
    \ values using the same inputs, where the inputs denote the variables both the\
    \ expressions depend on. This match is evaluated based on cost. Since both expressions\
    \ depend on different variables, the cost of a match denotes the number of changes/steps\
    \ it takes to transform the incorrect program's expression into the correct program's\
    \ expression, where a variable from the incorrect program replaces each variable\
    \ in the correct program's expression.\n\nIn the repair process, CLARA assumes\
    \ that the number of variables in the correct program is the minimum number of\
    \ variables needed, so the number of variables in the incorrect program needs\
    \ to match the number of variables in the correct program precisely. Therefore,\
    \ if the incorrect program contains extra variables, CLARA suggests deleting the\
    \ variables it cannot match. If the incorrect program contains fewer variables\
    \ than the correct program, CLARA suggests creating new variables. During cost\
    \ calculation, all the variables in the correct program's expression are substituted\
    \ by variables from the incorrect program as follows: Assume s = a + 2 is a statement\
    \ in the correct program. CLARA replaces a by all other variables present in the\
    \ corresponding location in the incorrect program and evaluates the associated\
    \ cost. If the incorrect program contains three variables x, y and z in the corresponding\
    \ location, a in s = a + 2 is replaced by x, y and z, respectively. Since it is\
    \ possible that the correct program has extra variables, CLARA also calculates\
    \ the cost of the substitution using a fresh variable that does not exist in the\
    \ incorrect program. This value is initialized to the value of a with a cost of\
    \ 1. CLARA finally saves all the costs for every location and provides the cost\
    \ array to a linear programming solver, which minimizes the overall cost and suggests\
    \ matches for all the variables involved. Based on these matches and costs, the\
    \ final set of repairs are suggested, which can be of three types: variable additions,\
    \ variable deletions, or variable changes.\n\nWe use the models shown in Figure\
    \ [5](#page-13-0) to illustrate how the variable matching process works. Both\
    \ models contain a single location that are trivially mapped to each other. Table\
    \ [1](#page-13-1) presents the variable matching of a in the correct program.\
    \ The table contains five columns as follows: The first column represents the\
    \ variable comparison number. The second column is the variable in the correct\
    \ program we aim to match. The third column rep-\n\n<span id=\"page-13-0\"></span>\n\
    \n| Correct Model:  | Incorrect Model: |\n|-----------------|------------------|\n\
    | a := 1          | x := 1           |\n| b := 2          | y := 2           |\n\
    | c := Add(a', 1) | z := Add(y', 1)  |\n\nFigure 5: Sample correct and incorrect\
    \ program models\n\n<span id=\"page-13-1\"></span>\n\n| # | Variable (C) | Variable\
    \ (IC) | Dependency | Cost |\n|---|--------------|---------------|------------|------|\n\
    | 1 | a            | *             | None       | 2    |\n| 2 | a            |\
    \ x             | None       | 0    |\n| 3 | a            | y             | None\
    \       | 1    |\n| 4 | a            | z             | None       | 2    |\n\n\
    Table 1: Repair cost table for variable a in Figure [5](#page-13-0)\n\nresents\
    \ the possible variable match in the incorrect program. The fourth column contains\
    \ the possible substitution for the dependent variables as a tuple (i, j), where\
    \ i is the dependent variable from the correct program, and j is its possible\
    \ substitution in the incorrect program. The fifth column is the cost for each\
    \ variable match. In the first row, ∗ entails that a fresh variable is used; the\
    \ cost is 2 because we need to create a new variable and assign its value to 1\
    \ since a's value is one. The cost of the second row is 0 because no changes are\
    \ needed. Note that there are no variable dependencies in this example.\n\nTable\
    \ [2](#page-13-2) shows the cost computation for variable b. Note that the fourth\
    \ row consists of replacing b by z, which depends on y; therefore, additional\
    \ combinations of variables in the correct program are used, e.g., y and a are\
    \ matched. Finally, Table [3](#page-14-1) presents the cost computation for variable\
    \ c in which fresh variables are also used in the dependencies. The optimal\n\n\
    <span id=\"page-13-2\"></span>\n\n| # | Variable (C) | Variable (IC) | Dependency\
    \ | Cost |\n|---|--------------|---------------|------------|------|\n| 1 | b\
    \            | *             | None       | 2    |\n| 2 | b            | x   \
    \          | None       | 1    |\n| 3 | b            | y             | None  \
    \     | 0    |\n| 4 | b            | z             | (a, y)     | 0    |\n| 5\
    \ | b            | z             | None       | 3    |\n\nTable 2: Repair cost\
    \ table for variable b in Figure [5](#page-13-0)\n\n<span id=\"page-14-1\"></span>\n\
    \n| #  | Variable (C) | Variable (IC) | Dependency | Cost |\n|----|--------------|---------------|------------|------|\n\
    | 1  | c            | *             | (a, *)     | 4    |\n| 2  | c          \
    \  | *             | (a, x)     | 4    |\n| 3  | c            | *            \
    \ | (a, y)     | 4    |\n| 4  | c            | *             | (a, z)     | 4\
    \    |\n| 5  | c            | x             | (a, *)     | 2    |\n| 6  | c  \
    \          | x             | (a, y)     | 2    |\n| 7  | c            | x    \
    \         | (a, z)     | 2    |\n| 8  | c            | y             | (a, *)\
    \     | 3    |\n| 9  | c            | y             | (a, x)     | 3    |\n| 10\
    \ | c            | y             | None       | 0    |\n| 11 | c            |\
    \ y             | (a, z)     | 3    |\n| 12 | c            | z             | (a,\
    \ *)     | 1    |\n| 13 | c            | z             | (a, x)     | 1    |\n\
    | 14 | c            | z             | (a, y)     | 0    |\n\nTable 3: Repair cost\
    \ table for variable c in Figure [5](#page-13-0)\n\nsolution is a matching that\
    \ minimizes the overall cost for all variables. All of these possible matches\
    \ for every variable are the input provided to the linear programming solver.\
    \ The best variable matching is as follows: {ϕ(a) = x , ϕ(b) = y, ϕ(c) = z}, which\
    \ corresponds to rows 2, 3 and 14 in Tables [1,](#page-13-1) [2](#page-13-2) and\
    \ [3,](#page-14-1) respectively. The overall cost is 1 and the suggested repair\
    \ is as follows: Replace z := Add(y ′ , 1) by z := Add(x ′ , 1) with cost = 1.0.\n\
    \n### <span id=\"page-14-0\"></span>4. Parser and interpreter modifications\n\n\
    We analyzed introductory programming assignments to identify language constructs\
    \ commonly used like print statements, input functions and import statements.\
    \ Some of these statements were not supported by CLARA's original implementation.\
    \ In this section, we report the language constructs we added and the changes\
    \ we performed to support them. Both abstract syntax tree processor and interpreter\
    \ were updated to include these language constructs, since the former builds models\
    \ and the latter executes the constructs.\n\nPrint statements. Many introductory\
    \ programming assignments use printing to console to verify whether a program\
    \ is correct or incorrect. The verification of correctness determines whether\
    \ a program should be repaired or not. Similar to other programming languages,\
    \ computations in Python can be performed using variables or inside the parentheses\
    \ of a print statement, removing the need for variables altogether. Hence, while\
    \ evaluating the similarity between two programs or performing a repair, it is\
    \ crucial to match the contents inside these print statements. CLARA's authors\
    \ did incorporate the parsing of print statements. However, when Python 3.x was\
    \ introduced, the print operation switched from a statement to a function call.\
    \ Furthermore, when CLARA's authors updated the implementation to work with Python\
    \ 3.x, not all of the code was updated, leading to the loss of functionality of\
    \ the print operation. We updated the section of the abstract syntax tree processor\
    \ that checks for function calls by checking if the print function was called,\
    \ and updated the model accordingly. Once the print function was correctly processed,\
    \ the comparison of the print operation during the matching and repair processes\
    \ was handled automatically.\n\nImport statements. Certain introductory programming\
    \ assignments require the use of external libraries, such as math, re or string.\
    \ These libraries provide access to functions like sqrt, ceil, search (regular\
    \ expressions), or format (a string). Hence, for CLARA to execute these functions\
    \ while performing a repair or a match, it is essential to have the functionality\
    \ to parse and record the data within these import statements. The original implementation\
    \ of CLARA ignored import statements, causing the program to crash during the\
    \ repair or alignment processes, as their corresponding functions cannot be found\
    \ while executing the function trace.\n\nSince CLARA has its own version of an\
    \ abstract syntax tree processor and interpreter for Python, after parsing and\
    \ processing import statements, we represent and store them in a way such that\
    \ a function call is successfully recognized during execution by the interpreter.\
    \ We created a section in the abstract syntax tree processor to deal with import\
    \ statements and stored them in a nested global dictionary, which is provided\
    \ to the interpreter to be accessed during execution.\n\nVariable assignment.\
    \ In Python 3.x, a programmer can use a variable assignment based on list deconstruction\
    \ or unpacking. For instance, the statement a, b, c = [1, 2, 3] is convenient\
    \ to assign the values 1, 2, and 3 to variables a, b and c, respectively. These\
    \ types of assignments are commonly used in introductory programming assignments.\
    \ We updated the abstract syntax tree processor to recognize and process multiple\
    \ assignments from a single statement. We separated the assignments with their\
    \ corresponding expressions and added each assignment as an individual expression\
    \ to the model. Without these changes, CLARA's original implementation produces\
    \ an error stating that multiple assignments within a single line are not supported,\
    \ halting the repair and alignment processes.\n\nBuilt-in Python functions. CLARA's\
    \ interpreter helps recognize functions in the model and execute them in Python.\
    \ Therefore, common built-in functions like max, sum or len are individually defined\
    \ in the interpreter using auxiliary functions like execute max, execute sum or\
    \ execute len, respectively. These auxiliary functions implement the expected\
    \ functionality. Since Python has a substantial collection of built-in functions,\
    \ manual addition of every function was not included in the interpreter, causing\
    \ CLARA to fail during the alignment and repair processes. Our approach to circumvent\
    \ the need for manual addition of every function is to use Python's internal dictionary\
    \ named builtins. Every time a function is called, we verify whether it is a built-in\
    \ Python function using such dictionary. If this is the case, we proceed to execute\
    \ the function. As a result, all auxiliary functions of the type execute XYZ are\
    \ not needed anymore.\n\nVariable additions and deletions. CLARA expects all variable\
    \ declarations to have a definition in the first location of the program. In other\
    \ words, the beginning of the program contains assignments for every variable,\
    \ and the rest of the program makes use of those variables. Hence, a new variable\
    \ cannot be declared later in the program. If this happens, CLARA outputs unnecessary\
    \ repairs and the final mapping of variables may be inaccurate. We modified the\
    \ abstract syntax tree processor by removing the restriction of requiring variables\
    \ to be declared in the first location, that is, new variables can be declared\
    \ at any point in the program. Additionally, we modified the list of repairs generated\
    \ by CLARA such that repairs suggesting to create and assign the same variable\
    \ are no longer output.\n\nDuring the repair process, CLARA creates a mapping\
    \ of variables from the correct program to an incorrect program. This mapping\
    \ is based on the variable tracing performed throughout the process. A dictionary\
    \ is used to store the mapping. It uses variables from the correct program as\
    \ keys and incorrect program variables as values. While updating the source code\
    \ to include our modifications, we noticed that, if more than one extra variable\
    \ is declared, CLARA does not suggest deleting more than one variable, resulting\
    \ in an incorrect final variable mapping. Figure [6](#page-17-0) illustrates this\
    \ issue with two programs such that the incorrect program contains two extra variables,\
    \ g and\n\n<span id=\"page-17-0\"></span>![](_page_17_Figure_0.jpeg)\n\n1) Delete\
    \ 'g := 3' ∗after∗ the 'for' loop (cost=1.0)\n\n### (c) Suggested repair\n\nFigure\
    \ 6: Correct and incorrect programs and the corresponding suggested repair that\
    \ indicates to delete a single variable rather than two variables (g and f)\n\n\
    f, that must be deleted; however, the suggested repair does not mention f. The\
    \ internal dictionary is as follows: {a : a, s : 0, x : x, − : g}, where variable\
    \ f has been omitted. In this dictionary, variable addition and deletion are represented\
    \ by the ∗ and − keys, respectively. Since it is a dictionary, one of the deletions\
    \ is overwritten as the key is the same. Note that, if the variables f and g were\
    \ in the correct program, CLARA would suggest to add two new variables. This never\
    \ results in an incorrect mapping problem because, in the dictionary, they are\
    \ represented as {f : ∗, g : ∗}. On the contrary, deletions do not work as expected\
    \ since {− : g, − : f} is not allowed and, therefore, we only get the suggestion\
    \ to remove one variable. We thus adjusted the internal dictionary to save an\
    \ array of values in the case of deletions, i.e., {− : ⟨f, g⟩} in our example.\n\
    \nInput statements. One of the commonalities of introductory programming assignments\
    \ is that they evaluate the correctness of a program based on test cases using\
    \ console input and output. The original implementation of CLARA, however, does\
    \ not support standard input. All inputs have to be provided via the command line\
    \ as function arguments. This is not always possible since input arguments can\
    \ be multiple lines long and do not have the same length. Therefore, we updated\
    \ CLARA to read all of the inputs using an argument file and store them in an\
    \ internal list accessible by the interpreter. We updated the interpreter to handle\
    \ calls to the input function separately. So a call like x = input() is handled\
    \ as follows: we extract the first element from the internal list and assign it\
    \ to variable x. If there are subsequent calls to input, we keep extracting elements\
    \ from the internal list. As a result, this modification allows us to repair programs\
    \ that had inputs of different length.\n\nHowever, while adding this feature,\
    \ we encountered another problem. Since CLARA nests the expressions of variables\
    \ while creating its model, it creates copies of the input function when there\
    \ should only be a single call. For example, consider the following Python statement:\n\
    \n<sup>1</sup> a , b , c = input () . split ()\n\nIt becomes the following statements\
    \ in the model:\n\na = GetElement(split(input()), 0) b = GetElement(split(input()),\
    \ 1) c = GetElement(split(input()), 2)\n\nThis change results in input being called\
    \ three times, where it should have been called just once. Since it is possible\
    \ for this problem to occur with other function calls as well, we updated the\
    \ abstract syntax tree processor to create a new variable to store the result\
    \ of calling the input function. Additionally, the expression referencing the\
    \ function references the new variable instead. Therefore, using the above example,\
    \ the statements in the model are as follows:\n\n> input val = input() a = GetElement(split(input\
    \ val), 0) b = GetElement(split(input val), 1) c = GetElement(split(input val),\
    \ 2)\n\nRepetition of expressions is expected if we have multiple variable declarations\
    \ in a single line during model creation. If these expressions include side-effecting\
    \ functions, we can have a similar problem as we had with the input function.\
    \ It is challenging to automatically detect whether a function is side-effecting,\
    \ and creating new variables for every single function call in a program is also\
    \ challenging to handle due to the addition of multiple variables. Furthermore,\
    \ it can cause a mismatch in the number of variables between the correct program\
    \ and the incorrect program, resulting in unexpected repairs. However, this is\
    \ not a problem for the input function, as we expect both the programs to have\
    \ the same number of calls to the input function. We adjusted the source code\
    \ to address this issue to receive an optional list of the side-effecting functions\
    \ via command line. New variables will be created for each of these functions\
    \ similar to input, aiding us in solving the problem and limiting the addition\
    \ of extra variables. In practice, one can apply a preprocessing step detecting\
    \ side-effecting functions and add them to this command-line list.\n\n### <span\
    \ id=\"page-19-0\"></span>5. Alignment and repair modifications\n\nBefore performing\
    \ the modifications described above, CLARA's original implementation did not output\
    \ any model when processing a program containing any unsupported statements. Since\
    \ both the alignment and repair processes depend on models, both processes were\
    \ thus not executed. After performing the modifications described above, the alignment\
    \ and repair processes worked properly for many programs. However, some programs\
    \ still failed. In this section, we report our modifications to the alignment\
    \ and repair processes of CLARA's original implementation. Note that these modifications\
    \ were necessary because of the modifications made to the parser and interpreter\
    \ presented above.\n\nNested functions. The original implementation of CLARA is\
    \ not able to parse nested functions as functions cannot store other functions\
    \ in the model. A function is thus only allowed to store expressions. We updated\
    \ the model to support nested functions by creating a link between two or more\
    \ functions. After adding it to the model, we updated the processes to align and\
    \ repair these functions successfully. Both processes involve creating a one-to-one\
    \ mapping between variables. Therefore, we need to ensure that the variables inside\
    \ the nested functions are not involved in the mapping as those exist in a different\
    \ environment. We treat each nested function as a variable, which is evaluated\
    \ during trace execution, and its return value is substituted by the variable\
    \ calling the function. If the function is called on its own and does not have\
    \ a return value, we check if it is printing to standard output. If that is the\
    \ case, the expression being printed is added to the standard output of the outer\
    \ function. Since CLARA performs variable tracing and tracks the values a variable\
    \ holds throughout the program, CLARA places more importance on the variable's\
    \ values than its expression. This helps eliminate the need for function inlining.\
    \ Our aim while updating the alignment and repair processes was to avoid the suggestion\
    \ of creating/deleting nested functions if the other program is performing the\
    \ exact computation without using nested functions.\n\nApplying repairs. CLARA's\
    \ repair process is sound and complete for the test case provided as input [\\\
    [10\\]](#page-45-6). However, it is typically the case that introductory programming\
    \ assignments are evaluated with a variety of test cases. Therefore, we aim to\
    \ determine whether the incorrect program provided as input is repaired for only\
    \ that particular test case or for all test cases available. To accomplish this,\
    \ we need to convert CLARA's output into actual repairs and, then, apply these\
    \ repairs to the model of the program. Note that the repair process focuses solely\
    \ on models and not the original source code; therefore, we decided to repair\
    \ the program's model rather than the source code.\n\nEvery statement output by\
    \ CLARA contains the variables involved in the repair for both the correct and\
    \ incorrect programs, the associated location in the correct program, and the\
    \ associated expression from the correct program. Hence, we must extract the rest\
    \ of the necessary information, i.e., the location in the incorrect program and\
    \ the expression. Every function in a program groups and stores its variables\
    \ and their associated expressions by location. There are three types of repairs:\
    \ variable deletion, variable addition, and changing the variable definition.\
    \ In the case of variable deletion, we access its corresponding location expressions\
    \ and remove the variable from the list. Similarly, we add the variable and the\
    \ new expression to its corresponding location expressions for variable additions.\
    \ Finally, we substitute the variable's expression in its corresponding location\
    \ for variable changes.\n\nHowever, CLARA's output is not sorted; therefore, for\
    \ variable additions and changes, we must ensure expressions are added in such\
    \ an order that the variables being used exist. For example, if we have the following\
    \ output:\n\n- 1) Change 'a = x + 5' to 'a = m + 5'\n- 2) Add 'm = 3'\n\nWe must\
    \ ensure that m is defined before a; otherwise, an error is thrown during program\
    \ execution. As mentioned earlier, CLARA differentiates between variable definition\
    \ and variable usage. An example of this can be seen\n\n```\n1 a = 3\n2 b = a\
    \ + 1\n3 for x in range (0 , 2 ):\n4 b += x\n5 b += a\n```\n<span id=\"page-21-1\"\
    ></span>Figure 7: Sample program to illustrate how CLARA differentiates between\
    \ variable definition and usage\n\nin Figures [7](#page-21-1) and [8,](#page-22-0)\
    \ where location 1 defines variable a and uses it, denoted as a ′ . Note that\
    \ location 3 uses the same variable; however, in this case, location 3 does not\
    \ (re)define variable a; therefore, it does not use a ′ . As a result, we need\
    \ to deal with an additional problem involving variable definition. For variable\
    \ usage, we must ensure that variables exist and are defined earlier in the location.\
    \ If we add a new variable definition within a location, we need to make sure\
    \ that usages of that variable are updated. For instance, if we add a definition\
    \ of a into location 3, we must change a to a ′ when it is used to update b. Therefore,\
    \ every time a new variable is added or deleted, we execute a trace of the function\
    \ to help us determine which variables we have access to before adding a repair.\
    \ If all of the variables used in that expression are defined, we add the repair.\
    \ Otherwise, we continue adding the rest of the repairs and come back to the ones\
    \ we skipped earlier until no more repairs are available.\n\nOnce all the repairs\
    \ have been applied, we rerun the repair process to determine if any additional\
    \ repairs are suggested for the same test case. If this happens, we halt and conclude\
    \ that the program is not successfully repaired. Otherwise, we conclude that the\
    \ incorrect program is repaired for that particular test case, run the repair\
    \ process for all other available test cases, and record if any repairs are suggested.\
    \ If no other repairs are suggested overall, we can successfully conclude that\
    \ the incorrect program has been fully repaired for all test cases.\n\n## <span\
    \ id=\"page-21-0\"></span>6. Flexible program alignment\n\nOne of CLARA's main\
    \ limitations is that it requires both the correct and the incorrect programs\
    \ to have similar control flows in order to proceed with the repair process. It\
    \ is uncommon to find many programs containing the same control flow, which reduces\
    \ the number of programs CLARA can\n\n<span id=\"page-22-0\"></span>Loc 1 (around\
    \ the beginning of function)\n\n−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−− a := 3 b :=\
    \ Add(a', 1) iter#0 := range(0, 2) ind#0 := 0 −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\
    \ True −> 2 False −> None Loc 2 (the condition of the 'for' loop at line 3) −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\
    \ \\$cond := Lt(ind#0, len(iter#0)) −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−− True −>\
    \ 4 False −> 3 Loc 3 (∗after∗ the 'for' loop starting at line 3) −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\
    \ b := AssAdd(b, a) −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−− True −> None False −>\
    \ None Loc 4 (inside the body of the 'for' loop beginning at line 4) −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\
    \ x := GetElement(iter#0, ind#0)\n\nind#0 := Add(ind#0, 1) b := AssAdd(b, x')\
    \ −−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−−\n\nTrue −> 2 False −> None\n\nFigure 8:\
    \ Model of the program in Figure [7](#page-21-1) that differentiates between variable\
    \ definition and usage, e.g., a and a ′\n\n<span id=\"page-23-0\"></span>![](_page_23_Figure_0.jpeg)\n\
    \nFigure 9: Correct and incorrect programs used to illustrate flexible alignment\n\
    \nrepair in practice. Hu et al. [\\[18\\]](#page-46-3) reported that CLARA's repair\
    \ process did not work for 35.5% of incorrect programs using several introductory\
    \ programming assignments. Our experiments below also confirm these findings.\n\
    \nWe propose an algorithm that creates a flexible alignment between the control\
    \ flow graphs of the correct and incorrect programs. This flexible alignment takes\
    \ into consideration both semantic and topological information of the graphs.\
    \ Our main goal is to reduce mismatches in the alignment process; however, this\
    \ comes with a penalty: since it is approximate, it is possible to obtain an alignment\
    \ that makes the repair process fail. We discuss these issues in this section.\n\
    \nFigure [9](#page-23-0) presents a simplified version of the programs presented\
    \ in Section [2.](#page-3-0) We use these two programs to illustrate our discussions\
    \ in this section. Note that, in this section, we assume CLARA's optimization\
    \ of replacing if statements containing no loops by ternary operators is disabled.\n\
    \n### 6.1. Creation of the control flow graph\n\nEach model created by CLARA is\
    \ based on the program's control flow. Hence, we decided to utilize the information\
    \ available to us in the model to create control flow graphs for both the correct\
    \ and incorrect programs. Each location is a node in the control flow graph, and\
    \ the location's transitions are the edges in the graph. Since many transitions\
    \ pointed to None, indicating that no transition exists, we decided to create\
    \ a special node for None.\n\nEach node in the control flow graph contains a location\
    \ number, the corresponding location's expressions, the starting line number of\
    \ that location, a description, and a multiset of labels. This multiset contains\
    \ all the semantic information we can extract from the (nested) expressions of\
    \ the location at hand. Each expression contains semantic information in terms\
    \ of constants and operation semantics. Operation semantics allow us to identify\
    \ the type of statement, e.g., addition or subtraction. Unlike expressions, which\
    \ can hold different values due to variables, we want the elements of a label\
    \ to always remain constant for a particular expression. Therefore, variable names\
    \ are not added to the multiset of labels. For example, consider the following\
    \ Python statements:\n\n$$\\begin{array}{rcl} \\mathbf{a} & \\mathbf{a} & = &\
    \ \\begin{bmatrix} \\mathbf{1} & \\mathbf{5} \\end{bmatrix}, & \\mathbf{6} \\\
    end{array}$$\n\n$$\\begin{array}{rcl} \\mathbf{a} & \\mathbf{b} & = & \\mathbf{a}\
    \ \\begin{bmatrix} \\mathbf{0} \\end{bmatrix} \\end{array}$$\n\n$$\\begin{array}{rcl}\
    \ \\mathbf{a} & \\mathbf{c} & = & \\mathbf{b} \\end{array} + \\begin{array}{rcl}\
    \ \\mathbf{1} \\end{array}$$\n\nWe extract a multiset of labels for each statement.\
    \ Note that these labels correspond to expressions in the model derived from the\
    \ Python statements. Since a is a list formed by the elements 1, 5 and 6, it contains\
    \ the labels {ListInit, 1, 5, 6}. Also, b is initialized with the first element\
    \ of a, so it has the labels {GetElement, 0}; similarly, c is initialized with\
    \ b + 1, so it has the labels, {Add, 1}. Therefore, the labels assigned to the\
    \ node is the union of all of these multisets, i.e, {ListInit, 1, 5, 6, GetElement,\
    \ 0, Add, 1} (note that 1 appears twice). Recall that we exclude the variable\
    \ names a, b and c from the labels of the node as the variables do not necessarily\
    \ evaluate to the same value at every point in the program.\n\nWe iterate through\
    \ the model of a function to create the nodes of the control flow graph with the\
    \ information mentioned above. After the nodes have been created, we connect the\
    \ nodes with edges representing the transitions between the model locations. Each\
    \ edge is annotated with a True or False label based on the type of the transition.\
    \ Figure [10](#page-26-0) shows the control flow graphs obtained from the programs\
    \ in Figure [9.](#page-23-0) Each node in the figure contains the location number\
    \ and its corresponding multiset of labels. The expressions, line numbers, and\
    \ descriptions have been omitted from the figure to improve readability. The dotted\
    \ arrows represent False transitions, and the solid arrows represent True transitions.\
    \ The node with the label Empty represents a location in the program model that\
    \ does not contain any expressions, which corresponds to the end of the loop.\n\
    \nAlgorithm 2: FlexAlign\n\n<span id=\"page-25-9\"></span><span id=\"page-25-8\"\
    ></span><span id=\"page-25-7\"></span><span id=\"page-25-6\"></span><span id=\"\
    page-25-5\"></span><span id=\"page-25-4\"></span><span id=\"page-25-3\"></span><span\
    \ id=\"page-25-2\"></span><span id=\"page-25-1\"></span><span id=\"page-25-0\"\
    ></span>input : G<sup>C</sup> = (U , E) control flow graph of the correct program;\
    \ G<sup>I</sup> = (V , F) control flow graph of the incorrect program input/output:\
    \ ϕbest : U → V <sup>1</sup> // Initialize best alignment and similarity. <sup>2</sup>\
    \ ϕbest ← {}, sbest ← 0 <sup>3</sup> // Check every permutation. <sup>4</sup>\
    \ for ϕ ∈ Permutations(U , V ) do <sup>5</sup> // s is the similarity of ϕ. <sup>6</sup>\
    \ s ← 0 <sup>7</sup> for u ∈ dom ϕ do <sup>8</sup> v ← ϕ(u) <sup>9</sup> // Jaccard\
    \ similarity between the labels of u and v. <sup>10</sup> slabel ← Jaccard(L(u),\
    \ L(v)) <sup>11</sup> // u ′ and u ′′ (v ′ and v ′′) are the neighbors of u (v).\
    \ <sup>12</sup> Let {u True −−→ u ′ , u False −−−→ u ′′} ⊆ E, {v True −−→ v ′\
    \ , v False −−−→ v ′′} ⊆ F <sup>13</sup> // Edge similarity is 0.5 by default.\
    \ <sup>14</sup> sedge ← 0.5 <sup>15</sup> // Check if the neighbors match. <sup>16</sup>\
    \ if v ′ = ϕ(u ′ ) ∧ v ′′ = ϕ(u ′′) then <sup>17</sup> sedge ← 1 <sup>18</sup>\
    \ else if v ′ ̸= ϕ(u ′ ) ∧ v ′′ ̸= ϕ(u ′′) then <sup>19</sup> sedge ← 0 <sup>20</sup>\
    \ end <sup>21</sup> // Aggregate both similarities (same importance). <sup>22</sup>\
    \ s ← s + (slabel + sedge )/2 <sup>23</sup> end <sup>24</sup> // Update the best\
    \ alignment found. <sup>25</sup> if s > sbest then <sup>26</sup> sbest ← s, ϕbest\
    \ ← ϕ <sup>27</sup> end <sup>28</sup> end\n\n<span id=\"page-26-0\"></span>![](_page_26_Figure_0.jpeg)\n\
    \nv7\n\nv8\n\nu2 v1 u2 Figure 10: Control flow graphs derived from the programs\
    \ in Figure [9](#page-23-0)\n\n0,101,0\n\nv1 0,101,0\n\nv2 cond,Lt,len\n\nv2 cond,Lt,len\n\
    \n#### u3 u4 6.2. Alignment algorithm\n\ncond,Lt,len\n\ncond,Lt,len\n\nu1 0,101,0\n\
    \nu1 0,101,0\n\nu3 Empty\n\n> u0 None\n\nu1 0,101,0\n\nu3\n\nu0\n\nv3 Empty v0\
    \ None v11 out,StrAppend,Add,Add,\",\" v4 AssAdd,GetElement v5 cond,Lt,GetElement\
    \ v6 GetElement v7 AssAdd,1 Empty u0 None u8 out,StrAppend,Add,Add,\",\" AssAdd,GetElement\
    \ u5 cond,Gt,GetElement u6 GetElement u7 AssAdd,1 v8 cond,Eq,0 v9 Sub,1 v10 Empty\
    \ v3 Empty v0 None v11 out,StrAppend,Add,Add,\",\" v4 AssAdd,GetElement v5 cond,Lt,GetElement\
    \ v6 GetElement v7 AssAdd,1 Empty None u8 out,StrAppend,Add,Add,\",\" u4 AssAdd,GetElement\
    \ u5 cond,Gt,GetElement u6 GetElement u7 AssAdd,1 v8 cond,Eq,0 v9 Sub,1 v10 Empty\
    \ Our graph alignment process aims to find a mapping between the nodes of the\
    \ control flow graphs of the correct and incorrect programs. Algorithm [2](#page-25-0)\
    \ aims to compute such mapping taking into consideration both the semantic and\
    \ topological information of the graph, i.e., labels and edges, respectively.\
    \ The algorithms takes the two control flow graphs of the incorrect and correct\
    \ programs as input, denoted as G<sup>C</sup> = (U , E) and G<sup>I</sup> = (V\
    \ , F), respectively, where U and V are sets of nodes, and E and F are sets of\
    \ edges. The algorithm aims to find a mapping ϕbest from U to V . To accomplish\
    \ this, it explores all possible permutations of these mappings, that is, all\
    \ combinations of nodes in U mapped to nodes in V , which is performed by the\
    \ Permutations function (line [4\\)](#page-25-1). Let ϕ be one of these permutations.\
    \ The similarity of ϕ, denoted by s, is computed by considering label and edge\
    \ similarities. For each node u present in ϕ (line [7\\)](#page-25-2) and its\
    \ corresponding v (line [8\\)](#page-25-3), the algorithm computes the Jaccard\
    \ similarity between the multisets of labels of both nodes (line [10\\)](#page-25-4).\
    \ The formula for the multisets L(u) and L(v) is as follows [\\[19\\]](#page-46-4):\n\
    \n$$Jaccard(L(u), L(v)) = \\frac{\\sum\\_{x \\in L(u) \\cap L(v)} \\min(W(x, L(u)),\
    \ W(x, L(v)))}{\\sum\\_{x \\in L(u) \\cup L(v)} \\max(W(x, L(u)), W(x, L(v)))}$$\n\
    \n<span id=\"page-27-0\"></span>\n\n| Multiset<br>L(u)             | Multiset<br>L(v)\
    \             | Jaccard |\n|------------------------------|------------------------------|---------|\n\
    | GetElement, 0, 0             | GetElement, 0                | 0.667   |\n| GetElement,\
    \ 0                | GetElement, 0                | 1       |\n| cond, Lt, ind#0,\
    \ len, iter#0 | cond, Gt, ind#1, len, iter#1 | 0.25    |\n| ListInit, 5, 6   \
    \            | ListInit, 8, 9               | 0.2     |\n\nTable 4: Multisets\
    \ of labels and their corresponding Jaccard similarities\n\nwhere W (x , S) is\
    \ the number of times x appears in the multiset S. Note that 0 ≤ Jaccard(L(u),\
    \ L(v)) ≤ 1, where zero indicates no similarity and one indicates both multisets\
    \ are equal. Table [4](#page-27-0) presents several examples of multisets of labels\
    \ and their corresponding Jaccard similarities. We rely on Jaccard similarity\
    \ because it penalizes dissimilarities between the multisets compared, intersection\
    \ divided by union, more than others like Sørensen–Dice.\n\nOnce Jaccard similarity\
    \ is computed, the algorithm computes edge similarity (lines [12](#page-25-5)[–19\\\
    )](#page-25-6). It considers both neighbors of u and v that correspond to the\
    \ False and True transitions in each control flow graph. If both sets of neighbors\
    \ are mapped in ϕ, the edge similarity is one; if none of them are mapped in ϕ,\
    \ the edge similarity is zero; otherwise, the edge similarity is 0.5 (one but\
    \ not the other is mapped).\n\nBoth similarities are combined using the same importance\
    \ and added to the current similarity of ϕ (line [22\\)](#page-25-7). Finally,\
    \ the graph alignment that is output is the one with highest similarity (lines\
    \ [25–](#page-25-8)[26\\)](#page-25-9).\n\nNote that, even though we expect to\
    \ deal with small programs, the number of nodes in a program in an introductory\
    \ programming assignment typically ranges between 10 and 20; therefore, it is\
    \ possible to have more than 3 million permutations. In practice, we aim to find\
    \ permutations with high similarities first. To accomplish this, we use a heuristic\
    \ in which we explore the permutations in ascending order by semantic similarity.\
    \ Furthermore, we only explore the top-k permutations found using this approach.\n\
    \nFigure [11](#page-28-0) presents an alignment between the control flow graphs\
    \ discussed above. The control flow graph of the correct program is on the left\
    \ side, and the graph of the incorrect program is on the right side. The solid\
    \ red lines indicate the mapping ϕ between the nodes. As it can be observed, nodes\
    \ v8, v<sup>9</sup> and v<sup>10</sup> are not mapped to any nodes in the correct\
    \ program. These locations correspond to the second if statement in the incorrect\
    \ program.\n\nAlgorithm [2](#page-25-0) always produces an alignment between the\
    \ input programs.\n\n<span id=\"page-28-0\"></span>![](_page_28_Figure_0.jpeg)\n\
    \nv1 0,101,0\n\n> v3 Empty v0 None\n\nv11 out,StrAppend,Add,Add,\",\"\n\nv10 Empty\n\
    \nv6 GetElement\n\nv2 cond,Lt,len\n\nv4 AssAdd,GetElement\n\nv5 cond,Lt,GetElement\n\
    \n> v9 Sub,1\n\nv7 AssAdd,1\n\n> v8 cond,Eq,0\n\nFigure 11: Alignment between\
    \ the control flow graphs from Figure [10](#page-26-0)\n\nOne can use s, the similarity\
    \ of an alignment, to decide whether or not to proceed with the repair process.\
    \ In our experiments below, we use a threshold over s to proceed to repair the\
    \ programs.\n\n### 6.3. Recreating the model\n\nu1 0,101,0\n\nu3 Empty\n\n> u0\
    \ None\n\nu8 out,StrAppend,Add,Add,\",\"\n\nu6 GetElement\n\nu2 cond,Lt,len\n\n\
    u4 AssAdd,GetElement\n\nu5 cond,Gt,GetElement\n\n> u7 AssAdd,1\n\nOnce we have\
    \ computed an alignment ϕ between the control flow graphs of the correct and the\
    \ incorrect programs, we have to recreate the input that CLARA's repair process\
    \ requires. Since the process receives models for each program, we rely on ϕ and\
    \ the model of the correct program to recreate the new model. There are three\
    \ possibilities. First, the control flow graph of the correct program has less\
    \ nodes than the graph of the incorrect program. In this case, nodes need to be\
    \ removed from the new model. Second, the control flow graph of the correct program\
    \ has more nodes, which implies that new nodes need to be added to the new model.\
    \ Third, both graphs have the same size, so no nodes need to be added or removed.\
    \ In all of the three cases, edges or nodes might need rearrangement in the new\
    \ model after an alignment has been determined.\n\nAlgorithm [3](#page-29-0) takes\
    \ as input both control flow graphs (G<sup>C</sup> and G<sup>I</sup> ) as well\
    \ as the alignment between them (ϕ). It outputs M<sup>I</sup> , the recreated\
    \ model of the incorrect program. If there are more nodes in the incorrect program\n\
    \n### <span id=\"page-29-0\"></span>Algorithm 3: RecreateModel\n\n<span id=\"\
    page-29-6\"></span><span id=\"page-29-5\"></span><span id=\"page-29-4\"></span><span\
    \ id=\"page-29-3\"></span><span id=\"page-29-2\"></span><span id=\"page-29-1\"\
    ></span>input : G<sup>C</sup> = (U , E) control flow graph of the correct program;\
    \ G<sup>I</sup> = (V , F) control flow graph of the incorrect program; ϕ : U →\
    \ V alignment output: M<sup>I</sup> = (W , J ) recreated model of the incorrect\
    \ program <sup>1</sup> // Initialize M<sup>I</sup> with the nodes in G<sup>I</sup>\
    \ and empty edges. <sup>2</sup> W ← V , J ← ∅ <sup>3</sup> // Correct is smaller\
    \ than incorrect; remove extra nodes. <sup>4</sup> if |U | < |V | then <sup>5</sup>\
    \ // If v is not in ϕ, remove from W . <sup>6</sup> for v ∈ V such that v ∈/ ran\
    \ ϕ do <sup>7</sup> W ← W \\ {v} <sup>8</sup> end <sup>9</sup> end <sup>10</sup>\
    \ // Incorrect is smaller than correct; add extra nodes. <sup>11</sup> if |U |\
    \ > |V | then <sup>12</sup> // If u is not in ϕ, add new node to W and ϕ. <sup>13</sup>\
    \ for u ∈ U such that u ∈/ dom ϕ do <sup>14</sup> v ′ ← CreateNode() <sup>15</sup>\
    \ W ← W ∪ {v ′} <sup>16</sup> ϕ(u) ← v ′ <sup>17</sup> end <sup>18</sup> end <sup>19</sup>\
    \ // Update J to reflect the edges in G<sup>C</sup> . <sup>20</sup> for u ∈ dom\
    \ ϕ do <sup>21</sup> v ← ϕ(u) <sup>22</sup> Let {u True −−→ u ′ , u False −−−→\
    \ u ′′} ⊆ E <sup>23</sup> J ← J ∪ {v True −−→ ϕ(u ′ ), v False −−−→ ϕ(u ′′)} <sup>24</sup>\
    \ end\n\nthan in the correct program, the algorithm removes the extra nodes from\
    \ the new model (lines [4](#page-29-1)[–7\\)](#page-29-2). Note that, for every\
    \ node that is deleted, its corresponding expressions and edges (transitions)\
    \ are deleted too. If there are less nodes, it generates new, fresh nodes using\
    \ the CreateNode function, which are added to both the new model and ϕ (lines\
    \ [11](#page-29-3)[–16\\)](#page-29-4). Note that these new nodes do not contain\
    \ any expressions because we do not know yet the corresponding variables associated\
    \ with those expressions. During the repair process, additions of new expressions\
    \ will be suggested for these new nodes. Finally, the algorithm updates the edges\
    \ of the new model based on the edges of the correct program (lines [20–](#page-29-5)[23\\\
    )](#page-29-6).\n\n### <span id=\"page-30-0\"></span>7. Evaluation\n\nTo evaluate\
    \ the performance of CLARA and the improvements of our flexible alignment scheme,\
    \ we built a dataset of correct and incorrect programs from the online programming\
    \ website Codeforces ([https://codeforces.](https://codeforces.com) [com](https://codeforces.com)).\
    \ It is an online platform that hosts competitive programming contests and programming\
    \ problems divided into multiple difficulty ratings. Submissions by users, both\
    \ correct and incorrect, are publicly available. To evaluate the correctness of\
    \ a program, the platform executes it on several test cases. Codeforces programming\
    \ problems follow the same structure: each test case must be read from the console\
    \ by a given program, and such a test case consists of line-delimited parameters.\
    \ The first line indicates the number of arguments, and the following lines include\
    \ arguments as a single block of text that requires parsing before performing\
    \ any computations to solve the problem at hand. A variety of methods can be used\
    \ for such parsing, but the most common is Python's input function for reading\
    \ console input.\n\nIf a program does not pass a particular test case, the testing\
    \ stops and the program is declared incorrect. The test case on which the program\
    \ failed is provided by the platform. Therefore, we only have access to the first\
    \ test case that is not passed for every incorrect program. Furthermore, because\
    \ CLARA uses variable tracing to find repairs in the program, we only need the\
    \ test case input, not the output it is supposed to produce. The platform does\
    \ not display test cases that are longer than 50 lines; instead, it displays the\
    \ initial 50 lines followed by \". . . \" characters. As a result, these test\
    \ cases are incomplete, inaccessible, and therefore, invalid for our purposes.\n\
    \nTaking these factors into account, in our experiments, we utilized valid submissions\
    \ for twenty programming problems with the highest number of Python submissions,\
    \ and fulfilled the condition of having at least one of the following: (1) a loop,\
    \ (2) an if statement, (3) a call to read from standard input, and (4) a call\
    \ to print to standard output.\n\n### 7.1. Dataset and Experimental Setup\n\n\
    Since CLARA analyzes an incorrect program based on correct programs, we selected\
    \ thirty correct programs to be compared with the pool of all incorrect programs\
    \ for each of the twenty programming problems. The subset of thirty correct programs\
    \ for each problem was selected as follows: select the top-10 programs when sorted\
    \ by date and they are from different users. Then, select the top-10 programs\
    \ when sorted by size ascending and they are from different users. Repeat the\
    \ same operation using descending order. All of the incorrect programs taken into\
    \ account failed valid test cases as recorded by the platform. These programs\
    \ were all unique and made by different users. We evaluated five techniques as\
    \ follows:\n\n- 1. Baseline CLARA with No Alignment (CNA): The original implementation\
    \ of CLARA with no modifications and no flexible alignment.\n- 2. SARFGEN: Sarfgen\
    \ [\\[3\\]](#page-44-1) is not publicly available; therefore, we simulated its\
    \ alignment step. We used our proposed flexible alignment (see Algorithm [2\\\
    )](#page-25-0), considering both semantic and topological similarities (label\
    \ and edge), and model recreation (see Algorithm [3\\)](#page-29-0). However,\
    \ we set a threshold: only similarities greater or equal than 0.95 are kept. This\
    \ simulates Sarfgen's rigid program comparison in which both control flow graphs\
    \ must perfectly match.\n- 3. Baseline CLARA: The original implementation with\
    \ the modifications described in Section [4.](#page-14-0) The alignment process\
    \ is the one originally implemented (see Algorithm [1\\)](#page-11-0).\n- 4. FA(L):\
    \ It uses our proposed flexible alignment (FA) (see Algorithm [2\\)](#page-25-0)\
    \ and model recreation (see Algorithm [3\\)](#page-29-0). However, it only exploits\
    \ semantic information (label) for alignments, i.e., edge similarity is always\
    \ equal to one (sedge = 1).\n- 5. FA(L+E): Similar to FA(L) but it considers both\
    \ semantic and topological similarities (label and edge) as described in Algorithm\
    \ [2.](#page-25-0)\n\nNote that the five techniques rely on the same repair process,\
    \ i.e., the process of CLARA's original implementation. Furthermore, we noted\
    \ that the number of nodes in each program's control flow graph ranges between\
    \ 1 and\n\n| Reasons                      | CNA    | SGEN   | CLARA  | FA(L) \
    \ | FA(L+E) |\n|------------------------------|--------|--------|--------|--------|---------|\n\
    | Unavailable Test Cases       | 25,485 | 25,498 | 25,485 | 25,498 | 25,498  |\n\
    | Unsupported Constructs       | 26,152 | 26,152 | 26,152 | 26,152 | 26,152  |\n\
    | Unsupported Class Attributes | 7,868  | 7,868  | 7,868  | 7,868  | 7,868   |\n\
    | Keyword Arguments            | 5,148  | 5,148  | 5,148  | 5,148  | 5,148   |\n\
    | Timeout                      | 9      | 172    | 9      | 191    | 172     |\n\
    | Total Invalid                | 64,838 | 64,838 | 64,662 | 64,857 | 64,838  |\n\
    | Total Valid                  | 15,925 | 15,749 | 15,925 | 15,730 | 15,749  |\n\
    | Total Comparisons            | 80,587 | 80,587 | 80,587 | 80,587 | 80,587  |\n\
    \n<span id=\"page-32-0\"></span>Table 5: Program comparisons available in our\
    \ dataset and summary of invalidity reasons. SGEN refers to SARFGEN while CNA\
    \ refers to CLARA with no flexible alignment.\n\n70. This implies that, in many\
    \ cases, we can have millions of permutations to be evaluated to compute an alignment.\
    \ Therefore, for SARFGEN, FA(L) and FA(L+E), we set a limit of 1,000 permutations.\
    \ The best alignment is thus chosen from these permutations. Recall that we sort\
    \ the node candidates by semantic similarity (labels) with the expectation that\
    \ an alignment with a high similarity will be computed. We also set a time limit\
    \ of one minute for SARFGEN, FA(L), and FA(L+E), and an overall time limit of\
    \ five minutes. If any of these limits is reached, we report a timeout error.\n\
    \nTable [5](#page-32-0) presents a summary of the program comparisons available\
    \ in our dataset. The total number of program comparisons is 80,587, which corresponds\
    \ to the Cartesian product between the total number of incorrect programs and\
    \ the subset of correct programs selected as explained above. A significant portion\
    \ of the comparisons was filtered out because of the following reasons: (1) The\
    \ test cases were not available, (2) Contained unsupported language constructs\
    \ like lambda expressions or try-catch blocks, (3) Contained class attributes,\
    \ (4) Contained functions with keyword arguments, and (5) There were timeout errors.\
    \ Note that there were only 191 timeout errors in the worst case among the comparisons,\
    \ which amounts to less than 1.25% of the total valid comparisons. Therefore,\
    \ timeout errors were significantly mitigated thanks to the time thresholds we\
    \ established. Due to the difference in the number of timeouts for each technique,\
    \ the total valid comparisons are different between them. As a result, we further\
    \ filter the remaining valid comparisons to only pick the comparisons with common\
    \ permutations of valid and invalid programs. This results in 15,688 common valid\
    \ program comparisons available for all the techniques.\n\n| Problem | Total \
    \ | Correct | Incorrect | LOC               | Exprs.             | Diff. |\n|---------|--------|---------|-----------|-------------------|--------------------|-------|\n\
    | 4A      | 1,059  | 10      | 43        | 6.94<br>±<br>0.43 | 5.02<br>±<br>0.14\
    \  | 800   |\n| 50A     | 567    | 5       | 60        | ±<br>2.38<br>1.31 | ±<br>4.90<br>1.26\
    \  | 800   |\n| 214A    | 717    | 7       | 66        | ±<br>11.8<br>5.21 | ±<br>21.0<br>7.87\
    \  | 800   |\n| 255A    | 1,856  | 12      | 96        | 12.5<br>±<br>7.77 | 13.1<br>±<br>7.14\
    \  | 800   |\n| 265A    | 300    | 6       | 25        | 4.95<br>±<br>0.22 | 11.6<br>±<br>1.75\
    \  | 800   |\n| 510A    | 1,001  | 7       | 78        | 17.7<br>±<br>5.14 | 18.4<br>±<br>8.68\
    \  | 800   |\n| 1097A   | 1,329  | 10      | 72        | 16.1<br>±<br>15.6 | 17.6<br>±<br>13.13\
    \ | 800   |\n| 1360B   | 544    | 4       | 85        | ±<br>8.61<br>1.20 | ±<br>18.1<br>2.71\
    \  | 800   |\n| 1370A   | 3,012  | 6       | 249       | ±<br>4.53<br>1.09 | ±<br>10.0<br>3.06\
    \  | 800   |\n| 1385A   | 4,779  | 6       | 428       | 26.8<br>±<br>3.45 | 24.9<br>±<br>4.52\
    \  | 800   |\n| 1391A   | 9,033  | 25      | 148       | 5.83<br>±<br>2.27 | 9.23<br>±<br>4.35\
    \  | 800   |\n| 1391B   | 318    | 6       | 51        | 9.91<br>±<br>2.80 | 23.1<br>±<br>5.19\
    \  | 800   |\n| 208A    | 447    | 5       | 65        | ±<br>8.64<br>10.9 | ±<br>8.44<br>10.16\
    \ | 900   |\n| 1A      | 877    | 5       | 125       | ±<br>2.00<br>0.00 | ±<br>5.73<br>1.03\
    \  | 1000  |\n| 1382B   | 1,532  | 5       | 145       | 15.5<br>±<br>4.31 | 21.2<br>±<br>2.59\
    \  | 1100  |\n| 492B    | 1,147  | 9       | 90        | 9.03<br>±<br>8.15 | 18.7<br>±<br>11.41\
    \ | 1200  |\n| 1363A   | 2,788  | 7       | 295       | 17.0<br>±<br>9.96 | 27.5<br>±<br>5.96\
    \  | 1200  |\n| 1364A   | 12,581 | 11      | 679       | 8.63<br>±<br>5.74 | 14.5<br>±<br>4.65\
    \  | 1200  |\n| 1369B   | 2,410  | 7       | 211       | ±<br>8.00<br>5.72 | ±<br>14.4<br>5.63\
    \  | 1200  |\n| 4C      | 1,107  | 10      | 66        | ±<br>10.3<br>1.57 | ±<br>16.9<br>2.53\
    \  | 1300  |\n\n<span id=\"page-33-0\"></span>Table 6: Dataset statistics for\
    \ valid programs, where LOC and Exprs. respectively indicate total lines of code\
    \ and number of expressions, and Diff. is the problem's difficulty\n\nThe summary\
    \ statistics of the dataset are shown in Table [6.](#page-33-0) The Total column\
    \ indicates the number of valid comparisons each programming problem comprises,\
    \ while the Correct and Incorrect columns display the number of unique programs\
    \ that are part of the total valid comparisons. The LOC and Exprs. columns highlight\
    \ the mean and standard deviation of the number of lines of code and expressions\
    \ (nodes in the control flow graph) respectively across all programs, both correct\
    \ and incorrect. The Diff. column displays the number assigned by Codeforces to\
    \ indicate the difficulty of the problem. However, the ranking and reasoning behind\
    \ the assignment of the number are not officially documented. The closest explanation\
    \ we found was through a Codeforces blogpost [\\[20\\]](#page-46-5), where difficulty\
    \ is assigned such that the expected probability of solving the problem is 0.5\
    \ for coders of that rating. Since we are looking at introductory assignments,\
    \ we limit our ratings from 800 to 1300. We consider the difficulty rating of\
    \ 800 to be low difficulty (it is the lowest available in Codeforces). We selected\
    \ the range of 900-1300 as hard difficulty problem as there are 11,841 data points\
    \ for 800, and 9,518 for 900-1300, allowing for as close to equal binning between\
    \ the two as possible. Analyzing the table, we observe lower lines of code with\
    \ greater variance for low-difficulty problems while higher-difficulty problems\
    \ on average have more lines of code but less variance. This is indicative that\
    \ low-difficulty problems comprise a combination of one-line and longer solutions,\
    \ depending on the capability of the programmers. In contrast, the number of expressions\
    \ at higher difficulty is higher with higher variance, indicating the increase\
    \ in complexity of the solution to the problems. This is also confirmed by Figure\
    \ [12,](#page-35-0) which displays boxplots of the number of lines of code and\
    \ expressions in the programs grouped by difficulty.\n\n### 7.2. Quantitative\
    \ Analysis\n\nSuccessful repairs. In Figure [13,](#page-35-1) we present the percentage\
    \ of successful repairs, which was computed as follows: the number of unique incorrect\
    \ programs fully repaired divided by the total number of incorrect programs. In\
    \ Figure [13a,](#page-35-2) we present the macro success rate for the five techniques\
    \ under evaluation. It can be observed that flexible alignment in both flavors\
    \ significantly outperforms CLARA (5%) and CNA (0.3%) with FA(L) at 45% and FA(L+E)\
    \ at 46% success rates, respectively. We can also observe that baseline CLARA\
    \ performs slightly better than SARFGEN and significantly better than CNA. This\
    \ macro result highlights the major improvement in repair capability that flexible\
    \ alignment can achieve. Figure [13b](#page-35-3) aggregates\n\n<span id=\"page-35-0\"\
    ></span>![](_page_35_Figure_0.jpeg)\n\nFigure 12: Number of lines of code and\
    \ expressions of programs grouped by difficulty\n\n<span id=\"page-35-2\"></span><span\
    \ id=\"page-35-1\"></span>![](_page_35_Figure_2.jpeg)\n\n<span id=\"page-35-3\"\
    ></span>Figure 13: Percentage of incorrect programs fully repaired grouped by\
    \ technique and difficulty\n\n<span id=\"page-36-2\"></span><span id=\"page-36-0\"\
    ></span>![](_page_36_Figure_0.jpeg)\n\nFigure 14: Percentage of incorrect programs\
    \ fully repaired grouped by lines of code and expressions. Cases that failed before\
    \ model creation are ignored.\n\n<span id=\"page-36-1\"></span>Table 7: Number\
    \ of samples in each bin when grouped by LOC (lines of code) and Exprs. (expressions).\
    \ Failed indicates failures before model creation.\n\n<span id=\"page-36-3\"></span>\n\
    \n| LOC    | #     | Exprs. | #     |\n|--------|-------|--------|-------|\n|\
    \ 0–4    | 1,072 | 0–4    | 464   |\n| 5      | 2,301 | 5–10   | 1,597 |\n| 6–15\
    \   | 2,661 | 11–20  | 3,398 |\n| 16–40  | 1,712 | 21–40  | 2,230 |\n| 41–80 \
    \ | 209   | 41–80  | 266   |\n| Failed | 7,733 | Failed | 7,733 |\n\nresults by\
    \ problem difficulty. We observe that the five techniques achieve better success\
    \ rates in low-difficulty problems. We also observe that success rates decrease\
    \ in high-difficulty problems compared to low-difficulty ones. In low-difficulty\
    \ problems, FA(L+E) at 48.2% outperforms FA(L) at 47.5% by 0.7%. However, this\
    \ gain is not as evident in the other problems. Our hypothesis to explain this\
    \ behavior is that, on one hand, low-difficulty problems contain similar statements\
    \ that cannot be easily differentiated based solely on labels. On the other hand,\
    \ high-difficulty problems contain many specialized statements that are almost\
    \ unique, so labels are helpful to align statements without the use of edges.\
    \ We can conclude that using both label and edge similarities in the alignment\
    \ process is beneficial.\n\nAs lines of code increase for programs as shown in\
    \ Figure [14a,](#page-36-0) the performance of all the techniques decreases, but\
    \ baseline CLARA fails to find repairs for programs with 41 lines of code or higher.\
    \ Note that these bins\n\n<span id=\"page-37-0\"></span>![](_page_37_Figure_0.jpeg)\n\
    \n<span id=\"page-37-1\"></span>Figure 15: Number of repairs necessary to repair\
    \ incorrect programs and change percentage (the proportion of the incorrect program\
    \ that was changed) grouped by difficulty\n\nare not balanced as presented in\
    \ Table [7.](#page-36-1) In 7,733 of these comparisons, the techniques failed\
    \ to produce a model to compute lines of code and expressions, which are reported\
    \ in the table. In Figure [14,](#page-36-2) once model creation has been completed,\
    \ flexible alignment has a success percentage over 80% for all LOC and Exprs.\
    \ except for those above 41. In Figure [14a,](#page-36-0) FA(L+E) with its additional\
    \ topological information and flexibility performs better compared to more rigid\
    \ alignment schemes. In addition to lines of code, if we analyze successful repairs\
    \ in terms of expressions in programs, FA(L+E) with both semantic and topological\
    \ information outperforms FA(L), even as the number of expressions – by proxy\
    \ complexity – increases, as seen in Figure [14b.](#page-36-3)\n\nNumber of repairs\
    \ and percentage changes. We also evaluate the performance considering the number\
    \ of repairs. Note that, for a given incorrect program, there is typically the\
    \ case that several correct programs can be used to repair it. We measure, for\
    \ each incorrect program, the minimum number of repairs among all correct programs,\
    \ and the change percentage, that is, the percentage of the incorrect program\
    \ that was altered in order to repair it. As shown in Figure [15a,](#page-37-0)\
    \ flexible alignment has a higher minimum number of repairs than baseline CLARA,\
    \ and the range of repairs is significantly higher. This happens in both bins\
    \ of low- and high-difficulty problems. We observe that the number of repairs\
    \ in the high-difficulty problems is similar for both FA(L) and FA(L+E); however,\
    \ for low-difficulty problems, FA(L) has a slightly reduced number of repairs\
    \ compared to FA(L+E) when they both achieve very similar performance. CNA and\
    \ SARFGEN achieve less number of repairs than any of the other techniques, and\
    \ their performances\n\n<span id=\"page-38-0\"></span>![](_page_38_Figure_0.jpeg)\n\
    \nFigure 16: Average number of repairs necessary to repair incorrect programs\
    \ and change percentage (the proportion of the incorrect program that was changed)\
    \ grouped by lines of code\n\nare quite poor for high-difficulty problems.\n\n\
    Figure [15b](#page-37-1) presents the change percentage, i.e., the percentage\
    \ of the incorrect program that was replaced with the correct program. As expected,\
    \ for low-difficulty problems, our flexible alignment techniques change a higher\
    \ percentage of the incorrect programs than baseline CLARA. Surprisingly, this\
    \ is not the case in the high-difficulty problems, in which we observe a higher\
    \ mean of change percentages for baseline CLARA. This implies that our flexible\
    \ scheme finds smaller repairs than baseline CLARA. The behavior of both FA(L)\
    \ and FA(L+E) are very similar. This highlights the benefit of using both label\
    \ and edge flexible alignments for high-difficulty problems. In contrast, SARFGEN\
    \ significantly reduces the number of changes, but this comes with the penalty\
    \ of very low repair rates. For CNA, without any flexible alignment or parser\
    \ modifications, the median number of changes is lower than SARFGEN but at a penalty\
    \ of even lower repair rates than SARFGEN due to the rigidity of the approach\
    \ i.e. it will fix only similar programs.\n\nFigure [16](#page-38-0) presents\
    \ the average number of repairs and change percentage achieved by each technique\
    \ when grouped by lines of code. We observe that, as lines of code increase, the\
    \ average change percentage of baseline CLARA decreases, while the same average\
    \ for our flexible schemes increases. It is surprising though that, for the small\
    \ bin (0–4), baseline CLARA's and SAR-FGEN's means are higher than those of our\
    \ flexible schemes while CNA has the highest mean. The presence of labels and\
    \ edges allows our flexible approach to reduce the change percentage by identifying\
    \ key labels and edges,\n\n<span id=\"page-39-0\"></span>![](_page_39_Figure_0.jpeg)\n\
    \nFigure 17: Percentage of programs fully repaired grouped by programming problem\n\
    \nwhile also maintaining a high degree of repairs at higher lines of code. This\
    \ suggests that by using flexible alignment, one can find a correct–incorrect\
    \ program comparison that is more efficient than using a rigid program comparison\
    \ scheme.\n\n### 7.3. Qualitative Analysis\n\nWe conducted a fine-grained analysis\
    \ of the repairs within the programming problems selected in our dataset. Figure\
    \ [17](#page-39-0) shows the percentage of programs successfully repaired for\
    \ each technique grouped by problem. The results achieved by baseline CLARA, CNA,\
    \ SARFGEN, FA(L), and FA(L+E) across the twenty problems are consistent with the\
    \ macro results in the previous section. Flexible alignment consistently outperforms\
    \ baseline CLARA and CNA: in four problems (50A, 1360B, 1A, 1363A), FA(L) and\
    \ FA(L+E) achieve more than 80% of successful repairs, while baseline CLARA achieves\
    \ less than 20% success rate. CLARA outperforms SARFGEN except in problems 1385A\
    \ and 208A. In these two problems, FA(L), and FA(L+E) are far superior. CNA fails\
    \ to find solutions in most problems with no flexibility or alignment except for\
    \ 4A and 1A.\n\nWe observe several problems in which baseline CLARA achieves poor\
    \ performance of 5% or less success rate. In the worst cases, FA(L) and FA(L+E)\
    \ achieve approximately 20% success rate (problems 214A, 1097A, and 1364A), still\
    \ outperforming the rest. Comparing the performance of FA(L) vs. FA(L+E), we observe\
    \ that, in problem 510A, FA(L+E) significantly outperforms FA(L). In the rest\
    \ of the problems, both techniques perform similarly.\n\n### 7.4. Threats to validity\n\
    \nWe built our dataset of correct and incorrect programs from Codeforces and utilized\
    \ their assignment of difficulty as a metric for our comparisons. However, the\
    \ reasoning and ranking behind the difficulty assignment from Codeforces for each\
    \ of the problems are not well documented (see discussion above). We present an\
    \ analysis to check correlations between difficulty, lines of code, and expressions\
    \ (code complexity) in Figure [12](#page-35-0) to get a better understanding of\
    \ the dataset. Due to the addition of the graph alignment step, we need to process\
    \ the feedback returned by CLARA before it is provided to students. Based on the\
    \ locations added or deleted and the edges modified, we need to be able to inform\
    \ the learner to add/delete the corresponding expressions.\n\nAnother limitation\
    \ of the flexible alignment step is that, while removing locations from the incorrect\
    \ program model, it is possible to remove a variable with no other definition\
    \ in the rest of the program. Therefore, causing the program to crash if it is\
    \ used. We hope to address this issue in the future by checking if deleting a\
    \ variable can cause the program to crash and, if so, adding that variable and\
    \ its expression to a different location.\n\nRecent advances in large language\
    \ models like ChatGPT[2](#page-40-0) and Codex [\\[21\\]](#page-46-6) have raised\
    \ the question of whether they can be used for program repairs such as the one\
    \ we discuss in this paper. While such language models are good at providing suggestions\
    \ during coding or to generate introductory code from scratch, they are not yet\
    \ developed enough to identify and repair incorrect programs given a correct program\
    \ and test cases as a reference. For example, we prompted ChatGPT with the following\
    \ request: Fix the issues in the incorrect code to match the correct code. The\
    \ result of ChatGPT was to replace the entire incorrect program with the correct\
    \ program instead of\n\n<span id=\"page-40-0\"></span><sup>2</sup>https://chat.openai.com/\n\
    \nidentifying exactly the issues of the incorrect program. Our future work will\
    \ focus on adapting our flexible alignment scheme utilizing the semantic strength\
    \ of such large language models.\n\n### <span id=\"page-41-0\"></span>8. Related\
    \ work\n\nThere are many approaches to automatically repair programs in different\
    \ areas [\\[14\\]](#page-45-8). We categorize these into data- and non-data-driven.\
    \ We also discuss program comparison approaches.\n\nData-driven feedback. CLARA\
    \ [\\[10\\]](#page-45-6) clusters correct programs based on test cases and variable\
    \ traces. Each incorrect program is compared to the representative of each cluster\
    \ to find minimal repairs. The repairs consist of adding new variables and modifying\
    \ existing statements without changing the control flow of the incorrect program.\
    \ Sarfgen [\\[3\\]](#page-44-1) searches for correct programs that share the same\
    \ control flow structure as the incorrect program. Incorrect and correct programs\
    \ are fragmented based on their control flows, and, for each fragment pair that\
    \ is matched, potential repairs are computed using abstract syntax tree edits.\
    \ CLARA and Sarfgen only consider pairs of programs whose control flow match,\
    \ which is a hard constraint since such a pair may not currently be present in\
    \ the set of correct programs or, when the incorrect program significantly deviates\
    \ from a correct program, a correct program with such a control flow may not even\
    \ be possible. Hu et al. [\\[18\\]](#page-46-3) addressed CLARA's drawback of\
    \ rigid program comparisons by refactoring the correct program at hand using a\
    \ set of predefined transformations, such that its control flow matches the incorrect\
    \ program at hand. Using program refactoring, it is possible to modify a program\
    \ so thoroughly that it no longer resembles the original version, and can potentially\
    \ cause a correct program to become incorrect. Furthermore, the repairs suggested\
    \ to change the incorrect program into a correct one need to be backtraced to\
    \ the original program before refactoring.\n\nRefazer [\\[13\\]](#page-45-7) proposes\
    \ \"if-then\" rules to match and transform abstract syntax subtrees of a program.\
    \ Such rules are synthesized from sample pairs of correct/incorrect programs,\
    \ in which tree edit distance comparisons between correct and incorrect programs\
    \ help identify individual transformations. Refazer has been extended to propagate\
    \ feedback based on learned transformations [\\[22\\]](#page-46-7). sk p [\\[12\\\
    ]](#page-45-9) relies on neural networks to repair incorrect programs. It constructs\
    \ partial fragments of three consecutive statements using these renamed tokens.\
    \ The middle statements are removed and fed to the repairer for training. The\
    \ order of statements is one of the main drawbacks of Refazer, Sarfgen, and sk\
    \ p: Refazer and Sarfgen rely on edit distances of abstract syntax trees, while\
    \ sk p treats programs as documents. Our flexible alignment allows to account\
    \ for more implementation variability and increases the number of valid program\
    \ comparisons. Piech et al. [\\[11\\]](#page-45-10) select a subset of existing\
    \ programs to annotate with feedback. Each annotation is used individually to\
    \ learn a binary classifier to propagate feedback to unseen programs. These binary\
    \ classifiers are applied to each incorrect program to decide whether it should\
    \ be annotated with a piece of feedback. This approach requires the number of\
    \ variables in programs to be fixed beforehand and a large number of existing\
    \ programs [\\[11\\]](#page-45-10).\n\nNon-data-driven feedback. AutoGrader [\\\
    [7\\]](#page-45-3) allows to define rules using an error model language to describe\
    \ potential repairs to be applied to incorrect programs, e.g., a condition x <\
    \ y can be mistaken by x ≤ y. Based on these rules, AutoGrader generates a \"\
    sketch\" of the program, i.e., a program that contains multiple choices for those\
    \ statements that matched the given rules [\\[23\\]](#page-46-8). A correct program\
    \ is then assembled by ensuring functional equivalence with respect to a single,\
    \ reference program. Repairs are computed as the changes to transform from an\
    \ incorrect to a correct program. There are several approaches that rely on program\
    \ sketching to compute repairs [\\[24](#page-46-9)[–26\\]](#page-47-0). Codewebs\
    \ [\\[27\\]](#page-47-1) allows to search for code snippets by exploiting probabilistic\
    \ semantic equivalence between abstract syntax trees to perform the matching,\
    \ which is based on functional tests over the trees. Feedback can be propagated\
    \ to identified code snippets that are similar. Marin et al. [\\[28\\]](#page-47-2)\
    \ encode correct and incorrect feedback in subgraph patterns over program dependence\
    \ graphs. Feedback is propagated based on exact subgraph matching with approximations\
    \ at the statement level defined by regular expressions. Verifix [\\[29\\]](#page-47-3)\
    \ uses satisfiability modulo theories solvers to find verified repairs between\
    \ incorrect and correct programs. Edmison and Edwards [\\[30\\]](#page-47-4),\
    \ Nguyen et al. [\\[31\\]](#page-47-5) and Li et al. [\\[32\\]](#page-47-6) applied\
    \ fault localization techniques to detect defects in student programs and suggest\
    \ repairs.\n\nMany approaches have focused on discovering repairs by mutating\
    \ programs until repairing them [\\[14,](#page-45-8) [33\\]](#page-47-7). These\
    \ mutations can be predefined and explored using genetic algorithms [\\[34\\]](#page-47-8).\
    \ Yi et al. [\\[35\\]](#page-47-9) analyzed the usage of some of these approaches\
    \ to repair student programs, and concluded that they are better suited for programs\
    \ that fail a small number of tests, while student programs are typically significantly\
    \ incorrect. Mutations can also be retrieved from existing software repositories\
    \ [\\[36–](#page-48-0)[38\\]](#page-48-1). While these approaches can be seen\
    \ as data-driven, they aim to find repairs based on programs that are generally\
    \ not related to the incorrect program at hand to be repaired; therefore, this\
    \ is a more difficult problem than the one we aim to tackle.\n\nProgram comparison.\
    \ There is a large body of knowledge of program comparison in the context of code\
    \ clones and code plagiarism, i.e., copied-andpasted pieces of code with some\
    \ possible modifications. Successful code clone detectors have focused on comparing\
    \ program tokens and (features of) abstract syntax trees [\\[39\\]](#page-48-2).\
    \ These detectors find blocks of lines of code that are similar, but they usually\
    \ fail to detect correspondences between statements. Program dependence graphs\
    \ are believed to achieve the best accuracy when detecting Type 4 clones, i.e.,\
    \ two pieces of code that perform the same computation but are implemented by\
    \ different syntactic variants [\\[39\\]](#page-48-2). Existing approaches have\
    \ mainly focused on comparing programs based on subgraph isomorphism [\\[40–](#page-48-3)[43\\\
    ]](#page-48-4); however, they are generally not flexible enough to cope with implementation\
    \ variability, and they only provide binary comparisons (Are graphs isomorphic?\
    \ Is a graph contained in the other graph?).\n\nThe approach by Li et al. [\\\
    [44\\]](#page-48-5), the most related to our approximate alignment, compares the\
    \ kernel representations of data-flow and API-call graphs. In this case, a kernel\
    \ is the histogram of node colors that result after the Weisfeiler-Leman algorithm\
    \ is applied for several rounds. This algorithm computes an initial coloring for\
    \ each node based on its immediate neighbors, which is later refined in subsequent\
    \ rounds. It only computes graph topological similarity while our approach aims\
    \ to combine both topological and semantic similarities of nodes. Also, this approach\
    \ does not compute similarities between mapped nodes that can be later exploited.\n\
    \n### <span id=\"page-43-0\"></span>9. Conclusions\n\nNowadays, programming is\
    \ perceived as a must-have skill. It is thus not surprising that the number of\
    \ learners have scaled to millions, especially in online settings. Delivering\
    \ feedback is addressed by repairing learners' incorrect programs. The trend in\
    \ data-driven approaches is to perform a rigid matching between correct and incorrect\
    \ programs to discover snippets of code with mending capabilities. The downside\
    \ is that potential repairs that could be captured by looser alignments may be\
    \ missed.\n\nThis paper explores using a flexible alignment between statements\
    \ in pairs of programs to discover potential repairs. We extend an existing data-driven\
    \ automated repair approach that is open source, CLARA, with our flexible alignment\
    \ approach to deal with such real-world problems. We utilize the abstract syntax\
    \ tree parser in Python to build control flow graphs, and assign a similarity\
    \ to aligning a node in a correct program to a node in an incorrect program. In\
    \ our evaluation, we compare flexible alignment with respect to rigid program\
    \ comparisons. The former is capable of repairing more programs than rigid schemes,\
    \ which supports our hypothesis that rigid approaches might be missing valuable\
    \ code snippets for repairs that could be discovered by an approximate method\
    \ otherwise. Furthermore, our analysis reveals that flexible alignment also decreases\
    \ the changes required to fix more difficult problems. For shorter programs, less\
    \ number of changes are necessary than when using rigid schemes. As a result,\
    \ we claim that \"search, align, and repair\" approaches should rely on flexible\
    \ alignments to improve their repair capabilities. Our analysis comparing both\
    \ semantic and topological (labels and edges) similarities of our flexible alignment\
    \ approach indicates that using both types of similarities is beneficial compared\
    \ to only using labels.\n\nIn future work, we plan to integrate our flexible alignment\
    \ schemes with repairs based on variable traces or program sketches. We will use\
    \ other node semantic similarities rather than the Jaccard distance between multisets\
    \ of labels, such as graph representation of statements. We also plan to study\
    \ how large language models can be leveraged to improve our flexible alignment\
    \ approach.\n\n## References\n\n- <span id=\"page-44-0\"></span>[1] D. D. Garcia,\
    \ J. Campbell, J. DeNero, M. L. Dorf, S. Reges, CS10K teachers by 2017?: Try CS1K+\
    \ students now! coping with the largest CS1 courses in history, in: SIGCSE, 2016,\
    \ pp. 396–397.\n- [2] C. O. Rodriguez, MOOCs and the AI-Stanford like courses:\
    \ Two successful and distinct course formats for massive open online courses,\
    \ EU-RODL 15 (2012).\n- <span id=\"page-44-1\"></span>[3] K. Wang, R. Singh, Z.\
    \ Su, Search, align, and repair: data-driven feedback generation for introductory\
    \ programming exercises, in: PLDI, 2018, pp. 481–495.\n- <span id=\"page-45-0\"\
    ></span>[4] S. Zweben, B. Bizot, 2015 Taulbee Survey, Technical Report, Computing\
    \ Research Association, 2016.\n- <span id=\"page-45-1\"></span>[5] J. Huang, C.\
    \ Piech, A. Nguyen, L. J. Guibas, Syntactic and functional variability of a million\
    \ code submissions in a machine learning MOOC, in: AIED Workshops, 2013.\n- <span\
    \ id=\"page-45-2\"></span>[6] R. Y. Toledo, L. Mart´ınez-L´opez, A recommendation\
    \ approach for programming online judges supported by data preprocessing techniques,\
    \ AI 47 (2017) 277–290.\n- <span id=\"page-45-3\"></span>[7] R. Singh, S. Gulwani,\
    \ A. Solar-Lezama, Automated feedback generation for introductory programming\
    \ assignments, in: PLDI, 2013, pp. 15–26.\n- <span id=\"page-45-4\"></span>[8]\
    \ P. A. Kirschner, J. Sweller, R. E. Clark, Why minimal guidance during instruction\
    \ does not work: An analysis of the failure of constructivist, discovery, problem-based,\
    \ experiential, and inquiry-based teaching, Educational Psychologist 41 (2006)\
    \ 75–86.\n- <span id=\"page-45-5\"></span>[9] D. Coetzee, A. Fox, M. A. Hearst,\
    \ B. Hartmann, Should your MOOC forum use a reputation system?, in: CSCW, 2014,\
    \ pp. 1176–1187.\n- <span id=\"page-45-6\"></span>[10] S. Gulwani, I. Radicek,\
    \ F. Zuleger, Automated clustering and program repair for introductory programming\
    \ assignments, in: PLDI, 2018, pp. 465–480.\n- <span id=\"page-45-10\"></span>[11]\
    \ C. Piech, J. Huang, A. Nguyen, M. Phulsuksombati, M. Sahami, L. J. Guibas, Learning\
    \ program embeddings to propagate feedback on student code, in: ICML, 2015, pp.\
    \ 1093–1102.\n- <span id=\"page-45-9\"></span>[12] Y. Pu, K. Narasimhan, A. Solar-Lezama,\
    \ R. Barzilay, sk p: A neural program corrector for MOOCs, in: SPLASH, 2016, pp.\
    \ 39–40.\n- <span id=\"page-45-7\"></span>[13] R. Rolim, G. Soares, L. D'Antoni,\
    \ O. Polozov, S. Gulwani, R. Gheyi, R. Suzuki, B. Hartmann, Learning syntactic\
    \ program transformations from examples, in: ICSE, 2017, pp. 404–415.\n- <span\
    \ id=\"page-45-8\"></span>[14] M. Monperrus, Automatic software repair: A bibliography,\
    \ CSUR 51 (2018) 17:1–17:24.\n- <span id=\"page-46-0\"></span>[15] V. J. Marin,\
    \ M. R. Contractor, C. R. Rivero, Flexible program alignment to deliver data-driven\
    \ feedback to novice programmers, in: ITS, volume 12677, 2021, pp. 247–258.\n\
    - <span id=\"page-46-1\"></span>[16] M. R. Contractor, C. R. Rivero, Improving\
    \ program matching to automatically repair introductory programs, in: ITS, 2022,\
    \ pp. 323–335.\n- <span id=\"page-46-2\"></span>[17] R. Harper, Practical Foundations\
    \ for Programming Languages (2nd. Ed.), Cambridge University Press, 2016.\n- <span\
    \ id=\"page-46-3\"></span>[18] Y. Hu, U. Z. Ahmed, S. Mechtaev, B. Leong, A. Roychoudhury,\
    \ Refactoring based program repair applied to programming assignments, in: ASE,\
    \ 2019, pp. 388–398.\n- <span id=\"page-46-4\"></span>[19] L. da F. Costa, Further\
    \ generalizations of the jaccard index, CoRR abs/2110.09619 (2021).\n- <span id=\"\
    page-46-5\"></span>[20] M. Mirzayanov, Codeforces: Problem Difficulties, 2018.\
    \ URL: [https:](https://codeforces.com/blog/entry/62865?#comment-468443) [//codeforces.com/blog/entry/62865?#comment-468443](https://codeforces.com/blog/entry/62865?#comment-468443).\n\
    - <span id=\"page-46-6\"></span>[21] M. Chen, J. Tworek, H. Jun, Q. Yuan, H. P.\
    \ de Oliveira Pinto, J. Kaplan, H. Edwards, Y. Burda, N. Joseph, G. Brockman,\
    \ A. Ray, R. Puri, G. Krueger, M. Petrov, H. Khlaaf, G. Sastry, P. Mishkin, B.\
    \ Chan, S. Gray, N. Ryder, M. Pavlov, A. Power, L. Kaiser, M. Bavarian, C. Winter,\
    \ P. Tillet, F. P. Such, D. Cummings, M. Plappert, F. Chantzis, E. Barnes, A.\
    \ Herbert-Voss, W. H. Guss, A. Nichol, A. Paino, N. Tezak, J. Tang, I. Babuschkin,\
    \ S. Balaji, S. Jain, W. Saunders, C. Hesse, A. N. Carr, J. Leike, J. Achiam,\
    \ V. Misra, E. Morikawa, A. Radford, M. Knight, M. Brundage, M. Murati, K. Mayer,\
    \ P. Welinder, B. Mc-Grew, D. Amodei, S. McCandlish, I. Sutskever, W. Zaremba,\
    \ Evaluating large language models trained on code, CoRR (2021).\n- <span id=\"\
    page-46-7\"></span>[22] A. Head, E. Glassman, G. Soares, R. Suzuki, L. Figueredo,\
    \ L. D'Antoni, B. Hartmann, Writing reusable code feedback at scale with mixedinitiative\
    \ program synthesis, in: L@S, 2017, pp. 89–98.\n- <span id=\"page-46-8\"></span>[23]\
    \ A. Solar-Lezama, Program sketching, STTT 15 (2013) 475–495.\n- <span id=\"page-46-9\"\
    ></span>[24] L. D'Antoni, R. Samanta, R. Singh, Qlose: Program repair with quantitative\
    \ objectives, in: CAV, 2016, pp. 383–401.\n- [25] J. Hua, M. Zhang, K. Wang, S.\
    \ Khurshid, Towards practical program repair with on-demand candidate generation,\
    \ in: ICSE, 2018, pp. 12–23.\n- <span id=\"page-47-0\"></span>[26] X. Liu, S.\
    \ Wang, P. Wang, D. Wu, Automatic grading of programming assignments: an approach\
    \ based on formal semantics, in: ICSE, 2019, pp. 126–137.\n- <span id=\"page-47-1\"\
    ></span>[27] A. Nguyen, C. Piech, J. Huang, L. J. Guibas, Codewebs: Scalable homework\
    \ search for massive open online programming courses, in: WWW, 2014, pp. 491–502.\n\
    - <span id=\"page-47-2\"></span>[28] V. J. Marin, T. Pereira, S. Sridharan, C.\
    \ R. Rivero, Automated personalized feedback in introductory Java programming\
    \ MOOCs, in: ICDE, 2017, pp. 1259–1270.\n- <span id=\"page-47-3\"></span>[29]\
    \ U. Z. Ahmed, Z. Fan, J. Yi, O. I. Al-Bataineh, A. Roychoudhury, Verifix: Verified\
    \ repair of programming assignments, ACM Trans. Softw. Eng. Methodol. 31 (2022)\
    \ 74:1–74:31.\n- <span id=\"page-47-4\"></span>[30] B. Edmison, S. H. Edwards,\
    \ Turn up the heat!: using heat maps to visualize suspicious code to help students\
    \ successfully complete programming problems faster, in: ICSE-SEET, 2020, pp.\
    \ 34–44.\n- <span id=\"page-47-5\"></span>[31] T. Nguyen, T. Le-Cong, D. Luong,\
    \ V. Duong, X. D. Le, D. Lo, Q. Huynh, FFL: fine-grained fault localization for\
    \ student programs via syntactic and semantic reasoning, in: ICSME, 2022, pp.\
    \ 151–162.\n- <span id=\"page-47-6\"></span>[32] Z. Li, S. Wu, Y. Liu, J. Shen,\
    \ Y. Wu, Z. Zhang, X. Chen, VsusFL: Variable-suspiciousness-based fault localization\
    \ for novice programs, J. Syst. Softw. 205 (2023) 111822.\n- <span id=\"page-47-7\"\
    ></span>[33] Y. Hu, U. Z. Ahmed, S. Mechtaev, B. Leong, A. Roychoudhury, Refactoring\
    \ based program repair applied to programming assignments, in: ASE, 2019, pp.\
    \ 388–398.\n- <span id=\"page-47-8\"></span>[34] C. Le Goues, T. Nguyen, S. Forrest,\
    \ W. Weimer, GenProg: A generic method for automatic software repair, TSE 38 (2012)\
    \ 54–72.\n- <span id=\"page-47-9\"></span>[35] J. Yi, U. Z. Ahmed, A. Karkare,\
    \ S. H. Tan, A. Roychoudhury, A feasibility study of using automated program repair\
    \ for introductory programming assignments, in: ESEC/FSE, 2017, pp. 740–751.\n\
    - <span id=\"page-48-0\"></span>[36] F. Long, M. Rinard, Automatic patch generation\
    \ by learning correct code, in: POPL, 2016, pp. 298–312.\n- [37] S. Sidiroglou-Douskos,\
    \ E. Lahtinen, F. Long, M. Rinard, Automatic error elimination by horizontal code\
    \ transfer across multiple applications, in: PLDI, 2015, pp. 43–54.\n- <span id=\"\
    page-48-1\"></span>[38] Q. Xin, S. P. Reiss, Leveraging syntax-related code for\
    \ automated program repair, in: ASE, 2017, pp. 660–670.\n- <span id=\"page-48-2\"\
    ></span>[39] C. K. Roy, J. R. Cordy, R. Koschke, Comparison and evaluation of\
    \ code clone detection techniques and tools: A qualitative approach, SCP 74 (2009)\
    \ 470–495.\n- <span id=\"page-48-3\"></span>[40] C. Liu, C. Chen, J. Han, P. S.\
    \ Yu, GPLAG: Detection of software plagiarism by program dependence graph analysis,\
    \ in: KDD, 2006, pp. 872–881.\n- [41] J. Li, M. D. Ernst, CBCD: Cloned buggy code\
    \ detector, in: ICSE, 2012, pp. 310–320.\n- [42] B. Sun, G. Shu, A. Podgurski,\
    \ S. Li, S. Zhang, J. Yang, Propagating bug fixes with fast subgraph matching,\
    \ in: ISSRE, 2010, pp. 21–30.\n- <span id=\"page-48-4\"></span>[43] S. Xu, Y.\
    \ S. Chee, Transformation-based diagnosis of student programs for programming\
    \ tutoring systems, TSE 29 (2003) 360–384.\n- <span id=\"page-48-5\"></span>[44]\
    \ W. Li, H. Saidi, H. Sanchez, M. Sch¨af, P. Schweitzer, Detecting similar programs\
    \ via the Weisfeiler-Leman graph kernel, in: ICSR, 2016, pp. 315–330."
- title: Automated Test Production -- Systematic Literature Mapping
  abstract: 'The broader goal of this research, on the one hand, is to obtain the
    State of

    the Art in Automated Test Production (ATP), to find the open questions and

    related problems and to track the progress of researchers in the field, and on

    the other hand is to list and categorize the methods, techniques and tools of

    ATP that meet the needs of practitioners who produce computerized business

    applications for internal use in their corporations - eventually it can be

    extended to the needs of practitioners in companies that specialize in

    producing computer applications for generic use.'
  url: http://arxiv.org/abs/2401.01430v1
  keywords: ''
  document: "# Automated Test Production Systematic Literature Mapping\n\nGomes, J.M.\
    \ <sup>1</sup> and Dias, L.A.V. 1\n\n1 Instituto Tecnol´ogico de Aeron´autica\
    \ - ITA\n\nJanuary 4, 2024\n\n# 1 Objectives\n\nThe broader goal of this research,\
    \ on the one hand, is to obtain the State of the Art in ATP (Automated Test Production),\
    \ to find the open questions and related problems and to track the progress of\
    \ researchers in the field, and on the other hand is to list and categorize the\
    \ methods, techniques and tools of ATP that meet the needs of practitioners who\
    \ produce computerized business applications for internal use in their corporations\
    \ - eventually it can be extended to the needs of practitioners in companies that\
    \ specialize in producing computer applications for generic use.\n\n# 2 Literature\
    \ Systematic Mapping\n\n### 2.1 Planning\n\nIn order to obtain an overview of\
    \ the research on ATP, an SLM (Systematic Literature Mapping) is conducted here\
    \ so that from this study we can perform an SLR (Systematic Literature Review)\
    \ in order to investigate it further. We apply the method proposed by Petersen\
    \ et al. and which we present in the Figure [1](#page-1-0) to conduct this SLM[\\\
    [1\\]](#page-16-0).\n\nWe sought with this study to identify the amount and types\
    \ of research and its results under the topic ATP. As important secondary results,\
    \ we also sought to identify the discussion forums on the subject.\n\nThe question\
    \ QP1 is a filter for narrowing the scope of the research. The question QP2 aims\
    \ to identify the main discussion forums where researchers related to ATP publish\
    \ their work or meet to present advances and update their knowledge in the area.\
    \ In the question QP3 we propose to classify the search results and identify the\
    \ main types of studies related to ATP and categorize their contributions.\n\n\
    <span id=\"page-1-0\"></span>![](_page_1_Figure_0.jpeg)\n\nFigure 1: Steps do\
    \ execute the research for an SLM (adapted from [\\[1\\]](#page-16-0))\n\nThe\
    \ search term was generated from keywords and their synonyms as presented in the\
    \ Table [2.](#page-1-1) In Keele et al. it is pointed out that Petticrew and Roberts\
    \ suggest the use of PICOC (Population, Intervention, Comparison, Outcome, Context)\
    \ to formulate the search term in scientific publication databases [\\[2,](#page-16-1)\
    \ [3\\]](#page-16-2).\n\nTwo of the main considerations in designing the search\
    \ protocol are that, first, we are neglecting \"comparison\", and are therefore\
    \ using the PIOC (Population, Intervention, Outcome, Context) variation, because\
    \ it is not part of our goal to compare different solutions to the same problem,\
    \ and second, we avoid considering specific results, i.e., studies that are not\
    \ aimed at the production of general-purpose computer applications, or use within\
    \ an enterprise and business world context.\n\n<span id=\"page-1-2\"></span>\n\
    \n| #   | Question                                         |\n|-----|--------------------------------------------------|\n\
    | QP1 | Is the study?                                    |\n|     | Recently published\
    \ (within the last five years)? |\n| QP2 | Which \"journals\" include studies\
    \ in \"ATP?        |\n|     | Or Annals of Congresses, Events, Authors, etc. \
    \  |\n| QP3 | What kinds of studies are published in ATP?      |\n|     | Categorized\
    \ as listed in Figure 5                |\n\n<span id=\"page-1-1\"></span>\n\n\
    | Term       | Synonyms                                        | Related to  \
    \ |\n|------------|-------------------------------------------------|--------------|\n\
    | software   | program                                         | Population  \
    \ |\n| test       | check<br>checking<br>validation<br>verification | Population\
    \   |\n| generation | creation<br>inception<br>production             | Intervention\
    \ |\n| method     | methodology<br>model<br>process<br>standard     | Outcome\
    \      |\n| tool       | environment<br>framework<br>software<br>suite   | Outcome\
    \      |\n\nTable 1: Research questions for SLM\n\nTable 2: Search terms for the\
    \ SLM\n\nThe Context is an extended view of the population, where we say whether\
    \ the study is conducted in Academy or Industry, in which Industry segment [\\\
    [4\\]](#page-16-3). In our case we were indifferent with regard to this aspect.\n\
    \nFinally we applied the search criteria of the Section [2.1](#page-2-0) to the\
    \ scientific publication databases listed in the Table [3.](#page-2-1)\n\n```\n\
    (\"software\" OR \"program\" OR \"test\" OR \"check\" OR \"checking\" OR \"\n\
    \   ,→ validation\" OR \"verification\") AND (\"generation\" OR \"\n   ,→ creation\"\
    \ OR \"inception\" OR \"production\") AND (\"method\" OR\n   ,→ \"methodology\"\
    \ OR \"model\" OR \"process\" OR \"standard\" OR \"\n   ,→ tool\" OR \"environment\"\
    \ OR \"framework\" OR \"software\" OR \"\n   ,→ suite\")\n```\nListing 1: Search\
    \ criteria for the SLM\n\n### 2.2 Conduction\n\n<span id=\"page-2-1\"></span>The\
    \ scientific publication sources, listed in Table [3,](#page-2-1) are, according\
    \ to Brereton et al., the most relevant for Software Engineering [\\[5\\]](#page-16-4).\n\
    \n| Name                |  |\n|---------------------|--|\n| IEEE Xplore      \
    \   |  |\n| ACM Digital Library |  |\n| Google Scholar      |  |\n| CiteSeerX\
    \           |  |\n| Inspec              |  |\n| ScienceDirect       |  |\n| EI\
    \ Compendex        |  |\n| Springer Link       |  |\n\nTable 3: Scientific publishing\
    \ databases\n\nThe choice of primary research sources was based on simple and\
    \ practical premises:\n\n- use of structured search terms (using \"AND\", \"OR\"\
    , \"NOT\" and parentheses);\n- filters to search for more recent documents; and\n\
    - filters to list relevant documents in the desired area of expertise.\n\nBased\
    \ on these criteria, the ScienceDirect and ISI Web of Science publication bases\
    \ were discarded for not presenting satisfactory results for this research [1](#page-2-2)\
    \ and both Google Scholar and CiteSeerX by not providing additional\n\n<span id=\"\
    page-2-2\"></span><sup>1</sup>The ScienceDirect of Elsevier for example restricts\
    \ the search to only 8 terms, and in one exercise returned only 11 studies. Of\
    \ these only one could be read in full and was still not relevant to the present\
    \ study.\n\nfilters by area or subarea of knowledge and finally EI Compendex and\
    \ Inspec also did not allow access. As an alternative we used the Periodical Portal\
    \ of CAPES (Coordena¸c˜ao de Aperfei¸coamento de Pessoal de N´ıvel Superior do\
    \ Brasil) [2](#page-3-0) with the exception that the search criteria had to be\
    \ adapted because of restrictions in the platform as can be seen in the Section\
    \ [2.2](#page-3-1) (as in the other platforms, additional filters were applied\
    \ - see Table [7\\)](#page-4-0).\n\n```\n(software OR program OR test OR check\
    \ OR checking OR\n   ,→ validation OR verification) AND\n(generation OR creation\
    \ OR inception OR production)\n```\nListing 2: Search criteria for the SLM used\
    \ at CAPES\n\n<span id=\"page-3-2\"></span>Then, within each publication base,\
    \ filters were applied to improve the quality of the results obtained. In general,\
    \ we selected only recent documents (2015 to 2020 - up to the date of the survey:\
    \ April 2020). The particular criteria for each base are listed in the Tables\
    \ [4](#page-3-2) to [7.](#page-4-0)\n\n| Filter            | Value           \
    \                                                                            \
    \                                                                            \
    \                              |\n|-------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Publication title | IEEE Access<br>IEEE Systems Journal<br>IEEE Latin America<br>Transactions\
    \                                                                            \
    \                                                 |\n|                   | IEEE\
    \ Transactions on<br>Software Engineering                                    \
    \                                                                            \
    \                                          |\n| Indexation terms  | learning (artificial<br>intelligence)<br>optimisation<br>neural\
    \ nets<br>cloud computing<br>genetic algorithms<br>probability<br>program testing<br>search\
    \ problems<br>Internet<br>resource allocation |\n\nTable 4: IEEE Xplore filters\n\
    \n| Filter                   | Value                   |\n|--------------------------|-------------------------|\n\
    | ACM Full-Text Collection | All journals collection |\n| Publication Title  \
    \      | Search title only       |\n\nTable 5: ACM Digital Library filters\n\n\
    <span id=\"page-3-0\"></span><sup>2</sup>See <http://www.periodicos.capes.gov.br>.\n\
    \n| Filter        | Value                                                    \
    \                                                                            \
    \                                                                            \
    \                                                        |\n|---------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Content Type  | Article<br>Chapter<br>Conference Paper                     \
    \                                                                            \
    \                                                                            \
    \                                                      |\n| Discipline    | Computer\
    \ Science                                                                    \
    \                                                                            \
    \                                                                            \
    \                             |\n| Subdiscipline | Computer Science,<br>general<br>Computer\
    \ Systems<br>Organizations and<br>Communications<br>Networks<br>Data Structures\
    \ and<br>Information Theory<br>Information Systems<br>and Communication<br>Service<br>Software\
    \ Engineer<br>ing/Programming and<br>Operating Systems |\n\n<span id=\"page-4-0\"\
    ></span>\n\n| Filter                          | Value                        \
    \                        |\n|---------------------------------|------------------------------------------------------|\n\
    | Type of<br>source               | Studies                                  \
    \            |\n| Language<br>Refinement<br>Topic | English<br>Pair revised journals<br>Computer\
    \ Science |\n\n| Table 7: \"Peri´odicos da CAPES\" filters |\n|-----------------------------------------|\n\
    |-----------------------------------------|\n\n<span id=\"page-4-1\"></span>After\
    \ running the search using the Section [2.1](#page-2-0) criteria and applying\
    \ the filters listed in the Tables [4](#page-3-2) to [7](#page-4-0) we obtained\
    \ the results listed in the Table [8](#page-4-1) (in number of documents).\n\n\
    | Name                 | Qty. | %     |\n|----------------------|------|-------|\n\
    | IEEE Xplore          | 715  | 33.10 |\n| ACM Digital Library  | 308  | 14.26\
    \ |\n| Springer Link        | 709  | 32.82 |\n| Peri´odicos da CAPES | 428  |\
    \ 19.81 |\n| TOTAL                | 2160 |       |\n\nTable 8: Total documents\
    \ retrieved from each publishing databases for the SLM\n\nThe selection of documents\
    \ was based on Inclusion and Exclusion criteria defined iteratively during the\
    \ reading of the documents found and served to determine the suitability of each\
    \ one to the objectives of this work. The Inclusion Criteria are those presented\
    \ in the Table [9,](#page-5-0) and in the Table [10](#page-5-1) we have the Exclusion\
    \ Criteria.\n\n<span id=\"page-5-0\"></span>\n\n| #   | Description          \
    \                                                                        |\n|-----|----------------------------------------------------------------------------------------------|\n\
    | CI1 | Document types:<br>books (book excerpts), technical re<br>ports;     \
    \                        |\n| CI2 | If several have reported the same study, only\
    \ the most<br>recent one will be considered; and |\n| CI3 | From the abstract\
    \ the researcher can deduce that the ar<br>ticle is about ATP.               |\n\
    \nTable 9: Inclusion criteria for the SLM\n\n<span id=\"page-5-1\"></span>\n\n\
    | #   | Description                                                |\n|-----|------------------------------------------------------------|\n\
    | CE1 | The article strays from the main topic of this study which |\n|     |\
    \ deals with ATP for general applications;                   |\n| CE2 | The topic\
    \ ATP is not part of the article's contribution or |\n|     | the topic is only\
    \ mentioned; and                           |\n| CE3 | No empirical findings or\
    \ current available literature are  |\n|     | reported.                     \
    \                             |\n\nTable 10: Exclusion criteria for the SLM\n\n\
    Given the large number of studies (see Table [8\\)](#page-4-1) found we organized\
    \ our work into iterative steps:\n\n- 1. Reading the summary and conclusion; and\n\
    - 2. Selection and classification by reading the entire document.\n\nA pre-selection\
    \ was based only on the title of the document found because, as already noted\
    \ by Keele et al., searches of electronic databases bring a very large number\
    \ of irrelevant results. During the review, other studies were rejected as being\
    \ outside the scope of this study [\\[2\\]](#page-16-1).\n\n| Name           \
    \      | Qty. | %     |\n|----------------------|------|-------|\n| IEEE Xplore\
    \          | 33   | 14.73 |\n| ACM Digital Library  | 66   | 29.46 |\n| Springer\
    \ Link        | 11   | 4.91  |\n| Peri´odicos da CAPES | 114  | 50.89 |\n| Sub-total\
    \            | 224  |       |\n| Duplicate studies    | 7    | 4.24  |\n| Rejected\
    \ studies     | 52   | 31.52 |\n| TOTAL                | 165  |       |\n|   \
    \                   |      |       |\n\nTable 11: Primary studies selction result\
    \ for the SLM\n\n<span id=\"page-6-0\"></span>\n\n| #     | Description      \
    \                                  |\n|-------|----------------------------------------------------|\n\
    | CE1.1 | Applied to hardware;                               |\n| CE1.2 | Applied\
    \ to embedded software;                      |\n| CE1.3 | Language-specific; \
    \                                |\n| CE1.4 | Does not deal with tests for general\
    \ applications; |\n| CE1.5 | Not intended for general applications;          \
    \   |\n| CE2.1 | Does not deal with test generation;                |\n| CE3.1\
    \ | No contribution to this study;                     |\n| CE3.2 | This is not\
    \ scientific research; and               |\n| CE3.3 | Survey with old data.  \
    \                            |\n\nTable 12: Refining exclusion criteria for the\
    \ SLM\n\n<span id=\"page-6-1\"></span>The studies were rejected in the second\
    \ selection based on a refinement of the exclusion criteria listed in the Table\
    \ [10](#page-5-1) and that we list in the Table [12.](#page-6-0) Our motivation\
    \ behind these criteria, as explained in the \"Objectives\", is to find solutions\
    \ that meet the needs of professionals who produce computerized business applications\
    \ for internal use in their corporations - eventually extending to the needs of\
    \ professionals in companies specializing in the production of generic computer\
    \ applications.\n\n![](_page_6_Figure_3.jpeg)\n\nFigure 2: Classification scheme\
    \ (adapted from [\\[1\\]](#page-16-0))\n\nFor documents classification we adopted\
    \ the Petersen et al. as can be seen in the Figure [2,](#page-6-1) and in the\
    \ same way we adopted facets analyzing the abstracts of the studies found. We\
    \ started by analyzing two main facets to classify the documents. The research\
    \ type facet was based on the classification proposed by Wieringa et al. and summarized\
    \ in the Table [13.](#page-7-0) The type of contribution is based on the interpretation\
    \ of the abstracts and listed in the Table [14](#page-8-0) [\\[1,](#page-16-0)\
    \ [6\\]](#page-16-5).\n\n<span id=\"page-7-0\"></span>\n\n| Category      | Description\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                             |\n|---------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Validation    | The techniques investigated are new and have not<br>been implemented\
    \ in practice. Techniques used<br>are from experimental examples and done in the<br>laboratory.\
    \                                                                            \
    \                                              |\n| Avaliation    | The technique\
    \ was implemented in practice and<br>the evaluation was conducted.<br>Demonstrated<br>how\
    \ the technique was implemented in practice<br>and what the consequences were\
    \ in terms of ben<br>efits and disadvantages. Also includes identifica<br>tion\
    \ of problems in the industry. |\n| Proposal      | A solution to a problem has\
    \ been proposed, ei<br>ther new or a significant extension of an existing<br>technique.\
    \ The potential benefits and applicabil<br>ity of the solution is shown by a short\
    \ example or<br>a good line of argument.                                     \
    \              |\n| Philosophical | These studies outlined a new approach to pre<br>existing\
    \ knowledge and structured the field in the<br>form of a taxonomy or conceptual\
    \ work.                                                                      \
    \                                                                          |\n\
    | Opinion       | These studies express someone's personal opinion<br>about a\
    \ particular technique, whether it is good<br>or not, or how things are done.<br>They\
    \ are not<br>supported by related work or research methods.                  \
    \                                                                 |\n| Practice\
    \      | They explain in what and how something was<br>done in practice. It has\
    \ to be the author's per<br>sonal experience.                                \
    \                                                                            \
    \                                                              |\n\nTable 13:\
    \ Researches types\n\n<span id=\"page-8-0\"></span>\n\n| Category     | Description\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \   |\n|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Metric       | A system or standard of measures or measure<br>ments taken using\
    \ an existing standard.                                                      \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                          |\n| Tool         | A device or implementation, used\
    \ to perform a<br>certain function.                                          \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                          |\n| Model        |\
    \ A comprehensive and systematic approach that<br>includes theoretical principles,\
    \ benefits and draw<br>backs, objectives, methodological guidelines and<br>specifications,\
    \ and the characteristic use of cer<br>tain sets of methods and techniques.  \
    \                                                                            \
    \                                                                         |\n\
    | Method       | No particular theoretical orientation is inferred<br>in a method.\
    \ Researchers impose their own par<br>ticular theoretical beliefs on an experiment\
    \ when<br>they design and implement it by applying one or<br>more techniques.\
    \                                                                            \
    \                                                                            \
    \                    |\n| Technique    | A single operation or interaction in\
    \ which a re<br>searcher uses one or more procedures to elicit an<br>immediate\
    \ reaction from the object of study or to<br>shape the experiment and obtain results.\
    \                                                                            \
    \                                                                            \
    \                                             |\n| Procedure    | An organized\
    \ sequence of operations and interac<br>tions that a researcher uses to conduct\
    \ an exper<br>iment.                                                         \
    \                                                                            \
    \                                                                            \
    \                                                                            |\n\
    | Intervention | Purposefully interferes with or mitigates various<br>aspects\
    \ of the object of study and that affect the<br>outcome by applying procedure,\
    \ technique. The<br>elements acting on the industry during a partic<br>ular intervention\
    \ are most often computer appli<br>cations, the researcher, or both.         \
    \                                                                            \
    \                  |\n| Approach     | A broad way of addressing an industry concern\
    \ or<br>problem. A specific methods is not implied, but<br>a specific set of techniques\
    \ will likely come into<br>play when trying to intervene in the industry and<br>the\
    \ problem that is the subject of the research.<br>The procedures to be used will\
    \ be determined by<br>the delimitations of the methodological variant in<br>which\
    \ we design the study. |\n| Strategy     | An action plan designed to achieve\
    \ an overall<br>goal.                                                        \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                        |\n\nTable 14: Contributions\
    \ types\n\n### 2.3 Analysis of Results\n\n<span id=\"page-8-1\"></span>Based on\
    \ the criteria listed in the Table [10](#page-5-1) and expanded in the Table [12](#page-6-0)\
    \ we selected 165 and rejected 52 documents categorized according to the Table\
    \ [15.](#page-8-1)\n\n| Motive                                            | Qty.\
    \ |\n|---------------------------------------------------|------|\n| Applied to\
    \ hardware                               | 9    |\n| Applied to embedded software\
    \                      | 2    |\n| Language-specific                         \
    \        | 2    |\n| No contribution to this study                     | 5   \
    \ |\n| This is not scientific research                   | 1    |\n| Does not\
    \ deal with test generation                | 22   |\n| Does not deal with tests\
    \ for general applications | 3    |\n| Not intended for general applications \
    \            | 7    |\n| Survey with old data                              | 1\
    \    |\n| TOTAL                                             | 52   |\n\nTable\
    \ 15: Rejection motives\n\nThe research questions listed in Table [1](#page-1-2)\
    \ were applied to the selected studies and we obtained the results that we list\
    \ below.\n\n#### QP1 - Is the study current?\n\n<span id=\"page-9-1\"></span>Recently\
    \ published (within the last five years)?\n\n| Tipo  | criteria |\n|-------|----------|\n\
    | 2015  | 34       |\n| 2016  | 32       |\n| 2017  | 20       |\n| 2018  | 26\
    \       |\n| 2019  | 38       |\n| 2020  | 15       |\n| TOTAL | 165      |\n\n\
    Table 16: Publications / Year\n\n| Tipo        | Qty. | %     |\n|-------------|------|-------|\n\
    | Books       | 3    | 1.82  |\n| Conferences | 51   | 30.91 |\n| Journals   \
    \ | 111  | 67.27 |\n| TOTAL       | 165  |       |\n\nTable 17: Studies / Channel\n\
    \n<span id=\"page-9-0\"></span>We can observe a relative constancy of studies\
    \ published on the topic in recent years, indicating that the topic is of interest\
    \ and there is potential progress to be explored.\n\n#### QP2 - Which \"journals\"\
    \ include studies in \"ATP\"?\n\nOr Annals of Congresses, Events, Authors, etc.\n\
    \nWe classified how the studies were published (see Table [17\\)](#page-9-0) and\
    \ then sought to identify where they were published to get an idea of the best\
    \ Journals and Events where to look for information on the topic. Unfortunately,\
    \ as can be seen in the Table [18](#page-10-0) there is no specific event for\
    \ this topic. In the Figure [3](#page-10-1) and Table [19](#page-11-0) we obtained\
    \ a more satisfactory result in identifying the most relevant publications for\
    \ our research.\n\n<span id=\"page-10-1\"></span>![](_page_10_Figure_0.jpeg)\n\
    \nFigure 3: Participation of ATP Studies in Congresses\n\n<span id=\"page-10-0\"\
    ></span>\n\n| Conference                                                     \
    \                                                         | Qty. |\n|-------------------------------------------------------------------------------------------------------------------------|------|\n\
    | The Search-Based Software Testing (SBST) Workshop (co-located<br>in ICSE)  \
    \                                             | 7    |\n| ACM ESEC/FSE Joint European\
    \ Software Engineering Conference<br>and Symposium on the Foundations of Software\
    \ Engineering | 6    |\n| Internation Conference on Software Engineering     \
    \                                                                     | 6    |\n\
    | IEEE/ACM International Conference on Automated Software En<br>gineering    \
    \                                             | 5    |\n| ACM ICSCA Software and\
    \ Computer Applications                                                      \
    \                      | 3    |\n| ACM SIGSOFT ISSTA International Symposium on\
    \ Software<br>Testing and Analysis                                           |\
    \ 3    |\n| ACM/IEEE International Conference on Automation of Software<br>Test\
    \                                                     | 2    |\n| ACM ESEC/FSE\
    \ Joint European Software Engineering Conference                             \
    \                                | 2    |\n| and Symposium on the Foundations\
    \ of Software Engineering                                                    \
    \            |      |\n| ACM SBES Brazilian Symposium on Software Engineering\
    \                                                                    | 2    |\n\
    | Symposium on Information and Communication Technology                      \
    \                                             | 2    |\n\nTable 18: Major conferences\
    \ addressing ATP\n\nIn the graph from Figure [3](#page-10-1) we have a look at\
    \ the interest in the topic over the course of the surveyed period in the main\
    \ congresses listed.\n\nIn Journals we identify in the Table [19](#page-11-0)\
    \ where the topic is most frequently addressed.\n\n![](_page_11_Figure_0.jpeg)\n\
    \nParticipation of ATP Studies in Publications\n\n<span id=\"page-11-0\"></span>Figure\
    \ 4: Participation of ATP Studies in Publications\n\n| Publication           \
    \                                         | Qty. |\n|----------------------------------------------------------------|------|\n\
    | IEEE Trans. Software Eng.                                      | 20   |\n| IEEE\
    \ Access                                                    | 9    |\n| The Journal\
    \ of Systems & Software                              | 6    |\n| Science of Computer\
    \ Programming                                | 5    |\n| IET Software        \
    \                                           | 4    |\n| International Journal\
    \ of Software Engineering and Knowledge En | 4    |\n| gineering             \
    \                                         |      |\n| Journal of King Saud University\
    \ - Computer and Information Sci | 4    |\n| ences                           \
    \                               |      |\n| ACM Trans. Softw. Eng. Methodol. \
    \                              | 3    |\n| Applied Soft Computing            \
    \                             | 3    |\n| Autom Softw Eng                    \
    \                            | 3    |\n| Empir Software Eng                  \
    \                           | 3    |\n| J Softw Eng Res Dev                  \
    \                          | 3    |\n| Software Testing, Verification and Reliability\
    \                 | 3    |\n| The Computer Journal                           \
    \                | 3    |\n\nTable 19: Major Publications Addressing ATP\n\nOnce\
    \ again we present in a graph at Figure [3](#page-10-1) a view of the interest\
    \ in the topic over the surveyed period in the main Journals listed.\n\nWe also\
    \ sought to identify the main authors on the subject, regardless of the medium\
    \ of publication. In the Table [20](#page-12-1) we list those who presented the\
    \ highest production within this research and their H-Index [\\[7\\]](#page-16-6).\n\
    \n<span id=\"page-12-1\"></span>\n\n| Author                    | Institution\
    \                                | Qty. | h-idx3 |\n|---------------------------|--------------------------------------------|------|--------|\n\
    | Harman, Mark              | University College Lon<br>don              | 3 \
    \   | 68     |\n| Arcuri, Andrea            | Kristiania<br>University<br>College\
    \        | 9    | 39     |\n| Fraser, Gordon            | University of Passau\
    \                       | 8    | 39     |\n| McMinn, Phil              | University\
    \ of Sheffield                    | 4    | 27     |\n| Zamli,<br>Kamal<br>Z. \
    \    | University<br>Malaysia<br>Pahang           | 8    | 23     |\n| Panichella,\
    \ An<br>nibale  | Delft<br>University<br>of<br>Technology    | 3    | 27     |\n\
    | Gargantini,<br>Angelo     | University of Bergamo                      | 3 \
    \   | 18     |\n| Vergilio,<br>Silvia<br>R. | Federal<br>University<br>of<br>Paran´a\
    \     | 4    | 17     |\n| Riccobene,<br>Elvinia     | Universit`a di Milano \
    \                     | 3    | 16     |\n| Arcaini, Paolo            | National<br>Institute<br>of<br>Informatics\
    \ | 3    | 15     |\n| Staats, Matt4             | University<br>of<br>Luxem<br>bourg\
    \         | 3    | 15     |\n| Gay, Gregory              | Chalmers, University\
    \ of<br>Gothenburg      | 6    | 12     |\n| Rojas,<br>Jos´e<br>Miguel | University\
    \ of Leicester                    | 3    | 13     |\n\nTable 20: Main Authors\
    \ in ATP of this Study\n\nThe Table [20](#page-12-1) seeks to order the authors\
    \ by weighting their H-Index and the number of publications found within the search.\n\
    \n### QP3 - What kinds of studies are published in ATP?\n\nCategorized as listed\
    \ in Figure [5](#page-12-0)\n\nWe first build on the classification proposed by\
    \ Wieringa et al. and quantify the Facet of Study Types in Figure [5](#page-12-0)\
    \ [\\[6\\]](#page-16-5). This categorization will be useful in performing a SLR\
    \ as we qualify the studies with the desired bias for this research.\n\n<span\
    \ id=\"page-12-0\"></span>![](_page_12_Figure_6.jpeg)\n\nFigure 5: Types of Artifacts\
    \ Generated\n\n<span id=\"page-12-3\"></span><span id=\"page-12-2\"></span><sup>3</sup>Data\
    \ obtained via Google Scholar and calculated since 2015.\n\n<sup>4</sup>See Scopus\
    \ [https://www.scopus.com/results/authorNamesList.uri?sort=count-f&](https://www.scopus.com/results/authorNamesList.uri?sort=count-f&src=al&affilName=University+of+Luxembourg&s=AUTHLASTNAME%28Staats%29+AND+AUTHFIRST%28Matt%29+AND+AFFIL%28University+of+Luxembourg%29&st1=Staats&st2=Matt)\
    \ [src=al&affilName=University+of+Luxembourg&s=AUTHLASTNAME%28Staats%29+AND+](https://www.scopus.com/results/authorNamesList.uri?sort=count-f&src=al&affilName=University+of+Luxembourg&s=AUTHLASTNAME%28Staats%29+AND+AUTHFIRST%28Matt%29+AND+AFFIL%28University+of+Luxembourg%29&st1=Staats&st2=Matt)\n\
    \n[AUTHFIRST%28Matt%29+AND+AFFIL%28University+of+Luxembourg%29&st1=Staats&st2=Matt](https://www.scopus.com/results/authorNamesList.uri?sort=count-f&src=al&affilName=University+of+Luxembourg&s=AUTHLASTNAME%28Staats%29+AND+AUTHFIRST%28Matt%29+AND+AFFIL%28University+of+Luxembourg%29&st1=Staats&st2=Matt).\n\
    \n<span id=\"page-13-0\"></span>![](_page_13_Figure_0.jpeg)\n\nFigure 6: Types\
    \ of Test Generators\n\nIn Figure [6](#page-13-0) we categorize studies also with\
    \ respect to the level of access to the source code of the program object of testing\
    \ in the Verification and Validation language, where white-box [5](#page-13-1)\
    \ tests are applied in verification (i.e., was the correct program built?) and\
    \ black-box [6](#page-13-2) tests are applied in validation (i.e., was the program\
    \ built correctly?). For the purposes of this research, we consider any access\
    \ to the source code to mean white-box testing and neglect so-called graybox [7](#page-13-3)\
    \ testing. We classify as white-box or black-box tests those tests that apply\
    \ verification techniques through observation or direct experience.\n\nWe consider\
    \ as Formal tests verifiable by theoretical means or pure logic, whose specifications\
    \ may include expressions in various logical forms, used to write pre and post\
    \ conditions, axioms of data types, constraints, temporal properties. They can\
    \ represent definitions of process states, and there is a formal deduction system,\
    \ enabling proofs, or other verifications (such as model checking), or both. Thus,\
    \ formal specifications can be analyzed to guide the identification of appropriate\
    \ test cases. According to Gaudel, these are black-box type tests, where the internal\
    \ organization of the program under test is ignored and the strategy is based\
    \ on a description of the desired properties and program behavior, grouped here\
    \ by those that meet these [\\[8\\]](#page-16-7) characteristics.\n\nAlso following\
    \ the methodology proposed by Wieringa et al., we quantified the documents by\
    \ the Facet of the Artifact Type generated by the study, taking as a basis the\
    \ approach presented by each and which we list in the Figure [7](#page-14-0) [\\\
    [6\\]](#page-16-5). In a future SLR we can apply qualitative aspects that will\
    \ determine whether for the purposes of this research specialized (generate only\
    \ the code or the test data) or general (generate both the code and the test data)\
    \ approaches are the most relevant.\n\n<span id=\"page-13-2\"></span><span id=\"\
    page-13-1\"></span><sup>5</sup>Validating non-functional, internal aspects of\
    \ a computer application.\n\n<sup>6</sup>Validating functional and external aspects\
    \ of a computer application.\n\n<span id=\"page-13-3\"></span><sup>7</sup>The\
    \ combination of white-box and black-box testing methods.\n\n<span id=\"page-14-0\"\
    ></span>![](_page_14_Figure_0.jpeg)\n\nFigure 7: Types of Artifacts Generated\n\
    \n<span id=\"page-14-1\"></span>![](_page_14_Figure_2.jpeg)\n\nFigure 8: Contributions\
    \ of the Studies\n\nThe quantification of the studies by the Contribution Type\
    \ Facet (see Figure [7\\)](#page-14-0) was important for the qualification and\
    \ selection of the most relevant studies to meet the objectives of the present\
    \ research and the quantified can be observed in the Figure [8.](#page-14-1)\n\
    \n# 3 Results\n\nWas presented the elementary results of a SLM applied to finding\
    \ relevant studies in ATP. This review applied the methodology of Petersen et\
    \ al. with elements of Keele et al., Brereton et al. [\\[1,](#page-16-0) [2,](#page-16-1)\
    \ [5\\]](#page-16-4)\n\n### 3.1 Conclusions\n\nBased on the research questions\
    \ developed in the Table [1](#page-1-2) the conclusions is:\n\n#### 3.1.1 Is the\
    \ study current?\n\nWas ensured that the studies were recent by restricting our\
    \ search to the last 5 years and we can observe in the Table [16](#page-9-1) an\
    \ even distribution of studies across the surveyed period.\n\n#### 3.1.2 Which\
    \ \"journals\" include studies in ATP?\n\nIn the Table [17](#page-9-0) it can\
    \ be seen the large concentration of studies published in conferences and \"Journals\"\
    \ and this led us to list the main conferences (see Table [18\\)](#page-10-0)\
    \ and the main publications (see Table [19\\)](#page-11-0). The relatively small\
    \ number of books on the subject, in our view, is due to the innovative characteristics\
    \ under which the fields of engineering and computer science live today.\n\n####\
    \ 3.1.3 What categories of studies are published in ATP?\n\nOf particular interest\
    \ to our research on ATP, the types of studies that stood out the most can be\
    \ seen in Figure [8.](#page-14-1) The concentration in practical aspects, as tools,\
    \ methods, models and metrics leads us to conclude that the maturity the subject\
    \ is now in Academy. The generation of both code and data is addressed by the\
    \ studies, and this is a guarantee that we're covering all aspects of the subject.\n\
    \n### 3.2 Future Work\n\nThis work aims to prepare ground for a SLR where it will\
    \ determine the challenges in applying generative testing techniques and evaluate\
    \ the solutions intended to be applied in future work.\n\n# Acronyms\n\nATP Automated\
    \ Test Production - pages: 1, 2, 6, 10, 13, 15, 16\n\nCAPES Coordena¸c˜ao de Aperfei¸coamento\
    \ de Pessoal de N´ıvel Superior do Brasil - page: 4\n\nPICOC Population, Intervention,\
    \ Comparison, Outcome, Context - page: 2\n\nPIOC Population, Intervention, Outcome,\
    \ Context - page: 2\n\nSLM Systematic Literature Mapping - pages: 1, 15\n\nSLR\
    \ Systematic Literature Review - pages: 1, 13, 14, 16\n\n# References\n\n- <span\
    \ id=\"page-16-0\"></span>[1] K. Petersen, R. Feldt, S. Mujtaba, and M. Mattsson,\
    \ \"Systematic mapping studies in software engineering,\" in 12th International\
    \ Conference on Evaluation and Assessment in Software Engineering (EASE) 12, 2008,\
    \ pp. 1– 10.\n- <span id=\"page-16-1\"></span>[2] S. Keele et al., \"Guidelines\
    \ for performing systematic literature reviews in software engineering,\" Technical\
    \ report, Ver. 2.3 EBSE Technical Report. EBSE, Tech. Rep., 2007.\n- <span id=\"\
    page-16-2\"></span>[3] M. Petticrew and H. Roberts, Systematic reviews in the\
    \ social sciences: A practical guide. John Wiley & Sons, 2008.\n- <span id=\"\
    page-16-3\"></span>[4] C. Wohlin, P. Runeson, M. H¨ost, M. C. Ohlsson, B. Regnell,\
    \ and A. Wessl´en, Experimentation in software engineering. Springer Science &\
    \ Business Media, 2012.\n- <span id=\"page-16-4\"></span>[5] P. Brereton, B. A.\
    \ Kitchenham, D. Budgen, M. Turner, and M. Khalil, \"Lessons from applying the\
    \ systematic literature review process within the software engineering domain,\"\
    \ Journal of systems and software, vol. 80, no. 4, pp. 571–583, 2007.\n- <span\
    \ id=\"page-16-5\"></span>[6] R. Wieringa, N. Maiden, N. Mead, and C. Rolland,\
    \ \"Requirements engineering paper classification and evaluation criteria: A proposal\
    \ and a discussion,\" Requirements engineering, vol. 11, no. 1, pp. 102–107, 2006.\n\
    - <span id=\"page-16-6\"></span>[7] J. E. Hirsch, \"An index to quantify an individual's\
    \ scientific research output,\" Proceedings of the National academy of Sciences,\
    \ vol. 102, no. 46, pp. 16 569–16 572, 2005.\n- <span id=\"page-16-7\"></span>[8]\
    \ M.-C. Gaudel, \"Formal methods for software testing,\" in 2017 International\
    \ Symposium on Theoretical Aspects of Software Engineering (TASE), IEEE, 2017,\
    \ pp. 1–3."
- title: "Practical Guidelines for the Selection and Evaluation of Natural\n  Language\
    \ Processing Techniques in Requirements Engineering"
  abstract: 'Natural Language Processing (NLP) is now a cornerstone of requirements

    automation. One compelling factor behind the growing adoption of NLP in

    Requirements Engineering (RE) is the prevalent use of natural language (NL) for

    specifying requirements in industry. NLP techniques are commonly used for

    automatically classifying requirements, extracting important information, e.g.,

    domain models and glossary terms, and performing quality assurance tasks, such

    as ambiguity handling and completeness checking. With so many different NLP

    solution strategies available and the possibility of applying machine learning

    alongside, it can be challenging to choose the right strategy for a specific RE

    task and to evaluate the resulting solution in an empirically rigorous manner.

    In this chapter, we present guidelines for the selection of NLP techniques as

    well as for their evaluation in the context of RE. In particular, we discuss

    how to choose among different strategies such as traditional NLP, feature-based

    machine learning, and language-model-based methods. Our ultimate hope for this

    chapter is to serve as a stepping stone, assisting newcomers to NLP4RE in

    quickly initiating themselves into the NLP technologies most pertinent to the

    RE field.'
  url: http://arxiv.org/abs/2401.01508v3
  keywords: ''
  document: '# 15. Practical Guidelines for the Selection and Evaluation of Natural
    Language Processing Techniques in Requirements Engineering


    Mehrdad Sabetzade[h](https://orcid.org/0000-0002-4711-8319) <sup>1</sup> and Chetan
    Aror[a](https://orcid.org/0000-0003-1466-7386) <sup>2</sup>


    <sup>1</sup> University of Ottawa, ON, Canada.


    <sup>2</sup> Monash University, Vic, Australia.


    Contributing authors: m.sabetzadeh@uottawa.ca; chetan.arora@monash.edu;


    #### Abstract


    Natural Language Processing (NLP) is now a cornerstone of requirements automation.
    One compelling factor behind the growing adoption of NLP in Requirements Engineering
    (RE) is the prevalent use of natural language (NL) for specifying requirements
    in industry. NLP techniques are commonly used for automatically classifying requirements,
    extracting important information, e.g., domain models and glossary terms, and
    performing quality assurance tasks, such as ambiguity handling and completeness
    checking. With so many different NLP solution strategies available and the possibility
    of applying machine learning alongside, it can be challenging to choose the right
    strategy for a specific RE task and to evaluate the resulting solution in an empirically
    rigorous manner. In this chapter, we present guidelines for the selection of NLP
    techniques as well as for their evaluation in the context of RE. In particular,
    we discuss how to choose among different strategies such as traditional NLP, feature-based
    machine learning, and language-model-based methods. Our ultimate hope for this
    chapter is to serve as a stepping stone, assisting newcomers to NLP4RE in quickly
    initiating themselves into the NLP technologies most pertinent to the RE field.


    # 1 Introduction


    NLP''s role in requirements automation is pivotal, due to the widespread use of
    natural language (NL) in industrial requirements specifications. Historically,
    NL has posed challenges for requirements analysis because of its inherent proneness
    to defects such as incompleteness and ambiguity. Recent breakthroughs in NLP,
    e.g., the emergence of large language models, have nonetheless drastically enhanced
    our ability to automatically analyze textual information. This development is
    poised to even further amplify the adoption and influence of NL in requirements
    engineering.


    Due to the rapid advancement of NLP, newcomers to NLP4RE may feel overwhelmed
    by the numerous potentially applicable technologies. Another challenge is the
    necessity to empirically assess a proposed automation solution, ensuring proper
    optimization, and, where applicable, improve performance over existing solutions.


    Over the past several years, we have studied various requirements automation problems,
    including checking compliance with requirements templates [\[5\]](#page-20-0),
    glossary construction [\[7\]](#page-20-1), model extraction [\[6\]](#page-20-2),
    requirements demarcation [\[2\]](#page-20-3), ambiguity handling [\[19\]](#page-21-0),
    and question answering [\[20\]](#page-21-1). With the benefit of hindsight, this
    chapter aims to reflect on our research process and offer our collective insights
    into how we approach NLP4RE problems. Before we start, we need to emphasize that
    our perspective is retrospective. Given the fast pace of progress in NLP technologies,
    new considerations may surface, and existing technologies could become outdated.
    Therefore, it is important for readers to consider the time this chapter was written
    (2023) when dealing with new technologies. This advice applies to most works in
    the fast-changing field of Applied AI.


    Structure. Section [2](#page-1-0) outlines the steps for automating pre-processing,
    analysis, and post-processing in NLP4RE. Section [3](#page-6-0) describes various
    NLP techniques and discusses their key considerations for automation in RE. Finally,
    Section [4](#page-20-4) summarizes the chapter and presents conclusions.


    # <span id="page-1-0"></span>2 Automation Steps in NLP4RE


    The automation process for NL requirements and related textual artifacts can be
    structured into three sequential steps. These steps, shown in Figure [1](#page-2-0)
    are: (1) Preprocessing, (2) Analysis, and (3) Post-processing. We outline these
    steps next.


    ### 2.1 Pre-processing


    The goal of pre-processing is to automatically examine the NL content of requirements
    or requirements-related artifacts (e.g., design documents and code) and generate
    structured information for use by the Analysis step (Section [2.2\)](#page-2-1).


    The specific information targeted by pre-processing depends on the needs of the
    subsequent Analysis step. Importantly, the information to obtain through preprocessing
    relies on the selection of the units of analysis for the Analysis step. In the
    context of NLP, "unit of analysis" refers to the particular textual components
    that are intended for processing and interpretation. Some common units of analysis
    are: words, phrases, sentences, and paragraphs. For instance, when the objective
    of Analysis is identifying statements that contain requirements, sentences are
    frequently adopted as the units of analysis [\[2\]](#page-20-3). We note that
    there is a composition relationship between different unit types in NLP. For example,
    a sentence is made up of phrases, and a phrase


    ![](_page_2_Figure_0.jpeg)


    #### <span id="page-2-0"></span>Fig. 1 NLP4RE Steps


    is made up of words. Because of this characteristic, it is possible to use a combination
    of units of analysis simultaneously, e.g., phrases alongside sentences.


    Typically, during the pre-processing phase, a set of "features" are calculated
    for the units of analysis (or the relationships between the units). A feature
    refers to a distinct attribute or characteristic of a unit of analysis. Features
    can be numeric (e.g., the number of tokens appearing in a sentence) or categorical
    (e.g., part-of-speech tags).


    The most common enabling technologies for computing features are presented in
    Figure [1](#page-2-0) under the Pre-processing activity. These technologies include
    the NLP Pipeline, Relevance Measures and Embeddings, which are discussed further
    in Section [3.](#page-6-0)


    #### <span id="page-2-1"></span>2.2 Analysis


    The core of the process shown in Figure [1](#page-2-0) is the Analysis step. In
    NLP4RE, this step typically manifests as one of the following three alternative
    activities: Classification, Clustering, and Text Generation.


    #### 2.2.1 Analysis Activities


    Classification involves the assignment of labels or categories to the units of
    analysis. There are numerous NLP4RE use cases for classification. An example use
    case would be differentiating between functional (F) and non-functional requirements
    (NF) [\[27\]](#page-22-0). This task can be framed as the assignment of F and
    NF labels to the units of analysis, which in this context, are typically sentences
    within a requirements document.


    Classification further extends to encompass verbatim information extraction. Verbatim
    information extraction involves directly extracting exact segments from source
    documents without abstraction, inference, or interpretation. This is done by marking
    off the text segments of interest and assigning labels to them. A typical use
    case is identifying requirements-related text segments in legal documents and
    annotating them with labels such as "permission", "obligation", "condition", and
    "exception" [\[43\]](#page-23-0).


    Clustering leverages inherent similarities among the units of analysis to organize
    them into groups or themes. Unlike classification, which requires predetermined
    labels, clustering emphasizes the intrinsic structure and similarities within
    the content. The goal is to bring together similar content based on shared features,
    thereby avoiding the need for explicit predefined categories. This makes clustering
    particularly useful when dealing with problems where the labels are not well-defined
    or when exploring content where the underlying patterns might not be immediately
    evident. For instance, clustering can be used to identify groups of closely related
    requirements phrases during glossary construction [\[7\]](#page-20-1); here there
    is no predetermined set of classes for the groups of related phrases that will
    emerge.


    Text Generation involves the automated creation of human-readable text based on
    either structured or unstructured inputs to aid the derivation, completion, understanding
    and communication of requirements. NLP4RE solutions based on text generation are
    a relatively recent development but are rapidly gaining momentum thanks to advances
    in generative language models like GPT [\[9\]](#page-21-2). Example use cases
    for text generation include constructing requirements models based on prompts
    and early-stage descriptions [\[16\]](#page-21-3), summarizing requirements-related
    documents [\[26\]](#page-22-1), and providing predictive assistance for requirements
    completion [\[31\]](#page-22-2).


    #### 2.2.2 Technique Selection


    Selecting suitable enabling technique(s) for the Analysis step is crucial. To
    make this selection easier, we have developed a decision process, shown in Figure
    [2.](#page-4-0) This simple process, which is based on our past experience, aims
    to facilitate narrowing the options for the Analysis step.


    The first and most important criterion in this process is decision node (a), as
    depicted in Figure [2.](#page-4-0) This decision concerns whether we have a well-established
    and pre-existing set of conceptual categories relevant to automation. For instance,
    consider the task of classifying functional and non-functional requirements. In
    this task, the categories would be functional and non-functional, and this understanding
    exists before classification. For another example, consider the task of domain
    model extraction. Here, all pertinent categories are identified and can be listed,
    such as class, attribute, association, cardinality constraint, and so on. In contrast,
    consider a problem like identifying similar and potentially redundant requirements.
    When presented with a requirements document, predicting the number of equivalence
    classes (clusters) is impossible. As a result, there is no predefined set of conceptual
    categories for this problem that can be known beforehand.


    ![](_page_4_Figure_0.jpeg)


    <span id="page-4-0"></span>Fig. 2 Identifying Suitable Enabling Technique(s) for
    a Specific Analysis Task


    Without established conceptual categories, dataset size is the next crucial criterion
    to consider. Historically, when predefined categories are not possible, clustering
    algorithms have been the preferred enabling technique for analysis. Recent advances
    in generative language models like ChatGPT and Llama nonetheless offer an alternative.
    For instance, when dealing with data sources such as requirements documents, one
    can use exploratory prompts like the following to uncover the main themes: "Cluster
    the primary concepts in the following: [contents of the data source]".


    As of writing, using a generative language model as an alternative to clustering
    algorithms is effective only for relatively small content volumes. Existing language
    models set a limit on total input and output tokens during interactive dialogs,
    known as "token limit" or "session size." This limit defines how much context
    the model is capable of taking into account for response generation. Currently,
    the largest token limit we are aware of is 32,768 tokens (GPT-4-32k); this would
    be insufficient for many NLP4RE problems, such as traceability retrieval, which
    can potentially involve millions of tokens.


    When an a-priori-known set of conceptual categories exists, the next question
    is whether a labelled dataset is available. This is captured by decision node
    (c) in Figure [2.](#page-4-0) When a labelled dataset is lacking, the most common
    enabling technique is query-based pattern matching. Although pattern matching
    does not require the explicit creation of labelled data, formulating the queries
    often entails some form of qualitative analysis, e.g., grounded theory [\[41\]](#page-23-1).
    Alternatively, language models can be employed when labelled data is unavailable.
    In such a scenario, one has to rely exclusively on the language model''s pre-training,
    without further specific training for the task at hand. For example, a language
    model could be asked the following: "Is this requirements statement functional
    or non-functional? [an individual requirements statement]".


    If labelled data is available, the next factor to consider is the volume of such
    data, as captured by decision node (d) in Figure [2.](#page-4-0) When a considerable
    amount of labelled data is available, there are two options: applying feature-based
    learning or utilizing the labelled data to "fine-tune" a language model. Fine-tuning
    involves adapting a pre-trained model to a specific task through targeted training.
    In cases of limited labelled data, achieving task adaptation for a language model
    with minimal examples – a technique known as few-shot learning – is likely to
    yield better results.


    It is important to note that there is no general rule as to what constitutes "considerable"
    or "limited" labelled data. Several parameters such as the quality of labels,
    the complexity of the relationships to be learned, the number of classes (in classification)
    and the range of values (in regression), the amount of noise in the data, the
    dimensionality of the feature space (in case of feature-based learning), and the
    desired level of accuracy to achieve can influence data needs. As such, experimentation
    on a case-by-case basis is crucial to determine whether the labelled data at hand
    should be regarded as considerable or limited. In our experience, and for the
    sake of offering ballpark figures, having fewer than 100 data points tends to
    constitute a limited amount. A considerable amount of data, on the other hand,
    is likely to materialize within the range of 500 to 5000 labelled data points.


    We need to highlight three important aspects related to the process in Figure
    [2.](#page-4-0) First, no individual decision model can encompass the full spectrum
    of techniques employed in NLP4RE. Our model aims to offer a simplified representation
    of common scenarios, rather than imposing constraints or promoting a lack of flexibility
    in technique selection. Second, the process is likely to evolve in the future
    to stay in step with NLP4RE research. In particular, capitalizing on the interactive
    capabilities of large language models, there is potential to further elaborate
    the process by considering prompting strategies and providing additional guidelines.
    However, due to the scarcity of NLP4RE approaches built on large language models,
    we have to defer doing so to the future. Finally, when selecting enabling techniques
    for analysis, the cost and environmental impact must be considered. Most notably,
    the resource-intensive nature of large language models requires justification,
    especially when alternatives cannot be dismissed due to compelling reasons such
    as lack of accuracy.


    #### 2.3 Post-processing


    Post-processing – the third step in the process of Figure [1](#page-2-0) – aims
    to enhance the results of the Analysis step or to adapt these results for human
    analysts'' better understanding. Post-processing is not needed in all NLP4RE solutions
    and is thus an optional step.


    To illustrate a simple scenario where post-processing is required, let us consider
    the task of requirements identification. For this task, one may apply the following
    heuristic as a post-processing step: if all but one sentence in a passage are
    categorized as requirements (during the Analysis step), that lone sentence should
    be reclassified from a non-requirement to a requirement. This adjustment will
    likely increase the accuracy of requirements identification [\[2\]](#page-20-3).


    For a more advanced example of post-processing, let us consider requirements completion
    based on predictions by a language model. In this context, the language model
    is likely to generate a non-negligible number of predictions that are not useful
    (false positives) alongside the useful ones. To reduce the incidence of unuseful
    predictions in the final results, the development of a post-processing filter
    becomes essential [\[31\]](#page-22-2).


    In its simplest form, post-processing can be light, e.g., in the case of the heuristic
    mentioned earlier for requirements identification. In more complex scenarios,
    like the one mentioned above where predictions need to be filtered, additional
    enabling techniques might be needed to carry out post-processing.


    # <span id="page-6-0"></span>3 Enabling Techniques: Overview and Guidelines


    In this section, we outline the various enabling techniques shown in Figure [1](#page-2-0)
    and provide practical guidelines for applying and evaluating them.


    #### <span id="page-6-1"></span>3.1 NLP Pipeline


    The NLP pipeline is a sequence of modules that incrementally add linguistic annotations
    to an input text. The pipeline typically begins with tasks like tokenization (breaking
    text into words or sub-words), sentence splitting (segmenting a passage into sentences),
    and lemmatization (reducing words to their base forms). Next and depending on
    the annotations required, the pipeline performs tasks such as part-ofspeech (POS)
    tagging (labelling words with their grammatical roles), named-entity recognition
    (identifying entities like names, dates, and locations), and syntactic parsing
    (analyzing sentence structure). Syntactic parsing includes two main techniques:
    constituency parsing (deconstructing sentences into grammatical constituents)
    and dependency parsing (determining grammatical relationships between words).


    Figures [3](#page-7-0) (a) and (b) respectively exemplify the annotations generated
    by the constituency parsing and dependency parsing modules for the following requirements
    sentence: R = "The flight simulator shall store log messages in the database.".
    The annotations generated by the constituency parser for this sentence are: NP
    (noun phrase), VP (verb phrase), and PP (prepositional phrase). These annotations
    capture the hierarchical constituents of the sentence. The relationships between
    the words in the sentence are given by the pairwise links generated through dependency
    parsing. For instance, from the dependency parse graph of Figure [3](#page-7-0)
    (b), one can determine that "simulator" functions as the subject (nsubj) for "store,"
    and that "messages" serves as the object (obj) for this transitive verb. Crucially,
    both parsing methods require sentence splitting and POS tagging. Figure [3\(](#page-7-0)a)
    illustrates sentence annotation (S),


    ![](_page_7_Figure_0.jpeg)


    This is an implementation of a minimal neural model for constituency parsing based
    on an independent scoring of labels and spans. This SpanConstituencyParser simply
    encodes a sequence of text with a stacked Seq2SeqEncoder , extracts span representations
    using a SpanExtractor , and then predicts a label for each span in the sequence.
    These labels are non-terminal nodes in a constituency parse tree, which we then
    greedily reconstruct. The model uses ELMo embeddings, which are completely character-based
    and improves single model performance from 92.6 F1 to 94.11 F1 on the


    The flight simulator shall store log messages in the database .


    **Constituency Parsing**


    **Constituency Parser with ELMo embeddings**


    Penn Treebank, a 20% relative error reduction.


    The flight simulator shall store log messages in the database.


    Demo Model Card Model Usage


    Model


    Example Inputs Select a Sentence Sentence


    Answer a question Reading Comprehension Visual Question Answering Annotate a sentence
    Named Entity Recognition Open Information Extraction Sentiment Analysis Dependency
    Parsing Constituency Parsing Semantic Role Labeling Annotate a passage Coreference
    Resolution Generate a passage Language Modeling Masked Language Modeling Compare
    two sentences Textual Entailment Evaluate Reading Comprehension


    **Model Output**


    Run Model


    **CLI Output** *What is this?*


    Input Model Output


    Constituency parsing is the task of breaking a text into sub-phrases, or constituents.
    Non-terminals in the parse tree are types of phrases, the terminals are the words
    in the sentence.


    © The Allen Institute for Artificial Intelligence - All Rights Reserved | Privacy
    Policy | Terms of Use | Business Code of Conduct (b) Dependency Parse Graph


    The flight simulator shall store log messages in the database . DT NN NN MD VB
    NN NNS IN DT NN . compound aux compound det det nsubj obj case 1 Fig. 3 Illustration
    of (a) Constituency Parsing and (b) Dependency Parsing. Both Parsing Methods Require
    Sentence Detection and POS Tagging.


    <span id="page-7-0"></span>obl:in punct **— Text to annotate —**


    version 4.5.4


    **— Language —**


    Share


    English Submit


    CoreNLP Tools: while both figures include POS tags (DT: determiner, NN: noun,
    NNS: plural noun, MD: modifier, VB: verb, IN: preposition).


    **Enter a TokensRegex expression to run against the above sentence:** TokensRegex
    Semgrex Tregex e.g., (?\$foxtype [{pos:JJ}]+ ) fox Match When using the NLP pipeline,
    it is important to consider the specific natural language(s) that require support.
    While most NLP modules have good performance over well-written English, their
    effectiveness can vary significantly when dealing with other languages or when
    processing text that deviates from grammatical norms, such as user feedback (e.g.,
    app reviews) or developer commit messages. Experimentation is therefore typically
    necessary for constructing an accurate NLP pipeline. NLP workbenches such as GATE
    [\[23\]](#page-22-3) and DKPro [\[14\]](#page-21-4) facilitate the integration
    of NLP modules from different NLP libraries. For instance, these workbenches enable
    the use of the POS tagger provided by one library, say, Apache OpenNLP [\[4\]](#page-20-5),
    alongside the constituency and dependency parsers from another library, say, Stanford
    CoreNLP [\[32\]](#page-22-4). This flexibility to combine NLP modules from different
    libraries enables systematic experimentation with various pipeline configurations
    to determine the optimal configuration for the task at hand. An example of such
    experimentation can be found in our work on checking conformance with requirements
    templates [\[5\]](#page-20-0).


    Visualisation provided using the brat visualisation/annotation software. If systematic
    experimentation with alternative NLP modules is not feasible or if there are constraints
    on using a single library, e.g., to minimize complexity, it would be important
    to conduct an error analysis on the annotations generated by the NLP pipeline.
    This analysis helps with ensuring the absence of systemic issues. Common


    8


    systemic issues include recurring errors in sentence detection, repeated inaccuracies
    in tokenization and POS tags, and incorrect parsing results.


    Takeaway: NLP Pipeline


    Prioritize pipeline implementations that are known to work well for the language(s)
    you need to support. Experimentation with different NLP modules is often useful
    for improving accuracy. If extensive experimentation with the NLP pipeline is
    not possible or you are limited to a single library, conduct an error analysis
    on the annotations to identify and address any systemic issues such as recurring
    errors in sentence detection, POS tags, and parsing.


    #### <span id="page-8-0"></span>3.2 Relevance Measures


    In the context of RE, relevance denotes the extent to which various requirement
    segments are related or how closely a specific requirements segment aligns with
    a particular query, topic, or artifact (e.g., a design document or a portion thereof).
    The concept of relevance is typically quantified using one or a combination of
    three distinct categories of metrics: syntactic, semantic, and statistical.


    - Syntactic Relevance is the string-based or structural relatedness between two
    or more text segments. There are numerous syntactic relevance measures. For a
    fairly comprehensive list of syntactic measures, consult [\[24\]](#page-22-5).
    An example metric in the syntactic category is Levenshtein [\[24\]](#page-22-5).
    This metric calculates the minimum number of single-character edits (insertions,
    deletions, or substitutions) required to transform one string into another. Levenshtein
    distance is usually normalized (scaled from 0 to 1) by dividing it by the maximum
    possible edit distance between the two strings. For instance, the (normalized)
    Levenshtein distance between the phrases "software system" and "software systems"
    is 0.9375, indicating that the two strings have considerable lexical overlap.

    - Semantic Relevance goes beyond string matching to measure similarity between
    word meanings. Semantic relevance is typically quantified using metrics like PATH
    within a semantic network such as WordNet [\[37\]](#page-23-2). WordNet captures
    various relationships, such as hypernymy and hyponymy, which denote an "is-a"
    connection, and meronymy and holonymy, representing a "part-of" association. To
    illustrate, consider the relationship between "vehicle" and "car", where "vehicle"
    serves as the hypernym of "car", and the relationship between "wheel" and "car",
    with "wheel" acting as the meronym of "car". PATH similarity calculates the shortest
    path between two concepts on the "is-a" hierarchy. For instance, the PATH score
    between the terms "cat" and "mammal" is higher than between "cat" and "vehicle",
    indicating that "cat" is semantically more related to "mammal" than "vehicle".

    - Statistical Relevance assesses relevance by analyzing the frequency and distribution
    of terms within a document, often employing algorithms such as TF-IDF and BM25.
    These algorithms are frequently normalized on a scale from 0 to 1 [\[12\]](#page-21-5).
    Statistical methods typically operate at the level of term frequency and do not
    necessitate


    a pre-constructed semantic network. For instance, TF-IDF evaluates a term''s importance
    within a document based on its frequency of occurrence in that document, normalized
    by its frequency across the entire corpus. BM25, which extends TF-IDF, takes into
    account further factors like term saturation and document length. To illustrate,
    consider a corpus of requirements documents. A term like "user authentication"
    might appear infrequently but could be highly significant. BM25 can rank a document
    that extensively discusses this term higher than a document that only mentions
    it in passing, thereby indicating its greater relevance in the context of security
    requirements. Statistical measures are more commonly employed in information retrieval
    (IR) problems within NLP4RE, such as querying requirements [\[3\]](#page-20-6).


    Applications and Other Considerations. Relevance measures serve two main use cases
    in NLP4RE. The first is to calculate similarity either within a set of requirements
    or between requirements and textual segments found in other development artifacts.
    The second use case is to assess the relative significance of terms in documents.
    Frequently, relevance measures are employed as features in both supervised and
    unsupervised learning.


    Different relevance measures can be combined to provide a more holistic characterization
    of relevance. For example, when tasked with constructing a requirements glossary,
    the combination of syntactic and semantic measures can help identify a wider range
    of variations among related domain terms. To illustrate, if our objective is to
    cluster terms related to a flight simulation system, we anticipate that "flight
    coordinates", "aircraft position", and all concepts associated with "flight positioning"
    should land in the same cluster [\[7\]](#page-20-1). Simultaneously applying both
    syntactic and semantic measures facilitates the determination of these terms being
    highly similar.


    In relation to syntactic measures, it is important to note that, because requirements
    frequently manifest variability in phrasing, vocabulary selection and syntactic
    structure, techniques like lemmatization and tokenization are often required prior
    to computing syntactic measures. This preprocessing helps mitigate variability
    and enhances the accuracy of comparisons [\[7\]](#page-20-1).


    Finally, and in relation to semantic measures, we note that these measures are
    quickly being replaced by more advanced techniques, notably embeddings. Embeddings
    not only capture semantic similarity but also contextual similarity, as we discuss
    in Section [3.3.](#page-10-0) Furthermore, while lexical resources like WordNet
    offer the advantage of establishing human-interpretable connections between words,
    techniques such as embeddings provide a more nuanced characterization of meaning,
    although they may not be entirely interpretable by humans. Consequently, when
    the primary goal is the application of similarity metrics, rather than explaining
    relationships, there is often limited justification for employing semantic measures
    like PATH in future research.


    #### Takeaway: Relevance Measures


    Combining different relevance measures often results in more accurate analytical
    outcomes. Relevance measures can be applied at different levels of granularity,
    ranging from individual tokens (e.g., Levenshtein distance) to entire documents
    (e.g., TF-IDF). Empirical evaluations of relevance measures can centre around
    identifying the most effective combination of these measures or benchmarking advanced
    solutions against relevance measures considered as baseline methods.


    #### <span id="page-10-0"></span>3.3 Embeddings


    Embeddings enable the conversion of words into numerical vectors. These vectors
    encapsulate the semantic connections among words, in turn supporting a more meaningful
    manipulation of language. Word embeddings are typically derived through self-supervised
    approaches such as Word2Vec [\[34\]](#page-22-6), GloVe [\[36\]](#page-23-3),
    and the pre-training of language models such as BERT [\[18\]](#page-21-6) and
    GPT [\[38\]](#page-23-4). For example, using the 300 dimensional variant of GloVe
    embedding vectors, the word "requirements" would be represented as a 300-dimensional
    vector: [-1.3598e-01, -1.8174e-01, · · · , -6.2015e-02].


    While the primary goal of embeddings is to represent individual words, methods
    also exist for generating embeddings for phrases and sentences. For example, a
    simple approach for obtaining sentence embeddings is to compute the weighted average
    of the word embeddings in a given sentence [\[10\]](#page-21-7).


    There are two main use cases for embeddings in the existing NLP4RE literature:
    (1) computing semantic similarity, typically through the cosine measure, and (2)
    using embeddings as features for learning. To illustrate, suppose that we are
    interested in identifying most similar requirements, e.g., as a way to find overlapping
    or redundant requirements. Consider the following three statements: R1 = "The
    system shall react to user input within one second."; R2 = "The system shall respond
    within one second."; and R3 = "The system shall encrypt sensitive data.". For
    a requirement sentence R, let emb(R) denote the sentence''s embeddings. By utilizing
    the 300 dimensional variant of GloVe and employing averaging to derive sentence
    embeddings from word embeddings, we would obtain the following: cosine(emb(R1),
    emb(R2)) ≈ 0.95 > cosine(emb(R1), emb(R3)) ≈ 0.83 > cosine(emb(R2), emb(R3)) ≈
    0.78. Now, the requirements analyst can, for example, sort the requirements pairs
    in descending order of similarity and inspect the most similar pairs to determine
    if there are overlaps or redundancies. Alternatively, when it is feasible to create
    a labelled dataset for training, the embeddings can be used as features – either
    on their own or alongside other features – for building a feature-based classifier
    that distinguishes similar and non-similar requirements pairs. In our illustrative
    example, and assuming that only R1 and R2 are deemed similar, one could infer
    (among other labelled data points) the following for training: emb(R1)|emb(R2)|SIMILAR
    and emb(R1)|emb(R3)|NOT-SIMILAR. Here, "|" denotes vector concatenation, and "SIMILAR"
    and "NOT-SIMILAR" denote labels for pairs of requirements.


    There are some important considerations to note when working with embeddings:


    Dimensionality of Embeddings. The dimensionality of embeddings, which refers to
    the number of dimensions (or features) used to represent each word as a vector,
    determines the richness of information in word vectors. While some dimensions
    may have clear interpretations, e.g., gender or sentiment, others can be complex,
    capturing subtle and abstract aspects of word semantics that would be difficult
    for humans to interpret directly. There is no universally suitable choice for
    the dimensionality of word embeddings. Although a larger dimensionality can provide
    increased semantic nuance and potentially improved accuracy, one must consider
    the curse of dimensionality [\[34\]](#page-22-6) – the inherent challenges that
    arise when dealing with high-dimensional data. We recommend experimentation with
    alternative embedding methods and dimensionality options to find an acceptable
    trade-off between accuracy for the analytical task at hand and the challenges
    posed by high-dimensional data. Note that the techniques discussed in Section
    [3.5](#page-14-0) for feature selection and reduction can also be applied to embeddings
    to reduce dimensionality.


    Non-contextual vs. Contextual Embeddings. Embeddings can be either noncontextual
    or contextual. Non-contextual embeddings, such as those produced by GloVe, create
    fixed word vectors that remain the same regardless of context. In contrast, contextual
    word embeddings, as produced by models like BERT and GPT, consider the surrounding
    words to generate word vectors that adapt to the context. To illustrate, consider
    the following two sentences: S = "Meeting privacy requirements is essential.";
    and S ′ = "The system shall meet all the privacy requirements stipulated by the
    GDPR." Using GloVe to obtain embeddings for the word "requirements" yields the
    same vector for both sentences. In contrast, if one uses models such as BERT or
    GPT, the embeddings obtained for the same word in different sentences would differ.
    For instance, the bert-base-uncased variant of BERT yields the following vectors
    for "requirements" in S and S ′ , respectively: [2.7466e-01, 4.8193e-01, · · ·
    , 4.1681e-01] and [-1.6852e-01, 3.5143e-01, · · · , 3.5699e-01]. This difference
    is due to the contextually different meaning of "requirements" in these two sentences,
    where the word conveys the sense of a prerequisite condition in S and the sense
    of a specification in S ′ .


    Contextual embeddings offer greater accuracy but come at a higher computational
    cost. It is therefore important not to dismiss non-contextual embeddings outright
    but to weigh their potential alongside contextual embeddings to determine whether
    the added accuracy of contextual embeddings is worth the extra cost.


    Domain-specific Embeddings. Domain-specific embeddings capture contextspecific
    word meanings that generic embeddings may miss. For instance, specialized BERT
    variants, such as BioBERT [\[28\]](#page-22-7) for biomedical texts and LegalBERT
    [\[15\]](#page-21-8) for legal documents, provide domain-specific embeddings for
    their respective domains. When domain-specific embeddings exist, it is worthwhile
    to compare them with generic embeddings for potential improvements. Further, in
    cases where domain-specific embeddings are unavailable, but a suitable domain-specific
    corpus is accessible, one can


    attempt to construct domain-specific embeddings from scratch. Recent efforts in
    software engineering, such as building Word2Vec and GloVe embeddings for model-driven
    engineering [\[30\]](#page-22-8), provide useful guidance in this regard.


    ### Takeaway: Embeddings


    Experiment with different embedding technologies and dimensionality options to
    strike a balance between accuracy and the challenges of high-dimensional data.
    Assess whether the added accuracy of contextual embeddings justifies their higher
    computational cost, or if non-contextual embeddings suffice for your specific
    task. Explore domain-specific embeddings when available, as they may be superior
    at capturing context-specific meanings.


    #### 3.4 Query-based Pattern Matching


    The annotations produced by the NLP pipeline provide a rich basis for defining
    queries that detect patterns of interest within an input text. Typically, pattern-matching
    queries work with "spans". Each span represents a distinct sequence of consecutive
    words or tokens within the given text.


    An important technical aspect in pattern matching is the choice of the query language.
    In NLP, span information can be flat, focusing on individual words and their properties
    (like POS tags), hierarchical, revealing how words combine into larger structures
    (as in constituency parsing), or graph-based, capturing relationships between
    words (as in dependency parsing). Different NLP toolkits offer different query
    languages; CoreNLP [\[32\]](#page-22-4), for instance, provides TokensRegex for
    token-based regular expressions, Tregex for tree-based linguistic structures,
    and Semgrex for syntactic dependency patterns. To illustrate, we exemplify these
    query languages:


    - (a) The TokensRegex query [{tag:/VB.\*/}] extracts all spans tagged as verbs.

    - (b) The Tregex expression NP[<NN | <NNS] extracts all spans that are Noun Phrases
    (NPs) and immediately dominate a singular noun (NN) or a plural noun (NNS).

    - (c) The Semgrex query {pos:/VB.\*/} >nsubj {}=subject >obj {}=object extracts
    verbs that both have a subject and an object, alongside the subject and the object.


    Figure [4](#page-13-0) shows the results of the above queries as applied to the
    annotations in Fig. [3.](#page-7-0) All three queries serve a purpose in NLP4RE.
    Query (a) produces results that can be used as a feature for identifying requirements,
    grounded in the hypothesis that a higher verb count signifies a higher likelihood
    of requirements being present. Query (b) identifies constituent noun phrases and
    verb phrases within a requirements statement. This information is valuable for
    various purposes, one of which is to validate whether the statement conforms to
    a specific template, such as EARS [\[33\]](#page-22-9). Query (c) is useful for
    constructing a domain model [\[6\]](#page-20-2); the query extracts a probable
    association. In the case of our example, the association would be "[flight] simulator
    stores [log] messages".


    Query-based pattern matching techniques often face criticism related to both the
    scope of the study that informs query development and the applicability of the
    resulting queries beyond their initial purpose. To address these concerns, we
    recommend a


    ![](_page_13_Figure_0.jpeg)


    © The Allen Institute for Artificial Intelligence - All Rights Reserved | Privacy
    Policy | Terms of Use | Business Code of Conduct


    **Constituency Parsing**


    1


    1


    Penn Treebank, a 20% relative error reduction.


    1


    1


    1


    Demo Model Card Model Usage Example Inputs


    Model **Constituency Parser with ELMo embeddings**


    Answer a question Reading Comprehension Visual Question Answering Annotate a sentence
    Named Entity Recognition Open Information Extraction Sentiment Analysis Dependency
    Parsing


    Constituency parsing is the task of breaking a text into sub-phrases, or constituents.
    Non-terminals in the parse tree are types of phrases, the terminals are the words
    in the sentence.


    TokensRegex Semgrex Tregex


    **DT**


    **DT**


    **The**


    **The**


    This is an implementation of a minimal neural model for constituency parsing based
    on an independent scoring of labels and spans. This SpanConstituencyParser simply
    encodes a sequence of text with a stacked Seq2SeqEncoder , extracts span representations
    using a SpanExtractor , and then predicts a label for each span in the sequence.
    These labels are non-terminal nodes in a constituency parse tree, which we then
    greedily reconstruct. The model uses ELMo embeddings, which are completely character-based
    and improves single model performance from 92.6 F1 to 94.11 F1 on the


    The flight simulator shall store log messages in the database . DT NN NN MD VB
    NN NNS IN DT NN . compound aux compound det det nsubj obj case


    The flight simulator shall store log messages in the database . DT NN NN MD VB
    NN NNS IN DT NN . compound aux compound det det nsubj obj case


    The flight simulator shall store log messages in the database . DT NN NN MD VB
    NN NNS IN DT NN . compound aux compound det det nsubj obj case


    > obl punct


    obl punct


    obl:in punct


    The flight simulator shall store log messages in the database . DT NN NN MD VB
    NN NNS IN DT NN .


    **NP**


    **NN**


    **flight**


    The flight simulator shall store log messages in the database.


    The flight simulator shall store log messages in the database . DT NN NN MD VB
    NN NNS IN DT NN .


    The flight simulator shall store log messages in the database.


    parts-of-speech dependency parse constituency parse


    parts-of-speech dependency parse constituency parse


    **NP**


    **NN**


    **NN**


    **NN**


    **simulator**


    **MD**


    **MD**


    **shall**


    **— Annotations —**


    **— Annotations —**


    **shall**


    **simulator**


    **flight**


    Share


    Part-of-Speech:


    **VP**


    **— Text to annotate —**


    **ROOT**


    **S**


    Constituency Parse:


    Part-of-Speech:


    **— Text to annotate —**


    Constituency Parse:


    **ROOT**


    **S**


    **VP**


    **VB**


    **VB**


    **store**


    **store**


    **VP**


    **VP**


    **NNS**


    **.**


    **.**


    **.**


    **NNS**


    **messages**


    **.**


    **PP**


    **PP**


    **NP**


    **NP**


    **DT**


    **the**


    **DT**


    **NN**


    **NN**


    **database**


    **database**


    **the**


    **IN**


    **IN**


    **in**


    **— Language —**


    **— Language —**


    English Submit


    English Submit


    **in**


    **messages**


    **NP**


    **NP**


    **NN**


    **log**


    **NN**


    **log**


    Basic Dependencies:


    CoreNLP Tools:


    Basic Dependencies:


    Enhanced++ Dependencies:


    Enhanced++ Dependencies:


    **Enter a TokensRegex (http://nlp.stanford.edu/software/tokensregex.shtml) expression
    to run against the above sentence:**


    CoreNLP Tools:


    **dependencies" above:**


    Visualisation provided using the brat visualisation/annotation software (http://brat.nlplab.org/).
    Fig. 4 Illustration of Query-based Pattern Matching over the Annotations of Fig.
    [3.](#page-7-0)


    <span id="page-13-0"></span>Output


    two-fold approach. First, it is important for query designers to carefully document
    the query specification process, providing a clear explanation of the considered
    documents and domains. The primary objective should be to enhance empirical reliability,
    ensuring that the process is as reproducible as possible by others. Second and
    concerning generalizability, one should avoid using all the text under analysis
    for query development. This approach allows for the assessment of query generalizability
    on unseen text, resulting in a more credible evaluation. An even more robust strategy
    involves expanding the analysis beyond the immediate domain under study. For example,
    if the focus is on regulatory documents, it is common to derive queries in one
    legal jurisdiction, such as Europe, and subsequently evaluate query accuracy in
    texts from another jurisdiction, like Canada [\[43\]](#page-23-0). By adhering
    to these basic principles — detailed documentation of the query derivation process
    and assessments of generalizability — one can enhance the utility of query-based
    pattern matching techniques.


    #### Takeaway: Query-based Pattern Matching


    (1) When working with NLP annotations, select query language(s) that align with
    your specific analysis needs. (2) To ensure the reliability of query derivation,
    carefully document the steps you take to create the queries. This documentation
    should include the criteria, context, and content used for query design, making
    it easier for others to reproduce your work. (3) Refrain from using all the text
    you have for query development. To improve the applicability of your queries,
    evaluate their performance on unseen (or withheld) text or in different domains.


    ### <span id="page-14-0"></span>3.5 Feature-based Machine Learning


    Feature-based machine learning (ML) is concerned with using labelled data to train
    algorithms to make predictions based on predefined features. Feature-based ML
    has numerous applications in NLP4RE. For instance, it can be used for (1) categorizing
    input requirements as either functional or non-functional [\[27\]](#page-22-0),
    or (2) predicting the number of story points for user stories based on historical
    data [\[17\]](#page-21-9). The former application is a classification problem,
    entailing the assignment of discrete labels to data points ("functional" or "non-functional");
    whereas the latter scenario constitutes a regression problem as it involves estimating
    numeric values (story points).


    Building a feature-based ML model has five main steps. Below, we discuss these
    steps and outline some important practical considerations related to each step.


    - 1. Data collection involves gathering relevant and sufficient data, including
    the labelling process. This phase can be very time- and effort-intensive, particularly
    when manual labelling is required. To ensure consistency, it is crucial to define
    a clear and agreed-upon labelling task with protocols that annotators can consistently
    follow. To enhance internal validity, authors should avoid annotating their test
    data. When feasible, it is further important to employ multiple annotators with
    some overlap to enable the calculation of inter-annotator agreement. Detailed
    documentation of the data-collection protocol is essential for reliability [\[2,](#page-20-3)
    [3\]](#page-20-6).

    - 2. Data wrangling is concerned with handling missing data, noise removal (e.g.,
    stop words or redundant information), deciding about how to manage structured
    and unstructured data, and transforming results into the desired format. It is
    crucial to thoroughly document all techniques and decisions made in this step,
    as even minor changes can significantly impact the accuracy of the ML model [\[21\]](#page-21-10).

    - 3. Feature engineering is the process of defining relevant features for learning
    from the input data. In NLP4RE, features are usually defined over the outputs
    of the preprocessing techniques discussed in Sections [3.1–](#page-6-1)[3.3.](#page-10-0)
    For instance, a feature based on the NLP pipeline could be the number of verbs
    in a sentence. A feature using relevance measures might be the highest TF-IDF
    rank of a specific term across all articles in a corpus. Finally and in relation
    to embeddings, the components within an embedding vector can be regarded as features,
    as elaborated in Section [3.3.](#page-10-0)


    Features should be treated as hypotheses for addressing the problem at hand, and
    their usefulness must be evaluated. Techniques for computing feature importance,
    e.g., information gain [\[11\]](#page-21-11), and PCA analysis [\[1\]](#page-20-7),
    may be used for eliminating redundant or less significant features, thereby preventing
    overfitting. Feature engineering must also prioritize computational efficiency,
    particularly in real-time tasks such as live editing of requirements [\[2\]](#page-20-3),
    where almost instant feature computation is necessary. In such scenarios, certain
    computationally expensive features may need to be sacrificed, even if they offer
    marginal improvements. For example, the resource-intensive process of constituent
    parsing, despite its potential value, may prove impractical. Conducting a cost-effectiveness
    analysis, weighing the cost of computing each feature against its impact on the
    resulting ML model''s accuracy is therefore recommended.


    4. Model Selection, Tuning, and Training is concerned with choosing an appropriate
    ML algorithm, fine-tuning its hyperparameters, and training it over featureengineered
    data [\[22\]](#page-22-10). Initially, the computed feature data should be split
    into three sets: the training set (typically 70% of all the data), the validation
    set (usually 10% of the data) for model selection and hyperparameter optimization,
    and the test set (typically 20% of the data) to evaluate the trained ML model
    [\[39\]](#page-23-5). During dataset partitioning, it is paramount to avoid data
    leakage, which means avoiding any exposure of test set data during training and
    validation [\[42\]](#page-23-6). If the dataset covers multiple projects, it is
    advisable to ensure that the test set includes data from ''hold-out'' projects
    not involved in training or validation at all [\[39\]](#page-23-5).


    NLP4RE frequently encounters a scarcity of the kind of "abundant" data necessary
    for training complex ML algorithms, such as deep learning. In such instances,
    ML algorithms like Random Forest can provide scalable solutions, even when dealing
    with smaller datasets, noting of course that this advantage comes at the cost
    of requiring manual feature engineering.


    Model tuning is another vital step in the process. While hyperparameter optimization
    should theoretically be integrated with model selection, the number of combinations
    to evaluate when combining model selection and hyperparameter optimization can
    be exceedingly large [\[22\]](#page-22-10). For example, systematically exploring
    discrete values across key hyperparameters in the Random Forest algorithm can
    result in over 500 combinations. Given this challenge, a more practical approach
    would be to initially select a suitable ML algorithm by experimenting with multiple
    algorithms at their default settings, and then proceed to fine-tune the hyperparameters
    for the chosen algorithm. The choice of hyperparameter tuning strategy depends
    on available resources, such as an extensive grid search or a lightweight stochastic
    random search, for example.


    5. Evaluation involves assessing a trained ML model''s performance on a test set
    using metrics such as accuracy, precision, recall, F-score, and mean absolute
    error (MAE). Depending on the context, one can opt for "hold-out" test sets or
    k-fold crossvalidation. The selection and prioritization of metrics require special
    attention. For instance, in a binary classification task where 95% of samples
    belong to Class A and only 5% to Class B, a classifier exclusively predicting
    Class A would achieve 95% accuracy. Consequently, accuracy may not be a suitable
    metric when the dataset is imbalanced. Another notable point related to metrics
    is that, in NLP4RE, recall often outweighs precision in terms of importance, typically
    making recall a priority in solution development [\[13\]](#page-21-12). In relation
    to reporting, care needs to be taken when reporting aggregate metrics like F-score:
    such metrics should be reported alongside the source metrics (in this case, precision
    and recall) rather than as substitutes.


    Beyond reporting metrics, it is important to reflect on how these metrics translate
    into either benefits or drawbacks for users. For example, it is always valuable
    to contemplate the significance of various types of classification errors and
    determine their impact on users. When the cost of prediction errors is deemed
    too high, e.g., when the ML model''s predictions serve as recommendations requiring
    meticulous manual follow-up, one may consider implementing a human feedback loop
    to continuously retrain the model and reduce errors [\[8\]](#page-20-8).


    #### Takeaway: Feature-based ML


    Develop explicit procedures for manual data labelling during data collection and
    document these procedures. Keep track of data-wrangling decisions, as they can
    have a substantial impact on the outcomes. Approach features as hypotheses and
    confirm their significance before incorporating them into the final solution.
    Given the numerous combinations available for hyperparameter tuning during model
    selection and tuning, you may want to begin with experimentation using the default
    settings of machine learning algorithms. Ensure there is no data leakage, which
    means avoiding the inadvertent exposure of parts of test documents during the
    training and validation processes. The choice of evaluation metrics is of great
    importance and should be aligned with the specific NLP4RE task at hand.


    #### 3.6 Clustering Algorithms


    Clustering algorithms group similar data points into subsets or clusters to reveal
    patterns and structures within the data. This is achieved using a quantitative
    measure of similarity and ensuring that points in the same cluster are more similar
    to each other than to those in different clusters. In NLP4RE, relevance measures
    (Section [3.2\)](#page-8-0) and embeddings (Section [3.3\)](#page-10-0) are commonly
    used to compute similarity for clustering purposes. For instance, using GloVe
    embeddings, requirements statements can be transformed into vectors and then clustered
    using clustering algorithms such as Kmeans, agglomerative clustring or expectation
    maximization (EM) [\[46\]](#page-23-7). To illustrate, consider a system with
    six requirements: R1-R3 from Section [3.3](#page-10-0) and R4-R6 defined as follows:
    R4 = "The system shall allow users to customize the UI theme, available as ''dark''
    and ''light'' versions."; R5 = "The system shall allow users to sync data across
    multiple devices."; and R6 = "The system shall allow users to reset passwords
    only after email authentication.". Once sentence embeddings have been generated,
    cosine similarity between requirements pairs can be used as the basis for clustering.
    An illustrative clustering of these requirements, aimed at determining implementation
    responsibilities, might consist of [R1, R2] (system responsiveness), [R3, R6]
    (system protection), [R4] (system UI customization), and [R5] (system data management).
    Clustering has numerous applications in NLP4RE, including tasks such as traceability
    link retrieval, identifying overlapping or redundant requirements, and categorizing
    app reviews to pinpoint new feature requests. Below, we present some important
    practical considerations for an efficient utilization of clustering algorithms
    in NLP4RE.


    Determining the Number of Clusters (k). Choosing an appropriate number of clusters
    (k) is an important prerequisite for effectively applying many common clustering
    algorithms such as K-means and EM. Techniques like the Elbow method, Silhouette
    analysis, and Bayesian Information Criterion (BIC) can help estimate an appropriate
    k [\[46\]](#page-23-7). Another alternative is a recent summarization metric proposed
    in clustering app reviews [\[35\]](#page-23-8). Domain knowledge remains a key
    factor alongside these methods in deciding the number of clusters. The appropriate
    value of k is influenced by the task


    at hand and how users plan to utilize the resulting clusters. For instance, when
    clustering requirements terms, one may emphasize creating numerous small clusters,
    e.g., to simplify glossary construction [\[7\]](#page-20-1). On the other hand,
    when clustering core requirements within software product lines, it may be preferable
    to have a smaller number of clusters, as this streamlines the reviewing of common
    functions [\[40\]](#page-23-9).


    Hierarchical vs. Partitional vs. Soft Clustering. In partitional clustering algorithms,
    such as K-means, data is divided into non-overlapping clusters without any inherent
    structure. In contrast, hierarchical clustering creates a tree-like structure.
    Partitional methods are more suitable when the primary focus of the analysis is
    to rapidly identify overarching themes. For instance, Di Sorbo et al. [\[44\]](#page-23-10)
    adopt a partitional approach to categorize app reviews into pre-defined topics,
    determining the necessary changes in the apps according to user feedback. Hierarchical
    clustering, on the other hand, is better suited when there is a need to comprehend
    and visualize the relationships and nested structures within the dataset. For
    instance, Reinhartz-Berger and Kemelman [\[40\]](#page-23-9) use hierarchical
    clustering to explore the relationships between software product line requirements
    from different products by clustering the core requirements. It is worth noting
    that hierarchical clustering algorithms also provide mechanisms to create partitions.
    In soft clustering (also know as fuzzy clustering), each data point can belong
    to multiple clusters with varying degrees of membership. Soft clustering is ideal
    for situations where the boundaries between clusters are not rigidly defined,
    and instances may possess properties of multiple clusters. An example of this
    approach is the EM algorithm. An RE-related use case is clustering of requirements
    terms. In this context, it is beneficial to allow each term to have membership
    in different clusters [\[7\]](#page-20-1). For instance, the term "flight simulator"
    may find membership in both the "flight"-related and "simulator"-related clusters
    within a requirements document. Ultimately, the choice between partitional, hierarchical,
    or soft clustering depends on the specific task and analysis objectives at hand.
    Analysts should therefore understand the distinctions and potential applications
    of different types of clustering algorithms to ensure that their chosen algorithm
    aligns with the goals of their analysis.


    Evaluation. Cluster evaluation can be either internal or external. Internal evaluation
    assesses the quality of clusters without relying on external labels, focusing
    on the principles of cohesion and separation. Cohesion measures how closely related
    the members of the same cluster are, reflecting the compactness of the clusters,
    while separation assesses how distinct or well-separated a cluster is from others.
    A higher separation implies that clustering can more effectively distinguish between
    clusters. External evaluation, on the other hand, measures the quality of clusters
    by comparing them to a ground truth. This comparison can involve evaluating the
    overlap or mutual information between the original clusters and the generated
    ones. Developing a ground truth in clustering is challenging due to the inherent
    subjectivity of this task and its context dependence. Requirements and related
    artifacts can have multifaceted interpretations, leading to multiple valid ways
    of clustering based on different perspectives or objectives. Creating a good ground
    truth necessitates: (i) a clear understanding of the concept of clustering as
    well as the end goal to achieve, (ii) substantial time and effort, and (iii) vigilance
    against bias and inconsistency, as different experts may have


    contrasting opinions based on their experiences, potentially resulting in inconsistencies
    and posing threats to both internal and construct validity.


    #### Takeaway: Clustering Algorithms


    Important decisions in clustering include determining a suitable number of clusters
    (e.g., the Elbow method or Silhouette analysis), and opting between clustering
    types (partitional, hierarchical, or soft). The choice of clustering algorithm
    depends on the goal of the analysis and requires domain understanding. Evaluating
    the effectiveness of clustering is critical, which can be approached internally
    by assessing the cohesion and separation of clusters or externally by comparing
    against a ground truth. An external evaluation often poses challenges, as creating
    a ground truth for clustering is subjective and often requires substantial effort.


    ### 3.7 Large Language Models


    Language models (LMs) are statistical models that use neural networks to predict
    the next word in a sequence based on preceding words. For example, given the text
    "Paris is the capital of", a langauge model may predict the next word as "France".
    Language models increasingly serve as the foundation for various downstream NLP
    tasks such as text completion, translation, and summarization. Large language
    models (LLMs) like GPT-4 and BERT are scaled-up versions of the LM concept, with
    billions and sometimes even trillions of parameters. The descriptor "large" in
    LLM pertains to the model''s size in terms of the number of parameters. These
    parameters represent the neural network layers'' weights that the model acquires
    through training. Generally, larger models tend to perform better at comprehending
    context, drawing inferences and producing answers that resemble human responses.


    Hyperparameters. LLMs have a range of hyperparameters that can be adjusted during
    both training and fine-tuning. The hyperparameter profiles can vary among different
    LLMs, and the extent to which individual LLMs allow end-users to modify these
    hyperparameters also varies. Some common LLM hyperparameters include: (i) learning
    rate, determining how quickly the model adapts its weights during training; (ii)
    number of epochs, referring to how many times the model will go through the entire
    training dataset; (iii) batch size, denoting the number of training examples utilized
    in one iteration; (iv) sequence length, referring to the number of tokens that
    the model reads in one go; (v) dropout rate, referring to the fraction of input
    units to drop during training to mitigate overfitting; and (vi) temperature, a
    parameter that modulates the probability distribution over the predicted words,
    making the outputs more focused (lower values) or more random (higher values).


    Extensive experimentation across a broad range of LLM hyperparameter combinations
    currently presents challenges due to constraints in both time and budget. Nevertheless,
    it remains essential to select a practical subset of hyperparameter combinations
    that can be explored within the available resources. This approach enables a more
    informed understanding of how hyperparameters influence the performance of an
    LLM in conducting a specific task.


    Prompting. Prompting refers to providing a specific input or query to guide a
    generative AI model in producing the desired output, such as text or images [\[25\]](#page-22-11).
    Prompts, which are concise textual inputs given to generative AI models, including
    LLMs, convey information about the specific task that the model is expected to
    execute.


    Creating prompts that are effective in eliciting the desired output from an LLM
    requires good prompt engineering. Prompt engineering involves the selection of
    appropriate prompt patterns and prompting techniques [\[45\]](#page-23-11). Prompt
    patterns encompass various templates tailored for specific objectives. For example,
    the output customization pattern focuses on refining the format or structure of
    LLM-generated output, with the LLM often adopting a particular persona (role)
    while generating the output. Prompting techniques, on the other hand, are strategies
    to extract the best possible output from LLMs. Example prompting techniques include
    zero-shot prompting, few-shot prompting, chain-of-thought prompting, and tree-of-thought
    prompting [\[29\]](#page-22-12).


    When conducting empirical examinations of LLM-based solutions, it is important
    to take into account the alternative choices that one can make during prompt engineering.
    These alternatives should ideally be compared through empirical means. Nonetheless,
    much like the challenges encountered when exploring hyperparameters, the vast
    array of possible combinations of prompt patterns and prompting strategies may
    be too numerous to thoroughly investigate. Another important aspect to consider
    is that even minor alterations in prompts can lead to considerable variation in
    the outputs generated by LLMs. In view of this, empirical studies should also
    assess prompt robustness by examining multiple variants of the same prompt.


    Fine-tuning. While LLMs come pre-trained on very large corpora, they often require
    some level of fine-tuning to specialize them for particular tasks or domains.
    When the requirements automation task at hand aligns closely with common knowledge,
    such as ambiguity handling, one might achieve good results with little or no fine-tuning.
    However, if the task is specialized and involves RE-specific semantics, such as
    requirements classifications, fine-tuning often becomes necessary to ensure accurate
    results. When fine-tuning an LLM, one needs to be cognizant of the non-deterministic
    nature of the process, which is influenced by factors such as random initialization
    and regularization. Depending on the extent and diversity of the fine-tuning data,
    significant variations may be observed in results across different fine-tuning
    attempts. To account for this randomness, we recommend fine-tuning LLMs multiple
    times and reporting average results rather than relying on the outcome of a single
    fine-tuned model.


    #### Takeaway: Large Language Models


    When working with LLMs, explore hyperparameters within resource constraints. Invest
    in prompt engineering, using suitable prompt patterns and techniques, and empirically
    compare different alternatives. Take note of the non-deterministic nature of fine-tuning,
    and present results averaged over multiple fine-tuning runs.


    # <span id="page-20-4"></span>4 Summary and Conclusion


    The main goal of this chapter was to aid newcomers in the selection of appropriate
    NLP4RE techniques and the application of some essential principles for their evaluation.
    We acknowledge the wide array of NLP technologies employed in RE. Not all NLP4RE
    approaches may neatly align with the general, and sometimes simplified, framework
    we have outlined in this chapter.


    This chapter was written during a transformative period in the NLP field, spurred
    by the emergence of generative AI and large language models. We hope that this
    chapter can serve as a stepping stone for quickly grasping the NLP technologies
    most relevant to RE. With both the NLP and RE landscapes constantly evolving,
    our hope is to maintain this chapter as a living document, continuously integrating
    emerging trends and pertinent techniques for automated requirements analysis.


    Acknowledgements.The first author is grateful for the financial support provided
    by the Natural Sciences and Engineering Research Council of Canada (NSERC) through
    the Discovery and Discovery Accelerator programs.


    # References


    - <span id="page-20-7"></span>[1] Abdi H, Williams LJ (2010) Principal component
    analysis. Wiley interdisciplinary reviews: computational statistics 2(4):433–459.
    URL [https://api.semanticscholar.](https://api.semanticscholar.org/CorpusID:122379222)
    [org/CorpusID:122379222](https://api.semanticscholar.org/CorpusID:122379222)

    - <span id="page-20-3"></span>[2] Abualhaija S, Arora C, Sabetzadeh M, et al (2020)
    Automated demarcation of requirements in textual specifications: a machine learning-based
    approach. Empirical Software Engineering 25(6):5454–5497. [https://doi.org/10.](https://doi.org/10.1007/S10664-020-09864-1)
    [1007/S10664-020-09864-1](https://doi.org/10.1007/S10664-020-09864-1)

    - <span id="page-20-6"></span>[3] Abualhaija S, Arora C, Sleimi A, et al (2022)
    Automated question answering for improved understanding of compliance requirements:
    A multi-document study. In: 30th IEEE International Requirements Engineering Conference,
    RE, pp 39–50, <https://doi.org/10.1109/RE54965.2022.00011>

    - <span id="page-20-5"></span>[4] Apache OpenNLP (2006) Apache. URL [http://opennlp.apache.org,](http://opennlp.apache.org)
    last accessed: October 2023

    - <span id="page-20-0"></span>[5] Arora C, Sabetzadeh M, Briand L, et al (2015)
    Automated checking of conformance to requirements templates using natural language
    processing. IEEE Trans Software Eng 41(10):944–968. <https://doi.org/10.1109/tse.2015.2428709>

    - <span id="page-20-2"></span>[6] Arora C, Sabetzadeh M, Briand L, et al (2016)
    Extracting domain models from natural-language requirements: approach and industrial
    evaluation. In: Baudry B, Combemale B (eds) Proceedings of the ACM/IEEE 19th International
    Conference on Model Driven Engineering Languages and Systems, MODELS, pp 250–260,
    <https://doi.org/10.1145/2976767.2976769>

    - <span id="page-20-1"></span>[7] Arora C, Sabetzadeh M, Briand L, et al (2017)
    Automated extraction and clustering of requirements glossary terms. IEEE Trans
    Software Eng 43(10):918–945. <https://doi.org/10.1109/tse.2016.2635134>

    - <span id="page-20-8"></span>[8] Arora C, Sabetzadeh M, Briand LC (2019) An empirical
    study on the potential usefulness of domain models for completeness checking of
    requirements. Empir Softw Eng 24(4):2509–2539. <https://doi.org/10.1007/S10664-019-09693-X>

    - <span id="page-21-2"></span>[9] Arora C, Grundy J, Abdelrazek M (2023) Advancing
    requirements engineering through generative ai: Assessing the role of LLMs. CoRR
    abs/2310.13976. [https:](https://doi.org/10.48550/ARXIV.2310.13976) [//doi.org/10.48550/ARXIV.2310.13976](https://doi.org/10.48550/ARXIV.2310.13976)

    - <span id="page-21-7"></span>[10] Arora S, Liang Y, Ma T (2017) A simple but
    tough-to-beat baseline for sentence embeddings. In: 5th International Conference
    on Learning Representations, ICLR, URL <https://openreview.net/forum?id=SyK00v5xx>

    - <span id="page-21-11"></span>[11] Azhagusundari B, Thanamani AS, et al (2013)
    Feature selection based on information gain. International Journal of Innovative
    Technology and Exploring Engineering 2(2):18–21. URL <https://api.semanticscholar.org/CorpusID:212611078>

    - <span id="page-21-5"></span>[12] Baeza-Yates RA, Ribeiro-Neto B (1999) Modern
    information retrieval. Addison-Wesley Longman Publishing Co., Inc., USA, <https://doi.org/10.5555/553876>

    - <span id="page-21-12"></span>[13] Berry DM (2021) Empirical evaluation of tools
    for hairy requirements engineering tasks. Empir Softw Eng 26(5):111. <https://doi.org/10.1007/S10664-021-09986-0>

    - <span id="page-21-4"></span>[14] de Castilho RE, Gurevych I (2014) A broad-coverage
    collection of portable NLP components for building shareable analysis pipelines.
    In: Ide N, Grivolla J (eds) Proceedings of the Workshop on Open Infrastructures
    and Analysis Frameworks for HLT, OIAF4HLT@COLING, pp 1–11, <https://doi.org/10.3115/V1/W14-5201>

    - <span id="page-21-8"></span>[15] Chalkidis I, Fergadiotis M, Malakasiotis P,
    et al (2020) LEGAL-BERT: the muppets straight out of law school. CoRR abs/2010.02559.
    URL [https://arxiv.org/](https://arxiv.org/abs/2010.02559) [abs/2010.02559](https://arxiv.org/abs/2010.02559)

    - <span id="page-21-3"></span>[16] Chen B, Chen K, Hassani S, et al (2023) On
    the use of GPT-4 for creating goal models: An exploratory study. In: Schneider
    K, Dalpiaz F, Horkoff J (eds) 31st IEEE International Requirements Engineering
    Conference, RE, Workshops, pp 262–271, <https://doi.org/10.1109/REW57809.2023.00052>

    - <span id="page-21-9"></span>[17] Choetkiertikul M, Dam HK, Tran T, et al (2019)
    A deep learning model for estimating story points. IEEE Trans Software Eng 45(7):637–656.
    [https://doi.](https://doi.org/10.1109/TSE.2018.2792473) [org/10.1109/TSE.2018.2792473](https://doi.org/10.1109/TSE.2018.2792473)

    - <span id="page-21-6"></span>[18] Devlin J, Chang M, Lee K, et al (2019) BERT:
    pre-training of deep bidirectional transformers for language understanding. In:
    Burstein J, Doran C, Solorio T (eds) Proceedings of the 2019 Conference of the
    North American Chapter of the Association for Computational Linguistics: Human
    Language Technologies, NAACL-HLT, pp 4171–4186, <https://doi.org/10.18653/V1/N19-1423>

    - <span id="page-21-0"></span>[19] Ezzini S, Abualhaija S, Arora C, et al (2022)
    Automated handling of anaphoric ambiguity in requirements: A multi-solution study.
    In: XXXX (ed) 44th IEEE/ACM 44th International Conference on Software Engineering,
    ICSE, pp 187–199, <https://doi.org/10.1145/3510003.3510157>

    - <span id="page-21-1"></span>[20] Ezzini S, Abualhaija S, Arora C, et al (2023)
    AI-based question answering assistance for analyzing natural-language requirements.
    In: XXXX (ed) 45th IEEE/ACM International Conference on Software Engineering,
    ICSE, pp 1277–1289, <https://doi.org/10.1109/ICSE48619.2023.00113>

    - <span id="page-21-10"></span>[21] Fan Y, Arora C, Treude C (2023) Stop words
    for processing software engineering documents: Do they matter? In: 2nd IEEE/ACM
    International Workshop on Natural Language-Based Software Engineering, NLBSE@ICSE.
    IEEE, pp 40–47, <https://doi.org/10.1109/NLBSE59153.2023.00016>


    - <span id="page-22-10"></span>[22] Feurer M, Hutter F (2019) Hyperparameter Optimization,
    Springer International Publishing, Cham, pp 3–33. [https://doi.org/10.1007/978-3-030-05318-5](https://doi.org/10.1007/978-3-030-05318-5_1)
    1

    - <span id="page-22-3"></span>[23] GATE NLP Workbench (2020) GATE. URL [http://gate.ac.uk/,](http://gate.ac.uk/)
    last accessed: October 2023

    - <span id="page-22-5"></span>[24] Gomaa WH, Fahmy AA (2013) A survey of text
    similarity approaches. International Journal of Computer Applications 68(13):13–18.
    [https://doi.org/10.5120/](https://doi.org/10.5120/11638-7118) [11638-7118](https://doi.org/10.5120/11638-7118)

    - <span id="page-22-11"></span>[25] Hariri W (2023) Unlocking the potential of
    chatgpt: A comprehensive exploration of its applications, advantages, limitations,
    and future directions in natural language processing. CoRR abs/2304.02017. [https://doi.org/10.48550/ARXIV.2304.](https://doi.org/10.48550/ARXIV.2304.02017)
    [02017](https://doi.org/10.48550/ARXIV.2304.02017)

    - <span id="page-22-1"></span>[26] Jain C, Anish PR, Singh A, et al (2023) A transformer-based
    approach for abstractive summarization of requirements from obligations in software
    engineering contracts. In: Schneider K, Dalpiaz F, Horkoff J (eds) Proceedings
    of the 31st IEEE International Requirements Engineering Conference, (RE''23),
    pp 169–179, <https://doi.org/10.1109/RE57278.2023.00025>

    - <span id="page-22-0"></span>[27] Kurtanovic Z, Maalej W (2017) Automatically
    classifying functional and nonfunctional requirements using supervised machine
    learning. In: Moreira A, Ara´ujo J, Hayes J, et al (eds) 25th IEEE International
    Requirements Engineering Conference, RE, pp 490–495, <https://doi.org/10.1109/RE.2017.82>

    - <span id="page-22-7"></span>[28] Lee J, Yoon W, Kim S, et al (2020) Biobert:
    a pre-trained biomedical language representation model for biomedical text mining.
    Bioinform 36(4):1234–1240. <https://doi.org/10.1093/BIOINFORMATICS/BTZ682>

    - <span id="page-22-12"></span>[29] Liu P, Yuan W, Fu J, et al (2023) Pre-train,
    prompt, and predict: A systematic survey of prompting methods in natural language
    processing. ACM Comput Surv 55(9):195:1–195:35. <https://doi.org/10.1145/3560815>

    - <span id="page-22-8"></span>[30] L´opez JAH, Dur´a C, Cuadrado JS (2023) Word
    embeddings for model-driven engineering. In: 2023 ACM/IEEE 26th International
    Conference on Model Driven Engineering Languages and Systems (MODELS), pp 151–161,
    [https://doi.org/](https://doi.org/10.1109/MODELS58315.2023.00036) [10.1109/MODELS58315.2023.00036](https://doi.org/10.1109/MODELS58315.2023.00036)

    - <span id="page-22-2"></span>[31] Luitel D, Hassani S, Sabetzadeh M (2023) Using
    language models for enhancing the completeness of natural-language requirements.
    In: Ferrari A, Penzenstadler B (eds) Requirements Engineering: Foundation for
    Software Quality - 29th International Working Conference, REFSQ, pp 87–104, [https://doi.org/10.1007/](https://doi.org/10.1007/978-3-031-29786-1_7)
    [978-3-031-29786-1](https://doi.org/10.1007/978-3-031-29786-1_7) 7

    - <span id="page-22-4"></span>[32] Manning CD, Surdeanu M, Bauer J, et al (2014)
    The stanford corenlp natural language processing toolkit. In: Proceedings of the
    52nd Annual Meeting of the Association for Computational Linguistics, ACL, pp
    55–60, [https://doi.org/10.](https://doi.org/10.3115/V1/P14-5010) [3115/V1/P14-5010](https://doi.org/10.3115/V1/P14-5010)

    - <span id="page-22-9"></span>[33] Mavin A (2012) Listen, then use EARS. IEEE
    Softw 29(2):17–18. [https://doi.](https://doi.org/10.1109/MS.2012.36) [org/10.1109/MS.2012.36](https://doi.org/10.1109/MS.2012.36)

    - <span id="page-22-6"></span>[34] Mikolov T, Chen K, Corrado G, et al (2013)
    Efficient estimation of word representations in vector space. In: Bengio Y, LeCun
    Y (eds) 1st International Conference on Learning Representations, ICLR, URL <http://arxiv.org/abs/1301.3781>

    - <span id="page-23-8"></span>[35] Nema P, Anthonysamy P, Taft N, et al (2022)
    Analyzing user perspectives on mobile app privacy at scale. In: 44th IEEE/ACM
    44th International Conference on Software Engineering, ICSE, pp 112–124, [https://doi.org/10.1145/3510003.](https://doi.org/10.1145/3510003.3510079)
    [3510079](https://doi.org/10.1145/3510003.3510079)

    - <span id="page-23-3"></span>[36] Pennington J, Socher R, Manning CD (2014) Glove:
    Global vectors for word representation. In: Moschitti A, Pang B, Daelemans W (eds)
    Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing,
    EMNLP, pp 1532–1543, <https://doi.org/10.3115/V1/D14-1162>

    - <span id="page-23-2"></span>[37] Princeton University (2010) About WordNet.
    URL [https://wordnet.princeton.](https://wordnet.princeton.edu/) [edu/,](https://wordnet.princeton.edu/)
    last accessed: March 2019

    - <span id="page-23-4"></span>[38] Radford A, Narasimhan K, Salimans T, et al
    (2018) Improving language understanding by generative pre-training. OpenAI URL
    [https://api.semanticscholar.](https://api.semanticscholar.org/CorpusID:49313245)
    [org/CorpusID:49313245](https://api.semanticscholar.org/CorpusID:49313245)

    - <span id="page-23-5"></span>[39] Raschka S (2018) Model evaluation, model selection,
    and algorithm selection in machine learning. CoRR abs/1811.12808. URL <http://arxiv.org/abs/1811.12808>

    - <span id="page-23-9"></span>[40] Reinhartz-Berger I, Kemelman M (2020) Extracting
    core requirements for software product lines. Requir Eng 25(1):47–65. [https://doi.org/10.1007/](https://doi.org/10.1007/S00766-018-0307-0)
    [S00766-018-0307-0](https://doi.org/10.1007/S00766-018-0307-0)

    - <span id="page-23-1"></span>[41] Salda˜na J (2015) The coding manual for qualitative
    researchers. Sage Publications, Thousand Oaks, CA, USA, URL [https://us.sagepub.com/en-us/nam/](https://us.sagepub.com/en-us/nam/the-coding-manual-for-qualitative-researchers/book273583)
    [the-coding-manual-for-qualitative-researchers/book273583](https://us.sagepub.com/en-us/nam/the-coding-manual-for-qualitative-researchers/book273583)

    - <span id="page-23-6"></span>[42] Shabtai A, Elovici Y, Rokach L (2012) A Survey
    of Data Leakage Detection and Prevention Solutions. Springer, <https://doi.org/10.1007/978-1-4614-2053-8>

    - <span id="page-23-0"></span>[43] Sleimi A, Sannier N, Sabetzadeh M, et al (2021)
    An automated framework for the extraction of semantic legal metadata from legal
    texts. Empir Softw Eng 26(3):43. <https://doi.org/10.1007/S10664-020-09933-5>

    - <span id="page-23-10"></span>[44] Sorbo AD, Panichella S, Alexandru CV, et al
    (2016) What would users change in my app? summarizing app reviews for recommending
    software changes. In: Zimmermann T, Cleland-Huang J, Su Z (eds) Proceedings of
    the 24th ACM SIG-SOFT International Symposium on Foundations of Software Engineering,
    FSE, pp 499–510, <https://doi.org/10.1145/2950290.2950299>

    - <span id="page-23-11"></span>[45] White J, Fu Q, Hays S, et al (2023) A prompt
    pattern catalog to enhance prompt engineering with chatgpt. CoRR abs/2302.11382.
    [https://doi.org/10.](https://doi.org/10.48550/ARXIV.2302.11382) [48550/ARXIV.2302.11382](https://doi.org/10.48550/ARXIV.2302.11382)

    - <span id="page-23-7"></span>[46] Witten IH, Frank E, Hall MA (2011) Data mining:
    practical machine learning tools and techniques, 3rd Edition. Morgan Kaufmann,
    Elsevier, URL [https://](https://www.worldcat.org/oclc/262433473) [www.worldcat.org/oclc/262433473](https://www.worldcat.org/oclc/262433473)'
- title: "Which Syntactic Capabilities Are Statistically Learned by Masked\n  Language\
    \ Models for Code?"
  abstract: 'This paper discusses the limitations of evaluating Masked Language Models

    (MLMs) in code completion tasks. We highlight that relying on accuracy-based

    measurements may lead to an overestimation of models'' capabilities by

    neglecting the syntax rules of programming languages. To address these issues,

    we introduce a technique called SyntaxEval in which Syntactic Capabilities are

    used to enhance the evaluation of MLMs. SyntaxEval automates the process of

    masking elements in the model input based on their Abstract Syntax Trees

    (ASTs). We conducted a case study on two popular MLMs using data from GitHub

    repositories. Our results showed negative causal effects between the node types

    and MLMs'' accuracy. We conclude that MLMs under study fail to predict some

    syntactic capabilities.'
  url: http://arxiv.org/abs/2401.01512v2
  keywords: ''
  document: '# Which Syntactic Capabilities Are Statistically Learned by Masked Language
    Models for Code?


    Alejandro Velasco, David N. Palacio, Daniel Rodriguez-Cardenas and Denys Poshyvanyk


    {svelascodimate,danaderpalacio,dhrodriguezcar,dposhyvanyk}@wm.edu


    William & Mary


    Williamsburg, Virginia, USA


    #### ABSTRACT


    This paper discusses the limitations of evaluating Masked Language Models (MLMs)
    in code completion tasks. We highlight that relying on accuracy-based measurements
    may lead to an overestimation of models'' capabilities by neglecting the syntax
    rules of programming languages. To address these issues, we introduce a technique
    called SyntaxEval in which Syntactic Capabilities are used to enhance the evaluation
    of MLMs. SyntaxEval automates the process of masking elements in the model input
    based on their Abstract Syntax Trees (ASTs). We conducted a case study on two
    popular MLMs using data from GitHub repositories. Our results showed negative
    causal effects between the node types and MLMs'' accuracy. We conclude that MLMs
    under study fail to predict some syntactic capabilities.


    #### CCS CONCEPTS


    #### • Software and its engineering → Software maintenance tools.


    #### KEYWORDS


    deep learning, code generation, interpretability, transformers, dl4se


    #### ACM Reference Format:


    Alejandro Velasco, David N. Palacio, Daniel Rodriguez-Cardenas and Denys Poshyvanyk.
    2024. Which Syntactic Capabilities Are Statistically Learned by Masked Language
    Models for Code? . In New Ideas and Emerging Results (ICSE-NIER''24), April 14–20,
    2024, Lisbon, Portugal. ACM, New York, NY, USA, [5](#page-4-0) pages.<https://doi.org/10.1145/3639476.3639768>


    #### 1 INTRODUCTION


    Large language models have illustrated convincing performance across a range of
    different software engineering (SE) tasks [\[5,](#page-4-1) [7,](#page-4-2) [23,](#page-4-3)
    [35,](#page-4-4) [36,](#page-4-5) [39](#page-4-6)[–41\]](#page-4-7). In particular,
    code generation has been an important area of research for SE tasks such as code
    completion [\[8\]](#page-4-8). Code completion is a disciplined technique for
    generating missing syntactic features of an incomplete snippet based on its semantic
    and structural context [\[4\]](#page-4-9). These syntactic features usually adopt
    the form of identifiers, function names, conditionals, or parameters depending
    on the granularity of the snippet. Software researchers are particularly interested
    in improving code completion to optimize time spent during the development and
    maintenance cycles [\[12,](#page-4-10) [13\]](#page-4-11). Numerous studies have
    investigated code completion automation


    ICSE-NIER''24, April 14–20, 2024, Lisbon, Portugal


    © 2024 Copyright held by the owner/author(s).


    ACM ISBN 979-8-4007-0500-7/24/04.


    <https://doi.org/10.1145/3639476.3639768>


    using machine learning [\[4,](#page-4-9) [15,](#page-4-12) [28,](#page-4-13) [42\]](#page-4-14).
    Current research has focused on exploiting deep learning representations using
    LSTMs [\[33\]](#page-4-15), GPT [\[32\]](#page-4-16), RoBERTa [\[20\]](#page-4-17),
    and T5 [\[6,](#page-4-18) [9\]](#page-4-19).


    Masked Language Models (MLMs) have been recently used for code completion tasks
    demonstrating promising results (an avg. accuracy of 38.7% in perfect predictions)
    at different masking levels (i.e., Token, Construct, and Block) [\[6\]](#page-4-18).
    Some studies suggest that MLMs statistically learn the underlying structure of
    Abstract Syntax Trees (ASTs) at certain degree [\[19,](#page-4-20) [24,](#page-4-21)
    [37\]](#page-4-22). Yet, given the high accuracy achieved by MLMs [\[6\]](#page-4-18),
    few attempts have been made to investigate the role of Syntactic Capabilities
    for evaluating code completion. Syntactic Capabilities are interpretable prediction
    estimates for a terminal () and non-terminal (Σ) nodes of ASTs that are ruled
    by a Context Free Grammar (CFG) of Programming Languages (PLs) [\[31\]](#page-4-23).


    To date, the primary focus on evaluating MLMs has been on the role of accuracy
    as the principal metric, which may lead to erroneous and/or incomplete interpretation
    of the syntactic features embedded in neural architectures [\[25,](#page-4-24)
    [27,](#page-4-25) [37\]](#page-4-22). Relatively little is understood about incorporating
    these interpretable prediction estimates into the evaluation of MLMs, hence current
    evaluation methods do not help practitioners to decide whether MLMs are confidently
    generating code at AST node granularity and to what extent these syntactic features
    affect general prediction performance. That is, these methods do not reveal information
    about syntactic capabilities and their causal effects on the overall MLMs performance.


    Our study attempts to establish the causal connection between syntactic features
    in the form of AST node types and MLMs'' performance. Under this premise, we introduce
    SyntaxEval, an approach that leverages syntactic capabilities to evaluate how
    good MLMs infer and Σ AST nodes of a given PL. When evaluating the performance
    of an MLM, SyntaxEval selectively masks tokens according to the AST Node types
    defined by the CFG. Subsequently, an MLM predicts the masked tokens. Finally,
    SyntaxEval measures the causal effect of AST node types on code completion performance.


    Our results suggest that although MLMs are homogeneously predicting individual
    AST node types with high accuracy, we observed no evidence of effects from syntactic
    features on MLMs'' prediction after controlling for confounding factors. Hence,
    no causal evidence supports the fact that MLMs are statistically learning syntactic
    structures with acceptable confidence, contradicting recent studies in the explainability
    field [\[24,](#page-4-21) [37\]](#page-4-22). We hope that the results of our
    work will shed more light on the syntactic capabilities of current MLMs to enable
    a more systematic and rigorous evaluation of code completion tasks. The contributions
    of this paper are as follows: 1) a technique for evaluating the extent to which
    MLMs


    Permission to make digital or hard copies of part or all of this work for personal
    or classroom use is granted without fee provided that copies are not made or distributed
    for profit or commercial advantage and that copies bear this notice and the full
    citation on the first page. Copyrights for third-party components of this work
    must be honored. For all other uses, contact the owner/author(s).


    predict AST structures; 2) a case study that leverages causal analysis to understand
    how different AST node types influence code completion; 3) experimental data,
    curated datasets, source code, and complementary statistical analysis used in
    this research are published in an open-source repository [\[1\]](#page-4-26).


    #### 2 BACKGROUND & RELATED WORK


    The accurate identification and generation of code tokens is a widely studied
    field at the intersection of SE and DL [\[38\]](#page-4-27). State-of-the-art
    code generators estimate the token prediction using probabilistic distribution
    (i.e., a Large Language Model (LLMs)) obtained by training on large amounts of
    code corpora. Put simply, code completion models should statistically approximate
    the production rules defined by the CFG. These production rules are recursively
    applied to terminal and non-terminal Σ nodes to formally define the structure
    of a PL. For instance, recent explainability studies have claimed that the syntactic
    structures of code are encapsulated in the internal layers of LLMs across software
    tasks, implying a foundational statistical comprehension of code semantics [\[14,](#page-4-28)
    [37\]](#page-4-22). In this section, we introduce the concept of MLMs and their
    current evaluation methods.


    Masked Language Models for Code. Considerable research attention has been directed
    toward the usage of Bidirectional Encoder Representation from Transformers (BERT)
    on code completion as an attempt to push the predictability boundaries beyond
    the next token prediction. BERT allows higher granularity syntax structures (i.e.,
    entire code statement) to be generated using self-attention layers trained to
    restore a masked subset of tokens in the input [\[6,](#page-4-18) [10\]](#page-4-29).
    This peculiar form of training the architecture is known as denoising autoencoding,
    or Masked Language Models (MLM), which we formalize as () = E∈E <sup>⊂</sup> hÍ
    <sup>∈</sup> log ( |˜) i , || = |()|, where a masking rate (usually 15%) is applied
    on the original sequence of a training corpus . The model attempts to predict
    the set of masked tokens given the corrupted context ˜ (the masked version of
    ) [\[18\]](#page-4-30). MLMs for code completion are mostly evaluated using metrics
    such as CodeBleu, EM, F1, and Pass@k [\[16\]](#page-4-31).


    Syntax-Based Evaluation of MLMs. Due to the unpredictable behavior of MLMs while
    generating tokens, explainability techniques are complementary evaluative methods
    for understanding the decision-making process by reducing the uncertainty of the
    models. Such uncertainty can be controlled by exploring the inner layers of the
    neural net or performing guided perturbations on models'' input [\[3\]](#page-4-32).
    Recent studies have explored the use of structural information as an interpretability
    tool for pre-trained models for code [\[25\]](#page-4-24). For instance, Wan et
    al. [\[37\]](#page-4-22) conducted an explainability analysis focusing on three
    aspects: 1) how the self-attention weights align with the syntax structure, 2)
    whether the syntax structure is encoded in the hidden layers, and 3) how pre-trained
    models induce syntax structures. Similarly, Mohammadkhani et al. [\[24\]](#page-4-21)
    propose an eXplainable AI method (attention mechanism) on three downstream code
    tasks: 1) code generation, 2) refinement, and 3) translation. Previous findings
    imply that Encoder-based models can effectively extract detailed syntactic information
    using selfattention mechanisms. We used prior observations about encoded information
    of ASTs to formulate an evaluative approach based


    <span id="page-1-0"></span>![](_page_1_Figure_7.jpeg)


    Figure 1: SyntaxEval Process for the identifier AST Node.


    on measuring the prediction performance of syntactic capabilities directly from
    (non)terminal nodes.


    #### 3 SYNTACTIC CAUSAL EVALUATION


    SyntaxEval is an evaluative approach organized into two distinct parts. The first
    part estimates a fine-grained performance, grouped by AST node types, for a given
    MLM ([RQ](#page-2-0)1). The second part adopts causal interpretability theory
    to quantify the influence of previously estimated AST node types on the accuracy
    of the model ([RQ](#page-2-1)2).


    Evaluating Syntactic Capabilities. Fig. [1](#page-1-0) depicts the process of
    evaluating syntactic capabilities for code completion using MLMs. This evaluative
    process is comprised of five steps. Firstly, we must define a set of AST node
    types to be analyzed. This set of AST node types is ruled by Python CFG adopting
    the form of = ∪ Σ. Then we search for the positions of these node types in the
    code sequence after iterating for each sample (i.e., snippet) of a given ground
    truth (Fig. [1-](#page-1-0) 1 ). Secondly, detected tokens, which correspond to
    the previously defined set , are masked with the label <mask> (Fig. [1-](#page-1-0)
    2 ). Thirdly, we use an MLM to infer the masked tokens for each sample obtaining
    a set ¯ of predicted samples¯ . Fourthly, we parse the AST of and ¯ to generate
    a list of extracted nodes for the ground truth and predicted samples using the
    in-order traversal algorithm (Fig. [1-](#page-1-0) 4 ). Finally, we compare both
    ground truth and predicted ¯ lists of extracted nodes by computing three similarity
    metrics for each sample (i.e., Jaccard, Levenshtein & Sorensen-Dice) (Fig. [1-](#page-1-0)
    5 ).


    Computing Causal Interpretability. Causal Inference has been adopted to complement
    the assessment of LLMs by controlling for confounding factors in code data. Palacio
    et al. [\[25\]](#page-4-24) introduce , a post hoc interpretability methodology
    that explains model predictions by providing causal explanations. These explanations
    are generated by estimating the effect of binary interventions , such as masking
    random tokens <sup>0</sup> versus masking AST node types 1, on MLMs'' performance.
    Specifically, in SyntaxEval, the treatment <sup>1</sup> refers to samples that
    are masked on AST node tokens , while the control <sup>0</sup> refers to samples
    that are randomly masked on any position. The control <sup>0</sup> preserves the
    same number of masked tokens as in 1.


    SyntaxEval formulates a Structural Causal Model (SCM), which is a graphical model
    composed of outcomes, treatments, and confounders [\[26\]](#page-4-33), to explain
    a set of potential outcomes (e.g., Jaccard, Levenshtein, Sorensen-Dice) in terms
    of treatments (i.e., <span id="page-2-2"></span>Which Syntactic Capabilities Are
    Statistically Learned by Masked Language Models for Code? ICSE-NIER''24, April
    14–20, 2024, Lisbon, Portugal


    Table 1: Evaluated Encoder-Based Transformers.


    | Id | MLM                     | Size | Layers | Vocab. |

    |----|-------------------------|------|--------|--------|

    | 𝑀1 | CodeBERTa-small-v1 [21] | 84M  | 6      | 52,000 |

    | 𝑀2 | codebert-base-mlm [11]  | 125M | 12     | 50,265 |


    masked AST node types) by controlling for a set of code confounders to avoid spurious
    correlations. These code confounders consist of seven variables, which include
    the # of parsing errors, the height of the AST, the # of nodes, the # of whitespaces,
    the # of lines of codes, the cyclo complexity, and the token counts. Finally,
    SyntaxEval computes the Average Treatment Effect () of a treatment has on the
    outcomes after controlling for confounders . In other words, we want to estimate
    the expected value = E[ ()] = E[ | (1)] − E[ | (0)] = E[<sup>1</sup> − 0]. The
    variables 1, <sup>0</sup> refer to potential outcomes observed under the treatments
    1,0. For the sake of brevity, we do not discuss the details of treatment effects
    computations. However, these effects are approximated using propensity score methods
    after applying the the back-door criterion [\[30\]](#page-4-36).


    #### 4 CASE STUDY DESIGN


    This section outlines the methodology employed to consider the potential influence
    of syntactic capabilities on the evaluation of MLMs, we conducted a case study
    on two popular architectures to explore the following RQs:


    - <span id="page-2-0"></span>RQ1 [Performance] How good are MLMs at predicting
    AST nodes?

    - <span id="page-2-1"></span>RQ2 [Causality] How do node types impact MLMs'' performance?


    Data Collection: To mitigate the risk of data snooping, we curated our testbed
    with 50 Python snippets. This testbed exclusively comprises commits executed between
    January 01, 2022 and January 01, 2023. We collected the snippets from newly added
    or updated Python Github repositories with over 1k stars scoring. Additionally,
    we discarded duplicated samples by referring to the history of the commits. The
    testbed also contains complementary code features (e.g., LoC, CYCLO, and # of
    nodes), these features were extracted using Galeras pipeline [\[29\]](#page-4-37).
    Masked Language Models: We evaluated two encoder-based transformers trained on
    CodeSearchNet [\[17\]](#page-4-38) with different hyperparameters (see Tab. [1\)](#page-2-2).
    These encoders have been assessed in prior studies in which they were found to
    capture structural information [\[37\]](#page-4-22), [\[37\]](#page-4-22), and
    [\[24\]](#page-4-21). Node Types: Tree-sitter CFG defines 196 AST node types for
    Python. For the sake of simplicity, we selected a subset of terminal and non-terminal
    nodes defined in Python''s CFG as depicted in the first column of Tab. [2.](#page-3-0)
    The subset entails the most basic syntactic structures for control, iteration,
    operators, and functional programming. This study showcases the nodes that exhibited
    the most interesting behavior. We chose Python for code completion experiments
    due to its extended use in recent studies.


    Evaluation Methodology. To address [RQ](#page-2-0)1, we estimated syntactic capabilities
    of <sup>1</sup> and <sup>2</sup> encoders using 8 randomly selected samples from
    the collected testbed. SyntaxEval masks the associated tokens for each chosen
    node type (1) and subsequently uses the MLM to infer the missing elements. Then,
    we compute normalized similarity distances (i.e., Jaccard, Levenshtain, and Sorence-Dice)
    between the AST in-order traversal of both the predictions and the ground truth.
    Global results indicate the average prediction


    accuracy (i.e., normalized distance) for all node types within . In contrast,
    local results detail the prediction accuracy for individual node types.


    To address [RQ](#page-2-1)2, SyntaxEval computes the Average Causal Effect between
    syntactic capabilities and MLMs'' performance. This method consists of estimating
    using treatments <sup>1</sup> and <sup>0</sup> (i.e., tokens randomly masked)
    while controlling for confounders in (code features in Data Collection), to mitigate
    the presence of spurious correlations. The removal of confounding bias can be
    formally achieved using both an SCM and the -operator introduced by Pearl et al.
    [\[26\]](#page-4-33). To verify the robustness of our SCM, we computed placebo
    refutations, which is a method that fakes an unrelated treatment by re-estimating
    the causal effects. That is, we assessed that the causal effects of the fake treatment
    on the outcome were close to zero. Moreover, to ensure a balanced distribution
    of randomly masking tokens within 0, we created 20 distinct variations for each
    sample. Afterward, we computed the average of the resulting similarity scores.
    Finally, to ensure statistical significance, we bootstrapped the similarity scores
    using the for 500 samples per node type.


    #### 5 RESULTS & DISCUSSION


    The aim of this study is to determine the effect of Syntactic Capabilities, in
    the form of interpretable prediction estimates for node types, on the prediction
    performance of MLMs. We concentrated on evaluating Encoder-based Transformers
    beyond accuracy.


    ## 5.1 [RQ](#page-2-0)<sup>1</sup> Syntactic Capabilities Performance


    Global Results. A cursory glance at Tab. [2](#page-3-0) reveals that control groups
    <sup>0</sup> of each performance metric are not significantly different from treatments
    <sup>1</sup> for both encoders. For example, the control median values greater
    than 0.8 are within the interquartile range () 0.78 ± 0.22 of the corresponding
    treatment. Furthermore, the standard deviation () values of the performance are
    predominantly more dispersed in the treatments than in the control. For example,
    the <sup>1</sup> of <sup>1</sup> Jaccard is 0.21, while the <sup>0</sup> is 0.17.
    Appealingly, all average values of performance are above 0.5, this indicates that
    <sup>1</sup> and <sup>2</sup> models are predicting masking tokens with high confidence
    despite the group treatments . Although the median global performance has consistently
    high accuracy among the metrics (> 0.8), the average separation values between
    the groups are not significant with an average median distance of 0.096 and 0.06
    for <sup>1</sup> and <sup>2</sup> respectively. However, a preliminary analysis
    for node types estimations suggests that <sup>1</sup> and <sup>2</sup> have a
    tendency to not statistically learn syntactic-oriented masked tokens 1. Our findings
    reveal a subtle inclination towards predicting random masked tokens over syntactic-oriented
    ones.


    <span id="page-2-3"></span>![](_page_2_Figure_17.jpeg)


    Figure 2: <sup>0</sup> vs. <sup>1</sup> Local Jaccard for Nodes using 1.


    <span id="page-3-0"></span>Table 2: Global Perf. and Causal Effects for <sup>1</sup>
    and 2.


    | Performance                                                                     |
    Jaccard                                                                                                     |                                                                         |
    Levenshtein |        | Sorensen-Dice |        |  |  |  |

    |---------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------|-------------|--------|---------------|--------|--|--|--|

    | MLMs                                                                            |
    𝑀1                                                                                                          |
    𝑀2                                                                      | 𝑀1          |
    𝑀2     | 𝑀1            | 𝑀2     |  |  |  |

    | Treatments                                                                      |
    Performance Metric 𝑌 [avg ± std]*<br>0.88 ± 0.17 0.84 ± 0.16 0.87 ± 0.16 0.83
    ± 0.17 0.92 ± 0.1 0.89 ± 0.12 |                                                                         |             |        |               |        |  |  |  |

    | 𝑇0                                                                              |                                                                                                             |                                                                         |             |        |               |        |  |  |  |

    | 𝑇1                                                                              |                                                                                                             |
    0.78 ± 0.21 0.76 ± 0.21 0.78 ± 0.22 0.76 ± 0.21 0.85 ± 0.17 0.84 ± 0.17 |             |        |               |        |  |  |  |

    | AST Node Type 𝐶                                                                 |
    CausalEffect 𝜏                                                                                              |                                                                         |             |        |               |        |  |  |  |

    | boolean_operator                                                                |
    -0.083                                                                                                      |
    -0.150                                                                  | -0.069      |
    -0.136 | -0.048        | -0.095 |  |  |  |

    | comparison_operator                                                             |
    -0.186                                                                                                      |
    -0.027                                                                  | -0.179      |
    -0.018 | -0.126        | -0.015 |  |  |  |

    | for_in_clause                                                                   |
    -0.059                                                                                                      |
    -0.053                                                                  | -0.050      |
    -0.045 | -0.034        | -0.029 |  |  |  |

    | for_statement                                                                   |
    -0.269                                                                                                      |
    -0.101                                                                  | -0.193      |
    -0.041 | -0.243        | -0.083 |  |  |  |

    | identifier                                                                      |
    0.016                                                                                                       |
    -0.075                                                                  | 0.001       |
    -0.073 | 0.010         | -0.039 |  |  |  |

    | if_clause                                                                       |
    -0.070                                                                                                      |
    -0.040                                                                  | -0.058      |
    -0.036 | -0.037        | -0.022 |  |  |  |

    | if_statement                                                                    |
    -0.163                                                                                                      |
    -0.118                                                                  | -0.140      |
    -0.093 | -0.116        | -0.095 |  |  |  |

    | parameters                                                                      |
    -0.140                                                                                                      |
    -0.048                                                                  | -0.127      |
    -0.046 | -0.087        | -0.029 |  |  |  |

    | return_statement                                                                |
    -0.144                                                                                                      |
    -0.121                                                                  | -0.118      |
    -0.113 | -0.087        | -0.075 |  |  |  |

    | string                                                                          |
    -0.156                                                                                                      |
    -0.168                                                                  | -0.102      |
    -0.145 | -0.118        | -0.116 |  |  |  |

    | while_statement                                                                 |
    -0.200                                                                                                      |
    -0.096                                                                  | -0.139      |
    -0.009 | -0.186        | -0.077 |  |  |  |

    | * Medians are > 0.8. The biggest causal effect 𝜏 for each node type is in gray.
    |                                                                                                             |                                                                         |             |        |               |        |  |  |  |


    Local Results. Fig. [2](#page-2-3) shows the Jaccard performance statistical behavior
    across some selected node types for 1. Due to the nonoverlapping between the <sup>0</sup>
    and 1, we observed a significant difference between treatment groups in the performance
    distribution for the nodes comparison\_operator and string, revealing that <sup>1</sup>
    struggles at predicting tokens associated with such types in contrast to random
    masked tokens. We found that identifier was the only node type that performed
    better in the treatment than the control group. Fig. [3](#page-3-1) presents the
    Empirical Cumulative Distribution (ECD) plots of <sup>1</sup> Jaccard distance
    across selected node types. We observed that if\_clause was remarkably achieved
    with the highest score prediction (0.9) at the lowest percentage of the population
    (42% of the samples in the testbed). Conversely, for\_statement was the most difficult
    node to predict across the population. We believe that MLMs struggle to predict
    these previous nodes due to their complexity. A node is complex when its block
    has incorporated other node types.


    <span id="page-3-1"></span>![](_page_3_Figure_4.jpeg)


    Figure 3: Syntactic Capabilities Statistically Learned by 1.


    [RQ](#page-2-0)1: MLMs tend to complete missing AST-masked tokens with acceptable
    accuracy (> 0.5). However, the reported performance suffers from high variability
    (±0.21) making the prediction process less confident compared to completing randomly
    masking tokens.


    ## 5.2 [RQ](#page-2-1)<sup>2</sup> Causal Evaluation Effect


    This study used a quantitative causal technique to analyze the influence of masking
    binary treatments (i.e., AST and random) on the performance of both <sup>1</sup>
    and 2 transformers after defining the


    Structural Causal Model of the problem. To draw a causal link between syntactic
    features (i.e., AST nodes) and performance metrics (i.e., Jaccard, Levenshtain,
    and SD), we expect to observe a positive causal effect. A positive effect would
    indicate that syntactic features are affecting models'' performance and AST nodes
    would be statistically learned by MLMs. On the other hand, a negative causal effect
    would imply that randomly masked tokens have more influence on the performance.
    That is, tokens without any particular syntactic order are being predicted accurately.


    Unlike previous assumptions, it can be inferred from Tab. [2](#page-3-0) that
    the control group (i.e., masking random treatment) is having more impact on MLMs''
    performance than the actual syntactic features. For instance, a set of samples
    masked for for\_statement tokens are underperforming (a.k.a. negative effects)
    compared to the same set but randomly masked tokens. This suggests that although
    transformers are predicting AST node types with confidence (see Fig. [3,](#page-3-1)
    these syntactic features are not particularly relevant compared to predicting
    any other set of unstructured tokens in the snippet (see gray areas in Tab. [2\)](#page-3-0).
    These findings tend to corroborate Karmakar et al. research [\[19\]](#page-4-20)
    in which MLMs do not fully grasp the syntax and structural aspects of code. Our
    findings offer an alternative perspective compared to claims made by other probing
    approaches [\[22,](#page-4-39) [34\]](#page-4-40). For example, Hernandez Lopez
    et al. [\[14\]](#page-4-28) argue for the presence of a syntax subspace within
    the hidden layers that encode structures of PLs. Similarly, Toufique et al. [\[2\]](#page-4-41)
    outline that pre-trained language models learn robust representations of code
    semantics, which implies a deep understanding of syntax elements from the source
    code.


    [RQ](#page-2-1)2: The performance of MLMs is negatively impacted by ASTmasked
    tokens ( < −0.1). Our causal analysis yielded no signs of Transformers'' performance
    being affected or guided by syntactic features, contradicting SOTA explainability
    findings.


    #### 6 CONCLUSION & FUTURE PLANS


    Our negative causal effect results corroborate recent findings that show flaws
    when claiming that MLMs are understanding syntax rules of PLs. Such effects amplify
    the disparities between Natural and Programming languages, underscoring the need
    for tailored representations in deep learning architectures. These findings pave
    the way for future research to evaluate semantic capabilities in the form of recursions,
    dead code, or code smells. We also highlight the necessity to delve deeper into
    understanding why MLMs are more adept at predicting random masked tokens than
    syntax-based tokens. This tendency may be linked to the models'' pre-training
    objectives, which frequently involve masking random tokens at a certain rate [\[10\]](#page-4-29).


    #### 7 ACKNOWLEDGEMENTS


    This research has been supported in part by the NSF CCF-2311469, CNS-2132281,
    CCF-2007246, and CCF-1955853. We also acknowledge support from Cisco Systems.
    Any opinions, findings, and conclusions expressed herein are the authors'' and
    do not necessarily reflect those of the sponsors.


    <span id="page-4-0"></span>Which Syntactic Capabilities Are Statistically Learned
    by Masked Language Models for Code? ICSE-NIER''24, April 14–20, 2024, Lisbon,
    Portugal


    #### REFERENCES


    - <span id="page-4-26"></span>[1] 2023. WM-SEMERU/SyntaxEval.<https://github.com/WM-SEMERU/SyntaxEval>
    original-date: 2022-09-09T20:53:59Z.

    - <span id="page-4-41"></span>[2] Toufique Ahmed, Dian Yu, Chengxuan Huang, Cathy
    Wang, et al. 2023. Towards Understanding What Code Language Models Learned. [https://doi.org/10.48550/](https://doi.org/10.48550/arXiv.2306.11943)
    [arXiv.2306.11943](https://doi.org/10.48550/arXiv.2306.11943) arXiv:2306.11943
    [cs].

    - <span id="page-4-32"></span>[3] Vaishak Belle and Ioannis Papantonis. 2020.
    Principles and Practice of Explainable Machine Learning. CoRR abs/2009.11698 (2020).
    arXiv:2009.11698 [https://arxiv.](https://arxiv.org/abs/2009.11698) [org/abs/2009.11698](https://arxiv.org/abs/2009.11698)

    - <span id="page-4-9"></span>[4] Marcel Bruch, Martin Monperrus, and Mira Mezini.
    [n. d.]. Learning from examples to improve code completion systems. In Proceedings
    of the 7th joint meeting of the European software engineering conference and the
    ACM SIGSOFT symposium on The foundations of software engineering (2009-08-24).
    ACM, 213– 222.<https://doi.org/10.1145/1595696.1595728>

    - <span id="page-4-1"></span>[5] Zimin Chen, Steve James Kommrusch, Michele Tufano,
    Louis-Noël Pouchet, et al. 2019. SEQUENCER: Sequence-to-Sequence Learning for
    End-to-End Program Repair. IEEE Transactions on Software Engineering (2019), 1–1.
    [https://doi.org/10.](https://doi.org/10.1109/TSE.2019.2940179) [1109/TSE.2019.2940179](https://doi.org/10.1109/TSE.2019.2940179)

    - <span id="page-4-18"></span>[6] Matteo Ciniselli, Nathan Cooper, Luca Pascarella,
    Antonio Mastropaolo, et al. [n. d.]. An Empirical Study on the Usage of Transformer
    Models for Code Completion. ([n. d.]), 1–1.<https://doi.org/10.1109/TSE.2021.3128234>

    - <span id="page-4-2"></span>[7] Matteo Ciniselli, Nathan Cooper, Luca Pascarella,
    Antonio Mastropaolo, et al. 2021. An Empirical Study on the Usage of Transformer
    Models for Code Completion. arXiv[:cs.SE/2108.01585](https://arxiv.org/abs/cs.SE/2108.01585)

    - <span id="page-4-8"></span>[8] Matteo Ciniselli, Nathan Cooper, Luca Pascarella,
    Denys Poshyvanyk, et al. 2021. An Empirical Study on the Usage of BERT Models
    for Code Completion. CoRR abs/2103.07115 (2021). arXiv:2103.07115<https://arxiv.org/abs/2103.07115>

    - <span id="page-4-19"></span>[9] Colin Clement, Dawn Drain, Jonathan Timcheck,
    Alexey Svyatkovskiy, et al. [n. d.]. PyMT5: multi-mode translation of natural
    language and Python code with transformers. In Proceedings of the 2020 Conference
    on Empirical Methods in Natural Language Processing (EMNLP) (2020). Association
    for Computational Linguistics, 9052–9065.<https://doi.org/10.18653/v1/2020.emnlp-main.728>

    - <span id="page-4-29"></span>[10] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
    Kristina Toutanova. [n. d.]. BERT: Pre-training of Deep Bidirectional Transformers
    for Language Understanding. <https://doi.org/10.48550/arXiv.1810.04805> arXiv[:1810.04805
    \[cs\]](https://arxiv.org/abs/1810.04805 [cs])

    - <span id="page-4-35"></span>[11] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan,
    et al. 2020. CodeBERT: A Pre-Trained Model for Programming and Natural Languages.
    arXiv[:cs.CL/2002.08155](https://arxiv.org/abs/cs.CL/2002.08155)

    - <span id="page-4-10"></span>[12] Sangmok Han, David R. Wallace, and Robert C.
    Miller. [n. d.]. Code Completion from Abbreviated Input. In 2009 IEEE/ACM International
    Conference on Automated Software Engineering (2009-11). IEEE, 332–343. [https://doi.org/10.1109/ASE.2009.](https://doi.org/10.1109/ASE.2009.64)
    [64](https://doi.org/10.1109/ASE.2009.64)

    - <span id="page-4-11"></span>[13] Sangmok Han, David R. Wallace, and Robert C.
    Miller. [n. d.]. Code completion of multiple keywords from abbreviated input.
    18, 3 ([n. d.]), 363–398. [https:](https://doi.org/10.1007/s10515-011-0083-2)
    [//doi.org/10.1007/s10515-011-0083-2](https://doi.org/10.1007/s10515-011-0083-2)

    - <span id="page-4-28"></span>[14] José Antonio Hernández López, Martin Weyssow,
    Jesús Sánchez Cuadrado, and Houari Sahraoui. 2022. AST-Probe: Recovering abstract
    syntax trees from hidden representations of pre-trained language models. Proceedings
    of the 37th IEEE/ACM International Conference on Automated Software Engineering
    (Oct. 2022), 1–11.<https://doi.org/10.1145/3551349.3556900> Conference Name: ASE
    ''22: 37th IEEE/ACM International Conference on Automated Software Engineering
    ISBN: 9781450394758 Place: Rochester MI USA Publisher: ACM.

    - <span id="page-4-12"></span>[15] Abram Hindle, Earl T. Barr, Zhendong Su, Mark
    Gabel, et al. 2012. On the naturalness of software. In 2012 34th International
    Conference on Software Engineering (ICSE). 837–847.<https://doi.org/10.1109/ICSE.2012.6227135>

    - <span id="page-4-31"></span>[16] Xinyi Hou, Yanjie Zhao, Yue Liu, Zhou Yang,
    et al. 2023. Large Language Models for Software Engineering: A Systematic Literature
    Review. [http://arxiv.org/abs/](http://arxiv.org/abs/2308.10620) [2308.10620](http://arxiv.org/abs/2308.10620)
    arXiv:2308.10620 [cs].

    - <span id="page-4-38"></span>[17] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit,
    Miltiadis Allamanis, et al. 2019. CodeSearchNet Challenge: Evaluating the State
    of Semantic Code Search. arXiv:1909.09436 [cs, stat] (Sept. 2019).<http://arxiv.org/abs/1909.09436>
    arXiv: 1909.09436.

    - <span id="page-4-30"></span>[18] Masahiro Kaneko, Masato Mita, Shun Kiyono,
    Jun Suzuki, et al. 2020. Encoder-Decoder Models Can Benefit from Pre-trained Masked
    Language Models in Grammatical Error Correction. arXiv[:cs.CL/2005.00987](https://arxiv.org/abs/cs.CL/2005.00987)

    - <span id="page-4-20"></span>[19] Anjan Karmakar and Romain Robbes. 2023. INSPECT:
    Intrinsic and Systematic Probing Evaluation for Code Transformers. IEEE Transactions
    on Software Engineering (2023), 1–19.<https://doi.org/10.1109/TSE.2023.3341624>
    Conference Name: IEEE Transactions on Software Engineering.

    - <span id="page-4-17"></span>[20] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei
    Du, et al. 2019. RoBERTa: A Robustly Optimized BERT Pretraining Approach. arXiv[:cs.CL/1907.11692](https://arxiv.org/abs/cs.CL/1907.11692)

    - <span id="page-4-34"></span>[21] Yinhan Liu, Myle Ott, Naman Goyal, Jingfei
    Du, et al. 2019. RoBERTa: A Robustly Optimized BERT Pretraining Approach. [https://doi.org/10.48550/arXiv.1907.](https://doi.org/10.48550/arXiv.1907.11692)
    [11692](https://doi.org/10.48550/arXiv.1907.11692) arXiv:1907.11692 [cs].

    - <span id="page-4-39"></span>[22] Wei Ma, Mengjie Zhao, Xiaofei Xie, Qiang Hu,
    et al. 2023. Are Code Pre-trained Models Powerful to Learn Code Syntax and Semantics?
    [https://doi.org/10.48550/](https://doi.org/10.48550/arXiv.2212.10017) [arXiv.2212.10017](https://doi.org/10.48550/arXiv.2212.10017)
    arXiv:2212.10017 [cs].

    - <span id="page-4-3"></span>[23] Antonio Mastropaolo, Simone Scalabrino, Nathan
    Cooper, David Nader Palacio, et al. 2021. Studying the Usage of Text-To-Text Transfer
    Transformer to Support Code-Related Tasks. (2021), 336–347. [https://doi.org/10.1109/icse43902.2021.](https://doi.org/10.1109/icse43902.2021.00041)
    [00041](https://doi.org/10.1109/icse43902.2021.00041)

    - <span id="page-4-21"></span>[24] Ahmad Haji Mohammadkhani and Hadi Hemmati.
    [n. d.]. Explainable AI for Pre-Trained Code Models: What Do They Learn? When
    They Do Not Work? ([n. d.]).

    - <span id="page-4-24"></span>[25] David N. Palacio, Nathan Cooper, Alvaro Rodriguez,
    Kevin Moran, et al. [n. d.]. Toward a Theory of Causation for Interpreting Neural
    Code Models. [https:](https://doi.org/10.48550/arXiv.2302.03788) [//doi.org/10.48550/arXiv.2302.03788](https://doi.org/10.48550/arXiv.2302.03788)
    arXiv[:2302.03788 \[cs, stat\]](https://arxiv.org/abs/2302.03788 [cs, stat])

    - <span id="page-4-33"></span>[26] Judea Pearl. 2009. Causality: models, reasoning,
    and inference.

    - <span id="page-4-25"></span>[27] Rafiqul Islam Rabin, Arjun Mukherjee, Omprakash
    Gnawali, and Mohammad Amin Alipour. [n. d.]. Towards Demystifying Dimensions of
    Source Code Embeddings. ([n. d.]), 29–38. ISBN: 9781450381253.

    - <span id="page-4-13"></span>[28] Veselin Raychev, Martin Vechev, and Eran Yahav.
    [n. d.]. Code completion with statistical language models. In Proceedings of the
    35th ACM SIGPLAN Conference on Programming Language Design and Implementation
    (2014-06-09). ACM, 419– 428.<https://doi.org/10.1145/2594291.2594321>

    - <span id="page-4-37"></span>[29] Daniel Rodriguez-Cardenas, David N. Palacio,
    Dipin Khati, Henry Burke, et al. 2023. Benchmarking Causal Study to Interpret
    Large Language Models for Source Code. In 2023 IEEE International Conference on
    Software Maintenance and Evolution (ICSME). 329–334.<https://doi.org/10.1109/ICSME58846.2023.00040>

    - <span id="page-4-36"></span>[30] Amit Sharma, Vasilis Syrgkanis, Cheng Zhang,
    and Emre Kıcıman. 2021. DoWhy : Addressing Challenges in Expressing and Validating
    Causal Assumptions. (2021).

    - <span id="page-4-23"></span>[31] P. K. Srimani and S. F. B. Nasir. 2007. A Textbook
    on Automata Theory. Foundation Books.<https://doi.org/10.1017/UPO9788175968363>

    - <span id="page-4-16"></span>[32] Alexey Svyatkovskiy, Shao Kun Deng, Shengyu
    Fu, and Neel Sundaresan. [n. d.]. IntelliCode compose: code generation using transformer.
    In Proceedings of the 28th ACM Joint Meeting on European Software Engineering
    Conference and Symposium on the Foundations of Software Engineering (2020-11-08).
    ACM, 1433–1443.<https://doi.org/10.1145/3368089.3417058>

    - <span id="page-4-15"></span>[33] Alexey Svyatkovskiy, Ying Zhao, Shengyu Fu,
    and Neel Sundaresan. [n. d.]. Pythia: AI-assisted Code Completion System. In Proceedings
    of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data
    Mining (2019- 07-25). 2727–2735.<https://doi.org/10.1145/3292500.3330699> arXiv[:1912.00742](https://arxiv.org/abs/1912.00742
    [cs]) [\[cs\]](https://arxiv.org/abs/1912.00742 [cs])

    - <span id="page-4-40"></span>[34] Sergey Troshin and Nadezhda Chirkova. 2022.
    Probing Pretrained Models of Source Codes. Proceedings of the Fifth BlackboxNLP
    Workshop on Analyzing and Interpreting Neural Networks for NLP (2022), 371–383.
    [https://doi.org/10.18653/v1/](https://doi.org/10.18653/v1/2022.blackboxnlp-1.31)
    [2022.blackboxnlp-1.31](https://doi.org/10.18653/v1/2022.blackboxnlp-1.31) Conference
    Name: Proceedings of the Fifth BlackboxNLP Workshop on Analyzing and Interpreting
    Neural Networks for NLP Place: Abu Dhabi, United Arab Emirates (Hybrid) Publisher:
    Association for Computational Linguistics.

    - <span id="page-4-4"></span>[35] Michele Tufano, Cody Watson, Gabriele Bavota,
    Massimiliano Di Penta, et al. 2018. Deep Learning Similarities from Different
    Representations of Source Code. In 2018 IEEE/ACM 15th International Conference
    on Mining Software Repositories (MSR). 542–553.

    - <span id="page-4-5"></span>[36] Rosalia Tufano, Luca Pascarella, Michele Tufano,
    Denys Poshyvanyk, et al. 2021. Towards Automating Code Review Activities. In 43rd
    International Conference on Software Engineering, ICSE''21.<https://arxiv.org/abs/2101.02518>

    - <span id="page-4-22"></span>[37] Yao Wan, Wei Zhao, Hongyu Zhang, Yulei Sui,
    et al. [n. d.]. What Do They Capture? – A Structural Analysis of Pre-Trained Language
    Models for Source Code.<https://doi.org/10.48550/arXiv.2202.06840> arXiv[:2202.06840
    \[cs\]](https://arxiv.org/abs/2202.06840 [cs])

    - <span id="page-4-27"></span>[38] Cody Watson, Nathan Cooper, David Nader Palacio,
    Kevin Moran, et al. 2022. A Systematic Literature Review on the Use of Deep Learning
    in Software Engineering Research. ACM Transactions on Software Engineering and
    Methodology 31, 2 (March 2022), 32:1–32:58.<https://doi.org/10.1145/3485275>

    - <span id="page-4-6"></span>[39] Cody Watson, Michele Tufano, Kevin Moran, Gabriele
    Bavota, et al. 2020. On Learning Meaningful Assert Statements for Unit Test Cases.
    In Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering
    (ICSE ''20). Association for Computing Machinery, New York, NY, USA, 1398–1409.
    [https:](https://doi.org/10.1145/3377811.3380429) [//doi.org/10.1145/3377811.3380429](https://doi.org/10.1145/3377811.3380429)

    - [40] Martin White, Michele Tufano, Matías Martínez, Martin Monperrus, et al.
    2019. Sorting and Transforming Program Repair Ingredients via Deep Learning Code
    Similarities. In 2019 IEEE 26th International Conference on Software Analysis,
    Evolution and Reengineering (SANER). 479–490. [https://doi.org/10.1109/SANER.](https://doi.org/10.1109/SANER.2019.8668043)
    [2019.8668043](https://doi.org/10.1109/SANER.2019.8668043)

    - <span id="page-4-7"></span>[41] Martin White, Michele Tufano, Christopher Vendome,
    and Denys Poshyvanyk. 2016. Deep learning code fragments for code clone detection.
    In 2016 31st IEEE/ACM International Conference on Automated Software Engineering
    (ASE). 87–98.

    - <span id="page-4-14"></span>[42] Martin White, Christopher Vendome, Mario Linares-Vasquez,
    and Denys Poshyvanyk. [n. d.]. Toward Deep Learning Software Repositories. In
    2015 IEEE/ACM 12th Working Conference on Mining Software Repositories (2015-05).
    IEEE, 334–345. <https://doi.org/10.1109/MSR.2015.38>'
- title: "De-Hallucinator: Mitigating LLM Hallucinations in Code Generation Tasks\n\
    \  via Iterative Grounding"
  abstract: 'Large language models (LLMs) trained on datasets of publicly available
    source

    code have established a new state of the art in code generation tasks. However,

    these models are mostly unaware of the code that exists within a specific

    project, preventing the models from making good use of existing APIs. Instead,

    LLMs often invent, or "hallucinate", non-existent APIs or produce variants of

    already existing code. This paper presents De-Hallucinator, a technique that

    grounds the predictions of an LLM through a novel combination of retrieving

    suitable API references and iteratively querying the model with increasingly

    suitable context information in the prompt. The approach exploits the

    observation that predictions by LLMs often resemble the desired code, but they

    fail to correctly refer to already existing APIs. De-Hallucinator automatically

    identifies project-specific API references related to the model''s initial

    predictions and adds these references into the prompt. Unlike

    retrieval-augmented generation (RAG), our approach uses the initial

    prediction(s) by the model to iteratively retrieve increasingly suitable API

    references. Our evaluation applies the approach to two tasks: predicting API

    usages in Python and generating tests in JavaScript. We show that

    De-Hallucinator consistently improves the generated code across five LLMs. In

    particular, the approach improves the edit distance by 23.3-50.6% and the

    recall of correctly predicted API usages by 23.9-61.0% for code completion, and

    improves the number of fixed tests that initially failed because of

    hallucinations by 63.2%, resulting in a 15.5% increase in statement coverage

    for test generation.'
  url: http://arxiv.org/abs/2401.01701v3
  keywords: ''
  document: "# De-Hallucinator: Mitigating LLM Hallucinations in Code Generation Tasks\
    \ via Iterative Grounding\n\nAryaz Eghbali Software Lab University of Stuttgart\
    \ Stuttgart, Germany aryaz.eghbali@iste.uni-stuttgart.de\n\n#### ABSTRACT\n\n\
    Large language models (LLMs) trained on datasets of publicly available source\
    \ code have established a new state of the art in code generation tasks. However,\
    \ these models are mostly unaware of the code that exists within a specific project,\
    \ preventing the models from making good use of existing APIs. Instead, LLMs often\
    \ invent, or \"hallucinate\", non-existent APIs or produce variants of already\
    \ existing code. This paper presents De-Hallucinator, a technique that grounds\
    \ the predictions of an LLM through a novel combination of retrieving suitable\
    \ API references and iteratively querying the model with increasingly suitable\
    \ context information in the prompt. The approach exploits the observation that\
    \ predictions by LLMs often resemble the desired code, but they fail to correctly\
    \ refer to already existing APIs. De-Hallucinator automatically identifies project-specific\
    \ API references related to the model's initial predictions and adds these references\
    \ into the prompt. Unlike retrieval-augmented generation (RAG), our approach uses\
    \ the initial prediction(s) by the model to iteratively retrieve increasingly\
    \ suitable API references. Our evaluation applies the approach to two tasks: predicting\
    \ API usages in Python and generating tests in JavaScript. We show that De-Hallucinator\
    \ consistently improves the generated code across five LLMs. In particular, the\
    \ approach improves the edit distance by 23.3–50.6% and the recall of correctly\
    \ predicted API usages by 23.9–61.0% for code completion, and improves the number\
    \ of fixed tests that initially failed because of hallucinations by 63.2%, resulting\
    \ in a 15.5% increase in statement coverage for test generation.\n\n#### 1 INTRODUCTION\n\
    \nLarge language models (LLMs) have proven effective in many natural language\
    \ [\\[7\\]](#page-10-0) and programming tasks [\\[4,](#page-10-1) [9,](#page-10-2)\
    \ [23,](#page-10-3) [46,](#page-11-0) [54,](#page-11-1) [61,](#page-11-2) [63\\\
    ]](#page-11-3). Rapid adoption of LLM-based tools, such as Copilot[1](#page-0-0)\
    \ and Tabnine[2](#page-0-1) , shows practical productivity benefits [\\[33,](#page-10-4)\
    \ [66\\]](#page-11-4). State-of-the-art LLMs build on transformers [\\[58\\]](#page-11-5),\
    \ which use self-attention to generate sequences of tokens in an auto-regressive\
    \ process. That is, the model decides what token to predict next based on the\
    \ tokens in the prompt and any already generated tokens. Hence, designing effective\
    \ prompts, sometimes called prompt engineering, is a crucial part of developing\
    \ a practical LLM-based technique [\\[35,](#page-11-6) [39,](#page-11-7) [56\\\
    ]](#page-11-8).\n\nDespite the impressive success of LLM-based code generation,\
    \ these techniques are still at an early stage. In particular, we identify two\
    \ key challenges faced by current approaches:\n\nChallenge 1: Project-specific\
    \ APIs. As LLMs are trained on huge code bases, they effectively capture typical\
    \ language idioms and\n\nMichael Pradel Software Lab University of Stuttgart Stuttgart,\
    \ Germany michael@binaervarianz.de\n\n<span id=\"page-0-2\"></span>\n\n| DataStore.py<br>class\
    \ DataStore():<br>def __init__(self, file: str):                             \
    \                   |\n|---------------------------------------------------------------------------------------------------------------------|\n\
    |                                                                            \
    \                                         |\n|                               \
    \                                                                            \
    \          |\n| with open(file, 'r') as f:                                   \
    \                                                       |\n| self.documents =\
    \ f.read().split('-----')                                                    \
    \                        |\n| <br>def find_by_keyword(self, keyword: str) -> List[str]:<br>return\
    \ [d for d in self.documents if keyword in d]<br> |\n| utils.py<br>          \
    \                                                                            \
    \                  |\n| def relevance(document: str, keyword: str) -> float:<br>return\
    \ document.count(keyword) / len(document)<br>          |\n| UI.py            \
    \                                                                            \
    \                       |\n| <br>def search(ds: DataStore, keyword: str, top_k:\
    \ int) -> List[str]:<br>docs = ds.find_by_keyword(keyword)         |\n| return\
    \ sorted(docs, key=lambda d: relevance(d, keyword),                          \
    \                                  |\n| reverse=True)[:top_k]                \
    \                                                                            \
    \   |\n|                                                                     \
    \                                                |\n|                        \
    \                                                                            \
    \                 |\n\nFigure 1: The desired completion of **search** is highlighted\
    \ in gray .\n\n<span id=\"page-0-3\"></span>\n\n|  | def search(ds: DataStore,\
    \ keyword: str, top_k: int) -> List[str]: |  |  |  |  |\n|--|-------------------------------------------------------------------|--|--|--|--|\n\
    |  | docs = ds.find_by_keyword(keyword)                                |  |  |\
    \  |  |\n|  | return sorted(docs, key=lambda x: x.score , reverse=True)[:top_k]\
    \ |  |  |  |  |\n\nFigure 2: The completion of **search** by CodeGen-2B-mono highlighted\
    \ in gray , and the wrong API usage highlighted in red .\n\ncommonly used libraries.\
    \ In contrast, a general-purpose model lacks knowledge of project-specific APIs,\
    \ and may fail to correctly use existing functions and classes. In particular,\
    \ this lack of knowledge may cause the model to \"hallucinate\" APIs that actually\
    \ do not exist in the current code base [\\[40\\]](#page-11-9), or perhaps even\
    \ worse, it may reimplement some functionality that is already present in the\
    \ code base. Developers perceive this lack of knowledge about projectspecific\
    \ APIs as an obstacle to using AI programming assistants [\\[33\\]](#page-10-4).\n\
    \nAs a running example, consider three files in a large project dealing with text\
    \ documents, shown in Fig. [1.](#page-0-2) One file, DataStore.py, contains a\
    \ class implementing a data structure that stores documents and provides a keyword-based\
    \ search over the documents. Another file, utils.py, provides helper functions,\
    \ one of which allows for measuring the relevance of a document to a keyword.\
    \ In a third file, UI.py, the developer is working on a function, search, to search\
    \ for the top\\_k documents that are most relevant to a keyword.\n\nRequesting\
    \ an LLM, e.g., CodeGen [\\[43\\]](#page-11-10), to complete the search function\
    \ given a prompt that contains all existing code in UI.py results in Fig. [2.](#page-0-3)\
    \ The code is partially correct, but refers to a nonexisting API (an attribute\
    \ x.score). The underlying problem is that the models are not aware of the project-specific\
    \ APIs that should be used to complete the code, and hence, the LLM simply hallucinates\
    \ some plausible but ultimately wrong APIs.\n\n<span id=\"page-0-0\"></span><sup>1</sup>https://github.com/features/copilot\n\
    \n<span id=\"page-0-1\"></span><sup>2</sup>https://www.tabnine.com/\n\nChallenge\
    \ 2: Prioritizing context. A naive solution to address Challenge 1 would be to\
    \ simply add all of the code in the project into the prompt. However, LLMs have\
    \ a fixed maximum sequence length, which restricts how many tokens one can provide\
    \ to the model. Even with the recent increases in sequence length of LLMs, providing\
    \ the most useful context can improve the output and reduce the costs. Choosing\
    \ the most helpful context for a given completion task is crucial, but an inherently\
    \ difficult problem, because the optimal context depends on the desired code,\
    \ which is not known a-priori. While traditional code completion approaches typically\
    \ have access to various kinds of information available in IDEs, such as the names\
    \ and types of program elements, providing all this information, or even all the\
    \ code of the project, to an LLM is impossible due to the limited prompt size.\n\
    \nThis paper presents De-Hallucinator, which addresses the above challenges through\
    \ a novel combination of retrieval-augmented generation (RAG) and an iterative\
    \ form of LLM-based code generation. Our approach uses three types of prompts,\
    \ which provide increasingly suitable context information. The initial prompt\
    \ type is querying the LLM with the conventional prompt, i.e., without any retrieval.\
    \ Retrieval-augmented generation (RAG) [\\[28\\]](#page-10-5) proposes to retrieve\
    \ relevant context based on the initial prompt to address both Challenges 1 and\
    \ 2, which we refer to as the RAG prompt type. The idea of augmenting an LLM with\
    \ well-grounded facts relates to work on grounding of language models for natural\
    \ languages [\\[2,](#page-10-6) [17,](#page-10-7) [52\\]](#page-11-11). However,\
    \ also this prompt may fail to generate factually correct code (i.e., without\
    \ hallucinations), because the initial prompt might not have any similar code\
    \ to the desired API, or there are other APIs more similar to the initial prompt\
    \ than the correct one. We make the improtant observation that the generated code\
    \ from the previous prompt types often resembles the desired API. Hence, we construct\
    \ a new type of prompt called the iterative prompt. De-Hallucinator leverages\
    \ the code that the model predicts to retrieve suitable project-specific APIs,\
    \ which are then added to the iterative prompt for the next round of model prediction.\
    \ The iterative prompt type complements prior work that tries to guess the most\
    \ suitable context from the incomplete code alone [\\[12,](#page-10-8) [56\\]](#page-11-8).\n\
    \nThe presented approach offers several benefits. First, De-Hallucinator works\
    \ with any off-the-shelf LLM trained on code because the approach treats the model\
    \ as a black box. In particular, we do not require to train or fine-tune the model\
    \ in any way, but simply exploit the fact that its predictions contain implicit\
    \ hints about additional context the model would benefit from. Second, because\
    \ APIs usually evolve only slowly, De-Hallucinator can precompute, and occasionally\
    \ update in the background, the set of project-specific API references. As a result,\
    \ the latency of code generation is not impacted by any expensive program analysis,\
    \ which is important for practical adoption. Finally, the approach is fully transparent\
    \ to developers, because the approach hides the iterative interaction with the\
    \ LLM from the user and simply returns a ranked list of predictions.\n\nWe evaluate\
    \ De-Hallucinator by applying the approach to code completion with four state-of-the-art\
    \ LLMs for code, namely Code-Gen [\\[43\\]](#page-11-10), CodeGen 2.5 [\\[42\\\
    ]](#page-11-12), UniXcoder [\\[18\\]](#page-10-9), and StarCoder+ [\\[30\\]](#page-10-10),\
    \ and to test generation with GPT-3.5-turbo. Conceptually, the approach can be\
    \ applied to any programming language, and our evaluation focuses on two popular\
    \ languages, Python and JavaScript\n\nas they are among the most popular languages\
    \ [3](#page-1-0) and common targets of prior work on code completion [\\[9,](#page-10-2)\
    \ [18,](#page-10-9) [29,](#page-10-11) [30,](#page-10-10) [42,](#page-11-12) [43,](#page-11-10)\
    \ [57,](#page-11-13) [65\\]](#page-11-14) and test generation [\\[3,](#page-10-12)\
    \ [54\\]](#page-11-1). Compared to conventional prompts, we find that De-Hallucinator\
    \ enables the models to provide more accurate predictions. In particular, we show\
    \ a relative improvement of 23.3–50.6% in edit distance, and of 23.9–61.0% in\
    \ recall of correctly predicted API usages for code completion. Moreover, we show\
    \ relative improvement of 17.9% in number of passing tests, of 15.5% in coverage,\
    \ and of 63.2% in the number of mitigated hallucinations. In summary, this paper\
    \ contributes the following:\n\n• Empirical motivation showing that API hallucinations\
    \ affect a large portion of failed code completion and test generation tasks.\n\
    \n- A technique for addressing this problem using off-the-shelf, unmodified LLMs.\n\
    - A novel algorithm that combines retrieval-augmented generation with an iterative\
    \ method for constructing increasingly suitable prompts by using the hallucinations\
    \ produced in earlier iterations to augment the context information provided in\
    \ the prompts of future iterations.\n- Empirical evidence that, across two code\
    \ generation tasks, two programming languages, and five state-of-the-art LLMs,\
    \ De-Hallucinator offers more accurate generations than conventional prompts.\n\
    \n## 2 PRELIMINARY STUDY\n\nBefore delving into our approach, we validate the\
    \ motivation for this work by performing a preliminary study, which assesses the\
    \ importance of the two challenges described in the introduction.\n\n#### 2.1\
    \ Project-Specific APIs\n\nThe main motivation for this work is our observation\
    \ that LLMs often hallucinate code that resembles the desired code, but that fail\
    \ to correctly refer to an API. To assess the importance of this limitation, we\
    \ investigate the prevalence and causes of hallucinated APIs in the two code generation\
    \ tasks focused in this paper. For code completion, we manually investigate and\
    \ classify the reasons why an LLM fails to predict the desired completion. We\
    \ perform this preliminary study on 50 function-level code completion tasks, which\
    \ we collect by (i) randomly selecting ten Python projects from a curated list\
    \ of open-source projects [4](#page-1-1) and (ii) by then randomly selecting five\
    \ functions from each project. The only filtering we perform is to ignore functions\
    \ with more than 25 lines, as these are likely out of reach for today's LLMs.\
    \ For each of the 50 functions, we query an LLM (CodeGen 2.5 with 7B parameters\
    \ and 4-bit quantization) with the code before the beginning of the function body,\
    \ including the function signature and any docstring, in the prompt.\n\nGiven\
    \ the 50 pairs of an LLM-predicted function body and the ground-truth function\
    \ body, we manually classify them based on two questions. First, is the prediction\
    \ correct w.r.t. the ground truth, where \"correct\" includes exact matches and\
    \ semantically equivalent code? Second, does the ground truth contain an API usage,\
    \ e.g., a function call, that is missing in the prediction? Initially, two\n\n\
    <span id=\"page-1-0\"></span><sup>3</sup><https://octoverse.github.com/2022/top-programming-languages>\n\
    \n<span id=\"page-1-1\"></span><sup>4</sup>[https://github.com/vinta/awesome-python.](https://github.com/vinta/awesome-python)\
    \ We randomly sample ten application domains and then sample one project from\
    \ each domain.\n\nof the authors independently classify the 50 pairs, with an\
    \ interrater agreement (Cohen's kappa) of 0.76, which is considered excellent\
    \ [\\[14\\]](#page-10-13), and after discussing the discrepencies reach a consensus\
    \ about all 50 pairs.\n\nThe final inspection results show that in 13 out of the\
    \ 50 cases, the LLM either predicts exactly the expected function body or a function\
    \ body that is semantically equivalent to the expected one. For 22 out of the\
    \ 37 remaining cases, there is at least one API usage that the LLM fails to correctly\
    \ predict, similar to the example in Fig. [2.](#page-0-3) In other words, the\
    \ problem identified and addressed in this work affects 44% of all studied function-level\
    \ code completion tasks, and even 59% of all tasks where the LLM alone fails to\
    \ predict the expected code.\n\nFor test generation, we use error messages of\
    \ crashing tests generated by TestPilot [\\[54\\]](#page-11-1) on a diverse set\
    \ of 12 JavaScript projects. We automatically count the number of generated tests\
    \ that result in \"\\* is not a function\", or \"Cannot read properties of undefined\"\
    \ errors, which typically indicates hallucinations of non-existing APIs. We find\
    \ that, on average, 16.4% of all generated tests fail because of the aforementioned\
    \ errors, which indicates that hallucinations of non-existing APIs are a common\
    \ problem in test generation as well.\n\n## 2.2 Prioritizing Context\n\nTo validate\
    \ the importance of the second challenge, we compare the amount of code in a single\
    \ project to the prompt sizes of highend LLMs. The models in the popular GPT series\
    \ by OpenAI have prompt sizes between 4k (GPT-3.5 models) and 128k (GPT-4) tokens.\
    \ In contrast, in a sample dataset of 50 Python projects, which are randomly selected\
    \ from the same curated list of projects as above, there are 488,635 tokens per\
    \ project, on average. Furthermore, the average project has around 13 files longer\
    \ than 8,192 tokens, and 22 projects in our sample have at least one file longer\
    \ than 32,768 tokens. This means that even knowing the exact file that contains\
    \ the relevant context (e.g., based on heuristics, such as recently used files\
    \ or similar file names) leaves us with more tokens than one could fit into the\
    \ prompt of some models. Even for models with longer context window, considering\
    \ a cost of 0.5\\$ for 100k tokens means that the cost of long prompts would be\
    \ impractical for regular use. In other words, simply adding all potentially relevant\
    \ code to the prompt is not a viable solution, but we need to prioritize the context\
    \ information.\n\n#### 3 APPROACH\n\nThis section describes our approach for iteratively\
    \ retrieving relevant APIs to improve the prompts for code generation tasks. We\
    \ call the approach De-Hallucinator, as it reduces the hallucinations of the LLM\
    \ by providing relevant API references to ground the model. First, we provide\
    \ an overview of the approach (Section [3.1\\)](#page-2-0), and then present each\
    \ of the components of De-Hallucinator in detail (Sections [3.2](#page-2-1) to\
    \ [3.5\\)](#page-4-0).\n\n#### <span id=\"page-2-0\"></span>3.1 Overview\n\n3.1.1\
    \ Main Algorithm. Figure [3](#page-2-2) gives an overview of the approach, which\
    \ we use to illustrate the main algorithm. The top of the figure shows the traditional\
    \ code generation process, where an LLM receives a prompt and generates code.\
    \ We call this prompt the initial\n\n<span id=\"page-2-2\"></span>![](_page_2_Figure_10.jpeg)\n\
    \nFigure 3: Overview of De-Hallucinator.\n\nprompt. Because the model may not\
    \ be aware of project-specific APIs, the output is likely to refer to some hallucinated\
    \ APIs.\n\nTo help the model predict better code, De-Hallucinator refines the\
    \ initial prompt using two techniques. Both of them add API references to the\
    \ prompt, but they do so in different ways. First, as shown by the dotted lines,\
    \ De-Hallucinator uses the initial prompt to retrieve related API references from\
    \ the project. This approach is similar to retrieval-augmented generation (RAG)\
    \ [\\[28\\]](#page-10-5), and we refer to the resulting prompt as the RAG prompt.\n\
    \nSecond, as shown by the dashed lines, De-Hallucinator uses the output of the\
    \ model to retrieve related API references. This technique is unique to our approach,\
    \ and it is based on the observation that the model's output often resembles the\
    \ desired code, but fails to refer to the correct APIs. Retrieving suitable API\
    \ references based on the model's output can be done multiple times, and hence,\
    \ we refer to the resulting prompt as the iterative prompt. In general, De-Hallucinator\
    \ repeats the iterative prompt refinement, i.e., the dashed loop in the figure,\
    \ until exhausting a configurable maximum number of queries to the model.\n\n\
    For efficient retrieval of APIs, De-Hallucinator analyzes the project in advance,\
    \ as shown in the \"Pre-analysis\" component, and indexes all APIs of the project.\n\
    \n3.1.2 Example. Fig. [4](#page-3-0) shows each step of the approach on our running\
    \ example from Fig. [1.](#page-0-2) Given the initial prompt, the initial completion\
    \ by the model refers to a non-existing API x.score. Then, for the RAG prompt\
    \ the initial prompt is used for retrieval. In this step, as shown in Fig. [4,](#page-3-0)\
    \ the reference to an already used function, find\\_by\\_keyword is retrieved.\
    \ Consequently, the completion uses the wrong API, as the model still does not\
    \ have knowledge of the relevance function. Next, using the initial completion\
    \ by the model, De-Hallucinator retrieves a reference to the relevance function\
    \ defined in utils.py. In the example, the iterative prompt results in the correct\
    \ completion, as shown at the bottom of Fig. [4.](#page-3-0)\n\nThe following\
    \ presents each component of De-Hallucinator in more detail, as well as how we\
    \ instantiate the components for our two target tasks, code completion and test\
    \ generation.\n\n#### <span id=\"page-2-1\"></span>3.2 Pre-Analysis\n\n3.2.1 General\
    \ Idea. To ensure that the retrieval of API references does not unnecessarily\
    \ slow down the code generation, De-Hallucinator has a preprocessing phase that\
    \ indexes the current project for fast retrieval. We use API reference throughout\
    \ this paper to refer to a piece of text extracted from the project's code, which\
    \ can be added to the prompt to provide further information about a project-specific\
    \ API.\n\n<span id=\"page-3-0\"></span>\n\n| Initial prompt                  \
    \                                                                            \
    \                                                                            \
    \                                                      |\n|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | <br>def search(ds: DataStore, keyword: str, top_k: int) -> List[str]:<br>docs\
    \ = ds.find_by_keyword(keyword)                                              \
    \                                                                            \
    \         |\n| Initial completion<br>def search(ds: DataStore, keyword: str, top_k:\
    \ int) -> List[str]:<br>docs = ds.find_by_keyword(keyword)<br>return sorted(docs,\
    \ key=lambda x: x.score , reverse=True)[:top\\_k]                            \
    \               |\n| Most relevant API reference<br>DataStore.find_by_keyword(self,\
    \ keyword: str) -> List[str]                                                 \
    \                                                                            \
    \                        |\n| RAG prompt<br># API Reference:<br># DataStore.find_by_keyword(self,\
    \ keyword: str) -> List[str]<br>def search(ds: DataStore, keyword: str, top_k:\
    \ int) -> List[str]:<br>docs = ds.find_by_keyword(keyword)                   \
    \                  |\n| RAG prompt completion<br>def search(ds: DataStore, keyword:\
    \ str, top_k: int) -> List[str]:<br>docs = ds.find_by_keyword(keyword)<br>return\
    \ sorted(docs, key=lambda x: x.score , reverse=True)[:top\\_k]               \
    \                         |\n| Most relevant API reference<br>relevance(document:\
    \ str, keyword: str) -> float                                                \
    \                                                                            \
    \                                    |\n| Iterative prompt<br># API Reference:<br>#\
    \ relevance(document: str, keyword: str) -> float<br>def search(ds: DataStore,\
    \ keyword: str, top_k: int) -> List[str]:<br>docs = ds.find_by_keyword(keyword)\
    \                                          |\n| Iterative prompt completion<br>def\
    \ search(ds: DataStore, keyword: str, top_k: int) -> List[str]:<br>docs = ds.find_by_keyword(keyword)<br>return\
    \ sorted(docs, key=lambda doc: relevance(keyword, doc),<br>reverse=True)[:top\\\
    _k] # <- Correct |\n\n<span id=\"page-3-1\"></span>Figure 4: Step-by-step progression\
    \ of De-Hallucinator on the example in Fig. [1.](#page-0-2) Table 1: Examples\
    \ of API references extracted from the project in Fig. [1.](#page-0-2)\n\n| Source\
    \       | API reference                                                 | Type<br>of<br>API<br>reference\
    \ |\n|--------------|---------------------------------------------------------------|--------------------------------|\n\
    | DataStore.py | DataStore.find_by_keyword(self,<br>keyword: str) -> List[str]\
    \ | Function refer<br>ence         |\n| utils.py     | relevance(document:<br>str,<br>keyword:\
    \ str) -> float         | Function refer<br>ence         |\n| DataStore.py | class\
    \ DataStore()                                             | Class reference  \
    \              |\n| DataStore.py | DataStore.documents                       \
    \                    | Attribute refer<br>ence        |\n\nDefinition 3.1 (API\
    \ reference). An API reference is one of the following:\n\n- A function reference,\
    \ which consists of\n\t- the qualified name of the function,\n\t- the parameter\
    \ names,\n\t- any available default values for arguments,\n\t- any available type\
    \ annotations, and\n\t- any available function-level docstring.\n- A class reference,\
    \ which consists of\n\t- the qualified name of the class,\n\t- the parent class(es),\
    \ and\n\t- any available class-level docstring.\n- An attribute reference, which\
    \ is the qualified name of a self attribute assigned to in the constructor.\n\n\
    3.2.2 Example. Table [1](#page-3-1) shows some of the API references extracted\
    \ from our example project. Note that the API references resemble real code to\
    \ maintain compatibility with any model that is trained on source code.\n\n3.2.3\
    \ Application to Code Completion. For the code completion task, we use CodeQL[5](#page-3-2)\
    \ to statically extract APIs from the project source. The Python language support\
    \ of CodeQL offers easy access to the classes, functions, etc. in a code base.\
    \ Another benefit of CodeQL is that we can utilize databases created by GitHub\
    \ for open-source projects.\n\n3.2.4 Application to Test Generation. Since the\
    \ APIs in JavaScript are in many cases only available once a module is instantiated,\
    \ De-Hallucinator dynamically loads the modules and traverses them to extract\
    \ API references.\n\nAlternatively to our approaches for gathering API references,\
    \ an IDE-based implementation could reuse information about the current project\
    \ that is anyway computed by the static code indexing in an IDE.\n\n#### 3.3 Retrieval\
    \ of Related APIs\n\n3.3.1 General Idea. The retrieval module takes an input code\
    \ piece and returns a ranked list of project-specific API references that are\
    \ most similar to the input. To enable similarity-based search, De-Hallucinator\
    \ embeds the extracted API references into a vector space. Formally, we need an\
    \ embedding function, , for which () = ∈ R , such that, for two code pieces <sup>1</sup>\
    \ and 2, the cosine similarity of their embeddings, <sup>1</sup> · <sup>2</sup>\
    \ /(|<sup>1</sup> ||<sup>2</sup> |), approximates the semantic similarity of <sup>1</sup>\
    \ and 2. Recently, many models have been trained for this task [\\[1\\]](#page-10-14).\
    \ Because our approach uses the embedding function as a black-box, any embedding\
    \ model or similarity-preserving vector representation [\\[59\\]](#page-11-15)\
    \ can be used with De-Hallucinator, e.g., GloVe [\\[45\\]](#page-11-16), BERT\
    \ [\\[11\\]](#page-10-15), or FastText [\\[5\\]](#page-10-16).\n\nGiven the embeddings\
    \ of the API references, De-Hallucinator retrieves API references that are most\
    \ similar to the input code piece. To this end, the approach embeds the input\
    \ code piece and searches for the API references that minimize the cosine distance\
    \ to the input code piece. The parameter specifies the number of API references\
    \ to include in the prompt.\n\n3.3.2 Example. Getting back to our running example,\
    \ consider the third section in Fig. [4.](#page-3-0) It shows the API reference\
    \ from our example project that the retrieval component finds to be the topmost\
    \ relevant to the incomplete code (initial prompt). Even though our implementation\
    \ retrieves relevant API references, we show only one in the example for brevity.\n\
    \n3.3.3 Application to Code Completion. For code completion, we split the given\
    \ input code piece into lines, then retrieve the most relevant APIs for each line,\
    \ and finally merge the most similar API references into single sorted list. The\
    \ reason for retrieving the API references similar to full lines of code, as opposed\
    \ to only API usages, is that we want the completion to avoid re-implementing\
    \ existing code. Therefore, if there exists some API similar to a line of code\
    \ that does not use any APIs, we want the approach to be able to retrieve suitable\
    \ API references to generate the correct completion. We embed the API references\
    \ into a vector space using Sentence-BERT [\\[51\\]](#page-11-17), a BERT-based\
    \ model designed for measuring the semantic similarity between sentences. We use\
    \ a variant of this\n\n<span id=\"page-3-2\"></span><sup>5</sup>https://codeql.github.com/\n\
    \nmodel that is pre-trained on code.[6](#page-4-1) The model maps sentences, or\
    \ in our case lines of code, into a dense vector representation of size 768.\n\
    \nAfter embedding the API references, the approach indexes the normalized vectors\
    \ (/| | for all ∈ API references) in a Ball Tree.[7](#page-4-2) This index allows\
    \ for fast retrieval of nearest neighbors. During the retrieval, we embed each\
    \ line in the input using the same pre-trained SentenceBERT model used for indexing\
    \ the API references, and then normalize the vectors. The normalization is done\
    \ to turn the Euclidean distance used by the Ball Tree into cosine similarity,\
    \ which is commonly used. Next, we find the closest API reference of each line\
    \ by querying the Ball Tree constructed in the pre-analysis step. The result is\
    \ a list of API references, sorted by their similarity to the line in the input.\
    \ To obtain a single ranked list of API references, we merge the lists across\
    \ all ∈ completion based on their similarity scores. This finally yields a single\
    \ list of API references, of which we use the top- as additional context to add\
    \ into the prompt.\n\n3.3.4 Application to Test Generation. For test generation,\
    \ we extract all API usages in a previously generated test using regular expression\
    \ matching and embed them. Next, we retrieve the most relevant APIs for every\
    \ API usage and return a single list. Here we retrieve API references based on\
    \ API usages, and not based on lines. The reason is that as there are no ground\
    \ truths for the test generation task, and the main goal is to generate passing\
    \ tests. Therefore, fixing a wrong API usage is more important than avoiding re-implementation\
    \ of existing code. The embedding used for indexing the API references and during\
    \ retrieval is a BERT-based model available on HuggingFace.[8](#page-4-3) The\
    \ reason for using a different model than the one used for code completion is\
    \ that not all models on HuggingFace are compatible with TypeScript, so we choose\
    \ a compatible model. Using mean pooling, we embed the code pieces into a vector\
    \ of size 768. We use the same model for both indexing and retrieval, where during\
    \ indexing each API signature is embedded and stored in a list, and during retrieval\
    \ the API usage is embedded. During retrieval, we perform a linear search for\
    \ the most relevant API references. Since the size of JavaScript projects are\
    \ much smaller than the Python projects, there is not much benefit in using the\
    \ Ball Tree data structure.\n\n#### 3.4 Prompt Construction\n\n3.4.1 General Idea.\
    \ Given the input and a list of at most API references that may enable the LLM\
    \ to accurately generate code, De-Hallucinator constructs an augmented prompt\
    \ for querying the model. The prompt is designed in a way that resembles \"normal\"\
    \ code, i.e., the kind of data that the LLM has been trained on. The API references\
    \ are augmented as a block of commented lines to the prompt. These lines start\
    \ with API Reference:, and the following lines contain the relevant API references\
    \ in decreasing order of similarity to the lines in the input of the retrieval\
    \ module.\n\n<span id=\"page-4-2\"></span><span id=\"page-4-1\"></span><sup>6</sup>https://huggingface.co/flax-sentence-embeddings/st-codesearch-distilroberta-base\
    \ <sup>7</sup>https://scikit-learn.org/stable/modules/neighbors.html#ball-tree\n\
    \n<span id=\"page-4-3\"></span><sup>8</sup><https://huggingface.co/jinaai/jina-embeddings-v2-base-code>\n\
    \n3.4.2 Example. For our running example, the \"Iterative prompt\" section in\
    \ Fig. [4](#page-3-0) shows the prompt for function search in our example, augmented\
    \ with the API reference. Given the iterative prompt, the same LLM that predicted\
    \ the code in Fig. [2,](#page-0-3) completes this function correctly in the last\
    \ section of Fig. [4.](#page-3-0)\n\n3.4.3 Application to Code Completion. In\
    \ the code completion task, we prepend the prompt with the API references, as\
    \ it minimally disrupts the structure of the existing code. See our running example\
    \ for illustration.\n\n3.4.4 Application to Test Generation. On the other hand,\
    \ for test generation, as TestPilot already includes additional information into\
    \ the prompt, we append the API references to the end of the additional context\
    \ section. Figure [6](#page-7-0) shows how the prompt is augmented with the API\
    \ references in JavaScript, and the model's success in generating a correct test\
    \ based on that prompt.\n\n#### <span id=\"page-4-0\"></span>3.5 Integration with\
    \ the LLM\n\nDe-Hallucinator is designed with minimal assumptions about the underlying\
    \ LLM, and the tool that solves the code generation task. The approach considers\
    \ the LLM to be a black box that we query with a string, which then returns one\
    \ or multiple strings with suggested code pieces. Hence, we do not fine-tune the\
    \ LLM, or train a model to preform retrievals, which makes De-Hallucinator applicable\
    \ to more scenarios. To that end, the instantiation of De-Hallucinator in both\
    \ code completion and test generation tasks are compatible with any LLM, and our\
    \ experiments with five LLMs show the flexibility of the approach.\n\n#### <span\
    \ id=\"page-4-4\"></span>4 IMPLEMENTATION\n\nThe general ideas behind De-Hallucinator\
    \ are language-agnostic, and the approach can be applied to different programming\
    \ languages and to different code prediction tasks. We present two implementations,\
    \ one for code completion in Python and one for test generation in JavaScript.\
    \ The code completion implementation is in Python and builds on top of the HuggingFace\
    \ transformers library. Adapting our implementation to other models requires only\
    \ to adjust the prompt size of the model and to select other parameters passed\
    \ to its API. The test generation implementation is in TypeScript and builds on\
    \ top of the state-of-the-art LLM-based test generator TestPilot [\\[54\\]](#page-11-1).\
    \ Like TestPilot, we use GPT-3.5-turbo as the LLM. TestPilot generates tests by\
    \ going through the functions in the package under test, and for each function\
    \ tries to generate a test with a simple input, which consists of a test header\
    \ and the signature of the function under test. Then, a set of \"prompt refiners\"\
    \ modify the prompt to include usage snippets, error messages, and the body of\
    \ the function under test. We implement two new prompt refiners, one for the RAG\
    \ prompts, and one for iterative prompts. These two refiners are only activated\
    \ when a test fails with an error that is likely caused by a hallucinated API,\
    \ which we detect by checking if the error message contains \"is not a function\"\
    \ or \"of undefined\".\n\n#### 5 EVALUATION\n\nTo evaluate the effectiveness and\
    \ efficiency of our approach, we perform experiments that answer the following\
    \ research questions:\n\n- Table 2: List of projects used for evaluation.\n- RQ1:\
    \ How much does De-Hallucinator improve the generated code compared to the baseline\
    \ approachs?\n- RQ2: How effective is De-Hallucinator at adding the correct API\
    \ references to the prompt?\n- RQ3: How do the hyperparameters of De-Hallucinator\
    \ affect the results?\n- RQ4: How efficient is De-Hallucinator, and how much do\
    \ the different steps of the approach contribute to the running time?\n\n####\
    \ 5.1 Experimental Setup\n\n5.1.1 Tasks. Our evaluation targets two tasks, code\
    \ completion and test generation. For code completion, we define the task as completing\
    \ an incomplete function at the beginning of a line with an API usage, given the\
    \ preceding code and the existing code in the project. This problem definition\
    \ matches the common scenario of a developer implementing a function in an existing\
    \ project, where the code to be written should use a project-specific API. For\
    \ example, suppose that the cursor in Fig. [1](#page-0-2) is at the beginning\
    \ of the code marked with gray background. Everything above the cursor is our\
    \ incomplete code , and the problem is to predict the marked code ′ , which refers,\
    \ e.g., to the project-specific relevance API. For test generation, the task is\
    \ to generate tests for a given JavaScript package. This problem setting has been\
    \ well established by previous work [\\[3,](#page-10-12) [54\\]](#page-11-1).\n\
    \n#### 5.1.2 LLMs and Baseline.\n\nCode Completion. We evaluate the code completion\
    \ task on four state-of-the-art LLMs: CodeGen [\\[43\\]](#page-11-10) with 2.7B\
    \ parameters (Salesforce/codegen-2B-mono), CodeGen 2.5 [\\[42\\]](#page-11-12)\
    \ with 7B parameters (Salesforce/codegen25-7b-mono), UniXCoder [\\[18\\]](#page-10-9)\
    \ with 125M parameters (microsoft/unixcoder-base), and StarCoder+ [\\[31\\]](#page-10-17)\
    \ with 15.5B parameters (bigcode/starcoderplus). The reason for selecting these\
    \ models is that they cover a variety of parameter sizes, model architectures,\
    \ and pre-training processes. We leave all parameters of the models at their defaults,\
    \ except for the maximum new tokens parameter, which we set to 256 to allow for\
    \ longer completions. As a baseline, we query the models with a prompt that contains\
    \ all the code preceding the cursor. In case this prompt exceeds the maximum prompt\
    \ size of 2,048 tokens, we truncate the prompt from the beginning.\n\nTest Generation.\
    \ For the test generation task, we build upon Test-Pilot and use GPT-3.5-turbo-0125\
    \ for the LLM as the OpenAI GPT models are already integrated into TestPilot and\
    \ require minimal effort to run. As a baseline, we use the original TestPilot\
    \ implementation with a one-hour time limit per package, 130k token limit per\
    \ package, and four completions per prompt with temperature 0.1. To make the comparison\
    \ fair, we set the token limit of De-Hallucinator to the amount of tokens used\
    \ by the baseline, and the number of completions to four with temperature 0.1.\
    \ This prevents De-Hallucinator being advantaged with generating more tokens.\
    \ Moreover, we cache the model outputs so that the same prompts return the same\
    \ completion for De-Hallucinator and the baseline.\n\n#### 5.1.3 Datasets.\n\n\
    Code Completion. With the goal of having a diverse set of projects in terms of\
    \ size, domain, and popularity, we gather a dataset of\n\n<span id=\"page-5-0\"\
    ></span>\n\n| Project (owner/name)                         | Commit  | LoC   \
    \  | Stars∗ |  |  |  |  |\n|----------------------------------------------|---------|---------|--------|--|--|--|--|\n\
    | Python projects used for code completion     |         |         |        |\
    \  |  |  |  |\n| graphql-python/graphene                      | 57cbef6 | 9,484\
    \   | 7.8k   |  |  |  |  |\n| geopy/geopy                                  | ef48a8c\
    \ | 10,000  | 4.3k   |  |  |  |  |\n| nvbn/thefuck                           \
    \      | ceeaeab | 12,181  | 83.3k  |  |  |  |  |\n| aaugustin/websockets∗∗  \
    \                     | ba1ed7a | 14,186  | 5k     |  |  |  |  |\n| arrow-py/arrow\
    \                               | 74a759b | 14,402  | 8.6k   |  |  |  |  |\n|\
    \ lektor/lektor                                | be3c8cb | 16,852  | 3.8k   |\
    \  |  |  |  |\n| Parsely/streamparse                          | aabd9d0 | 26,214\
    \  | 1.5k   |  |  |  |  |\n| Supervisor/supervisor                        | ca54549\
    \ | 29,860  | 8.3k   |  |  |  |  |\n| mwaskom/seaborn                        \
    \      | f9827a3 | 37,367  | 12.1k  |  |  |  |  |\n| psf/black               \
    \                     | ef6e079 | 106,005 | 37.6k  |  |  |  |  |\n| scikit-learn/scikit-learn\
    \                    | f3c6fd6 | 193,863 | 58.5k  |  |  |  |  |\n| JavaScript\
    \ projects used for test generation |         |         |        |  |  |  |  |\n\
    | node-red/node-red                            | 29ed5b2 | 60      | 18.8k  |\
    \  |  |  |  |\n| winstonjs/winston                            | c63a5ad | 496\
    \     | 22.2k  |  |  |  |  |\n| prettier/prettier                            |\
    \ 7142cf3 | 916     | 48.5k  |  |  |  |  |\n| tj/commander.js                \
    \              | 83c3f4e | 1,134   | 26.3k  |  |  |  |  |\n| js-sdsl/js-sdsl \
    \                             | 055866a | 1,198   | 0.7k   |  |  |  |  |\n| goldfire/howler.js\
    \                           | 003b917 | 1,319   | 23.1k  |  |  |  |  |\n| websockets/ws\
    \                                | b73b118 | 1,546   | 21.2k  |  |  |  |  |\n\
    | handlebars-lang/handlebars.js                | 8dc3d25 | 2,117   | 17.8k  |\
    \  |  |  |  |\n| petkaantonov/bluebird                        | df70847 | 3,105\
    \   | 20.4k  |  |  |  |  |\n| hapijs/joi                                   | 5b96852\
    \ | 4,149   | 20.7k  |  |  |  |  |\n| Unitech/pm2                            \
    \      | a092db2 | 5,048   | 40.9k  |  |  |  |  |\n| 11ty/eleventy           \
    \                     | e71cb94 | 5,772   | 16.4k  |  |  |  |  |\n\n<sup>∗</sup>\
    \ As of June 5, 2024\n\n∗∗ Has been moved to python-websockets/websockets\n\n\
    eleven public Python projects from GitHub, shown in Table [2](#page-5-0) for the\
    \ code completion task. We construct a dataset of API-related code completion\
    \ tasks by removing API usages from the benchmark projects and by considering\
    \ the removed code as the ground truth to be predicted by a model. For each such\
    \ API call, we remove the lines containing the call. If a call spans multiple\
    \ lines, we remove all of them. To prevent data leakage from imports of the API\
    \ in the ground truth, we also remove API-related imports. Next, we check if the\
    \ off-the-shelf LLMs can predict the exact code as in the original file using\
    \ the code preceding the cursor as the prompt. If an LLM predicts exactly the\
    \ original code, we ignore this API usage for the evaluation, as there is no need\
    \ to further improve the prediction and to avoid any potential memorizations.\
    \ We continue with this process for each of the four models, until we have ten\
    \ code completion tasks for each of the eleven projects. During this process,\
    \ we ignore 18, 51, 76, and 31 completions for UniXcoder, CodeGen, CodeGen v2.5,\
    \ and StarCoder+, respectively. Overall, the code completion evaluation dataset\
    \ consists of 11 projects × 10 × 4 models = 440 code completion tasks.\n\nTest\
    \ Generation. For the test generation task, we also gather a diverse set of 12\
    \ JavaScript projects from GitHub, shown in Table [2.](#page-5-0) These projects\
    \ cover a variety of domains, such as website generation, code formatting, and\
    \ process management. Since TestPilot cannot generate tests for ES modules, we\
    \ only consider JavaScript\n\nDe-Hallucinator: Mitigating LLM Hallucinations in\
    \ Code Generation Tasks via Iterative Grounding\n\nprojects that are CommonJS\
    \ packages. The rest of the setup is the same as in the TestPilot paper [\\[54\\\
    ]](#page-11-1).\n\n5.1.4 Metrics.\n\nCode Completion. We evaluate the code completions\
    \ in three ways:\n\n- Edit distance. To quantify the number of edits a developer\
    \ needs to apply after receiving a code completion, we measure the edit distance\
    \ between the predicted code and the ground truth. This metric provides a sense\
    \ for how many token edits are saved when using De-Hallucinator. We compute edit\
    \ distance using the Levenshtein distance at the subtoken level. For each pair\
    \ of completion and ground truth, we tokenize the code pieces with a GPT-2 fast\
    \ tokenizer,[9](#page-6-0) and then calculate the edit distance using NLTK's edit\\\
    _distance. [10](#page-6-1)\n- Normalized edit similarity. Similar to previous\
    \ work [\\[36\\]](#page-11-18) we also compute the normalized edit similarity.\
    \ To this end, we normalize the absolute edit distance (computed as above) to\
    \ the length of the longer of the two token sequences, and then turn the result\
    \ into a similarity metric.\n- Exact API match. Since the goal of De-Hallucinator\
    \ is to predict better API usages, we measure how many of all desired API usages\
    \ are predicted exactly as in the ground truth. To identify the API usages in\
    \ the lines of code to complete, we extract function calls, including the access\
    \ path to the function, and the parameters.\n\nFor all the above metrics, we report\
    \ the best completion obtained among completions of De-Hallucinator. Measuring\
    \ the @ matches a common usage scenario where a developer inspects a ranked list\
    \ of code completion suggestions, and picks the first that matches the developer's\
    \ expectations.\n\nTest Generation. For the test generation task, we use the following\
    \ three metrics:\n\n- Number of passing tests. We count the number of passing\
    \ tests as a proxy for code without any hallucinations.\n- Coverage. We measure\
    \ the statement coverage in the passing tests.\n- Number of fixed hallucinated\
    \ tests. We measure the number of tests that initially crash with \"∗ is not a\
    \ function\" or \"Reading property of undefined\" errors and that subsequently\
    \ De-Hallucinator turns into passing tests.\n\n5.1.5 Hardware. We perform the\
    \ experiments with the CodeGen v2.5 model and the GPT-3.5-turbo-0125 model on\
    \ a machine equipped with two Nvidia T4 GPUs, each having 16GB of memory. The\
    \ experiments with the UniXcoder, CodeGen, and the StarCoder+ models are performed\
    \ on a machine with a single Nvidia Tesla V100 with 32GB of memory. Each machine\
    \ has a 48-core Intel Xeon CPU clocked at 2.20GHz.\n\n#### <span id=\"page-6-4\"\
    ></span>5.2 RQ1: Effectiveness of De-Hallucinator\n\nCode Completion. In the first\
    \ set of experiments, we investigate to what extent De-Hallucinator improves code\
    \ completions compared to the baseline. By default, we run De-Hallucinator with\
    \ = 3\n\n<span id=\"page-6-1\"></span><span id=\"page-6-0\"></span>![](_page_6_Figure_15.jpeg)\n\
    \n<span id=\"page-6-2\"></span>Table 3: Effectiveness of De-Hallucinator in code\
    \ completion compared to the baseline on four off-the-shelf LLMs. The bold numbers\
    \ show statistically significant improvement over the initial prompt. The numbers\
    \ in parentheses show the relative improvement over the baseline.\n\n| Prompt<br>type\
    \              | UniXCoder<br>125M                    | CodeGen v1<br>2B     \
    \                | CodeGen<br>v2.5 7B                   | StarCoder+<br>15B  \
    \                  |  |\n|-----------------------------|--------------------------------------|--------------------------------------|--------------------------------------|--------------------------------------|--|\n\
    |                             | Edit distance (lower is better):     |       \
    \                               |                                      |     \
    \                                 |  |\n| Initial<br>RAG<br>Iterative | 52.4<br>46.8\
    \ (10.7%)<br>25.9 (50.6%) | 40.0<br>33.4 (16.5%)<br>30.7 (23.3%) | 47.2<br>31.6\
    \ (33.0%)<br>30.1 (36.3%) | 44.6<br>35.9 (19.4%)<br>33.5 (24.9%) |  |\n|     \
    \                        | Edit similarity (lower is better):   |            \
    \                          |                                      |          \
    \                            |  |\n| Initial<br>RAG<br>Iterative | 33.4<br>37.3\
    \ (11.7%)<br>42.6 (27.5%) | 43.6<br>48.0 (10.0%)<br>48.9 (12.1%) | 43.9<br>49.4\
    \ (12.5%)<br>50.2 (14.2%) | 33.2<br>38.0 (14.3%)<br>39.7 (19.3%) |  |\n|     \
    \                        | Exact API match (higher is better):  |            \
    \                          |                                      |          \
    \                            |  |\n| Initial<br>RAG<br>Iterative | 4.8<br>4.8\
    \ (0.0%)<br>5.9 (23.9%)     | 7.1<br>10.2 (42.6%)<br>11.1 (55.3%)  | 8.3<br>11.6\
    \ (39.1%)<br>13.4 (61.0%)  | 5.7<br>7.5 (32.0%)<br>7.5 (32.0%)    |  |\n|    \
    \                         |                                      |           \
    \                           |                                      |         \
    \                             |  |\n\n<span id=\"page-6-3\"></span>Table 4: Effectiveness\
    \ of De-Hallucinator in test generation compared to Test-Pilot. The bold numbers\
    \ show statistically significant improvement over the baseline. The numbers in\
    \ parentheses show the relative improvement over the baseline.\n\n| Prompt type\
    \         | Passing      | Coverage     | Fixed hallu  |  |\n|---------------------|--------------|--------------|--------------|--|\n\
    |                     | tests        |              | cinations    |  |\n| Initial\
    \ (TestPilot) | 64.8         | 32.1         | 19.3         |  |\n| RAG & iterative\
    \     | 66.3 (3.1%)  | 33.7 (3.6%)  | 43.2 (94.0%) |  |\n| Iterative         \
    \  | 76.4 (17.9%) | 37.0 (15.5%) | 31.4 (63.2%) |  |\n\niterations and add = 20\
    \ API references into the prompt. As shown in Table [3,](#page-6-2) De-Hallucinator\
    \ reduces the edit distance by 9.3 to 26.5 tokens, on average over the completions\
    \ by the initial prompt, which is a relative improvement between 23.3% and 50.6%\
    \ . This in turn translates to normalized edit similarity improvements of 12.1%\
    \ to 27.5% relative to the baseline. Moreover, the approach relatively improves\
    \ the exact API matches by 23.9% to 61.0%. For example, for the CodeGen v2.5 model,\
    \ De-Hallucinator is able to predict 1.5 times more APIs correctly than the baseline.\
    \ The approach shows statistically significant (using the Wilcoxon test and Pratt\
    \ method) improvements over the baseline consistently for all metrics and all\
    \ models. For example, Figure [5](#page-7-1) shows a scenario where De-Hallucinator\
    \ improves the completion. In this case the correct function is used by the model\
    \ in the first try, but the order of parameters is wrong. By providing the API\
    \ reference in the prompt, De-Hallucinator predicts the correct API usage, as\
    \ shown in Fig. [5.](#page-7-1)\n\nTest Generation. In the second set of experiments,\
    \ we evaluate the effectiveness of De-Hallucinator in test generation. We use\
    \ = 3 and = 3 as default parameters for these experiments. Table [4](#page-6-3)\
    \ shows statistically significant (using Wilcoxon test and Pratt method) improvements\
    \ for code coverage and fixed hallucinations by De-Hallucinator. Since RAG prompts\
    \ use the initial prompt for retrieval, and because the initial prompt just contains\
    \ a single signature, it is not as useful as iterative prompts. This is also reflected\
    \ in Table [4](#page-6-3) as lower coverage compared to only using iterative prompts.\n\
    \n<span id=\"page-7-1\"></span>**async def** schedule\\_formatting(sources: Set[Path],\
    \ fast: bool, write\\_back: WriteBack, mode: Mode, report: \"Report\", loop: asyncio.AbstractEventLoop,\
    \ executor: \"Executor\") -> **None**: \"\"\"Run formatting of `sources` in parallel\
    \ using the provided `executor`. (Use ProcessPoolExecutors for actual parallelism.)\
    \ `write\\_back`, `fast`, and `mode` options are passed to :func:`format\\_file\\\
    _in\\_place`. \"\"\" cache: Cache = {} **if** write\\_back **not in** (WriteBack.DIFF,\
    \ WriteBack.COLOR\\_DIFF): cache = read\\_cache(mode) sources, cached = filter\\\
    _cached(sources, cache) # <- baseline sources, cached = filter\\_cached(cache,\
    \ sources) # <- ground truth # API Reference: # filter\\_cached(cache: Cache,\
    \ sources: Iterable[Path]) -> Tuple[Set[Path], Set[Path]] # Split an iterable\
    \ of paths in `sources` into two sets. The first contains paths of files that\
    \ modifi ... **async def** schedule\\_formatting(sources: Set[Path], fast: bool,\
    \ write\\_back: WriteBack, mode: Mode, report: \"Report\", loop: asyncio.AbstractEventLoop,\
    \ executor: \"Executor\") -> **None**: \"\"\"Run formatting of `sources` in parallel\
    \ using the provided `executor`. (Use ProcessPoolExecutors for actual parallelism.)\
    \ `write\\_back`, `fast`, and `mode` options are passed to :func:`format\\_file\\\
    _in\\_place`. \"\"\" cache: Cache = {} **if** write\\_back **not in** (WriteBack.DIFF,\
    \ WriteBack.COLOR\\_DIFF): cache = read\\_cache(mode) sources, cached = filter\\\
    _cached(cache, sources) #<-De-Hallucinator\n\nFigure 5: Completion by CodeGen\
    \ highlighted in red , the ground truth, highlighted in green, and the completion\
    \ by De-Hallucinator after augmenting the prompt with relevant APIs highlighted\
    \ in blue .\n\nNote that TestPilot uses some prompt refiners, such as retrying\
    \ with error message, and including usage snippets and function bodies. These\
    \ refiners can mitigate some hallucinations, but not as much as De-Hallucinator,\
    \ as shown in Section [5.2.](#page-6-4) For example, Figure [6](#page-7-0) shows\
    \ a test generated by TestPilot, which uses non-existing APIs, but after providing\
    \ the API reference in the prompt De-Hallucinator generates a test using the correct\
    \ API.\n\n#### 5.3 RQ2: Correct Retrieval of API References\n\nCode Completion.\
    \ To better understand the effectiveness of De-Hallucinator, we investigate how\
    \ often the approach successfully augments the prompt with the correct API references.\
    \ Answering this question for all code completion tasks and all LLMs is difficult,\
    \ because comparing the API references to the API usages is non-trivial due to\
    \ different ways of importing APIs and passing arguments. Instead, for code completion,\
    \ we manually inspect a sample of 20 completion tasks per LLM and count the number\
    \ of times an API used in the ground truth is successfully added to the prompt\
    \ by De-Hallucinator.\n\nIn our inspected samples for code completion, there are\
    \ in total between 22 and 25 API usages (a completion can contain multiple API\
    \ usages). The new prompt generated by our approach contains the correct API between\
    \ two and six times, as shown in Table [5.](#page-7-2) Moreover, for CodeGen and\
    \ CodeGen v2.5 there are five completion tasks where the completion from the initial\
    \ prompt either misses the APIs or uses them incorrectly, but in the completions\
    \ from RAG or iterative prompts, the API reference section of the prompt contains\
    \ the correct API. The same happens for UniXcoder in four\n\n<span id=\"page-7-0\"\
    ></span>\n\n| let mocha = require('mocha');                   |  |  |  |  |  |\
    \  |\n|-------------------------------------------------|--|--|--|--|--|--|\n\
    | let assert = require('assert');                 |  |  |  |  |  |  |\n| let js_sdsl\
    \ = require('js-sdsl');               |  |  |  |  |  |  |\n| // class js-sdsl.Deque(t\
    \ = [], i = 1 << 12)     |  |  |  |  |  |  |\n| describe('test js_sdsl', function()\
    \ {           |  |  |  |  |  |  |\n| it('test js-sdsl.Deque', function(done) {\
    \       |  |  |  |  |  |  |\n| let deque = new js_sdsl.Deque([1, 2, 3, 4, 5]);\
    \ |  |  |  |  |  |  |\n| assert.equal(deque.size(), 5);                  |  |\
    \  |  |  |  |  |\n| assert.equal(deque.front(), 1);                 |  |  |  |\
    \  |  |  |\n| assert.equal(deque.back(), 5);                  |  |  |  |  |  |\
    \  |\n| deque.push_back(6);                             |  |  |  |  |  |  |\n\
    | assert.equal(deque.size(), 6);                  |  |  |  |  |  |  |\n| assert.equal(deque.back(),\
    \ 6);                  |  |  |  |  |  |  |\n| deque.push_front(0);           \
    \                 |  |  |  |  |  |  |\n| assert.equal(deque.size(), 7);      \
    \            |  |  |  |  |  |  |\n| assert.equal(deque.front(), 0);          \
    \       |  |  |  |  |  |  |\n| assert.equal(deque.pop_back(), 6);            \
    \  |  |  |  |  |  |  |\n| assert.equal(deque.size(), 6);                  |  |\
    \  |  |  |  |  |\n| assert.equal(deque.pop_front(), 0);             |  |  |  |\
    \  |  |  |\n| assert.equal(deque.size(), 5);                  |  |  |  |  |  |\
    \  |\n| done();                                         |  |  |  |  |  |  |\n\
    | })                                              |  |  |  |  |  |  |\n| })  \
    \                                            |  |  |  |  |  |  |\n|          \
    \                                       |  |  |  |  |  |  |\n| let mocha = require('mocha');\
    \                   |  |  |  |  |  |  |\n| let assert = require('assert');   \
    \              |  |  |  |  |  |  |\n| let js_sdsl = require('js-sdsl');      \
    \         |  |  |  |  |  |  |\n| // class js-sdsl.Deque(t = [], i = 1 << 12) \
    \    |  |  |  |  |  |  |\n| // API Reference:                               |\
    \  |  |  |  |  |  |\n\n| // js-sdsl.Deque.prototype.pushFront(t)   |  |\n|-------------------------------------------|--|\n\
    | // js-sdsl.Deque.prototype.front()        |  |\n| // js-sdsl.Queue.prototype.front()\
    \        |  |\n| describe('test js_sdsl', function() {     |  |\n| it('test js-sdsl.Deque',\
    \ function(done) { |  |\n| let deque = new js_sdsl.Deque([1, 2, 3]); |  |\n| assert.equal(deque.front(),\
    \ 1);           |  |\n| deque.pushFront(0);                       |  |\n| assert.equal(deque.front(),\
    \ 0);           |  |\n| done();                                   |  |\n| }) \
    \                                       |  |\n\n<span id=\"page-7-2\"></span>Figure\
    \ 6: Test generated by TestPilot using GPT-3.5-turbo (top), and the iterative\
    \ prompt by De-Hallucinator resulting in correct usage of APIs (bottom).\n\n})\n\
    \n|              |       | API usages |                         |         |  \
    \       |         |\n|--------------|-------|------------|-------------------------|---------|---------|---------|\n\
    | Model        | Tasks | Missing    | Expected API ref. added |         |    \
    \     |         |\n|              |       | /wrong     | RAG                 \
    \    | Iter. 1 | Iter. 2 | Iter. 3 |\n| UniXcoder    | 20    | 18         | 4\
    \                       | 5       | 5       | 5       |\n| CodeGen v1   | 20 \
    \   | 17         | 5                       | 6       | 6       | 6       |\n|\
    \ CodeGen v2.5 | 20    | 15         | 5                       | 5       | 6  \
    \     | 6       |\n| StarCoder+   | 20    | 17         | 2                   \
    \    | 3       | 3       | 3       |\n\ntasks and for StarCoder+ in two tasks.\
    \ For cases where the approach fails to add the correct API reference into the\
    \ prompt, the main reason is that the initial completion has low relevance w.r.t.\
    \ the ground truth.\n\nTest Generation. Since for the test generation task there\
    \ are no ground truths for the generated code pieces, manual inspection is infeasible.\
    \ Instead, we measure the number of passing tests and the number of non-crashing\
    \ failing tests from an iterative prompt, as a proxy of success for the retrieval.\
    \ Note that an iterative prompt is only created when an initial prompt causes\
    \ a crash with one of the specified errors in Section [4.](#page-4-4) We observe\
    \ that from the 622 instances where an iterative prompt is generated, 16.7% of\
    \ iterative prompts result in a passing test, and 26.8% of iterative prompts result\
    \ in a\n\n<span id=\"page-8-0\"></span>![](_page_8_Figure_1.jpeg)\n\nFigure 7:\
    \ Effects of and for code completion.\n\ntest without hallucinations. These results\
    \ are also in line with the manual inspections of the code completion task above.\n\
    \nOverall, the results show that De-Hallucinator is able to successfully augment\
    \ the prompt with the correct API references in many cases.\n\n#### 5.4 RQ3: Impact\
    \ of the Hyperparameters\n\nThis research question evaluates the impact of the\
    \ two main parameters of our approach. First, we consider the number of iterations\
    \ of iterative prompting. For both code completion and test generation, we run\
    \ the approach with ∈ {1, 2, 3}. As shown in Fig. [7,](#page-8-0) the first iteration\
    \ provides significant improvement over the baseline, but the gain is reduced\
    \ with further iterations. Higher values of are beneficial when the model cannot\
    \ immediately predict a relevant code, but upon presenting the first round of\
    \ API references, the model responds with more relevant outputs. At the same time,\
    \ even = 1 provides clear improvements over the baseline, which makes De-Hallucinator\
    \ useful even in scenarios where the cost of querying the model is high. We choose\
    \ = 3 for all other experiments in this paper.\n\nSecond, we study the impact\
    \ of the maximum number of API references that we add to the prompt. Depending\
    \ on the task, the optimal number of API references in the prompt varies. Setting\
    \ low values for can result in missing relevant context, whereas adding many API\
    \ references can confuse the model, while also costing context space. We perform\
    \ experiments with ∈ {2, 10, 20, 40} for code completion, and ∈ {3, 5, 10} for\
    \ test generation. Figure [7](#page-8-0) shows the results of code completion,\
    \ with exact API match peaking between = 10 and = 20. As a default in the rest\
    \ of the paper, we use = 20 for code completion. Figure [8](#page-8-1) shows the\
    \ effects of on coverage of the generated tests. The peak in this case is at =\
    \ 3, which we use as the parameter for other experiments in this paper.\n\n####\
    \ 5.5 RQ4: Efficiency\n\nThe following evaluates the efficiency of the approach\
    \ and how much each of De-Hallucinator's components contributes to its running\
    \ time. The pre-analysis step of code completion using CodeQL\n\n<span id=\"page-8-1\"\
    ></span>![](_page_8_Figure_10.jpeg)\n\nFigure 8: Effects of and for test generation.\n\
    \ntakes, on average, under one second per 1,000 lines of code in a project. For\
    \ the projects in our dataset, it takes at most 80 seconds, and most projects\
    \ need at most 26 seconds for the whole preprocessing phase. In a production-level\
    \ implementation, our CodeQL-based approach could be replaced by using static\
    \ information that is available in an IDE anyway, which is likely to further reduce\
    \ the computational effort. Moreover, updating the indexed API references, e.g.,\
    \ when the code base evolves, can be done at low frequency in the background.\
    \ For test generation, the pre-analysis takes between 0.6 seconds and 20 seconds\
    \ with an average of 3.5 seconds. Because the JavaScript projects in our dataset\
    \ are smaller than the Python projects, the pre-analysis is faster for test generation.\n\
    \nRetrieving relevant APIs and constructing the augmented prompt for one iteration\
    \ takes from 21 to 227 milliseconds for code completion, and from 0.1 to 17 milliseconds\
    \ for test generation. The time to query the LLMs ranges between 1.3 seconds (for\
    \ the remotely deployed GPT-3.5) and 66.7 seconds (for CodeGen v2.5 running on\
    \ our local Nvidia T4 GPU), on average per query. These numbers are roughly the\
    \ same for the baseline and for querying the model with De-Hallucinator-augmented\
    \ prompts. It is important to note that a production-level deployment would run\
    \ the LLM on a GPU cluster, which typically answers queries within tens to hundreds\
    \ of milliseconds, as evidenced by tools like Copilot and Tabnine.\n\n#### 6 LIMITATIONS\
    \ AND THREATS TO VALIDITY\n\nWe assume an API to be available when generating\
    \ the code that uses it. However, in some cases, a developer may first write an\
    \ API usage and then implement the API. In such cases, De-Hallucinator would be\
    \ unable to retrieve the API reference, and hence, could not provide any benefits.\
    \ To address this limitation, one could configure De-Hallucinator to abstain from\
    \ repeatedly querying the LLM if the similarity between the initial completion\
    \ and the retrieved API references is below a threshold. We implement and evaluate\
    \ De-Hallucinator for Python and JavaScript, and although our general approach\
    \ could be applied to any language, our conclusions are valid only for these languages.\
    \ The set of projects we use might\n\nnot be representative of all projects, which\
    \ we try to mitigate by selecting a diverse set of popular projects.\n\n#### 7\
    \ RELATED WORK\n\nData-Driven Code Completion. The idea to augment traditional\
    \ type-based code completion in a data-driven manner was introduced by Bruch et\
    \ al.[\\[8\\]](#page-10-18). More recently, statistical models are used, such\
    \ as a pre-trained BERT model [\\[10\\]](#page-10-19) applied to code completion\
    \ [\\[34\\]](#page-11-19), and models trained for specific kinds of completions,\
    \ e.g., API usages [\\[50\\]](#page-11-20) and test methods [\\[41\\]](#page-11-21).\
    \ Grammars can improve statistical code completions, either by restricting the\
    \ tokens to predict [\\[46\\]](#page-11-0) or by generating code that leaves some\
    \ syntax subtrees undefined [\\[19\\]](#page-10-20). Hellendoorn et al. [\\[21\\\
    ]](#page-10-21) study data-driven code completion based on recorded real-world\
    \ completion requests, with a focus on completing single identifiers. Our work\
    \ differs from all the above by providing project-specific API references based\
    \ on previous completions as an input to a code completion model.\n\nCode Completion\
    \ with LLMs and Local Context. Motivated by the observation that LLMs lack project-specific\
    \ information, Shrivastava et al. [\\[56\\]](#page-11-8) propose a repository-level\
    \ prompt generation technique to select the best context from a set of predefined\
    \ contexts to solve the task of line completion. Their method relies on training\
    \ a separate model that takes a context window around the incomplete line as input,\
    \ and outputs a ranking for additional contexts. The training routine uses the\
    \ LLM (in their case Codex) to calculate the loss function. Ding et al.[\\[12\\\
    ]](#page-10-8) describe a similar method, called CoCoMIC, to address the challenge\
    \ of project-specific APIs. They utilize a custom static analyzer, CCFinder, that\
    \ initially creates a context graph of program components in the project, and\
    \ allows retrieval of relevant contexts to complete a statement. They then fine-tuned\
    \ CodeGen-2B-mono by adding the cross-file contexts to the input. Both of the\
    \ above are tightly coupled with the underlying LLM: The first approach [\\[56\\\
    ]](#page-11-8) uses the LLM to calculate the loss function for training a new\
    \ model, and the second approach [\\[12\\]](#page-10-8) changes the model's weights\
    \ during fine-tuning. In contrast, De-Hallucinator queries the LLM as a black-box,\
    \ and hence, can be easily applied to other models.\n\nAn approach developed concurrently\
    \ with ours [\\[64\\]](#page-11-22) includes fragments of project-specific code\
    \ in the prompt to improve the LLM's predictions. Similar to our work, they also\
    \ query the model iteratively. Unlike De-Hallucinator, their approach retrieves\
    \ existing code fragments, and not API signatures. Since their approach relies\
    \ on existing code fragments, it can only improve predictions when a project-specific\
    \ API has already been used before and when this existing usage resembles the\
    \ desired prediction, whereas our approach applies to all usages of project-specific\
    \ APIs.\n\nCombining LLMs and Retrieval. Lu et al.[\\[36\\]](#page-11-18) use\
    \ conventional retrieval methods to find similar code pieces in a pre-defined\
    \ code database and add them to the prompt as dead code. Although this approach\
    \ improves the quality of code completions by the LLMs, it does not address the\
    \ challenge of project-specific APIs. Nashid et al.[\\[39\\]](#page-11-7) propose\
    \ a retrieval technique to find suitable examples for few-shot learning, but do\
    \ not apply the idea to code completion. HyDE [\\[15\\]](#page-10-22) prompts\
    \ an LLM to generate hypothetical textual documents for a given query, and then\
    \ retrieves real documents that\n\nhave an embedding similar to the hypothetical\
    \ documents. Their work shares the observation that LLM predictions may be factually\
    \ inaccurate, e.g., in our case by referring to non-existing APIs, while being\
    \ similar to a factually correct document. By addressing this problem via retrieval,\
    \ their approach is limited to producing already existing documents, whereas De-Hallucinator\
    \ generates new code using an augmented prompt.\n\nAutomated Test Generation.\
    \ Before the era of LLMs, random feedback-directed test generation became practical\
    \ through Randoop [\\[44\\]](#page-11-23). LambdaTester [\\[55\\]](#page-11-24)\
    \ integrates higher order functions into test generation, and Nessie [\\[3\\]](#page-10-12)\
    \ targets asynchronous callbacks. TestPilot [\\[54\\]](#page-11-1) uses LLMs and\
    \ prompt refinement to generate humanreadable regression tests. CodaMosa [\\[27\\\
    ]](#page-10-23) uses LLMs to increase the coverage of automatic test generators\
    \ when stuck in a plateau.\n\nImproving LLM-Suggested Code. To improve code suggested\
    \ by LLMs, existing techniques for automated program repair [\\[26\\]](#page-10-24)\
    \ can be applied in a post-processing step [\\[13\\]](#page-10-25). Alternatively,\
    \ the code predicted by a model can serve as input for initializing and guiding\
    \ component-based code synthesis [\\[49\\]](#page-11-25). The above work and ours\
    \ shares the observation that completions from LLMs often share code elements\
    \ with the desired code. Instead of improving code in a post-processing step,\
    \ De-Hallucinator nudges an LLM toward producing better completions by improving\
    \ the prompt.\n\nQuerying LLMs Multiple Times. Work on program repair queries\
    \ a model multiple times until finding a suitable repair [\\[37\\]](#page-11-26).\
    \ They repeatedly query the model with the same prompt and may trigger thousands\
    \ of queries, whereas De-Hallucinator continuously augments the prompt and queries\
    \ the model only a few times. Li et al.[\\[32\\]](#page-10-26) propose querying\
    \ a model with multiple mutations of the given code, and to then use the completion\
    \ that is closest to the \"average\" completion. De-Hallucinator instead uses\
    \ the initial prediction to construct an improved prompt. Xia et al.[\\[62\\]](#page-11-27)\
    \ introduce conversational program repair, which iteratively improves a prompt\
    \ by adding test failures observed when executing the predicted code. In contrast,\
    \ we do not require tests or executions, but only information that is statically\
    \ available in a typical IDE.\n\nOther Work on Models of Code. The impressive\
    \ abilities of neural models of code [\\[47\\]](#page-11-28) has lead to various\
    \ other applications beyond code completion. For example, neural models provide\
    \ type predictions [\\[20,](#page-10-27) [38,](#page-11-29) [48,](#page-11-30)\
    \ [60\\]](#page-11-31), make predictions about code changes [\\[6,](#page-10-28)\
    \ [22\\]](#page-10-29), and enable code search [\\[16,](#page-10-30) [53\\]](#page-11-32).\
    \ LLMs are shown to be useful, e.g., for code mutation, test oracle generation,\
    \ and test case generation [\\[4,](#page-10-1) [25,](#page-10-31) [54\\]](#page-11-1),\
    \ and for automated program repair [\\[24\\]](#page-10-32).\n\n#### 8 CONCLUSION\n\
    \nMotivated by the inability of current LLM-based code generation approaches to\
    \ correctly predict project-specific APIs, we present De-Hallucinator. The approach\
    \ exploits the observation that LLMs often predict code that is similar to the\
    \ desired code, but factually incorrect. We address the hallucination problem\
    \ by iteratively augmenting the prompt with increasingly relevant API references.\
    \ Our evaluation on two task, code completion and test generation, shows that\
    \ De-Hallucinator significantly improves the quality of generations over the state-of-the-art\
    \ baselines.\n\nDe-Hallucinator: Mitigating LLM Hallucinations in Code Generation\
    \ Tasks via Iterative Grounding\n\n## DATA-AVAILABILITY STATEMENT\n\nOur implementation,\
    \ datasets, and evaluation scripts are publicly available at<https://github.com/AryazE/dehallucinator>\
    \ and [https:](https://github.com/AryazE/testpilot) [//github.com/AryazE/testpilot.](https://github.com/AryazE/testpilot)\n\
    \n## REFERENCES\n\n- <span id=\"page-10-14\"></span>[1] [n. d.]. HuggingFace code\
    \ embedding models. [https://huggingface.co/models?](https://huggingface.co/models?pipeline_tag=feature-extraction&sort=trending&search=code)\
    \ [pipeline\\\\_tag=feature-extraction&sort=trending&search=code.](https://huggingface.co/models?pipeline_tag=feature-extraction&sort=trending&search=code)\
    \ Accessed: 2024- 06-05.\n- <span id=\"page-10-6\"></span>[2] Michael Ahn, Anthony\
    \ Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron David, Chelsea Finn,\
    \ Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman, et al. 2022. Do as i can,\
    \ not as i say: Grounding language in robotic affordances. arXiv preprint arXiv:2204.01691\
    \ (2022).\n- <span id=\"page-10-12\"></span>[3] Ellen Arteca, Sebastian Harner,\
    \ Michael Pradel, and Frank Tip. 2022. Nessie: Automatically Testing JavaScript\
    \ APIs with Asynchronous Callbacks. In ICSE.\n- <span id=\"page-10-1\"></span>[4]\
    \ Patrick Bareiß, Beatriz Souza, Marcelo d'Amorim, and Michael Pradel. 2022. Code\
    \ Generation Tools (Almost) for Free? A Study of Few-Shot, Pre-Trained Language\
    \ Models on Code. CoRR abs/2206.01335 (2022). [https://doi.org/10.48550/arXiv.](https://doi.org/10.48550/arXiv.2206.01335)\
    \ [2206.01335](https://doi.org/10.48550/arXiv.2206.01335) arXiv[:2206.01335](https://arxiv.org/abs/2206.01335)\n\
    - <span id=\"page-10-16\"></span>[5] Piotr Bojanowski, Edouard Grave, Armand Joulin,\
    \ and Tomas Mikolov. 2017. Enriching Word Vectors with Subword Information. TACL\
    \ 5 (2017), 135–146. <https://transacl.org/ojs/index.php/tacl/article/view/999>\n\
    - <span id=\"page-10-28\"></span>[6] Shaked Brody, Uri Alon, and Eran Yahav. 2020.\
    \ A Structural Model for Contextual Code Changes. In OOPSLA.\n- <span id=\"page-10-0\"\
    ></span>[7] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan,\
    \ Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,\
    \ Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon\
    \ Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher\
    \ Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack\
    \ Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and\
    \ Dario Amodei. 2020. Language Models are Few-Shot Learners. In Advances in Neural\
    \ Information Processing Systems 33: Annual Conference on Neural Information Processing\
    \ Systems 2020, NeurIPS. [https://proceedings.neurips.](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html)\
    \ [cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html](https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html)\n\
    - <span id=\"page-10-18\"></span>[8] Marcel Bruch, Martin Monperrus, and Mira\
    \ Mezini. 2009. Learning from examples to improve code completion systems. In\
    \ European Software Engineering Conference and International Symposium on Foundations\
    \ of Software Engineering (ESEC/FSE). ACM, 213–222.\n- <span id=\"page-10-2\"\
    ></span>[9] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de\
    \ Oliveira Pinto, Jared Kaplan, Harrison Edwards, Yuri Burda, Nicholas Joseph,\
    \ Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy\
    \ Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder,\
    \ Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter,\
    \ Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios\
    \ Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol,\
    \ Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu\
    \ Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Joshua\
    \ Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage,\
    \ Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish,\
    \ Ilya Sutskever, and Wojciech Zaremba. 2021. Evaluating Large Language Models\
    \ Trained on Code. CoRR abs/2107.03374 (2021). arXiv[:2107.03374 https://arxiv.org/abs/2107.03374](https://arxiv.org/abs/2107.03374)\n\
    - <span id=\"page-10-19\"></span>[10] Jacob Devlin, Ming-Wei Chang, Kenton Lee,\
    \ and Kristina Toutanova. 2018. BERT: Pre-training of Deep Bidirectional Transformers\
    \ for Language Understanding. CoRR abs/1810.04805 (2018). arXiv[:1810.04805](https://arxiv.org/abs/1810.04805)<http://arxiv.org/abs/1810.04805>\n\
    - <span id=\"page-10-15\"></span>[11] Jacob Devlin, Jonathan Uesato, Rishabh Singh,\
    \ and Pushmeet Kohli. 2017. Semantic Code Repair using Neuro-Symbolic Transformation\
    \ Networks. CoRR abs/1710.11054 (2017). arXiv[:1710.11054](https://arxiv.org/abs/1710.11054)<http://arxiv.org/abs/1710.11054>\n\
    - <span id=\"page-10-8\"></span>[12] Yangruibo Ding, Zijian Wang, Wasi Uddin Ahmad,\
    \ Murali Krishna Ramanathan, Ramesh Nallapati, Parminder Bhatia, Dan Roth, and\
    \ Bing Xiang. 2022. CoCoMIC: Code Completion By Jointly Modeling In-file and Cross-file\
    \ Context. arXiv preprint arXiv:2212.10007 (2022).\n- <span id=\"page-10-25\"\
    ></span>[13] Zhiyu Fan, Xiang Gao, Abhik Roychoudhury, and Shin Hwei Tan. 2022.\
    \ Improving automatically generated code from Codex via Automated Program Repair.\
    \ Technical Report.\n- <span id=\"page-10-13\"></span>[14] Joseph L Fleiss. 1981.\
    \ Statistical methods for rates and proportions. John Wiley.\n- <span id=\"page-10-22\"\
    ></span>[15] Luyu Gao, Xueguang Ma, Jimmy Lin, and Jamie Callan. 2023. Precise\
    \ Zero-Shot Dense Retrieval without Relevance Labels. In Proceedings of the 61st\
    \ Annual Meeting of the Association for Computational Linguistics (Volume 1: Long\
    \ Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, Anna Rogers, Jordan L.\
    \ Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics,\
    \ 1762–1777. <https://aclanthology.org/2023.acl-long.99>\n- <span id=\"page-10-30\"\
    ></span>[16] Xiaodong Gu, Hongyu Zhang, and Sunghun Kim. 2018. Deep code search.\
    \ In Proceedings of the 40th International Conference on Software Engineering,\
    \ ICSE. 933–944.<https://doi.org/10.1145/3180155.3180167>\n- <span id=\"page-10-7\"\
    ></span>[17] Yu Gu, Xiang Deng, and Yu Su. 2022. Don't Generate, Discriminate:\
    \ A Proposal for Grounding Language Models to Real-World Environments. arXiv preprint\
    \ arXiv:2212.09736 (2022).\n- <span id=\"page-10-9\"></span>[18] Daya Guo, Shuai\
    \ Lu, Nan Duan, Yanlin Wang, Ming Zhou, and Jian Yin. 2022. Unixcoder: Unified\
    \ cross-modal pre-training for code representation. arXiv preprint arXiv:2203.03850\
    \ (2022).\n- <span id=\"page-10-20\"></span>[19] Daya Guo, Alexey Svyatkovskiy,\
    \ Jian Yin, Nan Duan, Marc Brockschmidt, and Miltiadis Allamanis. 2022. Learning\
    \ to Complete Code with Sketches. In ICLR. <https://arxiv.org/abs/2106.10158>\n\
    - <span id=\"page-10-27\"></span>[20] Vincent J. Hellendoorn, Christian Bird,\
    \ Earl T. Barr, and Miltiadis Allamanis. 2018. Deep learning type inference. In\
    \ Proceedings of the 2018 ACM Joint Meeting on European Software Engineering Conference\
    \ and Symposium on the Foundations of Software Engineering, ESEC/SIGSOFT. 152–162.\
    \ [https://doi.org/10.1145/3236024.](https://doi.org/10.1145/3236024.3236051)\
    \ [3236051](https://doi.org/10.1145/3236024.3236051)\n- <span id=\"page-10-21\"\
    ></span>[21] Vincent J. Hellendoorn, Sebastian Proksch, Harald C. Gall, and Alberto\
    \ Bacchelli. 2019. When Code Completion Fails: a Case Study on Real-World Completions.\
    \ In ICSE.\n- <span id=\"page-10-29\"></span>[22] Thong Hoang, Hong Jin Kang,\
    \ David Lo, and Julia Lawall. 2020. Cc2vec: Distributed representations of code\
    \ changes. In Proceedings of the ACM/IEEE 42nd International Conference on Software\
    \ Engineering. 518–529.\n- <span id=\"page-10-3\"></span>[23] Naman Jain, Skanda\
    \ Vaidyanath, Arun Shankar Iyer, Nagarajan Natarajan, Suresh Parthasarathy, Sriram\
    \ K. Rajamani, and Rahul Sharma. 2022. Jigsaw: Large Language Models meet Program\
    \ Synthesis. In 44th IEEE/ACM 44th International Conference on Software Engineering,\
    \ ICSE. 1219–1231. [https://doi.org/10.1145/](https://doi.org/10.1145/3510003.3510203)\
    \ [3510003.3510203](https://doi.org/10.1145/3510003.3510203)\n- <span id=\"page-10-32\"\
    ></span>[24] Nan Jiang, Kevin Liu, Thibaud Lutellier, and Lin Tan. 2023. Impact\
    \ of Code Language Models on Automated Program Repair. In 45th IEEE/ACM International\
    \ Conference on Software Engineering, ICSE. IEEE, 1430–1442. [https://doi.org/10.](https://doi.org/10.1109/ICSE48619.2023.00125)\
    \ [1109/ICSE48619.2023.00125](https://doi.org/10.1109/ICSE48619.2023.00125)\n\
    - <span id=\"page-10-31\"></span>[25] Sungmin Kang, Juyeon Yoon, and Shin Yoo.\
    \ 2023. Large Language Models are Few-shot Testers: Exploring LLM-based General\
    \ Bug Reproduction. In 45th IEEE/ACM International Conference on Software Engineering,\
    \ ICSE. 2312–2323. <https://doi.org/10.1109/ICSE48619.2023.00194>\n- <span id=\"\
    page-10-24\"></span>[26] Claire Le Goues, Michael Pradel, and Abhik Roychoudhury.\
    \ 2019. Automated program repair. Commun. ACM 62, 12 (2019), 56–65. [https://doi.org/10.1145/](https://doi.org/10.1145/3318162)\
    \ [3318162](https://doi.org/10.1145/3318162)\n- <span id=\"page-10-23\"></span>[27]\
    \ Caroline Lemieux, Jeevana Priya Inala, Shuvendu K Lahiri, and Siddhartha Sen.\
    \ 2023. CODAMOSA: Escaping Coverage Plateaus in Test Generation with Pretrained\
    \ Large Language Models. In 45th International Conference on Software Engineering,\
    \ ser. ICSE.\n- <span id=\"page-10-5\"></span>[28] Patrick Lewis, Ethan Perez,\
    \ Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich\
    \ Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. 2020. Retrieval-augmented\
    \ generation for knowledge-intensive nlp tasks. Advances in Neural Information\
    \ Processing Systems 33 (2020), 9459–9474.\n- <span id=\"page-10-11\"></span>[29]\
    \ Jian Li, Yue Wang, Michael R. Lyu, and Irwin King. 2018. Code Completion with\
    \ Neural Attention and Pointer Networks. In Proceedings of the Twenty-Seventh\
    \ International Joint Conference on Artificial Intelligence, IJCAI 2018, July\
    \ 13-19, 2018, Stockholm, Sweden, Jérôme Lang (Ed.). ijcai.org, 4159–4165. [https:](https://doi.org/10.24963/ijcai.2018/578)\
    \ [//doi.org/10.24963/ijcai.2018/578](https://doi.org/10.24963/ijcai.2018/578)\n\
    - <span id=\"page-10-10\"></span>[30] Raymond Li, Loubna Ben Allal, Yangtian Zi,\
    \ Niklas Muennighoff, Denis Kocetkov, Chenghao Mou, Marc Marone, Christopher Akiki,\
    \ Jia Li, Jenny Chim, et al. 2023. StarCoder: may the source be with you! arXiv\
    \ preprint arXiv:2305.06161 (2023).\n- <span id=\"page-10-17\"></span>[31] Raymond\
    \ Li, Loubna Ben Allal, Yangtian Zi, Niklas Muennighoff, Denis Kocetkov, Chenghao\
    \ Mou, Marc Marone, Christopher Akiki, Jia Li, Jenny Chim, Qian Liu, Evgenii Zheltonozhskii,\
    \ Terry Yue Zhuo, Thomas Wang, Olivier Dehaene, Mishig Davaadorj, Joel Lamy-Poirier,\
    \ João Monteiro, Oleh Shliazhko, Nicolas Gontier, Nicholas Meade, Armel Zebaze,\
    \ Ming-Ho Yee, Logesh Kumar Umapathi, Jian Zhu, Benjamin Lipkin, Muhtasham Oblokulov,\
    \ Zhiruo Wang, Rudra Murthy V, Jason Stillerman, Siva Sankalp Patel, Dmitry Abulkhanov,\
    \ Marco Zocca, Manan Dey, Zhihan Zhang, Nour Moustafa-Fahmy, Urvashi Bhattacharyya,\
    \ Wenhao Yu, Swayam Singh, Sasha Luccioni, Paulo Villegas, Maxim Kunakov, Fedor\
    \ Zhdanov, Manuel Romero, Tony Lee, Nadav Timor, Jennifer Ding, Claire Schlesinger,\
    \ Hailey Schoelkopf, Jan Ebert, Tri Dao, Mayank Mishra, Alex Gu, Jennifer Robinson,\
    \ Carolyn Jane Anderson, Brendan Dolan-Gavitt, Danish Contractor, Siva Reddy,\
    \ Daniel Fried, Dzmitry Bahdanau, Yacine Jernite, Carlos Muñoz Ferrandis, Sean\
    \ Hughes, Thomas Wolf, Arjun Guha, Leandro von Werra, and Harm de Vries. 2023.\
    \ StarCoder: may the source be with you! CoRR abs/2305.06161 (2023). <https://doi.org/10.48550/arXiv.2305.06161>\
    \ arXiv[:2305.06161](https://arxiv.org/abs/2305.06161)\n- <span id=\"page-10-26\"\
    ></span>[32] Zongjie Li, Chaozheng Wang, Zhibo Liu, Haoxuan Wang, Shuai Wang,\
    \ and Cuiyun Gao. 2022. CCTEST: Testing and Repairing Code Completion Systems.\
    \ arXiv preprint arXiv:2208.08289 (2022).\n- <span id=\"page-10-4\"></span>[33]\
    \ Jenny T. Liang, Chenyang Yang, and Brad A. Myers. 2024. A Large-Scale Survey\
    \ on the Usability of AI Programming Assistants: Successes and Challenges. In\
    \ Proceedings of the IEEE/ACM 46th International Conference on Software Engineering\
    \ (<conf-loc>, <city>Lisbon</city>, <country>Portugal</country>, </conf-loc>)\
    \ (ICSE '24). Association for Computing Machinery, New York, NY, USA, Article\
    \ 52, 13 pages.<https://doi.org/10.1145/3597503.3608128>\n- <span id=\"page-11-19\"\
    ></span>[34] Fang Liu, Ge Li, Yunfei Zhao, and Zhi Jin. 2020. Multi-Task Learning\
    \ based Pre-Trained Language Model for Code Completion. In ASE.\n- <span id=\"\
    page-11-6\"></span>[35] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki\
    \ Hayashi, and Graham Neubig. 2021. Pre-train, Prompt, and Predict: A Systematic\
    \ Survey of Prompting Methods in Natural Language Processing. CoRR abs/2107.13586\
    \ (2021). arXiv[:2107.13586 https://arxiv.org/abs/2107.13586](https://arxiv.org/abs/2107.13586)\n\
    - <span id=\"page-11-18\"></span>[36] Shuai Lu, Nan Duan, Hojae Han, Daya Guo,\
    \ Seung won Hwang, and Alexey Svyatkovskiy. 2022. ReACC: A Retrieval-Augmented\
    \ Code Completion Framework. arXiv[:2203.07722](https://arxiv.org/abs/2203.07722)\
    \ [cs.SE]\n- <span id=\"page-11-26\"></span>[37] Thibaud Lutellier, Hung Viet\
    \ Pham, Lawrence Pang, Yitong Li, Moshi Wei, and Lin Tan. 2020. CoCoNuT: combining\
    \ context-aware neural translation models using ensemble for program repair. In\
    \ ISSTA '20: 29th ACM SIGSOFT International Symposium on Software Testing and\
    \ Analysis, Virtual Event, USA, July 18-22, 2020, Sarfraz Khurshid and Corina\
    \ S. Pasareanu (Eds.). ACM, 101–114. [https:](https://doi.org/10.1145/3395363.3397369)\
    \ [//doi.org/10.1145/3395363.3397369](https://doi.org/10.1145/3395363.3397369)\n\
    - <span id=\"page-11-29\"></span>[38] Rabee Sohail Malik, Jibesh Patra, and Michael\
    \ Pradel. 2019. NL2Type: Inferring JavaScript function types from natural language\
    \ information. In Proceedings of the 41st International Conference on Software\
    \ Engineering, ICSE 2019, Montreal, QC, Canada, May 25-31, 2019. 304–315.<https://doi.org/10.1109/ICSE.2019.00045>\n\
    - <span id=\"page-11-7\"></span>[39] Noor Nashid, Mifta Sintaha, and Ali Mesbah.\
    \ 2023. Retrieval-Based Prompt Selection for Code-Related Few-Shot Learning. In\
    \ ICSE.\n- <span id=\"page-11-9\"></span>[40] Nhan Nguyen and Sarah Nadi. 2022.\
    \ An Empirical Evaluation of GitHub Copilot's Code Suggestions. In 2022 IEEE/ACM\
    \ 19th International Conference on Mining Software Repositories (MSR). 1–5.<https://doi.org/10.1145/3524842.3528470>\n\
    - <span id=\"page-11-21\"></span>[41] Pengyu Nie, Rahul Banerjee, Junyi Jessy\
    \ Li, Raymond J Mooney, and Milos Gligoric. 2023. Learning Deep Semantics for\
    \ Test Completion, In ICSE. arXiv preprint arXiv:2302.10166.\n- <span id=\"page-11-12\"\
    ></span>[42] Erik Nijkamp, Hiroaki Hayashi, Caiming Xiong, Silvio Savarese, and\
    \ Yingbo Zhou. 2023. Codegen2: Lessons for training llms on programming and natural\
    \ languages. arXiv preprint arXiv:2305.02309 (2023).\n- <span id=\"page-11-10\"\
    ></span>[43] Erik Nijkamp, Bo Pang, Hiroaki Hayashi, Lifu Tu, Huan Wang, Yingbo\
    \ Zhou, Silvio Savarese, and Caiming Xiong. 2022. CodeGen: An Open Large Language\
    \ Model for Code with Multi-Turn Program Synthesis. arXiv preprint (2022).\n-\
    \ <span id=\"page-11-23\"></span>[44] Carlos Pacheco, Shuvendu K. Lahiri, Michael\
    \ D. Ernst, and Thomas Ball. 2007. Feedback-Directed Random Test Generation. In\
    \ International Conference on Software Engineering (ICSE). IEEE, 75–84.\n- <span\
    \ id=\"page-11-16\"></span>[45] Jeffrey Pennington, Richard Socher, and Christopher\
    \ Manning. 2014. GloVe: Global Vectors for Word Representation. In Proceedings\
    \ of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP).\
    \ Association for Computational Linguistics, Doha, Qatar, 1532–1543. [https://doi.org/10.3115/v1/](https://doi.org/10.3115/v1/D14-1162)\
    \ [D14-1162](https://doi.org/10.3115/v1/D14-1162)\n- <span id=\"page-11-0\"></span>[46]\
    \ Gabriel Poesia, Alex Polozov, Vu Le, Ashish Tiwari, Gustavo Soares, Christopher\
    \ Meek, and Sumit Gulwani. 2022. Synchromesh: Reliable Code Generation from Pre-trained\
    \ Language Models. In The Tenth International Conference on Learning Representations,\
    \ ICLR 2022, Virtual Event, April 25-29, 2022. OpenReview.net. <https://openreview.net/forum?id=KmtVD97J43e>\n\
    - <span id=\"page-11-28\"></span>[47] Michael Pradel and Satish Chandra. 2022.\
    \ Neural software analysis. Commun. ACM 65, 1 (2022), 86–96.<https://doi.org/10.1145/3460348>\n\
    - <span id=\"page-11-30\"></span>[48] Michael Pradel, Georgios Gousios, Jason\
    \ Liu, and Satish Chandra. 2020. Type-Writer: Neural Type Prediction with Search-based\
    \ Validation. In ESEC/FSE '20: 28th ACM Joint European Software Engineering Conference\
    \ and Symposium on the Foundations of Software Engineering, Virtual Event, USA,\
    \ November 8-13, 2020. 209–220.<https://doi.org/10.1145/3368089.3409715>\n- <span\
    \ id=\"page-11-25\"></span>[49] Kia Rahmani, Mohammad Raza, Sumit Gulwani, Vu\
    \ Le, Daniel Morris, Arjun Radhakrishna, Gustavo Soares, and Ashish Tiwari. 2021.\
    \ Multi-modal program inference: a marriage of pre-trained language models and\
    \ component-based synthesis. Proc. ACM Program. Lang. 5, OOPSLA (2021), 1–29.\
    \ [https://doi.org/](https://doi.org/10.1145/3485535) [10.1145/3485535](https://doi.org/10.1145/3485535)\n\
    - <span id=\"page-11-20\"></span>[50] Veselin Raychev, Martin T. Vechev, and Eran\
    \ Yahav. 2014. Code completion with statistical language models. In ACM SIGPLAN\
    \ Conference on Programming Language Design and Implementation, PLDI '14, Edinburgh,\
    \ United Kingdom - June 09 - 11, 2014. 44.\n- <span id=\"page-11-17\"></span>[51]\
    \ Nils Reimers and Iryna Gurevych. 2019. Sentence-BERT: Sentence Embeddings using\
    \ Siamese BERT-Networks.<https://doi.org/10.48550/ARXIV.1908.10084>\n- <span id=\"\
    page-11-11\"></span>[52] Deb Roy. 2005. Semiotic schemas: A framework for grounding\
    \ language in action and perception. Artificial Intelligence 167, 1-2 (2005),\
    \ 170–205.\n- <span id=\"page-11-32\"></span>[53] Saksham Sachdev, Hongyu Li,\
    \ Sifei Luan, Seohyun Kim, Koushik Sen, and Satish Chandra. 2018. Retrieval on\
    \ source code: a neural code search. In Proceedings of the 2nd ACM SIGPLAN International\
    \ Workshop on Machine Learning and Programming Languages. ACM, 31–41.\n- <span\
    \ id=\"page-11-1\"></span>[54] Max Schäfer, Sarah Nadi, Aryaz Eghbali, and Frank\
    \ Tip. 2024. An Empirical Evaluation of Using Large Language Models for Automated\
    \ Unit Test Generation. IEEE Transactions on Software Engineering 50, 1 (2024),\
    \ 85–105. [https://doi.org/](https://doi.org/10.1109/TSE.2023.3334955) [10.1109/TSE.2023.3334955](https://doi.org/10.1109/TSE.2023.3334955)\n\
    - <span id=\"page-11-24\"></span>[55] Marija Selakovic, Michael Pradel, Rezwana\
    \ Karim Nawrin, and Frank Tip. 2018. Test Generation for Higher-Order Functions\
    \ in Dynamic Languages. In OOPSLA.\n- <span id=\"page-11-8\"></span>[56] Disha\
    \ Shrivastava, Hugo Larochelle, and Daniel Tarlow. 2023. Repository-level prompt\
    \ generation for large language models of code. In International Conference\n\n\
    on Machine Learning. PMLR, 31693–31715.\n\n- <span id=\"page-11-13\"></span>[57]\
    \ Alexey Svyatkovskiy, Ying Zhao, Shengyu Fu, and Neel Sundaresan. 2019. Pythia:\
    \ Ai-assisted code completion system. In Proceedings of the 25th ACM SIGKDD international\
    \ conference on knowledge discovery & data mining. 2727–2735.\n- <span id=\"page-11-5\"\
    ></span>[58] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion\
    \ Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention\
    \ is All you Need. In NIPS. 6000–6010. [http://papers.nips.cc/paper/7181-attention-is](http://papers.nips.cc/paper/7181-attention-is-all-you-need)[all-you-need](http://papers.nips.cc/paper/7181-attention-is-all-you-need)\n\
    - <span id=\"page-11-15\"></span>[59] Yaza Wainakh, Moiz Rauf, and Michael Pradel.\
    \ 2021. IdBench: Evaluating Semantic Representations of Identifier Names in Source\
    \ Code. In 43rd IEEE/ACM International Conference on Software Engineering, ICSE\
    \ 2021, Madrid, Spain, 22-30 May 2021. IEEE, 562–573.<https://doi.org/10.1109/ICSE43902.2021.00059>\n\
    - <span id=\"page-11-31\"></span>[60] Jiayi Wei, Maruth Goyal, Greg Durrett, and\
    \ Isil Dillig. 2020. LambdaNet: Probabilistic Type Inference using Graph Neural\
    \ Networks. In 8th International Conference on Learning Representations, ICLR\
    \ 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net.<https://openreview.net/forum?id=Hkx6hANtwH>\n\
    - <span id=\"page-11-2\"></span>[61] Chunqiu Steven Xia and Lingming Zhang. 2022.\
    \ Less training, more repairing please: revisiting automated program repair via\
    \ zero-shot learning. In Proceedings of the 30th ACM Joint European Software Engineering\
    \ Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE\
    \ 2022, Singapore, Singapore, November 14-18, 2022, Abhik Roychoudhury, Cristian\
    \ Cadar, and Miryung Kim (Eds.). ACM, 959–971.<https://doi.org/10.1145/3540250.3549101>\n\
    - <span id=\"page-11-27\"></span>[62] Chunqiu Steven Xia and Lingming Zhang. 2023.\
    \ Conversational Automated Program Repair. CoRR abs/2301.13246 (2023). [https://doi.org/10.48550/arXiv.](https://doi.org/10.48550/arXiv.2301.13246)\
    \ [2301.13246](https://doi.org/10.48550/arXiv.2301.13246) arXiv[:2301.13246](https://arxiv.org/abs/2301.13246)\n\
    - <span id=\"page-11-3\"></span>[63] Frank F. Xu, Uri Alon, Graham Neubig, and\
    \ Vincent J. Hellendoorn. 2022. A Systematic Evaluation of Large Language Models\
    \ of Code. CoRR abs/2202.13169 (2022). arXiv[:2202.13169 https://arxiv.org/abs/2202.13169](https://arxiv.org/abs/2202.13169)\n\
    - <span id=\"page-11-22\"></span>[64] Fengji Zhang, Bei Chen, Yue Zhang, Jin Liu,\
    \ Daoguang Zan, Yi Mao, Jian-Guang Lou, and Weizhu Chen. 2023. RepoCoder: Repository-Level\
    \ Code Completion Through Iterative Retrieval and Generation. arXiv[:2303.12570](https://arxiv.org/abs/2303.12570)\
    \ [cs.CL]\n- <span id=\"page-11-14\"></span>[65] Tianyi Zhang, Tao Yu, Tatsunori\
    \ B. Hashimoto, Mike Lewis, Wen-tau Yih, Daniel Fried, and Sida I. Wang. 2023.\
    \ Coder Reviewer Reranking for Code Generation. In ICML.\n- <span id=\"page-11-4\"\
    ></span>[66] Albert Ziegler, Eirini Kalliamvakou, X. Alice Li, Andrew Rice, Devon\
    \ Rifkin, Shawn Simister, Ganesh Sittampalam, and Edward Aftandilian. 2024. Measuring\
    \ GitHub Copilot's Impact on Productivity. Commun. ACM 67, 3 (feb 2024), 54–63.\
    \ <https://doi.org/10.1145/3633453>"
- title: Profiling the carbon footprint of performance bugs
  abstract: 'Much debate nowadays is devoted to the impacts of modern information
    and

    communication technology on global carbon emissions. Green information and

    communication technology is a paradigm creating a sustainable and

    environmentally friendly computing field that tries to minimize the adverse

    effects on the environment. Green information and communication technology are

    under constant development nowadays. Thus, in this paper, we undertake the

    problem of performance bugs that, until recently, have never been studied so

    profoundly. We assume that inappropriate software implementations can have a

    crucial influence on global carbon emissions. Here, we classify those

    performance bugs and develop inappropriate implementations of four programs

    written in C++. To mitigate these simulated performance bugs, measuring

    software and hardware methods that can estimate the increased carbon footprint

    properly were proposed.'
  url: http://arxiv.org/abs/2401.01782v1
  keywords: carbon footprint, green computing, performance bugs, software engineering
  document: '# Profiling the carbon footprint of performance bugs


    1 st Iztok Fister Jr. *University of Maribor* Maribor, Slovenia iztok.fister1@um.si


    2 nd Dusan Fister ˇ *University of Maribor* Maribor, Slovenia dusan.fister@um.si


    3 th Vili Podgorelec *University of Maribor* Maribor, Slovenia vili.podgorelec@um.si


    4 th Iztok Fister *University of Maribor* Maribor, Slovenia iztok.fister@um.si


    *Abstract*—Much debate nowadays is devoted to the impacts of modern information
    and communication technology on global carbon emissions. Green information and
    communication technology is a paradigm creating a sustainable and environmentally
    friendly computing field that tries to minimize the adverse effects on the environment.
    Green information and communication technology are under constant development
    nowadays. Thus, in this paper, we undertake the problem of performance bugs that,
    until recently, have never been studied so profoundly. We assume that inappropriate
    software implementations can have a crucial influence on global carbon emissions.
    Here, we classify those performance bugs and develop inappropriate implementations
    of four programs written in C++. To mitigate these simulated performance bugs,
    measuring software and hardware methods that can estimate the increased carbon
    footprint properly were proposed.


    *Index Terms*—carbon footprint, green computing, performance bugs, software engineering


    ## I. INTRODUCTION


    We find ourselves in an era marked by turbulence, where the ominous specters of
    global warming and excessive carbon emissions loom large in our collective consciousness
    [\[8\]](#page-6-0). Many scientists have long sounded the alarm about the urgent
    need to curb these emissions to avert catastrophic consequences. However, despite
    the multitude of dire projections, political movements worldwide often fall short
    in their efforts to mitigate the impact of global warming effectively [\[9\]](#page-6-1).


    Modern humans and novel economic systems play a pivotal role in exacerbating the
    carbon footprint. On one hand, we engage in activities such as deforestation,
    construction on valuable land, the proliferation of supermarkets, while, on the
    other, in the extensive use of automobiles and airplanes [\[1\]](#page-6-2), [\[10\]](#page-6-3).
    Moreover, it has become increasingly evident that Information and Communication
    Technology (ICT), which we rely upon heavily, contributes significantly in increasing
    the carbon emissions. Considering the vast number of data centers scattered across
    the globe [\[7\]](#page-6-4), as well as the multitude of machine learning models
    running incessantly [\[5\]](#page-6-5), it becomes clear just how profound our
    environmental impact can be. In addition to all these examples, the personal computers
    are using electricity, and potentially contribute in increasing the carbon emissions
    [\[11\]](#page-6-6).


    The task of Green ICT is to mitigate the carbon emissions of ICT production, applications,
    and services [\[12\]](#page-6-7). It holds that the ICT systems nowadays produce
    even 2 % of global emissions [\[6\]](#page-6-8). The reduction of carbon emissions
    comes out either directly from the hardware, or directly and indirectly from the
    software. Indeed, the carbon emission is measured as a Carbon Footprint (CF) that
    is proportional to the amount of trees needed to absorb the emitted carbon dioxide
    in a year [\[12\]](#page-6-7).


    Several publications have tackled the challenge of enhancing the sustainability
    of ICT and its associated processes. In a paper authored by Taina [\[12\]](#page-6-7),
    a comprehensive approach was presented for analyzing the carbon footprint associated
    with software. This study examined each phase of a typical software lifecycle
    meticulously, quantifying the carbon emissions generated at each step. Additionally,
    the author shared insightful strategies aimed at minimizing this carbon footprint.
    Conversely, in paper [\[6\]](#page-6-8), the authors introduced a systematic methodology
    for quantifying the carbon footprint of a software product throughout its entire
    lifecycle. Furthermore, they proposed a method for incorporating certain facets
    of carbon footprint assessment seamlessly into the software development process.
    The paper also delves into the implications and tools associated with this innovative
    calculation approach. Thus, this work underscores the significance of energy metrics,
    and the consideration of carbon footprint implications within the realm of Green
    Software Engineering.


    Performance bugs are unnecessarily inefficient code chunks in software that can
    cause prolonged execution times and degraded resource utilization [\[3\]](#page-6-9).
    For instance, an execution time of a program calling a function each time it needs
    in place of referencing the variable storing the result of the calling function
    can increase its execution time substantially. The execution time is increased
    proportionally to the number of function calls.


    The impact of the unnecessary inefficient code chunks has rarely been taken into
    consideration, especially in the sense of Green ICT. The purpose of the study
    is to observe the well known performance bug in C++ referring to a vector class,
    and to show how its inefficient usage can increase the energy consumption (indirectly
    also carbon emission) of the corresponding algorithm. Vector in C++ reallocates
    memory when the new elements are added, and no memory is avail-


    Corresponding author: Iztok Fister Jr. (e-mail: iztok.fister1@um.si).


    able to hold them. The reallocation would cause significant performance degradation
    if this occurs too often [\[3\]](#page-6-9).


    To simulate performance bug, four different versions of an algorithm were developed
    that manipulate the big number of elements, either in the vector class or the
    double linked list. All the algorithms were executed on three different platforms
    (i.e., a laptop, a Raspberry Pi 3 microcomputer, and an iPad table computer),
    and compared with each other according to the increased energy consumption measured,
    depending on the platform either using the Linux system software tool or a power
    meter capable of measuring the energy consumption on the hardware level.


    The motivation of the study was three-fold:


    - Identifying the performance bugs in software or inappropriate implementation
    that can have a great influence toward the carbon emission.

    - Investigating the influence of the iteration performance bugs on the increased
    carbon emission by results of four simulation programs developed in C++ programming
    language.

    - Searching for methods of how to measure the influence of performance bugs.


    Although it can be found three performance bugs in the literature [\[3\]](#page-6-9)
    (i.e., iteration, enumeration, and deadlock performance bugs), here, we are focused
    on the first kind only. As a result, the main contributions of the study are as
    follows:


    - Simulating the performance bugs by four different algorithms written in C++.

    - Measuring an increasing carbon footprint caused by the simulation.

    - Showing that the proposed measuring methods can be applied to estimate the increased
    carbon footprint due to the simulated performance bugs.


    In general, the main novelty of the proposed method is to link the identification
    of performance bugs with measuring the increased carbon footprint they cause.
    Thus, the domain of software engineering is integrated with the domain of green
    computing.


    The structure of the paper is as follows: Section [II](#page-1-0) discusses potential
    ways in which to measure the carbon footprint on various digital computers. In
    Section [III,](#page-2-0) the concept of performance bugs is explained briefly.
    The performed experiments and the obtained results are the subjects of Section
    [IV.](#page-3-0) Section [V](#page-5-0) concludes the paper and outlines the plausible
    directions for the future work.


    ## <span id="page-1-0"></span>II. MEASURING THE CARBON FOOTPRINT OF COMPUTERS


    A carbon footprint is the amount of greenhouse gases (e.g., carbon dioxide and
    methane) that are generated by our actions [\[4\]](#page-6-10). The carbon footprint
    is measured in units of CO<sup>2</sup> per unit (CO2e). Actually, most things
    in the world contribute to carbon emissions, i.e., has its carbon footprint [\[2\]](#page-6-11).
    Electricity belongs today to the primary source of energy. Moreover, energy consumption
    is increasing crucially. As the production of electricity increases, the carbon
    emissions rise simultaneously. However, electricity can be produced based on different
    sources (e.g., coal, oil, gas, nuclear and renewable) that contribute a different
    level of carbon emissions. For instance, the low-carbon sources, like nuclear
    and renewable, are more environmentally friendly than the coal that belongs to
    the high-carbon sources.


    Typically, each country produces electricity from sources of different levels
    of carbon emissions. Therefore, the carbon footprint of electricity varies from
    country to country. The carbon footprint for electricity in the United States
    is estimated to be 0.65 kg CO2e.


    The energy consumption needs to be estimated in order to determine the carbon
    footprint of computers. Although the electricity is not the only source of carbon
    emissions by computers [\[2\]](#page-6-11), it is a good approximation for calculation
    of the carbon footprint. Indeed, there are two ways to determine the energy consumption
    of computers, i.e., software and hardware tools. However, the known software tools
    only measure power consumption on laptops when running on a battery. On the other
    hand, for desktop or server machines the only current solution is an electronic
    power-meter that plugs into the mains socket. In our study, the *powertop* utility
    was examined among the software tools, and the AVHzY ct-3 power-meter among the
    hardware tools. The characteristics of both tools are discussed in the remainder
    of the paper.


    ## *A. Powertop utility on Linux*


    The purpose of the *powertop* utility is to analyze and manage power consumption
    on laptops using battery power. The tool is able to display and export reports
    about the estimated discharge rate, and statics about processors, devices, kernel,
    timer, and interrupt handler behavior. It also lets us tune some kernel parameters
    easily on the fly, in order to maximize the battery life.


    Before operating the tools needs to be calibrated, where, during the process,
    the power engine adjusts to the specific computer environment in order to take
    the accurate power measures. In operation mode, the laptop must be on battery
    power only. The *powertop* takes measurements at 20 seconds intervals by default.
    Obviously, the interval can be set arbitrarily by the user.


    Indeed, the process of discharging the battery is strongly non-linear. Consequently,
    measurements taken at full battery capacity under a similar strain can differ
    from those taken when the capacity of the battery is not full. As a result, we
    need to ensure that the battery is at full capacity at the beginning of each experiment.


    ## *B. Power meter AVHzY CT-3*


    A power-meter measures electrical power in Watts. For measuring computer power,
    electronic Watt-meters are used that are capable of small power measurements,
    or of power measurements at frequencies beyond the range of dynamometertype instruments.


    The AVHzY CT-3 power-meter (Fig. [1\)](#page-2-1) measures active electrical power
    while connected directly to the electricity network, and works in 0 − 26 V of
    voltage and 0 − 6 A of current ranges. The device is connected to the electricity


    ![](_page_2_Picture_1.jpeg)


    Fig. 1. Power meter AVHzY ct-3.


    <span id="page-2-1"></span>network via a 230 V plug adapter with a USB port. It
    measures the consumer that is connected to it via an output USB port. Furthermore,
    the power-meter also enables connecting the external power via a USB-C input port.


    The main advantage of the power-meter is represented by the USB-C output port,
    to which the personal computer can be connected, on which the powerful PC software
    can be installed for monitoring power consumption simultaneously. The software
    is dedicated for data logging up to 1000sps, viewing the VBUS ripple, and diagnosing
    the devices. Using this PC software, the power consumption can be monitored online
    at a high level of accuracy.


    ## III. PERFORMANCE BUGS


    <span id="page-2-0"></span>Performance bugs typically increase the time complexity
    of the algorithm due to coding the inefficient code chunks. Obviously, this inefficient
    coding is programmed by the programmer unintentionally, but has a crucial impact
    on the performance behavior of the algorithm. For instance, allocations of heap
    memory are performed with a *malloc* function in standard C and with *new* function
    in C++. If low-level system allocations are needed, the custom allocators, e.g.,
    kalloc in Linux kernel, or ALLOC and xmalloc in gnulib, are available for vector
    reallocation. Consequently, performance improvements are clearly observable by
    calling the low-level allocation function.


    In order to show, how the performance bugs affect the performance of the algorithm,
    different applications of the vector class in C++ were taken into consideration.
    Indeed, the memory is allocated on demand by the class, and is deallocated at
    the very least when the vector''s destructor is called. When no memory is available
    to hold the new allocated elements in a heap, the vector in C++ needs to reallocate
    memory. These reallocations can be simulated as a performance bug by mass insertion
    of the new head vector''s elements by its member function *push back*, and mass
    deletion of the last vector''s element by the member function *pop back*.


    In line with this, the following four different algorithms were developed:


    • Vector (i.e., the simulation of the performance bug),


    - Raw (i.e., avoiding the performance bug version I),

    - Array (i.e., avoiding the performance bug version II),

    - double linked List (i.e., avoiding the performance bug version III).


    obtaining the same results in different ways, of course. The task of each algorithm
    is simply to initialize the array of long integer elements with their sequence
    numbers in the interval [0, 99], and, then, iterate deleting the last element
    of the array and adding the next element in the sequence of numbers to the head
    of the array. Finally, the elements of the array are ordered in descend order
    starting with the the first number that is equal to the maximum number of iterations,
    until the number that is for 100 elements lower than the maximum. Thus, two representations
    of the array are applied, i.e., vector class and array data structure in C++.
    Thus, it is expected that algorithms using the elementary data structures (e.g.,
    Array and Link) would be more efficient than those using the more abstract Vector
    class (e.g., Vector and Raw).


    The pseudo-code of the algorithm Vector is illustrated in Algorithm [1,](#page-2-2)
    from which it can be seen that this uses the vector


    <span id="page-2-2"></span>


    | Algorithm 1 Algorithm Vector              |

    |-------------------------------------------|

    | ▷ vector class C++                        |

    |                                           |

    | ▷ Initialization of vector                |

    |                                           |

    | ▷ Program loop<br>for i=0L to MAX ITER do |

    | ▷ Delete the last element                 |

    | ▷ Insert new as the first element         |

    |                                           |

    |                                           |


    class functions *push back*, *pop back*, and *insert* for adding the last, removing
    the last and inserting the first element into/from the vector variable *vec*.


    Algorithm Raw is implemented according to the pseudocode depicted in Algorithm
    [2.](#page-2-3) As evident from the pseudo-


    <span id="page-2-3"></span>


    | Algorithm 2 Algorithm Raw |                            |

    |---------------------------|----------------------------|

    | vector < long int > vec   | ▷ vector class C++         |

    | for i=0L to 100L do       |                            |

    | vec.push back(i)          | ▷ Initialization of vector |

    | end for                   |                            |

    | for i=0L to MAX ITER do   | ▷ Program loop             |

    | for j=99 to 1 step -1 do  | ▷ Exchange elements        |

    | vec[j] = vec[j-1]         |                            |

    | end for                   |                            |

    | vec[0] = i+100L           |                            |

    | end for                   |                            |


    code, the array of integer elements is defined as a class of long integer, where
    the initialization is performed in the same way as by the algorithm Vector (i.e.,
    using the *push back* function call). However, manipulation of the vector elements
    is developed in a more elementary way: At first, the whole array are reassigned
    sequentially element by element backward, while the first element is adopted with
    the number proportional to the current iteration (i.e., variable i).


    Algorithm Array, presented in pseudo-code Algorithm [3,](#page-3-1) applies the
    array C++ data structure for representation of elements of type long integer.
    As is evident from the pseudo-code,


    <span id="page-3-1"></span>


    | Algorithm 3 Algorithm Array |                            |

    |-----------------------------|----------------------------|

    | long int vec[100]           | ▷ array C++ data structure |

    | for i=0L to 100L do         |                            |

    | vec[i] = i                  | ▷ Initialization of vector |

    | end for                     |                            |

    | for i=0L to MAX ITER do     | ▷ Program loop             |

    | for j=99 to 1 step -1 do    |                            |

    | vec[j] = vec[j-1]           |                            |

    | end for                     |                            |

    | vec[0] = i+100L             |                            |

    | end for                     |                            |


    the implementation is similar to the implementation of the Raw algorithm, except
    in the declaration of the array variable vec. Here, the array data structure in
    C++ is employed in place of using vector class. The motivation behind implementing
    the algorithm is to show, which potential overhead brings the introduction of
    the more abstract class vector over the more elementary data structure array in
    C++.


    Finally, the algorithm List implements the double linked list data structure in
    C++. The advantage of this algorithm is that the functions of the high-level vector
    class are replaced with the low-level functions implemented by its own, which
    are able to optimize the algorithm''s behavior in the sense of speed and space.
    The double linked list uses the data structure as illustrated in Algorithm [4,](#page-3-2)
    from which it can be seen that this


    <span id="page-3-2"></span>


    | Algorithm 4 Double linked List data structure |                      |  |

    |-----------------------------------------------|----------------------|--|

    | struct str list {                             |                      |  |

    | long int num;                                 |                      |  |

    | str list* prev;                               |                      |  |

    | str list* next;                               |                      |  |

    | } *list;                                      | ▷ double linked list |  |


    consists of two pointers prev and next, and the long integer variable num.


    The pseudo-code of the algorithm List is presented in Algorithm [5,](#page-3-3)
    from which it can be considered that the elements are entered into the double
    linked list by calling the function *add new*. The implementation of the function
    is straightforward, and demands only to allocate the new item in the heap, initialize
    it, and ensure the proper forward and backward linking. Therefore, the pseudo-code
    of the function is not presented in the paper. Interestingly, the effect of element
    temptation is achieved by putting the current iteration number into the first
    element and tying the other 99 elements for one. This whole task can be performed
    simply by modifying the value of the pointers first and last (i.e., no reallocation
    is needed).


    <span id="page-3-3"></span>


    | Algorithm 5 Algorithm double linked List |                            |

    |------------------------------------------|----------------------------|

    | struct str list* first = NULL            |                            |

    | struct str list* last = NULL             |                            |

    | for i=99L to 1L step -1L do              |                            |

    | first = add new(first, last, i)          | ▷ Initialization of vector |

    | if i == 99 then                          |                            |

    | last = first                             |                            |

    | end if                                   |                            |

    | end for                                  |                            |

    | for i=0L to MAX ITER do                  | ▷ Program loop             |

    | last− >num = i + 100L                    |                            |

    | first = last                             |                            |

    | last = last− >prev                       |                            |

    | end for                                  |                            |


    ## IV. EXPERIMENTS AND RESULTS


    <span id="page-3-0"></span>The purpose of our experimental work was to show what
    amount of carbon footprint can be expected due to performance bugs. In line with
    this, the four implemented algorithms (i.e., Vector, Raw, Array and List) [1](#page-3-4)
    were compared according to their carbon footprint, measured on three different
    computer platforms, i.e.,:


    - with software tools on a laptop,

    - with a power-meter on a Raspberry Pi 3,

    - with a power-meter on an Apple iPad.


    In the remainder of the paper, the results of all three measurements are discussed
    in detail.


    ## *A. Measuring the carbon footprint on a laptop*


    The effective electrical energy consumption was measured on a laptop using battery
    power with *powertop* software utility under the Linux operating system. The four
    implemented test algorithms were running on the mentioned computer platforms with
    the maximum number of iterations set to MAX ITER = 10<sup>10</sup>. All the programs
    were performed independently over 10 runs and the average measures were taken
    into consideration.


    <span id="page-3-5"></span>The characteristics of the laptop battery are illustrated
    in Table [I.](#page-3-5) Let us mention that the laptop battery was at full


    TABLE I LAPTOP BATTERY CHARACTERISTICS.


    | Specification      | Description        |

    |--------------------|--------------------|

    | Type               | HP ProBook 470 G3  |

    | Amp-hour capacity  | 3 Ah               |

    | Watt-hour capacity | 44 Wh              |

    | Voltage            | 14.8 V             |

    | Cell type          | 4 cell Lithium-Ion |


    capacity before each start of the particular experiment.


    The results of the experiments are depicted in Table [II](#page-5-1) that is divided
    into the following columns: the "Init DR" represents the average initial Discharging
    Rate (DR) before and after running the algorithm, the "Running DR" is the DR under
    the strain, the "Alg. DR" refers to the DR caused


    <span id="page-3-4"></span><sup>1</sup><https://codeberg.org/firefly-cpp/green-ict-benchmarks>


    by the running algorithm, the "Time" measures the average execution time of the
    algorithm, the "Energy" denotes the energy used as a product of algorithm DR by
    the time, and the "Carbon footprint" estimates the carbon footprint as a product
    of CO<sup>2</sup> per unit emitted by one kWh (i.e., 0.65 CO2e/kWh). As indicated
    from the table, the Raw algorithm produced the higher carbon footprint among the
    four algorithms. As expected, the List algorithm was the most green in the sense
    of Green ITC.


    # *B. Measuring the carbon footprint with a power-meter on a Raspberry Pi 3*


    Raspberry Pi is a series of small single-board computers (SBCs) based on an ARM
    processor that represents an all in one computer. Due to its affordability, it
    is suitable for using in teaching basic computer science in schools. In our study,
    the Raspberry Pi was used that was equipped with a 32-bit ARM processor, 1 GB
    memory, 256 GB SSD, DVI video port, Ethernet and Wireless LAN. The Raspbian OS
    was installed on the device. The main advantage of this all in one computer represents
    its power supply over a USB-C port. This means that it is able to be monitored
    using the already mentioned AVHzY CT-3 power-meter. Let us mention that the maximum
    number of iterations was set to MAX ITER = 10<sup>8</sup> .


    An example of the measuring protocol obtained by measuring the power consumption
    by executing the Array algorithm by the PC is illustrated in Fig. [2.](#page-5-2)
    The curve in the figure illustrates the VBUS ripple that reflects a reaction of
    the Raspberry Pi in the strain caused by executing the Array algorithm. As can
    be observed, the strain is demonstrated as a step function denoting the increasing
    of the voltage. Interestingly, the sudden withdrawal of voltage is a typical consequence
    of some interrupts caused by the algorithm itself (e.g., by the output of control
    messages), different I/O actions (e.g., moving the mouse) or system actions. Let
    us mention that no other programs were active during the experimental work.


    The results of measuring the carbon footprint are depicted in Table [III.](#page-5-3)
    Actually, all the experiments consisted of three phases: (1) measuring the inactivity
    before the strain, (2) measuring the strain activity, and (3) measuring the inactivity
    after the strain. Typically, the duration of both inactivity phases was approximately
    one minute, while the strain activity phase denotes the effective power obtained
    during executing the particular algorithm. In the table, the row "Average inactivity"
    denotes the average carbon footprint in CO2/Wh measured during both inactivity
    phases, the row "Total strain" is the total carbon footprint measured during the
    strain phase, while the row "Algorithm strain" refers to the foot print caused
    by executing the algorithm (i.e., simply the difference between the total and
    the average strain). As evident from the table, the double linked list implementation
    is the most environmentally sustainable in the sense of emitting the lowest carbon
    footprint. The Vector implementation of the algorithm was better than the rest
    of the algorithms in the tests.


    # *C. Measuring the carbon footprint with a power meter on an Apple iPad*


    The Apple iPad prefers the foreground applications in order to ensure users the
    online response. Therefore, terminations are part of the application life-cycle,
    when the system terminates the long-term running process. In the case of running
    the C++ application, this termination is followed with issuing the message "Too
    much resources..." by the iOS after approximately 20 sec. Although the iPad allows
    running a long-term application in the background asynchronously, our goal was
    to indicate the carbon footprint of the foreground processes running on the iPad.
    In line with this, the maximum number of iterations need to be reduced significantly
    to MAX ITER = 10<sup>7</sup> . The specifications of the iPad were as follow:
    model number MYLA2HC/A, iPad OS version 16.7, processor 2 × Vortex, 3 GB operating
    memory, and 32 GB built-in memory.


    The measuring protocol obtained by the Array algorithm strain on the iPad using
    the power-meter AVHzY CT-3 was presented in Fig. [3,](#page-6-12) from which it
    can be concluded that the supplement of the Array algorithm to the total power
    consumption (i.e., the VBUS ripple) was not easy to observe. Therefore, this supplement
    of 6.135 seconds is denoted in the figure by arrows. When one compares the curve
    with those presented in Fig. [2](#page-5-2) obtained on the Raspberry Pi, he/she
    can conclude that the iPad system is very agile when handling a lot of active
    processes simultaneously. Although frequent withdrawal of voltage can be indicated
    in the figure, the running application left its carbon footprint clearly.


    The measured carbon footprint is depicted in Table [IV,](#page-5-4) from which
    it is evident that the carbon footprint by the algorithms in test was lower due
    to the lower execution time, but the relations between the algorithms remained
    the same as in the last experiment, i.e., the double linked list left the lesser
    carbon footprint, while the Raw algorithm was distinguished as the worst environment
    pollutant.


    ## *D. Discussion*


    As evident from the performed experimental work, measuring the power consumption
    is more accurate using the hardware device (i.e., the power-meter) than with software
    tools (i.e., the *powertop*). Although the measurements using *powertop* were
    taken at 1 second intervals, less than one-third could be captured in one minute
    (i.e., 16/60). The reason behind the behavior needs to be searched for in the
    slow communication of the tool with the power engine. On the other hand, the communication
    of the control PC with the power-meter was very fast and accurate. The hardware
    device is able to transmit up to 100 measurements in one second. This means that
    even small changes of power consumption can be sensed by the power-meter. However,
    the basic problem which arose by using the AVHzY CT-3 device with the laptop was
    that the power-meter device was able to support only devices connected to the
    power source with the USB port. This means that for measuring power consumption
    on laptops the more professional equipment is necessary.


    TABLE II CARBON FOOTPRINT OBTAINED ON THE LAPTOP BY DIFFERENT C++ ALGORITHMS.


    | Algorithm | Init DR<br>[W] | Running DR<br>[W] | Alg. DR<br>[W] | Time<br>[sec]
    | Energy<br>[Wh] | Carbon footprint<br>[CO2e/Wh] |

    |-----------|----------------|-------------------|----------------|---------------|----------------|-------------------------------|

    | Vector    | 9.288          | 15.953            | 6.665          | 198.496       |
    22.051         | 14.333                        |

    | Raw       | 9.010          | 16.142            | 7.132          | 195.606       |
    23.250         | 15.113                        |

    | Array     | 9.532          | 16.221            | 6.689          | 177.381       |
    19.776         | 12.854                        |

    | List      | 7.850          | 15.138            | 7.288          | 16.081        |
    1.953          | 1.270                         |


    <span id="page-5-1"></span>![](_page_5_Figure_2.jpeg)


    <span id="page-5-2"></span>Fig. 2. Measuring protocol on AVHzY CT-3 by Array algorithm
    strain.


    TABLE III RESULTS OF MEASURING THE CARBON FOOTPRINT.


    <span id="page-5-3"></span>


    | Carbon footprint   | Vector | Raw    | Array  | List  |  |  |  |  |  |

    |--------------------|--------|--------|--------|-------|--|--|--|--|--|

    | Average inactivity | 3.299  | 3.242  | 3.273  | 3.637 |  |  |  |  |  |

    | Total strain       | 12.860 | 63.659 | 27.496 | 8.211 |  |  |  |  |  |

    | Algorithm strain   | 9.561  | 60.417 | 24.223 | 4.574 |  |  |  |  |  |

    |                    |        |        |        |       |  |  |  |  |  |

    |                    |        |        |        |       |  |  |  |  |  |

    | TABLE IV           |        |        |        |       |  |  |  |  |  |


    APPLE IPAD


    <span id="page-5-4"></span>


    | Carbon footprint   | Vector | Raw   | Array | List  |

    |--------------------|--------|-------|-------|-------|

    | Average inactivity | 6.087  | 6.121 | 5.808 | 5.975 |

    | Total strain       | 0.855  | 1.289 | 0.637 | 0.824 |

    | Algorithm strain   | 0.123  | 0.516 | 0.317 | 0.075 |


    In first sight, it seems that measuring the carbon footprint was measured incorrectly,
    because the measured algorithm was executed on an operating system that handles
    a lot of the other programs simultaneously and also affected the increased power
    consumption. However, the number of these processes (e.g., internet explorer,
    e-mail client, etc.) was minimized during the measuring, while the average of
    both the so-called inactivity phases (i.e., before and after executing the algorithm)
    were measured explicitly. Obviously, the best solution is to put the computer
    in single-user mode, but this option is unfortunately not available to all computers
    (e.g., an iPad).


    It turns out, that the vector in C++ is sensitive on performance problem only,
    when the data class is used a lot of the time. Interestingly, sequential usage
    of the array data structure by the algorithm Array was even more efficient than
    using the built-in functions by the algorithm Vector, when the enormous actions
    were applied on the class. As expected, the algorithm List, using the classical
    implementation of double linked list, outperformed all the other algorithms.


    ## V. CONCLUSION


    <span id="page-5-0"></span>The paper tries to achieve three goals: (1) to estimate
    how the performance bugs in software influence increasing the carbon footprint,
    (2) to focus primarily on the iteration performance bugs, and (3) to find methods
    for measuring the carbon footprint caused by the performance bugs properly. In
    line with this, four algorithms simulating the iterative performance bugs were
    considered and run on three platforms (i.e., a laptop, a micro-computer Raspberry
    Pi, and an Apple iPad). Two methods for measuring the carbon footprint were


    ![](_page_6_Figure_0.jpeg)


    <span id="page-6-12"></span>Fig. 3. Measuring protocol on AVHzY CT-3 by Array
    algorithm strain on iPad.


    examined, i.e., using the software tool *powertop* on Linux and the power meter
    AVHzY CT-3. The experiments revealed that the hardware measurement using the power
    meter was more accurate than those using the software tools. However, both can
    adequately identify the increased carbon footprint caused by the simulation.


    In summary, the study integrates two domains, i.e., software engineering and green
    computing. The former can identify the software bugs, while the latter deals with
    the effects of computing on global warming. In line with this, this study warns
    of harmful effects caused by performance bugs in the sense of the increased carbon
    footprint.


    As potential directions for the future, searching for cheaper and more accurate
    solutions should be made for measuring power consumption on computers connected
    to the 230 V electricity network(e.g., AVHzY AC WiFi Watt Meter). Also, widening
    the study to include all performance bugs would be welcome.


    ## REFERENCES


    - <span id="page-6-2"></span>[1] Clare Balboni, Aaron Berman, Robin Burgess, and
    Benjamin A Olken. The economics of tropical deforestation. *Annual Review of Economics*,
    15:723–754, 2023.

    - <span id="page-6-11"></span>[2] M. Berners-Lee. *The Carbon Footprint of Everything*.
    Greystone Books, 2022.

    - <span id="page-6-9"></span>[3] Yiqun Chen, Oliver Schwahn, Roberto Natella,
    Matthew Bradbury, and Neeraj Suri. Slowcoach: Mutating code to simulate performance
    bugs. In *2022 IEEE 33rd International Symposium on Software Reliability Engineering
    (ISSRE)*, pages 274–285, 2022.

    - <span id="page-6-10"></span>[4] The Nature Conservancy. Calculate your carbon
    footprint, 2023. Last accessed 25 Octobre 2023.

    - <span id="page-6-5"></span>[5] Payal Dhar. The carbon impact of artificial intelligence.
    *Nat. Mach. Intell.*, 2(8):423–425, 2020.

    - <span id="page-6-8"></span>[6] Eva Kern, Markus Dick, Stefan Naumann, and Tim
    Hiller. Impacts of software and its engineering on the carbon footprint of ict.
    *Environmental Impact Assessment Review*, 52:53–61, 2015.

    - <span id="page-6-4"></span>[7] Jonathan Koomey et al. Growth in data center
    electricity use 2005 to 2010. *A report by Analytical Press, completed at the
    request of The New York Times*, 9(2011):161, 2011.

    - <span id="page-6-0"></span>[8] Zhu Liu, Zhu Deng, Steven J Davis, Clement Giron,
    and Philippe Ciais. Monitoring global carbon emissions in 2021. *Nature Reviews
    Earth & Environment*, 3(4):217–219, 2022.

    - <span id="page-6-1"></span>[9] Leonardo Nascimento and Niklas Hohne. Expanding
    climate policy ¨ adoption improves national mitigation efforts. *npj Climate Action*,
    2(1):12, 2023.

    - <span id="page-6-3"></span>[10] Ambuj D Sagar. Automobiles and global warming:
    Alternative fuels and other options for carbon dioxide emissions reduction. *Environmental
    Impact Assessment Review*, 15(3):241–274, 1995.

    - <span id="page-6-6"></span>[11] Pavel Somavat, Vinod Namboodiri, et al. Energy
    consumption of personal computing including portable communication devices. *Journal
    of Green Engineering*, 1(4):447–475, 2011.

    - <span id="page-6-7"></span>[12] Juha Taina. How green is your software? In *International
    Conference of Software Business*, pages 151–162. Springer, 2010.'
- title: Automated Test Production -- Systematic Literature Review
  abstract: 'Identifying the main contributions related to the Automated Test Production

    (ATP) of Computer Programs and providing an overview about models,

    methodologies and tools used for this purpose is the aim of this Systematic

    Literature Review (SLR). The results will enable a comprehensive analysis and

    insight to evaluate their applicability. A previously produced Systematic

    Literature Mapping (SLM) contributed to the formulation of the ``Research

    Questions'''' and parameters for the definition of the qualitative analysis

    protocol of this review.'
  url: http://arxiv.org/abs/2401.02033v1
  keywords: ''
  document: "## Automated Test Production Systematic Literature Review\n\nGomes, J.M.\
    \ <sup>1</sup> and Dias, L.A.V. 1\n\n1 Instituto Tecnol´ogico de Aeron´autica\
    \ - ITA\n\nJanuary 5, 2024\n\n#### Abstract\n\nIdentifying the main contributions\
    \ related to the Automated Test Production of Computer Programs and providing\
    \ an overview about models, methodologies and tools used for this purpose is the\
    \ aim of this Systematic Literature Review. The results will enable a comprehensive\
    \ analysis and insight to evaluate their applicability. A previously produced\
    \ SLM (Systematic Literature Mapping) contributed to the formulation of the \"\
    Research Questions\" and parameters for the definition of the qualitative analysis\
    \ protocol of this review.\n\n## 1 Objectives\n\nThe broader goal of this research,\
    \ while on the one hand is to obtain the State of the Art in ATP (Automated Test\
    \ Production), find the problems faced and track the progress of researchers in\
    \ the field, on the other hand we also intend to list and categorize the ATP methods,\
    \ techniques and tools that meet the needs of professionals producing specialized\
    \ business applications for internal use within their corporations - eventually\
    \ extending to the needs of professionals in companies specializing in the production\
    \ of generic or even academic computer applications.\n\nProviding the scientific\
    \ and technological community with an overview of models, methodologies and tools\
    \ used for this purpose is the goal of this SLR (Systematic Literature Review).\
    \ The results will allow a comprehensive analysis and insight to evaluate their\
    \ applicability.\n\n## <span id=\"page-0-0\"></span>2 Systematic Literature Review\n\
    \n### 2.1 Planning\n\nIn order to analyze, evaluate and interpret the available\
    \ research for the matter of ATP of Computer Programs, we applied the method proposed\
    \ by Brereton et\n\n![](_page_1_Figure_0.jpeg)\n\n<span id=\"page-1-0\"></span>Figure\
    \ 1: Steps to perform an SLR (adaptedo from [\\[1\\]](#page-13-0))\n\nal. and\
    \ presented in the Figure [1.](#page-1-0) Whereas the Systematic Literature Mapping[\\\
    [2\\]](#page-13-1) survey gave us an overview and insight into what represents\
    \ current research in ATP, with the present SLR we aim to identify the effort\
    \ needed to answer our research questions[\\[1\\]](#page-13-0).\n\nSeveral adjustments\
    \ suggested by Kitchenham et al. led us to consider the methodologies of Basili\
    \ and Weiss for formulating the research questions, of Chen and Babar for classifying\
    \ the type of study, of Keele et al. for conducting a quality assessment of each\
    \ proposal, and of Kitchenham et al., Dyba et al. for gauging the scientific rigor\
    \ of the studies obtained and in accordance with criteria of interest to our research\
    \ [\\[3,](#page-13-2) [4,](#page-13-3) [5,](#page-13-4) [6,](#page-14-0) [7,](#page-14-1)\
    \ [8\\]](#page-14-2).\n\nWe defined the questions that this research intends to\
    \ answer by following the Basili and Weiss Basili and Weiss - a systematic method\
    \ for organizing measurements. The method begins by specifying an objective (purpose,\
    \ object, problem, point of view). The goal is refined into several questions,\
    \ each of which in turn is refined into Basili and Weiss metrics. Providing the\
    \ answers to the questions, the data can be analyzed to identify whether or not\
    \ the objectives were met [\\[4\\]](#page-13-3).\n\nThus, the goal of this SLR\
    \ is:\n\n- Purpose Understand and characterize ...\n\t- Problem ... the solutions\
    \ in ATP ...\n\t\t- ∗ Object ... of Computer Program Testing ...\n\t\t\t- · Point\
    \ of view ... used by researchers and informatics professionals.\n\nBased on the\
    \ above stated goal, we derive the questions to be answered (see Table [1\\)](#page-2-0).\n\
    \n| #     | Question                                           |  |\n|-------|----------------------------------------------------|--|\n\
    | QP1   | What is the model, process, framework or tool      |  |\n|       | used\
    \ for test production?                          |  |\n| QP1.1 | What type of test\
    \ is generated?                    |  |\n| QP1.2 | What test production techniques\
    \ were applied?      |  |\n| QP1.3 | What tools does the study employ?       \
    \           |  |\n| QP1.4 | What are the prerequisites for its application?  \
    \  |  |\n| QP1.5 | What types of studies or evaluations have been con |  |\n|\
    \       | ducted?                                            |  |\n\n<span id=\"\
    page-2-0\"></span>Table 1: Research questions from SLR\n\nThe question QP1 allows\
    \ us to categorize the approaches and learn about the applicability of the study\
    \ proposal and meets the requirement of identifying solutions to the problem.\n\
    \n| Name                                                                     \
    \                                    |  |  |  |\n|--------------------------------------------------------------------------------------------------------------|--|--|--|\n\
    | IEEE Xplore<br>ACM Digital Library<br>Google Scholar<br>CiteSeerX<br>Inspec<br>ScienceDirect<br>EI\
    \ Compendex |  |  |  |\n| Springer Link                                      \
    \                                                          |  |  |  |\n\n<span\
    \ id=\"page-2-1\"></span>Table 2: Scientific publication bases\n\n### 2.2 Conduction\n\
    \nThe studies obtained for conducting this SLR were obtained from the scientific\
    \ publication sources listed in the Table [2](#page-2-1) and selected in our SLM[\\\
    [2\\]](#page-13-1).\n\nThe selection of documents was based on Inclusion and Exclusion\
    \ Criteria defined iteratively during the reading of the documents found and provided\
    \ to determine the suitability of each to the objectives of this work. The Inclusion\
    \ Criteria are those presented in the Table [3,](#page-2-2) and in the Table [4](#page-3-0)\
    \ we have the Exclusion Criteria.\n\n| #   | Descri¸c˜ao                     \
    \                                                      |\n|-----|---------------------------------------------------------------------------------------|\n\
    | CI1 | The Study is a review of current<br>models/processes/frameworks      \
    \                 |\n| CI2 | The study is useful for a better understanding of\
    \ the<br>problem                      |\n| CI3 | The study discusses one or more\
    \ tools within a process<br>applicable to this research |\n| CI4 | The study proposes\
    \ a<br>model/process/framework/methodology                           |\n\n<span\
    \ id=\"page-2-2\"></span>Table 3: Inclusion criteria for the SLR\n\n| CE1<br>The\
    \ study presents some<br>model/process/framework/methodology but does not<br>provide\
    \ enough information about its use<br>CE2<br>The study does not contain any kind\
    \ of evaluation for<br>the demonstration of results, such as case studies,<br>experiments,\
    \ or examples of use<br>CE3<br>The study is not directly related to this research\
    \ | # | Descri¸c˜ao |\n|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---|-------------|\n\
    |                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                       |   |             |\n|               \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                        |   |             |\n|                              \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \         |   |             |\n|                                             \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                      |   | \
    \            |\n|                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                       |   |             |\n\
    |                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                       |   |             |\n|               \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                        |   |             |\n\n<span id=\"page-3-0\"></span>Table\
    \ 4: Exclusion criteria from SLR\n\nGiven the large number of studies[\\[2\\]](#page-13-1)\
    \ found we organized our work into iterative steps:\n\n- 1. Reading the summary\
    \ and conclusion; and\n- 2. Selection by reading the entire document.\n\n| Name\
    \                 | Qty. | %     |\n|----------------------|------|-------|\n\
    | IEEE Xplore          | 33   | 14.73 |\n| ACM Digital Library  | 66   | 29.46\
    \ |\n| Springer Link        | 11   | 4.91  |\n| Peri´odicos da CAPES | 114  |\
    \ 50.89 |\n| Sub-total            | 224  |       |\n| Duplicate studies    | 7\
    \    | 4.24  |\n| Rejected studies     | 52   | 31.52 |\n| TOTAL             \
    \   | 165  |       |\n\n<span id=\"page-3-1\"></span>Table 5: Result of the selection\
    \ of primary studies for the SLR\n\nAfter reading the abstract of the pre-selected\
    \ publications, if they are interesting, we also read the conclusion, and if the\
    \ paper remains promising to our expectation it is then selected (see Figure [1](#page-1-0)\
    \ and Table [5\\[](#page-3-1)[2\\]](#page-13-1)). The selection criteria at this\
    \ stage become slightly stricter and we are now looking for model-oriented papers,\
    \ methods, techniques and tools that generate tests for general-purpose computer\
    \ applications and we avoid for example:\n\n- Texts that deal with test generation\
    \ but never in an automated or semiautomated way;\n- Tests applied to computing\
    \ devices or equipment of specific use such as those of industrial, embedded and\
    \ specialized use such as automotive and so on;\n- Tests related to a specific\
    \ or particular application such as a database manager or a commercial application,\
    \ etc;\n- Tests aimed at a specific use of a technology or facility, such as geo-location\
    \ or the use of gestures on touch screens, etc;\n- Testing targeted at a particular\
    \ industry or segment of the economy or society, such as healthcare, banking and\
    \ finance, trade, etc.; and\n\n• Tests oriented to the detection of non-functional\
    \ flaws, such as security, performance, etc.\n\nOf course, despite the rigor we\
    \ seek to conduct this research, exceptions will be made for the sake of completeness\
    \ and common sense, and we may include studies, which applied to the technologies\
    \ or segments listed above, are part of a case study within a larger context.\n\
    \nA difficult decision to make at this point is whether or not to discriminate\
    \ the application of tests on a given platform. Nowadays we see the proliferation\
    \ of the use of computing resources in a pervasive way, and we have computing\
    \ devices on our desks, in our pockets, like jewelry on our wrists, and even in\
    \ our home appliances [\\[9\\]](#page-14-3). And this is just one of the aspects\
    \ we observe directly, since the computing itself can take place inside the device\
    \ locally, or remotely on servers connected to the Internet, or even in hybrid\
    \ mode. Following the criteria listed above, we will discriminate particular or\
    \ niche or proprietary uses of certain manufacturers and not consider them, but\
    \ we must include the cases where these platforms are extremely widespread and\
    \ have a wide range of applications developed on them, such as those used in cell\
    \ phone handsets for example.\n\nAfter this preliminary selection we will proceed\
    \ with a more careful reading of the complete document that will generate notes\
    \ that will be useful in this work.\n\nIn the full reading of the documents obtained\
    \ after the first and second search criteria, the selection becomes a qualitative\
    \ analysis where each document is evaluated according to quality criteria and\
    \ scored, a method proposed by Keele et al. and which we used to evaluate quality\
    \ of studies for this review [\\[6\\]](#page-14-0). These new criteria, which\
    \ we call Quality Criteria, are based on the research questions listed in the\
    \ Table [1](#page-2-0) and whose answers will be mapped into points. The sum of\
    \ the points obtained by each document will give us a score, within which we define\
    \ a cut-off value that will select or eliminate the document.\n\nThe questions\
    \ defined for this selection phase are those listed in the Table [6.](#page-4-0)\n\
    \n| #     | Description                  | Questions    |\n|-------|------------------------------|--------------|\n\
    | CQ1   | Describe the model, process, |              |\n|       | framework or\
    \ tool used or    |              |\n|       | created?                     | \
    \             |\n| CQ1.1 | Does it show the types       | QP1.1        |\n|  \
    \     | of tests generated?          |              |\n| CQ1.2 | Does it present\
    \ the test     | QP1.2        |\n|       | generation techniques used?  |    \
    \          |\n| CQ2   | List the prerequisites?      | QP1.3, QP1.4 |\n| CQ2.1\
    \ | Does it list technologies    |              |\n|       | and knowledge required\
    \ for   |              |\n|       | proper use?                  |           \
    \   |\n| CQ2.2 | List situations for which    |              |\n|       | its\
    \ use is recommended?      |              |\n| CQ2.3 | List situations for which\
    \    |              |\n|       | the use is not recommended?  |              |\n\
    \n<span id=\"page-4-0\"></span>Table 6: Quality criteria of the SLR\n\nThe possible\
    \ answers to the questions presented in the Table [6](#page-4-0) are listed in\
    \ the Table [7.](#page-5-0) With the quality assessment we answered most of the\
    \ research questions proposed in the Table [1](#page-2-0) with the exception of\
    \ the question \"QP1.4 - What types of studies or evaluations have been conducted\"\
    , for which we adopted the classification into six categories proposed by Chen\
    \ and Babar and listed in the Table [9](#page-6-0) [\\[5\\]](#page-13-4).\n\n\
    | Answer    | Value |\n|-----------|-------|\n| Yes       | 1.0   |\n| Partially\
    \ | 0.5   |\n| No        | 0.0   |\n\n<span id=\"page-5-0\"></span>Table 7: Quality\
    \ criteria values\n\nBased on the questions in the Table [6](#page-4-0) and the\
    \ answer values listed in the Table [7](#page-5-0) we have a Max Score of 10 points\
    \ (only elementary questions count towards the maximum score). We set the cutoff\
    \ score at cutoffScore points, i.e. documents that do not get at least this score\
    \ in the Qualitative Analysis phase will be discarded.\n\n| Criteria | Weight\
    \ |  |\n|----------|--------|--|\n| CQ1      | 7      |  |\n| CQ2      | 3   \
    \   |  |\n\n<span id=\"page-5-1\"></span>Table 8: Quality criteria weights\n\n\
    We apply the weights listed in the \"Table [8](#page-5-1) and thus a description\
    \ of the requirements in the studies (\"CQ1\") of the models or tools presented\
    \ have higher objective value than the description (\"CQ2\") or the listing of\
    \ their prerequisites.\n\n| Description                                      \
    \                                 |\n|-----------------------------------------------------------------------------------|\n\
    | Rigorous Analysis                                                          \
    \       |\n| Rigorous derivation and proof suitable for formal model         \
    \                  |\n| Case Study                                           \
    \                             |\n| An empirical investigation of a current phenomenon\
    \ in its actual context;         |\n| when the boundaries between phenomenon and\
    \ context are not clearly evident;       |\n| and in which multiple sources of\
    \ evidence are used                                |\n| Discussion           \
    \                                                             |\n| Qualitative\
    \ and textual opinion                                                   |\n| Example\
    \                                                                           |\n\
    | The authors describe an application and provide an example to help in the  \
    \       |\n| description, but the example is \"used to validate\" or \"evaluate\"\
    \ to the extent    |\n| that the authors suggest                             \
    \                             |\n| Experience Report                         \
    \                                        |\n| The result has been used in real\
    \ examples, but not in the form of case studies or |\n| controlled experiments,\
    \ evidence of its use is collected informally or formally   |\n| Field Study \
    \                                                                      |\n| Controlled\
    \ experiment conducted in industry settings                              |\n|\
    \ Laboratory Experiment with Human Subjects                                  \
    \       |\n| Identifying precise relationships between variables in a controlled\
    \ environment   |\n| using humans and applying quantitative techniques       \
    \                          |\n| Laboratory Experiment with Software Subjects \
    \                                     |\n| A laboratory experiment to compare\
    \ the performance of the proposed model or       |\n| tool with existing ones\
    \                                                           |\n| Simulation  \
    \                                                                      |\n| Running\
    \ with stochastic data and using a real model or tool                       |\n\
    |                                                                            \
    \       |\n\n<span id=\"page-6-0\"></span>Table 9: Categories of studies evaluated\
    \ in the SLR\n\nWith the adoption of the categorization of studies that we have\
    \ listed in Table [9,](#page-6-0) it only remains to quantify these categories\
    \ so that we can properly score the studies and select those of interest to us.\
    \ For this Galster et al. suggests an analysis in three dimensions[\\[10\\]](#page-14-4).\n\
    \n- C Context, which refers to the environment in which conducted, includes the\
    \ experience of the personnel involved, processes used, and illustrates the feasibility\
    \ of applying a particular technology\n- D Design, which describes the products,\
    \ resources and processes used in the study\n- V Validity, that is, a discussion\
    \ of the validity of the results obtained, their limitations, and what threatens\
    \ this validity\n\nWe capture the value of each dimension as proposed in Ivarsson\
    \ and Gorschek in three levels [\\[11\\]](#page-14-5):\n\n- 1 weak;\n- 2 regular;\
    \ and\n- 3 strong.\n\nThis rigor is appropriate for empirical studies and meets\
    \ the ideas presented by Kitchenham et al. and elaborated on in Dyba et al. Cross-referencing\
    \ the\n\n|                                                              | Value\
    \                                                                            \
    \                      |                                                     \
    \                                                                            \
    \                                                                            \
    \         |                                                                  \
    \                                                                            \
    \                                                                            \
    \                                        |\n|--------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Dimension                                                    | Weak (1)    \
    \                                                                            \
    \               | Regular (2)                                                \
    \                                                                            \
    \                                                                            \
    \  | Strong (3)                                                              \
    \                                                                            \
    \                                                                            \
    \                                 |\n| Context<br>of<br>the<br>study<br>(C)  \
    \                       | There seems to<br>be no<br>description of<br>the context\
    \ in<br>which the<br>evaluation is<br>conducted | The context in<br>which the\
    \ study<br>is conducted is<br>mentioned or<br>briefly<br>presented, but is<br>not\
    \ described in<br>a way that the<br>reader can<br>understand it<br>and compare\
    \ it<br>to another<br>context | The context is<br>described in a<br>way that the<br>reader\
    \ can<br>understand it<br>and compare it<br>to another<br>context            \
    \                                                                            \
    \                                               |\n| Study design<br>(D)     \
    \                                     | There seems to<br>be no<br>description\
    \ of<br>the evaluation<br>design presented                        | The study\
    \ design<br>is described<br>briefly, e.g., \"10<br>students turned<br>in assignments<br>1,\
    \ 2, and 3 on<br>time\"                                                      \
    \                                         | The study design<br>is described in\
    \ a<br>way that a<br>reader can<br>understand,<br>among other<br>things, the<br>variables<br>measured,\
    \ the<br>control used, the<br>treatments, the<br>selection and<br>sampling used,<br>and\
    \ other<br>pertinent<br>information |\n| Validity<br>of<br>the<br>dis<br>cussion<br>of<br>results\
    \ (V) | There seems to<br>be no<br>description of<br>any threats to<br>the validity\
    \ of<br>the evaluation       | The validity of<br>the study is<br>mentioned, but<br>not\
    \ described in<br>detail                                                     \
    \                                                                            \
    \     | The validity of<br>the evaluation is<br>discussed in<br>detail where<br>threats\
    \ are<br>described and<br>measures to<br>limit them are<br>detailed          \
    \                                                                            \
    \                          |\n\ndimensions with the values we arrive at the Table\
    \ [10](#page-7-0) with the classification of rigor [\\[7,](#page-14-1) [8\\]](#page-14-2).\n\
    \n<span id=\"page-7-0\"></span>Table 10: Classification of rigor applied to studies\
    \ in the SLR\n\n## 2.3 Qualitative Analysis\n\nBased on the parameters set in\
    \ the Tables [6,](#page-4-0) [7](#page-5-0) and [10](#page-7-0) the selected studies\
    \ (see Table [5\\)](#page-3-1) were qualified and the result can be seen in the\
    \ \"Selected Primary Studies\".\n\n![](_page_7_Figure_5.jpeg)\n\n<span id=\"page-7-2\"\
    ></span><span id=\"page-7-1\"></span>Figure 2: Qualified studies\n\nIn the Figure\
    \ [2](#page-7-1) and Table [11](#page-7-2) we list the totals of studies that\
    \ have qualified based on the cutoff score (7 points).\n\n## 2.4 Analysis of Results\n\
    \nBased on the criteria listed in the Table [3](#page-2-2) 165 were selected and\
    \ 52[\\[2\\]](#page-13-1) rejected.\n\nThe research questions listed in Table\
    \ [1](#page-2-0) were applied to the selected studies and we obtained the results\
    \ that we list further below.\n\n#### 2.4.1 Models, processes, frameworks or tools\
    \ used for test production (QP1)\n\nIn the SLM[\\[2\\]](#page-13-1) we applied\
    \ the Petersen et al. systematics to classify the obtained documents as seen in\
    \ the Figure [3](#page-8-0) and evaluated the type of contribution based on interpretation\
    \ of the abstracts and listed in the Figure [4](#page-8-1) and Table [17](#page-11-0)\
    \ [\\[12,](#page-14-6) [13\\]](#page-14-7).\n\n![](_page_8_Figure_6.jpeg)\n\n\
    <span id=\"page-8-0\"></span>Figure 3: Classification Scheme (adapted from [\\\
    [12\\]](#page-14-6))\n\nWhat types of tests are produced (QP1.1)? In the Figure\
    \ [4](#page-8-1) we list the types of generators addressed by the studies, and\
    \ in the Figure [5](#page-8-2) the types of tests produced.\n\n![](_page_8_Figure_9.jpeg)\n\
    \n<span id=\"page-8-2\"></span><span id=\"page-8-1\"></span>Figure 4: Artifact\
    \ Types\n\n| Artifact Type | %   | Qty.  |\n|---------------|-----|-------|\n\
    | Both          | 32  | 6.67  |\n| Code          | 5   | 57.58 |\n| Data     \
    \     | 124 | 32.73 |\n| N/A           | 4   | 3.03  |\n\n| Generator Type | %\
    \   | Qty.  |\n|----------------|-----|-------|\n| Formal         | 33  | 20.00\
    \ |\n| White-box      | 130 | 78.79 |\n| Black-box      | 2   | 1.21  |\n\nTable\
    \ 12: Types of Artifacts Produced\n\nTable 13: Types of Generators\n\nWhat test\
    \ generation techniques were applied (QP1.2)? The most used techniques found in\
    \ the studies can be seen in Figure [6.](#page-9-0)\n\n![](_page_9_Figure_5.jpeg)\n\
    \n<span id=\"page-9-0\"></span>Figure 6: Models, methods, processes and techniques\
    \ applied in ATP\n\nWhat tools does the study employ (QP1.3)? In Figure [7](#page-9-1)\
    \ we list the tools employed by the studies.\n\n![](_page_9_Figure_8.jpeg)\n\n\
    <span id=\"page-9-1\"></span>Figure 7: Tools used in the studies\n\n<span id=\"\
    page-9-2\"></span>Table 14: Tools used in the studies\n\nWe classified as \"Proof\
    \ of concept\" the studies that used some program to present their approach but\
    \ did not use or produce a tool that can be considered ready for use by industry\
    \ and in some even for other studies.\n\nWhat are the prerequisites for its application\
    \ (QP1.4)? What artificats we observed that are required to perform the analysis\
    \ according to the study.\n\n![](_page_10_Figure_0.jpeg)\n\n<span id=\"page-10-0\"\
    ></span>Figure 8: Study Requirements\n\n| Study type          | %     | Qty. |\n\
    |---------------------|-------|------|\n| Source code         | 52.12 | 86   |\n\
    | Model               | 9.09  | 15   |\n| Model + Source code | 0.61  | 1    |\n\
    | Tool + Source code  | 30.30 | 50   |\n| Tool + Model        | 7.88  | 13   |\n\
    \n<span id=\"page-10-1\"></span>Table 15: Study Requirements\n\nWhat types of\
    \ studies or evaluations have been conducted (QP1.5)? The types of studies were\
    \ classified according to Table [16](#page-11-1) and the results listed in Figure\
    \ [9](#page-11-2) and Table [17.](#page-11-0)\n\n| Category     | Description\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \   |\n|--------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Metric       | A system or standard of measures or measure<br>ments taken using\
    \ an existing standard.                                                      \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                          |\n| Tool         | A device or implementation, used\
    \ to perform a<br>certain function.                                          \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                          |\n| Model        |\
    \ A comprehensive and systematic approach that<br>includes theoretical principles,\
    \ benefits and draw<br>backs, objectives, methodological guidelines and<br>specifications,\
    \ and the characteristic use of cer<br>tain sets of methods and techniques.  \
    \                                                                            \
    \                                                                         |\n\
    | Method       | No particular theoretical orientation is inferred<br>in a method.\
    \ Researchers impose their own par<br>ticular theoretical beliefs on an experiment\
    \ when<br>they design and implement it by applying one or<br>more techniques.\
    \                                                                            \
    \                                                                            \
    \                    |\n| Technique    | A single operation or interaction in\
    \ which a re<br>searcher uses one or more procedures to elicit an<br>immediate\
    \ reaction from the object of study or to<br>shape the experiment and obtain results.\
    \                                                                            \
    \                                                                            \
    \                                             |\n| Procedure    | An organized\
    \ sequence of operations and interac<br>tions that a researcher uses to conduct\
    \ an exper<br>iment.                                                         \
    \                                                                            \
    \                                                                            \
    \                                                                            |\n\
    | Intervention | Purposefully interferes with or mitigates various<br>aspects\
    \ of the object of study and that affect the<br>outcome by applying procedure,\
    \ technique. The<br>elements acting on the industry during a partic<br>ular intervention\
    \ are most often computer appli<br>cations, the researcher, or both.         \
    \                                                                            \
    \                  |\n| Approach     | A broad way of addressing an industry concern\
    \ or<br>problem. A specific methods is not implied, but<br>a specific set of techniques\
    \ will likely come into<br>play when trying to intervene in the industry and<br>the\
    \ problem that is the subject of the research.<br>The procedures to be used will\
    \ be determined by<br>the delimitations of the methodological variant in<br>which\
    \ we design the study. |\n| Strategy     | An action plan designed to achieve\
    \ an overall<br>goal.                                                        \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                        |\n\n<span id=\"page-11-1\"\
    ></span>Table 16: Type of contribution\n\n![](_page_11_Figure_2.jpeg)\n\n<span\
    \ id=\"page-11-0\"></span>Table 17: Contributions of the Studies\n\n<span id=\"\
    page-11-2\"></span>Figure 9: Contributions of the Studies\n\n## 3 Results\n\n\
    We present the results of a SLR employed to find relevant studies on ATP. This\
    \ review applied the methodology of Petersen et al. with elements of Basili and\
    \ Weiss, Keele et al., Brereton et al. The results obtained list different models,\
    \ processes, frameworks and tools used with diverse approaches and results.\n\n\
    ### 3.1 Conclusions\n\nBased on the research questions developed in Section [2](#page-0-0)\
    \ we conclude that:\n\n#### 3.1.1 Models, processes, frameworks or tools applied\
    \ to test production\n\nTypes of tests produced As we can see from the Figures\
    \ [4](#page-8-1) and [5](#page-8-2) much of the studies have been devoted to producing\
    \ test verification of white-box [1](#page-12-0) . We also observe significant\
    \ concern with the Oracle problem (determining the correct outputs for given inputs)\
    \ and there are a significant number of approaches that produce data for program\
    \ verification.\n\nGiven the aspect of this research and the questions we address,\
    \ black-box tests[2](#page-12-1) were not representative in our results, however\
    \ according to Gaudel formal methods were a highlight and these can be considered\
    \ to be black-box tests.\n\nTechniques applyed to test production Several techniques\
    \ were employed in test production, and among them we highlight Search Methods\
    \ (see Figure [6\\)](#page-9-0). Secondly we note the application of Specification\
    \ Extraction[3](#page-12-2) as an important approach employed by the studies.\n\
    \nHighlighted we can also observe: Symbolic Execution, Combinatorial Methods and\
    \ Model Notation.\n\nTools applyed by the studies In the Figure [7](#page-9-1)\
    \ and Table [14](#page-9-2) we observed a great diversity of tools used and none\
    \ in particular stood out in our study, highlighting the use of UML (Unified Modelling\
    \ Language) by a significant percentage (if compared to other approaches) of studies.\
    \ This fragmentation demonstrates, on the one hand, a great wealth of available\
    \ solutions and approaches, but it may also be indicative of a lack of maturity\
    \ of the solutions presented, which can be observed by the opinion of some authors\
    \ [\\[15,](#page-14-8) [16\\]](#page-14-9).\n\nPre-requisites to the proposed\
    \ approaches For even obvious reasons (related to white-box testing - see Figure\
    \ [5\\)](#page-8-2), the vast majority of studies require access to the source\
    \ code of the applications (see Figure [8](#page-10-0) and Table [15\\)](#page-10-1).\
    \ Many\n\n<span id=\"page-12-0\"></span><sup>1</sup>Method of validating non-functional,\
    \ internal aspects of a computer application.\n\n<span id=\"page-12-1\"></span><sup>2</sup>Method\
    \ of validating functional and external aspects of a computer application\n\n\
    <span id=\"page-12-2\"></span><sup>3</sup>Comparative studies do not present particular\
    \ techniques or methods\n\nstudies are conducted using tools (none in particular\
    \ as we have noted - see Figure [7\\)](#page-9-1), but an important number have\
    \ been conducted from models (previously produced by a development process or\
    \ ad hoc).\n\nTypes of studies or evaluations conducted In the Figure [9](#page-11-2)\
    \ and Table [17](#page-11-0) we list the main contributions of the studies, and\
    \ note a rather encouraging number of concrete contributions (in the form of methods,\
    \ tools, metrics, and models) that can be leveraged and extended by the industry.\n\
    \n### 3.2 Future work\n\nThis work aimed to prepare the ground for further research\
    \ on ATP where we will determine the challenges in applying generative testing\
    \ techniques and evaluate the solutions we intend to address.\n\n## Acronyms\n\
    \n| ATP        | Automated Test Production<br>- pages: 1, 2, 13, 14          \
    \                                          |\n|------------|-------------------------------------------------------------------------------------------------------|\n\
    | SLM<br>SLR | Systematic Literature Mapping<br>- pages: 1, 3, 9<br>Systematic\
    \ Literature Review<br>- pages: 1–3, 13 |\n\nUML Unified Modelling Language -\
    \ page: 13\n\n## References\n\n- <span id=\"page-13-0\"></span>[1] P. Brereton,\
    \ B. A. Kitchenham, D. Budgen, M. Turner, and M. Khalil, \"Lessons from applying\
    \ the systematic literature review process within the software engineering domain,\"\
    \ Journal of systems and software, vol. 80, no. 4, pp. 571–583, 2007.\n- <span\
    \ id=\"page-13-1\"></span>[2] J. M. Gomes and L. A. V. Dias, \"Automated test\
    \ production – systematic literature mapping,\" 2024. arXiv: [2401.01430 \\[cs.SE\\\
    ]](https://arxiv.org/abs/2401.01430).\n- <span id=\"page-13-2\"></span>[3] B.\
    \ Kitchenham, O. P. Brereton, D. Budgen, M. Turner, J. Bailey, and S. Linkman,\
    \ \"Systematic literature reviews in software engineering–a systematic literature\
    \ review,\" Information and software technology, vol. 51, no. 1, pp. 7–15, 2009.\n\
    - <span id=\"page-13-3\"></span>[4] V. R. Basili and D. M. Weiss, \"A methodology\
    \ for collecting valid software engineering data,\" IEEE Transactions on software\
    \ engineering, no. 6, pp. 728–738, 1984.\n- <span id=\"page-13-4\"></span>[5]\
    \ L. Chen and M. A. Babar, \"A systematic review of evaluation of variability\
    \ management approaches in software product lines,\" Information and Software\
    \ Technology, vol. 53, no. 4, pp. 344–362, 2011.\n- <span id=\"page-14-0\"></span>[6]\
    \ S. Keele et al., \"Guidelines for performing systematic literature reviews in\
    \ software engineering,\" Technical report, Ver. 2.3 EBSE Technical Report. EBSE,\
    \ Tech. Rep., 2007.\n- <span id=\"page-14-1\"></span>[7] B. A. Kitchenham, T.\
    \ Dyba, and M. Jorgensen, \"Evidence-based software engineering,\" in Proceedings.\
    \ 26th International Conference on Software Engineering, IEEE, 2004, pp. 273–281.\n\
    - <span id=\"page-14-2\"></span>[8] T. Dyba, B. A. Kitchenham, and M. Jorgensen,\
    \ \"Evidence-based software engineering for practitioners,\" IEEE software, vol.\
    \ 22, no. 1, pp. 58–65, 2005.\n- <span id=\"page-14-3\"></span>[9] R. M. Davis,\
    \ \"Evolution of computers and computing,\" Science, vol. 195, no. 4283, pp. 1096–1102,\
    \ 1977.\n- <span id=\"page-14-4\"></span>[10] M. Galster, D. Weyns, D. Tofan,\
    \ B. Michalik, and P. Avgeriou, \"Variability in software systems—a systematic\
    \ literature review,\" IEEE Transactions on Software Engineering, vol. 40, no.\
    \ 3, pp. 282–306, 2013.\n- <span id=\"page-14-5\"></span>[11] M. Ivarsson and\
    \ T. Gorschek, \"A method for evaluating rigor and industrial relevance of technology\
    \ evaluations,\" Empirical Software Engineering, vol. 16, no. 3, pp. 365–395,\
    \ 2011.\n- <span id=\"page-14-6\"></span>[12] K. Petersen, R. Feldt, S. Mujtaba,\
    \ and M. Mattsson, \"Systematic mapping studies in software engineering,\" in\
    \ 12th International Conference on Evaluation and Assessment in Software Engineering\
    \ (EASE) 12, 2008, pp. 1–10.\n- <span id=\"page-14-7\"></span>[13] R. Wieringa,\
    \ N. Maiden, N. Mead, and C. Rolland, \"Requirements engineering paper classification\
    \ and evaluation criteria: A proposal and a discussion,\" Requirements engineering,\
    \ vol. 11, no. 1, pp. 102–107, 2006.\n- [14] M.-C. Gaudel, \"Formal methods for\
    \ software testing,\" in 2017 International Symposium on Theoretical Aspects of\
    \ Software Engineering (TASE), IEEE, 2017, pp. 1–3.\n- <span id=\"page-14-8\"\
    ></span>[15] U. Rueda, F. Kifetew, and X. Devroey, \"Towards automated test case\
    \ generation maturity,\" in Proceedings of the 12th International Workshop on\
    \ Search-Based Software Testing, ser. SBST '19, ZSCC: 0000000, IEEE Press, 2019,\
    \ pp. 9–10. doi: [10.1109/SBST.2019.00011](https://doi.org/10.1109/SBST.2019.00011).\
    \ [Online]. Available: <https://doi.org/10.1109/SBST.2019.00011>.\n- <span id=\"\
    page-14-9\"></span>[16] A. Arcuri, \"An experience report on applying software\
    \ testing academic results in industry: We need usable automated test generation,\"\
    \ Empir Software Eng, vol. 23, no. 4, pp. 1959–1981, 2018, issn: 1382-3256. doi:\
    \ [10.1007/s10664-017-9570-9](https://doi.org/10.1007/s10664-017-9570-9).\n\n\
    | #        | Title                                                           \
    \                                                                            \
    \                         | Author                                           \
    \                                                                            \
    \ |\n|----------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|\n\
    | 1<br>2   | Support<br>Software<br>and<br>Primary<br>Evolving<br>Using<br>for<br>Generation<br>Generation<br>Suite<br>Test<br>Test<br>Unit<br>Multifaceted<br>Automated\
    \          | Sina<br>Gregory<br>Shamshiri,<br>Gay,                           \
    \                                                              |\n|          |\
    \ Functions<br>Fitness<br>ing                                                \
    \                                                                            \
    \              |                                                             \
    \                                                                  |\n| 3    \
    \    | Decomposition<br>Model<br>by<br>Generation<br>Test<br>Model-Based<br>Improving\
    \                                                                            \
    \           | Riccobene,<br>Angelo;<br>Gargantini,<br>Paolo;<br>Arcaini,<br>Elvinia\
    \                                                         |\n| 4        | the<br>to<br>Applied<br>Algorithms<br>Search-Based<br>of<br>Generation<br>Automatic\
    \                                                                            \
    \      | A.<br>Jackson<br>Lima,<br>Jakubovski;<br>L.<br>Helson<br>Filho,     \
    \                                                          |\n| 5        | Strategy<br>Optimization<br>Lines<br>Learning-Based<br>Product<br>Software<br>Teaching<br>of<br>Adaptive<br>Testing<br>Feature<br>Fuzzy\
    \                              | Z.<br>Kamal<br>R.<br>Silvia<br>Zamli,<br>Vergilio,<br>Fakhrud;<br>Prado;<br>Din,\
    \                                              |\n|          | Generation<br>Cases<br>Test<br>Functional<br>GUI<br>for\
    \                                                                            \
    \                                  |                                         \
    \                                                                            \
    \          |\n| 6        | Context<br>Using<br>Generation<br>Test<br>Improving<br>Functions<br>One-Size-Fits-None?<br>Fitness<br>Optimized\
    \                                                      | Gregory<br>Gay,     \
    \                                                                            \
    \                              |\n| 7        | Optimisa<br>Many-Objective<br>a<br>as<br>Generation<br>Case<br>Test<br>Automated\
    \                                                                            \
    \         | Meshesha;<br>Fitsum<br>Kifetew,<br>Annibale;<br>Panichella,      \
    \                                                             |\n| 8        |\
    \ Generation<br>Test<br>Targets<br>Model-Based<br>the<br>of<br>Selection<br>for<br>Approach<br>Dynamic<br>Decomposition-Based<br>with<br>Problem<br>tion\
    \               | Riccobene,<br>Angelo;<br>Gargantini,<br>Paolo;<br>Paolo<br>Tonella,<br>Arcaini,\
    \                                               |\n| 9        | Distributed<br>for<br>Suites<br>Test<br>Controllable<br>Complete<br>Generating\
    \                                                                            \
    \           | M.<br>Robert<br>Hierons,<br>Elvinia                            \
    \                                                               |\n|         \
    \ | Testing                                                                  \
    \                                                                            \
    \                |                                                           \
    \                                                                    |\n| 10<br>11\
    \ | Mo<br>for<br>Strategy<br>Testing<br>Generation<br>Event-Based<br>Model<br>for<br>Morphology<br>Static-Dynamic<br>Model<br>A<br>Exploiting<br>AMOGA:\
    \                  | Ahmed,<br>Rosziati;<br>Ibrahim,<br>Mutlu<br>Ibrahim-Anka;<br>Beyazit,<br>Fevzi;<br>Salihu,<br>Belli,\
    \                          |\n|          | Testing<br>Apps<br>bile           \
    \                                                                            \
    \                                                       | Asmau<br>Usman,<br>Z.;<br>Kamal<br>Zamli,<br>S.;<br>Bestoun\
    \                                                                   |\n| 12  \
    \     | Optimisa<br>Compiler<br>via<br>Equivalences<br>Mutant<br>Trivial<br>Detecting<br>tions\
    \                                                                            \
    \   | Yue;<br>Mark<br>Jia,<br>Harman,<br>Mike;<br>Yves;<br>Papadakis,<br>Traon,<br>Le<br>Marinos;<br>Nicos;<br>Malevris,<br>Kintis,\
    \ |\n| 13       | to<br>Proofs<br>Pen-and-Paper<br>From<br>Verification:<br>Software<br>Tools<br>Deductive<br>Industrial\
    \                                                               | Marieke<br>Huisman,<br>Reiner;<br>H¨ahnle,\
    \                                                                            \
    \        |\n| 14       | test<br>mutation<br>for<br>approach<br>generation<br>data<br>test<br>multi-objective<br>A\
    \                                                                            |\
    \ R.<br>Silvia<br>Vergilio,<br>A.;<br>Rui<br>Filho,<br>Matnei                \
    \                                                   |\n| 15       | val<br>for<br>data<br>invalid<br>and<br>valid<br>of<br>models<br>feature<br>Automatic<br>of<br>ing\
    \                                                                   |        \
    \                                                                            \
    \                                           |\n|          | string<br>expressions<br>regular<br>test<br>and<br>searches<br>web<br>using<br>generation<br>routines<br>idation\
    \                                                     | Stevenson,<br>Phil;<br>McMinn,<br>Muzammil;<br>Shahbaz,<br>Mark\
    \                                                               |\n| 16      \
    \ | suites<br>test<br>whole<br>of<br>generation<br>mutation-based<br>scalable<br>Achieving\
    \                                                                            \
    \   | Andrea<br>Arcuri,<br>Gordon;<br>Fraser,                                \
    \                                                       |\n| 17       | T<br>AC<br>CONSTRAINTS<br>LATE<br>ON<br>BASED<br>OF<br>STRATEGY<br>BENCHMARKING<br>GENERATION<br>COMPARATIVE<br>TEST<br>WAY\
    \                                          | Alsewari;<br>Rahman<br>Abdul<br>Z.;<br>Al-Kazemi<br>Kamal<br>Basem<br>Zamli,\
    \                                                  |\n| 18       | and<br>selection<br>ALGORITHM<br>CLIMBING<br>of<br>HILL<br>CEPTANCE<br>An\
    \                                                                            \
    \                | Gra<br>Kamal                                              \
    \                                                                    |\n|    \
    \      | acceptance<br>generation<br>suite<br>hyper-heuristic<br>test<br>t-way<br>combinatorial<br>study<br>experimental<br>for<br>mechanism\
    \                                  | Kendall,<br>Fakhrud;<br>S.<br>Din,<br>Bestoun<br>Z.;<br>Ahmed,<br>Zamli,<br>ham;\
    \                                              |\n| 19       | for<br>graph<br>flow<br>control<br>condition<br>multiple<br>MOF-based<br>an<br>MCCFG:\
    \                                                                            \
    \    | R.<br>Kim,<br>Young;<br>Park,<br>Hyun;<br>Son,                        \
    \                                                        |\n| 20       | gen<br>suite<br>test<br>t-way<br>for<br>strategy<br>hyper-heuristic<br>generation<br>case<br>Search<br>test<br>automatic<br>Tabu<br>A\
    \                                | Kendall,<br>Y;<br>Basem<br>Alkazemi,<br>Z.;<br>Kamal<br>Zamli,\
    \                                                                |\n|        \
    \  | eration                                                                 \
    \                                                                            \
    \                 | Graham                                                   \
    \                                                                     |\n| 21\
    \       | specification<br>evolved<br>for<br>generation<br>case<br>test<br>based<br>net<br>Petri\
    \                                                                            \
    \   | Jin,<br>Haibo;<br>Chen,<br>Mingyue;<br>Jiang,<br>Mengchu<br>Zuohua;<br>Zhou,<br>Ding,<br>Zhi;\
    \                                 |\n| 22       | Reduc<br>Mutant<br>of<br>Generation<br>the<br>for<br>Hyper-Heuristic<br>A<br>Sentinel:\
    \                                                                            \
    \   | Jens;<br>Krinke,<br>Federica;<br>Sarro,<br>Giovani;<br>Guizzo,         \
    \                                                       |\n| 23       | debug<br>and<br>for<br>oracles<br>(F)LTL<br>of<br>Strategies<br>Automated<br>tion\
    \                                                                            \
    \        | Franz<br>Wotawa,<br>R.<br>Silvia<br>Vergilio,<br>Pill,            \
    \                                                            |\n|          | testing<br>generation<br>ging\
    \                                                                            \
    \                                                            | Ingo;         \
    \                                                                            \
    \                                    |\n| 24       | Gen<br>Test<br>for<br>Solvers<br>SMT<br>and<br>SAT<br>Expressions<br>of<br>Use<br>the<br>Boolean<br>Optimize<br>of<br>to<br>eration<br>How\
    \                           | Riccobene,<br>Angelo;<br>Gargantini,<br>Paolo;<br>Arcaini,<br>Elvinia\
    \                                                         |\n| 25       | generation<br>Automated<br>job:<br>the<br>for<br>function<br>fitness<br>the<br>Choosing\
    \                                                                            \
    \  | Gre<br>Gay,<br>Hussein;<br>Almulla,<br>Alireza;<br>Salahirad,           \
    \                                                      |\n| 26       | Gen<br>Case<br>Test<br>Automatic<br>for<br>faults<br>Tool<br>and<br>real<br>Process<br>detect<br>that<br>TDD<br>suites<br>A<br>MoFQA:<br>test<br>of\
    \                  | Nathalie<br>Gonz´alez;<br>Magal´ı<br>Riquelme;<br>Linda<br>gory\
    \                                                               |\n|         \
    \ | Models<br>MDD<br>from<br>eration                                         \
    \                                                                            \
    \                | Cernuzzi<br>Luca<br>Aquino;                               \
    \                                                                    |\n| 27 \
    \      | models<br>process<br>business<br>from<br>generation<br>cases<br>test<br>Automatic\
    \                                                                            \
    \        | Mohammad;<br>Amiri,<br>Mahnaz<br>Arezoo;<br>Koupaee,<br>Seqerloo,<br>Saeed;<br>Yazdani<br>Parsa,\
    \                              |\n| 28<br>29 | chart<br>Covering<br>state<br>Cell<br>from<br>by<br>generation<br>Expressions<br>case<br>Boolean<br>test<br>based<br>for<br>Generation<br>Transition<br>Case<br>Test\
    \ | S.K.<br>Swain,<br>Mitrabinda;<br>Tsai<br>Wei-Tek<br>Ray,<br>S.;<br>Pradhan,<br>Yu;<br>Lian\
    \                                    |\n|          | coverage<br>diagram     \
    \                                                                            \
    \                                                                 |          \
    \                                                                            \
    \                                         |\n| 30<br>31 | algo<br>pollination<br>generation<br>flower<br>suite<br>on<br>based<br>test<br>whole<br>generation<br>for<br>Algorithm<br>data<br>test<br>Memetic<br>Pairwise<br>A\
    \   | Tairan,<br>Phil<br>McMinn,<br>A.A.;<br>Alsewari,<br>Andrea;<br>Arcuri,<br>B.;<br>Abdullah<br>Gordon;<br>Nasser,<br>Fraser,\
    \    |\n| 32       | Isabelle<br>in<br>diagrams<br>invariant<br>for<br>generation<br>code<br>and<br>Verification<br>rithm\
    \                                                                 | J<br>Eriksson,<br>Rj;<br>Z.<br>Kamal<br>Back,<br>V;<br>Zamli,<br>Preoteasa,<br>N.M.;\
    \                                          |\n| 33       | generation<br>test<br>for<br>under-approximation<br>Tri-modal\
    \                                                                            \
    \                            | Masson,<br>Jacques;<br>Julliand,<br>Hadrien;<br>Pierre-Alain<br>Bride,\
    \                                                        |\n| 34       | strength<br>variable<br>for<br>algorithm<br>greedy<br>on<br>elitism<br>the<br>Adapting\
    \                                                                            \
    \   | Kamal<br>Zamli,<br>A.A.;<br>Alsewari,<br>A.A.B.A.;<br>Homaid,          \
    \                                                       |\n\n# Appendices\n\n\
    ## Appendix A Selected Primary Studies\n\ncombinatorial\n\n35 Model Learning and\
    \ Test Generation\n\n test cases generation\n\n Using Cover Automata\n\nZ.; Alsariera,\n\
    \n Ipate, Florentin;\n\n Y.A.\n\n Stefanescu,\n\n Alin; Dinca, Ionut"
- title: "ModuleGuard:Understanding and Detecting Module Conflicts in Python\n  Ecosystem"
  abstract: 'Python has become one of the most popular programming languages for software

    development due to its simplicity, readability, and versatility. As the Python

    ecosystem grows, developers face increasing challenges in avoiding module

    conflicts, which occur when different packages have the same namespace modules.

    Unfortunately, existing work has neither investigated the module conflict

    comprehensively nor provided tools to detect the conflict. Therefore, this

    paper systematically investigates the module conflict problem and its impact on

    the Python ecosystem. We propose a novel technique called InstSimulator, which

    leverages semantics and installation simulation to achieve accurate and

    efficient module extraction. Based on this, we implement a tool called

    ModuleGuard to detect module conflicts for the Python ecosystem. For the study,

    we first collect 97 MC issues, classify the characteristics and causes of these

    MC issues, summarize three different conflict patterns, and analyze their

    potential threats. Then, we conducted a large-scale analysis of the whole PyPI

    ecosystem (4.2 million packages) and GitHub popular projects (3,711 projects)

    to detect each MC pattern and analyze their potential impact. We discovered

    that module conflicts still impact numerous TPLs and GitHub projects. This is

    primarily due to developers'' lack of understanding of the modules within their

    direct dependencies, not to mention the modules of the transitive dependencies.

    Our work reveals Python''s shortcomings in handling naming conflicts and

    provides a tool and guidelines for developers to detect conflicts.'
  url: http://arxiv.org/abs/2401.02090v1
  keywords: ''
  document: "# ModuleGuard: Understanding and Detecting Module Conflicts in Python\
    \ Ecosystem\n\n[Ruofan Zhu](https://orcid.org/0009-0005-5181-4797) zhuruofan@zju.edu.cn\
    \ Zhejiang University Hangzhou, China\n\n[Zhengzi Xu](https://orcid.org/0000-0002-8390-7518)\
    \ zhengzi.xu@ntu.edu.sg Nanyang Technological University Singapore\n\n[Xingyu\
    \ Wang](https://orcid.org/0009-0009-9988-8065) wangxingyu@zju.edu.cn Zhejiang\
    \ University Hangzhou, China\n\n[Wenbo Shen](https://orcid.org/0000-0003-2899-6121)<sup>∗</sup>\
    \ shenwenbo@zju.edu.cn Zhejiang University Hangzhou, China\n\n[Liu Yang](https://orcid.org/0000-0001-7300-9215)\
    \ yangliu@ntu.edu.sg Nanyang Technological University Singapore\n\n[Chengwei Liu](https://orcid.org/0000-0003-1175-2753)\
    \ chengwei001@e.ntu.edu.sg Nanyang Technological University Singapore\n\n> [Rui\
    \ Chang](https://orcid.org/0000-0002-0178-0171) crix1021@zju.edu.cn Zhejiang University\
    \ Hangzhou, China\n\n### ABSTRACT\n\nPython has become one of the most popular\
    \ programming languages for software development due to its simplicity, readability,\
    \ and versatility. As the Python ecosystem grows, developers face increasing challenges\
    \ in avoiding module conflicts, which occur when different packages have the same\
    \ namespace modules. Unfortunately, existing work has neither investigated the\
    \ module conflict comprehensively nor provided tools to detect the conflict. Therefore,\
    \ this paper systematically investigates the module conflict problem and its impact\
    \ on the Python ecosystem. We propose a novel technique called InstSimulator,\
    \ which leverages semantics and installation simulation to achieve accurate and\
    \ efficient module extraction. Based on this, we implement a tool called ModuleGuard\
    \ to detect module conflicts for the Python ecosystem.\n\nFor the study, we first\
    \ collect 97 MC issues, classify the characteristics and causes of these MC issues,\
    \ summarize three different conflict patterns, and analyze their potential threats.\
    \ Then, we conducted a large-scale analysis of the whole PyPI ecosystem (4.2 million\
    \ packages) and GitHub popular projects (3,711 projects) to detect each MC pattern\
    \ and analyze their potential impact. We discovered that module conflicts still\
    \ impact numerous TPLs and GitHub projects. This is primarily due to developers'\
    \ lack of understanding of the modules within their direct dependencies, not to\
    \ mention the modules of the transitive dependencies. Our work reveals Python's\
    \ shortcomings in handling naming conflicts and provides a tool and guidelines\
    \ for developers to detect conflicts.\n\nICSE '24, April 14–20, 2024, Lisbon,\
    \ Portugal\n\n© 2024 Copyright held by the owner/author(s). Publication rights\
    \ licensed to ACM. ACM ISBN 979-8-4007-0217-4/24/04. . . \\$15.00 <https://doi.org/10.1145/3597503.3639221>\n\
    \n#### CCS CONCEPTS\n\n• Software and its engineering → Software safety; Software\
    \ reliability.\n\n#### KEYWORDS\n\nModule Conflict, PyPI Ecosystem, Dependency\
    \ Graphs, Namespace Conflict, Dependency Resolution\n\n#### ACM Reference Format:\n\
    \nRuofan Zhu, Xingyu Wang, Chengwei Liu, Zhengzi Xu, Wenbo Shen, Rui Chang, and\
    \ Liu Yang. 2024. ModuleGuard: Understanding and Detecting Module Conflicts in\
    \ Python Ecosystem. In 2024 IEEE/ACM 46th International Conference on Software\
    \ Engineering (ICSE '24), April 14–20, 2024, Lisbon, Portugal. ACM, Lisbon, Portugal,\
    \ [12](#page-11-0) pages. [https://doi.org/10.1145/3597503.](https://doi.org/10.1145/3597503.3639221)\
    \ [3639221](https://doi.org/10.1145/3597503.3639221)\n\n#### 1 INTRODUCTION\n\n\
    Namespace conflicts are a ubiquitous challenge in the field of computer science.\
    \ However, with the thriving development of the software supply chain in recent\
    \ years, there has been explosive growth in the number of open-source software,\
    \ making the issue of namespace conflicts more pressing [\\[47\\]](#page-11-1).\
    \ According to the Sonatype report [\\[39\\]](#page-11-2), the number of open-source\
    \ software represents a 20% year-over-year growth globally. As software systems\
    \ become larger and more diverse, the likelihood of encountering namespace conflicts\
    \ increases significantly.\n\nWhile namespace conflicts have long been a topic\
    \ of discussion, different language ecosystems have taken different approaches\
    \ to address namespace conflict issues. For instance, the Java ecosystem uses\
    \ groupId, artifactId, and version to name an open-source package uniquely and\
    \ extracts the package's modules to a unique path formed by this triplet [\\[26\\\
    ]](#page-11-3). Rust isolates different open-source packages by placing them in\
    \ separate folders [\\[9\\]](#page-11-4). Similarly, Python Package Index (PyPI)\
    \ uses the project name as a unique identifier for an open-source package, but\
    \ the module names within the package are not unique [\\[29\\]](#page-11-5). As\
    \ a result, we have found that it poses some threats in handling naming conflicts.\
    \ First, unlike other languages,\n\n<sup>∗</sup>Wenbo Shen is the corresponding\
    \ author.\n\nPermission to make digital or hard copies of all or part of this\
    \ work for personal or classroom use is granted without fee provided that copies\
    \ are not made or distributed for profit or commercial advantage and that copies\
    \ bear this notice and the full citation on the first page. Copyrights for components\
    \ of this work owned by others than the author(s) must be honored. Abstracting\
    \ with credit is permitted. To copy otherwise, or republish, to post on servers\
    \ or to redistribute to lists, requires prior specific permission and/or a fee.\
    \ Request permissions from permissions@acm.org.\n\nPython does not isolate each\
    \ package that has been downloaded locally but instead installs them together\
    \ by default. This results in an impact of module overwriting when two packages\
    \ with conflicting module namespaces are installed simultaneously.\n\nSecond,\
    \ as an interpreted language, Python determines which specific module to import\
    \ at runtime, unlike compiled languages that can report errors in advance. Hence,\
    \ when importing packages at runtime, the existence of modules in different paths\
    \ may lead to conflicts, posing a threat of import confusion. We refer to the\
    \ conflicts caused by module namespaces as Module Conflicts (MC). These two threats\
    \ of module conflicts are unique to the Python ecosystem since they are caused\
    \ by Python's specific mechanisms for handling namespace conflicts. These threats\
    \ can cause the program to break locally existing third-party packages when installed,\
    \ causing environmental damage that is difficult to repair. They can cause function\
    \ errors in program execution, leading to bugs that are hard to trace and fix.\
    \ Moreover, the MC issues can inhibit the normal update of packages, breaking\
    \ their integrity.\n\nExisting work provides in-depth research and analysis on\
    \ a number of issues specific to the Python ecosystem. Cheng et al. [\\[7\\]](#page-10-0)\
    \ propose PyCRE, a new approach to automatically infer Pythoncompatible runtime\
    \ environments with domain knowledge graphs. Ye et al. [\\[49\\]](#page-11-6)\
    \ propose PyEGo, a knowledge-based technique that can automatically infer dependencies'\
    \ compatible versions for Python programs. Unfortunately, when dealing with module\
    \ conflicts, they both simply consider the conflicting modules belonging to the\
    \ most popular packages. Wang et al. [\\[45\\]](#page-11-7) present SnifferDog,\
    \ an approach that can restore the execution environments of Jupyter notebooks.\
    \ Garcia et al. [\\[20\\]](#page-11-8) present DockerizeMe, a tool that can generate\
    \ Dockerfiles for Python projects. However, when dealing with module conflicts,\
    \ they all use a limited number of module-to-package mappings, which do not realize\
    \ conflicts. Other works primarily focus on dependency conflicts [\\[7,](#page-10-0)\
    \ [24,](#page-11-9) [44,](#page-11-10) [46\\]](#page-11-11) that resolve different\
    \ software components require incompatible versions of the same dependency, dependency\
    \ diagnosis [\\[6\\]](#page-10-1) that fix incorrect dependency configurations,\
    \ and detecting malicious packages [\\[3,](#page-10-2) [10,](#page-11-12) [19,](#page-11-13)\
    \ [36,](#page-11-14) [42\\]](#page-11-15) for PyPI packages and dependencies.\
    \ These works do not systematically address the MC problem or detect MC. They\
    \ either ignore the existence of multiple packages that provide the same module\
    \ or rely on incomplete module-to-package mappings that can not cover all possible\
    \ scenarios.\n\nTo fill this gap, this paper conducts a systematic study to investigate\
    \ the module conflict problem and its impact on the Python ecosystem. To achieve\
    \ the large-scale study, we first propose a novel technique named installation-free\
    \ module extraction (InstSimulator in short). It extracts the semantics of different\
    \ configuration files from multiple dimensions and then simulates the installation\
    \ process according to the semantics to extract exact modules. Our evaluation\
    \ shows that InstSimulator achieves over 95% accuracy and can complete the module\
    \ extraction of all four million packages in 10 hours with 40 threads in parallel.\
    \ Then, based on InstSimulator we implement a novel tool named ModuleGuard for\
    \ the study.\n\nTo conduct the study, we first collect 97 MC issues on GitHub\
    \ and StackOverflow, classify the characteristics and causes of these MC issues,\
    \ summarize three different conflict patterns, and analyze their potential threats.\
    \ Next, using ModuleGuard, we conduct a largescale analysis of the whole PyPI\
    \ ecosystem (4.2 million packages)\n\nand GitHub popular projects (3,711 projects)\
    \ to detect each MC pattern and analyze their potential impact. We have discovered\
    \ that there are still numerous open-source software packages in PyPI that are\
    \ impacted by module conflicts among their dependencies. This is primarily due\
    \ to developers lacking understanding of the modules within their direct and indirect\
    \ dependencies. Our work not only reveals Python's shortcomings in handling naming\
    \ conflicts but also provides tools and guidelines for developers to detect conflicts\
    \ when developing and debugging.\n\nTo summarize, this paper makes the following\
    \ contributions.\n\n- New study. We conduct a systematic study on module conflicts\
    \ (MC) in the Python ecosystem. We conducted an issue study from GitHub and StackOverflow\
    \ and summarized three MC patternsmodule-to-TPL, module-to-Lib, and module-in-Dep\
    \ conflicts and their two potential threats.\n- New technique. We propose InstSimulator,\
    \ which leverages the semantics and installation simulation to achieve accurate\
    \ and efficient module extraction. Based on this, we implement a tool ModuleGuard\
    \ to detect MCs for the Python ecosystem. We construct benchmarks for evaluating\
    \ the capabilities of module information extraction and dependency graph resolution.\n\
    - Ecosystem-scale analysis. Utilizing ModuleGuard, we conduct a large-scale study\
    \ and analyze 4.2 million packages on PyPI (434,823 latest version packages as\
    \ of April 2023). We get a lot of interesting findings, shed some light on the\
    \ nature of module conflicts, and provide some guidance for developers.\n- Issue\
    \ reporting. We examine 93,487 tags of 3,711 popular GitHub projects, of which\
    \ 108 are now or ever affected by MC. We reported issues, and a lot of issues\
    \ have been confirmed and fixed. This proves that our work can help developers\
    \ understand previously unrealized errors and help them fix potential threats.\n\
    \nThis paper is organized as follows. We introduce background knowledge in [§2.](#page-1-0)\
    \ In [§3,](#page-2-0) we propose our ModuleGuard tool and introduce it in detail.\
    \ In [§4](#page-4-0) we evaluate ModuleGuard in different metrics. In [§5](#page-5-0)\
    \ we conduct an ecosystem-scale study on MC, including issues study, GitHub projects,\
    \ and PyPI packages. [§6](#page-9-0) and [§7](#page-9-1) present some limitations\
    \ and discussion. Related work is described in [§8.](#page-10-3) Finally, we conclude\
    \ the whole paper in [§9.](#page-10-4)\n\n#### <span id=\"page-1-0\"></span>2\
    \ BACKGROUND\n\nIn this section, we provide the necessary background for our study.\
    \ We first explain how Python code is managed and how Python modules are shared\
    \ among developers. Then, we describe how PyPI handles third-party libraries (TPLs)\
    \ and their dependencies. Finally, we illustrate two examples of module conflicts\
    \ (MCs), which are the main problem we address in this paper.\n\nPython code management.\
    \ Python uses pip [\\[29\\]](#page-11-5) as its official package manager for downloading\
    \ and installing TPLs from PyPI. When pip receives a package request, it first\
    \ resolves the constraint and selects a suitable version of the package. Then,\
    \ it downloads the package to a local temporary folder. If the package is a source\
    \ distribution package, pip extracts all the files, compiles the package, generates\
    \ metadata files, and installs the package based on the metadata files. If the\
    \ package is a binary distribution package, pip installs it directly based on\
    \ the metadata files embedded in it. By default, pip installs third-party packages\
    \ into the site-packages\n\n<span id=\"page-2-1\"></span>![](_page_2_Figure_1.jpeg)\n\
    \nFigure 1: Module conflict example. Example (a) illustrates the overwriting module\
    \ when downloading the package. Example (b) illustrates importing confusion when\
    \ running the code.\n\nfolder unless the user specifies a different folder using\
    \ the target (-t) argument.\n\nAfter installing packages, users can import modules\
    \ from them in their Python codes. The import process consists of two steps: first,\
    \ the user declares the name of the module to be imported (e.g., import bs4).\
    \ Second, the Python interpreter searches for the module when it executes the\
    \ import statement. The Python interpreter first looks in the module cache that\
    \ records the modules already imported. If not found in the cache, the interpreter\
    \ searches in the sys.path order, which is a list of directories where Python\
    \ looks for modules. Once the interpreter finds a module with the same name as\
    \ the import statement, it stops the search and returns the module.\n\nPython\
    \ dependency management. Python developers can specify the dependencies of their\
    \ projects in requirement.txt and use the command pip install -r requirement.txt\
    \ to install them. Alternatively, developers can package and upload their projects\
    \ to PyPI after declaring the dependencies in a configuration file, such as setup.py\
    \ or pyproject.toml. The configuration file is compiled to generate metadata files,\
    \ which contain the dependency information. The dependency information is stored\
    \ in the requires.txt file of the source distribution package or in the METADATA\
    \ file of the binary distribution package.\n\nPython supports various types of\
    \ dependencies, such as build, install, extra, and test dependencies. Each type\
    \ can also be conditional on the local environment so that pip will install them\
    \ selectively. Build dependencies and test dependencies are typically used only\
    \ during development and testing, and they do not affect the installation process.\
    \ Therefore, in this paper, we only consider install dependencies and extra dependencies,\
    \ which are the dependencies required for a successful installation of a package.\n\
    \nModule conflict examples. Here we give two examples of how module conflicts\
    \ can affect Python projects. Figure [1\\(](#page-2-1)a) shows a module conflict\
    \ example that causes the module overwriting\n\nthreat. More specifically, the\
    \ project ysr-monitor@0.1.5 [\\[50\\]](#page-11-16) has two dependencies board@1.0\
    \ [\\[5\\]](#page-10-5) and adafruit-blinka@8.15.2 [\\[1\\]](#page-10-6), which\
    \ both contain a module named board.py. When pip installs these packages, it will\
    \ overwrite the board.py module from the first package with the one from the second\
    \ package. This can lead to errors that are hard to debug, especially in CI/CD\
    \ environments. To fix this issue, the developer needs to manually find the overwritten\
    \ module and reinstall the corresponding package. However, this process is complicated\
    \ and may corrupt the local environment further. Figure [1\\(](#page-2-1)b) shows\
    \ another example of importing a wrong module. The packages jwt@1.3.1 and pyjwt@2.6.0\
    \ are installed in the two different targets (e.g., one in the system site-packages\
    \ folder and one in the virtualenv [\\[41\\]](#page-11-17) site-packages folder).\
    \ However, they both have the jwt/exceptions.py module, which will conflict when\
    \ imported. The Python interpreter will import the module based on the order of\
    \ the folders in the sys.path list, which may not be the intended one. To fix\
    \ this issue, the developer needs to either change the order of the folders in\
    \ the sys.path list or use absolute paths to import the modules, which is inconvenient\
    \ and error-prone.\n\n#### <span id=\"page-2-0\"></span>3 MODULEGUARD DESIGN\n\
    \nWe present ModuleGuard, a tool that helps us to investigate the impacts of module\
    \ conflicts in the Python ecosystem. Figure [2](#page-3-0) illustrates the framework\
    \ of our work, which comprises two main components. The first component is InstSimulator,\
    \ which extracts module information from various configuration files and simulates\
    \ the installation process without actually installing the packages. The second\
    \ component is EnvResolution, which resolves more accurate dependency graphs of\
    \ Python packages by considering the local environment and the extra dependencies.\n\
    \n# 3.1 InstSimulator: Installation-free Module Extraction\n\nChallenges. To conduct\
    \ a large-scale study of the Python ecosystem, we need to obtain the module information\
    \ of Python packages. However, this is not a trivial task, as it faces several\
    \ challenges. First, PyPI has several types of packages, and each type has its\
    \ own configuration files and formats. However, there is no comprehensive documentation\
    \ that specifies which files and parameters are related to module information\
    \ and how to parse them. Second, the module information can change before and\
    \ after the package installation. As shown in Figure [3,](#page-3-1) the package\
    \ pugs@0.0.1 has different modules before and after the installation. This is\
    \ because the installation process is controlled by configuration files (e.g.,\
    \ setup.py), which can add, remove, or rename modules. For example, if namespace\\\
    _packages = ['namespace\\_pugs'] is defined in the setup.py, it will remove the\
    \ namespace\\_pugs/\\_\\_init\\_\\_.py module and add a new nspkg.pth module.\n\
    \nTo address these challenges, we propose InstSimulator, which has two main functionalities:\
    \ (1) To solve the first challenge, we systematically study all module-related\
    \ files and parse the raw module data from different types of configuration and\
    \ metadata files, and (2) to solve the second challenge, we leverage a novel approach\
    \ to simulate the installation process to obtain the accurate module information\
    \ without installing the packages.\n\n<span id=\"page-3-0\"></span>![](_page_3_Figure_2.jpeg)\n\
    \nFigure 2: Overview of our work.\n\nTable 1: Module and dependency-related data.\n\
    \n<span id=\"page-3-2\"></span>\n\n|                        | File           |\
    \ Module-Related Data    | Dependency-Related Data |  |\n|------------------------|----------------|------------------------|-------------------------|--|\n\
    | Files<br>Metadata      | EGG-INFO*      | top_level.txt          | requires.txt\
    \            |  |\n|                        |                | SOURCES.txt   \
    \         |                         |  |\n|                        |         \
    \       | top_level.txt          |                         |  |\n|           \
    \             | egg-info*      | namespace_packages.txt | requires.txt       \
    \     |  |\n|                        |                | SOURCES.txt          \
    \  |                         |  |\n|                        |                |\
    \ top_level.txt          |                         |  |\n|                   \
    \     | dist-info*     | namespace_packages.txt | METADATA                |  |\n\
    |                        |                | RECORD                 |         \
    \                |  |\n| Files<br>Configuration | setup.py       | py_modules\
    \             |                         |  |\n|                        |     \
    \           | packages               | install_requires        |  |\n|       \
    \                 |                | package_dir            | extras_require \
    \         |  |\n|                        |                | namespace_packages\
    \     |                         |  |\n|                        |             \
    \   | py_modules             |                         |  |\n|               \
    \         | setup.cfg      | packages               | install_requires       \
    \ |  |\n|                        |                | package_dir            | extras_require\
    \          |  |\n|                        |                | namespace_packages\
    \     |                         |  |\n|                        |             \
    \   | py-modules             |                         |  |\n|               \
    \         | pyproject.toml | packages               | dependencies           \
    \ |  |\n|                        |                | package-dir            | optional-dependencies\
    \   |  |\n|                        |                |                        |\
    \                         |  |\n\n\\* The EGG-INFO is in \"egg\" type packages.\
    \ The egg-info is in \"tar.gz\" type packages. The dist-info is in \"whl\" type\
    \ packages.\n\n<span id=\"page-3-1\"></span>![](_page_3_Figure_7.jpeg)\n\n####\
    \ Figure 3: Module paths change after installation. Specific parameters in the\
    \ configuration file control these behaviors.\n\nRaw module data extraction. To\
    \ extract the raw module data from Python packages, we first identify the types\
    \ and formats of files that contain module information. Then, we implement different\
    \ parsers for each type of file.\n\nWe conduct a systematic study of the packaging,\
    \ compilation, and installation process of Python packages. We use differential\
    \ testing to modify different parameters in the configuration files and observe\
    \ the changes in the metadata files and the module information. Based on these\
    \ results, we combine the official Python [\\[15\\]](#page-11-18) and pip [\\\
    [29\\]](#page-11-5) documentation to infer the function of different parameters.\
    \ Table [1](#page-3-2) shows the result of our study. Python packages have three\
    \ kinds of metadata files: egg-info, EGG-INFO, and dist-info. They correspond\
    \ to the .tar.gz, .egg, and .whl distribution packages, respectively. Moreover,\
    \ Python packages have three types of configuration files: setup.py, setup.cfg,\
    \ and pyproject.toml. The setup.py is an executable script file, while the other\
    \ two are formatted configuration files. They can all define module information\
    \ but use different formats and parameters.\n\nThe InstSimulator implements different\
    \ parsers for each type of configuration and metadata file. Specifically, InstSimulator\
    \ converts text-type files into a list, parses formatted configuration files with\
    \ a format-specific parser, and for setup.py, the executable script file, InstSimulator\
    \ uses AST and data flow analysis to extract module configuration parameters based\
    \ on a PyCD tool proposed in [\\[6\\]](#page-10-1). These parsers can extract\
    \ the relevant information from the files and store them in a structured way.\
    \ In this way, InstSimulator can avoid decompressing the package locally by reading\
    \ only a few configuration files and metadata files from memory, which saves time\
    \ and space.\n\nInstallation-free module simulation. We propose a novel technique\
    \ named installation-free module simulation to convert raw module data into module\
    \ information after installation. This technique consists of three steps: (1)\
    \ InstSimulator first takes the file structure in the compressed package and turns\
    \ it into a virtual file tree. (2) It then translates each raw data semantics\
    \ into operations that add, delete, and search for nodes in the virtual file tree.\
    \ (3) It employs the DFS algorithm to traverse the file tree and obtain all module\
    \ paths.\n\nFor example, suppose a package has the raw data packages = [pugs\\\
    _lib, namespace\\_pugs] and package\\_dir = pugs\\_lib : pugs. The packages data\
    \ is a list of folder names after installation, and the package\\_dir data is\
    \ a mapping of folder names before and after installation (pugs\\_lib is the folder\
    \ name of the pugs after installation). If there is no mapping in package\\_dir,\
    \ the folder name will not change before and after installation. Based on their\
    \ semantics, InstSimulator uses the BFS algorithm to search for the folder names\
    \ (e.g., pugs) before installation recorded in package\\_dir (searching root node\
    \ is the parent node of the setup.py or other configuration files), and changes\
    \ their node names to the names after installation (i.e., pugs\\_lib). Then, it\
    \ deletes all the subtrees except the nodes\n\nrecorded in the packages data.\
    \ After simulating all the raw module data semantics, we can obtain a file tree\
    \ that contains the module information without the installation process. Finally,\
    \ InstSimulator uses the DFS algorithm to traverse the file tree and obtain the\
    \ module paths. Note that each path from the root node to a leaf node within this\
    \ tree corresponds to a module path. We have described the semantics of all the\
    \ parameters and a more detailed code demo in the artifact we release.\n\n# 3.2\
    \ EnvResolution: Environment-aware Dependency Resolution\n\nChallenges. To investigate\
    \ the module conflicts in the Python ecosystem, we need to resolve the dependency\
    \ graphs of over 4.2 million packages. However, it faces the following challenges.\
    \ First, using common static resolution methods to obtain the dependency graphs\
    \ without installation is not very accurate. This is because the Python dependency\
    \ graphs depend on the local environment information, and the dependencies between\
    \ packages are complex due to the extra dependencies. Moreover, previous work\
    \ [\\[17,](#page-11-19) [40,](#page-11-20) [44,](#page-11-10) [46\\]](#page-11-11)\
    \ either lacks up-to-date information or has lower accuracy. They often parse\
    \ dependencies from only a single dimension, such as setup.py or requires.txt,\
    \ resulting in incomplete information. Furthermore, they do not consider the local\
    \ environment-related and extra dependencies, which are common in Python packages\
    \ and can affect the dependency graphs. This leads to inaccurate dependency graphs.\
    \ On the other hand, obtaining accurate dependency graphs using pip requires the\
    \ installation process, which is time-consuming and may fail due to local environment\
    \ incompatibilities.\n\nTo solve these, we present EnvResolution, a local environmentaware\
    \ dependency resolution that supports the local environment and extra dependencies.\
    \ It consists of three steps: (1) multidimensional dependency information extraction,\
    \ (2) local environment information collection, and (3) dependency graph resolution.\n\
    \nMultidimensional dependency information extraction. EnvResolution adopts a multi-dimensional\
    \ approach for extracting direct dependencies from three dimensions: PyPI API\
    \ [\\[12\\]](#page-11-21), dependencies in metadata files, and dependencies in\
    \ configuration files. Similar to the approach in [§3.1,](#page-3-1) we first\
    \ classify the dependencyrelated information from the metadata and configuration\
    \ files, as shown in Table [1.](#page-3-2) In this step, we will save both the\
    \ direct dependencies with their environmental conditions and the optional extra\
    \ dependencies of the Python project. Then we convert the dependency information\
    \ parsed from different files into a unified format for subsequent parsing.\n\n\
    Local environment information collection. For the local environment, EnvResolution\
    \ collects 11 types of environmental information [\\[14\\]](#page-11-22) that\
    \ may affect the dependency graphs, such as python\\_version, os\\_name, and so\
    \ on. These environment variables and their values are stored in a global dictionary\
    \ when resolving dependencies (e.g., {(python\\_version, 3.10), (os\\_name, posix),\
    \ (sys\\_platform, linux), ...}).\n\nDependency resolution. EnvResolution uses\
    \ the resolvelib [\\[37\\]](#page-11-23) framework as the core backtracking resolution\
    \ algorithm. To improve the efficiency and accuracy of dependency graph resolution,\
    \ EnvResolution implements the following optimizations. First, like\n\nTable 2:\
    \ Evaluation of ModuleGuard.\n\n<span id=\"page-4-1\"></span>\n\n| Benchmark \
    \    | Dataset | Correct | Miss | Excess | Error | Accuracy |\n|---------------|---------|---------|------|--------|-------|----------|\n\
    |               | Data1   | 4,045   | 152  | 28     | 7     | 95.58%   |\n| InstSimulator\
    \ | Data2   | 3,834   | 116  | 37     | 2     | 96.11%   |\n| EnvResolution |\
    \ Data1   | 4,177   | 41   | 8      | 13    | 98.70%   |\n| (Node)        | Data2\
    \   | 3,795   | 93   | 30     | 20    | 96.37%   |\n| EnvResolution | Data1  \
    \ | 4,133   | 46   | 11     | 47    | 97.66%   |\n| (Edge)        | Data2   |\
    \ 3,748   | 107  | 40     | 33    | 95.18%   |\n\n\\* Node: evaluate nodes in\
    \ dependency graph only.\n\n\\* Edge: evaluate nodes and edges in the dependency\
    \ graph.\n\n\\* Accuracy: correct/total\n\nprevious work [\\[6,](#page-10-1) [44,](#page-11-10)\
    \ [46\\]](#page-11-11), EnvResolution also employs a local knowledge base. However,\
    \ EnvResolution adopts multi-dimensional dependency information extraction, which\
    \ can obtain more comprehensive dependency information than previous work, including\
    \ local environmental conditions and extra dependencies.\n\nSecond, EnvResolution\
    \ supports resolving extra dependencies and local environment dependencies. More\
    \ specifically, during dependency resolution, an extra dependency will add an\
    \ entry to the environment variable dictionary. For example, dependency pandas[compression]\
    \ will add compression to the environmental variable dictionary. After that, we\
    \ can treat an extra dependency as a special local environmental dependency. When\
    \ resolving each direct dependency of packages, EnvResolution checks whether the\
    \ dependency's environmental conditions match the values in the environmental\
    \ variable dictionary. A dependency will be dropped if the value in the dictionary\
    \ does not meet the condition. For instance, dependency numpy>= 1.21.0; (python\\\
    _version, >= 3.11) will be dropped if the python version is 3.10 and does not\
    \ meet the condition >=3.11.\n\nThird, EnvResolution adopts a priority policy\
    \ when resolving dependencies for efficiency. This is based on our observation\
    \ that the order of dependencies does not affect the result of the resolution,\
    \ but it does affect the time to backtrack the resolution algorithm. A good order\
    \ can reduce the number of backtrack times, thus improving the parsing efficiency.\
    \ Therefore, EnvResolution sorts the dependencies according to the following rules\
    \ in each recursion: resolving the pinned version dependencies first, then the\
    \ dependencies with a scope constraint, and finally the dependencies with no constraint.\
    \ Moreover, dependencies that are close to the root node are always resolved before\
    \ dependencies that are far from the root node. In this way, EnvResolution can\
    \ significantly reduce the number of backtracking times and thus improve the resolution\
    \ efficiency.\n\n#### <span id=\"page-4-0\"></span>4 MODULEGUARD EVALUATION\n\n\
    Due to the lack of established ground truth for comparison, we carefully construct\
    \ a benchmark to evaluate the two aspects of ModuleGuard, respectively. We collect\
    \ datasets from the two following sources:\n\n• Dataset 1. We select the top 3,000\
    \ projects from Libraries.io [\\[25\\]](#page-11-24) and PyPI Downloads Table\
    \ [\\[18\\]](#page-11-25) for six months from August 2022 to February 2023, respectively\
    \ and we apply a de-weighting process to the two sets to reduce the bias.\n\n\
    • Dataset 2. We randomly select 5000 projects from the total list of the PyPI\
    \ package.\n\nFor each dataset, we select the latest version and install it using\
    \ pip for each project. We use the module relative paths and the dependency graphs\
    \ obtained after the installation as the ground truth for comparison. There are\
    \ two main reasons for installation failure: First, the local environment is not\
    \ compatible with the package, e.g. Python2 package cannot be installed in the\
    \ Python3 environment; Second, an error occurred while running the installation\
    \ script, causing the installation process to exit. Finally, we get 4,232 and\
    \ 3,989 projects in the two datasets.\n\nEvaluate metrics. We define four metrics\
    \ to evaluate the accuracy of ModuleGuard. (1) Correct. The modules or dependency\
    \ graphs resolved by ModuleGuard are totally consistent with the ground truth.\
    \ (2) Miss. Some modules or some elements in dependency graphs of the ground truth\
    \ do not exist in our results. (3) Excess. Some modules or some elements in dependency\
    \ graphs resolved by ModuleGuard do not exist in the ground truth. (4) Error.\
    \ Other cases.\n\nExperimental setup. To obtain the module paths after installation,\
    \ we use pip install XXX -t target –no-dependencies to install packages. This\
    \ command implies that the latest version package will be installed in the target\
    \ folder and no dependencies will be installed. Moreover, we only considered modules\
    \ with .py extensions, so the data files (e.g. pictures, tables) included in the\
    \ packages will be ignored.\n\nTo obtain the dependency graphs, we also use pip\
    \ installation to get the ground truth. We add the following settings to obtain\
    \ the exact dependency graph. First, pip installation process depends on the repository\
    \ status of the remote, which is updated in real-time. In contrast, our local\
    \ knowledge base is updated on a daily basis. To address this gap, we mirrored\
    \ approximately 13TB of PyPI packages locally with bandersnatch [\\[4\\]](#page-10-7)\
    \ tool and we use this local mirror during pip installations (i.e. pip install\
    \ -i localhost/simple). Second, in order to obtain pip's dependency resolution\
    \ results, we hook pip's dependency resolve function and write the dependency\
    \ graph to files.\n\nInstSimulator result. Table [2](#page-4-1) shows the results\
    \ of InstSimulator evaluation benchmark. The results show that InstSimulator has\
    \ the ability to extract module information with 95.58% and 96.11% accuracy on\
    \ different datasets. In addition, the table shows that InstSimulator technique\
    \ has 152 (3.59%) and 116 (2.91%) Misses on the two datasets, respectively. This\
    \ is mainly because InstSimulator uses AST static analysis method parsing the\
    \ setup.py install script, which has limitations on parsing syntactically complex\
    \ install scripts correctly. Moreover, a given version of a Python project has\
    \ multiple packages with slightly different modules. However, the InstSimulator\
    \ selects only one of these packages to parse, which might differ from the package\
    \ actually installed. For instance, the 0.4.4 version of the jaxlib project has\
    \ 12 packages. Overall, ModuleGuard is able to achieve over 95% accuracy in module\
    \ extraction. It meets our requirement of extracting the whole ecosystem packages'\
    \ modules.\n\nEnvResolution result. We considered both node-level and graph-level\
    \ benchmarks to evaluate the accuracy of the EnvResolution technique in ModuleGuard.\
    \ The node-level benchmark focuses\n\nsolely on the individual nodes within the\
    \ graph, without considering the edges between them. It evaluates the ability\
    \ to extract direct dependencies. In contrast, the graph-level benchmark takes\
    \ into account both the nodes and edges present in the graph. It evaluates the\
    \ ability to resolve dependency graphs.\n\nTable [2](#page-4-1) shows the results\
    \ of our evaluation. The results show that the accuracy of EnvResolution ranges\
    \ from 95.18% to 98.70% where the edge accuracy is lower than that of node. What's\
    \ more, we manually reviewed projects that were unable to resolve and identified\
    \ two primary causes for their failure. First, we are unable to process complex\
    \ setup.py configuration files. For example, the setup.py file of the project\
    \ ta retrieves dependencies from files within the package, however, ModuleGuard\
    \ does not unpack the package to optimize extraction speed. Second, we read dependencies\
    \ from metadata files generated by maintainers' local environments, which may\
    \ deviate from our experimental environment. For instance, project fortnitepy\
    \ has three direct dependencies in its metadata, whereas pip only extracts two\
    \ during our local installation.\n\nOverall, the results demonstrate that although\
    \ EnvResolution has some limitations in extracting dependencies information, it\
    \ is capable of handling large-scale packages quickly with an acceptable error.\n\
    \n#### <span id=\"page-5-0\"></span>5 LARGE-SCALE STUDY\n\nSince the MC problem\
    \ has not been studied systematically in Python language in existing work, we\
    \ empirically study the MC issues from GitHub and Stack Overflow and classify\
    \ them into three patterns. We then used ModuleGuard to evaluate all 4.2 million\
    \ PyPI packages and 3,711 high-star projects collected from GitHub for the presence\
    \ of MCs and their potential impacts. In summary, we propose the following research\
    \ questions:\n\n- RQ1 (Issue Study). What are the common types of module conflict\
    \ issues? What potential threats might they have?\n- RQ2 (PyPI Packages). How\
    \ many of all PyPI packages have MC effects?\n- RQ3 (GitHub Projects). How many\
    \ popular projects on GitHub are affected by MC, and what are their characteristics?\n\
    \n#### 5.1 RQ1: Issue Study\n\n5.1.1 Data Collection. We collect 97 MC issues\
    \ in total and we search them in two steps. First, we combined two sets of keywords—\
    \ (module OR name) AND (clash OR conflict) to search for MC issues on GitHub and\
    \ added is:issue and language:python options. Since Github can only show the first\
    \ 100 pages of search results for each combination search result, we obtained\
    \ the search results in order of best match and collected 4,000 issues. Second,\
    \ for the 4,000 issues, the three co-authors manually reviewed the descriptions\
    \ and bug reports in the issues and finally filtered out 55 issues that were strongly\
    \ related to MC issues. We also notice that some maintainers or reporters would\
    \ cite related issues in their comments. As a result, we searched for other issues\
    \ mentioned in these 55 issues using the snowballing technique [\\[21\\]](#page-11-26)\
    \ and checked them manually. Finally, we collected 78 MC issues from GitHub. The\
    \ keyword \"Python module name (clash OR conflict)\" was used to search on StackOverflow.\
    \ We manually review the top 200 most relevant issues that include\n\nanswers.\
    \ Ultimately, a total of 19 issues related to MC are collected from Stackoverflow.\n\
    \n5.1.2 Module Conflict Types. After studying the collected 97 MC issues, we observe\
    \ that module conflicts can occur in three situations after packaging the project\
    \ and uploading it to the PyPI or Github. First, modules of the project may conflict\
    \ with the built-in standard library modules, causing module-to-Lib conflict.\
    \ Second, As a TPL, its modules can conflict with the other TPLs (not relevant\
    \ to this project), leading to module-to-TPL conflict. In addition, projects that\
    \ declare direct dependencies in their configuration files may have module conflicts\
    \ within the dependency graph (those TPLs are relevant), resulting in module-in-Dep\
    \ conflicts.\n\nIn the following, we give each type of conflict a formal definition\
    \ and discuss them in detail with illustrative issue examples. To ease the discussion,\
    \ we first give some grammar below:\n\n: the set of all packages on PyPI\n\n-\
    \ : ∈ ,representing a specific package\n- : { | is a module after installing package\
    \ }\n\n : { | is a standard library module}\n\n() : the dependency graph of the\
    \ package\n\n1 conflict ←−−−−→ <sup>2</sup> : <sup>1</sup> and <sup>2</sup> have\
    \ the same name or same path\n\nModule-to-Lib conflict. Conflicts can occur between\
    \ the project's modules and standard library (Lib) modules (21/97=21.65%). Suppose\
    \ there are two modules. One module belongs to package and the other is a library\
    \ module and they have conflicts. In that case, we consider the packages to have\
    \ a module-to-Lib conflict. We formulate it as the following:\n\n∃ ∈ ,\n\n$$m\
    \ \\in M\\_{\\mathfrak{p}} \\land m\\_l \\in M\\_{Lib} \\land m \\xleftarrow{\\\
    text{conflict}} m\\_l$$\n\nFor example, the #14 issue [\\[48\\]](#page-11-27)\
    \ of the python-hgijson. The package python-hgijson@1.5.0 has a json module, and\
    \ it conflicts with the standard library json module, resulting in module-to-Lib\
    \ conflict.\n\nModule-to-TPL conflict. Modules will also conflict with the modules\
    \ of the other unrelated third-party packages (64/97=65.98%). Suppose there are\
    \ two different modules. One module belongs to package and the other module ′\
    \ belongs to another unrelated package ′ such that the two module conflicts with\
    \ each other, we consider the package and ′ both have a module-to-TPL conflict.\
    \ We formulate module-to-TPL conflict as the following:\n\n$$\n\\exists \\text{\
    \ } p, p' \\in P \\land p \\neq p',\n$$\n\n$$m \\in M\\_{\\mathfrak{b}} \\land\
    \ m' \\in M\\_{\\mathfrak{b}'} \\land m \\xleftarrow{\\text{conflect}} m'$$\n\n\
    For example, the #3 issue [\\[28\\]](#page-11-28) shows that the python-slugify@8.0.0\
    \ and the awesome-slugify@1.6.5 packages both have a slugify conflicting module\
    \ and they have a conflict with each other if they installed together, so the\
    \ two packages have a module-to-TPL conflict.\n\nModule-in-Dep conflict. Conflicts\
    \ can occur within the project's dependency graphs (12/97=12.37%). If there are\
    \ two packages and ′ within a Dependency Graph of the root package ( can be one\n\
    \n<span id=\"page-6-0\"></span>Table 3: Statistics of MC types and their potential\
    \ threats.\n\n| MC types           | Modules overwriting | Import confusion |\n\
    |--------------------|---------------------|------------------|\n| Module-to-Lib\
    \ (21) | -                   | ✓                |\n| Module-to-TPL (64) | ✓  \
    \                 | ✓                |\n| Module-in-Dep (12) | ✓             \
    \      | -                |\n\nof or ′ , or it can be another package), a module\
    \ within package and a module ′ within package ′ such that they conflict with\
    \ each other, we denote the packages has a module-in-Dep conflict. We formulate\
    \ it as the following:\n\n$$\\begin{aligned} \\Xi \\left( \\not p, \\not p' \\\
    right) &\\subseteq DG(r) \\land p \\neq p',\\\\ m &\\in M\\_{\\mathfrak{d}} \\\
    land m' \\in M\\_{\\mathfrak{d}'} \\land m \\xleftarrow{\\text{conflict}} m' \\\
    end{aligned}$$\n\nFor example, the #44 issue [\\[35\\]](#page-11-29) of theemoca.\
    \ The package emoca@1.0 has opencv-python-headless@4.5.5 and opencv-python@4.5.5\
    \ in its dependency graph, and they both have a cv2 module, so the root package\
    \ emoca@1.0 has a module-in-Dep conflict.\n\n5.1.3 Module Conflict Threats. Based\
    \ on the description of issues, we summarize that the Python ecosystem suffers\
    \ from two shortcomings in code management. First, pip installs TPL modules into\
    \ the site-packages folder by default and does not isolate packages from each\
    \ other. This means that different packages, including their direct and indirect\
    \ dependencies, are mixed in the same directory. As a result, different modules\
    \ from different TPLs would conflict with each other and will cause modules overwriting\
    \ threats. Second, Python provides a more flexible code management mechanism,\
    \ allowing the import of modules (with access rights) from anywhere in the system,\
    \ including standard libraries, TPL modules, and the project's own modules. However,\
    \ they use the same statement for importing and do not differentiate between them.\
    \ The Python interpreter searches for modules using the first-match principle.\
    \ Therefore, conflicts can occur between modules that have the same module path\
    \ but are installed in different locations and will lead to importing confusion\
    \ threats. Furthermore, these two flaws pose threats that will have potential\
    \ impacts on the installation, upgrade, and importing of software packages. Table\
    \ [3](#page-6-0) illustrates statistics on the different types of module conflicts\
    \ that may have threats on the corresponding stages. In the following, we will\
    \ introduce them in detail with examples.\n\nThreat 1 (Modules overwriting). Module\
    \ overwriting is a serious threat to the integrity and functionality of Python\
    \ projects, as it may cause unexpected errors or behaviors. Module overwriting\
    \ occurs when two modules with the same relative module path are installed into\
    \ the same directory, resulting in one module being overwritten by another. It\
    \ can be triggered by two types of module conflicts: module-to-TPL conflict and\
    \ module-in-Dep conflict.\n\nModule-to-TPL conflict refers to the situation where\
    \ two packages have conflicting modules. This can happen when pip installs TPL\
    \ modules into the site-packages folder by default and it does not isolate packages\
    \ from each other. For instance, in issue #4625 [\\[32\\]](#page-11-30) of the\
    \ project pypa/pip, the developer installs both pyjwt@1.5 and jwt@0.5.2, which\
    \ have conflicts on the module jwt/exceptions.py. The later installed module will\
    \ overwrite the first installed module when two conflicting modules are installed\
    \ simultaneously.\n\n′\n\nMoreover, module-to-TPL conflict can also occur in Windows\
    \ systems due to case insensitivity of paths. For example, in issue #156 [\\[31\\\
    ]](#page-11-31) of the project pycrypto, the developer installs the crypto (lowercase)\
    \ module first, and then installs pycrypto, which has the Crypto (upper case)\
    \ module name. However, since the crypto folder already exists locally, pip cannot\
    \ create the Crypto (upper case) folder and instead installs all modules under\
    \ the pre-existing crypto (lowercase) folder. Consequently, this process overwrites\
    \ crypto's modules and breaks the project's functionality.\n\nModule-in-Dep conflict\
    \ refers to the situation where a project and its dependencies have conflicting\
    \ modules. The conflict can cause module overwriting during the installation.\
    \ For example, in issue #841[\\[2\\]](#page-10-8) of the project Albumentations,\
    \ the project installs both opencv-python (indirect dependency) and opencv-python-headless\
    \ (direct dependency). They have conflicts on the cv2 module and its sub-modules.\
    \ Although the official documentation [\\[13\\]](#page-11-32) states that they\
    \ cannot be installed simultaneously, developers are not aware of this restriction\
    \ as indirect dependencies are a black box for them.\n\nFurthermore, module overwriting\
    \ can also affect package upgrades, as pip's update process may cause module conflicts\
    \ during installation or uninstallation. For example, in issue #8509 [\\[33\\\
    ]](#page-11-33), the package ansible@2.9.10 misses some files after upgrading\
    \ due to modules being overwritten during the update process. The update process\
    \ is as follows: first, pip installs the package's dependencies (where module\
    \ overwrites may occur), then it uninstalls the old version of the package (possibly\
    \ uninstalling newly installed modules that have already been overwritten), and\
    \ finally it installs the new version of the package (package integrity is compromised).\n\
    \nThreat 2 (Importing confusion). Conflicts between modules and the standard library\
    \ (module-to-Lib) or third-party libraries (module-to-TPL) pose a potential threat\
    \ of importing confusion. For module-to-Lib conflicts, the standard library modules\
    \ are stored separately and cannot be overwritten when downloading a package.\
    \ However, if a module has the same name as a standard library module, it can\
    \ confuse the interpreter and cause it to import the wrong module. For example,\
    \ the project FibexConverter [\\[23\\]](#page-11-34) has a module named parser.py,\
    \ which conflicts with the standard library module parser. This leads to an issue\
    \ where the program imports the parser module from the standard library instead\
    \ of the parser.py module from the project. This is because Python's import mechanism\
    \ first searches for modules already imported in sys.modules, which contains a\
    \ cache of modules pre-recorded when the Python interpreter starts up, such as\
    \ os, abc, etc. As a result, modules with names identical to these standard library\
    \ modules are not properly imported.\n\nFor module-to-TPL conflicts, Python searches\
    \ for modules in the order of the paths in sys.path and stops at the first match\
    \ it finds. When conflicting modules are downloaded and located in different locations,\
    \ this requires the developer to be very experienced and carefully set the order\
    \ of sys.path to handle conflicts. Note that while the namespace package handles\
    \ modules overwriting, it does not address the importing confusion threats caused\
    \ by the import prioritization. Moreover, Python also supports various ways to\
    \ install packages, which often have different default paths. For example, one\
    \ can use apt-get to install packages in /usr/, pip to install packages in site-packages/,\
    \ or other tools such as conda [\\[8\\]](#page-11-35)\n\nTable 4: Top 10 conflict\
    \ modules in packages.\n\n<span id=\"page-7-0\"></span>\n\n| Module paths    \
    \                      | # of latest pkgs | # of all pkgs |\n|---------------------------------------|------------------|---------------|\n\
    | src/__init__.py                       | 1,157            | 8,777         |\n\
    | __init__.py                           | 1,083            | 4,421         |\n\
    | utils/__init__.py                     | 410              | 3,899         |\n\
    | distributions/__init__.py             | 404              | 448           |\n\
    | distributions/Generaldistribution.py  | 394              | 431           |\n\
    | distributions/Gaussiandistribution.py | 394              | 431           |\n\
    | distributions/Binomialdistribution.py | 393              | 428           |\n\
    | client/__init__.py                    | 367              | 1,142         |\n\
    | scripts/__init__.py                   | 363              | 5,336         |\n\
    | server/__init__.py                    | 360              | 796           |\n\
    \nand poetry [\\[30\\]](#page-11-36) that have their own default installation\
    \ paths. This greatly increases the threat of importing confusion.\n\n#### 5.2\
    \ RQ2: PyPI Packages Study\n\nWe use ModuleGuard to conduct a large-scale study\
    \ of module conflicts (MCs) in the PyPI ecosystem. We study three types of MC\
    \ patterns for all 4.2 million PyPI packages as of March 2023. For module-to-TPL\
    \ conflict, we only consider the latest version packages for each project as of\
    \ March 2023, since different versions of the same project cannot coexist in a\
    \ local environment and pip will install the latest version by default unless\
    \ specified constraints otherwise. We identify packages that have module conflicts,\
    \ and make the assumption that these packages will be installed at the same time.\
    \ For module-to-Lib conflict, we first collect 199 standard library module names\
    \ from the Python official documentation [\\[16\\]](#page-11-37). Then we analyze\
    \ the module names used by all the packages in the ecosystem. It's worth noting\
    \ that we cannot know the order of sys.path or the standard library in the users'\
    \ environment. Therefore, we also assume that the users have 199 standard libraries\
    \ available locally, all of which are loaded into the cache. For modulein-Dep\
    \ conflict, we consider all version packages for each project and resolve their\
    \ dependency graphs with EnvResolution. For the nodes in the resolved dependency\
    \ graphs, we check whether their modules have conflicts.\n\nWe extract 177,216,363\
    \ modules and 27,678,668 direct dependencies for 4,223,950 packages from PyPI\
    \ as of March 2023 and resolve 4,223,950 dependency graphs. This includes 424,823\
    \ latest version packages with 5,419,306 modules.\n\nModule-to-TPL conflict. We\
    \ use the latest version packages of 424,408 projects as of 2023 March to study\
    \ module-to-TPL conflicts. We find that 91,134 (21.45%) packages have module-to-TPL\
    \ conflicts, affecting 386,595 (7.13% out of 5,419,306) module paths. These packages\
    \ may have module overwriting or importing confusion threats depending on whether\
    \ they are installed in the same or different locations. Moreover, 27,851 (6.56%)\
    \ packages may have an overwriting impact in a Windows environment, involving\
    \ 3,517 module paths.\n\nFindings. We observe that developers often package redundant\
    \ modules that are not needed for runtime, such as testing modules (e.g., 41,095\
    \ packages have test(s)/\\_\\_init\\_\\_.py,) and example modules (e.g., 14,877\
    \ packages have example(s)/\\_\\_init\\_\\_.py). These modules are only for the\
    \ development process and are more\n\n<span id=\"page-8-0\"></span>![](_page_8_Figure_1.jpeg)\n\
    \nFigure 4: Statistics of the number of packages released and the number of conflict\
    \ packages in each year.\n\nerror-prone and confused [\\[34\\]](#page-11-38).\
    \ They not only increase the storage pressure on the PyPI server, but also slow\
    \ down the efficiency of pip resolution due to the backtracking algorithm.\n\n\
    Furthermore, we identify the top 10 most common module paths in software packages\
    \ as shown in Table [4.](#page-7-0) There are over 1000 packages that include\
    \ src/\\_\\_init\\_\\_.py and \\_\\_init\\_\\_.py, which are the result of the\
    \ misconfiguration of the src-layout and flat-layout format packages [\\[34\\\
    ]](#page-11-38), respectively. These two modules are stored in the project root\
    \ directory without any meaning or functionality.\n\nAdditionally, we find that\
    \ packages with conflicting modules often have similar names, which reflect their\
    \ functionality. For example, out of the 404 packages that have the distributions/\\\
    _\\_init\\_\\_.py module, 290 contain the substring 'distribution' in their project\
    \ name. This means that conflicting packages are more likely to be installed together,\
    \ because they most likely belong to the same domain or have the same functionality.\n\
    \nIn addition, through exploring related GitHub Issues, we find that project maintainers\
    \ who have the same module name are often reluctant to change their own module\
    \ name. Changing the module name will not only break forward compatibility, but\
    \ also the workload is very large, and increase the learning cost of users when\
    \ used.\n\nModule-to-Lib conflict. We analyzed the entire ecosystem of 4.2 million\
    \ packages and found that 345,068 (8.17%) packages have module-to-Lib conflicts,\
    \ which may cause import errors at runtime. Moreover, we discovered that 182 (91.96%)\
    \ out of 199 standard library modules are affected by these conflicts. The most\
    \ frequently used standard library module names that conflict with third-party\
    \ packages are types, io, and logging, which are used by 69,940, 47,214, and 35,694\
    \ packages, respectively. These results suggest that developers should be careful\
    \ when choosing module names for their packages and avoid using names that already\
    \ exist in the standard library.\n\nFindings. We also observed a gap between the\
    \ local development and the deployment environments that can lead to import confusion\
    \ issues. When a program is developed locally, the current working directory has\
    \ a higher priority than the standard library modules in sys.path. However, when\
    \ the program is packaged and\n\ninstalled by others from PyPI, the site-packages\
    \ directory has a lower priority than the standard library modules in sys.path.\
    \ This gap can result in unexpected runtime errors due to importing wrong modules.\
    \ To address this problem, developers have two options: changing the module name\
    \ or using relative path import. However, the two solutions may break backward\
    \ compatibility and reduce the readability or portability of the code.\n\nIn addition,\
    \ we notice that the number of Module-to-Lib conflict packages increased each\
    \ year. To further illustrate this trend, we plot the number and percentage of\
    \ Module-to-Lib conflict packages for each year from 2005 to 2022. As shown in\
    \ the Figure [4,](#page-8-0) both the number and percentage increased steadily\
    \ over the years, indicating that this threat became more prevalent and severe\
    \ as the Python ecosystem grew and the extensions to the standard library. This\
    \ suggests that developers do not pay enough attention to the potential conflicts\
    \ with the standard library modules when naming their modules, or they are unaware\
    \ of the existing or newly added standard library modules that might conflict\
    \ with their modules.\n\nModule-in-Dep conflict. We conducted an empirical study\
    \ on the entire ecosystem of 4.2 million packages and detected 129,840 (3.07%)\
    \ packages with module-in-Dep conflicts, involving 11,666 projects. we also find\
    \ 38,371 packages involving 4,516 projects that exhibit different module file\
    \ contents but the same paths, which may cause functionality errors. Moreover,\
    \ we noticed that some conflicting modules may change their contents after package\
    \ updates, which could introduce new problems in the future. Although these conflicting\
    \ modules may not be invoked at runtime, they do have the effect of module overwriting,\
    \ which compromises the integrity of packages. There is also no guarantee that\
    \ these modules will not be called and used in a future version.\n\nFindings.\
    \ We further analyzed the characteristics of the conflicting packages. First,\
    \ two packages from different maintainers that provide similar functionalities\
    \ often use the same or similar module names. This is because they tend to copy\
    \ from each other, thus avoiding unnecessary duplication of the wheel or convenient\
    \ naming. Second, two packages related by migration often result in a conflict,\
    \ where one package is deprecated and replaced by another package. Third, two\
    \ packages that are different incompatible versions or variants of the same project.\
    \ For example, in the dependency graph of saleor, python-magic-bin is a fork of\
    \ python-magic with a different maintainer; in the dependency graph of riffusion,\
    \ soundfile is a migrated version of pysoundfile; and opencv-python and opencv-python-headless\
    \ are two distributions of opencv for different environments.\n\nWe also observed\
    \ that these conflicts often occurred either in older continuous versions (2,342\
    \ out of 4,516) or in all versions (1,819 out of 4,516) of a project. This indicates\
    \ that some developers or users discovered and resolved some conflicts when they\
    \ encountered functionality issues, while others did not notice or update their\
    \ dependencies. This implies that module-in-Dep conflicts have a certain persistence\
    \ and concealment, which may affect the reliability of Python applications. For\
    \ example, the project aniposelib used opencv-python and opencv-contrib-python\
    \ dependencies prior to version 0.3.7, which was fixed by maintainers in a later\
    \ version due to bugs raised in issue [\\[22\\]](#page-11-39) caused by Module-in-Dep\
    \ conflicts. What's more, such conflicts exist in an average of 6.5 versions.\
    \ Such a large time gap can affect the functionality and maintainability\n\nof\
    \ the project. Therefore, we argue that it is important to detect and prevent\
    \ module-in-Dep conflicts in Python packages to ensure correct functionality.\n\
    \nFrom the time dimension, the number of packages with Modulein-Dep conflicts\
    \ also gradually increases over time, as shown in Figure [4.](#page-8-0) Many\
    \ older packages that didn't have conflicts before are coming back into conflict\
    \ as dependencies are migrated.\n\n#### 5.3 RQ3: GitHub Projects Study\n\nWe select\
    \ popular Python projects from GitHub. We collect the top 3,000 most-starred Python\
    \ projects and 1,187 popular projects from awesome-Python[\\[11\\]](#page-11-40).\
    \ We merge and deduplicate the two datasets and obtain a total of 3,711 projects\
    \ with 93,487 tags. We analyze their dependencies, resolve dependency graphs with\
    \ EnvResolution, and detect module-in-Dep conflicts for them.\n\nWe detect 519\
    \ (13.93%) projects with 10,850 (11.61%) tags that have module overwriting threats.\
    \ The results show that modulein-Dep conflicts are more prevalent in GitHub projects,\
    \ as these projects tend to declare more dependencies than packages on PyPI. Although\
    \ these conflicting modules may not affect the functionality of the program if\
    \ the file contents are unchanged before and after overwriting, they can break\
    \ the integrity of the package in the local environment and cause errors that\
    \ are hard to debug. Moreover, there are 2,569 tags for 108 projects that may\
    \ have functional errors, due to the difference in file contents before and after\
    \ overwriting. Of the 108 projects, 65 are the latest version, while 43 projects\
    \ have fixed module-in-Dep issues in later versions. This means that the module\
    \ conflict problem is latent, with an average of 23 historical versions affected.\
    \ It is often only when a user encounters an error that the maintainer becomes\
    \ aware of the problem and fixes it. We manually analyze the conflicting modules\
    \ in these 65 projects and report 35 issues to the project developers, of which\
    \ 11 projects replied and 12 fixed the MC problems. The others do not respond,\
    \ but since they have the same conflicting modules as the confirmed issues, we\
    \ can assume that they have a real impact.\n\nFindings. We find that module conflicts\
    \ occur more often in the AI field. This is because developers need to introduce\
    \ one of the four opencv-python base packages when adding dependencies, along\
    \ with other related AI projects. However, other related AI projects may also\
    \ introduce other incompatible versions of the base package. These base packages\
    \ are stated in the official documentation [\\[13\\]](#page-11-32) that they cannot\
    \ coexist because they all use the module name of cv2. This behavior is beyond\
    \ the developer's control because they can only control direct dependencies, and\
    \ the indirect dependencies are a black box. Such conflicts result in incompatibility\
    \ between different AI projects when they are used together.\n\nIn addition, we\
    \ find that some developers even include the same functional dependency in the\
    \ direct dependency, and the two dependencies have module conflicts. Talking to\
    \ the developers, they say that adding a dependency when they encountered an error\
    \ could fix a strange error (which was actually caused by module overwriting).\
    \ This means that developers tend to focus more on whether the program can run\
    \ properly, and introduce functionally redundant dependencies, which not only\
    \ increase the complexity of the project, but also increase the difficulty of\
    \ building the project environment. To make matters worse, project issues reveal\
    \ that\n\nmany developers are not aware of module conflicts. They often add or\
    \ remove dependencies after getting an error report to keep the program working.\
    \ Of the 12 latest tags that were fixed, 10 were fixed by removing redundant dependencies.\
    \ Therefore, our work reveals the nature and potential impact of module conflicts,\
    \ and helps them to recognize and correctly declare dependencies to mitigate conflicts\
    \ during the debugging phase.\n\n#### <span id=\"page-9-0\"></span>6 LIMITATIONS\n\
    \nModuleGuard can help developers detect potential module conflict threats during\
    \ the development and packaging phase, thus helping them properly configure packaging\
    \ scripts, but it faces the following threats.\n\nFirst, in terms of detecting\
    \ module-in-Dep conflicts, Module-Guard is responsible for detecting whether there\
    \ are conflict modules in the dependencies declared by the project, which will\
    \ definitely cause module overwriting and destroy the integrity of packages installed\
    \ in the local environment. However, environmental damage does not necessarily\
    \ affect the running of the program, because they may not have been imported or\
    \ the files are empty (e.g., empty \\_\\_init\\_\\_.py file). For the sake of\
    \ efficiency, our work did not take into account the call graph, which is time-consuming.\
    \ But we will analyze it as our future work to optimize ModuleGuard.\n\nSecond,\
    \ when it comes to detecting module-to-Lib conflicts, ModuleGuard doesn't know\
    \ which standard library packages are cached by the user's native runtime. Because\
    \ this involves the Python interpreter running time, Python version updates, etc.,\
    \ we have no way to collect relevant data from users due to privacy reasons. As\
    \ a result, ModuleGuard only collects and detects if the module names declared\
    \ in packages conflict with the names in the standard library as a reminder, and\
    \ we recommend that developers rename these modules that may conflict to prevent\
    \ potential problems.\n\n#### <span id=\"page-9-1\"></span>7 DISCUSSION\n\nWe\
    \ discuss from different perspectives: developers, PyPI maintainers, and future\
    \ works.\n\nDevelopers. For developers, when declaring dependencies, it is important\
    \ to be aware of the potential module conflicts between dependencies, especially\
    \ those that provide similar functionality. In addition, redundant dependencies\
    \ should be avoided to prevent some errors caused by module overwriting during\
    \ the installation process, which are often difficult to detect and debug. Furthermore,\
    \ when developers declare a dependency, they should pay attention to whether the\
    \ dependency is deprecated or migrated. Because these dependencies mean that there\
    \ is no subsequent maintenance. If a vulnerability is disclosed, there is no maintainer\
    \ to release a patch to fix it. We believe effective dependency management is\
    \ very important, as it not only reduces the likelihood of module conflicts, but\
    \ also ensures compatibility and functional integrity.\n\nPyPI maintainers. Although\
    \ Python provides the concept of namespace packages, the installation process\
    \ for namespace packages is similar to that of regular packages and can still\
    \ result in overwriting behavior. While the presence of \\_\\_init\\_\\_.py files\
    \ in the same namespace does not cause impacts, because there is no real reason\
    \ to call them, if there are other module conflicts between\n\ntwo packages within\
    \ the same namespace, it can still lead to problems. In addition, we think pip\
    \ should isolate third-party packages from each other when installing them, like\
    \ other languages do, so that different third-party packages cannot interact with\
    \ each other. Moreover, pip should warn about overwriting when appropriate, rather\
    \ than overwriting by default, which can cause developers to destroy the local\
    \ development environment without their notice. Python should provide a mechanism\
    \ to select modules from third-party packages to be imported, instead of importing\
    \ an entire module or importing some features from a module while missing the\
    \ concept of packages.\n\nFuture work. We see two main directions for future work.\
    \ First, existing developers lack analysis tools for their own dependencies and\
    \ project profiles. This is mainly because we found that developers pack redundant\
    \ files into packages and upload them to PyPI, or project developers declare redundant\
    \ dependencies. Second, because the current tools of ModuleGuard do not take into\
    \ account the actual order of installation and whether the overwritten modules\
    \ are actually imported, there is a certain false positive. However, these false\
    \ positive examples do have overwriting problems, which we summarized in the issues\
    \ study. Moreover, considering the efficiency of large-scale analysis, ModuleGuard\
    \ does not use the project's call graph to analyze whether the conflicting modules\
    \ in Python projects have real import behavior. Therefore, we will make up for\
    \ this deficiency in future work, so as to improve the accuracy of the tool.\n\
    \n# <span id=\"page-10-3\"></span>8 RELATED WORK\n\nThe most relevant works to\
    \ this paper are PyCRE [\\[7\\]](#page-10-0), Pipreq [\\[38\\]](#page-11-41),\
    \ PyEGo [\\[49\\]](#page-11-6), SnifferDog [\\[45\\]](#page-11-7), and PyDFix\
    \ [\\[27\\]](#page-11-42). PyCRE [\\[7\\]](#page-10-0) and PyD-Fix [\\[27\\]](#page-11-42)\
    \ aim to solve the problem that some projects on PyPI cannot be installed properly\
    \ due to environmental compatibility issues. PyCRE generates project dependencies\
    \ through static analysis of calls between modules to form a domain knowledge\
    \ graph, while PyDFix dynamically obtains the log content of installation failures\
    \ to judge dependency errors and fixes them through continuous patching. However,\
    \ our work focuses on the module conflicts that occur during and after the installation\
    \ of PyPI projects, assuming that the installation process is successful. In addition,\
    \ in terms of module extraction, PyCRE not only does not notice that the module\
    \ path will change before and after package installation, but also does not notice\
    \ that modules with the same import statement may belong to different packages.\n\
    \nPipreq is a tool that generates the requirement.txt from the project source\
    \ code. It treats modules and packages as one-to-one mappings, and doesn't deal\
    \ with the case where different packages can contain the same module path. PyEGo\
    \ [\\[49\\]](#page-11-6) is a tool that automatically infers the dependencies\
    \ of third-party packages, the Python interpreter, and system libraries at compatible\
    \ versions for Python programs. It only extracts module paths from the metadata\
    \ file. For cases where different packages can contain the same module path, it\
    \ considers the conflicting module to belong to the most popular package. Vu et\
    \ al. [\\[43\\]](#page-11-43) study the possible attack vectors in the Python\
    \ ecosystem, but do not delve into the MC problem. SnifferDog [\\[45\\]](#page-11-7)\
    \ fixes the environment of the Jupyter Notebook project using module information\
    \ and dependency information. It\n\nalso uses a one-to-one mapping, so it doesn't\
    \ notice the module conflict problem either.\n\nOn the contrary, our work mainly\
    \ analyzes the impact of MC problem in the ecosystem on a large scale, which is\
    \ not involved in the above work. They either did not cover the module extraction\
    \ process, or simply took the module information from the file (low accuracy),\
    \ and did not pay attention to the complex problem of mapping the module before\
    \ and after installation. For the dependency resolution part, they use their own\
    \ specific algorithm for resolution, but the resolution rules are different from\
    \ the resolution rules used in the actual pip installation. In general, we noticed\
    \ some aspects in the module aspect that others had not noticed before, and used\
    \ pip-compatible algorithms in dependency resolution with higher accuracy.\n\n\
    #### <span id=\"page-10-4\"></span>9 CONCLUSION\n\nThis paper makes a systematic\
    \ empirical study of module conflicts in Python. We implemented a tool called\
    \ ModuleGuard. It parses module information and dependency information from the\
    \ PyPI project and, in turn, detects three types of module conflicts. We used\
    \ ModuleGuard to detect 4.2 million version packages and 3,711 popular GitHub\
    \ projects. We identified 108 GitHub projects with module-in-Dep conflicts and\
    \ reported issues to them and we get 12 fixed and good feedback. All experimental\
    \ data in this paper are available at [https://sites.google.com/view/moduleguard.](https://sites.google.com/view/moduleguard)\n\
    \n#### ACKNOWLEDGMENTS\n\nThe authors would like to thank all reviewers sincerely\
    \ for their valuable comments. This work is partially supported by the National\
    \ Key R&D Program of China (2022YFB3103900). It is also supported by the National\
    \ Research Foundation, Singapore, and DSO National Laboratories under the AI Singapore\
    \ Programme (AISG Award No: AISG2-GC-2023-008). It is also supported by the National\
    \ Research Foundation, Singapore, and the Cyber Security Agency under its National\
    \ Cybersecurity R&D Programme (NCRP25-P04-TAICeN) and the NRF Investigatorship\
    \ NRF-NRFI06-2020-0001. Any opinions, findings, conclusions, or recommendations\
    \ expressed in this material are those of the author(s) and do not reflect the\
    \ views of the National Research Foundation, Singapore, and the Cyber Security\
    \ Agency of Singapore.\n\n#### REFERENCES\n\n- <span id=\"page-10-6\"></span>[1]\
    \ Adafruit-Blinka. 2023. Retrieved March 10, 2023 from [https://pypi.org/project/](https://pypi.org/project/Adafruit-Blinka/)\
    \ [Adafruit-Blinka/](https://pypi.org/project/Adafruit-Blinka/)\n- <span id=\"\
    page-10-8\"></span>[2] albumentations team. 2022. Retrieved March 10, 2023 from\
    \ [https://github.com/](https://github.com/albumentations-team/albumentations/issues/841)\
    \ [albumentations-team/albumentations/issues/841](https://github.com/albumentations-team/albumentations/issues/841)\n\
    - <span id=\"page-10-2\"></span>[3] Mahmoud Alfadel, Diego Elias Costa, and Emad\
    \ Shihab. 2021. Empirical Analysis of Security Vulnerabilities in Python Packages.\
    \ In 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering\
    \ (SANER). 446–457. <https://doi.org/10.1109/SANER50967.2021.00048>\n- <span id=\"\
    page-10-7\"></span>[4] bandersnatch developers. 2022. bandersnatch. Retrieved\
    \ March 10, 2023 from <https://bandersnatch.readthedocs.io/en/latest/>\n- <span\
    \ id=\"page-10-5\"></span>[5] board. 2023. Retrieved March 10, 2023 from<https://pypi.org/project/board/>\n\
    - <span id=\"page-10-1\"></span>[6] Yulu Cao, Lin Chen, Wanwangying Ma, Yanhui\
    \ Li, Yuming Zhou, and Linzhang Wang. 2022. Towards Better Dependency Management:\
    \ A First Look At Dependency Smells in Python Projects. IEEE Transactions on Software\
    \ Engineering (2022), 1–26.<https://doi.org/10.1109/TSE.2022.3191353>\n- <span\
    \ id=\"page-10-0\"></span>[7] Wei Cheng, Xiangrong Zhu, and Wei Hu. 2022. Conflict-Aware\
    \ Inference of Python Compatible Runtime Environments with Domain Knowledge Graph.\
    \ In Proceedings of the 44th International Conference on Software Engineering\
    \ (Pittsburgh, Pennsylvania) (ICSE '22). Association for Computing Machinery,\
    \ New\n\n<span id=\"page-11-0\"></span>York, NY, USA, 451–461.<https://doi.org/10.1145/3510003.3510078>\n\
    \n- <span id=\"page-11-35\"></span>[8] conda. 2023. . Retrieved January 10, 2023\
    \ from<https://conda.io/>\n- <span id=\"page-11-4\"></span>[9] crates.io. 2022.\
    \ cargo. Retrieved March 10, 2023 from<https://crates.io/>\n- <span id=\"page-11-12\"\
    ></span>[10] Ruian Duan, Omar Alrawi, Ranjita Pai Kasturi, Ryan Elder, Brendan\
    \ Saltaformaggio, and Wenke Lee. 2020. Towards measuring supply chain attacks\
    \ on package managers for interpreted languages. arXiv preprint arXiv:2002.01139\
    \ (2020).\n- <span id=\"page-11-40\"></span>[11] dylanhogg. 2022. Python Awesome\
    \ Project. Retrieved March 10, 2023 from <https://awesomepython.org/>\n- <span\
    \ id=\"page-11-21\"></span>[12] Python Software Foundation. 2022. api-reference.\
    \ Retrieved March 10, 2023 from<https://warehouse.pypa.io/api-reference/xml-rpc.html>\n\
    - <span id=\"page-11-32\"></span>[13] Python Software Foundation. 2022. opencv-python.\
    \ Retrieved March 10, 2023 from<https://pypi.org/project/opencv-python/>\n- <span\
    \ id=\"page-11-22\"></span>[14] Python Software Foundation. 2022. Python Dependency\
    \ Specifiers. Retrieved March 10, 2023 from [https://packaging.python.org/en/latest/specifications/](https://packaging.python.org/en/latest/specifications/dependency-specifiers/)\
    \ [dependency-specifiers/](https://packaging.python.org/en/latest/specifications/dependency-specifiers/)\n\
    - <span id=\"page-11-18\"></span>[15] Python Software Foundation. 2022. Python\
    \ Documentation. Retrieved March 10, 2023 from<https://docs.python.org/3/>\n-\
    \ <span id=\"page-11-37\"></span>[16] Python Software Foundation. 2022. Python\
    \ Standard Libraries Documentation. Retrieved March 10, 2023 from<https://docs.python.org/3.10/library/index.html>\n\
    - <span id=\"page-11-19\"></span>[17] Google. 2022. deps.dev. Retrieved March\
    \ 10, 2023 from<https://deps.dev/>\n- <span id=\"page-11-25\"></span>[18] Google.\
    \ 2022. PyPI downloads table. Retrieved March 10, 2023 from [https:](https://bigquery.cloud.google.com/table/bigquery-public-data:pypi.downloads)\
    \ [//bigquery.cloud.google.com/table/bigquery-public-data:pypi.downloads](https://bigquery.cloud.google.com/table/bigquery-public-data:pypi.downloads)\n\
    - <span id=\"page-11-13\"></span>[19] Wenbo Guo, Zhengzi Xu, Chengwei Liu, Cheng\
    \ Huang, Yong Fang, and Yang Liu. 2023. An Empirical Study of Malicious Code In\
    \ PyPI Ecosystem. In 2023 38th IEEE/ACM International Conference on Automated\
    \ Software Engineering (ASE). IEEE, 166–177.\n- <span id=\"page-11-8\"></span>[20]\
    \ Eric Horton and Chris Parnin. 2019. Dockerizeme: Automatic inference of environment\
    \ dependencies for python code snippets. In 2019 IEEE/ACM 41st International Conference\
    \ on Software Engineering (ICSE). IEEE, 328–338.\n- <span id=\"page-11-26\"></span>[21]\
    \ Piergiorgio Ladisa, Henrik Plate, Matias Martinez, and Olivier Barais. 2022.\
    \ Taxonomy of attacks on open-source software supply chains. arXiv preprint arXiv:2204.04008\
    \ (2022).\n- <span id=\"page-11-39\"></span>[22] lambdaloop. 2022. aniposelib.\
    \ Retrieved March 10, 2023 from [https://github.](https://github.com/lambdaloop/anipose/issues/22)\
    \ [com/lambdaloop/anipose/issues/22](https://github.com/lambdaloop/anipose/issues/22)\n\
    - <span id=\"page-11-34\"></span>[23] LarsVoelker. 2022. Retrieved March 10, 2023\
    \ from [https://github.com/](https://github.com/LarsVoelker/FibexConverter/issues/7)\
    \ [LarsVoelker/FibexConverter/issues/7](https://github.com/LarsVoelker/FibexConverter/issues/7)\n\
    - <span id=\"page-11-9\"></span>[24] Shuo Li. [n. d.]. EasyPip: Detect and Fix\
    \ Dependency Problems in Python Dependency Declaration Files. ([n. d.]).\n- <span\
    \ id=\"page-11-24\"></span>[25] Libraries.io. 2022. Libraries.io Query. Retrieved\
    \ March 10, 2023 from [https:](https://libraries.io/search?order=desc&platforms=PyPI)\
    \ [//libraries.io/search?order=desc&platforms=PyPI](https://libraries.io/search?order=desc&platforms=PyPI)\n\
    - <span id=\"page-11-3\"></span>[26] Maven. 2021. Maven – Guide to Naming Conventions.\
    \ [https://maven.apache.](https://maven.apache.org/guides/mini/guide-naming-conventions.html)\
    \ [org/guides/mini/guide-naming-conventions.html](https://maven.apache.org/guides/mini/guide-naming-conventions.html)\
    \ Accessed: 2022-01-19.\n- <span id=\"page-11-42\"></span>[27] Suchita Mukherjee,\
    \ Abigail Almanza, and Cindy Rubio-González. 2021. Fixing dependency errors for\
    \ Python build reproducibility. In Proceedings of the 30th ACM SIGSOFT international\
    \ symposium on software testing and analysis. 439–451.\n- <span id=\"page-11-28\"\
    ></span>[28] opendatateam. 2022. Cookiecutter-udata-plugin issue. Retrieved March\
    \ 10, 2023 from<https://github.com/opendatateam/cookiecutter-udata-plugin/issues/3>\n\
    - <span id=\"page-11-5\"></span>[29] pip. 2023. pip documentation v22.3.1. Retrieved\
    \ March 10, 2023 from [https:](https://pip.pypa.io/) [//pip.pypa.io/](https://pip.pypa.io/)\n\
    - <span id=\"page-11-36\"></span>[30] poetry. 2023. . Retrieved January 10, 2023\
    \ from [https://python-poetry.org/docs/](https://python-poetry.org/docs/repositories/)\
    \ [repositories/](https://python-poetry.org/docs/repositories/)\n- <span id=\"\
    page-11-31\"></span>[31] pycrypto. 2022. Pycrypto issue. Retrieved March 10, 2023\
    \ from [https://github.](https://github.com/pycrypto/pycrypto/issues/156) [com/pycrypto/pycrypto/issues/156](https://github.com/pycrypto/pycrypto/issues/156)\n\
    - <span id=\"page-11-30\"></span>[32] pypa. 2022. Retrieved March 10, 2023 from\
    \ [https://github.com/pypa/pip/issues/](https://github.com/pypa/pip/issues/4625)\
    \ [4625](https://github.com/pypa/pip/issues/4625)\n- <span id=\"page-11-33\"></span>[33]\
    \ pypa. 2022. Retrieved March 10, 2023 from [https://github.com/pypa/pip/issues/](https://github.com/pypa/pip/issues/8509)\
    \ [8509](https://github.com/pypa/pip/issues/8509)\n- <span id=\"page-11-38\"></span>[34]\
    \ pypa. 2023. Package Discovery and Namespace Packages. Retrieved January 10,\
    \ 2023 fro[m https://setuptools.pypa.io/en/latest/userguide/package\\\\_discovery.html](https://setuptools.pypa.io/en/latest/userguide/package_discovery.html)\n\
    - <span id=\"page-11-29\"></span>[35] radekd91. 2022. Emoca issue. Retrieved March\
    \ 10, 2023 from [https://github.com/](https://github.com/radekd91/emoca/issues/44)\
    \ [radekd91/emoca/issues/44](https://github.com/radekd91/emoca/issues/44)\n- <span\
    \ id=\"page-11-14\"></span>[36] Jukka Ruohonen, Kalle Hjerppe, and Kalle Rindell.\
    \ 2021. A Large-Scale Security-Oriented Static Analysis of Python Packages in\
    \ PyPI. In 2021 18th International Conference on Privacy, Security and Trust (PST).\
    \ IEEE, 1–10.\n- <span id=\"page-11-23\"></span>[37] sarugaku. 2022. resolvelib.\
    \ Retrieved March 10, 2023 from [https://github.com/](https://github.com/sarugaku/resolvelib)\
    \ [sarugaku/resolvelib](https://github.com/sarugaku/resolvelib)\n- <span id=\"\
    page-11-41\"></span>[38] Jessamyn Smith. 2023. pipreq. Retrieved March 10, 2023\
    \ from [https://github.](https://github.com/bndr/pipreqs/) [com/bndr/pipreqs/](https://github.com/bndr/pipreqs/)\n\
    - <span id=\"page-11-2\"></span>[39] Sonatype. 2021. State of the 2021 Software\
    \ Supply Chain. Sonatype Blog (2021). <https://www.sonatype.com/blog/software-supply-chain-2021>\n\
    - <span id=\"page-11-20\"></span>[40] TIDELIFT. 2022. Libraries.io. Retrieved\
    \ March 10, 2023 from<https://libraries.io/>\n- <span id=\"page-11-17\"></span>[41]\
    \ virtualenv [n. d.]. Retrieved March 10, 2023 from<https://virtualenv.pypa.io/>\n\
    - <span id=\"page-11-15\"></span>[42] Duc-Ly Vu, Ivan Pashchenko, Fabio Massacci,\
    \ Henrik Plate, and Antonino Sabetta. 2020. Typosquatting and combosquatting attacks\
    \ on the python ecosystem. In 2020 IEEE European Symposium on Security and Privacy\
    \ Workshops. IEEE, 509–514.\n- <span id=\"page-11-43\"></span>[43] Duc-Ly Vu,\
    \ Ivan Pashchenko, Fabio Massacci, Henrik Plate, and Antonino Sabetta. 2020. Typosquatting\
    \ and Combosquatting Attacks on the Python Ecosystem. In 2020 IEEE European Symposium\
    \ on Security and Privacy Workshops. IEEE. <https://doi.org/10.1109/eurospw51379.2020.00074>\n\
    - <span id=\"page-11-10\"></span>[44] Chao Wang, Rongxin Wu, Haohao Song, Jiwu\
    \ Shu, and Guoqing Li. 2022. Smart-Pip: A Smart Approach to Resolving Python Dependency\
    \ Conflict Issues. IEEE Transactions on Software Engineering (2022).\n- <span\
    \ id=\"page-11-7\"></span>[45] Jiawei Wang, Li Li, and Andreas Zeller. 2021. Restoring\
    \ execution environments of Jupyter notebooks. In 2021 IEEE/ACM 43rd International\
    \ Conference on Software Engineering (ICSE). IEEE, 1622–1633.\n- <span id=\"page-11-11\"\
    ></span>[46] Ying Wang, Ming Wen, Yepang Liu, Yibo Wang, Zhenming Li, Chao Wang,\
    \ Hai Yu, Shing-Chi Cheung, Chang Xu, and Zhiliang Zhu. 2020. Watchman: Monitoring\
    \ Dependency Conflicts for Python Library Ecosystem. In 2020 IEEE/ACM 42nd International\
    \ Conference on Software Engineering (ICSE). 125–135. [https://doi.](https://doi.org/10.1145/3377811.3380426)\
    \ [org/10.1145/3377811.3380426](https://doi.org/10.1145/3377811.3380426)\n- <span\
    \ id=\"page-11-1\"></span>[47] Wikipedia. 2023. Identifier. Retrieved March 10,\
    \ 2023 from [https://en.wikipedia.](https://en.wikipedia.org/wiki/Identifier#Implicit_context_and_namespace_conflicts)\
    \ [org/wiki/Identifier#Implicit\\\\_context\\\\_and\\\\_namespace\\\\_conflicts](https://en.wikipedia.org/wiki/Identifier#Implicit_context_and_namespace_conflicts)\n\
    - <span id=\"page-11-27\"></span>[48] wtsi hgi. 2022. Python-hgijson issue. Retrieved\
    \ March 10, 2023 from [https:](https://github.com/wtsi-hgi/python-hgijson/issues/14)\
    \ [//github.com/wtsi-hgi/python-hgijson/issues/14](https://github.com/wtsi-hgi/python-hgijson/issues/14)\n\
    - <span id=\"page-11-6\"></span>[49] Hongjie Ye, Wei Chen, Wensheng Dou, Guoquan\
    \ Wu, and Jun Wei. 2022. Knowledge-based environment dependency inference for\
    \ Python programs. In Proceedings of the 44th International Conference on Software\
    \ Engineering. 1245– 1256.\n- <span id=\"page-11-16\"></span>[50] ysr monitor.\
    \ 2023. Retrieved March 10, 2023 from [https://pypi.org/project/ysr](https://pypi.org/project/ysr-monitor/)[monitor/](https://pypi.org/project/ysr-monitor/)"
- title: Automated Test Production -- Complement to "Ad-hoc" Testing
  abstract: 'A view on software testing, taken in a broad sense and considered a important

    activity is presented. We discuss the methods and techniques for applying tests

    and the reasons we recognize make it difficult for industry to adopt the

    advances observed in academia. We discuss some advances in the area and briefly

    point out the approach we intend to follow in the search for a solution.'
  url: http://arxiv.org/abs/2401.02230v1
  keywords: ''
  document: '# Automated Test Production Complement to "Ad-hoc" Testing


    Gomes, J.M.<sup>1</sup> and Dias, L.A.V.<sup>1</sup>


    1 Instituto Tecnol´ogico de Aeron´autica - ITA


    January 5, 2024


    #### Abstract


    A view on software testing, taken in a broad sense and considered a important
    activity is presented. We discuss the methods and techniques for applying tests
    and the reasons we recognize make it difficult for industry to adopt the advances
    observed in academia. We discuss some advances in the area and briefly point out
    the approach we intend to follow in the search for a solution.


    # 1 Motivation


    Accepting that tests are important, but are not always implemented or kept up
    to date during the lifetime of a program, we conclude that nothing has changed
    since the introduction of the Agile Manifesto earlier this century [\[1\]](#page-13-0)
    which we reproduce below and from which we highlight the passage "Software that
    works rather than complete documentation"[\[1\]](#page-13-0).


    - "Individuals and interactions over processes and tools"

    - "Working software over comprehensive documentation"

    - "Customer collaboration over contract negotiation"

    - "Responding to change over following a plan"


    This view has come to become an important industry trend [\[2\]](#page-13-1)[1](#page-0-0)
    , where face-to-face interactions are preferable to formal communication processes
    and working programs are preferable to comprehensive documentation, leaving the
    interpretation of the term "comprehensive" to each agile development team to decide
    [\[4](#page-13-2)]. In fact the agile method suggests that all documentation can
    be replaced by informal communication with an emphasis on tacit rather than explicit
    knowledge [\[5\]](#page-14-0).


    <span id="page-0-0"></span><sup>1</sup>The 14<sup>o</sup> annual report STATEofAGILE
    from 2020 points out that 95% of organizations practice agile software development
    methods. [\[3](#page-13-3)].


    On the other hand, the adoption of continuous integration and continuous delivery
    processes and tools has been steadily and unequivocally growing in both industry
    [\[6](#page-14-1), [7](#page-14-2)] and open source projects [\[8\]](#page-14-3),
    which can to some extent be interpreted as a denial of one of the principles of
    the Agile Manifesto: "Individuals and interactions over processes and tools",
    yet this does not come as a relief to the fact that many see benefits in building
    and maintaining formal models, but are not content to build them as they believe
    they consume too much time and resources, even believing in the slim chances of
    success of projects that do not use some modeling [\[9\]](#page-14-4).


    The implications of this view for the construction and maintenance of programs
    and the use and application of development methods and tools are discussed.


    # 2 Test Production Methods


    The present discussion is a contribution to the understanding of how software
    testing fits into the present realities perceived by both industry and academia,
    even if these realities, as we shall see, do not correspond and will not converge.
    The TDD (Test Driven Development) technique is widely cited and recommended by
    the signers of the Agile Manifesto [\[10\]](#page-14-5), even though it is not
    part of the manifesto or its twelve principles [\[1\]](#page-13-0), so we can
    conclude that the IT (Information Technology) industry at least recognizes the
    importance of testing programs. The academia, on the other hand, perceives program
    testing based on formal specifications as inevitable in pioneering studies since
    the 1970s [\[11,](#page-14-6) [12\]](#page-14-7), the foundations for combining
    formal methods and program testing being established and accepted, and it is up
    to the community to put them into practice, optimize and extend them.


    In general, we classify the tests in Formal: verifiable by theoretical means or
    pure logic; and Empirical: verifiable through observation or direct experience[2](#page-1-0)
    .


    ### 2.1 Formal Testing


    Hoare and Floyd introduced formal methods by introducing the "Hoare calculus"
    for proving the correctness of a program as well as the notions of pre and postconditions,
    invariants and assertions. His ideas were gradually developed into the current
    formal software engineering tools and techniques, such as the OCL (Object Constraint
    Language) [\[15](#page-14-8)] used to specify constraints in UML (Unified Modelling
    Language) diagrams.


    According to Gaudel, for each and every specification method, there is a notation
    [\[16](#page-14-9)]. Depending on the method, specifications can include expressions
    in various logical forms, used to write pre and postconditions, axioms of data
    types, constraints, temporal properties. They can represent definitions of process
    states, such as:


    <span id="page-1-0"></span><sup>2</sup>We take into account the formality of the
    test and not the conduct of the test, as it is perfectly possible to conduct empirical
    tests by adopting formal practices in their execution.


    - CSP (Communicating Sequential Processes) [\[17\]](#page-14-10)

    - CCS (Calculus of Communicating Systems) [\[18](#page-14-11)]

    - LOTOS (Language Of Temporal Ordering Specification) [\[19](#page-14-12)]

    - Circus [\[20\]](#page-14-13)


    Or they can have annotated diagrams, such as:


    - FSM (Finite State Machine) [\[21\]](#page-15-0)

    - LTS (Labelled Transition Systems) [\[22](#page-15-1)]

    - Petri Networks [\[23\]](#page-15-2)

    - etc.


    But there is more than a syntax. First, there is a formal semantics, in terms
    of mathematical notions such as:


    - Predicate transformers for pre and post conditions

    - Classified sets and algebras for axiomatic definitions

    - Various types of automata, traces, faults, divergences, for process algebras


    Second, there is a formal deduction system, making it possible to perform proofs,
    or other checks (such as model checking), or both. Thus, formal specifications
    can be analyzed to guide the identification of appropriate test cases.


    In addition to syntax, semantics, and the deduction system, formal methods come
    with some relations between specifications that formalize equivalence or correct
    step-by-step development. Depending on the context, such relations are called:
    refinement, conformance, or, in the case of formulas, satisfiability, and are
    fundamental to test methods [\[16\]](#page-14-9).


    Gaudel concludes that model-based tests are tests of the black-box [3](#page-2-0)
    type, where the internal organization of the program under test is ignored and
    the strategy is based on a description of the desired properties and behavior
    of the program[4](#page-2-1) , which may be formal or not, or in other words,
    these methods target certain classes of faults and assume that the program is
    exempt from other types and classes of faults [\[16\]](#page-14-9).


    <span id="page-2-0"></span><sup>3</sup>Method of validating functional and external
    aspects of a computer application.


    <span id="page-2-1"></span><sup>4</sup>We separate these tests into a category
    - that of Formal Tests - that is, tests with a formal basis and that originate
    from models.


    ### 2.2 Empirical Tests


    Without formal defined specifications a priori, which as we have seen in "Motivation"
    is a trend in the industry, we are left only with informal and empirical practice[5](#page-3-0)
    for the verification and validation of the correctness of computer program implementation[6](#page-3-1)
    . One of the practices advocated by supporters of agile methods is TDD, where
    tests are written even before the program itself, but it does not show clear benefits[7](#page-3-2)
    compared to the option of implementing the tests after the program is ready [\[25](#page-15-3),
    [26](#page-15-4), [27](#page-15-5)], or it may be linked to the fact that processes
    like TDD encourage stable and refined steps of continuous improvement [\[28\]](#page-15-6).


    In the informal test, we have a relation of the hypothesis to an observation statement,
    which is nothing more than a proposition about the perceptible properties of some
    entity, set of entities, or system, followed by a rule transmission where, if
    the observation statement directly confirms the hypothesis, then indirectly it
    confirms any of its logical consequences [\[29](#page-15-7)].


    We can state that formal tests are cases of inductive inference[8](#page-3-3)
    , and that in empirical tests we have a direct confirmation of the hypothesis,
    but without the soundness and precision that formal methods[9](#page-3-4) guarantee
    [\[30\]](#page-15-8) as a consequence of the ad hoc attitude with which the informality
    of design[10](#page-3-5) of empirical testing is practiced.


    Just as using only Formal Methods we are unable to judge all the possibilities
    of flaws that a program may present[\[31\]](#page-15-9), we can state that Empirical
    Methods are also so, and for the same reasons, with the aggravating factor of
    introducing a certain randomness[11](#page-3-6) to the process.


    ### 2.3 Static and Dynamic Analysis


    This is a case where the test can either be defined a priori (as in TDD or modelbased)
    or a posteriori (as most informal tests are done), and which according to Gaudel,
    would be the answer to the lack of coverage of Formal Tests, but which as we will
    see below, also present problems of application in practice.


    Static analysis was introduced in 1980 with the work "Methods to ensure the standardization
    of FORTRAN software. [PFORT, DAVE, POLISH, and BRNANL, for analysis and editing
    of codes, in FORTRAN for PDP-10 and IBM 360 and 370]" by Gaffney and Wooten [\[32](#page-15-10)].
    The nature of verification


    <span id="page-3-0"></span><sup>5</sup>Which generally means: verifiable by direct
    observation or experience rather than by theory or pure logic, even though it
    is possible to adopt formal practices during an empirical procedure.


    <sup>6</sup>Nothing prevents that, even starting from a basis of formal specifications,
    empirical tests be adopted in the verification of the implementation.


    <span id="page-3-1"></span><sup>7</sup>The practice of TDD is advocated mainly
    because the alternative is to have no tests at all after the program is ready[\[24\]](#page-15-11).


    <span id="page-3-3"></span><span id="page-3-2"></span><sup>8</sup>We cannot call
    "formal tests" a case of "indirect confirmation".


    <span id="page-3-4"></span><sup>9</sup>Formal methods pursue qualitative and quantitative
    metrics of the soundness and precision of the method itself.


    <sup>10</sup>And as we said earlier, not necessarily of the actual conduct, which
    can be perfectly formal.


    <span id="page-3-6"></span><span id="page-3-5"></span><sup>11</sup>The observer''s
    objectivity and his judgment.


    performed by static parsers include [\[33,](#page-15-12) [34\]](#page-15-13) (but
    not limited to only these) the following analyses:


    - Layout and source code formatting

    - Identifying language constructs known to be non-portable

    - Identifying algorithm constructs known to be unsafe

    - Use of variables or constants with suspect names and contents (for example:
    PASSWORD = ''SECRET'')

    - Detection of faults not considered by compilers

    - Control flow analysis (detection of loops)

    - Detect data usage in variables before a value has been entered

    - Detect value overloading in variables (assign a very large value to a variable
    that only supports small values - in some languages assign a DOUBLE value to a
    simple INT variable)

    - Detect memory overflow (leak) or the non-validation of may memory overflow (assigning
    a very long constant to a variable that supports a small memory size)

    - Detect leakage of handles (the reference to the control structure) of files
    and accesses to communication resources

    - Check permission to perform certain operations

    - Ensuring the termination of a processing (or ensuring indications that it will
    not terminate)

    - Ensure the order in which processing is performed and terminated in a way that
    maintains the integrity of the information (or ensure that it gives indications
    that the information is not intact)

    - Ensure that the process can be observed as deterministic[12](#page-4-0) (or
    ensure that there are indications that the process cannot be observed as deterministic)


    Many of these validations can be (and most often are) done by compilers (when
    the language is compiled)[\[35\]](#page-15-14). Since the purpose of the compiler
    is to generate executable code and not to check for programming faults, and other
    classes of faults can only be determined at runtime, such as memory overflow,
    which only occurs if a very long constant is supplied during program use,[13](#page-4-1)
    ,


    <span id="page-4-0"></span><sup>12</sup>If an action is visible to the environment
    (i.e. if it performs data retrieval or changes data), then we say it is observable.
    The order of execution of non-priority rules will make a difference in the order
    of appearance of observable actions.


    <span id="page-4-1"></span><sup>13</sup>Although it is possible, as we can see
    later, to predict overflow using one of the many static analysis methods available.


    | Classe                      | Descri¸c˜ao                                                                                                                                                         |

    |-----------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------|

    | Lexical Analysis            | Lexical analysis is based on the grammatical structure
    of the language. It divides the                                                                              |

    |                             | program into small parts that are compared to
    known fault libraries. Disregarding                                                                                   |

    |                             | syntax, semantics and interaction between subroutines,
    the incidence of false posi                                                                                  |

    |                             | tives is high [42].                                                                                                                                                 |

    | Type Inference              | It infers the type of variables and functions
    by the compiler or interpreter, and checks                                                                            |

    |                             | that accesses to these variables and functions
    conform to predefined rules for the type                                                                             |

    | Data Flow                   | [43].<br>Refers to collecting semantic information
    from source code, and using algebraic                                                                            |

    | Analysis                    | method determines the definition and use of variables
    at compile time.<br>Starting                                                                                  |

    |                             | from the execution flow graph, a data flow analysis
    determines whether values in a                                                                                  |

    |                             | program are flagged as potentially vulnerable
    variables [44].                                                                                                       |

    | Rule Checking               | Checks the security of a program using pre-set
    rules [45]. Some rules, such as re                                                                                   |

    |                             | quiring execution under elevated privilege, carry
    security implications [42] and are                                                                                |

    |                             | detected.                                                                                                                                                           |

    | Constraints                 | Divided between constraint generation and constraint
    resolution during the analysis                                                                                 |

    | Analysis                    | process. Constraint generation sets variable types
    or analyzes the constraint system                                                                                |

    |                             | between different states of execution using predetermined
    rules; constraint resolution                                                                              |

    |                             | applies and resolves the generated constraints
    [42].                                                                                                                |

    | Comparison of<br>Correction | Comparison of source or binary code snippets changed
    during the process of fixing                                                                                   |

    | Snippets                    | flaws is used to find known implementation gaps.
    After patches have been applied<br>to a program, the comparison serves to determine
    the location and causes of the |

    |                             | vulnerability to which they apply [42].                                                                                                                             |

    | Symbolic                    | It represents program inputs as symbols instead
    of the actual data, and produces al                                                                                 |

    | Execution                   | gebraic expressions over the symbol in the implementation
    process. By the constraint                                                                                |

    |                             | solving method symbolic execution can detect possible
    failures [46, 47, 48, 49].                                                                                    |

    | Abstract<br>Interpretation  | It is a formal description of program analysis,
    which maps the program to abstract                                                                                  |

    |                             | domains. The technique requires completeness,
    which makes it impractical for very                                                                                   |

    |                             | large programs, but proves correct for all possible
    inputs [50, 51].                                                                                                |

    | Proof of<br>Theorems        | Semantic analysis of the program, which can solve
    infinite state system problems [52,                                                                               |

    |                             | 53]. First convert the program into a logical
    formula, then prove that the program is                                                                               |

    |                             | a valid theorem using axioms and rules [42].                                                                                                                        |

    | Model<br>Verification       | Starting from formal models, such as state machines
    or directed graphs, it runs<br>through them and compares the model with the implementation
    to see if it matches |

    |                             | the characteristics predefined by the first [54].                                                                                                                   |

    |                             |                                                                                                                                                                     |


    <span id="page-5-0"></span>Table 1: Classification of Static Analyzers


    then specialized checkers such as Linters[\[36\]](#page-16-9) are adopted. Capable
    of detecting a wide range of faults, including style (layout of source code),
    some use source code annotations to achieve better problem detection, at the expense
    of extra developer work [\[37,](#page-16-10) [38,](#page-16-11) [39,](#page-16-12)
    [40,](#page-16-13) [41\]](#page-16-14).


    Static analyzers can then be classified (see Table [1\)](#page-5-0) into various
    types and capabilities, covering the detection of several possible fault categories,
    from implementation to vulnerability and security related.


    The problem with static analyzers is the high false positive rate (alerts that
    are not real problems), low understandability of alerts and lack of automation
    in quick fixes for the large number of identified problems [\[55\]](#page-17-4),
    such as: [\[56](#page-17-5)] code structure and [\[57](#page-17-6)] coding patterns,
    which could easily be fixed using automatic refactoring techniques [\[58](#page-17-7)],
    but as we will see below, the available tools are not in line with the latest
    advances made by the scientific community.


    Dynamic analysis, on the other hand, is in contrast to static analysis and contemplates
    the forms best known and adopted by the industry in the appli-


    | Classe           | Descri¸c˜ao                                                                            |

    |------------------|----------------------------------------------------------------------------------------|

    | Unit Test        | The process of testing subprograms, subroutines, classes,
    or functional units within   |

    |                  | a program to verify that there are no programming flaws [60,
    p. 486].                  |

    | Integration Test | Testing phase where the functional units are combined and
    tested as a group to assess  |

    |                  | whether they worked properly in the complete system [60,
    p. 235].                      |

    | System Testing   | Test conducted on multiple integrated systems to evaluate
    their ability to communi     |

    |                  | cate with each other and achieve general and specific integration
    requirements [60,    |

    |                  | p. 545].                                                                               |

    | Acceptance Test  | Testing of a system or functional unit generally performed
    by the buyer or user on     |

    |                  | site after installation of the software to make sure that
    the contractual requirements |

    |                  | have been met [60, p. 5].                                                              |


    <span id="page-6-0"></span>Table 2: Classification of Dynamic Tests


    cation of software testing [\[59\]](#page-17-9) (see Table [2\)](#page-6-0).


    # 3 The Challenge of Testing


    ### 3.1 Software Quality


    C. A. R. Hoare in the research "How did software get so reliable without proof?"
    conducted in 1996 states that it was reasonable to predict that the size and ambition
    of software products would be severely limited by the lack of reliability in their
    components. Estimates suggested, in its study, that professionally written programs
    may contain between one and ten correctable faults for every thousand lines of
    code; and any one software fault, in principle, can have a spectacular effect
    (or worse: a subtly misleading effect) on the behavior of the entire system [\[61\]](#page-17-10).


    Hoare found at the time that the software patch problem turned out to be far less
    serious than anticipated. An analysis by Mackenzie [\[62\]](#page-17-11) showed
    that of several thousand deaths attributed to computer applications, only ten
    or so could be explained by software crashes: most due to a few cases of incorrect
    dosage calculations in radiation cancer treatment. Similarly, predictions of collapse
    due to the size of computer programs have been falsified by the continuous operation
    of real-time software systems now measured in tens of millions of lines of code
    and subject to thousands of updates per year.


    In his review Hoare concludes that, despite appearances, modern software engineering
    practice owes much to the theoretical concepts and ideals of early research in
    this field; and that formalization and proof techniques have played an essential
    role in the validation and progress of research.


    Hoare concludes that the main factors for the apparent success of the software
    are:


    • Management - The most dramatic advances in the delivery of reliable software
    are directly attributable to a wider recognition of the fact that the process
    of program development can be predicted, planned, managed, and controlled just
    as in any other branch of engineering.


    - Test Thorough testing is the cornerstone of reliability in quality assurance
    and control in modern production engineering. Tests are applied as early as possible
    throughout the production line. They are rigorously designed to maximize the probability
    of detecting failures and as quickly as possible.

    - Debugging The secret of successful testing is that it checks the quality of
    the process and methods by which the code was produced. But there is an entirely
    different and very common response to the discovery of a flaw by testing: simply
    fix it and get on with the job. This is known as debugging, by analogy with trying
    to get rid of a mosquito infestation by killing the ones that bite - much faster,
    cheaper and more satisfying than draining the swamps in which they breed.

    - Excess Engineering The concept of safety factor is very widespread in engineering.
    After calculating the worst case load on a beam, the civil engineer will try to
    build it at least twice as strong. In computing, a continuous drop in the price
    of storage and increased processing power has made it acceptable to add redundancies
    to reduce the risk of software failures and a smaller scale of damage. This leads
    to the same kind of over-engineering required by law for bridge construction;
    and it is extremely effective, although there is no clear way to measure it by
    a numerical factor.

    - Programming Methodologies Most of the measures described so far for achieving
    reliability in software are the same ones that have been proven equally effective
    in all engineering disciplines. But the best general techniques for management,
    quality control, and safety would be totally useless by themselves; they are only
    effective when there is a general understanding, a common conceptual framework
    and terminology for discussing the relationship between cause and effect, between
    action and consequence. Research in programming methodology has this goal: to
    establish a conceptual framework and a theoretical basis to assist in the systematic
    derivation and justification of each design decision by a rational and explicable
    line of reasoning.


    ### 3.2 Perceived Quality when Using Software


    According to the NIST (National Institute of Standards and Technology) report,
    the estimated impact (in the United States) of inadequate software testing infrastructure
    is 859 billions dollars and the potential cost savings from feasible improvements
    is 822 billions dollars. Software users account for a larger share of the total
    costs of inadequate infrastructure (64 percent) compared to "viable" cost reductions
    (52 percent) because a large share of user costs are due to prevention activities.
    Whereas mitigation activities decrease proportionally to the decrease in the number
    of failures, prevention costs (such as redundant systems and investigating purchasing
    decisions) are likely to persist, even if only a few errors are expected. For
    software developers, the feasible cost savings are


    |            | Testers /<br>Employees<br>(millions) | Cost of inadequate<br>testing
    infrastructure |                              | Potential cost reduction<br>with
    feasible improvements |                              |

    |------------|--------------------------------------|----------------------------------------------|------------------------------|--------------------------------------------------------|------------------------------|

    |            |                                      | Unit cost                                    |
    Total cost<br>(million US\$) | Unit cost<br>(million US\$)                            |
    Total Cost<br>(million US\$) |

    | Developers | 0,302                                | 69.945                                       |
    21.155                       | 34.964                                                 |
    10.575                       |

    | Users      |                                      |                                              |                              |                                                        |                              |

    | Industry   | 25,0                                 | 459                                          |
    11.463                       | 135                                                    |
    3.375                        |

    | Services   | 74,1                                 | 362                                          |
    26.858                       | 112                                                    |
    8.299                        |

    | Total      |                                      |                                              |
    59.477                       |                                                        |
    22.249                       |


    Table 3: Estimated national impact in the US (adapted from [\[63\]](#page-17-12))


    approximately 50 percent of the total costs of inadequate infrastructure. This
    reflects a more proportional decrease in testing effort as testing resources and
    tools improve [\[63\]](#page-17-12).


    If we add up everything from minor inconveniences in our daily lives to incalculable
    human and social damage from software failures, the perception we have may be
    quite different from that of Hoare in his study. This is because today the penetration
    of computerized systems in our lives, with its own challenges and opportunities
    due to the great convergence of connected systems, interoperability and massive
    distribution of information, can make the most insignificant failure from a mere
    annoyance (such as losing access to your favorite music playlist) to a catastrophe
    of global proportions (such as a widespread failure in a worldwide satellite communications
    system).


    ### 3.3 The Gap Between Industry and Scientific Advances


    In 1996 Hoare noted that academic research gains in programming methodologies
    took up to 20 years to be adopted by industry as a sign of maturity and sanity
    - only in very specific areas and for a brief period would it be justified to
    apply the latest pure research advances to people''s everyday lives [\[61\]](#page-17-10).
    This mismatch also has the benefit of providing adequate planning of research
    and education as well as adequacy of the installed park in the industry. The result
    of not following this step is to adopt immature technologies and practices, with
    unpredictable and undesirable results, with no skilled labor available to apply
    it and make the necessary corrections when failures occur[14](#page-8-0) .


    Another consequence of not observing the maturity of cutting-edge research before
    its adoption in practice is the fact that, paradoxically, mature and effective
    technologies have not yet been adopted by industry, or when they are, they are
    isolated cases that cause astonishment when they present better results than those
    obtained with "state-of-the-art technologies". As an example we cite the adoption
    of the pairwise technique for test generation. The mathematical theory behind
    this technique has been around since the 1960s (see DESIGN, TESTING AND ESTIMATION
    IN COMPLEX EXPERIMENTATION. I. EXPANSIBLE AND CONTRACTIBLE FACTORIAL DESIGNS AND
    THE APPLICATION


    <span id="page-8-0"></span><sup>14</sup>If this scenario sounds like something
    that is happening in your industry, then maybe this is the reason.


    | Research                                               | Type      | Tests  |
    Time | Defects |

    |--------------------------------------------------------|-----------|--------|------|---------|

    | "A case study on pairwise testing application"<br>[66] | Ad<br>hoc | 14,041
    | 20h  | 10      |

    |                                                        | Pairwise  | 68     |
    4h   | 10      |

    | "A case study using testing technique for soft         | Manual    | 159    |
    6h   | 3       |

    | ware as a service (SaaS)" [67]                         | Pairwise  | 17     |
    1h   | 3       |


    <span id="page-9-0"></span>Table 4: Pairwise Application Research Results


    OF LINEAR PROGRAMMING TO COMBINATORIAL PROBLEMS publishied in 1965 [\[64](#page-17-13)]),
    the application in software testing using pairwise was presented earlier this
    century (see Combinatorial group testing and its applications published in 2000
    [\[65](#page-17-14)]). Recent research using these techniques (see Table [4\)](#page-9-0)
    shows promising numbers[15](#page-9-1):


    With results like this, it was expected that the adoption of the Pairwise technique
    to tests production in a cost-effective way would be more welcomed by the industry[16](#page-9-2)
    .


    # 4 Promises of Formal Development


    ### 4.1 Model Driven Development


    One of the most promising approaches to computer program development was MDD (Model
    Drive Development) and MDA (Model Drive Architecture), where models are the primary
    artifacts and the others, such as code, are generated from them [\[68\]](#page-18-2).
    The goal is to raise the level of abstraction, making software development closer
    to solving the requirements and problems outlined by its future users and making
    the developer''s life simpler and easier [\[69](#page-18-3)] and providing mainly
    automation of the process [\[70](#page-18-4)]. According to Yusuf et al. and Swithinbank
    et al., the advantages of using MDD are:


    - Increased developer productivity because of automation and focus on requirements
    analysis

    - Ease of maintenance many software was developed by specialists who left the
    organization at some point, and the technique would facilitate the evolution by
    retaining the knowledge of these specialists

    - Legacy reuse can make it easy and feasible to migrate old applications to new
    systems by applying the technique


    <span id="page-9-1"></span><sup>15</sup>We are aware that this sampling is neither
    meaningful nor representative, but only illustrative from our point of view.


    <span id="page-9-2"></span><sup>16</sup>Informally, in our contacts with software
    development practitioners and testing experts and discussions about the practice
    of Pairwise have ranged from ignorance of its existence to negative concepts and
    objections to its use as ineffective.


    - Adaptability adding or modifying is made easy given the automation already in
    place

    - Consistency every application will strictly follow the pattern established by
    the tools

    - Repetition great return on investment if applied throughout an organization

    - Improved communication with sponsors models are easier to interpret than code

    - Improved project communication templates help to understand the system design
    and assist in the discussion about the system itself

    - Domain knowledge capture if there is sufficient documentation of the system,
    the organization''s knowledge is maintained

    - Long-term asset high-level models and abstractions of business solutions are
    immune to technological change

    - Ability to postpone technology decisions focus on solving business problems
    allows decisions on non-functional problems to be left for a more opportune time


    #### 4.1.1 Problems with models


    The biggest problem with using models as the only source for software production
    is that trying to solve an organizational problem from conceptual abstractions
    larger than the machine languages used by computers to run programs implies a
    reduction of information [\[72](#page-18-5), p. 90]. This information has to be
    supplanted by the MDD tool itself by means of ready-made patterns, or from the
    developer by means of extensions, and that leads, according to Hailpern and Tarr
    [\[69\]](#page-18-3) to other problems:


    - Redundancy because of the widespread use of ready-made code examples

    - Unbridled back and forth problems to adjust the model to conform to another
    system or module

    - Moving complexity elsewhere rather than reducing it, requiring even more specialization


    #### 4.1.2 Future of MDD


    Standardization around UML and tool interoperability around the XMI (XML Metadata
    Interchange)[\[73\]](#page-18-6) standard can lead the open source community to
    produce products that can leverage development using MDD. Tools such as the Eclipse
    Modeling Framework (see <https://www.eclipse.org/modeling/emf/>) is an example
    of technology with this kind of potential, however this leads us to another conclusion.


    #### 4.1.3 Prospects


    Our view is that, the main barrier to the adoption of technologies like MDD, is
    how quickly this kind of solution becomes irrelevant.


    This irrelevance happens as the application and use of information technologies
    and platforms evolve.


    In the 1970s and 1980s, the adoption of CASE (Computer Aided Software Engineering)
    tools, which we can say were the precursors of MDD and MDA, was seen as a solution
    to the same problems we have listed above. At that time software development took
    place mainly on large computers, the Mainframes. But at the same time personal
    computers emerged, which at first were not seen as business tools, this soon became
    an untruth with the release of the IBM PC in 1981[\[74\]](#page-18-7) and since
    then software development has moved from the older and more expensive platform
    (Mainframes) to the more modern and cheaper (PCs (Personal Computers)), and this
    became increasingly true with the adoption of local networks like Novell in 1979
    [\[75](#page-18-8)] with over 500.000 computers installed in the world [\[76\]](#page-18-9)
    at the time. This movement continued, but once again changed focus. In 1989 Tim
    Berners-Lee invented the World Wide Web, in 1993 we had the release of the Mosaic
    browser by NCSA (National Center for Supercomputing Applications), and in 1994
    we had Netscape Navigator created by the same developers, now in a private company
    of the same name. Since then the development has been turning to applications
    presented by the browsers but running on corporate servers on the Internet. In
    early 2007 Apple introduces the iPhone, and at the end of the following year Google
    introduces Android. Still supported by the basic Internet infrastructure, application
    development shifts focus once again to the new mobile platform. And these days,
    some technologies are on the threshold, or at least promise to be, of creating
    new platforms, and among them we can mention Bitcoin (announced in 2009), virtual
    reality (as used in airplane pilot training and introduced as a consumer product
    in the 1990s by computer game companies like Sega in 1991) and augmented reality
    (made popular in games like Pok´emon Go in 2016) and finally the renaissance of
    Artificial Intelligence with the adoption of Machine Learning techniques.


    This rapid evolution and shift of focus to different platforms, with different
    approaches that decisively impact the architecture of the systems, databases,
    operating systems, programming languages, forms of presentation, number of application
    layers, and different APIs (Application Programming Interfaces) employed to mediate
    an increasingly large and complex network of interconnected products and services
    makes it practically impossible to develop, train personnel, and make them productive
    in the employment of any technology with the nature of the MDDs tools, which end
    up being relegated only to the role of modeling, right at the initial requirements
    gathering phase, within a longer development life cycle and without fulfilling
    the promise of covering it completely that has been made since the 1970s and 1980s
    by the CASE[\[77](#page-18-10)] tools, and which, as we saw earlier in this introduction,
    often does not motivate software development professionals and decision makers
    to bear the cost and time required in their absortion and deployment.


    # 5 Conclusions and Future Work


    If in one hand we have the promise of great advances and improvements in the quality
    of software products by applying techniques and tools developed by both academia
    and industry, despite the expected (and even desirable) delay between the development
    and adoption of these new technologies, we also have on the other hand the adoption
    of practices by the industry that make it difficult to incorporate certain mature
    technologies, or even to put them to the test, due to the lack of formalization
    that these practices prescribe in the name of agility in producing products quickly
    and meeting the desires of their customers.


    Without the adoption of formal software development methods, it is not possible
    to continue and progress with the advanced quality methods and methodologies developed
    in academia.


    The solution to this would be a back-and-forth approach, whereby by reverse engineering
    and starting from the source code of the computer programs, formal models are
    deduced and then complemented by the developers in order to produce the artifacts
    and inputs necessary for formal methods of quality verification and validation.
    Automation and adoption of standards are key to keeping costs within acceptable
    parameters for the industry.


    This approach has its pros and cons. Using reverse engineering to produce formal
    models will cause loss of information [17](#page-12-0), and this and other problems
    to come are what we set out to address.


    We intend to continue these studies with an analysis of the State of the Art in
    the conception and production of computer program tests, followed by ways of bringing
    together the methods and practices adopted by industry and the techniques developed
    by academia.


    <span id="page-12-0"></span><sup>17</sup>In general, models should have less information
    than the finished products that originated from them


    # Acronyms


    | API                | Application Programming Interface 12                                                                                  |  |  |

    |--------------------|-----------------------------------------------------------------------------------------------------------------------|--|--|

    | CASE<br>CCS<br>CSP | Computer Aided Software Engineering 12<br>Calculus of Communicating
    Systems 3<br>Communicating Sequential Processes 3 |  |  |

    | FSM                | Finite State Machine 3                                                                                                |  |  |

    | IT                 | Information Technology 2                                                                                              |  |  |

    | LOTOS<br>LTS       | Language Of Temporal Ordering Specification 3<br>Labelled
    Transition Systems 3                                        |  |  |

    | MDA<br>MDD         | Model Drive Architecture 10, 12<br>Model Drive Development
    10–12                                                      |  |  |

    | NCSA<br>NIST       | National Center for Supercomputing Applications 12<br>National
    Institute of Standards and Technology 8                |  |  |

    | OCL                | Object Constraint Language 2                                                                                          |  |  |

    | PC                 | Personal Computer 12                                                                                                  |  |  |

    | TDD                | Test Driven Development 2, 4                                                                                          |  |  |

    | UML                | Unified Modelling Language 2, 11                                                                                      |  |  |

    | XMI<br>XML         | XML Metadata Interchange 11<br>Extensible Markup Language
    11                                                          |  |  |


    # <span id="page-13-0"></span>References


    - <span id="page-13-1"></span>[1] K. Beck et al., "Manifesto for agile software
    development," 2001.

    - [2] B. Ramesh, L. Cao, K. Mohan, and P. Xu, "Can distributed software development
    be agile?" Communications of the ACM, vol. 49, no. 10, pp. 41–46, 2006.

    - <span id="page-13-3"></span>[3] V. One, "14th annual state of agile report,"
    Online: https://stateofagile.com, 2020.

    - <span id="page-13-2"></span>[4] R. Hoda, J. Noble, and S. Marshall, "How much
    is just enough? some documentation patterns on agile projects," in Proceedings
    of the 15th European Conference on Pattern Languages of Programs, 2010, pp. 1–13.

    - <span id="page-14-0"></span>[5] A. Cockburn and J. Highsmith, "Agile software
    development, the people factor," Computer, vol. 34, no. 11, pp. 131–133, 2001.

    - <span id="page-14-1"></span>[6] D. G. Feitelson, E. Frachtenberg, and K. L.
    Beck, "Development and deployment at facebook," IEEE Internet Computing, vol.
    17, no. 4, pp. 8–17, 2013.

    - <span id="page-14-2"></span>[7] G. G. Claps, R. B. Svensson, and A. Aurum, "On
    the journey to continuous deployment: Technical and social challenges along the
    way," Information and Software technology, vol. 57, pp. 21–31, 2015.

    - <span id="page-14-3"></span>[8] M. Hilton, T. Tunnell, K. Huang, D. Marinov,
    and D. Dig, "Usage, costs, and benefits of continuous integration in open-source
    projects," in 2016 31st IEEE/ACM International Conference on Automated Software
    Engineering (ASE), IEEE, 2016, pp. 426–437.

    - <span id="page-14-4"></span>[9] M. Canat, N. P. Catal`a, A. Jourkovski, S. Petrov,
    M. Wellme, and R. Lagerstr¨om, "Enterprise architecture and agile development:
    Friends or foes?" In 2018 IEEE 22nd International Enterprise Distributed Object
    Computing Workshop (EDOCW), IEEE, 2018, pp. 176–183.

    - <span id="page-14-5"></span>[10] K. Beck, "Aim, fire [test-first coding]," IEEE
    Software, vol. 18, no. 5, pp. 87–89, 2001.

    - <span id="page-14-6"></span>[11] J. B. Goodenough and S. L. Gerhart, "Toward
    a theory of test data selection," IEEE Transactions on software Engineering, no.
    2, pp. 156–173, 1975.

    - <span id="page-14-7"></span>[12] T. S. Chow, "Testing software design modeled
    by finite-state machines," IEEE transactions on software engineering, no. 3, pp.
    178–187, 1978.

    - [13] C. A. R. Hoare, "An axiomatic basis for computer programming," Communications
    of the ACM, vol. 12, no. 10, pp. 576–580, 1969.

    - [14] R. W. Floyd, "Toward interactive design of correct programs," in Readings
    in artificial intelligence and software engineering, Elsevier, 1986, pp. 331–
    334.

    - <span id="page-14-8"></span>[15] J. B. Warmer and A. G. Kleppe, The Object Constraint
    Language: Precise Modeling with UML. Addison Wesley, 1999.

    - <span id="page-14-9"></span>[16] M.-C. Gaudel, "Formal methods for software
    testing," in 2017 International Symposium on Theoretical Aspects of Software Engineering
    (TASE), IEEE, 2017, pp. 1–3.

    - <span id="page-14-11"></span><span id="page-14-10"></span>[17] B. Roscoe, "The
    theory and practice of concurrency," 1998.

    - [18] R. Milner, "Lectures on a calculus for communicating systems," in International
    Conference on Concurrency, Springer, 1984, pp. 197–220.

    - <span id="page-14-12"></span>[19] E. Brinksma, "An algebraic language for the
    specification of the temporal order of events in services and protocols," in Proc.
    of the European Teleinformatics Conference, Varese, Italy, 1983, pp. 533–542.

    - <span id="page-14-13"></span>[20] M. de Almeida Xavier, "Defini¸c˜ao e implementa¸c˜ao
    do sistema de tipos da linguagem circus," M.S. thesis, Universidade Federal de
    Pernambuco, 2006.

    - <span id="page-15-1"></span><span id="page-15-0"></span>[21] M. L. Minsky, Computation.
    Prentice-Hall Englewood Cliffs, 1967.

    - [22] E. M. Clarke, E. A. Emerson, and A. P. Sistla, "Automatic verification
    of finite-state concurrent systems using temporal logic specifications," ACM Transactions
    on Programming Languages and Systems (TOPLAS), vol. 8, no. 2, pp. 244–263, 1986.

    - <span id="page-15-11"></span><span id="page-15-2"></span>[23] C. A. Petri and
    W. Reisig, "Petri net," Scholarpedia, vol. 3, no. 4, p. 6477, 2008.

    - [24] B. George and L. Williams, "A structured experiment of test-driven development,"
    Information and software Technology, vol. 46, no. 5, pp. 337– 342, 2004.

    - <span id="page-15-3"></span>[25] F. Shull, G. Melnik, B. Turhan, L. Layman,
    M. Diep, and H. Erdogmus, "What do we know about test-driven development?" IEEE
    software, vol. 27, no. 6, pp. 16–19, 2010.

    - <span id="page-15-4"></span>[26] M. Josefsson, "Making architectural design
    phase obsolete-tdd as a design method," in Seminar course on SQA in Agile Software
    Development Helsinki University of Technology, 2004.

    - <span id="page-15-5"></span>[27] L. Madeyski, "The impact of test-first programming
    on branch coverage and mutation score indicator of unit tests: An experiment,"
    Information and Software Technology, vol. 52, no. 2, pp. 169–184, 2010.

    - <span id="page-15-6"></span>[28] D. Fucci, H. Erdogmus, B. Turhan, M. Oivo,
    and N. Juristo, "A dissection of the test-driven development process: Does it
    really matter to test-first or to test-last?" IEEE Transactions on Software Engineering,
    vol. 43, no. 7, pp. 597–614, 2016.

    - <span id="page-15-7"></span>[29] C. G. Hempel, "Studies in the logic of confirmation
    (i.)," Mind, vol. 54, no. 213, pp. 1–26, 1945.

    - <span id="page-15-8"></span>[30] G. ISO, "Information technology, open systems
    interconnection, conformance testing methodology and framework," International
    Standard IS, vol. 9646, 1991.

    - <span id="page-15-9"></span>[31] E. Dijkstra, "Structured programming," in Classics
    in software engineering, 1979, pp. 41–48.

    - <span id="page-15-10"></span>[32] P. W. Gaffney and J. W. Wooten, "Methods to
    ensure the standardization of fortran software. [pfort, dave, polish, and brnanl,
    for analysis and editing of codes, in fortran for pdp-10 and ibm 360 and 370],"
    May 1980.

    - <span id="page-15-12"></span>[33] A. Aiken, J. M. Hellerstein, and J. Widom,
    "Static analysis techniques for predicting the behavior of active database rules,"
    ACM Transactions on Database Systems (TODS), vol. 20, no. 1, pp. 3–41, 1995.

    - <span id="page-15-13"></span>[34] N. Ayewah, W. Pugh, D. Hovemeyer, J. D. Morgenthaler,
    and J. Penix, "Using static analysis to find bugs," IEEE software, vol. 25, no.
    5, pp. 22– 29, 2008.

    - <span id="page-15-14"></span>[35] R. P. Wilson and M. S. Lam, "Efficient context-sensitive
    pointer analysis for c programs," ACM Sigplan Notices, vol. 30, no. 6, pp. 1–12,
    1995.

    - <span id="page-16-10"></span><span id="page-16-9"></span>[36] I. F. Darwin,
    Checking C Programs with lint. " O''Reilly Media, Inc.", 1988.

    - [37] D. Evans, "Static detection of dynamic memory errors," ACM SIGPLAN Notices,
    vol. 31, no. 5, pp. 44–53, 1996.

    - <span id="page-16-11"></span>[38] D. Jackson, "Aspect: Detecting bugs with abstract
    dependences," ACM Transactions on Software Engineering and Methodology (TOSEM),
    vol. 4, no. 2, pp. 109–145, 1995.

    - <span id="page-16-12"></span>[39] D. L. Detlefs, "An overview of the extended
    static checking system," in Proceedings of The First Workshop on Formal Methods
    in Software Practice, Citeseer, 1996, pp. 1–9.

    - <span id="page-16-13"></span>[40] D. L. Detlefs, K. R. M. Leino, G. Nelson,
    and J. B. Saxe, "Extended static checking," 1998.

    - <span id="page-16-14"></span>[41] J. L. Jensen, M. E. Jørgensen, M. I. Schwartzbach,
    and N. Klarlund, "Automatic verification of pointer programs using monadic second-order
    logic," in Proceedings of the ACM SIGPLAN 1997 conference on Programming language
    design and implementation, 1997, pp. 226–234.

    - <span id="page-16-0"></span>[42] P. Li and B. Cui, "A comparative study on software
    vulnerability static analysis techniques and tools," in 2010 IEEE international
    conference on information theory and information security, IEEE, 2010, pp. 521–524.

    - <span id="page-16-1"></span>[43] C. Hankin and D. Le M´etayer, "Deriving algorithms
    from type inference systems: Application to strictness analysis," in Proceedings
    of the 21st ACM SIGPLAN-SIGACT symposium on Principles of programming languages,
    1994, pp. 202–212.

    - <span id="page-16-2"></span>[44] L. D. Fosdick and L. J. Osterweil, "Data flow
    analysis in software reliability," ACM Computing Surveys (CSUR), vol. 8, no. 3,
    pp. 305–330, 1976.

    - <span id="page-16-3"></span>[45] F. Hayes-Roth, "Rule-based systems," Communications
    of the ACM, vol. 28, no. 9, pp. 921–932, 1985.

    - <span id="page-16-4"></span>[46] R. S. Boyer, B. Elspas, and K. N. Levitt, "Select—a
    formal system for testing and debugging programs by symbolic execution," ACM SigPlan
    Notices, vol. 10, no. 6, pp. 234–245, 1975.

    - <span id="page-16-5"></span>[47] J. C. King, "Symbolic execution and program
    testing," Communications of the ACM, vol. 19, no. 7, pp. 385–394, 1976.

    - <span id="page-16-6"></span>[48] W. E. Howden, "Experiments with a symbolic
    evaluation system," in Proceedings of the June 7-10, 1976, national computer conference
    and exposition, 1976, pp. 899–908.

    - <span id="page-16-7"></span>[49] L. A. Clarke, "A program testing system," in
    Proceedings of the 1976 annual conference, 1976, pp. 488–491.

    - <span id="page-16-8"></span>[50] S. Abramsky and C. Hankin, Abstract interpretation
    of declarative languages. Prentice Hall Professional Technical Reference, 1987.

    - <span id="page-17-0"></span>[51] F. Nielson and N. Jones, "Abstract interpretation:
    A semantics-based tool for program analysis," Handbook of logic in computer science,
    vol. 4, pp. 527–636, 1994.

    - <span id="page-17-1"></span>[52] M. Davis, "The early history of automated deduction:
    Dedicated to the memory of hao wang," in Handbook of Automated Reasoning, Elsevier,
    2001, pp. 3–15.

    - <span id="page-17-2"></span>[53] W. Bibel, "Early history and perspectives of
    automated deduction," in Annual Conference on Artificial Intelligence, Springer,
    2007, pp. 2–18.

    - <span id="page-17-3"></span>[54] E. M. Clarke Jr, O. Grumberg, D. Kroening,
    D. Peled, and H. Veith, Model checking. MIT press, 2018.

    - <span id="page-17-4"></span>[55] B. Johnson, Y. Song, E. Murphy-Hill, and R.
    Bowdidge, "Why don''t software developers use static analysis tools to find bugs?"
    In 2013 35th International Conference on Software Engineering (ICSE), IEEE, 2013,
    pp. 672–681.

    - <span id="page-17-5"></span>[56] S. Panichella, V. Arnaoudova, M. Di Penta,
    and G. Antoniol, "Would static analysis tools help developers with code reviews?"
    In 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and
    Reengineering (SANER), IEEE, 2015, pp. 161–170.

    - <span id="page-17-6"></span>[57] F. Zampetti, S. Scalabrino, R. Oliveto, G.
    Canfora, and M. Di Penta, "How open source projects use static code analysis tools
    in continuous integration pipelines," in 2017 IEEE/ACM 14th International Conference
    on Mining Software Repositories (MSR), IEEE, 2017, pp. 334–344.

    - <span id="page-17-7"></span>[58] M. Agnihotri and A. Chug, "A systematic literature
    survey of software metrics, code smells and refactoring techniques," Journal of
    Information Processing Systems, vol. 16, no. 4, pp. 915–934, 2020.

    - <span id="page-17-9"></span>[59] G. J. Myers, T. Badgett, T. M. Thomas, and
    C. Sandler, The art of software testing. Wiley Online Library, 2004, vol. 2.

    - <span id="page-17-8"></span>[60] I. ( O. for Standardization), Iso/iec/ieee
    24765: 2017 systems and software engineering-vocabulary, 2017.

    - <span id="page-17-10"></span>[61] C. A. R. Hoare, "How did software get so reliable
    without proof?" In International Symposium of Formal Methods Europe, Springer,
    1996, pp. 1– 17.

    - <span id="page-17-11"></span>[62] D. MacKenzie, "Computer-related accidental
    death: An empirical exploration," Science and Public Policy, vol. 21, no. 4, pp.
    233–248, 1994.

    - <span id="page-17-12"></span>[63] S. Planning, "The economic impacts of inadequate
    infrastructure for software testing," National Institute of Standards and Technology,
    2002.

    - <span id="page-17-13"></span>[64] S. R. Webb, "Design, testing and estimation
    in complex experimentation. i. expansible and contractible factorial designs and
    the application of linear programming to combinatorial problems," ROCKETDYNE CANOGA
    PARK CA, Tech. Rep., 1965.

    - <span id="page-17-14"></span>[65] D. Du, F. K. Hwang, and F. Hwang, Combinatorial
    group testing and its applications. World Scientific, 2000, vol. 12.

    - <span id="page-18-0"></span>[66] C. B. Monteiro, L. A. V. Dias, and A. M. da
    Cunha, "A case study on pairwise testing application," in 2014 11th International
    Conference on Information Technology: New Generations, IEEE, 2014, pp. 639–640.

    - <span id="page-18-1"></span>[67] A. C. da Silva, L. R. Correa, L. A. V. Dias,
    and A. M. da Cunha, "A case study using testing technique for software as a service
    (saas)," in 2015 12th International Conference on Information Technology-New Generations,
    IEEE, 2015, pp. 761–762.

    - <span id="page-18-2"></span>[68] L. Yusuf, M. Chessel, and T. Gardner, "Implement
    model-driven development to increase the business value of your it system," Retrieved
    January, vol. 29, p. 2008, 2006.

    - <span id="page-18-3"></span>[69] B. Hailpern and P. Tarr, "Model-driven development:
    The good, the bad, and the ugly," IBM systems journal, vol. 45, no. 3, pp. 451–461,
    2006.

    - <span id="page-18-4"></span>[70] R. Jacobs, ARCast with Ron Jacobs, English.
    [Online]. Available: [https://channel9.msdn.com/Shows/AR](https://channel9.msdn.com/Shows/ARCast+with+Ron+Jacobs/ARCast-5)
    (visited on 11/19/2020).

    - [71] P. Swithinbank et al., Patterns: Model-Driven Development Using IBM Rational
    Software Architect. IBM, International Technical Support Organization, 2005.

    - <span id="page-18-6"></span><span id="page-18-5"></span>[72] S. K. Langer, Feeling
    and form. Routledge and Kegan Paul London, 1953, vol. 3.

    - [73] O. M. Group, XML Metadata Interchange, English, Technology Standards Consortium,
    Jun. 2015. [Online]. Available: <https://www.omg.org/spec/XMI/About-XMI/>.

    - <span id="page-18-7"></span>[74] M. J. Miller, Why the IBM PC had an Open Architecture,
    English, News Site, publisher: Ziff Davis, Aug. 2011. [Online]. Available: [https://www.pcmag.com/archive/why-the-ib](https://www.pcmag.com/archive/why-the-ibm-pc-had-an-open-architecture-286065)

    - <span id="page-18-8"></span>[75] L. Proven, How the clammy claws of Novell NetWare
    were torn from today''s networks, English, News Site, publisher: Situation Publishing,
    Jul. 2013. [Online]. Available: [https://www.theregister.com/2013/07/16/netware\\_4\\_anniversary/](https://www.theregister.com/2013/07/16/netware_4_anniversary/).

    - <span id="page-18-9"></span>[76] R. Payne and K. Manweiler, CCIE: Cisco Certified
    Internetwork Expert Study Guide: Routing and Switching. John Wiley & Sons, 2006.

    - <span id="page-18-10"></span>[77] V. J. Mercurio, B. F. Meyers, A. M. Nisbet,
    and G. Radin, "Ad/cycle strategy and architecture," IBM Systems Journal, vol.
    29, no. 2, pp. 170– 188, 1990.'
- title: On Augmenting Scenario-Based Modeling with Generative AI
  abstract: 'The manual modeling of complex systems is a daunting task; and although
    a

    plethora of methods exist that mitigate this issue, the problem remains very

    difficult. Recent advances in generative AI have allowed the creation of

    general-purpose chatbots, capable of assisting software engineers in various

    modeling tasks. However, these chatbots are often inaccurate, and an

    unstructured use thereof could result in erroneous system models. In this

    paper, we outline a method for the safer and more structured use of chatbots as

    part of the modeling process. To streamline this integration, we propose

    leveraging scenario-based modeling techniques, which are known to facilitate

    the automated analysis of models. We argue that through iterative invocations

    of the chatbot and the manual and automatic inspection of the resulting models,

    a more accurate system model can eventually be obtained. We describe favorable

    preliminary results, which highlight the potential of this approach.'
  url: http://arxiv.org/abs/2401.02245v1
  keywords: ''
  document: '# On Augmenting Scenario-Based Modeling with Generative AI


    David Harel<sup>1</sup> , Guy Katz<sup>2</sup> , Assaf Marron<sup>1</sup> , and
    Smadar Szekely<sup>1</sup>


    <sup>1</sup>*Weizmann Institute of Science, Rehovot, Israel*


    <sup>2</sup>*The Hebrew University of Jerusalem, Jerusalem, Israel*


    *dharel@weizmann.ac.il, guykatz@cs.huji.ac.il, assaf.marron@weizmann.ac.il, smadarsz@gmail.com*


    Keywords: Generative AI, chatbots, scenario-based modeling, rule-based specifications


    Abstract: The manual modeling of complex systems is a daunting task; and although
    a plethora of methods exist that mitigate this issue, the problem remains very
    difficult. Recent advances in generative AI have allowed the creation of general-purpose
    chatbots, capable of assisting software engineers in various modeling tasks. However,
    these chatbots are often inaccurate, and an unstructured use thereof could result
    in erroneous system models. In this paper, we outline a method for the safer and
    more structured use of chatbots as part of the modeling process. To streamline
    this integration, we propose leveraging scenario-based modeling techniques, which
    are known to facilitate the automated analysis of models. We argue that through
    iterative invocations of the chatbot and the manual and automatic inspection of
    the resulting models, a more accurate system model can eventually be obtained.
    We describe favorable preliminary results, which highlight the potential of this
    approach.


    ## 1 INTRODUCTION


    Manually modeling complex systems is a daunting and error-prone endeavor. Furthermore,
    even after the system is modeled, ongoing tasks, such as modification and repair,
    continue to tax human engineers. Creating tools and methodologies for streamlining
    and facilitating this process has been the topic of extensive work, but many aspects
    of the problem remain unsolved [\(Pettersson and Andersson, 2016;](#page-11-0)
    [Biolchini](#page-10-0) [et al., 2005\)](#page-10-0).


    In recent years, the deep learning revolution has been causing dramatic changes
    in many areas, including computer science; and this revolution has recently taken
    yet another step towards general-purpose AI, with the release of ChatGPT, the
    learning-based chatbot [\(OpenAI, 2022\)](#page-11-1). ChatGPT, and other, similar
    tools [\(Google, 2023;](#page-10-1) [MetaAI, 2023\)](#page-11-2), can be used
    for countless kinds of tasks — including the modeling and coding of complex systems
    [\(Surameery and](#page-11-3) [Shakor, 2023\)](#page-11-3). An engineer might
    provide ChatGPT with a natural-language description of the system at hand, and
    receive in return a model of the system, or even computer code that implements
    it; and through iterative querying of ChatGPT, the system can later be modified
    or enhanced. This approach has already been used in several application domains
    [\(Surameery](#page-11-3) [and Shakor, 2023;](#page-11-3) [Burak et al., 2023;](#page-10-2)
    [Liu et al., 2023\)](#page-11-4).


    Although the ability to integrate ChatGPT[1](#page-0-0) into the software development
    cycle will undoubtedly empower engineers, there are also potential pitfalls that
    need to be taken into account. One drawback of Chat-GPT and similar tools is that
    the answers they provide are often inaccurate, and might overlook important aspects
    of the input query [\(Liu et al., 2023\)](#page-11-4). Moreover, the input query
    itself might be imperfect, and the engineer might not realize this until the system
    is deployed. Thus, if we make the reasonable assumption that human engineers will
    gradually become dependent on chatbots for various tasks, the risk increases that
    these inaccuracies will find their way into the final models of the system at
    hand and the code that ensues. We are thus faced with the following challenge:
    how can we harness ChatGPT in a way that lifts a significant load of work off
    the shoulders of the engineers, but which still results in sound and accurate
    models?


    Here, we advocate the creation of an encompassing modeling scheme that will combine
    ChatGPT with more traditional techniques for manual modeling of systems [\(Biolchini
    et al., 2005;](#page-10-0) [Pettersson and](#page-11-0) [Andersson, 2016\)](#page-11-0),
    in a way that will achieve this goal. Our core idea is to use ChatGPT in a controlled
    way; i.e., to repeatedly invoke it for various tasks, but to


    <span id="page-0-0"></span><sup>1</sup>We will often use the term *ChatGPT* somewhat
    generically, to represent an arbitrary, modern chatbot.


    then thoroughly inspect and analyze its results, to ensure their soundness and
    accuracy. We argue that such a scheme, if designed properly, would allow software
    and system engineers to benefit from the capabilities of modern chatbots, but
    without jeopardizing the quality of the resulting products. In the long run, we
    regard such a scheme as a step towards the *Wise Computing* vision [\(Harel et
    al., 2018\)](#page-10-3), which calls for turning the computer into a proactive
    member of the software development team — one which can propose courses of action,
    detect under-specified portions of the model, and assist in the various routine
    actions that naturally arise as part of the software development cycle.


    In order to design such a modeling scheme, we propose to leverage the extensive
    work carried out in the modeling community over the years. Specifically, we propose
    to focus on modeling frameworks that afford two benefits that complement the capabilities
    of ChatGPT: (i) the models produced by the framework are naturally well-aligned
    with how humans perceive systems; this, we believe, will make it easier for the
    human engineer to inspect ChatGPT''s output; and (ii) the resulting models are
    amenable to automated analysis tasks, such as model checking, which will support
    the automated detection of bugs and inconsistencies in the automatically generated
    models.


    Several modeling approaches fit this description, and many of them can probably
    be used, but for the initial evaluation presented here, we focus on *scenario-based
    modeling* (*SBM*) — a technique that generates models comprised of simple *scenarios*,
    each of which describes a single aspect of the system at hand [\(Harel et al.,
    2012b;](#page-11-5) [Damm and Harel,](#page-10-4) [2001\)](#page-10-4). As we
    later discuss, this can facilitate the smooth collaboration between ChatGPT and
    the human engineers.


    To demonstrate the potential of this combined framework, we focus on a few tasks
    that arise naturally as part of a system''s life cycle. Specifically, we discuss
    the initial design of the model, its testing and the verification of its properties,
    its later enhancement or repair due to the discovery of inconsistencies, and also
    a search for under-specified portions of the model. Our results, although preliminary,
    are very promising, and we hope this paper will form a basis for further research
    in this direction.


    In the remainder of the paper, we present the key concepts of our approach, and
    discuss a high-level plan for the next steps. We begin by introducing the concepts
    of SBM and language model-based chatbots in Section [2.](#page-1-0) Next, we present
    the proposed integration of SBM and ChatGPT in Section [3,](#page-3-0) followed
    by a discussion of some of the more advanced aspects of this integration in Section
    [4.](#page-5-0) We discuss related work in Section [5](#page-9-0) and conclude
    in Section [6.](#page-9-1)


    # <span id="page-1-0"></span>2 BACKGROUND


    # 2.1 Large Language Model-Based Chatbots


    ChatGPT (Chat Generative Pre-trained Transformer) is a large language model (LLM)
    based chatbot, developed by OpenAI [\(OpenAI, 2022;](#page-11-1) [Chang et al.,](#page-10-5)
    [2023\)](#page-10-5). The chatbot is able to conduct an iterative conversation
    of variable length, format, style, level of detail, and language. At each stage,
    the user presents a new prompt to ChatGPT, which then replies, based on all previous
    prompts in that conversation (the context). Following its debut in 2022, ChatGPT
    quickly became highly successful, and inspired multiple other companies to release
    their own chatbots [\(Google,](#page-10-1) [2023;](#page-10-1) [MetaAI, 2023\)](#page-11-2).


    Internally, ChatGPT is implemented using a proprietary series of generative pre-trained
    transformer (GPT) models, which in turn are based on Google''s transformer architecture
    [\(Vaswani et al., 2017\)](#page-11-6). Chat-GPT is fine-tuned for conversational
    applications, through a combination of supervised and reinforcement learning techniques,
    as well as manual adjustment by human engineers. ChatGPT''s training, as well
    as its inference, are considered very costly in terms of power consumption and
    processing resources.


    Functionality-wise, ChatGPT is highly versatile. Some of its many uses include
    generating student essays [\(AlAfnan et al., 2023\)](#page-10-6), writing and
    debugging computer programs [\(Surameery and Shakor, 2023\)](#page-11-3), and
    composing music [\(Lu et al., 2023\)](#page-11-7). However, it will sometimes
    produce plausible-sounding but incorrect or nonsensical answers — a common limitation
    for large language models [\(Gregorcic and Pendrill,](#page-10-7) [2023\)](#page-10-7).


    #### 2.2 Scenario-Based Modeling


    Scenario-based modeling [\(Harel et al., 2012b\)](#page-11-5) (SBM) is a modeling
    approach aimed at modeling complex, reactive systems. The main component in a
    scenario-based (SB) model is the *scenario object*, which describes a single behavior
    of the system at hand, whether desirable or undesirable, so that one can specify
    it as necessary, allowed or forbidden. Each scenario object does not directly
    interact with its counterparts, and can be created in isolation. Crossscenario
    interaction is allowed only through a global execution mechanism, which can execute
    a collection of scenarios in a manner that produces cohesive, global behavior.


    There exist several flavors of SBM, employing slightly different mechanisms for
    cross-scenario interactions. We focus here on a particular set of idioms, which
    has become quite popular: the *requesting*, *waiting-for* and *blocking* of discrete
    events [\(Harel](#page-11-5) [et al., 2012b\)](#page-11-5). During execution,
    each scenario object repeatedly visits designated *synchronization points*, and
    in each of these the global execution mechanism selects one event for triggering.
    A scenario object may declare events that it wishes to be triggered (*requested*
    events), events that it wishes to avoid (*blocked* events), and also events it
    does not request itself but would like to monitor (*waited-for events*). The execution
    mechanism collects these declarations from each of the scenario objects (or a
    subset thereof [\(Harel et al., 2013a\)](#page-10-8)), selects one event that
    is requested and not blocked, and then informs all relevant scenario objects of
    this selection.


    In a given synchronization point, multiple events may be requested and not blocked,
    and several strategies have been proposed for selecting one of them. These include
    an arbitrary selection, a random selection, a round-robin mechanism, and look-ahead
    that simulates possible progression of the execution and selects events with an
    attempt to achieve a desirable objective specified a-priori (e.g., the avoidance
    of deadlocks). Executing a scenario-based program in this manner is termed play-out
    [\(Harel and Marelly,](#page-11-8) [2003\)](#page-11-8)).


    Fig. [1](#page-2-0) depicts a simple example of an SB model. The system at hand
    controls the water level in a water tank, which is equipped with hot and cold
    water taps. Each scenario object appears as a transition system, in which nodes
    corresponds to the predetermined synchronization points. Scenario object ADDHOT-WATER
    repeatedly waits for WATERLOW events, and when such an event is triggered, it
    requests three times the event ADDHOT. Similarly, scenario object AD-DCOLDWATER
    requests the addition of cold water. When the model includes only objects ADDHOTWA-TER
    and ADDCOLDWATER, three ADDHOT events and three ADDCOLD events may be triggered
    in any order during execution. If we wish to maintain a more stable water temperature
    within the tank, we might add the scenario object STABILITY, to enforce the interleaving
    of ADDHOT and ADDCOLD — through the use of event blocking. An execution trace
    of the model containing all three objects appears in the event log.


    The SBM framework has been implemented on top of multiple high-level languages,
    including


    <span id="page-2-0"></span>


    | ADDHOTWATER          | ADDCOLDWATER         | STABILITY | EVENT LOG |

    |----------------------|----------------------|-----------|-----------|

    |                      |                      | wait for  |           |

    | wait for<br>WATERLOW | wait for<br>WATERLOW | ADDHOT    | ···       |

    |                      |                      | while     | WATERLOW  |

    | request              | request              | blocking  | ADDHOT    |

    | ADDHOT               | ADDCOLD              | ADDCOLD   | ADDCOLD   |

    |                      |                      |           | ADDHOT    |

    | request              | request              | wait for  | ADDCOLD   |

    | ADDHOT               | ADDCOLD              | ADDCOLD   | ADDHOT    |

    |                      |                      | while     | ADDCOLD   |

    | request              | request              | blocking  | ···       |

    | ADDHOT               | ADDCOLD              | ADDHOT    |           |


    Figure 1: A scenario-based model for a system that controls the water level in
    a tank with hot and cold water taps (taken from [\(Harel et al., 2014\)](#page-11-9)).


    Java [\(Harel et al., 2010\)](#page-11-10), C++ [\(Harel and Katz, 2014\)](#page-10-9),
    Python [\(Yaacov, 2023\)](#page-11-11), JavsScript [\(Bar-Sinai et al.,](#page-10-10)
    [2018\)](#page-10-10) and ScenarioTools [\(Greenyer et al., 2017\)](#page-10-11).
    Furthermore, SBM has been applied in modeling various complex systems, such as
    web-servers [\(Harel](#page-10-9) [and Katz, 2014\)](#page-10-9), cache coherence
    protocols [\(Harel](#page-10-12) [et al., 2016a\)](#page-10-12) and robotic controllers
    [\(Gritzner and](#page-10-13) [Greenyer, 2018\)](#page-10-13). In order to simplify
    the presentation in the following sections, we mostly describe SB models as transitions
    systems.


    In formally defining SBM, we follow the definitions of [\(Katz, 2013\)](#page-11-12).
    A scenario object *O* over event set *E* is a tuple *O* = ⟨*Q*,δ,*q*0,*R*,*B*⟩,
    where the components are interpreted as follows:


    - *Q* is the set of states. Each state represents a single, predetermined synchronization
    point;

    - *q*<sup>0</sup> ∈ *Q* is the initial state;

    - *R* : *Q* → 2 *E* and *B* : *Q* → 2 *<sup>E</sup>* map states to the sets of
    events requested and blocked at these states, respectively; and

    - δ : *Q*×*E* → 2 *<sup>Q</sup>* is the transition function, which indicates how
    the object switches states in response to the triggering of events.


    Once the individual scenario objects are created, they can be composed in a pairwise
    fashion. Two scenario objects *O* <sup>1</sup> = ⟨*Q* 1 ,δ 1 ,*q* 1 0 ,*R* 1 ,*B*
    1 ⟩ and *O* <sup>2</sup> = ⟨*Q* 2 ,δ 2 ,*q* 2 0 ,*R* 2 ,*B* 2 ⟩, specified over
    a common set of events *E*, can be composed into a single scenario object *O*
    <sup>1</sup> ∥ *O* <sup>2</sup> = ⟨*Q* <sup>1</sup> ×*Q* 2 ,δ,⟨*q* 1 0 ,*q* 2
    0 ⟩,*R* <sup>1</sup> ∪*R* 2 ,*B* <sup>1</sup> ∪*B* 2 ⟩, where:


    - ⟨*q*˜ 1 ,*q*˜ 2 ⟩ ∈ δ(⟨*q* 1 ,*q* 2 ⟩, *e*) if and only if ˜*q* <sup>1</sup>
    ∈ δ 1 (*q* 1 , *e*) and ˜*q* <sup>2</sup> ∈ δ 2 (*q* 2 , *e*); and

    - the union of the labeling functions is defined in the natural way; i.e., *e*
    ∈ (*R* <sup>1</sup> ∪ *R* 2 )(⟨*q* 1 ,*q* 2 ⟩) if and only if *e* ∈ *R* 1 (*q*
    1 ) ∪ *R* 2 (*q* 2 ), and *e* ∈ (*B* <sup>1</sup> ∪ *B* 2 )(⟨*q* 1 ,*q* 2 ⟩) if
    and only if *e* ∈ *B* 1 (*q* 1 )∪*B* 2 (*q* 2 ).


    Using the composition operator ∥, we can define a *behavioral model M* as a collection
    of scenario objects, *M* = {*O* 1 ,*O* 2 ,...,*O <sup>n</sup>*}. The executions
    of *M* are defined to be the executions of the single, composite object *O* =
    *O* <sup>1</sup> ∥ *O* <sup>2</sup> ∥ ... ∥ *O n* . Thus, each execution starts
    from the initial state of *O*, which is the *n*tuple of the initial states of
    its constituent objects, and throughout the run, in each state *q* an enabled
    event *e* ∈ *R*(*q*)−*B*(*q*) is chosen for triggering, if one exists. The execution
    then moves to a state ˜*q* ∈ δ(*q*, *e*), and the process repeats.


    # <span id="page-3-0"></span>3 INTEGRATING CHATGPT AND SBM


    ### 3.1 Basic Integration


    As a first step to integrating ChatGPT and SBM, we present a simple methodology
    for creating scenario objects from free-text, using ChatGPT. In order to get ChatGPT
    to present its output as a scenario object, we propose to include in each query
    a *preamble* that describes the SBM semantics, as described in Section [2.](#page-1-0)
    This preamble instructs ChatGPT to present its output as a transition system,
    in which each state is labeled with requested and blocked events, and has a set
    of transition rules indicating its successor state, based on the event later triggered.
    Note that this preamble needs only be crafted once, and can then be attached to
    any subsequent query. If a specific implementation of SBM is used (e.g., C++,
    Java), the output can be crafted to match the required syntax of that implementation.


    The simple preamble that we used in our initial experiments is as follows:


    I would like you to help me create a scenariobased model. A scenario-based model
    is comprised of a finite set of events, and scenarios. Each scenario is a sequence
    of states. In each state the scenario can request events, wait-for events, and
    block events. Afterwards, one event that is requested by at least one scenario,
    but is blocked by no scenario, is selected for triggering. Scenarios that requested
    or waited-for this scenario may then change states, and the process repeats itself.
    Scenarios cannot have internal loops or variables; these must be expressed using
    additional states.


    To display scenarios, please use the following format. For each state, mention
    the state''s name, and the sets of requested and blocked events. Also, mention
    the transitions to other states. For example:


    - s1: request X, block Y. If X is triggered, go to state s2.

    - s2: request Y, block X. If Y is triggered, go to state s2.

    - Now, here are the details of the specific scenario-based model I''d like you
    to create. . .


    Given this preamble, we can use ChatGPT to produce the model we described in Section
    [2.](#page-1-0) To produce the ADDHOTWATER scenario, we use the following prompt:


    Consider the event set WaterLow, AddHot, AddCold.


    Please suggest a scenario that waits for event WaterLow (without requesting it).
    When Water-Low is triggered, the scenario performs the following, 3 times in a
    row: request the event AddHot, and wait for it to be triggered (both in a single
    state). When the 3rd AddHot event occurs, the scenario transitions back to its
    initial state.


    In response to this prompt, the chatbot replies:


    - s1: wait for WaterLow. If WaterLow is triggered, go to state s2.

    - s2: request AddHot, wait for AddHot. If AddHot is triggered, go to state s3.

    - s3: request AddHot, wait for AddHot. If AddHot is triggered, go to state s4.

    - s4: request AddHot, wait for AddHot. If AddHot is triggered, go to state s1.


    Which is equivalent to the transition system we presented in Fig. [1.](#page-2-0)
    The ADDCOLDWATER scenario can be generated symmetrically. Now, if we wish to incrementally
    modify the system by introducing the STA-BILITY scenario, we can issue the following
    prompt:


    Please suggests a scenario that ensures that uses blocking to ensure that no two
    consecutive AddHot events can be triggered, and that no two consecutive AddCold
    events can be triggered; that is, once AddHot is triggered, AddCold must be triggered
    before AddHot can be triggered again, and vice versa. This scenario should not
    request any events, and should work regardless of any WaterLow events.


    And in response, the chatbot produces the STABILITY scenario, as described in
    Fig. [1.](#page-2-0)


    We note a subtle difference between the way we prompted ChatGPT for the first
    two scenarios, ADDHOTWATER and ADDCOLDWATER, and our prompting for STABILITY.
    In the former two cases, our prompt contained information that roughly described
    the transition system itself, whereas in the third case our description was more
    high-level, and did not mention the word "state". Still, in both cases, ChatGPT
    produced the desired result. This demonstrates the wide range of specifications
    with which the chatbot can successfully deal, and suggests that it can be used
    even when the engineers are themselves not entirely certain of the structure of
    the scenario they require. While it stands to reason that more accurate descriptions
    would lead to more accurate results, it appears that even high-level descriptions
    can be very useful, especially when combined with the automated analysis techniques
    that we discuss next.


    ### 3.2 The Proposed Methodology


    Building upon this basic integration of ChatGPT and SBM, we now outline a structured
    LLM-agnostic and language-agnostic methodology for creating complex *reactive
    models*, i.e., models of systems that interact with their environment repeatedly
    over time, and receive external inputs [\(Harel and Pnueli, 1985\)](#page-11-13).
    Numerous modern, critical systems can be regarded as reactive [\(Aceto et al.,
    2007\)](#page-10-14), and consequently there has been extensive research on developing
    tools and methods for modeling these systems. Despite this tremendous effort,
    there still remain significant gaps, which could result in models that are inaccurate
    or that are difficult to maintain. The present work, which can be seen as an element
    of the Wise Computing vision [\(Harel et al., 2018\)](#page-10-3), seeks to mitigate
    these gaps, through the creation of advanced, intelligent tools that will begin
    to undertake the software and system development tasks that are normally assigned
    to humans. The core of the approach is to have system components be generated,
    iteratively and incrementally, with the help of an LLM; and to have the LLM''s
    outputs checked systematically, and perhaps automatically, using various tools
    and methods.


    - 1. Describe the problem and the environment textually, in natural language.

    - 2. Choose a compositional, scenario-based modeling language, which has well-defined
    execution semantics and is suitable for the incremental development of the system.

    - 3. Obtain an LLM that is familiar with the application domain in general, or
    can readily gain extensive knowledge about that domain, and which can (or can
    be taught to) generate code in the chosen scenario-based language.

    - 4. Describe, perhaps iteratively, the semantics of the scenario-based language
    to the LLM as a preamble. Confirm that the LLM indeed internalizes the details
    of the language semantics by teaching it to execute (i.e., play out [\(Harel and
    Marelly, 2003\)](#page-11-8)) systems described as scenarios or rules in the chosen
    language, where the LLM outputs logs of triggered events, scenario states, composite
    system states, values of environment variables and changes thereto, etc.

    - 5. Iteratively add scenarios and refine existing ones, as follows:

    - (a) Describe in a prompt one or more scenarios for certain not-yet-specified
    requirements or aspects of the system.

    - (b) Have the LLM generate actual scenarios for the prompt, in the chosen language.

    - (c) Have the LLM generate natural language description of properties to be verified,
    executable test cases, and assertions for formal verification tools, per the original
    requirements. This constitutes stating the requirement at hand from different
    perspectives.

    - (d) Carry out initial testing and validation within the LLM, challenging the
    LLM to find gaps and incorrect execution paths on its own. Correct the natural
    language specification and prompts as needed.

    - (e) Systematically check the LLM output outside of the LLM, using any or all
    of the following: code reviews by human engineers, unit testing of individual
    scenarios, subsystem testing with some or all of the already-developed scenarios,
    model checking of the new scenarios, as well as those of the composite system,
    etc. The testing is to be carried out in the execution environment of the language,
    and model checking is to be carried out using a suitable formal verification tool.
    Both should be independent of the LLM environment. Possibly automate the subjecting
    of generated scenarios to testing and model checking.

    - (f) When errors are found, do not modify the generated code. Instead, revise
    the LLM prompts until correct system scenarios and verification and testing properties
    are generated. This step is critical for aligning the stakeholder (i.e., customer)
    view of the requirements, the developer''s understanding, and the actual code.

    - (g) Once the set of generated scenarios seems ready, repeat the likes of step
    (d), asking the LLM to find gaps or potential failures in this set of scenarios;
    specifically look for LLM


    suggestions of new environment considerations that prevent the system from working
    correctly. This step simulates the common system engineering task of having external
    experts or potential customers review advanced prototypes of systems. Repeat earlier
    steps as needed.


    Next, we elaborate on some of these steps, and provide simple, illustrative examples.


    # <span id="page-5-0"></span>4 USING THE METHOD IN THE DEVELOPMENT CYCLE


    #### 4.1 Code Generation


    Code generation is probably the most straightforward chatbot capability that we
    propose be integrated into the development cycle. In Section [3](#page-3-0) we
    showed that ChatGPT can generate an (executable) SB model — a capability that
    has also been demonstrated with other languages [\(Surameery and Shakor, 2023;](#page-11-3)
    [Burak et al.,](#page-10-2) [2023;](#page-10-2) [Liu et al., 2023\)](#page-11-4).
    A unique advantage in the context of SB systems is the ability to generate standalone
    scenarios, which can be reviewed and tested separately, and then be incrementally
    added to the system under development. In our preliminary testing for this paper,
    we experimented with code generation for requirements in the realms of autonomous
    vehicles, algorithms on data structures, simulating natural phenomena, and control
    systems. In all of these, the ChatGPT/SBM integration proved useful.


    #### 4.2 Modeling


    Once ChatGPT understood the principles underlying scenario-based models, it was
    able to combine its knowledge of the problem domain, the world at large, and logic,
    in order to develop or enhance a model. It was able to introduce new environment
    events, describe the sensor scenarios that are required for triggering these events,
    and then add the necessary application scenarios that react to these events. For
    example, when we asked ChatGPT to generate scenariobased code for a bubble-sort
    algorithm to be used by a robot moving numbered tiles on a sequence of cells,
    it was able to introduce the events of detecting the arrival of a tile at the
    tail-end of the array, as well as scenarios for reacting to such events.


    #### 4.3 Play Out & Simulation


    After a few iterations, we were able to teach ChatGPT to produce an execution
    log of an arbitrary scenariobased specification. At first we observed "wishful
    thinking", where ChatGPT described the run as it should be per the problem description.
    However, as illustrated in Fig. [2,](#page-6-0) ChatGPT was then able to follow
    the execution steps correctly, displaying at each synchronization point the event
    that triggered the state transition that led to this synchronization point, and
    a table of all scenarios, indicating for each one whether or not it was put into
    action by the triggered event, and providing its declaration of requested, blocked
    and waited-for events.


    #### 4.4 SMT-Like Model Analysis


    One of the advantages of scenario-based modeling is its amenability to formal
    verification with appropriate tools, both by exhaustive model checking traversing
    all paths, and by using domain knowledge for Satisfiability Modulo Theory (SMT)
    verification [\(Harel et al.,](#page-11-14) [2011;](#page-11-14) [Harel et al.,
    2013b\)](#page-10-15). This is accomplished by virtue of the abstraction and encapsulation
    of domainspecific processes, actions and conditions as events and states. System
    complexity thus emerges from the composition of relatively small intuitive scenarios
    reflecting individual requirements, and not from the intricate conditional flow
    of delicate and sensitive processes with numerous steps.


    Our experiments have shown that ChatGPT is able to leverage this kind of abstraction
    and encapsulation to identify cases that a specification either omitted or handles
    incorrectly. For example, we presented ChatGPT with the following three requirements
    for an autonomous vehicle: (i) always stop at a red light; (ii) always obey a
    police person''s instructions; (iii) never injure a person. ChatGPT readily recognized
    that these requirements may be in conflict with each other. Given the safety property
    of not entering an intersection when the traffic light is red, it pointed out
    that the AV may be unable to stop if the road is icy, that it may enter the intersection
    involuntarily if after stopping it is hit from behind by a car that did not stop,
    and, furthermore, that it may injure a person without moving, if a person walks
    behind the AV, and another vehicle hits the person who is then thrust against
    the AV.


    In a mathematical, SMT-like analysis, ChatGPT was able to identify a particularly
    interesting execution path. We presented it with a system consisting of the following
    four scenarios: the first requests flashing a red light briefly in response to
    an external time tick event, and then waits for any event; the second does the
    same with a green light; the third scenario blocks the event of flashing the red
    light every third tick, and another blocks flashing the green light every


    <span id="page-6-0"></span>


    | Scenario Short name   Wake-up   Requested |   |   |                   | Blocked   Waited
    for |  |

    |-------------------------------------------|---|---|-------------------|----------------------|--|

    |                                           |   |   |                   |                      |  |

    | GI                                        |   | Y | Flash Green Light |                      |  |

    | RT.                                       | Y |   | Flash Red Light   |                      |  |

    | ALTG                                      |   | Y |                   | Flash
    Green Light    |  |

    | ALTR                                      |   | Y |                   | Flash
    Red Light      |  |


    | Scenario Short name   Wake-up   Requested |             |                                      |
    Blocked | Waited for                                            |

    |-------------------------------------------|-------------|--------------------------------------|---------|-------------------------------------------------------|

    | GL<br>RL<br>ALTG<br>ALTR                  | N<br>Y<br>N | Flash Green Light<br>Flash
    Red Light |         | Flash Green Light  Flash Red Light<br>Flash Red Light |


    Figure 2: *A simulation of scenario execution with ChatGPT.* Top: textual description
    of scenarios in user prompts. Middle and bottom: The first two entries in ChatGPT''s
    output when requested to play out the execution, showing triggered events, the
    scenarios that reacted to the triggered events, and the declarations of each scenario
    at the next synchronization point.


    five ticks. We then added the requirement that at least one light must be flashed
    between any two consecutive time ticks. ChatGPT was able to respond that the requirement
    is not satisfied, and that every 15 time ticks (3 · 5) both events will be blocked.
    ChatGPT apparently recognized this by arithmetic calculation and not by step-by-step
    simulation, as it was able to quickly reach the same conclusion for arbitrarily
    large numbers.


    Here is an excerpt from this conversation, after describing the scenarios. When
    prompted with


    now a new requirement came in: always, after every tick, *at least one light*
    must be flashed. Does the combined system of red flashing and green flashing with
    the 3 and 5 restrictions satisfy the requirement?


    ChatGPT replies:


    To analyze whether the combined system satisfies the new requirement that at least
    one light must flash after every tick, we must consider the synchronization points
    of both the red and green systems with their respective restrictions:


    The red system flashes on every tick, except every third one. The green system
    flashes on every tick, except every fifth one. If we consider the sequence of
    ticks and apply both restrictions, the combined system would not flash a light
    on a tick that is both a multiple of three and five specifically, on ticks that
    are multiples of fifteen, since 15 is the least common multiple of 3 and 5. At
    such ticks, both systems would be blocking their respective lights from flashing
    due to their individual restrictions.


    Therefore, on ticks that are multiples of fifteen (like the 15th, 30th, 45th tick,
    and so on), neither light would flash, violating the new requirement that at least
    one light must flash after every tick.


    In conclusion, the combined system of red flashing and green flashing with the
    restrictions of not flashing on ticks divisible by three and five, respectively,
    does not satisfy the requirement that at least one light must be flashed after
    every tick.


    ChatGPT also successfully discussed generaliza-


    tions of this computation, including calculating the number of composite system
    states that would have to be traversed in exhaustive model checking.


    It is interesting to note though, that while the LLM was able to apply its logic
    to find system execution paths with special properties, it did not do well when
    asked to list *all* the execution paths possessing a certain property. For example,
    we presented it with a 4-by-4 grid of cells, and asked for the steps that a robot
    may take from (0,0) at the bottom left to (3,3) at the top right, using the events
    for right, left, up, and down motions. We also required that the path remains
    within the grid. ChatGPT was able to list paths like *right,right,right,up,up,up*
    and *right,up,right,up,right,up*, but when asked to list all the paths that go
    through (1,3) it failed, listing several paths that do not reach the desired target,
    including *up,up,up,right,down,down,right,up,right*. Chat-GPT is thus not yet
    ready to carry out exhaustive model checking on scenario-based systems. This is
    not really an issue, however, since with the proposed methodology verification
    of the LLM''s outputs will be carried out independently of the LLM environment.


    #### 4.5 Identifying Under-Specification


    Even when the created model addresses the stated requirements perfectly, as may
    be possible with synthetic or reduced problem descriptions, there may be additional
    areas of the broader problem domain that can or must be handled. In response to
    appropriate prompts ChatGPT was able to significantly enrich a developed model,
    or helped restate the explicit boundaries and expected scope of the intended system.


    For example, in [\(Harel et al., 2023\)](#page-10-16) we presented ChatGPT with
    a scenario-based model that was developed for science teaching purposes. The model
    describes how bees depend on the ambient temperature for switching between hibernation
    and being active, flower plants depend on hours of daylight in order to start
    blooming, and active bees depend on blooming flowers for survival. In the original
    model, average temperatures and number of daylight hours were parameters that
    students could adjust to see how certain combinations of settings might be sustaining
    while others can cause the bees to die out due to hunger.


    When we asked ChatGPT to offer enhancements to the education model, it suggested
    to consider weather-related variations that modify the prespecified fixed average
    temperature and the number of daylight hours for a given time of year.


    ### 4.6 Explainability


    Given a certain observed or expected behavior of the system, ChatGPT is able to
    produce a natural language description of the cause of that behavior, finding
    a reasonable balance between the arcane details of the complete execution trace,
    and the overall requirement that "this is what the system was supposed to do".


    For example, following a paragraph on the semantics of SB modeling we presented
    the following prompt:


    In a system with two scenarios, one waits for time tick events and after each
    time tick requests a short beep (100 msec). The other scenario waits for time
    ticks, and after each such event requests a long beep (500 msec). Each of these
    scenarios waits for both the short and long beep events, so that after each time
    tick, exactly one beep occurs. Actuator scenarios actually cause the respective
    beeping action. Time tick events are injected by the environment every one second.
    A user reported that it watched the system for 20 seconds, and never heard a long
    beep. Can you explain why this may have happened?


    ChatGPT response was:


    The user''s report of not hearing a long beep in a system with two scenarios—one
    requesting a short beep after each time tick, and the other requesting a long
    beep after each time tick—can be explained through the principles of Scenariobased
    Modeling (SBM).


    In SBM, when multiple scenarios request different events after a shared trigger
    event, the execution environment selects one of these requested events to occur.
    The selection can be arbitrary or follow a specific strategy, such as alphabetic
    or lexical order, priority, random, round-robin, etc. In this case, if the event
    selection strategy prioritizes the short beep over the long beep (for example,
    due to alphabetic order, where "short beep" comes before "long beep"), then the
    short beep will always be selected to occur after each time tick, and the long
    beep will never be executed. Since time tick events are injected by the environment
    every second, and both scenarios are waiting for this event, each time tick leads
    to both scenarios being activated. However, if the system consistently selects
    the short beep event over the long beep event after each time tick, the scenario
    requesting the long beep will never progress to the state where it actually triggers
    the long beep. As a result, only short beeps will be heard.


    In summary, the user''s observation of not hearing any long beeps can be attributed
    to the event selection mechanism within the SBM framework, which in this case
    consistently favors the short beep event over the long beep event. This could
    be due to the selection strategy used by the system (like alphabetic order) or
    other operational logic specifics.


    We then challenged ChatGPT again:


    Thank you. Assume that the developers changed the selection algorithm and they
    now select events randomly. The user tested the system many times, for hours,
    and never heard a long beep. Can you try to explain?


    To this, ChatGPT produced a very comprehensive answer, covering possible issues
    with application scenarios, the execution infrastructure, and humanmachine interaction.
    Here are some excerpts:


    If the event selection algorithm was changed to randomly select between the short
    beep and long beep events, but the user still never hears a long beep, there are
    several potential explanations:


    Implementation Error in Random Selection: The most straightforward explanation
    could be a bug or implementation error in the random selection algorithm. It might
    not be truly random, or it could be incorrectly favoring the short beep event
    due to a coding mistake.


    Issue with the Long Beep Scenario: There might be a problem with the scenario
    that requests the long beep. This could be a coding error or a logical flaw in
    the scenario itself, preventing it from properly requesting the long beep event.


    User Perception or Reporting Error: Finally, there could be an issue with how
    the user is perceiving or reporting the beeps. They might be missing the long
    beep due to distraction, ambient noise, or misunderstanding what constitutes a
    long beep in the context of this system.


    To diagnose the issue accurately, developers would need to conduct thorough testing
    and debugging, looking into each of these potential areas to find where the problem
    lies.


    While such explanations are impressive, they were not perfect. We had cases where
    we presented Chat-GPT with well specified scenarios and a description of an observed
    execution log, i.e., an event sequence, but ChatGPT was not able to retrospectively
    produce a step by step play-out sequence that would generate this execution log.
    Instead, it provided incorrect explanations for that event sequence. While frequently
    providing ChatGPT with better reminders and interactive practice of its knowledge
    of semantics and play-out may remedy such issues, this caveat is a reminder that
    all outputs produced by the LLM must be formally checked.


    # 4.7 Accommodating Semantic Flexibility


    Most software development studios are tied to specific languages and their associated
    semantics. In our experiments, ChatGPT was able to accommodate, and discuss, alternative
    semantics.


    For example, in the water tap example in Section [2,](#page-1-0) when the scenario
    ADDHOTWATER is in any of the states where it requests ADDHOT, it cannot react
    to WATERLOW, since it is not waiting for that event. By contrast, in the semantics
    of the LSC scenario-based language, the infrastructure constantly listens for
    all events that are waited for in the first state of all scenarios. When such
    an event occurs, the infrastructure instantiates another copy of the scenario.
    In fact, from our first textual descriptions of SBP, ChatGPT understood this semantics
    to be the default.


    In another example, we asked ChatGPT to generate scenarios for Quicksort. Before
    starting, it commented that it will be hard, as classical solutions are recursive.
    We then pointed out to ChatGPT that there is a published implementation that is
    iterative, not recursive [\(Harel et al., 2021\)](#page-11-15), that is structured
    as instructions to human workers arranging cars in an automobile dealership parking
    lot according to, say, window-sticker price, where each employee had one narrow
    role. ChatGPT readily accommodated the new mindset and produced the desired scenario-based
    specification.


    #### 4.8 Interactive Mutual Learning


    In our experiments, we noticed that ChatGPT learns from multiple prompts, discussions
    and exploration better than from concise or detailed descriptions. We believe
    that the same may hold for software and system developers. Interactive, agile
    development processes may not be just trial and error, or spiral convergence to
    and discovery of a predefined but poorly specified goal. Rather, they are often
    constructive processes, where stakeholders and developers build their wishes and
    plans, as they refine their own understanding of the environment, the systems,
    their needs, and their future interactions with the system.


    An important part of this refinement is producing more explicit definitions of
    elements that are outside the scope of the system. In contrast, such definitions
    are often totally absent from classical system specifications.


    # <span id="page-9-0"></span>5 RELATED WORK


    Recent advances in LLM-based chatbots have made a considerable impact on numerous
    domains. Researchers and engineers are now examining the potential applications
    of this technology in education [\(AlAfnan et al., 2023\)](#page-10-6), music
    [\(Lu et al., 2023\)](#page-11-7), academia and libraries [\(Lund and Wang, 2023\)](#page-11-16),
    healthcare [\(Li et al., 2023\)](#page-11-17), and many other areas.


    Within the field of software engineering, which is our subject matter here, attempts
    have been made to apply chatbots to evaluate the quality of code [\(Burak](#page-10-2)
    [et al., 2023\)](#page-10-2), to correct bugs [\(Surameery and Shakor,](#page-11-3)
    [2023\)](#page-11-3), and to generate code automatically or semiautomatically
    [\(Feng et al., 2023;](#page-10-17) [Dong et al., 2023\)](#page-10-18). The general
    consensus appears to be that chatbots will play a key role in code generation
    in years to come. Our work here outlines a possible path towards allowing this
    integration in a safe and controlled manner.


    Our proposed methodology for integrating Chat-GPT into the software engineering
    process leverages the large body of existing work on scenariobased modeling [\(Harel
    et al., 2012b;](#page-11-5) [Damm and](#page-10-4) [Harel, 2001\)](#page-10-4).
    Specifically, we propose to make use of the amenability of SBM to formal analysis
    techniques [\(Harel et al., 2015a;](#page-10-19) [Harel et al., 2015b\)](#page-11-18),
    such as verification [\(Harel et al., 2011;](#page-11-14) [Harel et al., 2013b\)](#page-10-15),
    automatic repair [\(Harel et al., 2012a\)](#page-11-19), and synthesis [\(Greenyer
    et al., 2016\)](#page-10-20). Despite our focus on SBM, other modeling approaches,
    with similar traits, could be used in a similar manner.


    Finally, our work here can be regarded as another step towards the *Wise Computing*
    vision [\(Harel et al.,](#page-10-12) [2016a;](#page-10-12) [Harel et al., 2016b;](#page-10-21)
    [Harel et al., 2018\)](#page-10-3), which seeks to transform the computer into
    an active member of the software engineering team — raising questions, making
    suggestions and observations, and carrying out verification-like processes, even
    without explicitly being asked to do so.


    # <span id="page-9-1"></span>6 CONCLUSION


    The appearance of large language models, and the subsequent release of advanced
    chatbots, is a major development, and it is likely to revolutionize the domain
    of software engineering in coming years. However, because of inaccuracies and
    errors that are inherent to the outputs of these chatbots, such an integration
    must be performed with care. We outline here a possible method for such an integration,
    which makes use of the advanced features of chatbots, but which also puts an emphasis
    on inspecting and analyzing the results of the integration. We are hopeful that
    our work will trigger additional research in this important direction.


    Moving forward, we plan to continue this work along several axes. First and foremost,
    we intend to implement the necessary tools and environments needed to fully integrate
    ChatGPT with SBM, and then use these tools and environments in large, realworld
    case studies that will demonstrate the usefulness of the approach as a whole.


    In addition, we expect that this line of work will require us to enhance and modify
    existing tools, both on the SBM said and on the chatbot one. For instance, with
    the current version of ChatGPT, every conversation starts from a blank slate,
    whereas for the ongoing development of a system, as part of the Wise Computing
    vision, it would be more useful to have the chatbot remember and use previous
    conversations. This could be achieved, for instance, by summarizing each conversation
    as it ends, and then feeding these summaries back to the chatbot when a new conversation
    starts. In fact, with the newly announced GPTs feature introduced in ChatGPT one
    can build a chatbot that is customized specifically for developing SB models and
    programs.


    Ideally, LLMs will be able learn immediately from ongoing conversations, yet they
    will do so selectively, learning over time, to select what should be retained
    in each conversation and for how long.


    These developments can also be beneficial in a broader perspective: prompt engineering
    methods and practices that would be developed along the way for such interactive,
    incremental development may prove useful not only in teaching computers, but in
    enhancing the training and everyday communications of human engineers.


    ## ACKNOWLEDGEMENTS


    The work of Harel, Marron and Szekely was funded in part by an NSFC-ISF grant
    to DH, issued jointly by the National Natural Science Foundation of China (NSFC)
    and the Israel Science Foundation (ISF grant 3698/21). Additional support was
    provided by a research grant to DH from the Estate of Harry Levine, the Estate
    of Avraham Rothstein, Brenda Gruss, and Daniel Hirsch, the One8 Foundation, Rina
    Mayer, Maurice Levy, and the Estate of Bernice Bernath.


    The work of Katz was partially funded by the European Union (ERC, VeriDeL, 101112713).
    Views and opinions expressed are however those of the author(s) only and do not
    necessarily reflect those of the European Union or the European Research Council
    Executive Agency. Neither the European Union nor the granting authority can be
    held responsible for them.


    ## REFERENCES


    - <span id="page-10-14"></span>Aceto, L., Ingolfsd ´ ottir, A., Larsen, K., and
    Srba, J. (2007). ´ *Reactive Systems: Modelling, Specification and Verification*.
    Cambridge University Press.

    - <span id="page-10-6"></span>AlAfnan, M., Dishari, S., Jovic, M., and Lomidze,
    K. (2023). ChatGPT as an Educational Tool: Opportunities, Challenges, and Recommendations
    for Communication, Business Writing, and Composition Courses. *Journal of Artificial
    Intelligence and Technology*, 3(2):60–68.

    - <span id="page-10-10"></span>Bar-Sinai, M., Weiss, G., and Shmuel, R. (2018).
    BPjs: An Extensible, Open Infrastructure for Behavioral Programming Research.
    In *Proc. 21st ACM/IEEE Int. Conf. on Model Driven Engineering Languages and Systems
    (MODELS)*, pages 59–60.

    - <span id="page-10-0"></span>Biolchini, J., Mian, P., Natali, A., and Travassos,
    G. (2005). Systematic Review in Software Engineering. Technical Report. System
    Engineering and Computer Science Department COPPE/UFRJ, Report ES 679.

    - <span id="page-10-2"></span>Burak, Y., Ozsoy, I., Ayerdem, M., and Tuz¨ un,
    E. ¨ (2023). Evaluating the Code Quality of AI-Assisted Code Generation Tools:
    An Empirical Study on GitHub Copilot, Amazon CodeWhisperer, and Chat-GPT. Technical
    Report. [https://arxiv.org/abs/2304.](https://arxiv.org/abs/2304.10778/) [10778/.](https://arxiv.org/abs/2304.10778/)

    - <span id="page-10-5"></span>Chang, Y., Wang, X., Wang, J., Wu, Y., Zhu, K.,
    Chen, H., Yang, L., Yi, X., Wang, C., Wang, Y., and Ye, W. (2023). A Survey on
    Evaluation of Large Language Models. Technical Report. [https://arxiv.org/abs/2307.](https://arxiv.org/abs/2307.03109/)
    [03109/.](https://arxiv.org/abs/2307.03109/)

    - <span id="page-10-4"></span>Damm, W. and Harel, D. (2001). LSCs: Breathing Life
    into Message Sequence Charts. *J. on Formal Methods in System Design (FMSD)*,
    19(1):45–80.

    - <span id="page-10-18"></span>Dong, Y., Jiang, X., Jin, Z., and Li, G. (2023).
    Self-Collaboration Code Generation via ChatGPT. Technical Report. [https://arxiv.org/abs/2304.07590/.](https://arxiv.org/abs/2304.07590/)

    - <span id="page-10-17"></span>Feng, Y., Vanam, S., Cherukupally, M., Zheng, W.,
    Qiu, M., and Chen, H. (2023). Investigating Code Generation Performance of Chat-GPT
    with Crowdsourcing


    Social Data. In *Proc. 47th IEEE Computer Software and Applications Conf. (COMPSAC)*,
    pages 1–10.


    - <span id="page-10-1"></span>Google (2023). Bard. [https://bard.google.com/.](https://bard.google.com/)

    - <span id="page-10-11"></span>Greenyer, J., Gritzner, D., Gutjahr, T., Konig,
    F., Glade, ¨ N., Marron, A., and Katz, G. (2017). ScenarioTools — A Tool Suite
    for the Scenario-based Modeling and Analysis of Reactive Systems. *Journal of
    Science of Computer Programming (J. SCP)*, 149:15–27.

    - <span id="page-10-20"></span>Greenyer, J., Gritzner, D., Katz, G., and Marron,
    A. (2016). Scenario-Based Modeling and Synthesis for Reactive Systems with Dynamic
    System Structure in ScenarioTools. In *Proc. 19th ACM/IEEE Int. Conf. on Model
    Driven Engineering Languages and Systems (MOD-ELS)*, pages 16–23.

    - <span id="page-10-7"></span>Gregorcic, B. and Pendrill, A.-M. (2023). ChatGPT
    and the Frustrated Socrates. *Physics Education*, 58(2).

    - <span id="page-10-13"></span>Gritzner, D. and Greenyer, J. (2018). Synthesizing
    Executable PLC Code for Robots from Scenario-Based GR(1) Specifications. In *Proc.
    4th Workshop of Model-Driven Robot Software Engineering (MORSE)*, pages 247–262.

    - <span id="page-10-16"></span>Harel, D., Assmann, U., Fournier, F., Limonad,
    L., Marron, A., and Szekely, S. (2023). Toward Methodical Discovery and Handling
    of Hidden Assumptions in Complex Systems and Models. In *Engineering Safe and
    Trustworthy Cyber Physical Systems – Essays Dedicated to Werner Damm on the Occasion
    of His 71st Birthday. To Appear*. arXiV preprint. [https://arxiv.org/abs/2312.16507.](https://arxiv.org/abs/2312.16507)

    - <span id="page-10-8"></span>Harel, D., Kantor, A., and Katz, G. (2013a). Relaxing
    Synchronization Constraints in Behavioral Programs. In *Proc. 19th Int. Conf.
    on Logic for Programming, Artificial Intelligence and Reasoning (LPAR)*, pages
    355– 372.

    - <span id="page-10-15"></span>Harel, D., Kantor, A., Katz, G., Marron, A., Mizrahi,
    L., and Weiss, G. (2013b). On Composing and Proving the Correctness of Reactive
    Behavior. In *Proc. 13th Int. Conf. on Embedded Software (EMSOFT)*, pages 1–10.

    - <span id="page-10-9"></span>Harel, D. and Katz, G. (2014). Scaling-Up Behavioral
    Programming: Steps from Basic Principles to Application Architectures. In *Proc.
    4th SPLASH Workshop on Programming based on Actors, Agents and Decentralized Control
    (AGERE!)*, pages 95–108.

    - <span id="page-10-19"></span>Harel, D., Katz, G., Lampert, R., Marron, A., and
    Weiss, G. (2015a). On the Succinctness of Idioms for Concurrent Programming. In
    *Proc. 26th Int. Conf. on Concurrency Theory (CONCUR)*, pages 85–99.

    - <span id="page-10-12"></span>Harel, D., Katz, G., Marelly, R., and Marron, A.
    (2016a). An Initial Wise Development Environment for Behavioral Models. In *Proc.
    4th Int. Conf. on Model-Driven Engineering and Software Development (MODEL-SWARD)*,
    pages 600–612.

    - <span id="page-10-21"></span>Harel, D., Katz, G., Marelly, R., and Marron, A.
    (2016b). First Steps Towards a Wise Development Environment for Behavioral Models.
    *Int. Journal of Information System Modeling and Design (IJISMD)*, 7(3):1– 22.

    - <span id="page-10-3"></span>Harel, D., Katz, G., Marelly, R., and Marron, A.
    (2018). Wise Computing: Toward Endowing System Devel-


    opment with Proactive Wisdom. *IEEE Computer*, 51(2):14–26.


    - <span id="page-11-19"></span>Harel, D., Katz, G., Marron, A., and Weiss, G.
    (2012a). Non-Intrusive Repair of Reactive Programs. In *Proc. 17th IEEE Int. Conf.
    on Engineering of Complex Computer Systems (ICECCS)*, pages 3–12.

    - <span id="page-11-9"></span>Harel, D., Katz, G., Marron, A., and Weiss, G. (2014).
    Non-Intrusive Repair of Safety and Liveness Violations in Reactive Programs. *Transactions
    on Computational Collective Intelligence (TCCI)*, 16:1–33.

    - <span id="page-11-18"></span>Harel, D., Katz, G., Marron, A., and Weiss, G.
    (2015b). The Effect of Concurrent Programming Idioms on Verification. In *Proc.
    3rd Int. Conf. on Model-Driven Engineering and Software Development (MODEL-SWARD)*,
    pages 363–369.

    - <span id="page-11-14"></span>Harel, D., Lampert, R., Marron, A., and Weiss,
    G. (2011). Model-Checking Behavioral Programs. In *Proc. 9th ACM Int. Conf. on
    Embedded Software (EMSOFT)*, pages 279–288.

    - <span id="page-11-8"></span>Harel, D. and Marelly, R. (2003). Specifying and
    Executing Behavioral Requirements: The Play In/Play-Out Approach. *Software and
    System Modeling (SoSyM)*, 2:82–107.

    - <span id="page-11-10"></span>Harel, D., Marron, A., and Weiss, G. (2010). Programming
    Coordinated Scenarios in Java. In *Proc. 24th European Conf. on Object-Oriented
    Programming (ECOOP)*, pages 250–274.

    - <span id="page-11-5"></span>Harel, D., Marron, A., and Weiss, G. (2012b). Behavioral
    Programming. *Communications of the ACM (CACM)*, 55(7):90–100.

    - <span id="page-11-15"></span>Harel, D., Marron, A., and Yerushalmi, R. (2021).
    Scenario-Based Algorithmics: Coding Algorithms by Automatic Composition of Separate
    Concerns. *Computer*, 54(10):95–101.

    - <span id="page-11-13"></span>Harel, D. and Pnueli, A. (1985). On the Development
    of Reactive Systems. *Logics and Models of Concurrent Systems*, F-13:474–498.

    - <span id="page-11-12"></span>Katz, G. (2013). On Module-Based Abstraction and
    Repair of Behavioral Programs. In *Proc. 19th Int. Conf. on Logic for Programming,
    Artificial Intelligence and Reasoning (LPAR)*, pages 518–535.

    - <span id="page-11-17"></span>Li, J., Dada, A., Kleesiek, J., and Egger, J. (2023).
    Chat-GPT in Healthcare: A Taxonomy and Systematic Review. Technical Report. [https://www.medrxiv.org/](https://www.medrxiv.org/content/10.1101/2023.03.30.23287899v1)
    [content/10.1101/2023.03.30.23287899v1.](https://www.medrxiv.org/content/10.1101/2023.03.30.23287899v1)

    - <span id="page-11-4"></span>Liu, J., Xia, C., Wang, Y., and Zhang, L. (2023).
    Is your Code Generated by ChatGPT really Correct? Rigorous Evaluation of Large
    Language Models for Code Generation. Technical Report. [https://arxiv.org/abs/](https://arxiv.org/abs/2305.01210/)
    [2305.01210/.](https://arxiv.org/abs/2305.01210/)

    - <span id="page-11-7"></span>Lu, P., Xu, X., Kang, C., Yu, B., Xing, C., Tan,
    X., and Bian, J. (2023). MuseCoco: Generating Symbolic Music from Text. Technical
    Report. [https://arxiv.org/](https://arxiv.org/abs/2306.00110/) [abs/2306.00110/.](https://arxiv.org/abs/2306.00110/)

    - <span id="page-11-16"></span>Lund, B. and Wang, T. (2023). Chatting about Chat-GPT:
    how may AI and GPT Impact Academia and Libraries? *Library Hi Tech News*, 40(3):26–29.

    - <span id="page-11-2"></span>MetaAI (2023). LLaMa. [https://ai.meta.com/llama/.](https://ai.meta.com/llama/)

    - <span id="page-11-1"></span>OpenAI (2022). ChatGPT. [https://chat.openai.com/.](https://chat.openai.com/)

    - <span id="page-11-0"></span>Pettersson, O. and Andersson, J. (2016). A Survey
    of Modeling Approaches for Software Ecosystems. In *Proc. 7th Int. Conf. on Software
    Business (ICSOB)*, pages 79–93.

    - <span id="page-11-3"></span>Surameery, N. and Shakor, M. (2023). Use Chat GPT
    to Solve Programming Bugs. *Int. Journal of Information Technology & Computer
    Engineering (IJITC)*, 3(1):17–22.

    - <span id="page-11-6"></span>Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit,
    J., Jones, L., Gomez, A., Kaiser, L., and Polosukhin, I. (2017). Attention is
    all you Need. In *Proc. 31st Conf. on Advances in Neural Information Processing
    Systems (NeurIPS)*.

    - <span id="page-11-11"></span>Yaacov, T. (2023). BPPy: Behavioral Programming
    in Python. *SoftwareX*, 24.'
- title: 'REDriver: Runtime Enforcement for Autonomous Vehicles'
  abstract: 'Autonomous driving systems (ADSs) integrate sensing, perception, drive

    control, and several other critical tasks in autonomous vehicles, motivating

    research into techniques for assessing their safety. While there are several

    approaches for testing and analysing them in high-fidelity simulators, ADSs may

    still encounter additional critical scenarios beyond those covered once they

    are deployed on real roads. An additional level of confidence can be

    established by monitoring and enforcing critical properties when the ADS is

    running. Existing work, however, is only able to monitor simple safety

    properties (e.g., avoidance of collisions) and is limited to blunt enforcement

    mechanisms such as hitting the emergency brakes. In this work, we propose

    REDriver, a general and modular approach to runtime enforcement, in which users

    can specify a broad range of properties (e.g., national traffic laws) in a

    specification language based on signal temporal logic (STL). REDriver monitors

    the planned trajectory of the ADS based on a quantitative semantics of STL, and

    uses a gradient-driven algorithm to repair the trajectory when a violation of

    the specification is likely. We implemented REDriver for two versions of Apollo

    (i.e., a popular ADS), and subjected it to a benchmark of violations of Chinese

    traffic laws. The results show that REDriver significantly improves Apollo''s

    conformance to the specification with minimal overhead.'
  url: http://arxiv.org/abs/2401.02253v1
  keywords: ''
  document: "# REDriver: Runtime Enforcement for Autonomous Vehicles\n\n[Yang Sun](https://orcid.org/0000-0002-2409-2160)\
    \ Singapore Management University Singapore yangsun.2020@phdcs.smu.edu.sg\n\n\
    [Xiaodong Zhang](https://orcid.org/0000-0002-8380-1019) Xidian University China\
    \ zhangxiaodong@xidian.edu.cn\n\n# ABSTRACT\n\nAutonomous driving systems (ADSs)\
    \ integrate sensing, perception, drive control, and several other critical tasks\
    \ in autonomous vehicles, motivating research into techniques for assessing their\
    \ safety. While there are several approaches for testing and analysing them in\
    \ high-fidelity simulators, ADSs may still encounter additional critical scenarios\
    \ beyond those covered once they are deployed on real roads. An additional level\
    \ of confidence can be established by monitoring and enforcing critical properties\
    \ when the ADS is running. Existing work, however, is only able to monitor simple\
    \ safety properties (e.g., avoidance of collisions) and is limited to blunt enforcement\
    \ mechanisms such as hitting the emergency brakes. In this work, we propose REDriver,\
    \ a general and modular approach to runtime enforcement, in which users can specify\
    \ a broad range of properties (e.g., national traffic laws) in a specification\
    \ language based on signal temporal logic (STL). REDriver monitors the planned\
    \ trajectory of the ADS based on a quantitative semantics of STL, and uses a gradient-driven\
    \ algorithm to repair the trajectory when a violation of the specification is\
    \ likely. We implemented REDriver for two versions of Apollo (i.e., a popular\
    \ ADS), and subjected it to a benchmark of violations of Chinese traffic laws.\
    \ The results show that REDriver significantly improves Apollo's conformance to\
    \ the specification with minimal overhead.\n\n#### ACM Reference Format:\n\nYang\
    \ Sun, Christopher M. Poskitt, Xiaodong Zhang, and Jun Sun. 2024. REDriver: Runtime\
    \ Enforcement for Autonomous Vehicles. In 2024 IEEE/ACM 46th International Conference\
    \ on Software Engineering (ICSE '24), April 14–20, 2024, Lisbon, Portugal. ACM,\
    \ New York, NY, USA, [12](#page-11-0) pages. [https://doi.org/](https://doi.org/10.1145/3597503.3639151)\
    \ [10.1145/3597503.3639151](https://doi.org/10.1145/3597503.3639151)\n\n# 1 INTRODUCTION\n\
    \nAutonomous driving systems (ADSs) are the core of autonomous vehicles (AVs),\
    \ integrating sensing, perception, drive control, and several other tasks that\
    \ are necessary for automating their journeys. Given the safety-critical nature\
    \ of ADSs [\\[14,](#page-10-0) [18\\]](#page-10-1), it is imperative that they\
    \ operate safely at all times, including in rare or unexpected scenarios that\
    \ may not have been explicitly considered when the\n\nICSE '24, April 14–20, 2024,\
    \ Lisbon, Portugal\n\n© 2024 Copyright held by the owner/author(s).\n\nACM ISBN\
    \ 979-8-4007-0217-4/24/04.\n\n<https://doi.org/10.1145/3597503.3639151>\n\n[Christopher\
    \ M. Poskitt](https://orcid.org/0000-0002-9376-2471) Singapore Management University\
    \ Singapore cposkitt@smu.edu.sg\n\n[Jun Sun](https://orcid.org/0000-0002-3545-1392)\
    \ Singapore Management University Singapore junsun@smu.edu.sg\n\nsystem was designed.\
    \ This has spurred a multitude of research into techniques for establishing confidence\
    \ in an ADS, e.g., by modelling and verifying aspects of its design [\\[23\\]](#page-10-2),\
    \ by subjecting it to reconstructions of real-world accidents [\\[6\\]](#page-10-3),\
    \ or by testing it against automatically generated critical scenarios [\\[27,](#page-10-4)\
    \ [44,](#page-11-1) [50\\]](#page-11-2) in a high-fidelity simulator such as CARLA\
    \ [\\[15\\]](#page-10-5) or LGSVL [\\[38\\]](#page-11-3).\n\nThese approaches\
    \ all analyse an ADS before it is deployed on real roads, where it may still encounter\
    \ additional scenarios beyond those that were covered. In fact, an analysis of\
    \ accidents involving autonomous vehicles [\\[31\\]](#page-11-4) suggests that\
    \ the broader implementation of current AV technologies may not lead to a reduction\
    \ in vehicle crash frequency. An additional level of confidence can thus be established\
    \ if desirable properties are also monitored—even enforced—while the ADS is running.\
    \ This is the idea of runtime enforcement, a technique that observes the execution\
    \ of a system and then modifies it in a minimal way to ensure certain properties\
    \ are satisfied. In AVs, runtime enforcement has been applied, for example, to\
    \ monitor basic safety properties such as the avoidance of collisions, applying\
    \ the emergency brake before they are violated [\\[21\\]](#page-10-6). Avoiding\
    \ collisions, however, is not enough in general. ADSs are expected to satisfy\
    \ a broader range of complicated properties concerning the overall traffic systems\
    \ they operate in, such as national traffic laws that describe how vehicles should\
    \ behave with respect to various junctions, signals, and (most precariously) other\
    \ vehicles or pedestrians. Currently, no existing approach supports runtime enforcement\
    \ of properties in this direction.\n\nIn this work, we aim to provide a general\
    \ solution to the runtime enforcement problem for AVs. In particular, we propose\
    \ REDriver, a general framework for runtime enforcement that can be integrated\
    \ into ADSs with state-of-the-art modular designs, as exhibited by Apollo [\\\
    [4\\]](#page-10-7) and Autoware [\\[2\\]](#page-10-8). REDriver allows users to\
    \ specify desirable properties of AVs using an existing and powerful domainspecific\
    \ language (DSL) based on signal temporal logic (STL). This language supports\
    \ properties ranging from the simplest, concerning collision avoidance, through\
    \ to entire formalisations of national traffic laws [\\[44\\]](#page-11-1). REDriver\
    \ monitors the planned trajectories and command sequences of the ADS at runtime\
    \ and assesses them against the user's specifications. If the AV is predicted\
    \ to potentially violate them in the near future (based on a quantitative semantics\
    \ of STL), REDriver repairs the trajectories using a gradient-driven algorithm.\
    \ Furthermore, it does so while minimising the \"overhead\" (or change) to the\
    \ original journey. That is, by efficiently computing the gradient of each signal\
    \ (with respect to the robustness degree\n\nPermission to make digital or hard\
    \ copies of part or all of this work for personal or classroom use is granted\
    \ without fee provided that copies are not made or distributed for profit or commercial\
    \ advantage and that copies bear this notice and the full citation on the first\
    \ page. Copyrights for third-party components of this work must be honored. For\
    \ all other uses, contact the owner/author(s).\n\nICSE '24, April 14–20, 2024,\
    \ Lisbon, Portugal Yang Sun, Christopher M. Poskitt, Xiaodong Zhang, and Jun Sun\n\
    \n<span id=\"page-1-0\"></span>![](_page_1_Figure_2.jpeg)\n\nFigure 1: The architecture\
    \ of an ADS with REDriver\n\n<span id=\"page-1-1\"></span>\n\n| Time | Position\
    \         | Speed | Acc   | Steer | Gear  |\n|------|------------------|-------|-------|-------|-------|\n\
    | 0    | (x: 0, y: 0)     | 7.01  | -0.05 | 0     | DRIVE |\n| 2    | (x: 0, y:\
    \ 13.34) | 6.13  | -0.48 | 0     | DRIVE |\n| 4    | (x: 0, y: 24.83) | 5.44 \
    \ | -0.24 | 0     | DRIVE |\n| 6    | (x: 0, y: 35.85) | 5.09  | -0.18 | 0   \
    \  | DRIVE |\n| 8    | (x: 0, y: 44.75) | 3.89  | -1.44 | 0     | DRIVE |\n\n\
    Table 1: An example planned trajectory\n\nof the STL formula), we identify and\
    \ modify the signal that is most likely to repair the trajectories.\n\nREDriver\
    \ has been implemented for two versions of Apollo (i.e., versions 6.0 and 7.0,\
    \ the latest at the time of experimentation). The implementation consists of a\
    \ plan validation algorithm and a control validation algorithm that respectively\
    \ observe and modify (if necessary) the outputs of the ADSs' motion planning and\
    \ control modules. Note that the motion planning and control modules are black\
    \ boxes to us. In particular, we enforce that these outputs (i.e., planned trajectories\
    \ and command sequences) do not lead to violations—whenever possible—of a comprehensive\
    \ formalisation of the Chinese traffic laws. This goes far beyond existing runtime\
    \ enforcement approaches, which focus on simple safety properties (e.g., collision\
    \ avoidance) and blunt enforcement mechanisms (e.g., hitting the emergency brakes).\
    \ Figure [1](#page-1-0) depicts how REDriver is integrated into the modular design\
    \ of Apollo. In particular, we have added two new modules while ensuring that\
    \ the existing modules and their inner logic remain unchanged. In the diagram,\
    \ the perception, motion planning, and control boxes represent the existing Apollo\
    \ modules, while the green plan validation and control validation boxes represent\
    \ the new modules from REDriver. The arrow denotes the flow of signal transmission.\
    \ We evaluated our implementation of REDriver against a benchmark of violation-inducing\
    \ scenarios for Chinese traffic laws [\\[44\\]](#page-11-1), finding that our\
    \ runtime enforcement approach significantly reduces the likelihood of those violations\
    \ occurring. Furthermore, REDriver's overhead in terms of time and how often it\
    \ intervenes is negligible.\n\n# 2 BACKGROUND AND PROBLEM\n\nIn this section,\
    \ we review the architecture of ADSs, the DSL for specifying safety properties,\
    \ and then define our problem.\n\n# 2.1 Overview of Autonomous Driving Systems\n\
    \nState-of-the-art open-source ADSs such as Apollo [\\[3\\]](#page-10-9) and Autoware\
    \ [\\[2\\]](#page-10-8) have similar architectures. They are typically organised\
    \ into loosely coupled modules that communicate via messagepassing. Three of these\
    \ modules are particularly relevant to our context, i.e., perception, motion planning,\
    \ and control.\n\nFirst, the perception module receives sensor readings (e.g.,\
    \ from a camera or LIDAR), processes them, and then feeds them to the\n\n<span\
    \ id=\"page-1-2\"></span>\n\n| Type | Time | Position            | Speed | Acc\
    \   | Steer  |\n|------|------|---------------------|-------|-------|--------|\n\
    |      | 0    | (x: 2.5, y: 5)      | 7.42  | -0.05 | -7.25  |\n| Car1 | 2   \
    \ | (x: 1.67, y: 18.34) | 6.37  | -0.48 | -11.10 |\n|      | 4    | (x: 0, y:\
    \ 29.88)    | 5.44  | -0.24 | 0      |\n|      | 6    | (x: 0, y: 40.87)    |\
    \ 5.09  | -0.18 | 0      |\n|      | 8    | (x: 0, y: 49.76)    | 3.89  | -1.44\
    \ | 0      |\n|      | 0    | (x: -2.5, y: 15)    | 0     | 0     | 0      |\n\
    | Car2 | 2    | (x: -2.5, y: 15)    | 0     | 0     | 0      |\n|      | 4   \
    \ | (x: -2.5, y: 15)    | 0     | 0     | 0      |\n|      | 6    | (x: -2.5,\
    \ y: 15)    | 0     | 0     | 0      |\n|      | 8    | (x: -2.5, y: 15)    |\
    \ 0     | 0     | 0      |\n\n (x: 0.23, y: 48) 0 0 0 (x: 0.23, y: 48) 0 0 0 (x:\
    \ 0.23, y: 48) 0 0 0 (x: 0.23, y: 48) 0 0 0 (x: 0.23, y: 48) 0 0 0\n\n GREEN False\
    \ – – YELLOW False – – YELLOW False – – YELLOW False – – RED False – –\n\nTL-ID\
    \ Time Color Blink – –\n\nPed1\n\nTL-0\n\nTable 2: An example predicted environment\n\
    \nmotion planning module. Second, the motion planning module generates a planned\
    \ trajectory based on the map, the destination, the sensor inputs, and the state\
    \ of the ego vehicle, i.e., the one under the control of the ADS. Intuitively,\
    \ the planned trajectory describes where the vehicle will be at future time points,\
    \ and is computed based on a predicted environment that includes, for example,\
    \ the predicted trajectories of other vehicles (NPCs, non-player characters),\
    \ pedestrians, and traffic lights. For instance, Table [1](#page-1-1) shows a\
    \ planned trajectory for an ego vehicle with respect to the predicted environment\
    \ shown in Table [2.](#page-1-2) Here, the ego vehicle slows down before approaching\
    \ an intersection as the traffic light is changing to red. Every line in Table\
    \ [1](#page-1-1) represents a planned waypoint, i.e., the planned position, speed,\
    \ acceleration, steer, and gear of the ego vehicle at a series of future time\
    \ points. Note that an actual planned trajectory typically contains hundreds of\
    \ waypoints. Similarly, every line in Table [2](#page-1-2) corresponds to the\
    \ predicted states of NPCs such as vehicles and pedestrians, as well as environmental\
    \ parameters like traffic lights. Here, Car2 and Ped1 are predicted to be stationary,\
    \ Car1 is predicated to change lanes, and the color of the traffic light ahead\
    \ is predicted to change from green to yellow and eventually to red. Furthermore,\
    \ in general there may be multiple planned trajectories for a given destination,\
    \ and the planning module attempts to find the \"best\" one. Finally, the control\
    \ module translates the planned trajectory into control commands (e.g., 'brake',\
    \ and 'signal') so that the ego vehicle is likely to follow the planned trajectory,\
    \ i.e., passing through the waypoints with the planned speed, acceleration, steering\
    \ angle, and gear position. We refer to [\\[2,](#page-10-8) [3\\]](#page-10-9)\
    \ for details on how commands are generated.\n\nThere may be other modules in\
    \ an ADS (e.g., the map module in Apollo) or the above-mentioned modules may be\
    \ further divided into sub-modules (e.g., motion planning in Apollo is divided\
    \ into routing, prediction, and planning). Nonetheless, the similar highlevel\
    \ design of existing ADSs implies we could potentially introduce\n\n<span id=\"\
    page-2-0\"></span>\n$$\\begin{aligned} \\varphi &:= \\mu \\mid \\neg \\varphi\
    \ \\mid \\varphi\\_1 \\lor \\varphi\\_2 \\mid \\varphi\\_1 \\land \\varphi\\_2\
    \ \\mid \\varphi\\_1 \\Downarrow \\Downarrow \\varphi\\_2 \\\\ \\mu &:= f(x\\\
    _0, x\\_1, \\dots, x\\_k) \\sim 0 \\quad \\sim := > \\mid \\ge \\mid < \\mid \\\
    le \\mid \\ne \\mid =; \\end{aligned}$$\n\nFigure 2: Specification language syntax,\
    \ where , <sup>1</sup> and <sup>2</sup> are STL formulas, is an interval, and\
    \ is a multivariate linear continuous function over language variables\n\na module\
    \ for runtime monitoring and enforcement which sits inbetween existing modules,\
    \ i.e., to intercept, analyse, and alter (if necessary) the inter-module messages.\
    \ This way, runtime monitoring and enforcement can be introduced without changing\
    \ the inner logic of existing modules. For instance, given the planned trajectory\
    \ generated by the planning module shown in Table [1,](#page-1-1) if we decide\
    \ that the trajectory could potentially lead to the violation of a certain property,\
    \ we can simply modify the planned trajectory before forwarding it to the control\
    \ module (to trigger a different control command generation).\n\n# 2.2 Property\
    \ Specification\n\nTo go beyond the simplest safety requirements (e.g., 'the ego\
    \ vehicle does not collide'), we require a specification language that is able\
    \ to express a rich set of properties that are relevant to autonomous vehicles\
    \ and driving in general. In this work, we adopt the driveroriented specification\
    \ language of LawBreaker [\\[44\\]](#page-11-1), which is based on signal temporal\
    \ logic (STL), and has been demonstrated to be expressive enough to specify the\
    \ traffic laws of China and Singapore. We highlight its key features, referring\
    \ readers to [\\[44\\]](#page-11-1) for details.\n\nThe high-level syntax of the\
    \ language is shown in Figure [2.](#page-2-0) A time interval is of the form [,\
    \ ] where and are respectively the lower and upper bounds of the interval. Following\
    \ convention, we write ^ to denote U ; and □ to denote ¬ ^ ¬. Intuitively, U,\
    \ □, and ^ are modal operators that are respectively interpreted as 'until', 'always',\
    \ and 'eventually'. Note that the time interval is omitted when it is [0, ∞].\
    \ The propositions in this language are constructed using 17 variables and 16\
    \ functions that are relevant to AVs, some of which are shown in Tables [3.](#page-2-1)\
    \ In general, can be regarded as a proposition of the form (0, 1, · · · , ) ∼\
    \ 0 where is a multivariate linear continuous function and for all in [0, ] is\
    \ a variable supported in the language.\n\n<span id=\"page-2-2\"></span>Example\
    \ 2.1. Consider the following two (English translations of) traffic rules from\
    \ the Regulations for Road Traffic Safety of the People's Republic of China [\\\
    [9\\]](#page-10-10).\n\n- (1) Article #38-(3): When a red light is on, vehicles\
    \ are prohibited from passing. However, vehicles turning right can pass without\
    \ hindering the passage of vehicles or pedestrians.\n- (2) Article #58-(3): When\
    \ a vehicle is driving on a foggy day, the fog lights and hazard warning flashing\
    \ should be on.\n\nTable 3: Car and environment related variables\n\n<span id=\"\
    page-2-1\"></span>\n\n| Signal                                          | Type\
    \ | Remarks                                  |  |\n|-------------------------------------------------|------|------------------------------------------|--|\n\
    | speed                                           | Num  | Speed of ego vehicle\
    \ (\U0001D45A/\U0001D460).              |  |\n| acc                          \
    \                   | Num  | 2<br>Acceleration of ego veh (\U0001D45A/\U0001D460\
    <br>).  |  |\n| direction                                       | Enum | forward,\
    \ left, right                     |  |\n| D(stopline)                        \
    \             | Num  | distance to the stopline ahead           |  |\n| D(junction)\
    \                                     | Num  | distance to the junction ahead\
    \           |  |\n| Bool<br>whether the fog light is on<br>fogLight |      | \
    \                                         |  |\n| warningFlash               \
    \                     | Bool | whether the warning flash light is on    |  |\n\
    | PriorityV(n)                                    | Bool | Whether there are vehicles\
    \ with priority |  |\n|                                                 |    \
    \  | within n meters                          |  |\n| PriorityP(n)           \
    \                         | Bool | Whether there are pedestrians with pri   |\
    \  |\n|                                                 |      | ority within\
    \ n meters                    |  |\n| TL(color)                              \
    \         | Enum | YELLOW, GREEN, RED, or BLACK             |  |\n| TL(blink)\
    \                                       | Bool | if the traffic light ahead is\
    \ blinking   |  |\n| fog                                             | Num  |\
    \ degree of fog ranging from 0 to 1        |  |\n| snow                      \
    \                      | Num  | degree of snow ranging from 0 to 1       |  |\n\
    \nThe above can be formalised as follows.\n\n38<sup>3</sup> ≡ □( ( () = ∧ (()\
    \ < 2 ∨ () < 2) ∧ ¬ = ℎ) → (^[0,3] ( < 0.5)) ∧ ( () = ∧ (() < 2 ∨ () < 2) ∧ =\
    \ ℎ ∧ ¬ (20) ∧ ¬ (20)) → (^[0,2] ( > 0.5))) 58<sup>3</sup> ≡ □( ≥ 0.5 → ( ℎ ∧\
    \ ℎ))\n\nwhere speed, direction, fogLight, and warningFlash represent the speed,\
    \ direction, fog light status, and warning flash light status of the vehicle;\
    \ TL() returns the status of traffic light ahead; D(object) calculates the distance\
    \ from the vehicle to the object ahead; and PriorityV(n), PriorityP(n) check whether\
    \ there is a priority vehicle or pedestrian within n meters ahead. Note that several\
    \ configurable constants (e.g., the distance 2 and the time interval [0, 3]) are\
    \ introduced to reduce the vagueness of the law in practice [\\[44\\]](#page-11-1).\
    \ □\n\nA specification is evaluated with respect to a trace of scenes, denoted\
    \ as = ⟨0, 1, <sup>2</sup> . . . , ⟩, where each scene is a valuation of the propositions\
    \ at time step and <sup>0</sup> reflects the state at the start of a simulation.\
    \ These traces can be constructed from the planned trajectory generated by the\
    \ ADS (Section [3.1\\)](#page-3-0). We follow the standard semantics of STL (see\
    \ e.g., [\\[29\\]](#page-10-11)).\n\n# 2.3 The Runtime Enforcement Problem for\
    \ AVs\n\nGiven an ADS and a user-specified property , our goal is to solve the\
    \ runtime enforcement problem for AVs by monitoring traces of the ADS against\
    \ at runtime, and altering its behavior when a violation is likely in the near\
    \ future. Here, altering the ADS's behavior means adjusting its planned trajectory\
    \ and consequently the control commands. Solving this problem could systematically\
    \ improve the safety of ADSs when encountering unusual situations on the road.\
    \ We formulate our problem as follows:\n\nDefinition 1 (Problem Definition). Given\
    \ a runtime planned trajectory , runtime control commands , a specification of\
    \ ADS behavior , and a trace of the AV in a scenario. Let ′ , ′ , and ′ denote\
    \ the adjusted planned trajectory, modified control commands, and resulting trace\
    \ of the AV after these adjustments. Our problem is:\n\n$$Maximise: \\frac{\\\
    rho(\\wp, \\pi') - \\rho(\\wp, \\pi)}{|\\chi' - \\chi| + |\\zeta' - \\zeta|}.$$\n\
    \n□\n\nIntuitively, we seek to maximize the improvement in adhering to the desired\
    \ behavior, while considering the magnitude of changes made to the planned trajectory\
    \ and control commands. Here, the function serves as the quantitative semantics\
    \ of a trace concerning the specification. Its purpose is to provide a numerical\
    \ assessment that calculates the distance to a violation of the specification.\n\
    \n# <span id=\"page-3-4\"></span>3 OUR APPROACH\n\nREDriver, our runtime enforcement\
    \ approach, consists of three broad steps. First, plan validation, in which it\
    \ evaluates the planned trajectory against the specification to determine if there\
    \ is a risk of violation. Second, trajectory repair, in which the planned trajectory\
    \ is modified so as to avoid the violation. Finally, control validation, in which\
    \ the commands generated by the control module are further evaluated to ensure\
    \ the specification is satisfied. As shown in Figure [1,](#page-1-0) these steps\
    \ seamlessly integrate into the modular design of ADSs: REDriver sits between\
    \ the modules, intercepting and altering the messages they exchange. Note that\
    \ we assume that the sensor data received by the ADS is accurate.\n\n# <span id=\"\
    page-3-0\"></span>3.1 Plan Validation\n\nGiven a specification and a planned trajectory\
    \ from the motion planning module of the ADS, REDriver first determines whether\
    \ the trajectory is likely to violate . To achieve this, REDriver first constructs\
    \ a trace from the planned trajectory, i.e., by evaluating all variables and functions\
    \ relevant to at every time point with respect to the planned trajectory and the\
    \ predicted environment. For instance, given the planned trajectory in Table [1](#page-1-1)\
    \ (and the predicted environment in Table [2\\)](#page-1-2), Table [4](#page-3-1)\
    \ shows the constructed trace.\n\nOne practical complication is that some variables\
    \ relevant to cannot be obtained from the planned trajectory as they are only\
    \ known after command generation (see Section [3.3\\)](#page-6-0). For example,\
    \ the values of fogLight (i.e., whether the fog light is on) and warningFlash\
    \ can only be determined once the respective commands are generated. For such\
    \ situations, we use typed 'placeholder' variables x, in the scenes of the trace\
    \ for each time step and position . We define an assignment to be a function mapping\
    \ the typed variables x, to the value domains. Then, for traces containing those\
    \ variables, satisfies if and only if there exists an assignment such that [ (x,)/x,]\
    \ satisfies for every variable x, in . Practically, finding a suitable assignment\
    \ is straightforward: all variables for assignment have only a few possible discrete\
    \ values (e.g., the light is on or off), and thus brute force search is sufficient\
    \ and inexpensive.\n\nNext, REDriver computes how 'close' the ego vehicle will\
    \ come to violating . Note that our goal is to proactively react when a violation\
    \ is likely in the near future. This is because the ego vehicle operates in an\
    \ open environment (e.g., with other vehicles and pedestrians) and thus reacting\
    \ too late may be too risky if the predicted environment turns out to be wrong\
    \ (e.g., a sudden move of a pedestrian). To measure how close a trace is to violating\n\
    \nICSE '24, April 14–20, 2024, Lisbon, Portugal Yang Sun, Christopher M. Poskitt,\
    \ Xiaodong Zhang, and Jun Sun\n\nTable 4: Trace obtained from the trajectory in\
    \ Table [1](#page-1-1)\n\n<span id=\"page-3-1\"></span>\n\n| planning signals\
    \   | 0     | 2     | 4     | 6     | 8     |\n|--------------------|-------|-------|-------|-------|-------|\n\
    | speed              | 7.01  | 6.13  | 5.44  | 5.09  | 3.89  |\n| direction  \
    \        | 0     | 0     | 0     | 0     | 0     |\n| D(stopline)        | 44\
    \    | 30.66 | 19.17 | 8.15  | -0.75 |\n| D(junction)        | 44    | 30.66 |\
    \ 19.17 | 8.15  | -0.75 |\n| fogLight           | x0,0  | x2,0  | x4,0  | x6,0\
    \  | x8,0  |\n| warningFlash       | x0,1  | x2,1  | x4,1  | x6,1  | x8,1  |\n\
    | Prediction Signals | 0     | 2     | 4     | 6     | 8     |\n| TL(color)  \
    \        | 1     | 0     | 0     | 0     | 2     |\n| fog                | 0.6\
    \   | 0.6   | 0.6   | 0.6   | 0.6   |\n| PriorityV(20)      | false | false |\
    \ false | false | false |\n| PriorityP(10)      | false | false | false | true\
    \  | true  |\n\n, we adopt a quantitative semantics [\\[13,](#page-10-12) [29,](#page-10-11)\
    \ [34\\]](#page-11-5) that produces a numerical robustness degree.\n\n<span id=\"\
    page-3-3\"></span>Definition 2 (Quantitative Semantics). Given a trace and a formula\
    \ , the quantitative semantics is defined as the robustness degree (, , ), computed\
    \ as follows. Recall that propositions are of the form (0, 1, · · · , ) ∼ 0.\n\
    \n$$\\rho(\\mu,\\pi,t) = \\begin{cases} -\\pi\\_{\\ell}(f(\\mathbf{x}\\_{0},\\\
    mathbf{x}\\_{1},\\cdots,\\mathbf{x}\\_{k})) & \\text{if } \\sim \\text{ is } \\\
    llcorner \\alpha\\\\ \\pi\\_{\\ell}(f(\\mathbf{x}\\_{0},\\mathbf{x}\\_{1},\\cdots,\\\
    mathbf{x}\\_{k})) & \\text{if } \\sim \\text{ is } \\gg \\text{ or } > \\text{\
    \ and } \\gg \\text{ is } \\llcorner \\alpha\\\\ |\\;\\pi\\_{\\ell}(f(\\mathbf{x}\\\
    _{0},\\mathbf{x}\\_{1},\\cdots,\\mathbf{x}\\_{k}))| & \\text{if } \\sim \\text{\
    \ is } \\neq \\text{ and } \\gg \\text{ is } \\llcorner \\alpha\\\\ -|\\;\\pi\\\
    _{\\ell}(f(\\mathbf{x}\\_{0},\\mathbf{x}\\_{1},\\cdots,\\mathbf{x}\\_{k}))| &\
    \ \\text{if } \\sim \\text{ is } = \\text{ or } \\llcorner \\alpha\\\\ \\text{and\
    \ } \\sim \\text{ is } \\llcorner \\alpha\\\\ \\end{cases}$$\n\nwhere is the time\
    \ step and () is the valuation of expression at time in .\n\n$$\\begin{aligned}\
    \ \\rho(\\neg\\varphi,\\pi,t) &= -\\rho(\\varphi,\\pi,t) \\\\ \\rho(\\varphi\\\
    _1 \\wedge \\varphi\\_2,\\pi,t) &= \\min\\{\\rho(\\varphi\\_1,\\pi,t), \\rho(\\\
    varphi\\_2,\\pi,t)\\} \\\\ \\rho(\\varphi\\_1 \\vee \\varphi\\_2,\\pi,t) &= \\\
    max\\{\\rho(\\varphi\\_1,\\pi,t), \\rho(\\varphi\\_2,\\pi,t)\\} \\\\ \\rho(\\\
    varphi\\_1 \\cup \\varphi\\_2,\\pi,t) &= \\sup\\_{t\\_1 \\in t+\\mathbb{T}} \\\
    min\\{\\rho(\\varphi\\_2,\\pi,t\\_1), \\inf\\_{t\\_2 \\in \\left[t,t\\_1\\right]}\
    \ \\rho(\\varphi\\_1,\\pi,t\\_2)\\} \\end{aligned}$$\n\nwhere + is the interval\
    \ [ + , + ] given = [, ]. □\n\nNote that the smaller (, , ) is, the closer is\
    \ to violating . If (, , ) ≤ 0, is violated. We write (, ) to denote (, , 0);\
    \ ⊨ to denote (, , ) > 0; and ⊭ to denote (, , ) ≤ 0. Note that time is discrete\
    \ in our setting.\n\n<span id=\"page-3-2\"></span>Example 3.1. Let = □( < 90),\
    \ i.e., the speed limit is 90km/h. Suppose is ⟨( ↦→ 0, . . . ), ( ↦→ 0.5, . .\
    \ . ), · · · ( ↦→ 85, . . . )⟩ where the ego vehicle's max is 85km/h at the last\
    \ time step. We have (, ) = (, , 0) = ∈ [0,| | ] (90 − ()) = 5. Suppose instead\
    \ that is the specification from Example [2.1](#page-2-2) and is the trace from\
    \ Table [4.](#page-3-1) The robustness value is (, ) = 0, i.e., is violated as\
    \ the ego vehicle fails to stop before the stop line when the traffic light turns\
    \ red. □\n\n# 3.2 Trajectory Repair\n\nIf the robustness value of with respect\
    \ to a trace is below a certain threshold , there is a risk of violating in the\
    \ future, even if 0 < (, ) ≤ (given that there is uncertainty in the predicted\
    \ environment). This threshold is determined experimentally in our work (Section\
    \ [4\\)](#page-6-1): intuitively, it characterises how 'cautious' the ADS is.\
    \ In order to enforce , i.e., proactively prevent its possible violation, REDriver\
    \ repairs the planned trajectory before sending\n\nit to the control module of\
    \ the ADS so as to change the commands that will be generated.\n\nOur trajectory\
    \ repair method consists of three steps. First, we identify the earliest time\
    \ step when the robustness value falls below the threshold. Second, we compute\
    \ the gradient (through autodifferentiation [\\[22\\]](#page-10-13)) of each variable\
    \ at the identified time step with respect to the robustness degree. Based on\
    \ the result, we then modify the variable to increase the robustness degree. Finally,\
    \ we modify the planned trajectory accordingly and feed it into the control module.\
    \ In the following, we present each step in detail.\n\nDetermine the time step.\
    \ Given a trace = ⟨(0, 0), · · · , (, )⟩, we write to denote the prefix ⟨(0, 0),\
    \ (1, 1), · · · , ( , )⟩. Given such that (, ) < , we aim to identify a time step\
    \ such that: (1) (, ) < ; and (2) there does not exist a time step such that <\
    \ and (, ) < . Intuitively, is the earliest time step when the robustness value\
    \ falls below the threshold. We identify the time step using a sequential search,\
    \ i.e., we start from = 0 and keep increasing until we find a such that (, ) <\
    \ .\n\n<span id=\"page-4-0\"></span>Example 3.2. Let = 38<sup>3</sup> from Example\
    \ [2.1](#page-2-2) and denote the trace from Table [4.](#page-3-1) Suppose the\
    \ threshold is 10. Then, as shown in Example [3.1,](#page-3-2) (383, ) = 0 and\
    \ is thus below the threshold. Then, we apply the above-mentioned algorithm to\
    \ identify the time step. The following are computed in sequence.\n\n$$\\rho(\\\
    wp, \\pi^0) = 42, \\dots, \\rho(\\wp, \\pi^2) = 28.66, \\dots, \\text{ },$$\n\n\
    $$\\rho(\\wp, \\pi^4) = 17.17, \\dots, \\rho(\\wp, \\pi^6) = 6.15$$\n\nThus, the\
    \ time step that we are looking for is 6 (as 6 < ). □\n\nCalculate the gradient.\
    \ Next, we find out how the variables at time step should be modified so that\
    \ the robustness degree of the resulting trace can be improved. We thus define\
    \ a differentiation function that calculates the gradient of each relevant variable\
    \ with respect to the robustness degree. Intuitively, when the gradient of a variable\
    \ at time is positive (resp. negative), we can increase the robustness degree\
    \ by increasing (resp. decreasing) the value of .\n\nRecall that the robustness\
    \ degree of is computed using discrete functions and (Definition [2\\)](#page-3-3)\
    \ that are hard to differentiate [\\[46\\]](#page-11-6). Hence, we adopt a continuous\
    \ robustness measure as defined in [\\[20,](#page-10-14) [35\\]](#page-11-7) which\
    \ replaces and in Definition [2](#page-3-3) with continuous functions <sup>g</sup>\
    \ and <sup>g</sup> as follows:\n\n$$\\begin{aligned} \\widetilde{max}\\{\\mathbf{x}\\\
    _0, \\mathbf{x}\\_1, \\dots, \\mathbf{x}\\_m\\} &= \\frac{1}{a} \\ln(\\sum\\_{i=1}^m\
    \ e^{\\alpha \\mathbf{x}\\_i}) \\\\\\widetilde{min}\\{\\mathbf{x}\\_0, \\mathbf{x}\\\
    _1, \\dots, \\mathbf{x}\\_m\\} &= -\\widetilde{max}(-\\mathbf{x}\\_0, -\\mathbf{x}\\\
    _1, \\dots, -\\mathbf{x}\\_m) \\end{aligned}$$\n\nwhere is a constant that controls\
    \ the accuracy of <sup>g</sup> and <sup>g</sup>. The larger is, the closer <sup>g</sup>\
    \ (resp. <sup>g</sup>) is to (resp. ). We set to be 10, following [\\[20,](#page-10-14)\
    \ [35\\]](#page-11-7). We denote the continuous robustness degree as ˜(, ). The\
    \ following proposition from [\\[20,](#page-10-14) [35\\]](#page-11-7) establishes\
    \ the soundness of approximating (, ) with ˜(, ).\n\nProposition 3.3. Let be an\
    \ STL formula, be a trace, and be a real value larger than 0. Then, there exists\
    \ a value <sup>1</sup> such that |˜(, ,) − (, ,)| < holds for all > 1. □\n\nNext,\
    \ we define a differentiation function(, , ) that returns a given variable 's\
    \ gradient with respect to (, ) at time .\n\n$$D(\\boldsymbol{\\varphi}, \\boldsymbol{\\\
    pi}, \\mathbf{x}^k) = \\frac{\\partial \\bar{\\rho}(\\boldsymbol{\\varphi}, \\\
    boldsymbol{\\pi}, \\mathbf{0})}{\\partial \\mathbf{x}^k}$$\n\nThe following shows\
    \ how (, , ) is computed.\n\n<span id=\"page-4-1\"></span>Definition 3. Given\
    \ an STL formula and trace , function (, , ) is defined as follows:\n\n$$\\frac{\\\
    partial \\bar{\\rho}\\,(\\mu,\\pi,t)}{\\partial \\mathbf{x}^k} = \\begin{cases}\
    \ 0 & \\text{if } k \\neq t \\\\ \\frac{df'(\\varkappa\\_0, \\varkappa\\_1, \\\
    cdots, \\varkappa\\_n)}{dx^k} & \\text{otherwise} \\end{cases}$$\n\nwhere ′ (0,1,···\
    \ , ) is the derivative of function ′ with respect to . Furthermore, let ( {0,1,...,\
    \ } ) be defined as Í =1 , and let <sup>g</sup> ( {0,1,..., } ) be defined as\
    \ − Í =1 − . ˜ (¬, , ) = − ˜ (, , ) ˜ (<sup>1</sup> ∧ 2, , ) = <sup>g</sup> {˜\
    \ (1, , ) , ˜ (2, , ) } ˜ (1, , ) · ˜ (1, , ) + <sup>g</sup> {˜ (1, , ) , ˜ (2,\
    \ , ) } ˜ (2, , ) · ˜ (2, , ) ˜ (<sup>1</sup> ∨ 2, , ) = {˜ (1, , ) , ˜ (2, ,\
    \ ) } ˜ (1, , ) · ˜ (1, , ) + {˜ (1, , ) , ˜ (2, , ) } ˜ (2, , ) · ˜ (2, , ) ˜\
    \ (<sup>1</sup> U<sup>I</sup> 2, , ) = ∑︁ ′ ∈+I ˜ (<sup>1</sup> U<sup>I</sup>\
    \ 2, , ) ˜ (1, , ′ ) · ˜ (1, , ′ ) + ˜ (<sup>1</sup> U<sup>I</sup> 2, , ) ˜ (2,\
    \ , ′ ) · ˜ (2, , ′ ) \n\nwhere ˜(<sup>1</sup> <sup>U</sup><sup>I</sup> 2,,) ˜(1,,′\
    \ ) is the derivative of ˜ (1UI2, , ) with respect to ˜ (1, , ′ ), and is defined\
    \ as:\n\n∑︁ 1 ∈+I∧1≥ ′ © « { {˜ (<sup>2</sup> , , 1 ), inf<sup>2</sup> ∈ [,<sup>1</sup>\
    \ ] ˜ (1 , , 2 ) } |1 ∈ + I} {˜ (<sup>2</sup> , , 1 ), inf<sup>2</sup> ∈ [,<sup>1</sup>\
    \ ] ˜ (1 , , 2 ) } · {˜ (<sup>2</sup> , , 1 ), inf<sup>2</sup> ∈ [,<sup>1</sup>\
    \ ] ˜ (1 , , 2 ) } inf<sup>2</sup> ∈ [,<sup>1</sup> ] ˜ (1 , , 2 ) · {˜ (<sup>1</sup>\
    \ , , 2 ) | 2 ∈ [, 1 ]} ˜ (1 , , ′ ) ª ® where ˜(<sup>1</sup> <sup>U</sup><sup>I</sup>\
    \ 2,,) ˜(2,,′ ) is defined as:\n\n { <sup>g</sup> {˜(2, , <sup>1</sup> ), inf<sup>2</sup>\
    \ ∈ [,<sup>1</sup> ] ˜(1, , <sup>2</sup> ) } | <sup>1</sup> <sup>∈</sup> <sup>+</sup>\
    \ <sup>I</sup>} <sup>g</sup> {˜(2, , ′ ), inf<sup>2</sup> ∈ [, ′ ] ˜(1, , <sup>2</sup>\
    \ ) } · <sup>g</sup> {˜(2, , ′ ), inf<sup>2</sup> ∈ [, ′ ] ˜(1, , <sup>2</sup>\
    \ ) } ˜(2, , ′ )\n\n□\n\nGiven the time step previously identified, we apply the\
    \ above definition to compute(, , ) for every variable . The purpose of the differentiation\
    \ function D is to determine the \"responsibility\" of each signal in violating\
    \ the specification. In other words, consider the computation of robustness as\
    \ a function of multiple variables where D determines the gradient of each variable.\
    \ We remark that our implementation of (, , ) is based on automatic differentiation\
    \ techniques [\\[22\\]](#page-10-13). Intuitively, we store the intermediate values\
    \ while computing the robustness degree, and then compute the gradients based\
    \ on reverse accumulation.\n\n<span id=\"page-5-1\"></span>Example 3.4. Given\
    \ the trace of Table [4,](#page-3-1) the following shows how to calculate the\
    \ gradient of with respect to <sup>0</sup> = □( > 5) at time step 6:\n\n$$D\\\
    left(\\varphi\\_0, \\pi^6, speed^6\\right) = \\frac{\\partial \\rho\\left(\\varphi,\
    \ \\pi^6, 0\\right)}{\\partial \\rho\\left(speed^2 > 5, \\pi^6, 6\\right)} \\\
    cdot \\frac{\\partial \\rho\\left(speed > 5, \\pi^6, 6\\right)}{\\partial speed^6}$$\n\
    \n$$= \\frac{e^{-10 \\times 0.09}}{e^{-10 \\times 2.01} + e^{-10 \\times 1.13}\
    \ + e^{-10 \\times 0.44} + e^{-10 \\times 0.09}} \\cdot 1 = 0.97$$\n\n$$Similarly,\
    \ continuity \\, Example 3.2, the gradients \\, are \\, computed \\, as \\, follows:$$\n\
    \n$$D\\left(llaw \\, 38\\_3, \\pi^6, speed^6\\right) = 8.39 \\times 10^{-08}$$\n\
    \n$$D\\left(llaw \\, 38\\_3, \\pi^6, D\\left(stophine\\right)^6\\right) = 0.5$$\n\
    \n$$D\\left(llaw \\, 38\\_3, \\pi^6, D\\left(j\\omega cten\\right)^6\\right) =\
    \ 0.5$$\n\n$$D\\left(llaw \\, 38\\_3, \\pi^6, drection^6\\right) = -4.74 \\times\
    \ 10^{-19}$$\n\n$$D\\left(llaw \\, 38\\_3, \\pi^6, TL\\left(color\\,\\big)^6\\\
    right) = -9.48 \\times 10^{-19}$$\n\n$$D\\left(llaw \\, 38\\_3, \\pi^6, Plot\\\
    right) V\\left(20\\right)^6 = -9.77 \\times 10^{-28}$$\n\n$$D(la \\bowtie 38\\\
    _3, \\pi^6, Prior \\wr light yN(20)^6) = 2.15 \\times 10^{-23}$$\n\nThe gradients\
    \ for variable ( ) and () at time step 6 are positive, which means that we can\
    \ effectively increase the robustness value (383, <sup>6</sup> ) by increasing\
    \ ( ) 6 or () 6 . □\n\n<span id=\"page-5-0\"></span>Proposition 3.5. Let (, ,\
    \ ) be the result of gradient calculation as shown in Definition [3.](#page-4-1)\
    \ When (, , ) is positive (or negative), there exists an interval (0, Δ) such\
    \ that increasing (or decreasing) within this interval increases in the value\
    \ of ˜(, ).\n\nProof. First, if is a Boolean Expression , ˜(, ) can be represented\
    \ by a continuous function ′ (0, · · · , ) as shown in Definition [2.](#page-3-3)\
    \ Given that ′ (0, · · · , ) is confined to linear or absolute value functions,\
    \ the proposition holds for .\n\nThen, assuming the proposition holds, the proposition\
    \ holds if we can prove the proposition holds for each and every way can be constructed,\
    \ i.e., ¬1, <sup>1</sup> ∧ 2, <sup>1</sup> ∨ 2, and <sup>1</sup> U<sup>I</sup>\
    \ 2.\n\nIf is in the format of ¬1, we have ˜(¬1, ) = −˜(1, ), and (¬1, , ) = −(1,\
    \ , ). Thus, by negating the modification, we can ensure that the proposition\
    \ holds for ¬1.\n\nIf is in the format of <sup>1</sup> ∨ 2, ˜(<sup>1</sup> ∨ 2,\
    \ ) = 1 ln( <sup>1</sup> + <sup>2</sup> ), and (<sup>1</sup> ∨2, , ) = 1 1+ 2\
    \ · (1, , ) + 2 1+ 2 · (2, , ). Here, <sup>1</sup> = ˜(1, ), <sup>2</sup> = ˜(2,\
    \ ), → ∞. Suppose the proposition holds for ˜(1, ) within interval (0, Δ1), and\
    \ holds for ˜(2, ) within interval (0, Δ2). If <sup>1</sup> ≠ 2, suppose <sup>1</sup>\
    \ > 2, then we have 1 1+ <sup>2</sup> → 1, 2 1+ <sup>2</sup> → 0, and (<sup>1</sup>\
    \ ∨ 2, , ) → (1, , ). The proposition holds for interval (0, Δ1). If <sup>1</sup>\
    \ = 2, then (<sup>1</sup> ∨ 2, , ) > 0 indicates (1, , ) + (2, , ) > 0. Even if\
    \ one of (1, , ) and (2, , ) is negative, the value of <sup>1</sup> + <sup>2</sup>\
    \ still increases, leading to the increase of ˜(<sup>1</sup> ∨2, ). Let Δ ′ be\
    \ a number larger than 0 and smaller than {Δ1, Δ2}. The proposition holds for\
    \ (0, Δ ′ ).\n\nIf is in the format of <sup>1</sup> ∧ 2, since <sup>1</sup> ∧\
    \ <sup>2</sup> = ¬(¬<sup>1</sup> ∨ ¬2), we can deduce that the proposition always\
    \ holds for <sup>1</sup> ∧ 2.\n\nIf is in the format of <sup>1</sup> U<sup>I</sup>\
    \ 2. Since ˜(<sup>1</sup> U<sup>I</sup> 2, ) is a combination of the function\
    \ <sup>g</sup> and <sup>g</sup>, we can deduce that the proposition always holds\
    \ for <sup>1</sup> U<sup>I</sup> 2.\n\nTherefore, we can conclude that the proposition\
    \ holds. □\n\nIntuitively, Proposition [3.5](#page-5-0) clarifies that the gradient\
    \ calculation function (, , ) reflects the changing trend of the robustness\n\n\
    <span id=\"page-5-2\"></span>\n\n| Algorithm 1: Trajectory repair algorithm |\
    \                                                                            \
    \   |  |  |\n|------------------------------------------|-------------------------------------------------------------------------------|--|--|\n\
    |                                          | Input: variable/function<br>\U0001D465\
    , time step<br>\U0001D458, magnitude<br>\U0001D6FF                 |  |  |\n|\
    \                                          | 1 case \U0001D465 is \U0001D460\U0001D45D\
    \U0001D452\U0001D452\U0001D451 do                                            \
    \              |  |  |\n| 2                                        | \U0001D460\
    \U0001D45D\U0001D452\U0001D452\U0001D451\U0001D458<br>\U0001D460\U0001D45D\U0001D452\
    \U0001D452\U0001D451\U0001D458 +<br>Set<br>to be<br>\U0001D6FF;              \
    \                        |  |  |\n|                                          |\
    \ 3 case \U0001D465 is \U0001D451\U0001D456\U0001D45F\U0001D452\U0001D450\U0001D461\
    \U0001D456\U0001D45C\U0001D45B do                                            \
    \          |  |  |\n| 4                                        | \U0001D451\U0001D456\
    \U0001D45F\U0001D452\U0001D450\U0001D461\U0001D456\U0001D45C\U0001D45B\U0001D458\
    \ +<br>Choose a value<br>(0, 1, or 2) that is closest to<br>\U0001D6FF;<br>\U0001D451\
    0 |  |  |\n| 5                                        | Set the<br>\U0001D460\U0001D461\
    \U0001D452\U0001D452\U0001D45F at time<br>\U0001D458 to 0 if<br>\U0001D4510<br>=\
    \ 0;                           |  |  |\n| 6                                  \
    \      | Otherwise set the<br>\U0001D460\U0001D461\U0001D452\U0001D452\U0001D45F\
    \ at time<br>\U0001D458 to 0.1 if<br>= 1;<br>\U0001D4510               |  |  |\n\
    | 7                                        | Otherwise set the<br>\U0001D460\U0001D461\
    \U0001D452\U0001D452\U0001D45F at time<br>\U0001D458 to -0.1 if<br>\U0001D451\
    0<br>= 2;              |  |  |\n|                                          | 8\
    \ case \U0001D465 is of the form \U0001D437 (_) or \U0001D43F\U0001D44E\U0001D45B\
    \U0001D452 (_) do                                  |  |  |\n| 9              \
    \                          | Search for a coordinate<br>(\U0001D44E, \U0001D44F\
    ) (i.e., new position for the ego             |  |  |\n|                     \
    \                     | vehicle) such that<br>\U0001D437 (_)<br>becomes<br>\U0001D437\
    \ (_) +<br>\U0001D6FF or<br>\U0001D43F\U0001D44E\U0001D45B\U0001D452 (_)     \
    \    |  |  |\n|                                          | becomes<br>\U0001D43F\
    \U0001D44E\U0001D45B\U0001D452 (_) +<br>\U0001D6FF;                          \
    \                         |  |  |\n| 10                                      \
    \ | Set the position of the ego vehicle at time<br>\U0001D458 to<br>(\U0001D44E\
    , \U0001D44F);                |  |  |\n| 11 end                              \
    \     |                                                                      \
    \         |  |  |\n\nfunction ˜(, ) in terms of variable . However, the changing\
    \ trend is sensitive to the variable's current value. If we increase the variable\
    \ by too much, it may lead to a decrease in robustness. For instance, consider\
    \ the specification: = 10 < < 100. Suppose the current speed is 8, then the robustness\
    \ is −2, and the gradient for speed (, , ) is 1, indicating that we should increase\
    \ the value of speed. If we increase the speed within the interval (0, 94), the\
    \ robustness will always be larger than −2. However, if we increase the speed\
    \ to 103, the robustness will become −3, resulting in a decrease. Therefore, to\
    \ guarantee an increase in robustness, it is necessary to limit the modification\
    \ within an interval of (0, Δ). Repair the trajectory. The gradients calculated\
    \ above allow us to determine how to effectively increase the robustness degree.\
    \ We can proceed to repair the trace by modifying the variable with the maximal\
    \ absolute gradient at time step . The magnitude of the modification is calculated\
    \ as follows:\n\n$$\\delta = \\frac{\\theta - \\bar{\\rho}(\\varphi, \\pi^k)}{D(\\\
    varphi, \\pi^k, \\pi^k)}; \\text{ while } \\bar{\\rho}(\\varphi, \\pi') < \\bar{\\\
    rho}(\\varphi, \\pi) \\text{ Do} : \\ \\{\\delta \\gets \\delta/2\\}.$$\n\nwhere\
    \ ′ is the trace after the modification. This magnitude of the modification indicates\
    \ that we try to increase the robustness value to . However, this adjustment might\
    \ sometimes lead to overreactions, causing a decrease in the robustness value.\
    \ In such cases, we reduce until we observe an increase in the robustness value,\
    \ and the descent rate during this process follows a scale of 2 , enabling us\
    \ to efficiently determine the magnitude. For instance, according to Example [3.4,](#page-5-1)\
    \ we should modify () or () at time step 6 with a magnitude of − (383,<sup>6</sup>\
    \ ) 0.5 = 7.7. This modification results in (383, <sup>6</sup> ) increasing from\
    \ 6.15 to 13.85.\n\nProposition 3.6. Let be a variable, and be the magnitude of\
    \ the modification on . The robustness value ˜(, ) always increases after the\
    \ modification.\n\nProof. The modification is triggered only when − ˜(, ) > 0,\
    \ which implies that and (, , ) share the same sign. As shown in Proposition [3.5,](#page-5-0)\
    \ there exists an interval (0, Δ) in which the gradient value is effective. If\
    \ the previous modification results in a decrease of ˜(, ), we can ensure an increase\
    \ in ˜(, ) by decreasing | | to a value smaller than Δ. The proposition holds.\
    \ □\n\n<span id=\"page-6-2\"></span>\n\n| Input: specification<br>\U0001D711,\
    \ trajectory<br>Γ, the threshold<br>\U0001D703             |\n|----------------------------------------------------------------------------|\n\
    | 1 Generate trace<br>\U0001D70B based on<br>Γ;                              \
    \         |\n| 2 if \U0001D70C (\U0001D711, \U0001D70B ) ≤ \U0001D703 then   \
    \                                                 |\n| \U0001D70C (\U0001D711\
    , \U0001D70B\U0001D458<br>Identify the smallest<br>\U0001D458 such that<br>) ≤\
    \ \U0001D703;<br>3            |\n| \U0001D437 (\U0001D711, \U0001D70B\U0001D458\
    <br>, \U0001D465\U0001D458<br>Compute<br>) for every controllable variable<br>\U0001D465\
    <br>4 |\n| \U0001D458 with the maximal absolute gradient;<br>Identify variable<br>\U0001D465\
    <br>5       |\n| Invoke Algorithm 1 to fix the trajectory;<br>6              \
    \               |\n| 7 end                                                   \
    \                   |\n|                                                     \
    \                       |\n\n ;\n\nRecall that our goal is to modify the planned\
    \ trajectory so as to trigger different control commands. While we may modify\
    \ the trace arbitrarily, we cannot do the same for the planned trajectory. First,\
    \ some of the variables may not be controllable, e.g., the color of the traffic\
    \ light is beyond the control of the ADS. Second, a variable may have a specific\
    \ domain of discrete values in the ADS (e.g., has the value of 0, 1, or 2) and\
    \ thus we can only choose one of those valid values. Finally, the value of a variable\
    \ may be the result of a function which depends on the current and future scenes.\
    \ For instance, () measures the distance from the ego vehicle (according to the\
    \ planned trajectory) to the stop line ahead (according to the map). In these\
    \ situations, it is very difficult to translate the modification to the planned\
    \ trajectory. Thus, we focus on modifying those signals that the ADS has control\
    \ over and modify the planned trajectory accordingly, which are , , , (\\_) (i.e.,\
    \ which lane the ego vehicle should be in), and (\\_) (i.e., how far the ego vehicle\
    \ is from a certain artifact). These naturally correspond to what human drivers\
    \ focus on. Algorithm [1](#page-5-2) describes how the planned trajectory is repaired\
    \ with respect to a specific variable/function , time step , and magnitude . Note\
    \ that the fixes are specific to certain variables since they may have specific\
    \ domains. In the case of , we are constrained to choose a value from 0, 1, 2\
    \ and set the value in the trajectory accordingly. In the case of functions based\
    \ on the ego vehicle's position (e.g., ()), we search for nearby coordinates that\
    \ are close to the desired value while still remaining on the road. Note that\
    \ the ADS's planning module and the control module are entirely black boxes to\
    \ us. Therefore, we do not take into account the correlations between variables\
    \ when modifying the planned trajectory. To do so would require the construction\
    \ of an exhaustive physical model, essentially equivalent to rebuilding the planning\
    \ module of the ADS.\n\nExample 3.7. Given the planned trajectory in Table [1,](#page-1-1)\
    \ and the repair computed for () and () in Example [3.4.](#page-5-1) We modify\
    \ the planned car position at time step 6 from (0, 35.85) to (0, 28.15) (so the\
    \ vehicle should be positioned further from the junction), leaving the remaining\
    \ planned trajectory unchanged. Note that changing the value of can rectify the\
    \ trajectory as well, however, the gradient values strongly suggest that optimizing\
    \ the position of the waypoint is a more efficient approach. □\n\n# <span id=\"\
    page-6-0\"></span>3.3 Runtime Enforcement\n\nWe are now ready to present our runtime\
    \ enforcement algorithm, as shown in Algorithm [2.](#page-6-2) First, we generate\
    \ a trace based on the planned trajectory Γ and check whether (, ) ≤ . If so,\
    \ we\n\nproceed to identify the time step when the robustness degree falls below\
    \ the threshold. Then we compute gradients for the variables at time , identify\
    \ the controllable one with the maximal absolute gradient (w.r.t. the robustness\
    \ degree) and repair the trajectory accordingly. The repaired trajectory is then\
    \ sent to the control module, which generates the commands accordingly (e.g.,\
    \ turn on/off beam, and apply brake).\n\nRecall that the specification may also\
    \ constrain the generated commands, e.g., the need to signal before turning. To\
    \ make sure the commands generated do not violate , we introduce a control validation\
    \ module (refer to Figure [1\\)](#page-1-0) that intercepts and checks the generated\
    \ commands, modifying them if necessary. Recall that commands related to motion\
    \ (e.g., brake, accelerate, steer, and gear) are generated according to the (repaired)\
    \ trajectory and thus do not require modification. We remark that these commands\
    \ are mostly simple in nature (i.e., with Boolean values) and thus we can easily\
    \ modify them according to the specification. For instance, consider the beam-related\
    \ signals, namely highBeam and lowBeam, which have on and off states. We can easily\
    \ modify these states by switching the values in the control commands sent to\
    \ the AV's chassis control.\n\nExample 3.8. Consider the trace shown in Table\
    \ [4.](#page-3-1) Recall that the signals fogLight and warningFlash are not part\
    \ of the planned trajectory: in fact, the ADS turns these off by default, i.e.,\
    \ we initially have (x,) = false (x, is the placeholder variable as discussed\
    \ in Section [3.1\\)](#page-3-0). To satisfy the specification in Example [2.1,](#page-2-2)\
    \ REDriver sets (x,) = true for each , . To realize this, we activate the fogLight\
    \ and warningFlash in the control commands. □\n\n# <span id=\"page-6-1\"></span>4\
    \ IMPLEMENTATION AND EVALUATION\n\nWe implemented REDriver for Apollo 6.0 and\
    \ 7.0 [\\[3,](#page-10-9) [4\\]](#page-10-7). The code is on our website [\\[1\\\
    ]](#page-10-15). In particular, we built a bridge program that interprets Apollo's\
    \ messages (in JSON format) and obtains the values of variables and functions\
    \ used by the specification language. Some of these values are obtained directly\
    \ (e.g., and ), but some require complex processing. For example, to get the value\
    \ of variable ℎ. at time , we obtain the planned position of the ego vehicle at\
    \ time from the planning module, and check every NPC vehicle's predicted trajectory\
    \ from the prediction module to identify the one that is ahead of the ego vehicle\
    \ at time . Our implementation relies on a third party component provided by LawBreaker\
    \ [\\[44\\]](#page-11-1). In particular, we utilise the tool's specification language\
    \ and the corresponding verification algorithm.\n\nWe conducted experiments to\
    \ answer the following Research Questions (RQs):\n\nRQ1: Can REDriver be used\
    \ to enforce non-trivial specifications? RQ2: How much overhead is there for runtime\
    \ enforcement? RQ3: Does REDriver minimise the enforcement?\n\nRQ1 considers whether\
    \ REDriver achieves its primary goal of being able to enforce complex specifications\
    \ (i.e., beyond collision avoidance). RQ2 and RQ3 consider whether REDriver implements\
    \ its enforcement in a way that is practically reasonable. The former focuses\
    \ on the overhead of runtime enforcement, since AVs are expected to react quickly\
    \ on the road. The latter focuses on the\n\n<span id=\"page-7-0\"></span>\n\n\
    | traffic laws   |      | enforced? |          | improve | fail reason  | content\
    \                             |  |\n|----------------|------|-----------|----------|---------|--------------|-------------------------------------|--|\n\
    |                |      | 6.0<br>√  | 7.0<br>√ |         |              |    \
    \                                 |  |\n|                | sub1 | √         |\
    \ √        |         | -            | green light                         |  |\n\
    | Law38<br>Law46 | sub2 | √         | √        | +55.83% | -            | yellow\
    \ light                        |  |\n|                | sub3 | √         | √ \
    \       |         | -            | red light                           |  |\n\
    | Law44          |      | √         | √        | +30.00% | -            | lane\
    \ change                         |  |\n|                | sub2 |           | \
    \         | +44.00% | -            | speed limit                         |  |\n\
    |                | sub3 | ×         | ×        | -       | Lack support | speed\
    \ limit                         |  |\n| Law47          |      | ×         | ×\
    \        | -       | Lack support | overtake                            |  |\n\
    | Law51          | sub3 | ×<br>√    | ×<br>√   | -       | Lack support | traffic\
    \ light                       |  |\n|                | sub4 | √         | √  \
    \      | +35.00% | -            | traffic light                       |  |\n|\
    \                | sub5 |           |          |         | -            | traffic\
    \ light                       |  |\n| Law57          | sub1 | ×         | ×  \
    \      | -       | Lack support | left turn signal                    |  |\n|\
    \                | sub2 | ×         | ×        | -       | Lack support | right\
    \ turn signal<br>warning signal |  |\n| Law58          |      | ×         | ×\
    \        | -       | Lack support |                                     |  |\n\
    | Law59          |      | ×         | ×        | -       | Lack support | signals\
    \                             |  |\n\nTable 5: Violations of Chinese traffic laws\n\
    \nmagnitude of the repair to the original trajectory, i.e., the enforcement should\
    \ take place only if necessary and should minimally alter the behaviour of ADS.\n\
    \nOur experiments were run in the high-fidelity LGSVL simulator [\\[38\\]](#page-11-3).\
    \ Due to randomness in the simulator (mostly due to concurrency), each experiment\
    \ was executed 100 times and we report the averages. The threshold was determined\
    \ in a preliminary experiment in which we ran Apollo multiple times for each scenario\
    \ to get the range of the possible robustness values. All experiments were obtained\
    \ using two machines with 32GB of memory, an Intel i7-10700k CPU, and an RTX 2080Ti\
    \ graphics card. The machines respectively use Linux (Ubuntu 20.04.5 LTS) and\
    \ Windows (10 Pro).\n\nRQ1: Can REDriver be used to enforce non-trivial specifications?\
    \ To answer this question, we adopted the formalisation of traffic laws reported\
    \ in [\\[44\\]](#page-11-1) as our specification and evaluated whether REDriver\
    \ can be applied so that the ADS follows them. We remark the traffic laws are\
    \ rather complicated as they model 13 testable traffic laws with many sub-clauses.\
    \ Furthermore, we use the benchmark of scenarios provided by [\\[44\\]](#page-11-1)\
    \ in which Apollo is known to violate the specification. We replay these violation-inducing\
    \ scenarios with REDriver enabled, and report in Table [5](#page-7-0) whether\
    \ our approach is able to prevent the violations from occurring. Each 'subX' in\
    \ Table [5](#page-7-0) represents sub-rules of a traffic laws. For example, Law38\
    \ pertains to traffic light regulations and has three sub-rules, each covering\
    \ the yellow, green, and red lights, respectively. The 'enforced?' column indicates\
    \ whether the enforcement is successful. The enforcement was considered to be\
    \ successful if the average passing rate of the specification after the enforcement\
    \ is more than 50% across all the repetitions. Note that Apollo's passing rate\
    \ is always below 50% for the selected scenarios. The improve column in Table\
    \ [5](#page-7-0) reports the average improvement of REDriver over Apollo, i.e.,\
    \ the maximum enhancement achieved by REDriver across a threshold value spectrum\
    \ ranging from 0.0 to 1.2, with intervals of 0.1. The improvement is calculated\
    \ by subtracting the pass rate of Apollo from the pass rate of REDriver. Note\
    \ that since the sub laws of law38 and law51 are closely related, they are evaluated\
    \ together for avg improve. The only reason that we cannot enforce some of the\
    \ failed laws is that some simulator support is currently lacking. For example,\
    \ we generate a command to turn on fogLight to satisfy the law58 as shown in Example\
    \ [2.1](#page-2-2) and LGSVL's car model ignores the command since it currently\
    \ does not support fog lights. We mark Lack support in the table to illustrate\
    \ this. The detailed improvement for all thresholds is shown in Figure [3.](#page-7-1)\
    \ In this figure,\n\n<span id=\"page-7-1\"></span>![](_page_7_Figure_7.jpeg)\n\
    \nFigure 3: Improvement of performance across thresholds\n\nthe x-axis denotes\
    \ the threshold value (), while the y-axis signifies the average percentage improvement\
    \ of REDriver over Apollo. As shown in Figure [3,](#page-7-1) REDriver successfully\
    \ enforced all cases where an enforcement is feasible.\n\nTo explore RQ1 in more\
    \ detail, we designed a second experiment that focused on law38—one of the most\
    \ complicated formulae in [\\[44\\]](#page-11-1)—which specifies how a vehicle\
    \ should behave at a traffic light junction (i.e., the constraints on movements\
    \ due to green/yellow/red lights). We then selected three scenarios highly relevant\
    \ to this traffic law: Double Lined Junction, Single Direction Junction, and T\
    \ Junction. The detailed specification 38 is given in our website [\\[1\\]](#page-10-15).\
    \ Note that these scenarios were generated by Law-Breaker [\\[44\\]](#page-11-1)\
    \ to reliably induce traffic law violations in Apollo. The seeds for the fuzzing\
    \ algorithm are given on the website [\\[1\\]](#page-10-15).\n\nWe tested Apollo\
    \ with and without REDriver on each violationinducing scenario 100 times and recorded\
    \ the pass rate and average robustness with respect to law38. Table [6](#page-8-0)\
    \ presents the result of our evaluation using Apollo 7.0 (the results for version\
    \ 6.0 are on our website [\\[1\\]](#page-10-15)), where indicates threshold values.\
    \ Recall that the smaller the robustness value, the 'closer' is a violation.\n\
    \nAs can be seen from Table [6,](#page-8-0) REDriver significantly outperforms\
    \ the original Apollo in terms of respecting the specification. In scenarios \"\
    Double-Lined Junction\" and \"Single-Direction Junction\", the original Apollo\
    \ failed to pass at the green light because it is too conservative at the junction.\
    \ For instance, Apollo sometimes decides to stop before an intersection when there\
    \ is enough space for the vehicle to pass safely. REDriver avoided the violations\
    \ by enforcing the vehicle to drive within the junction first or pass the junction\
    \ directly. As a consequence, the average improvement to the pass rate is more\
    \ than 50% for scenario \"Double-Lined Junction\" and \"Single-Direction Junction\"\
    . For scenario \"T-Junction\", the improvement of REDriver is relatively small\
    \ since there is heavy traffic in this scenario and Apollo sometimes produces\
    \ the stop command. By design, the stop command has higher priority than the planned\
    \ trajectory since it prevents crashing in urgent situations. Therefore, the enforcement\
    \ did not take effect in some cases.\n\nFurthermore, the performance of REDriver\
    \ varies with threshold , i.e., being too small or too large both lead to degraded\
    \ performance. If is too small, for example 0 (which is equivalent to the driver\
    \ being ignorant of what is going to happen), sometimes the ADS cannot enforce\
    \ in time. But if is too large (e.g., 1.0-1.2 which is equivalent to the driver\
    \ being too scared of what might happen), REDriver is overcompensating and fixing\
    \ things it should\n\n<span id=\"page-8-0\"></span>Table 6: Performance comparison\
    \ of REDriver and Apollo\n\n| Scenario   | Driver    | \U0001D703   | pass/total\
    \ | robustness | avg time |\n|------------|-----------|-----|------------|------------|----------|\n\
    |            | Apollo7.0 | -   | 40/100     | 0.27       | 71.11s   |\n|     \
    \       | REDriver  | 0.0 | 73/100     | 0.67       | 55.18s   |\n|          \
    \  | REDriver  | 0.1 | 78/100     | 0.75       | 51.11s   |\n|            | REDriver\
    \  | 0.2 | 85/100     | 0.96       | 50.56s   |\n|            | REDriver  | 0.3\
    \ | 93/100     | 1.05       | 45.67s   |\n| Double     | REDriver  | 0.4 | 95/100\
    \     | 1.07       | 45.71s   |\n| Lined      | REDriver  | 0.5 | 93/100     |\
    \ 1.10       | 45.32s   |\n| Junction   | REDriver  | 0.6 | 98/100     | 1.19\
    \       | 44.92s   |\n|            | REDriver  | 0.7 | 99/100     | 1.21     \
    \  | 44.90s   |\n|            | REDriver  | 0.8 | 96/100     | 1.15       | 45.13s\
    \   |\n|            | REDriver  | 0.9 | 99/100     | 1.20       | 45.07s   |\n\
    |            | REDriver  | 1.0 | 80/100     | 0.78       | 51.90s   |\n|     \
    \       | REDriver  | 1.1 | 75/100     | 0.71       | 52.71s   |\n|          \
    \  | REDriver  | 1.2 | 81/100     | 0.80       | 53.10s   |\n|            | Apollo7.0\
    \ | -   | 18/100     | 0.18       | 57.60s   |\n|            | REDriver  | 0.0\
    \ | 26/100     | 0.38       | 56.38s   |\n|            | REDriver  | 0.1 | 24/100\
    \     | 0.37       | 55.93s   |\n|            | REDriver  | 0.2 | 85/100     |\
    \ 0.84       | 55.95s   |\n|            | REDriver  | 0.3 | 89/100     | 0.86\
    \       | 55.75s   |\n| Single     | REDriver  | 0.4 | 89/100     | 0.89     \
    \  | 55.69s   |\n| Direction  | REDriver  | 0.5 | 88/100     | 0.87       | 56.71s\
    \   |\n| Junction   | REDriver  | 0.6 | 91/100     | 0.92       | 56.18s   |\n\
    |            | REDriver  | 0.7 | 95/100     | 0.99       | 56.13s   |\n|     \
    \       | REDriver  | 0.8 | 93/100     | 0.96       | 57.09s   |\n|          \
    \  | REDriver  | 0.9 | 96/100     | 1.02       | 57.55s   |\n|            | REDriver\
    \  | 1.0 | 35/100     | 0.56       | 57.10s   |\n|            | REDriver  | 1.1\
    \ | 31/100     | 0.45       | 56.79s   |\n|            | REDriver  | 1.2 | 24/100\
    \     | 0.33       | 56.61s   |\n|            | Apollo7.0 | -   | 45/100     |\
    \ 0.29       | 64.66s   |\n|            | REDriver  | 0.0 | 41/100     | 0.32\
    \       | 64.10s   |\n|            | REDriver  | 0.1 | 45/100     | 0.43     \
    \  | 63.93s   |\n|            | REDriver  | 0.2 | 46/100     | 0.59       | 60.95s\
    \   |\n|            | REDriver  | 0.3 | 50/100     | 0.77       | 61.82s   |\n\
    |            | REDriver  | 0.4 | 49/100     | 0.79       | 60.76s   |\n| T-Junction\
    \ | REDriver  | 0.5 | 53/100     | 0.45       | 62.30s   |\n|            | REDriver\
    \  | 0.6 | 55/100     | 0.39       | 61.92s   |\n|            | REDriver  | 0.7\
    \ | 50/100     | 0.41       | 61.70s   |\n|            | REDriver  | 0.8 | 51/100\
    \     | 0.35       | 62.89s   |\n|            | REDriver  | 0.9 | 42/100     |\
    \ 0.33       | 63.23s   |\n|            | REDriver  | 1.0 | 43/100     | 0.37\
    \       | 63.45s   |\n|            | REDriver  | 1.1 | 40/100     | 0.40     \
    \  | 63.70s   |\n|            | REDriver  | 1.2 | 39/100     | 0.41       | 64.07s\
    \   |\n\nnot, which can lead to unexpected ADS behaviour. Note that a significant\
    \ number of valid trajectories have a robustness of 1, and such an overreaction\
    \ is more likely to occur for ≥ 1.\n\nRQ2: How much overhead does the runtime\
    \ enforcement impose? To answer this question, we collect information on the running\
    \ time of the plan validation module of REDriver for different scenarios. The\
    \ overhead for control validation is very small (less than 0.01% of the the overhead\
    \ of the plan validation module), and we ignore it in the later experiment. The\
    \ detailed data for REDriver based on Apollo 7.0 is shown in Table [7](#page-8-1)\
    \ (the results for version 6.0 are shown on our website [\\[1\\]](#page-10-15)).\
    \ Here, S1-S3 corresponds to the Double Lined Junction, Single-Direction Junction,\
    \ and T-Junction as in Table [6,](#page-8-0) avg fix represents the average number\
    \ of fixes during a test that successfully enables the ADS to follow the specification,\
    \ max fix represents the maximum number of fixes detected across the test cases,\
    \ avg(ms) means the average time consumption of the\n\nTable 7: Overhead of REDriver\n\
    \n<span id=\"page-8-1\"></span>\n\n|    | \U0001D703   | avg fix | max fix | fix\
    \ (%) | avg(ms) | max(ms) | time (%) |  |\n|----|-----|---------|---------|---------|---------|---------|----------|--|\n\
    | S1 | 0.0 | 26.08   | 35      | 5.09%   | 1.92    | 6.82    | 4.88%    |  |\n\
    |    | 0.1 | 24.19   | 35      | 4.76%   | 1.88    | 9.11    | 4.81%    |  |\n\
    |    | 0.2 | 19.20   | 35      | 4.15%   | 1.90    | 9.10    | 4.72%    |  |\n\
    |    | 0.3 | 18.33   | 32      | 3.57%   | 1.87    | 9.23    | 5.05%    |  |\n\
    |    | 0.4 | 22.33   | 35      | 3.89%   | 1.85    | 9.86    | 4.98%    |  |\n\
    |    | 0.5 | 33.12   | 45      | 6.19%   | 1.91    | 8.81    | 4.90%    |  |\n\
    |    | 0.6 | 32.06   | 45      | 6.07%   | 1.72    | 9.08    | 4.89%    |  |\n\
    |    | 0.7 | 33.20   | 45      | 6.19%   | 1.88    | 9.12    | 5.04%    |  |\n\
    |    | 0.8 | 39.75   | 93      | 7.31%   | 1.95    | 9.10    | 4.92%    |  |\n\
    |    | 0.9 | 40.18   | 102     | 7.45%   | 1.96    | 10.53   | 4.85%    |  |\n\
    |    | 1.0 | 87.20   | 230     | 17.29%  | 2.13    | 11.15   | 6.35%    |  |\n\
    |    | 1.1 | 86.02   | 231     | 17.14%  | 2.05    | 10.55   | 6.01%    |  |\n\
    |    | 1.2 | 86.05   | 230     | 16.79%  | 2.11    | 11.13   | 6.26%    |  |\n\
    |    | 0.0 | 10.22   | 17      | 2.51%   | 1.67    | 7.01    | 4.52%    |  |\n\
    |    | 0.1 | 10.71   | 17      | 2.55%   | 1.53    | 6.97    | 4.49%    |  |\n\
    |    | 0.2 | 10.56   | 20      | 2.78%   | 1.55    | 6.74    | 4.51%    |  |\n\
    |    | 0.3 | 12.05   | 22      | 2.93%   | 1.56    | 6.72    | 4.22%    |  |\n\
    |    | 0.4 | 12.10   | 22      | 2.90%   | 1.55    | 7.15    | 4.21%    |  |\n\
    |    | 0.5 | 12.21   | 20      | 2.95%   | 1.66    | 6.97    | 4.38%    |  |\n\
    | S2 | 0.6 | 12.23   | 20      | 2.98%   | 1.54    | 7.53    | 4.31%    |  |\n\
    |    | 0.7 | 12.48   | 22      | 2.73%   | 1.52    | 7.19    | 4.47%    |  |\n\
    |    | 0.8 | 14.35   | 22      | 3.11%   | 1.54    | 6.80    | 4.19%    |  |\n\
    |    | 0.9 | 14.75   | 20      | 3.60%   | 1.49    | 6.78    | 4.28%    |  |\n\
    |    | 1.0 | 170.15  | 177     | 42.57%  | 1.88    | 9.15    | 5.89%    |  |\n\
    |    | 1.1 | 169.12  | 185     | 40.82%  | 1.75    | 9.23    | 5.30%    |  |\n\
    |    | 1.2 | 169.20  | 177     | 41.17%  | 2.09    | 9.09    | 5.61%    |  |\n\
    |    | 0.0 | 38.92   | 51      | 9.02%   | 1.63    | 9.14    | 4.18%    |  |\n\
    |    | 0.1 | 37.03   | 49      | 8.87%   | 1.67    | 9.21    | 4.50%    |  |\n\
    | S3 | 0.2 | 37.71   | 49      | 8.89%   | 1.70    | 9.45    | 4.39%    |  |\n\
    |    | 0.3 | 37.28   | 49      | 8.96%   | 1.84    | 9.21    | 4.54%    |  |\n\
    |    | 0.4 | 35.22   | 52      | 8.75%   | 1.82    | 9.50    | 4.43%    |  |\n\
    |    | 0.5 | 37.33   | 49      | 9.01%   | 1.71    | 9.34    | 4.70%    |  |\n\
    |    | 0.6 | 34.70   | 52      | 8.05%   | 1.69    | 10.13   | 4.90%    |  |\n\
    |    | 0.7 | 33.13   | 52      | 7.80%   | 1.75    | 9.12    | 4.82%    |  |\n\
    |    | 0.8 | 35.56   | 40      | 8.35%   | 1.70    | 9.29    | 4.88%    |  |\n\
    |    | 0.9 | 32.46   | 40      | 7.76%   | 1.77    | 9.17    | 4.91%    |  |\n\
    |    | 1.0 | 233.73  | 298     | 52.05%  | 2.19    | 11.21   | 5.83%    |  |\n\
    |    | 1.1 | 232.76  | 298     | 52.18%  | 2.27    | 11.20   | 5.79%    |  |\n\
    |    | 1.2 | 234.46  | 298     | 51.99%  | 2.22    | 11.34   | 5.85%    |  |\n\
    \nplan validation module in one run, max(ms) indicates the maximum time consumption\
    \ detected, fix (%) is calculated by dividing the average fixes by the average\
    \ updates of the planned trajectory during a run, and time (%) is calculated by\
    \ dividing the average time consumption of the plan validation module by the average\
    \ time consumption of the production of a planned trajectory. The time units in\
    \ Table [7](#page-8-1) are all milliseconds.\n\nAs can be seen from Table [7,](#page-8-1)\
    \ the time consumption of the plan validation module is practical, i.e., the average\
    \ time consumption is always smaller than 2.5 milliseconds, the max time consumption\
    \ is always smaller than 12 milliseconds, and the time percent is always within\
    \ 6%. Furthermore, the number of fixes is related to the value of as expected.\
    \ There is a large increase in the number of fixes and fix percent for a large\
    \ ℎℎ ≥ 1.0 across all three scenarios. This is consistent with the performance\
    \ degradation at ℎℎ ≥ 1.0 shown in Table [6](#page-8-0) since unnecessary fixes\
    \ cause problems.\n\nRQ3: Does REDriver minimise the enforcement? To answer this\
    \ question, first, recall our approach as described in Section [3.](#page-3-4)\
    \ We identify the smallest k with (, ) < . Hence, our fix applies\n\n<span id=\"\
    page-9-0\"></span>![](_page_9_Figure_2.jpeg)\n\nFigure 4: Magnitude of modifications\
    \ to planned trajectories\n\nonly to the earliest part of the planned trajectory\
    \ that leads to the near-violation of the specification. In most cases, we only\
    \ modify one variable at one time step, such as the \"speed\" at some time step.\
    \ For some rare cases, we may modify multiple variables at one time step, such\
    \ as the \"speed\" and \"position\", if modifying one single variable is not sufficient.\
    \ Note that the ADS updates the planned trajectory based on current perceptions\
    \ and predictions and the impact of our change does not accumulate.\n\nHere, we\
    \ require a method to assess the variance between the modified planned trajectory\
    \ and the original trajectory. This quantification is calculated by assessing\
    \ the positional variance between these trajectories. When alterations are made\
    \ to the speed or acceleration, we translate these changes into positional differences.\
    \ To be precise, the conversion for speed discrepancies is determined as follows:\
    \ (′ − ) · , and for acceleration discrepancies: (′ −) · 2 , where signifies the\
    \ time interval between the current planned waypoint and the subsequent waypoint.\
    \ For instance, if a speed adjustment of magnitude 2/ is applied to a planned\
    \ waypoint, and the time interval is 0.2, then the positional difference is calculated\
    \ as 2/ · 0.1 = 0.2. The magnitude of modifications is shown in Figure [4.](#page-9-0)\
    \ In this figure, the x-axis represents the threshold value , and the y-axis represents\
    \ the magnitude of the modification of REDriver in meters. The graph presented\
    \ in the figure denotes the average/max modification value of REDriver across\
    \ thousands of fixes. Notably, for thresholds ranging from 0.0 to 1.2, the average\
    \ difference consistently remains below 1 meter. This observation suggests that\
    \ REDriver's modification on the planned trajectory is small. Note that there\
    \ is a significant increase in max difference for threshold 1.0. This phenomenon\
    \ is attributed to an excessive number of unnecessary fixes, as explained in RQ1.\n\
    \nIn addition, the average running time for the test cases is listed in the last\
    \ column of Table [6.](#page-8-0) Here, avg time represents the average time spent\
    \ by the ADS to travel from the start point to the destination. As can be seen\
    \ from the last column of Table [6,](#page-8-0) the running time did not increase\
    \ across all these test cases. This indicates that REDriver did not, in practice,\
    \ force the ADS to produce a substantially different trajectory to follow (e.g.,\
    \ halting the car). Note in addition that the time consumption of REDriver has\
    \ dropped substantially compared to the original Apollo in the scenario \"Double-Lined\
    \ Junction\". This is because Apollo hesitated at the green light, while REDriver\
    \ successfully passed through.\n\n# 5 RELATED WORK\n\nRuntime verification approaches\
    \ monitor messages obtained from ADSs and evaluate them against a specification\
    \ using a number of different techniques. For instance, Kane et al. [\\[26\\]](#page-10-16)\
    \ generate a system trace from the observed network state, and Heffernan et al.\
    \ [\\[24\\]](#page-10-17) use system-on-a-chip based monitors as sources of information.\
    \ Watanabe et al. [\\[45\\]](#page-11-8) focus on runtime monitoring of the controller\
    \ safety properties of advanced driver-assistance systems (ADASs). Mauritz et\
    \ al. [\\[30\\]](#page-10-18) generate monitors for ADAS features from safety\
    \ requirements and by training on simulators. D'Angelo et al. [\\[10\\]](#page-10-19)\
    \ present Lola, a simple and expressive specification language to describe both\
    \ correctness/failure assertions, which has been successfully deployed on autonomous\
    \ vehicles in addition to many successful flight deployments. Note that there\
    \ is no enforcement of specifications in the works mentioned above.\n\nRuntime\
    \ enforcement goes beyond monitoring and attempts to enforce certain safety properties.\
    \ Existing works [\\[8,](#page-10-20) [21,](#page-10-6) [25,](#page-10-21) [43\\\
    ]](#page-11-9) already propose a few methods for runtime enforcement of ADSs.\
    \ AVGuardian [\\[25\\]](#page-10-21) performs static analysis of the communication\
    \ messages between the ADS modules to generate control policies and enforce them\
    \ during runtime. Guardauto et al. [\\[8\\]](#page-10-20) divide the ADS into\
    \ a few partitions for the detection of rogue behaviours and restart the partition\
    \ in order to clear them. Shankaro et al. [\\[43\\]](#page-11-9) define a policy\
    \ using an automaton and enforce the car to stop when the policy is violated.\
    \ Grieser et al. [\\[21\\]](#page-10-6) build an end-to-end neural network (from\
    \ LIDAR to torques/steering) that implicitly picks up safety rules. Simultaneously,\
    \ the distance to obstacles on the current trajectory is monitored and emergency\
    \ brakes are applied if a collision is likely. Generally, when enforcement for\
    \ an ADS takes place in these works, it tends to be quite 'weak', (e.g. emergency\
    \ brake). REDriver, on the other hand, provides runtime enforcement for a rich\
    \ specification in ways that are less intrusive.\n\nIn addition, there are existing\
    \ works for cyber-physical systems [\\[37,](#page-11-10) [48,](#page-11-11) [49\\\
    ]](#page-11-12). Pinisetty et al. [\\[37\\]](#page-11-10) formalise the runtime\
    \ enforcement problem for CPSs, where policies depend not only on a controller\
    \ but also an environment. Another approach, Safety Guard [\\[49\\]](#page-11-12),\
    \ adds automata-based reactive components to the original system, which react\
    \ to ensure a predefined set of safety properties, while also keeping the deviation\
    \ from the original system to a minimum. ModelPlex [\\[32\\]](#page-11-13) checks\
    \ for model compliance of cyber-physical systems and includes a fail-safe action\
    \ to avoid violations of safety properties. CBSA [\\[36\\]](#page-11-14) proposes\
    \ the idea of integrating assume-guarantee reasoning to allow runtime assurance\
    \ of cyber-physical systems. These works are relevant to the runtime enforcement\
    \ of ADSs since ADSs are cyber-physical systems as well. However, we can not directly\
    \ apply these methods to ADSs and customization of the enforcement techniques\
    \ is necessary due to the unique requirements and challenges posed by ADSs. For\
    \ instance, the enforcement of ADSs requires consideration of not only the current\
    \ control commands but also the planned trajectory.\n\nRuntime enforcement is\
    \ not limited to ADSs, i.e., there are works providing runtime enforcement/verification\
    \ for general systems (e.g., [\\[5,](#page-10-22) [7,](#page-10-23) [11,](#page-10-24)\
    \ [12,](#page-10-25) [16,](#page-10-26) [17,](#page-10-27) [19,](#page-10-28)\
    \ [28,](#page-10-29) [33,](#page-11-15) [39](#page-11-16)[–42,](#page-11-17) [47\\\
    ]](#page-11-18)). The Simplex architecture [\\[5,](#page-10-22) [42\\]](#page-11-17)\
    \ introduces the idea of \"runtime enforcement\" to enhance the reliability of\
    \ complex software, and has been widely adopted in both academia and industry.\
    \ Shield synthesis [\\[7\\]](#page-10-23) proposes a method\n\nof runtime enforcement\
    \ for reactive systems while also minimising interference to the original behaviour.\
    \ Schneider [\\[40\\]](#page-11-19) looks at runtime enforcement of security policies\
    \ and stops the program when they are violated. Falcone et al. [\\[16\\]](#page-10-26)\
    \ propose enforcement by buffering actions and dumping them only when deemed safe.\
    \ Ligatti et al. [\\[28\\]](#page-10-29) use 'edit automata' to respond to dangerous\
    \ actions by suppressing them or inserting other actions. Desai et al. [\\[11\\\
    ]](#page-10-24) enforce the plan trajectory of mobile robots so as to follow STL\
    \ specifications. Expanding upon this idea, Soter [\\[12\\]](#page-10-25) allows\
    \ for safety properties to be specified and enforced in robotic systems. Tools\
    \ such as TuLip [\\[47\\]](#page-11-18) and LTLMoP [\\[19\\]](#page-10-28) synthesize\
    \ trajectories to assist evaluation of the control system under linear temporal\
    \ logic (LTL) specifications. Barron Associates provide a comprehensive study\
    \ of runtime enforcement architecture for highly adaptive flight ontrol systems\
    \ [\\[39\\]](#page-11-16). The Copilot tool [\\[33\\]](#page-11-15) offers a comprehensive\
    \ runtime enforcement environment that incorporates numerous operating-system-like\
    \ functionalities. The R2U2 [\\[41\\]](#page-11-20) monitors the security properties\
    \ of on-board Unmanned Aerial Systems (UAS) and is implemented in FPGA hardware.\
    \ Unfortunately, many existing general runtime enforcement/verification methods\
    \ are not suitable for ADSs due to their safety-critical and highly interactive\
    \ nature. The survey paper by Falcone et al. [\\[17\\]](#page-10-27) on existing\
    \ runtime enforcement/verification tools clarifies that many 'reactions' provided\
    \ by general runtime verification tools are weak, which is not acceptable for\
    \ our situation. In this paper, we propose a runtime enforcement method applicable\
    \ to any given specification with acceptable overhead for ADSs, and our method\
    \ concerns not only the current driving conditions but also the ADS's future plans.\n\
    \n# 6 CONCLUSION\n\nWe proposed, REDriver, a solution to the runtime enforcement\
    \ problem for ADSs. REDriver supports the enforcement of complex user-provided\
    \ specifications such as national traffic laws in a way which is similar to experienced\
    \ human drivers, i.e., based on nearfuture predictions and proactively correcting\
    \ the vehicle's trajectory accordingly with minimal adjustment.\n\n# ACKNOWLEDGMENT\n\
    \nWe are grateful to the anonymous ICSE referees for their insights and feedback,\
    \ which have helped to improve this paper. This research is supported by the Ministry\
    \ of Education, Singapore under its Academic Research Fund Tier 3 (Award ID: MOET32020-0004).\
    \ Any opinions, findings and conclusions or recommendations expressed in this\
    \ material are those of the author(s) and do not reflect the views of the Ministry\
    \ of Education, Singapore.\n\n# REFERENCES\n\n- <span id=\"page-10-15\"></span>[1]\
    \ 2023. REDriver Source Codes. [https://redriver2023.github.io/.](https://redriver2023.github.io/)\
    \ Online; accessed Jan 2024.\n- <span id=\"page-10-9\"></span><span id=\"page-10-8\"\
    ></span>[2] Autoware.AI. 2022. Autoware.AI. [www.autoware.ai/.](www.autoware.ai/)\
    \ Online; accessed Jan 2024. [3] Baidu. 2019. APOLLO 6.0. [https://github.com/ApolloAuto/apollo/releases/tag/v6.](https://github.com/ApolloAuto/apollo/releases/tag/v6.0.0)\
    \ [0.0.](https://github.com/ApolloAuto/apollo/releases/tag/v6.0.0) Online; accessed\
    \ Jan 2024.\n- <span id=\"page-10-7\"></span>[4] Baidu. 2022. APOLLO 7.0. [https://github.com/ApolloAuto/apollo/releases/tag/v7.](https://github.com/ApolloAuto/apollo/releases/tag/v7.0.0)\
    \ [0.0.](https://github.com/ApolloAuto/apollo/releases/tag/v7.0.0) Online; accessed\
    \ Jan 2024.\n- <span id=\"page-10-22\"></span>[5] Stanley Bak, Deepti K Chivukula,\
    \ Olugbemiga Adekunle, Mu Sun, Marco Caccamo, and Lui Sha. 2009. The system-level\
    \ simplex architecture for improved real-time embedded system safety. In 2009\
    \ 15th IEEE Real-Time and Embedded Technology and Applications Symposium. IEEE,\
    \ 99–107.\n- <span id=\"page-10-3\"></span>[6] Sai Krishna Bashetty, Heni Ben\
    \ Amor, and Georgios Fainekos. 2020. DeepCrashTest: Turning Dashcam Videos into\
    \ Virtual Crash Tests for Automated Driving\n\nSystems. In 2020 IEEE International\
    \ Conference on Robotics and Automation, ICRA. Paris, France, 11353–11360.\n\n\
    - <span id=\"page-10-23\"></span>[7] Roderick Bloem, Bettina Könighofer, Robert\
    \ Könighofer, and Chao Wang. 2015. Shield Synthesis: - Runtime Enforcement for\
    \ Reactive Systems. In TACAS'15 (Lecture Notes in Computer Science, Vol. 9035).\
    \ Springer, 533–548.\n- <span id=\"page-10-20\"></span>[8] Kun Cheng, Yuan Zhou,\
    \ Bihuan Chen, Rui Wang, Yuebin Bai, and Yang Liu. 2021. Guardauto: A Decentralized\
    \ Runtime Protection System for Autonomous Driving. IEEE Trans. Computers 70,\
    \ 10 (2021), 1569–1581.\n- <span id=\"page-10-10\"></span>[9] Chinese Government.\
    \ 2021. Regulations for the Implementation of the Road Traffic Safety Law of the\
    \ People's Republic of China. [http://www.gov.cn/gongbao/](http://www.gov.cn/gongbao/content/2004/content_62772.htm)\
    \ [content/2004/content\\\\_62772.htm.](http://www.gov.cn/gongbao/content/2004/content_62772.htm)\
    \ Online; accessed Jan 2024.\n- <span id=\"page-10-19\"></span>[10] Ben d'Angelo,\
    \ Sriram Sankaranarayanan, César Sánchez, Will Robinson, Bernd Finkbeiner, Henny\
    \ B Sipma, Sandeep Mehrotra, and Zohar Manna. 2005. LOLA: runtime monitoring of\
    \ synchronous systems. In 12th International Symposium on Temporal Representation\
    \ and Reasoning (TIME'05). IEEE, 166–174.\n- <span id=\"page-10-24\"></span>[11]\
    \ Ankush Desai, Tommaso Dreossi, and Sanjit A Seshia. 2017. Combining model checking\
    \ and runtime verification for safe robotics. In Runtime Verification: 17th International\
    \ Conference, RV 2017, Seattle, WA, USA, September 13-16, 2017, Proceedings. Springer,\
    \ 172–189.\n- <span id=\"page-10-25\"></span>[12] Ankush Desai, Shromona Ghosh,\
    \ Sanjit A Seshia, Natarajan Shankar, and Ashish Tiwari. 2019. SOTER: a runtime\
    \ assurance framework for programming safe robotics systems. In 2019 49th Annual\
    \ IEEE/IFIP International Conference on Dependable Systems and Networks (DSN).\
    \ IEEE, 138–150.\n- <span id=\"page-10-12\"></span>[13] Jyotirmoy V Deshmukh,\
    \ Alexandre Donzé, Shromona Ghosh, Xiaoqing Jin, Garvit Juniwal, and Sanjit A\
    \ Seshia. 2017. Robust online monitoring of signal temporal logic. Formal Methods\
    \ in System Design 51, 1 (2017), 5–30.\n- <span id=\"page-10-0\"></span>[14] Vinayak\
    \ V Dixit, Sai Chand, and Divya J Nair. 2016. Autonomous vehicles: disengagements,\
    \ accidents and reaction times. PLoS one 11, 12 (2016), e0168054.\n- <span id=\"\
    page-10-5\"></span>[15] Alexey Dosovitskiy, German Ros, Felipe Codevilla, Antonio\
    \ Lopez, and Vladlen Koltun. 2017. CARLA: An open urban driving simulator. In\
    \ Conference on Robot Learning. 1–16.\n- <span id=\"page-10-26\"></span>[16] Yliès\
    \ Falcone, Jean-Claude Fernandez, and Laurent Mounier. 2012. What can you verify\
    \ and enforce at runtime? Int. J. Softw. Tools Technol. Transf. 14, 3 (2012),\
    \ 349–382.\n- <span id=\"page-10-27\"></span>[17] Yliès Falcone, Srdan Krstic,\
    \ Giles Reger, and Dmitriy Traytel. 2021. A taxonomy for classifying runtime verification\
    \ tools. Int. J. Softw. Tools Technol. Transf. 23, 2 (2021), 255–284.\n- <span\
    \ id=\"page-10-1\"></span>[18] Francesca M Favarò, Nazanin Nader, Sky O Eurich,\
    \ Michelle Tripp, and Naresh Varadaraju. 2017. Examining accident reports involving\
    \ autonomous vehicles in California. PLoS one 12, 9 (2017), e0184952.\n- <span\
    \ id=\"page-10-28\"></span>[19] Cameron Finucane, Gangyuan Jing, and Hadas Kress-Gazit.\
    \ 2010. LTLMoP: Experimenting with language, temporal logic and robot control.\
    \ In 2010 IEEE/RSJ International Conference on Intelligent Robots and Systems.\
    \ IEEE, 1988–1993.\n- <span id=\"page-10-14\"></span>[20] Yann Gilpin, Vince Kurtz,\
    \ and Hai Lin. 2020. A smooth robustness measure of signal temporal logic for\
    \ symbolic control. IEEE Control Systems Letters 5, 1 (2020), 241–246.\n- <span\
    \ id=\"page-10-6\"></span>[21] Jörg Grieser, Meng Zhang, Tim Warnecke, and Andreas\
    \ Rausch. 2020. Assuring the Safety of End-to-End Learning-Based Autonomous Driving\
    \ through Runtime Monitoring. In DSD. IEEE, 476–483.\n- <span id=\"page-10-13\"\
    ></span>[22] Andreas Griewank et al. 1989. On automatic differentiation. Mathematical\
    \ Programming: recent developments and applications 6, 6 (1989), 83–107.\n- <span\
    \ id=\"page-10-2\"></span>[23] Rong Gu, Raluca Marinescu, Cristina Seceleanu,\
    \ and Kristina Lundqvist. 2019. Towards a Two-Layer Framework for Verifying Autonomous\
    \ Vehicles. In NFM (Lecture Notes in Computer Science, Vol. 11460). Springer,\
    \ 186–203.\n- <span id=\"page-10-17\"></span>[24] Donal Heffernan, Ciaran MacNamee,\
    \ and Padraig Fogarty. 2014. Runtime verification monitoring for automotive embedded\
    \ systems using the ISO 26262 functional safety standard as a guide for the definition\
    \ of the monitored properties. IET Softw. 8, 5 (2014), 193–203.\n- <span id=\"\
    page-10-21\"></span>[25] David Ke Hong, John Kloosterman, Yuqi Jin, Yulong Cao,\
    \ Qi Alfred Chen, Scott Mahlke, and Z Morley Mao. 2020. AVGuardian: Detecting\
    \ and mitigating publishsubscribe overprivilege for autonomous vehicle systems.\
    \ In 2020 IEEE European Symposium on Security and Privacy (EuroS&P). IEEE, 445–459.\n\
    - <span id=\"page-10-16\"></span>[26] Aaron Kane, Omar Chowdhury, Anupam Datta,\
    \ and Philip Koopman. 2015. A Case Study on Runtime Monitoring of an Autonomous\
    \ Research Vehicle (ARV) System. In RV'15 (Lecture Notes in Computer Science,\
    \ Vol. 9333). Springer, 102–117.\n- <span id=\"page-10-4\"></span>[27] Guanpeng\
    \ Li, Yiran Li, Saurabh Jha, Timothy Tsai, Michael Sullivan, Siva Kumar Sastry\
    \ Hari, Zbigniew Kalbarczyk, and Ravishankar Iyer. 2020. AV-FUZZER: Finding safety\
    \ violations in autonomous driving systems. In 2020 IEEE 31st International Symposium\
    \ on Software Reliability Engineering (ISSRE). IEEE, 25–36.\n- <span id=\"page-10-29\"\
    ></span>[28] Jay Ligatti, Lujo Bauer, and David Walker. 2009. Run-Time Enforcement\
    \ of Nonsafety Policies. ACM Trans. Inf. Syst. Secur. 12, 3 (2009), 19:1–19:41.\n\
    - <span id=\"page-10-11\"></span>[29] Oded Maler and Dejan Nickovic. 2004. Monitoring\
    \ temporal properties of continuous signals. In Formal Techniques, Modelling and\
    \ Analysis of Timed and Fault-Tolerant Systems. 152–166.\n- <span id=\"page-10-18\"\
    ></span>[30] Malte Mauritz, Falk Howar, and Andreas Rausch. 2016. Assuring the\
    \ Safety of Advanced Driver Assistance Systems Through a Combination of Simulation\
    \ and Runtime Monitoring. In ISoLA (2) (Lecture Notes in Computer Science, Vol.\
    \ 9953). 672–687.\n\n<span id=\"page-11-0\"></span>\n\n- <span id=\"page-11-4\"\
    ></span>[31] Roger L McCarthy. 2022. Autonomous vehicle accident data analysis:\
    \ California OL 316 reports: 2015–2020. ASCE-ASME Journal of Risk and Uncertainty\
    \ in Engineering Systems, Part B: Mechanical Engineering 8, 3 (2022), 034502.\n\
    - <span id=\"page-11-13\"></span>[32] Stefan Mitsch and André Platzer. 2016. ModelPlex:\
    \ Verified runtime validation of verified cyber-physical system models. Formal\
    \ Methods in System Design 49 (2016), 33–74.\n- <span id=\"page-11-15\"></span>[33]\
    \ NASA. 2023. Copilot. [https://nari.arc.nasa.gov/sws-tc3-diagram/capability/](https://nari.arc.nasa.gov/sws-tc3-diagram/capability/copilot/)\
    \ [copilot/.](https://nari.arc.nasa.gov/sws-tc3-diagram/capability/copilot/) Online;\
    \ accessed Jan 2024.\n- <span id=\"page-11-5\"></span>[34] Dejan Ničković and\
    \ Tomoya Yamaguchi. 2020. RTAMT: Online robustness monitors from STL. In International\
    \ Symposium on Automated Technology for Verification and Analysis. 564–571.\n\
    - <span id=\"page-11-7\"></span>[35] Yash Vardhan Pant, Houssam Abbas, and Rahul\
    \ Mangharam. 2017. Smooth operator: Control using the smooth robustness of temporal\
    \ logic. In 2017 IEEE Conference on Control Technology and Applications (CCTA).\
    \ IEEE, 1235–1240.\n- <span id=\"page-11-14\"></span>[36] Dung Phan, Junxing Yang,\
    \ Matthew Clark, Radu Grosu, John Schierman, Scott Smolka, and Scott Stoller.\
    \ 2017. A component-based simplex architecture for high-assurance cyber-physical\
    \ systems. In 2017 17th International Conference on Application of Concurrency\
    \ to System Design (ACSD). IEEE, 49–58.\n- <span id=\"page-11-10\"></span>[37]\
    \ Srinivas Pinisetty, Partha S. Roop, Steven Smyth, Nathan Allen, Stavros Tripakis,\
    \ and Reinhard von Hanxleden. 2017. Runtime Enforcement of Cyber-Physical Systems.\
    \ ACM Trans. Embed. Comput. Syst. 16, 5s (2017), 178:1–178:25.\n- <span id=\"\
    page-11-3\"></span>[38] Guodong Rong, Byung Hyun Shin, Hadi Tabatabaee, Qiang\
    \ Lu, Steve Lemke, Marti ¯ n,š Možeiko, Eric Boise, Geehoon Uhm, Mark Gerow, Shalin\
    \ Mehta, et al. 2020. LGSVL simulator: A high fidelity simulator for autonomous\
    \ driving. In 2020 IEEE 23rd International Conference on Intelligent Transportation\
    \ Systems (ITSC). 1–6.\n- <span id=\"page-11-16\"></span>[39] John D Schierman,\
    \ Michael D DeVore, Nathan D Richards, Neha Gandhi, Jared K Cooper, Kenneth R\
    \ Horneman, Scott Stoller, and Scott Smolka. 2015. Runtime assurance framework\
    \ development for highly adaptive flight control systems. Technical Report. Barron\
    \ Associates, Inc. Charlottesville.\n- <span id=\"page-11-19\"></span>[40] Fred\
    \ B. Schneider. 2000. Enforceable security policies. ACM Trans. Inf. Syst. Secur.\
    \ 3, 1 (2000), 30–50.\n- <span id=\"page-11-20\"></span>[41] Johann Schumann,\
    \ Patrick Moosbrugger, and Kristin Y Rozier. 2015. R2U2: monitoring and diagnosis\
    \ of security threats for unmanned aerial systems. In Runtime Verification: 6th\
    \ International Conference, RV 2015, Vienna, Austria, September 22-25, 2015. Proceedings.\
    \ Springer, 233–249.\n- <span id=\"page-11-17\"></span>[42] Lui Sha et al. 2001.\
    \ Using simplicity to control complexity. IEEE Software 18, 4 (2001), 20–28.\n\
    - <span id=\"page-11-9\"></span>[43] Saumya Shankar, Ujwal V. R, Srinivas Pinisetty,\
    \ and Partha S. Roop. 2020. Formal Runtime Monitoring Approaches for Autonomous\
    \ Vehicles. In OVERLAY'20 (CEUR Workshop Proceedings, Vol. 2785). CEUR-WS.org,\
    \ 89–94.\n- <span id=\"page-11-1\"></span>[44] Yang Sun, Christopher M. Poskitt,\
    \ Jun Sun, Yuqi Chen, and Zijiang Yang. 2022. LawBreaker: An Approach for Specifying\
    \ Traffic Laws and Fuzzing Autonomous Vehicles. In ASE. ACM, 62:1–62:12.\n- <span\
    \ id=\"page-11-8\"></span>[45] Kosuke Watanabe, Eunsuk Kang, Chung-Wei Lin, and\
    \ Shinichi Shiraishi. 2018. Runtime monitoring for safety of intelligent vehicles.\
    \ In DAC. ACM, 31:1–31:6.\n- <span id=\"page-11-6\"></span>[46] Ching-Feng Wen\
    \ and Hsien-Chung Wu. 2012. Using the parametric approach to solve the continuous-time\
    \ linear fractional max–min problems. Journal of Global Optimization 54, 1 (2012),\
    \ 129–153.\n- <span id=\"page-11-18\"></span>[47] Tichakorn Wongpiromsarn, Ufuk\
    \ Topcu, Necmiye Ozay, Huan Xu, and Richard M Murray. 2011. TuLiP: a software\
    \ toolbox for receding horizon temporal logic planning. In Proceedings of the\
    \ 14th international conference on Hybrid systems: computation and control. 313–314.\n\
    - <span id=\"page-11-11\"></span>[48] Meng Wu, Jingbo Wang, Jyotirmoy Deshmukh,\
    \ and Chao Wang. 2019. Shield Synthesis for Real: Enforcing Safety in Cyber-Physical\
    \ Systems. In FMCAD. IEEE, 129–137.\n- <span id=\"page-11-12\"></span>[49] Meng\
    \ Wu, Haibo Zeng, Chao Wang, and Huafeng Yu. 2017. Safety Guard: Runtime Enforcement\
    \ for Safety-Critical Cyber-Physical Systems: Invited. In DAC. ACM, 84:1–84:6.\n\
    - <span id=\"page-11-2\"></span>[50] Yuan Zhou, Yang Sun, Yun Tang, Yuqi Chen,\
    \ Jun Sun, Christopher M. Poskitt, Yang Liu, and Zijiang Yang. 2023. Specification-Based\
    \ Autonomous Driving System Testing. IEEE Trans. Software Eng. 49, 6 (2023), 3391–3410."
- title: Exception-aware Lifecycle Model Construction for Framework APIs
  abstract: 'The implementation of complex software systems usually depends on low-level

    frameworks or third-party libraries. During their evolution, the APIs adding

    and removing behaviors may cause unexpected compatibility problems. So,

    precisely analyzing and constructing the framework/ library''s API lifecycle

    model is of great importance. Existing works have proposed the API

    existence-changing model for defect detection, while not considering the

    influence of semantic changes in APIs. In some cases, developers will not

    remove or deprecate APIs but modify their semantics by adding, removing, or

    modifying their exception-thrown code, which may bring potential defects to

    upper-level code. Therefore, besides the API existence model, it is also

    necessary for developers to be concerned with the exception-related code

    evolution in APIs, which requires the construction of exception-aware API

    lifecycle models for framework/library projects. To achieve automatic

    exception-aware API lifecycle model construction, this paper adopts a static

    analysis technique to extract exception summary information in the framework

    API code and adopts a multi-step matching strategy to obtain the changing

    process of exceptions. Then, it generates exception-aware API lifecycle models

    for the given framework/library project. With this approach, the API lifecycle

    extraction tool, JavaExP, is implemented, which is based on Java bytecode

    analysis. Compared to the state-of-the-art tool, JavaExP achieves both a higher

    F1 score (+60%) and efficiency (+7x), whose precision of exception matching and

    changing results is 98%. Compared to the exception-unaware API lifecycle

    modeling on 60 versions, JavaExp can identify 18% times more API changes. Among

    the 75,433 APIs under analysis, 20% of APIs have changed their

    exception-throwing behavior at least once after API introduction, which may

    bring many hidden compatibility issues.'
  url: http://arxiv.org/abs/2401.02660v1
  keywords: '* static analysis; program evolution; Java exception summary; API lifecycle'
  document: "# 异常信息敏感的框架 API 生命周期模型构造\\*\n\n燕季薇 1) ,2) 黄进豪 3) 杨恒钦 2),4) 严俊 1),2) \\\
    *\n\n1) (中国科学院软件研究所 软件工程技术研究开发中心 北京 100190)\n\n> 2) (中国科学院大学 北京 100049)\n\n(北京工业大学\
    \ 北京 100124)\n\n3)\n\n4) (国科大杭州高等研究院 杭州 310024)\n\n摘 要 大型软件系统的实现通常依赖于底层框架或第三方库。这些框架/库代码数量繁多、实现复杂,但它们的演化升级\
    \ 往往独立于其调用者,为上层软件的质量保障带来挑战。例如,框架/库代码升级时 API 的新增和删除行为可能引发上层软 件的兼容性问题。准确分析并提取框架/库代码\
    \ API 生命周期模型可以有效辅助对这类代码演化情况的理解,支撑上层的分 析与测试。现有工作中的 API 生命周期模型主要关注 API 的存在性变动,而未考虑特定代码语义变更对开发者的影响。在\
    \ 某些情况下,开发者没有删除或废弃特定的 API,而是更改其代码语义,例如增加、删除或修改用于外部数据校验的异常抛 出相关代码。如果新版本框架/库中的异常抛出行为发生变更而调用者不知情,可能给上层软件系统带来隐患。因此,除了\
    \ API 的存在性,开发者还应特别关注异常相关代码的变更情况,即为框架/库代码构建异常信息敏感的 API 生命周期模型。\n\n为实现异常信息敏感的 API\
    \ 生命周期模型构造,本文采用面向 Java 字节码的静态分析方法,首先提取框架 API 中的异 常抛出行为,生成异常摘要信息,然后通过多轮流式匹配策略获取异常信息的变更情况,构造异常信息敏感的\
    \ API 生命周期 模型。该方法:1)通过控制依赖语句切片提取异常抛出语句的关键触发条件,采用参数推断策略将局部变量的约束条件转 换为仅与外部输入参数相关的异常前断言,并基于自底向上的摘要传递实现跨过程异常摘要提取;2)通过关键信息精准匹\
    \ 配和自适应模糊匹配策略,分析异常摘要信息的新增、删除和修改情况,最终得到异常敏感的 API 生命周期模型,共包含七 种 API 变更形式。基于该方法,实现了基于\
    \ Java 字节码分析的 API 生命周期提取工具 JavaExP。与最新的 Java 异常分析工 具相比,在异常摘要信息提取方面,JavaExP 在大幅提高分析效率(+7x)的同时实现了更高的\
    \ F1 分数(+60%)。通过人工确 认 Apache common-io 项目在 19 个版本上的演化报告,发现异常级别的演化分析准确率达到 98%。对六个真实框架/库项目\
    \ 在 60 个版本上的 API 生命周期分析表明,与异常不敏感的 API 生命周期相比,采用异常敏感的分析时,API 发生变动的比 例提高了 18%。在\
    \ 75,433 个被分析的 API 中,约有 20% API 的异常抛出行为至少发生过一次改变,这些 API 共涉及超过七 千多处独立的异常变更。在多个项目上的分析结果表明,异常敏感的模型构造能够更加精准地描述\
    \ API 的演化过程。\n\n关键词 静态分析;代码演化;Java 异常摘要;API 生命周期 中图法分类号 TP311 DOI 号 xxx\n\n# **Exception-aware\
    \ Lifecycle Model Construction for Framework APIs**\n\nYAN Ji-Wei1),2) HUANG Jin-Hao3)\
    \ Yang Heng-Qin2),4) YAN Jun1),2)\\*\n\n1)(Technology Center of Software Engineering,\
    \ Institute of Software, Chinese Academy of Sciences Beijing, 100190)\n\n2)(University\
    \ of Chinese Academy of Sciences, Beijing, 100049)\n\n3)(Beijing University of\
    \ Technology, Beijing, 100124)\n\n4)(Hangzhou Institute for Advanced Study, Hangzhou,\
    \ 310024)\n\n#### **Abstract**\n\nThe implementation of complex software systems\
    \ usually depends on low-level frameworks or third-party libraries. However, the\
    \ evolution of these frameworks or libraries is independent of the upper-level\
    \ applications, which brings challenges in upper-level code quality assurance.\
    \ For example, during code evolution, the APIs adding and removing behaviors may\
    \ cause unexpected compatibility problems. Precisely analyzing and constructing\
    \ the framework/ library's API lifecycle model is of great importance, which could\
    \ help in understanding changes in APIs as well as supporting the analysis and\
    \ testing of upper-level code. Nowadays, existing works propose the API existencechanging\
    \ model for defect detection, while not considering the influence of semantic\
    \ changes in APIs. In some cases, developers will not remove or deprecate APIs\
    \ but modify their semantics by adding, removing, or modifying their exception-thrown\
    \ code, which is used to verify the users' inputs. It may bring potential defects\
    \ to upper-level code if the exception-related behaviors in newer versions are\
    \ changed silently. Therefore, besides the API existence model, it is also necessary\
    \ for developers to be concerned with the exception-related code evolution in\
    \ APIs, which requires the construction of exception-aware API lifecycle models\
    \ for framework/library projects.\n\nTo achieve automatic exception-aware API\
    \ lifecycle model construction, this paper adopts static analysis technique to\
    \ extract exception summary information in the framework API code and adopts a\
    \ multi-step matching strategy to obtain the changing process of exceptions. Then,\
    \ it generates exception-aware API lifecycle models for the given framework/library\
    \ project. Our approach: 1) adopts control-dependency slicing analysis to extract\
    \ the conditions of the exception-thrown statements; uses a parameter tracing\
    \ strategy to transform exception-throwing conditions into external-variable-related\
    \ preconditions; and performs inter-procedure precondition construction by a bottom-up\
    \ summary-based analysis. 2) proposes the exact-matching and adaptive-matching\
    \ strategies to analyze the addition, deletion, and modification changes based\
    \ on the summarized exception summaries; generates exception-aware API lifecycle\
    \ model which covers seven API changing types. With this approach, the API lifecycle\
    \ extraction tool, JavaExP, is implemented, which is based on Java bytecode analysis.\
    \ Compared to the state-of-the-art tool, JavaExP achieves both higher F1-score\
    \ (+60%) and efficiency (+7x). By manually confirming the exception changing reports\
    \ on 19 versions of Apache common-io project, we found that the precision of exception\
    \ matching and changing results is 98%. The evaluation of 60 versions of six projects\
    \ shows that, compared to the exception-unaware API lifecycle modeling, JavaExp\
    \ can identify 18% times more API changes. Among the 75,433 APIs under analysis,\
    \ 20% of APIs have changed their exception-throwing behavior at least once after\
    \ API introduction. These APIs involve a total of more than 7k independent exception\
    \ changes, which shows that the exception-aware lifecycle modeling can describe\
    \ the evolution process of APIs more accurately.\n\n**Key words** static analysis;\
    \ program evolution; Java exception summary; API lifecycle\n\n# 1. 引言\n\n具有复杂功能的大型软件系统往往由多个模\
    \ 块组成,其实现依赖于底层编程框架和种类繁多的 第三方库。这些框架/库代码通过持续的版本更新修 改代码缺陷或完善代码功能,其演化过程独立于调 用它们的上层软件系统。在上层应用的开发过程\
    \ 中,软件供应链安全分析中的依赖安全检测工具会 帮助开发者识别项目依赖中的漏洞,并提醒应用开 发者尽快更新版本以保障代码质量安全。例如,当 GitHub\
    \ 检测到项目代码中使用易受攻击的依赖项 或恶意软件时,会向开发者发送 Dependabot 警报 [\\[1\\]](#page-16-0)。如果上层应用开发者在不熟悉框架/库代码\
    \ API 演化过程的情况下变更版本,可能会引入其他问 题,如使用了过时/被移除的 API 或未及时捕获处理 新抛出的异常,进而导致程序错误或引发兼容性问\
    \ 题等。\n\n框架/库代码中 API 的变更导致用户在迁移上 层软件系统时花费较多精力,间接增加了使用特定 框架/库的开发难度[\\[2\\]\\[3\\\
    ]](#page-16-1)[\\[4\\]](#page-16-2)。为保障这些依赖于底 层框架/库函数的软件系统质量,一种解决方案是预 先分析不同框架/库代码版本下的\
    \ API 调用规约,并 检测调用代码的正确性。针对这一问题,现有工作 提出了 API 级别的生命周期模型[\\[18\\]](#page-16-3),并通过分析\
    \ 框架更新时提供的 API 变更文本文件[\\[5\\]](#page-16-4)或通过轻 量级框架代码分析扫描其 API 列表[\\[6\\]\\[7\\\
    ]](#page-16-5)等方法来 构建 API 级别的生命周期模型。虽然这些工作考虑 了 API 的存在性变更,但忽略了 API 中关键代码语 义变更的影响。在某些情况下,开发者没有删除或\
    \ 废弃特定的 API,而是更改其代码语义。对于框架 /库的使用人员,除了 API 的存在性变更外,语义信 息变更也是 API 调用时以及 API 调用合规性检测中\
    \ 需要考虑的一项关键信息。\n\n基于API完整代码的差异分析可以准确反映代 码的变更情况,但完整的代码变更结果数据量庞大 且复杂,对于上层应用的分析和测试,并非所有变\
    \ 更都会对用户的使用产生影响。我们发现,在 API 演化过程中,同一 API 的基本功能往往保持一致, 即代码升级不应影响现有 API 的基本功能实现,这\
    \ 类变化应是对用户透明的,但 API 对外部输入数据 的校验过程和校验结果的反馈方式是可变的,它们 会影响 API 的上层调用。在 Java 代码中,当\
    \ API 接 收到非预期的外部输入时,通常会抛出异常来应对 这一非预期行为,而上层用户应该及时捕获并处理\n\n这些异常行为[\\[41\\]](#page-17-0)。Mostafa\
    \ 等人对 Java 库代码兼 容性错误的统计[\\[55\\]](#page-17-1)表明,由异常导致的兼容性问 题占比超过 1/3(105/296)。葛等人在文献[\\\
    [58\\]](#page-17-2)中指 出,框架/库代码中存在的错误或漏洞可能会被攻击 者利用, 从而损害软件供应链安全,这些错误或漏 洞往往与框架/库代码中存在的异常有关。由此可\
    \ 见,API 异常抛出行为的变化会对用户调用方式产 生重要影响,在软件快速演化背景下,其变更行为 对于软件的健壮性与安全性息息相关。\n\n| 1. public\
    \ int getCount() {                                 |  |  |  |  |\n|------------------------------------------------------------|--|--|--|--|\n\
    | 2. -<br>return (int) getByteCount();                       |  |  |  |  |\n|\
    \ 3. +<br>long result = getByteCount();                      |  |  |  |  |\n|\
    \ 4. +<br>if (result > Integer.MAX_VALUE) {                  |  |  |  |  |\n|\
    \ 5. +<br>throw new ArithmeticException(\"The byte count      |  |  |  |  |\n\
    | \" + result + \" is too large to be converted to an int\"); } |  |  |  |  |\n\
    | 6. +<br>return (int) result;<br>//修改返回空值为抛出异常              |  |  |  |  |\n|\
    \ 7. }                                                       |  |  |  |  |\n|\
    \ (a)新增异常实例                                                  |  |  |  |  |\n\n\
    | 1. public static void moveFile(File srcFile, File destFile) |  |  |\n|-------------------------------------------------------------|--|--|\n\
    | throws IOException {                                        |  |  |\n| 2.<br>if\
    \ (destFile.exists())                                |  |  |\n| 3. -<br>throw\
    \ new IOException(\"Destination '\" + destFile +  |  |  |\n| \"' already exists\"\
    );                                        |  |  |\n| 8. +<br>throw new FileExistsException(\"\
    Destination '\" +     |  |  |\n| destFile + \"' already exists\"); //修改异常类型  \
    \                  |  |  |\n| 4. }                                           \
    \             |  |  |\n| (b)修改抛出异常类型                                         \
    \        |  |  |\n\n| 1. public void forceDelete(File file) throws IOException\
    \ { |  |  |  |\n|------------------------------------------------------------|--|--|--|\n\
    | 2. +<br>boolean filePresent = file.exists();               |  |  |  |\n| 3.\
    \ +<br>if (!file.delete()) { //增加文件删除判断条件                 |  |  |  |\n| 4. +<br>if\
    \ (!filePresent) {                                |  |  |  |\n| 5. -<br>if (!file.exists())\
    \ {                              |  |  |  |\n| throw new FileNotFoundException(\"\
    File does<br>6.           |  |  |  |\n| not exist: \" + file); }             \
    \                       |  |  |  |\n| 7. +<br>}                              \
    \                    |  |  |  |\n| 8. }                                      \
    \                 |  |  |  |\n| (c)修改异常抛出条件                                  \
    \              |  |  |  |\n\n#### 图 **1** 不同版本 **API** 中异常相关代码变更示例\n\n图 1 给出了真实项目中的异常相关变更代码片\
    \ 段示例,其变更形式多种多样,包括新增或删除异 常实例[\\[12\\]\\[13\\]](#page-16-6)、修改异常实例的类型、描述或抛出 条件[\\\
    [14\\]](#page-16-7) [\\[15\\]](#page-16-8) [\\[16\\]](#page-16-9)等。在代码演化过程中,同一异常\
    \ 可能发生多次不同类型的变更[\\[14\\]\\[17\\]](#page-16-7)(参见图 3)。 这些变更可能对 API 的外部使用产生影响,即改变\n\
    \nAPI 使用规约。因此,为了正确理解框架 API 的生 命周期行为,需在考虑 API 增删变化之外,结合 API 中异常的变更情况,为其构造异常信息敏感的生命\
    \ 周期模型。该模型的构建依赖于对异常摘要信息的 准确提取与匹配分析。其中的关键挑战是:1)应提 取哪些关键信息表征API中的异常实例并尽量减少 数据中影响匹配的噪音;2)当一个方法中存在多个\
    \ 同类型的异常实例时,如何准确地在多个版本中匹 配到同一实例并识别变更内容,从而准确构建 API 及其异常集合的生命周期。\n\n针对这些挑战,本文首先设计了一种面向演化\
    \ 分析的异常摘要形式,包括异常类型、描述文本、 前断言三类核心信息。为了减少匹配时的数据噪 音,本文在异常抛出条件分析中,通过控制依赖约 束分析去除了与异常抛出无关的条件约束;通过数\
    \ 据流分析将所有中间局部变量约束转换为外部输 入变量约束;通过跨过程异常传递分析避免函数级 代码重构导致的函数内异常变更。此外,为准确识 别不同版本代码中的异常实例,本文共设计了基于\
    \ 类型、描述、前断言、关键前断言四类信息的过滤 器,对于无法完全匹配的异常实例,采用多轮流式 匹配策略识别变更实例、分析变更过程,最终生成 涵盖七类变更行为的异常敏感\
    \ API 生命周期报告。\n\n基于该方法,本文实现了异常信息敏感的 Java API 分析工具 JavaExP (Java Exception-aware\
    \ API analyzer[\\)\\[46\\]](#page-17-3)。其框架图如图 2 所示,对于任意两个\n\n(或多个)版本的 Java 框架/库的\
    \ jar 包/class 文件, JavaExP 先通过异常摘要提取模块获取每个版本的 异常摘要报告。其次,将这些摘要被输入到生命周 期构造模块,对不同版本中\
    \ API 异常语义摘要执行 自适应匹配和异常变更分析。分析后,可以获取 API 的新增、删除情况和 API 中异常的新增、删除和修 改情况,从而得到目标版本区间上异常信息敏感的\
    \ API 生命周期模型。\n\n![](_page_3_Figure_5.jpeg)\n\n#### 图 **2 JavaExP** 方法框架图\n\n\
    多组对比实验验证了本文方法的有效性。对于 异常摘要提取模块,与最新的 Java 异常分析工具 WI[T \\[26\\]](#page-16-10)相比,JavaExP\
    \ 使用更短的时间 (-87%) 提 取到了大量 WIT 无法分析的异常信息,并显著提高 F1 分数(相对提升 60%)。应用 JavaExP 分析了六 个项目的\
    \ 60 个版本,并为其生成 API 生命周期报 告,演化分析的准确率达到 98%;找到了 API 中大 量的异常变更行为,在 75,433 个 API 中,在异常敏\
    \ 感的 API 生命周期模型中,约 20%的 API 在首次引 入后,异常信息发生过至少一次变动;与异常不敏 感的 API 生命周期相比,异常敏感的 API\
    \ 发生变动 的比例提高了 18%。本文的工具和实验数据均已开 源到 GitHub [\\[46\\]](#page-17-3)。\n\n本文的章节结构设计如下:第\
    \ 1 章概述异常信 息敏感的 API 生命周期模型构造方法;第 2 章介 绍本文所需的基础知识和概念定义;第 3 章介绍面 向 Java 程序的异常摘要提取方法;第\
    \ 4 章介绍基于 异常摘要分析 API 生命周期构造方法;第 5 章给出 实验设计和结果分析,评估所提方法的有效性;第 6 章介绍本文的相关工作;最后一章为总结与展望。\n\
    \n# 2. 基础知识与示例应用\n\n### **2.1. Java**异常\n\n异常是在程序执行过程中出现的问题或错误 的一种表示。在 Java 语言中,异常被定义为派生\
    \ 自 java.lang.Throwable 类的对象,在 Java 类库、用 户方法及运行时故障中都可能会抛出异常。Java 提 供了很多内置的异常类\
    \ [\\[42\\]](#page-17-4),如 IOException、 IllegalArgumentException 等,此外,开发人员还可 以自定义异常类以便更好地适应特定需求。一部分\
    \ 异常会被 Java 虚拟机自动的抛出,在运行时不需要 显式处理,但它们可能会导致程序的异常终止,这 类异常也被称为非受检异常或运行时异常;还有一 类异常需在编译时显式地处理,否则会导致编译错\
    \ 误,它们又叫受检异常或编译时异常[\\[43\\]](#page-17-5)。在方法内 部检测到不符合预期条件或无法处理的情况时,开 发者可以通过 throw\
    \ 语句声明主动抛出异常提供有 关特定问题或错误的信息,并将控制权交给调用者 或上层代码来处理(try-catch 行为)。对于框架/库 API 的调用者,API\
    \ 中抛出的异常类型、抛出条件 等与API调用过程的中数据输入规约和异常捕获方 式息息相关。因此,这类变更应被及时传递给开发 人员。\n\n### **2.2.\
    \ API** 演化和生命周期\n\n 应用程序接口(API)是框架/库代码对外提供服 务的调用接口。随着代码功能的演化升级,旧版本 API 在新版中可能被删除,新版代码中也会增加\
    \ API 以提供更丰富的功能。除了 API 的增加与删除, API 中代码的实现方式、数据校验方式等均可能发 生变化。API 的生命周期指 API 在不同的框架/库版\
    \ 本中的存在范围,如 Li 等人提取了安卓框架代码中 API 的生命周期模型[\\[5\\]](#page-16-4),虽然 API 的变动较为频 繁,但在\
    \ API 持续存在的生命周期中,其中包含的 异常实例可能是持续演化的,这类变化在异常不敏 感的 API 级别生命周期模型中无法体现。\n\n### **2.3.**\
    \ 概念定义\n\n针对 API、异常及生命周期等概念,我们分别 给出如下定义。\n\n定义 **1**(应用程序接口方法): API = (id, version,\
    \ class, method, S\\_Exp) 为一个应用程序接口方法,它 包含 API 的签名、版本号、所在的类名称、方法名 称以及包含的异常集合 S\\\
    _Exp。\n\n定义 **2**(异常摘要):Summay(exp) = (API.id, type, message, condition, precondition),\
    \ exp∈API.S\\_Exp 为一个异常摘要,它包含异常所在的 API、异常的 类型、异常抛出时的描述文本信息、异常抛出语句 的控制依赖条件以及与异常抛出相关的外部参数\
    \ 前断言。\n\n定义 **3**(**API/**异常存在性生命周期)API 的存在性 生命周期为该 API 从引入到删除的版本区间的并 集。对于其中包含的异常实例\
    \ Exp∈S\\_Exp,异常的 存在性生命周期为该异常在该API中从引入到删除 的版本区间的并集。\n\n定义 **4**(异常敏感的 **API**\
    \ 生命周期)API 中所有异 常对象 exp∈API.S\\_Exp 摘要信息 Summay(exp)的 集合为 S\\_Summay(S\\_Exp)\
    \ ,在不同的版本中,当 且仅当两个异常摘要信息集合中任何异常摘要信 息均相同时,可认为异常摘要信息的取值在不同版 本上保持不变。对于异常摘要信息集合的特定取\
    \ 值,如果其出现的最早版本为 Vi,最末版本为 V<sup>j</sup> (i<=j),则其生命周期为[Vi, Vj]。对于异常敏感的 API 生命周期,它给出了摘要信息集合\
    \ S\\_Summay 在目标版本中所有不同取值到其生命周期的映射 关系。导致 API 中异常摘要信息取值变更的操作被 称为异常敏感的 API 操作,包括:API\
    \ 新增、API 删除、API 修改-异常新增、API 修改-异常删除、API 修改-异常类型变更、API 修改-异常描述变更和 API 修改-异常断言变更七类。\n\
    \n### **2.4.** 示例代码\n\n图 3 为 Apache commons-io [\\[14\\]\\[17\\]](#page-16-7)项目中\
    \ API moveFile()的部分代码,给出了其异常 e 在不同版本 中的变更情况,+表示新增代码,-表示删除代码。 该异常为针对 API 第 2 个参数变量\
    \ destFile 的文件 存在性校验。在版本号 1.4 的代码中,类型为 IOException 的异常实例 e 被引入,而在 2.0 版本 中,异常实例\
    \ e 的类型被更改为 FileExistsException 类。随后,在版本 2.7 中,该方法被重构,但实际 异常 e 的抛出条件未发生变化。在版本\
    \ 2.9 中,该 方法被再次重构,异常 e 的抛出位置发生变化,其 描述文本和异常前断言也发生改变。因此,对于图 5 中的异常 e,其演化过程为一次新增,一次异常类\
    \ 型更改,一次异常描述文本和前断言更改,其中经 历了两次方法重构。在这种情况下,上层开发者很 难快速评估不同版本中API包含的异常是否变动以 及变动的过程。为提取目标\
    \ API 的生命周期,首先 需准确获取每一个异常实例的关键信息,判定不同 版本中的多个异常信息是否指向同一个异常实例, 如是同一实例,则记录其变更过程,在此基础上,\
    \ 生成完整的 API 生命周期报告。\n\n```\n1. public static void moveFile(File srcFile, File\
    \ destFile) ...{\n2. if (srcFile == null) {\n3. throw new NullPointerException(\"\
    Source must not \nbe null\");\n4. if (destFile == null) {\n5. throw new NullPointerException(\"\
    Destination \nmust not be null\");\n6. if (!srcFile.exists()) {\n7. throw new\
    \ FileNotFoundException(\"Source '\" + \nsrcFile + \"' does not exist\");\n8.\
    \ if (srcFile.isDirectory()) {\n9. throw new IOException(\"Source '\" + srcFile\
    \ + \"' is \na directory\");\n10. if (destFile.exists()) \n11. - throw new IOException(\"\
    Destination '\" + destFile \n+ \"' already exists\"); //在 1.4 版本引入\n12. + throw\
    \ new FileExistsException(\"Destination '\" + \ndestFile + \"' already exists\"\
    ); //在 2.0 版本变更类型\n13. }\n                (a) 版本变更 V1.4 V2.0\n```\n\n| 1. public\
    \ static void moveFile(File srcFile, File destFile) {   |\n|-----------------------------------------------------------------|\n\
    | 2. +<br>validateMoveParameters(srcFile, destFile);// //throw    |\n| other three\
    \ exceptions //在 2.7 版本移动其他异常的位置                      |\n| 3.<br>if (srcFile.isDirectory())\
    \ {                              |\n| 4.<br>throw new IOException(\"Source '\"\
    \ + srcFile + \"' is        |\n| a directory\");                             \
    \                     |\n| 5.<br>if (destFile.exists())                      \
    \              |\n| 6.<br>throw new FileExistsException(\"Destination '\" +  \
    \         |\n| destFile + \"' already exists\");                             \
    \    |\n| 7. }                                                            |\n\
    | (b)版本变更 V2.0  V2.7                                             |\n| 1. public\
    \ static void moveFile(File srcFile, File destFile) {   |\n| 2. -<br>validateMoveParameters(srcFile,\
    \ destFile);// //throw    |\n| other two exceptions                          \
    \                  |\n| 3. -<br>if (srcFile.isDirectory()) {                 \
    \           |\n| 4. -<br>throw new IOException(\"Source '\" + srcFile + \"'  \
    \       |\n| is a directory\");                                              \
    \ |\n| 5. -<br>if (destFile.exists())                                  |\n| 6.\
    \ -<br>throw new FileExistsException(\"Destination '\" +         |\n| destFile\
    \ + \"' already exists\"); //在 2.9 版本整体重构                  |\n| 7. + moveFile(srcFile,\
    \ destFile,                                |\n| StandardCopyOption.COPY_ ATTRIBUTES);\
    \                           |\n| 8. }                                        \
    \                    |\n| 9.                                                 \
    \             |\n| 10. + public static void moveFile(File srcFile, File destFile,\
    \  |\n| CopyOption copyOptions) throws IOException {                    |\n| 11.\
    \ +<br>validateMoveParameters(srcFile, destFile); //throw     |\n| other three\
    \ exceptions                                          |\n| 12. +<br>requireFile(srcFile,\
    \ \"srcFile\"); //throw other two     |\n| exceptions                        \
    \                              |\n| 13. +<br>requireAbsent(destFile, null);  \
    \                       |\n| 14. + }                                         \
    \                |\n| 15.                                                    \
    \         |\n| 16. + private static File requireFile(File file, String name) {\
    \ |\n| 17. +<br>Objects.requireNonNull(file, name);                    |\n| 18.\
    \ +<br>if (!file.isFile())                                    |\n| 19. +<br>throw\
    \ new                                              |\n| IllegalArgumentException(\"\
    Parameter '\" + name + \"' is not       |\n| a file: \" + file);             \
    \                                 |\n| 20. +<br>return file;                 \
    \                          |\n| 21. +<br>}                                   \
    \                   |\n| 22.                                                 \
    \            |\n| 23. + private static void requireAbsent(File file, String  \
    \     |\n| name) throws FileExistsException {                              |\n\
    \n24. + if (file.exists())\n\n25. + throw new FileExistsException(String.format\
    \ (\"File element in parameter '%s' already exists: '%s'\", name, file));\n\n\
    26. +}\n\n#### (**c**)版本变更 **V2.7 V2.9**\n\n#### 图 **3 Apache Commons-IO** 异常变更示例代码\n\
    \n# 3. Java 程序异常摘要提取方法\n\n本章介绍异常摘要提取模块的主要方法。\n\n## **3.1.** 异常摘要提取模块概览\n\nJavaExP\
    \ 的异常摘要提取模块主要包含基本信 息分析和异常前断言分析两个部分。如图 4 所示, 基本信息分析部分以 jar 包或 class 文件为输入,负 责构建程序的控制流图、函数调用图等数据结构,\
    \ 并提取每个方法中抛出异常的基本信息,获得方法 到异常的映射。异常前断言分析部分首先通过构建 方法的控制依赖图,去除判定结果与异常抛出行为 无关的非控制依赖条件,提高了断言分析结果的精\
    \ 准性。获取依赖条件后,再通过参数约束推断将异 常触发条件关联到外部输入参数,获取单个方法的 前断言。此外,通过函数调用关系和参数传递关系 追踪进一步构造了跨过程的异常抛出前断言。最\
    \ 后,形成异常信息摘要报告。\n\n![](_page_5_Figure_11.jpeg)\n\n### 图 4 Java 程序异常摘要提取模块流程图\n\
    \n# **3.2.** 基本信息分析\n\n基本信息提取部分基于静态分析框架 Soot [\\[44\\]](#page-17-6) 对输入代码进行预处理,为每个程序方法构建控制\
    \ 流图(Control Flow Graph,CFG),并生成全局的 函数调用图(Call Graph,CG)。接着,通过遍历 所有的语句,可以定位到显式抛出异常的\
    \ throw() 语句(称为异常抛出点),分析在每个异常抛出点 抛出的异常类型和描述文本等异常基本信息。对于 异常类型,我们分析异常变量的定义语句,并分析\
    \ 对应实例的类型;对于描述分析,我们从异常抛出\n\n点的描述文本变量反向追踪,通过字符串函数建模 还原完整的文本字符串,考虑到部分变量取值无法 直接获取,这里将异常拼接后的文本信息转换为正\
    \ 则表达式形式。\n\n获取基本信息后,JavaExP 记录方法名称和方 法中显示抛出异常的映射关系,并生成方法-异常映 射表,其中一个方法可以对应多个异常。对于图\
    \ 3(c) 的示例应用,可以得到一条映射边{ requireAbsent () FileExistsException @loc25}。由于方法 moveFile\
    \ 的参数会影响 requireAbsent 的异常抛出,因此对 moveFile 也应生成异常前断言。在后续分析中,该 断言可通过为requireAbsent方法构建异常行为摘要\
    \ 和追踪跨过程参数关系得到。\n\n# **3.3.** 前断言分析\n\n除了基本信息,异常摘要中的另一类重要元素 是前断言信息。前断言分析包括控制依赖条件分\
    \ 析、外部输入参数约束推断和跨过程参数约束推断 三个部分。\n\n### **3.3.1.** 控制依赖条件分析\n\n为了生成异常的前断言,首先需要准确提取异\
    \ 常的控制依赖条件。控制依赖条件一定在异常触发 的前置路径上,即在异常被触发时经过的程序路径 上。该路径可以从异常抛出点通过后向路径遍历得 到,而该路径上的全部条件被称为为异常触发的前\
    \ 置路径条件。\n\n定义 **5**(异常前置路径):PrePath (m,e) = (S0,…,Si, Si+1,..,Se) 为异常触发的一条前置路径,其\
    \ 中 S<sup>0</sup> 为方法 m 的入口语句,S<sup>e</sup> 为异常 e 的抛出语 句,程序语句 Si+1 是语句 Si的一个后继节点。异常\
    \ e 对应的多个异常前置路径形成了异常前置路径集 合 PrePathSet (m, e)。\n\n定义 **6**(异常前置路径条件): CondInPath\
    \ (m, e, prePath) 为异常前置路径上的条件语句的集合, 每个元素 cond ∈ CondInPath均是一个条件语句。\n\n对于图 3(a)中的\
    \ moveFile () 方法,第 2-9 行分 别抛出四个异常,如果他们的异常条件被满足,第 12 行异常 e 不会被抛出,因此,异常 e 依赖于这些\
    \ 控制条件。但如果将 2-9 行中的 throw 语句更改为 非终止语句,如输出、日志、数据处理等语句,则 其所属的条件将与第 12 行的异常无关。所有与异\
    \ 常抛出无关的路径前置条件语句无需被作为最终 异常断言的一部分。\n\n定义 **7**(异常控制依赖条件):ControlCond InPath (m,\
    \ e, prePath) 为异常前置路径上控制依赖 条 件 的 集 合 , 其 中 每 个 元 素 controlCond ∈ ControlCondInPath\
    \ 是一条和异常 e 之间存在控制依 赖关系的条件语句。即对于条件 controlCond 的多 个后继节点,存在至少一个后继节点不存在于异常 e 的任何异常前置路径中。\n\
    \n定义 **8**(异常控制依赖约束):ControlConstraint InPath (m, e, prePath)为异常前置路径上的异常控制 依 赖\
    \ 约 束 集 合 , 每 个 异 常 控 制 依 赖 约 束 (controlCond, isCondTrue) ∈ ControlConstraintInPath包\
    \ 括一个控制依赖条件语句及其条件判定结果。\n\n算法 1(extractConstraint)给出了异常控制依赖 条件的提取算法。第 2 行首先获取方法\
    \ m 的控制流 图 cfg,其中节点代表语句,边代表语句之间的控制 流向关系。第 3 行提取控制依赖图 cdg [\\[32\\]\\[33\\]](#page-16-11),其\
    \ 中节点代表语句,边代表语句之间的控制依赖关 系。通过搜索 cdg,可以得到异常抛出语句 Se对应 的异常控制依赖约束集合 controlConstraintSet。接着,\
    \ 第 5 行通过在 cfg 上后向路径遍历得到异常前置路 径集合 prePathSet。对于 prePathSet 中的每条异常前 置路径 prePath,第\
    \ 7-13 行负责构建仅包含异常控 制依赖条件切片的集合 controlConstraintInPath,并 在第 14 行将其加入输出集合 controlConstraintSet\
    \ 中。在这一过程中,第 8 行遍历 prePath 中的每一 个节点,如果一个节点是条件语句,且存在于 Se的 控制依赖节点集合 controlNodeSet\
    \ 中,将记录该节 点 node(第 9 行)。第 10 行分析 node 在 prePath 上的后继节点 node.succ,判定当前路径上 if 条件的\
    \ 判定结果为 true 或为 false(在字节码中,if 语句会 指明当 if 条件为真时的 goto 语句的位置,因此,可 通过下一语句 succ 是否为\
    \ goto 的目标语句判定条 件是否取值为真)。随后在第 11 行,该节点 node 与条件判定结果 isCondTrue 形成的约束条件 constraint\
    \ 会被加入当前路径的异常控制依赖约束 集合 controlConstraintInPath 中。最后,第 16 行将 返 回 方 法 m 的 异 常 控\
    \ 制 依 赖 约 束 集 合 controlConstraintSet,其中每个元素为一条路径上的 一组控制依赖约束。\n\n| 算法<br>1 | 控制依赖条件分析<br>extractConstraint\
    \                      |\n|---------|----------------------------------------------------|\n\
    | 输入:方法   | m, 异常<br>e(异常抛出语句为<br>Se)                          |\n|         |\
    \ 输出:异常控制依赖约束集合<br>controlConstraintSet              |\n|         | 1 Set <Set<Constraint>>\
    \ controlConstraintSet = new |\n\nHashSet (); //初始化\n\n- 2 Graph cfg = constructCFG\
    \ (m); //构建控制流图 cfg\n- 3 Graph cdg = constructCDG (cfg, m); //构建控制依赖图 cdg\n- 4\
    \ Set <Node> controlNodeSet= getControlNodesOfExp (cdg, Se); //在 cdg 中找到 S<sup>e</sup>\
    \ 的控制依赖节点\n- 5 Set <Path> prePathSet = backTraverseFromExp (cfg, Se); //从 S<sup>e</sup>\
    \ 后向路径遍历得到异常前置路径\n- 6 for (Path prePath : prePathSet){\n- 7 Set <Constraint> controlConstraintInPath=\
    \ new HashSet ();\n- 8 for (node : prePath) {·\n- 9 if (node.isCondition () and\
    \ controlNodeSet.contains (node)) {\n- 10 Boolean isCondTrue =getCondJudgeRes\
    \ (node, node.succ); //获取分支条件的判定结果\n- 11 controlConstraintInPath.add (new Constraint\
    \ (node, isCondTrue)); //新增控制依赖条件\n- 12 }\n- 13 }\n- 14 controlConstraintSet.add\
    \ (controlConstraintInPath) //增加一条路径上的一组控制依赖条件\n- 15 }\n\n16 Return controlConstraintSet\n\
    \n例如,对于图 3(a)中的 moveFile() 方法,第 2- 11 行的 5 个控制条件均存在一个后继节点不在任 何一条异常前置路径中,因此异常控制依赖条件为\
    \ ControlCondInPath ={2,4,6,8,10}。接着,通过分析异 常控制依赖条件在异常前置路径中的后继语句,即 条件为真或为假时的后继语句在异常前置路径中,\
    \ 可以得到每个异常控制依赖条件取值结果,即 controlConstraintInPath = {(srcFile == null, false), (destFile\
    \ == null, false), (srcFile.exists(), true), (srcFile.isDirectory(), false), (destFile.exists(),\
    \ true)}。 这里仅为方便展示,在实际的字节码分析过程中, 可被获取的是中间变量约束,如(\\$z0==0, false)。\n\n# **3.3.2.**\
    \ 外部输入参数约束推断\n\n经过上一节的分析,可以获取异常的控制依赖 约束。但字节码中没有变量名称信息,仅有按序编 号的内部变量,如 r0,z1,而这些变量在不同版本\
    \ 中不存在关联关系,难以被直接用于匹配和比较。 因此,应将约束的主体转换为语义固定的对象,如 API 的参数,提取异常前断言时通过数据流追踪获 取的内部变量约束归约为参数相关约束,从而准确\
    \ 分析异常前断言的变更情况。\n\n算法 2(refineAnalysis)对于异常控制依赖条件 集合中每条路径上的每个 控制依赖约束条件 controlConstraint\
    \ 进行分析,通过参数推断得到仅 与外部输入参数相关的 refinedConstraint。算法第 1 行提取语句中的所有变量并将它们放入集合 dataRelatedVars。第\
    \ 2-4 行中,对于变量集合中非输 入参数相关的内部变量,通过数据流分析获取其最 近的变量赋值语句,其中方法 getDefUse 通过数据 流分析获取方法\
    \ m 的定义-使用链 [\\[45\\]](#page-17-7)。第 5 行根 据数据分析结果更改原约束条件 controlConstraint, 即依次使用内部变量的赋值结果替换该变量,并将\
    \ 更新后的约束条件递归地传入 refineAnalysis 方法 继续分析,直至 refinedConstraint 中不再包含内部 变量时,迭代终止。这里,中间码预先被转换为\
    \ SSA 格式。此外,JavaExP 还通过启发式策略调整优化 了输出形式,增强断言的用户可读性。该算法最后 返回推断后的约束条件 refinedConstraint。\n\
    \n| 算法<br>参数约束推断分析<br>2<br>refineAnalysis          |\n|------------------------------------------------|\n\
    | 输入:方法 m, 异常 e(异常抛出语句为 Se),异常                   |\n| 控制依赖条件 controlConstraint\
    \                       |\n| 输出:推断后的约束条件 refinedConstraint                  |\n\
    | 1 Set <Value> dataRelatedVars= getVarFromStmts |\n| (constraint.getStmt ());\
    \ //提取语句中的变量            |\n|                                                |\n\
    \n- 2 For (Value: value dataRelatedVars){\n- 3 if(isOutsideValue(value)) continue;\n\
    - 4 Stmt assignStmt= getAssignStmtofValue (getDefUse(m), value); //后向数据流分析获取最近\
    \ 的变量赋值语句\n- 5 refinedConstraint = replaceValueInConstraint (constraint.getStmt\
    \ (), value, assignStmt. getRightValue()) //将约束语句中的 value 替换为 value 的赋值内容\n- 6\
    \ refineAnalysis(m, e, refinedConstraint)\n- 7 }\n- 8 Return refinedConstraint\n\
    \n据流追踪,得到该方法内的控制依赖条件为 (\\$z0==0, false)}。表 1 (a) 中给出了通过数据流分析 反向推断外部数据约束 parameter0.exists()的过程。\n\
    \n# 表 **1(a)** 过程内追踪约束条件 **(requireAbsent)**\n\n| 控制依赖      | 数据流追踪后推断的约束条件  \
    \                            |  |  |\n|-----------|--------------------------------------------|--|--|\n\
    |           | \\$z0 is true + \\$z0 is-invoke r0.exists()  |  |  |\n| (\\$z0==0,\
    \ |  r0.exists() is true                      |  |  |\n| false)    | r0.exists()\
    \ is true + r0 denote parameter0 |  |  |\n|           |  parameter0.exists()\
    \ is true              |  |  |\n\n### **3.3.3.** 跨过程参数约束推断\n\n在 API 的演化过程中,异常的抛出位置可能发\
    \ 生移动,如将异常抛出语句移动到另一方法并调用 它[\\[17\\]](#page-16-12)。如采用过程间分析,这类代码重构会被识别 为异常的删除,从而引发\
    \ API 演化分析中的误报。 如图 3 对应的异常实例,在版本 1.4 中,异常抛出 代码仅在 moveFile()本身中出现,但在最新的 2.13 版本中,该异常需要至少联合分析六个函数的才能\
    \ 被准确获取。为了增加异常匹配分析的准确度, JavaExP 在为过程内所有异常实例构造摘要信息的 基础上,通过函数调用关系分析和参数映射关系分 析,生成跨过程的异常摘要信息。\n\
    \n具体的跨过程参数约束推断的过程为:首先构 造应用程序的函数调用图,并对函数调用关系进行 拓扑排序。再按照拓扑序的逆序自底向上的分析每 个方法,其中被调用的方法\
    \ callee 一定会比调用它 的方法 caller 更早被分析。当定位到当前方法 caller 中的一个调用语句 stmt 时,可得到被调用的方法 callee。如果被调用方法\
    \ callee 的参数与异常的抛出 有关,则会根据调用方法 caller 和被调用方法 callee 中参数位置的映射关系,更新从被调用方法 callee\
    \ 中获取的参数相关约束 cons1。此外,还应提取 caller 方法中调用 callee 语句前的程序路径上需要满足的 参数相关约束,包含路径上的控制依赖约束\
    \ cons2, 和路径上被调用函数中的其他异常抛出约束的取 反 cons3。约束 cons1、cons2、cons<sup>3</sup> 均更新到调用方\
    \ 法 caller 的参数约束中后,可得到关于方法 caller 的 异常前断言。对于函数内直接抛出的异常,类似的, 也应使用异常抛出前置路径的函数调用中使得异\
    \ 常不被抛出的条约束 cons<sup>3</sup> 更新其直接约束。按照 拓扑逆序分析,从而可以依次更新每个方法的前断 言信息,由于底层的约束会向上传递更新,每个方\
    \ 法仅需被分析一次。\n\n对于图 3(c)中的 moveFile 方法,其第 1 个参数\n\n对应方法 requireAbsent 中的第 0 个参数,根据这一\
    \ 参数映射关系可以更新 requireAbsent 中的前断言 信息得到 moveFile 的约束。此外,在 moveFile 中 调用 requireAbsent\
    \ 方法时,执行到该方法调用点时 应满足来自前置方法 validateMoveParameters 和 requireFile 中的其他约束,最终得到由 5\
    \ 个约束组 成的完整前置条件。结果见表 1(b)。\n\n| 表<br>跨过程追踪约束条件<br>1 (b)<br>(moveFile) |      \
    \                                                                 |  |  |  | \
    \ |\n|---------------------------------------|-----------------------------------------------------------------------|--|--|--|--|\n\
    | 控制依赖                                  | 数据流追踪后推断的约束条件                      \
    \                                   |  |  |  |  |\n|                         \
    \              | requireAbsent@parameter0.exists() is true<br>+ requireAbsent(r1,null)\
    \ |  |  |  |  |\n|                                       |  r1.exists() is true\
    \                                                 |  |  |  |  |\n| constraint\
    \ in                         | r1.exists() is true + r1 denote parameter1    \
    \                        |  |  |  |  |\n| requireAbsent                      \
    \   |  parameter1.exists() is true                                         |\
    \  |  |  |  |\n| + constraints                         | merge constraints from\
    \ related methods                                |  |  |  |  |\n| in moveFile\
    \                           | parameter0 is not null + parameterl is not     \
    \                       |  |  |  |  |\n|                                     \
    \  | null + parameter0.exists() is true +                                  | \
    \ |  |  |  |\n|                                       | parameter0. isFile() is\
    \ true +                                        |  |  |  |  |\n|             \
    \                          | parameterl.exists() is true                     \
    \                      |  |  |  |  |\n\n# 4. 基于异常提取的 API 生命周期构造\n\n本章介绍 API 生命周期构造模块的主要方法。\n\
    \n# **4.1. API**生命周期构造模块概览\n\nJavaExP 的生命周期构造模块主要包含 API 匹 配与变更分析、生命周期模型构造两个部分。如图\
    \ 5 所示,异常匹配与变更分析部分以异常摘要文件 为输入,先采用完全匹配策略获取 API 异常实例的 匹配关系,再通过自适应匹配策略识别其他异常实 例的映射和局部变更情况,生成异常敏感的\
    \ API 变 更报告;生命周期模型构造部分则以多个版本的 API 变更分析报告为输入,分析同一 API 方法或同 一异常实例在不同版本中的变更过程,最后生成相\
    \ 应的生命周期模型。\n\n![](_page_8_Figure_14.jpeg)\n\n图 5 API 生命周期构造模块流程图\n\n# **4.2.**\
    \ 异常信息敏感的**API**匹配与变更分析\n\n基于提取的异常摘要信息,接下来,我们采用 完全匹配和自适应匹配相结合的异常匹配方式对 不同版本中的异常进行匹配。在异常匹配过程,API\
    \ 签名、异常类型、描述和断言信息是四个关键信息, 这里仅考虑签名相同的 API 中异常的匹配,如果 API 签名变更,则认为发生方法级改变。如表 2 所\
    \ 示,异常类型、描述和断言信息的不同组合共有 8 种。如果两个异常符合规则 R1,三个信息可完全匹 配,则表明该异常未发生改变。如不能完全匹配, 则需根据规则\
    \ R2-R8 进行自适应匹配。在这些规则 中,我们将根据对符合该类别特征代码实例的经验 分析和意图理解,判定不同变更特征下的异常代码 是否可匹配。对于 R2-R4,仅有单一信息变更,这\
    \ 类变化更有可能是同一异常的正常演化导致的,而 非两个高度相似的异常。而如果多个信息变更,其 匹配情况将相对复杂,如果两个异常摘要中有至少 两类信息不一致(R5-R8),通常可认定两个异常指\
    \ 向不同的实例。但考虑到异常类型这一信息指向性 较为稳定,在代码重构中有可能出现类型不变但是 异常描述和断言发生改变的情况,因此规则 R5 下 的匹配结果将视情况而定,具体参见以下异常匹配\
    \ 的详细流程。\n\n|    | API | 异常摘要 |             |    |         |  |\n|----|-----|------|-------------|----|---------|--|\n\
    | 规则 | 签名  | 类型   | 描述          | 断言 | 匹配结果    |  |\n| R1 | √   | √    | √   \
    \        | √  | 匹配-未变更  |  |\n| R2 | √   | X    | √           | √  | 匹配-类型变更 |\
    \  |\n| R3 | √   | √    | X           | √  | 匹配-描述变更 |  |\n| R4 | √   | √    |\
    \ √           | X  | 匹配-断言变更 |  |\n|    |     |      |             |    | 可能匹配-断言\
    \ |  |\n| R5 | √   |      | √<br>X<br>X |    | 和描述变更   |  |\n| R6 | √   | X  \
    \  | √           | x  | 不匹配     |  |\n| R7 | √   | X    | X           | √  | 不匹配\
    \     |  |\n| R8 | √   | X    | X           | X  | 不匹配     |  |\n\n表 **2** 异常实例匹配规则\n\
    \n- 1) 对于所有待分析 API,采用规则 R1 对 API 在相 邻版本中的异常进行完全匹配,如果匹配成功则 将匹配到的一对异常分别从各自版本下的匹配\
    \ 队列中移除。\n- 2) 采用异常类型变更 R2、异常描述变更 R3、和异 常断言变更 R4 规则对应的三个规则进行匹配。 这里将择依次使用各个信息过滤器,比较异常类\n\
    \n型、描述、前断言信息是否一致。过滤器接受一 组异常,根据过滤器类型返回过滤后的一组异 常。如旧版本中的异常 e<sup>1</sup> 经过第一个过滤器之\
    \ 后匹配到多个异常,那么所有被匹配的异常会被 作为候选对象传递给下一个过滤器;如 e<sup>1</sup> 未匹 配到任何异常,则将当前过滤器接受到的全部异\
    \ 常将被作为候选对象传递给下一个过滤器。如果 在过滤过程中,e<sup>1</sup> 在新版本中唯一匹配到异常 e2,则表明 e<sup>1</sup>\
    \ 和 e<sup>2</sup> 指向同一个异常,e<sup>1</sup> 和 e<sup>2</sup> 将 被记录并从各自的匹配队列中移除。\n\n\
    - 3) 经过步骤 2 后未找到唯一匹配的异常,将继续采 用规则 R5 进行匹配。满足这种情况的可匹配异 常往往是由于代码重构造成的,由于前置方法、 代码位置变更导致了异常前断言不完全相同,但\
    \ 这种情况下异常最近最直接的抛出条件通常不 会改变,因此,可提取距离异常抛出点最近的直 接条件对应的前断言(关键前断言)信息用于匹 配。对于异常 e1,如果能够唯一找到异常\
    \ e2,它 们的异常类型和异常关键前断言均相同,即使断 言和描述信息不同,e1和 e<sup>2</sup> 也会被匹配,记录后 从各自的匹配队列中移除。\n\
    - 4) 经过步骤 3 后,待匹配异常集合规模可能减小, 使得之前一对多匹配的异常变更为唯一匹配。因 此,可再次重复过程 2)和 3),直至匹配结果不 变,即达到不动点。\n\
    - 5) 如果多轮匹配结束后异常仍未被匹配,那么旧版 本中的未匹配异常将被标记为异常删除,新版本 中的未匹配异常将被标记为异常新增。\n\n在图 3 代码中,JavaExP\
    \ 根据规则 R2 匹配到 V1.4-V2.0 的变化,根据规则 R1 完全匹配了 V2.0- V2.7,最后根据规则 R5 匹配到 V2.7-V2.9 的变化,\
    \ 从而完整刻画了该 API 中异常的变化情况。\n\n### **4.3.** 异常敏感的**API**生命周期模型构造\n\n经过异常匹配与变更分析后,可得到\
    \ API 在相 邻版本中异常的变更结果。变更类型包含定义 **4** 中 声明的七类操作:API 新增、API 删除、异常新增、 异常删除、异常类型变更、异常描述变更和异常断\
    \ 言变更。为了生成完整的生命周期报告,我们从初 始版本开始,不断使用相邻版本的异常摘要构造更 完整的生命周期报告,直至最新版本。\n\n图 6 给出对图\
    \ 3 示例中异常实例的生命周期报 告。该报告包含异常所在的 API 的信息,如引入和 删除版本;包括异常的基本信息,如异常的引入、 删除版本;以及在不同版本区间上异常摘要信息的\n\
    \n变更情况,如异常类型变更。在这个实例中,异常 所在的 API moveFile(), 在 1.4 版本引入,在最新的 2.13 版本中依然存在。其中目标异常\
    \ e 共发生了三 次变更,分别是:2.0 版本变更了异常类型;2.9 版 本中更改了异常的描述文本;2.9 版本中更改了异 常前断言中涉及到的方法调用。值得注意的是,在\
    \ 2.7 版本中,虽然相关代码被开发者重构,但异常信 息分析表明,其异常抛出行为未发生任何改变,因 此,该版本未出现在变更报告中。\n\n![](_page_10_Figure_2.jpeg)\n\
    \n图 6 图 3 中 **API moveFile()**的生命周期模型\n\n# 5. 工具实现与实验分析\n\n基于本文提出的方法,我们实现了一种基于静\
    \ 态分析的 Java 程序 API 生命周期模型自动分析工 具 JavaExP [\\[46\\]](#page-17-3)。该工具包含约 10k 行 Java\
    \ 代码和 1.4k 行 Python 代码,依赖于底层分析框架 Soot [\\[44\\]](#page-17-6) 完成中间码提取、控制流图、函数调用图和控制依\
    \ 赖图[\\[32\\]](#page-16-11)等数据结构的构建。为了评估本文方法的 有效性和效率,本章在多个基准数据集上对工具 JavaExP 开展了一系列实验,主要研究问题如下:\n\
    \n- **RQ1**:在手工构造和真实 Java 项目上,JavaExP 能否准确高效地提取异常摘要信息?\n- **RQ2**:在真实框架/库项目上,JavaExP\
    \ 能否正 确构造异常信息敏感的API的生命周期模型?\n- **RQ3**:在真实框架/库项目上,异常信息敏感的 API 的生命周期模型有何特征?\n\n\
    ### **5.1.** 实验设置\n\n为回答 RQ1,我们手工构造了一个包含常见异常抛 出方式的基准测试集 ExceptionBench [\\[51\\\
    ]](#page-17-8),涉及到 多种常见的 Java 特性。数据集中的六个类分别为: 基本场景 Basic 类,其中包含无条件抛出、判空条 件抛出、字符串取值条件抛出、字符串操作条件抛\
    \ 出、逻辑与/或条件抛出等;跨函数调用场景 MultipleCall 类,包括多种跨函数调用场景;多路径 场景 MultiplePath 类,包含 if-else\
    \ 分支路径和 for 循 环路径;多个异常场景 MultipleThrow 类,包含同 一函数内多个异常和跨过程调用导致的多个异常; 类字段变量使用场景\
    \ FieldValue 类;和一个融合了 多种场景的综合场景 Motivation 类;共包含 40 个 异常。此外,本实验复用了 Nassif 等人构造的面向\
    \ Apache Commons IO [\\[49\\]](#page-17-9)的异常断言标注集合[\\[34\\]](#page-17-10)。 为保证对比的公平性,本实验仅将目标项目的源文\
    \ 件和对应 Jar 包作为输入,而未将任何项目外的第 三方库、JDK 等代码作为分析目标,排除未显式抛 出的异常和代码实现不在项目中的异常后,该数据 集共包含\
    \ 392 个独立异常。此外,本实验还选取了 六个广泛使用的 Java 项目来评估工具在这些真实 项目上的分析性能。评估标准包括异常摘要数量和 运行时间等。这里对每个项目的分析时间上限均被\
    \ 设置为 2 小时。为回答 RQ2 和 RQ3,我们以 RQ1 中六个真实项目为演化分析目标,根据这些项目在 Maven 仓库[\\[53\\]](#page-17-11)中的代码发布情况,收集了共计\
    \ 60 个历史版本 jar 包。随后,我们在这些版本上对真 实项目中API的演化情况进行分析。对于同一项目, 演化分析时仅考虑同级别变更版本。\n\n在实验有效性评估的对比工具选择方面,由于\
    \ 尚没有对于异常信息敏感的API演化分析的直接对 比工具,我们首先选择 Java 异常信息提取工具,对 异常分析这一重要模块的精度进行评估,再人工检 验\
    \ API 演化分析结果的有效性。经调研,工作 [\\[21\\]\\[22\\]](#page-16-13)可通过自然语言处理方式从 JavaDoc 文档\
    \ 或注释中提取异常信息,但由于文档/注释信息和代 码信息常存在偏差,不能将文档信息中提取的异常 信息作为演化分析的对象。工作[\\[34\\]](#page-17-10)\
    \ [\\[54\\]](#page-17-12)通过机器 翻译方法为异常抛出代码生成文档或通过自然语 言处理技术自动生成测试用例,但其异常信息分析 结果无法直接用于异常演化分析。基于此,本文选\
    \ 择了最新 SOTA 的 Java 异常前断言提取自动化工 具 WIT [\\[26\\]](#page-16-10),评估该工具与 JavaExP 在异常提取方\
    \ 面的能力差异。WIT 工具通过静态分析解析目标 Java 项目源代码,构造控制流图并提取跨过程路径 约束,结合约束求解技术获得异常相关的变量约束 信息,最终提取出\
    \ Java 异常的类型、前断言、描述 等信息,且其工具是公开可获取的。\n\n### **5.2.** 实验结果与分析\n\n### **5.2.1.**\
    \ 异常摘要报告有效性评估 **(RQ1)**\n\n对于异常分析提取,分析工具提取到的异常都 是真实存在的,其错误结果分为两种:未识别到真 实的异常,对应为漏报\
    \ FN;识别到真实异常,提取 了错误的异常摘要信息,而遗漏了正确的异常摘要 信息,可被认为既属于误报,也属于漏报信息。\n\n|  |  |  |  |\
    \  |  | 表 3 工具在 ExceptionBench 数据集上的有效性 |\n|--|--|--|--|--|--|---------------------------------|\n\
    |--|--|--|--|--|--|---------------------------------|\n\n| 工具      | TP | FP |\
    \ FN | Precision | Recall | F1-Score |\n|---------|----|----|----|-----------|--------|----------|\n\
    | JavaExP | 39 | 1  | 0  | 0.98      | 0.98   | 0.98     |\n| WIT     | 30 | 5\
    \  | 10 | 0.86      | 0.75   | 0.80     |\n\n表 3 分别给出本文 JavaExP 工具和异常提取工 具 WIT\
    \ 工具在 ExceptionBench 数据集上的有效性 评估结果,包括 TP、FP、FN 数值,和根据公式 Precision=TP/(TP+FP),\
    \ Recall=TP/(TP+FN), F1- Score=2×Precision×Recall/(Precision+Recall)计算 出的精确度、召回率和\
    \ F1 分数的结果。可以看到, JavaExP成功为其中的39个异常生成了正确的异常 摘要报告,其中 1 个误报是由于异常涉及复杂的数 据值变更,导致前断言分析不准确。在\
    \ WIT 不能处 理的 10(5+5)个异常中,5 个由于包含冗余且错误 的约束或涉及复杂的数据值变更导致异常前断言 提取结果有误,5 个涉及不支持的语法特性导致异\
    \ 常摘要未成功提取。在精确度、召回率和 F1 分数 三个度量指标上,JavaExP 均优于 WIT 工具。\n\n| 工具      | TP  | FP\
    \ | FN  | Precision | Recall | F1-Score |  |\n|---------|-----|----|-----|-----------|--------|----------|--|\n\
    | JavaExP | 300 | 56 | 36  | 0.84      | 0.77   | 0.80     |  |\n| WIT     | 137\
    \ | 17 | 255 | 0.89      | 0.35   | 0.50     |  |\n\n表 4 给出了工具 WIT 和 JavaExP 在公开基准\
    \ 测试集 DScrib[e\\[34\\]](#page-17-10)中异常上的有效性分析结果。在 该数据集上,WIT 正确生成的异常摘要数量为 137。\
    \ WIT 不 能 正 确 生 成 摘 要 的 异 常 数 量 为 255 (238+17),其中有 238 个异常的摘要为空,17 个 异常的摘要信息不准确。与之相比,JavaExP\
    \ 成功 生成了 300 个正确的异常摘要报告。JavaExP 不能 正确生成摘要的异常数量为 92(36+56),其中有 36 个异常的摘要为空,56 个异常的摘要信息不准\
    \ 确。虽然 WIT 的分析精确度略高于 JavaExP,但其\n\n召回率显著下降。与 WIT 相比,JavaExP 同时实现 了较高的精确度和召回率,F1\
    \ 分数与 WIT 比相对 提升了 60%。\n\n通过对 JavaExP 错误结果的分类分析,我们发 现对于 56 个摘要信息不准确的异常,其中的 22\
    \ 个 异常受限于循环条件展开次数,11 个异常存在无法 正确分析的复杂关系,10 个异常缺少部分正确路 径,8 个异常中被调用函数 callee 中的前断言约束\
    \ 无法正确映射到调用函数 caller 的参数,3 个异常 没有正确处理 try 语句中的异常抛出,2 个异常的前 断言条件自相冲突。对于另外 36 个摘要结果为空\
    \ 的异常,导致精度损失的一个原因是复杂跨函数参 数传递增加了分析难度。如图 3 所示,随着版本更 新,框架/库开发者在重构的过程中倾向于将异常抛 出代码进行包装以便复用,这间接增加了分析的复\
    \ 杂性。在 Apache Commons IO 项目 V2.13 版本中, 调用链长度不少于 5 的共有 578 处,调用链长度不 少于 10 的共有 50\
    \ 处,而调用链中任意一处异常摘 要信息误差均可能影响最终的匹配情况。此外, JavaExP 对字节码的静态分析能力也影响了分析结 果,如在处理位运算代码的断言条件时尚存在偏\
    \ 差、对静态变量的取值使用初始赋值,循环条件仅 展开 0 次和 1 次等,这些分析影响了前断言中部分 条件的准确性。\n\n|             |\
    \       |         |       | WIT          | JavaExP |        |       |  |\n|-------------|-------|---------|-------|--------------|---------|--------|-------|--|\n\
    | 项目名         | 版本    | LOC     | 总摘    | 时间           | 独立摘     | 总摘     | 时间\
    \    |  |\n|             |       |         | 要数    | /秒           | 要数      |\
    \ 要数     | /秒    |  |\n| Commons IO  | 2.6   | 9,984   | 297   | 3,903       \
    \ | 268     | 1,285  | 44    |  |\n| JGraphT     | 0.9.2 | 15,660  | 142   | 119\
    \          | 176     | 4,17   | 52    |  |\n| GraphStream | 1.3   | 48,535  |\
    \ 142   | 431          | 342     | 2,087  | 160   |  |\n| Guava       | 19.0 \
    \ | 70,250  | 2,347 | 6,133        | 221     | 3,891  | 112   |  |\n| Nashorn\
    \     | 1.8   | 83,728  | 177   | 1,759        | 949     | 3,446  | 355   |  |\n\
    | Android     | 10.0  | 546,655 | 524*  | 7,200        | 7,906   | 51,915 | 1743\
    \  |  |\n| 合计/平均       |       | 129,135 |       | 3,692 19,545 | 9,862   | 62,624\
    \ | 2,466 |  |\n\n表 **5** 工具在真实项目上的分析结果\n\n进一步,我们在六个真实项目上进行分析性能 的评估。表 5 给出了所选项目的名称、版本和大小,\
    \ 其中大小为不含注释的 Java 源码行数。后五列对比 了两个工具的结果中异常摘要数量和分析时间。其 中,对于大型的 Android 框架代码,WIT 超时导致\
    \ 未完成分析,因此,仅统计其在两小时内生成的结 果,并计算其中包含的异常摘要数量。对于六个被 测项目,WIT 用时约 5.5 小时,提取的总异常摘要\n\n\
    数量为 3,692。与之相比,JavaExP 用时仅 0.7 小时, 提取的独立摘要数量为 9,862,总摘要数量为 62,624,分析效率提高约 7 倍,提取数量显著增加。\
    \ 基于这一结果,我们进一步分析了异常数量的增加 是由于 JavaExP 分析到了更多的独立异常,还是由 于独立异常在跨函数调用过程中在不同调用路径 中重复出现导致的。我们根据异常抛出方法、异常\
    \ 抛出语句位置信息进行去重后的异常数量计为独 立异常的数量,独立摘要的数量少于总摘要数量。 据统计, WIT 的总摘要数量 (3,692)显著少于 JavaExP\
    \ 的独立摘要数量(9,862),由此可知,与 WIT 相比,JavaExP 不仅提取出更多的异常摘要结果, 且成功分析了更多的独立异常。\n\n实验表明,JavaExP\
    \ 提取的异常摘要数量显著 多于 WIT,且用时更短,带来这一优势的主要原因 有以下三个方面。首先,JavaExP 基于字节码分析, 不受限于新的 Java\
    \ 语法特性,分析范围更广,能够 正确处理 Java 的各种复杂语法特性支持,其分析能 力不受到代码形式的影响。其次,JavaExP 对分析 规模的限制更少,该方法并没有对每条路径上的节\
    \ 点数、函数内联后的节点数量等做严格限制[26],而 是在遍历控制流路径时先提取终止于异常抛出的 语句,仅分析异常抛出行为相关的代码切片,分析 范围更为聚焦。此外,JavaExP\
    \ 采用自底向上构建 函数摘要的方式,对每个函数不会被重复分析,带 来了明显的效率优势。除了效率优势,JavaExP 的 分析准确度也较高。JavaExP\
    \ 通过提取异常的类型、 描述文本、前断言三类核心信息对异常进行刻画, 在异常前断言分析时主动忽略了与当前异常抛出 无关的非控制依赖条件,但沿着函数调用链追踪异\
    \ 常抛出必要的关键前置条件,提高了异常分析的准 确性,这也为后续在不同版本中匹配异常的演化信 息打下了良好的基础。\n\n**RQ1** 结论:相比于现有的异常分析工具,JavaExP\
    \ 能够更加准确地提取异常的摘要信息,在现有数 据集上,将分析精度提高了约 60%;通过跨函数 摘要合并策略,将分析效率提高了 7 倍,并显著 增加了成功提取的异常摘要数量。\n\
    \n# **5.2.2. API** 生命周期模型构造正确性 **(RQ2)**\n\n在 RQ2 中,我们选取六个项目中发布历史版本 数量最多(19 个)的\
    \ Apache Commons IO 项目,人 工确认 JavaExP 在该项目上 API 演化分析结果的有 效性。对于 API 和异常增删修改的七种形式,为了\
    \ 保证公平性,本实验选取对象具体的方法为:对于 每个变更类别,首先根据变更实例数量对所在的 Java 类(class)文件进行排序。对于各个变更类型, 根据其变更总数,从所有变更实例中按照均匀分布\
    \ 采样间隔地选择实例。考虑到异常前断言的数量相 对较多,在选择时容易选择到因方法封装在不同上 层方法被重复调用的异常实例,为增加多样性,避 免确认相似的异常,该类别下会对异常调用链进行\
    \ 过滤,仅收集未包含相同异常抛出方法的实例。我 们对每种类别均收集 10 个实例(不足 10 时按实际 数量)。最终,对于 7 种变更类型,共收集了 63\
    \ 个 变更实例,结果见表 6,详细的人工确认报告见[\\[46\\]](#page-17-3)。\n\n对于过程内的分析,大量跨过程调用引入的异 常均无法被分析,占异常总数的\
    \ 94%;对于在当前 方法中抛出的可被分析的异常,异常抛出之前的跨 过程调用也会对前断言产生影响。在表 6 中,过程 内分析评估时仅选择在当前方法中抛出的异常,如\
    \ 果只考虑当前方法内出现的约束条件,分析结果 均正确,但如考虑其他方法调用带来的隐式约束, 有 5 个断言信息变更行为正确,其中 3 个异常摘要 前断言信息提取结果完全正确。\n\
    \n表 **6 API** 演化分析的正确性\n\n|        | 统计 API |    | API | 异常 | 异常 | 异常文 | 异常类 |\
    \ 异常条      |\n|--------|--------|----|-----|----|----|-----|-----|----------|\n\
    |        |        | 新增 | 删除  | 新增 | 删除 | 本修改 | 型修改 | 件修改      |\n| 过程内 数量 |  \
    \      | 10 | 10  | 10 | 10 | 10  | 3   | 10       |\n|        | 正确     | 10 |\
    \ 10  | 10 | 10 | 10  | 3   | 10[5/3]  |\n| 跨过程 数量 |        | 10 | 10  | 10 |\
    \ 10 | 10  | 10  | 10       |\n|        | 正确     | 10 | 10  | 10 | 10 | 9   |\
    \ 10  | 10[10/5] |\n\n与之相比,跨过程的分析则可以分析被调用函 数中抛出的深层异常和前置函数中的隐式约束。受 限于字节码静态分析,在异常条件修改变更结果\
    \ 中,5 个异常摘要前断言信息提取结果完全正确。5 个异常摘要提取结果不完全准确,但它们不影响对 断言变更检测结果的正确性,如循环展开有限次和 位运算约束结果不完全准确,但变更前后能够显著\
    \ 区分。在异常描述变更结果中,有一处错误的异常 匹配。这是因为版本 2.9 中的代码被大幅重构,原 异常的类型、消息、前断言均发生了改变,但函数 中刚好存在另一个与原异常类型和关键前断言均\
    \ 相同的异常,从而导致它们被错误匹配。总体来看, 跨过程策略下,演化分析的整体准确率达到 98%, 跨过程分析能够捕获到其他函数内存在的异常及 其断言条件,变更分析结果整体较为准确。后续\
    \ RQ3 中异常演化分析默认采用跨过程分析策略。\n\n经人工总结,影响 API 中异常匹配的可能因素 包括:1)在跨过程传递分析中,异常断言分析的精 度和过程间参数约束的分析可能传递影响最终的\
    \ 匹配结果;2)开发者可能同时修改同一个异常的多 个信息,导致难以通过单一变化严格限制匹配规 则,需在尽量避免错误匹配的前提下,尽可能识别 出存在差异的同一异常。3)目前仅能匹配文本相等\
    \ 和逻辑相等,如果开发者换用语义相同的不同 API, 如!isFile()和 isDirectory()语义相同,因无法自动判 断前后是否一致,会识别其为异常条件变更。如需\
    \ 判断语义一致性,需在后续研究中引入语义分析。\n\n**RQ2** 结论: JavaExP 能够基于提取的异常摘要, 准确构建 API 的生命周期模型,其中跨过程分析\
    \ 策略更为准确。部分异常的前断言信息存在精度 损失,但对 API 演化分析的影响不大。\n\n### **5.2.3. API** 生命周期变更结果分析\
    \ **(RQ3)**\n\n对于 RQ2 中的六个项目,我们在 Maven 仓库 中收集了各项目的共计 60 个历史发布版本,并在 表 7 中统计了各个项目的\
    \ API 变更情况。所有版本 的分析时间共计 30 分钟。对于 API 本身的变更, 新增 API 数量较多,随着版本演化,API 的数量整 体趋向于一直增加,但也有部分\
    \ API 会被删除。当 发生大版本重构时,API 变化较为明显。除了 API 的新增删除,JavaExP 还识别出了大量的异常变更 行为。在所有的 75,433\
    \ 个 API 中,约 14.3%的 API 新增过异常抛出行为,13.9% 删除过原有的异常, 6.5%更改过抛出条件,1.9%更改过异常描述文本, 0.1%变更过异常类型。在异常敏感的\
    \ API 生命周期 模型中,约 20%的 API 在被引入后,异常信息在后 续版本中发生过调整,这说明 API 中异常相关代码 的调整是十分常见的,异常敏感的\
    \ API 生命周期构 造能够更加精准的描述 API 的实际变更情况。\n\n| 项目名         | #分析 | #总     | #新增    |\
    \ #删除    | #异常摘要        |\n|-------------|-----|--------|--------|--------|--------------|\n\
    |             | 版本  | API    | API    | API    | 改变 API       |\n| Commons IO\
    \  | 19  | 1,880  | 1,665  | 36     | 548 (29%)    |\n| JGraphT     | 7   | 2,493\
    \  | 1,859  | 740    | 665 (27%)    |\n| GraphStream | 5   | 3,345  | 1,607  |\
    \ 1,460  | 194 (6%)     |\n| Guava       | 14  | 3,772  | 1,868  | 666    | 848\
    \ (22%)    |\n| Nashorn     | 5   | 4,340  | 8      | 11     | 739 (17%)    |\n\
    | Android     | 10  | 59,603 | 32,331 | 8,260  | 11,512 (19%) |\n| Total     \
    \  | /   | 75,433 | 39,338 | 11,173 | 14,506 (20%) |\n\n表 **7 API** 变更情况统计分析\n\
    \n进一步的,我们在图 7 和表 8 中展示了六个项 目中异常实例的变更情况。图 7(a)中统计了每个 API 中的发生变更的全部异常实例,当一个异常被 封装并多次调用时会多次统计。可以看到,当考虑\
    \ 重复异常时,新增异常的数量占比最高,其次删除 异常的数量。实际上部分新增异常是被重复调用 的。图 7(b)以独立异常为关注对象,异常多次调 用时仅统计一次,表\
    \ 8 给出了对应图 7(b)中独立 异常变更的数量统计,与图 7(a)相比,新增删除 异常的数量占比有所下降。在异常语义行为的不同 变更中,异常类型变更整体数量最少,主要包括子\
    \ 类到父类的变更,父类到子类变更,原生异常类到 自定义异常类的变更,代码重构复用功能相似代码 导致的类型变更等。描述信息变更其次,其原因包 括修正文字错误、增加描述信息、代码重构导致使\
    \ 用封装代码的描述文字等。而异常前断言更改的数 量相对较多,包括增删路径上的前置异常导致条件 变化,代码重构导致的条件变更等。\n\n![](_page_13_Figure_8.jpeg)\n\
    \n(**a**)异常实例变更类型统计\n\n![](_page_13_Figure_10.jpeg)\n\n# (**b**)独立异常实例变更类型统计 图\
    \ **7** 异常变更情况统计\n\n| 项目名         | #异常    | #异常<br>新增 | #异常<br>删除 | #异常<br>类型<br>修改\
    \ | #异常<br>描述<br>修改 | #异常<br>条件<br>修改 |\n|-------------|--------|-----------|-----------|-----------------|-----------------|-----------------|\n\
    | Commons IO  | 746    | 148       | 160       | 6               | 135       \
    \      | 200             |\n| JGraphT     | 979    | 87        | 51        | 1\
    \               | 55              | 130             |\n| GraphStream | 485   \
    \ | 58        | 55        | 1               | 31              | 39           \
    \   |\n| Guava       | 453    | 46        | 56        | 2               | 28 \
    \             | 140             |\n| Nashorn     | 1,332  | 72        | 32   \
    \     | 11              | 6               | 269             |\n| Android     |\
    \ 11,471 | 1,669     | 901       | 21              | 310             | 3,039 \
    \          |\n\n#### 表 **8** 不同项目中独立异常变更统计\n\n**RQ3** 结论:在代码演化过程中,不仅 API 的新 增、删除行为较为常见,异常的新增、删除和更\
    \ 改行为也十分频繁。在 75,433 个被分析的 API 中,约有 20% API 的异常抛出行为至少发生过 一次改变,这些 API 共涉及超过七千多处独立\
    \ 的异常变更。相比于 API 的存在性生命周期模 型,采用异常敏感的分析时,API 发生变动的比 例提高了 18%,该模型能够更加精准地描述 API 的实际变更情况,对框架/库代码的开发者和使\
    \ 用者都具有指导意义。\n\n# **5.2.4.** 对实验有效性的威胁\n\n在本文中,对实验有效性的威胁主要与数据集 的构建与选取有关。1)在手工基准测试集的构建阶\
    \ 段,设计思路的不同会在一定程度上影响在该数据 集上的评估结果,这一偏差难以避免。为了保障测 试集的公平性,本文在构建手工基准测试集时预先 对抛出异常的基本场景进行分类,再按照类别设计\
    \ 数据集代码。对于这些场景,该数据集仅考虑具有 指定特性的精简代码片段,用于测试异常分析工具 在具有不同特性代码上的基础分析能力。我们注意 到 WIT 不支持一些常见的语法特性,为保障公平\
    \ 性,我们仅根据数据集设计需要设计不同特性的代 码片段,而未在设计后主动添加移除特定工具(如 WIT)不支持的语法特性。2)在真实项目数据集的 选取上,真实项目的异常抛出代码风格、函数封装\
    \ 复杂度、相邻版本代码变更差异等均会影响评估结 果,为增强被测项目的代表性,本文复用已有的异 常断言标注集合[34]用于异常分析能力评估,并选 取了六个广泛使用且具有多个版本的\
    \ Java 开源项 目用于 API 变更分析评估,通过工具在不同被测项 目上的整体结果评估工具的综合分析能力。\n\n# 6. 相关工作\n\n## **6.1.**\
    \ 异常摘要提取\n\n异常(Exception)机制是 Java 中正式的错误报 告机制,为了能够及时有效地处理程序中的运行错 误,开发者需合理地抛出、捕获并处理异常。程序\
    \ 崩溃时,打印的异常堆栈信息是错误调试的一类重 要信息[\\[57\\]](#page-17-13)。由于异常机制的复杂性,研究人员围绕 着异常的使用[\\\
    [38\\]](#page-17-14)、异常抛出代码的编程指导 [\\[39\\]\\[40\\]](#page-17-15)、异常抛出行为的正确性测试[\\\
    [37\\]\\[56\\]](#page-17-16)、以及 基 于 程 序 异 常 抛 出 信 息 的 错 误 定 位 与 修 复\n\n[\\[47\\\
    ]\\[46\\]](#page-17-17)[\\[48\\]](#page-17-18)等方向开展了一系列工作。其中,为了 帮助开发人员了解代码中何时何处会抛出异常,理\
    \ 解程序的规范行为,异常的摘要信息,特别是其前 断言生成工作也受到了广泛的关注,主要类别包括 基于自然语言处理的方法和基于代码静态分析的 方法。\n\n\
    # **6.1.1** 基于自然语言处理的断言提取\n\n在开发过程中,断言信息可以帮助开发人员明 确方法的使用规范,避免API演化导致的代码缺陷; 在代码缺陷检测和定位时,前断言分析结果可以辅\
    \ 助测试人员构造高质量的测试用例,对满足/不满足 断言的行为进行系统地测试。\n\n基于自然语言处理(NLP)的断言生成方法被 广泛地应用,这类方法通过统计分析文档、注释等\
    \ 文 本 文 件 推 断 方 法 的 断 言 或 测 试 预 言 信 息 [\\[5\\]\\[20\\]](#page-16-4)[\\[21\\]\\\
    [22\\]](#page-16-13) [\\[23\\]\\[24\\]](#page-16-14)。Tan 等人在@Tcommen[t \\[1\\\
    ]](#page-16-0) 中通过定义自然语言模式和使用启发式方法来推 断程序的异常前断言,该方法仅关注空指针类型。 与之相比,Goff 等人提出的 ToraDoc[u\
    \ \\[21\\]](#page-16-13) 通过解 析 Javadoc 文档,自动为所有的异常行为构造测试 预言,工作 JDoctor [\\[22\\\
    ]](#page-16-15) 在此基础上扩展,实现了 面向更多程序行为的断言提取。此外,Zhai 等人提 出了从文档中自动生成 JML 规范的方法 C2[S\\\
    [20\\]](#page-16-16)。 由于大部分真实应用并不存在完整的 JML 规范,该 方法仅基于 JDK 的规范文档进行训练,其模型不一 定适用于其它的\
    \ Java 项目。基于自然语言处理的方 法可以有效基于文本分析实现断言提取,但无论是 方法文档或是代码注释,开发者对它们的编写情况 都是不确定的。代码中的文档、注释信息既可能缺\
    \ 失,也可能在代码演化过程中未被及时更新,因此, 这类方法适用于文档编写较为规范且被长期维护 的大型项目。但在大量真实项目中,存在着文档缺 失、不完整或未被及时维护的现象[\\\
    [25\\]\\[35\\]](#page-16-17)[\\[36\\]](#page-17-19),无 法准确体现 API 代码实现本身的演化情况。\n\
    \n# **6.1.2** 基于代码分析的断言提取\n\n另一类方法基于静态代码分析来提取断言信 息[\\[52\\]](#page-17-20)。Buse\
    \ 和 Weimer 基于 Java 异常分析工具 Jex [\\[30\\]](#page-16-18) 提出了一种自动推断 Java 方法异常抛出条件\
    \ 的方法 [\\[29\\]](#page-16-19)。该工作首先提取方法和异常的映射 表,然后采用符号执行和跨过程数据流分析技术提 取每个异常的抛出条件。由于该工作后向遍历了所\
    \ 有的控制流路径(control flow path),在单个方法 代码复杂、异常抛出前存在分支条件较多的情况下 会出现路径爆炸问题;收集到路径约束后,该方法\n\
    \n设计了一些约束处理规则以简化断言形式,但其生 成的结果均是围绕所有程序变量的,而不是只关注 异常和方法输入参数的关系。与之相似,Chandra 等 人也采用后向符号执行技术,提出了一种推断最弱\
    \ 前断言的技术 SnuggleBu[g \\[31\\]](#page-16-20),它将问题泛化为如 何找到从某入口点到达目标状态的前置条件,因此 该方法不限于异常分析。为了解决\
    \ Java 多态虚函数 调用关系分析带来的路径爆炸问题,该工作采用符 号执行和函数调用图交错的按需分析方法以提高 效率。但它们[\\[29\\]](#page-16-19)\
    \ [\\[31\\]](#page-16-20)均未提供可公开获取的工具。\n\n近期,Marcilio 等人[\\[26\\]](#page-16-10)\
    \ 提出了基于 Java 源码 分析的轻量级异常前断言分析方法 WIT。该方法可 以有效提取部分 Java 方法断言,但由于面向源代 码,其分析而受限于复杂的语法特性,如不能处理\
    \ 包含 for-each 循环语句, switch 语句, 和 try/catch 块的代码;此外,基于源码的分析依赖于变量名称 的匹配,在变量重新赋值时难以准确解析条件变量\
    \ 和输入参数的关系。WIT 项目的源码未公开,但工 具可公开获取。\n\n在基于代码分析的断言提取方法中,于源码的 分析可以有效提取部分方法的断言,但其受限于复\
    \ 杂且不断更新的 Java 语法特性、难以准确追踪内部 变量和外部参数之间的复杂关系[\\[26\\]](#page-16-10)。此外,对于上 层应用依赖的底层框架和第三方库,其源代码未必\
    \ 是可获取的。与之相比,基于字节码的分析不会受 限于高级语言的语法特性,并支持开展精确的控制 流和数据流追踪。为增加方法的普适性,适应不同 版本的 Java\
    \ 代码,并支撑框架/库源码不可获取的 分析场景,JavaExP 向 Java 字节码的静态分析技术, 通过追踪分析字节码中的异常抛出条件和变量取 值,实现异常相关的\
    \ API 语义变更分析。\n\n### **6.2. API**生命周期模型构建\n\nAPI 生命周期模型常被用于上层应用的 API 误 用检测或兼容性错误检测。Li\
    \ 等人在工作 CiD [\\[5\\]](#page-16-4) 中提出了安卓生命周期模型 (ALM),CiD 从安卓 开发框架中提取了完整的 API 方法列表,并给出不\
    \ 同 API 存在的版本范围。Huang 等人提出了 CIDE[R\\[8\\],](#page-16-21)该工作关注 API 回调函数变化导致的兼 容性问题,该工作依赖于手工构建的回调函数调用\
    \ 协议一致性图。工作 ACI[D\\[7\\]](#page-16-22)同时关注 API 调用问 题和 API 回调函数兼容性问题,该工作没有分析框 架代码,而是根据安卓框架官方提供的\
    \ API 差异列 表轻量级地获取其生命周期。本文也关注与框架 API 生命周期的提取,与这些工作相比,我们不仅 关注 API 的存在性问题,即在不同版本中\
    \ API 的新 增和删除情况,还重点分析了API中异常抛出情况, 特别是同一个 API 中异常抛出条件、描述、类型等 是否发生变化。\n\n除了 API\
    \ 方法的演化,工作[\\[11\\]](#page-16-23)还关注了框架 代码中字段(Field)信息的演化,并关注了字段变 化引发的上层代码缺陷。更多的工作[\\\
    [6\\]\\[9\\]](#page-16-5)[\\[10\\]](#page-16-24)关注 与在给定 API 生命周期模型的基础上,如何精确分 析上层应用代码,以找到\
    \ API 的误用问题,我们的 模型提取工作可以为这类研究提供支撑。\n\n# 7. 总结与展望\n\n针对框架/库项目和上层应用开发者在代码升 级演化过程中难以准确获取其开发或使用的API变\
    \ 更行为这一问题,本文基于静态分析方法,提出了 面向底层框架和第三方库的异常信息敏感的API生 命周期模型生成方法,形成原型工具 JavaExP。与 已有工作相比,JavaExP\
    \ 生成的异常摘要信息在准 确率和分析效率方面均有大幅提高。与异常不敏感 的 API 演化分析相比,异常敏感的 API 发生变动的 比例提高了 18%,在六个真实框架/库项目的\
    \ 60 个 版本中发现了超过七千多处独立的异常变更。\n\n这一工具可同时服务于框架/库的开发人员和 使用人员。一方面,对于框架/库的开发者,应在发 布新版本软件前,通过\
    \ API 生命周期分析工具精确 获取新版本代码中 API 中异常信息变更情况,确保 小版本升级时不产生 API 语义变更,大版本升级时 及时将语义变更情况更新在文档中。另一方面,对\
    \ 于应用开发者,在对所使用的框架/库代码进行版本 升级时,可通过分析工具查看当前版本到新版本中 API 的方法变更和异常变更情况,开展未捕获的异 常分析和异常传播分析等应用层检测,保障应用层\
    \ API 调用的正确性和鲁棒性,服务于软件供应链安 全分析。此外,对于基于大模型的自动代码生成, 框架/库 API 误用是生成代码中的一种典型错误模 式,API\
    \ 生命周期信息对于生成代码的版本一致性 检测和修复也有重要意义。\n\n考虑到真实的大规模框架/库中异常信息变动 非常频繁,在后续的研究工作中,我们将进一步探\
    \ 索如何从大量的异常信息变更中自动识别出可能 影响代码可靠性的语义变化、如何自动构造可触发 API 中的异常抛出行为的测试用例等研究问题,从 而精准定位上层软件系统中的\
    \ API 误用行为。\n\n# 致 谢 诚挚感谢评阅老师对论文提出的改进意见!\n\n### 参考文献:\n\n<span id=\"page-16-0\"\
    ></span>[1] Dependabot. https://docs.github.com/en/code-security/dependabot/ dependabot-alerts\n\
    \n<span id=\"page-16-1\"></span>[2] Hora, André, Romain Robbes, Marco Tulio Valente,\
    \ Nicolas Anquetil, Anne Etien, and Stéphane Ducasse. How do developers react\
    \ to API evolution? A large-scale empirical study. Software Quality Journal 26\
    \ (2018): 161-191.\n\n[3] Wu, Wei, Foutse Khomh, Bram Adams, Yann-Gaël Guéhéneuc,\
    \ and Giuliano Antoniol. An exploratory study of api changes and usages based\
    \ on apache and eclipse ecosystems. Empirical Software Engineering 21 (2016):\
    \ 2366-2412.\n\n<span id=\"page-16-2\"></span>[4] Bavota, Gabriele, Mario Linares-Vasquez,\
    \ Carlos Eduardo Bernal-Cardenas, Massimiliano Di Penta, Rocco Oliveto, and Denys\
    \ Poshyvanyk. The impact of api change-and fault-proneness on the user ratings\
    \ of android apps. IEEE Transactions on Software Engineering 41, no. 4 (2014):\
    \ 384-407.\n\n<span id=\"page-16-4\"></span>[5] Li Li, Tegawendé F Bissyandé,\
    \ Haoyu Wang, and Jacques Klein. 2018. Cid: Automating the detection of api-related\
    \ compatibility issues in android apps. https://github.com/lilicoding/CiD. In\
    \ Proceedings ofthe 27th ACM SIGSOFT Inter- national Symposium on Software Testing\
    \ and Analysis. 153–163.\n\n<span id=\"page-16-5\"></span>[6] Dongjie He, Lian\
    \ Li, Lei Wang, Hengjie Zheng, Guangwei Li, and Jingling Xue. 2018. Understanding\
    \ and detecting evolution-induced compatibility issues in android apps. In 2018\
    \ 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE).\
    \ IEEE, 167–177.\n\n<span id=\"page-16-22\"></span>[7] Tarek Mahmud, Meiru Che,\
    \ and Guowei Yang. 2021. Android compatibility issue detection using api differences.\
    \ In 2021 IEEE International Conference on Software Analysis, Evolution and Reengineering\
    \ (SANER). IEEE, 480–490.\n\n<span id=\"page-16-21\"></span>[8] Huaxun Huang,\
    \ Lili Wei, Yepang Liu, and Shing-Chi Cheung. 2018. Under- standing and detecting\
    \ callback compatibility issues for android applications. In Proceedings ofthe\
    \ 33rdACM/IEEE International Conference on Automated Software Engineering. 532ś542.\n\
    \n[9] Patrick Mutchler, Yeganeh Safaei, Adam Doupé, and John Mitchell. 2016. Target\
    \ fragmentation in Android apps. In 2016 IEEE Security and Privacy Workshops (SPW).\
    \ IEEE, 204–213.\n\n<span id=\"page-16-24\"></span>[10] Yang Sen, Sen Chen, Lingling\
    \ Fan, Sihan Xu, Zhanwei Hui, and Song Huang. Compatibility Issue Detection for\
    \ Android Apps Based on Path-Sensitive Semantic Analysis. In 2023 IEEE/ACM 45th\
    \ International Conference on Software Engineering (ICSE), pp. 257-269. IEEE,\
    \ 2023.\n\n<span id=\"page-16-23\"></span>[11] Mahmud Tarek, Meiru Che, and Guowei\
    \ Yang. Android api field evolution and its induced compatibility issues. Proceedings\
    \ of the 16th ACM/IEEE International Symposium on Empirical Software Engineering\
    \ and Measurement. 2022.\n\n<span id=\"page-16-6\"></span>[12] 新增异常实例。[https://github.com/apache/commons-](https://github.com/apache/commons-io/commit/e03d721bb4dfd2e4ba7719f76ce17e860890dd2e)\n\
    \n[io/commit/e03d721bb4dfd2e4ba7719f76ce17e860890dd2e](https://github.com/apache/commons-io/commit/e03d721bb4dfd2e4ba7719f76ce17e860890dd2e)\n\
    \n[13] 删除异常实例。[https://github.com/aosp-](https://github.com/aosp-mirror/platform_frameworks_base/commit/8b73d86492c3bcd2fbca6545b89c159ace637b72)\n\
    \n[mirror/platform\\\\_frameworks\\\\_base/commit/8b73d86492c3bcd2fbca6545b89](https://github.com/aosp-mirror/platform_frameworks_base/commit/8b73d86492c3bcd2fbca6545b89c159ace637b72)\
    \ [c159ace637b72](https://github.com/aosp-mirror/platform_frameworks_base/commit/8b73d86492c3bcd2fbca6545b89c159ace637b72)\n\
    \n<span id=\"page-16-7\"></span>[14] 修改异常类型。[https://github.com/apache/commons](https://github.com/apache/commons-io/commit/af9bf289fbd7f6294ca399c54f4277e8631e903a)[io/commit/af9bf289fbd7f6294ca399c54f4277e8631e903a](https://github.com/apache/commons-io/commit/af9bf289fbd7f6294ca399c54f4277e8631e903a)\n\
    \n<span id=\"page-16-8\"></span>[15] 修改异常抛出条件。[https://github.com/apache/commons-](https://github.com/apache/commons-io/commit/50f9c9370c1286039fb6750e08e0fcbc20c6adc0)\n\
    \n[io/commit/50f9c9370c1286039fb6750e08e0fcbc20c6adc0](https://github.com/apache/commons-io/commit/50f9c9370c1286039fb6750e08e0fcbc20c6adc0)\n\
    \n<span id=\"page-16-9\"></span>[16] 修改异常描述文本。[https://github.com/apache/commons-](https://github.com/apache/commons-io/commit/8814b6d7efa235fc1410c9699eb136da780d70a2)\n\
    \n[io/commit/8814b6d7efa235fc1410c9699eb136da780d70a2](https://github.com/apache/commons-io/commit/8814b6d7efa235fc1410c9699eb136da780d70a2)\n\
    \n<span id=\"page-16-12\"></span>[17] 移动异常位置。[https://github.com/apache/commons-](https://github.com/apache/commons-io/commit/2d37ab6a0d53fce60095b352d36dddd9d26f5ab0)\n\
    \n[io/commit/2d37ab6a0d53fce60095b352d36dddd9d26f5ab0](https://github.com/apache/commons-io/commit/2d37ab6a0d53fce60095b352d36dddd9d26f5ab0)\n\
    \n<span id=\"page-16-3\"></span>[18] Yu, Dung-Feng, Cheng-Ying Chang, Hewijin\
    \ Christine Jiau, and Kuo-Feng Ssu. Which API Lifecycle Model is the Best for\
    \ API Removal Management?. ICSEA 2017: 230.\n\n[19] Shin Hwei Tan, Darko Marinov,\
    \ Lin Tan, and Gary T. Leavens. @tComment: Testing Javadoc Comments to Detect\
    \ Comment-Code Inconsistencies. ICST 2012: 260–269, 2012.\n\n<span id=\"page-16-16\"\
    ></span>[20] Juan Zhai, Yu Shi, Minxue Pan, Guian Zhou, Yongxiang Liu, Chunrong\
    \ Fang, Shiqing Ma, Lin Tan, and Xiangyu Zhang. 2020. C2S: translating natural\
    \ language comments to formal program specifications. ESEC/FSE 2020: 25-37, 2020.\n\
    \n<span id=\"page-16-13\"></span>[21] Alberto Goffi, Alessandra Gorla, Michael\
    \ D. Ernst, and Mauro Pezzè. 2016. Automatic generation of oracles for exceptional\
    \ behaviors. ISSTA 2016: 213–224, 2016.\n\n<span id=\"page-16-15\"></span>[22]\
    \ Arianna Blasi, Alberto Goffi, Konstantin Kuznetsov, Alessandra Gorla, Michael\
    \ D. Ernst, Mauro Pezzè, and Sergio Delgado Castellanos. Translating code comments\
    \ to procedure specifications. ISSTA 2018:242- 253, 2018.\n\n<span id=\"page-16-14\"\
    ></span>[23] Elizabeth Dinella, Gabriel Ryan, Todd Mytkowicz, and Shuvendu K.\
    \ Lahiri. 2022. TOGA: a neural method for test oracle generation. In Proceedings\
    \ of the 44th International Conference on Software Engineering (ICSE '22): 2130–2141,\
    \ 2022.\n\n[24] Rahul Pandita, Xusheng Xiao, Hao Zhong, Tao Xie, Stephen Oney,\
    \ and Amit Paradkar. Inferring method specifications from natural language api\
    \ descriptions. ICSE 2012: 815–825, 2012.\n\n<span id=\"page-16-17\"></span>[25]\
    \ Zhong, Hao, Na Meng, Zexuan Li, and Li Jia. An empirical study on API parameter\
    \ rules. ICSE 2020:899-911, 2020.\n\n<span id=\"page-16-10\"></span>[26] Diego\
    \ Marcilio and Carlo A. Furia, What Is Thrown? Lightweight Precise Automatic Extraction\
    \ of Exception Preconditions in Java Methods. ICSME 2022:340-35, 2022.\n\n[27]\
    \ Raymond P. L. Buse and Westley Weimer. Automatic documentation inference for\
    \ exceptions. ISSTA 2008: 273–282. 2008.\n\n[28] Yu Zhou, Changzhi Wang, Xin Yan,\
    \ Taolue Chen, Sebastiano Panichella, and Harald Gall. Automatic detection and\
    \ repair recommendation of directive defects in java api documentation. IEEE Transactions\
    \ on Software Engineering, 46(9):1004–1023, 2020.\n\n<span id=\"page-16-19\"></span>[29]\
    \ Raymond P. L. Buse and Westley Weimer. Automatic documentation inference for\
    \ exceptions. ISSTA 2008: 273–282. 2008.\n\n<span id=\"page-16-18\"></span>[30]\
    \ Martin P. Robillard and Gail C. Murphy. Static analysis to support the evolution\
    \ of exception structure in object-oriented systems. ACM Trans. Softw. Eng. Methodol.\
    \ 12(2):191–221, 2003.\n\n<span id=\"page-16-20\"></span>[31] Satish Chandra,\
    \ Stephen J. Fink, and Manu Sridharan. Snugglebug: a powerful approach to weakest\
    \ preconditions. PLDI 2009: 363–374. 2009.\n\n<span id=\"page-16-11\"></span>[32]\
    \ Jeanne Ferrante, Karl J. Ottenstein, and Joe D. Warren. The program dependence\
    \ graph and its use in optimization. ACM Trans. Program. Lang. Syst. 9, 3, 319–349,\
    \ 1987.\n\n[33] Cytron, Ron, Jeanne Ferrante, Barry K. Rosen, Mark N. Wegman,\
    \ and F. Kenneth Zadeck. Efficiently computing static single assignment form and\
    \ the control dependence graph. ACM Transactions on Programming Languages and\
    \ Systems (TOPLAS) 13, no. 4 (1991): 451-490.\n\n<span id=\"page-17-10\"></span>[34]\
    \ Nassif, Mathieu, Alexa Hernandez, Ashvitha Sridharan, and Martin P. Robillard.\
    \ Generating unit tests for documentation. IEEE Transactions on Software Engineering\
    \ 48, no. 9 (2021): 3268-3279.\n\n<span id=\"page-17-19\"></span>[35] Emad Aghajani,\
    \ Csaba Nagy, Olga Lucero Vega-Márquez, Mario Linares-Vásquez, Laura Moreno, Gabriele\
    \ Bavota, and Michele Lanza. Software documentation issues unveiled. In Proceedings\
    \ of the 41st International Conference on Software Engineering, ICSE, 1199–1210,\
    \ 2019. [36] Emad Aghajani, Csaba Nagy, Mario Linares-Vásquez, Laura Moreno, Gabriele\
    \ Bavota, Michele Lanza, and David C. Shepherd. Software documentation: the practitioners'\
    \ perspective. In Proceedings of the ACM/IEEE 42nd International Conference on\
    \ Software Engineering (ICSE '20): 590–601, 2020.\n\n<span id=\"page-17-16\"></span>[37]\
    \ Francisco Dalton, Márcio Ribeiro, Gustavo Pinto, Leo Fernandes, Rohit Gheyi,\
    \ and Baldoino Fonseca. 2020. Is Exceptional Behavior Testing an Exception? An\
    \ Empirical Assessment Using Java Automated Tests. In Proceedings of the 24th\
    \ International Conference on Evaluation and Assessment in Software Engineering\
    \ (EASE '20). 170–179, 2020.\n\n<span id=\"page-17-14\"></span>[38] Haidar Osman,\
    \ Andrei Chiş, Jakob Schaerer, Mohammad Ghafari, and Oscar Nierstrasz. On the\
    \ evolution of exception usage in Java projects, 2017 IEEE 24th International\
    \ Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 422-426,\
    \ 2017.\n\n<span id=\"page-17-15\"></span>[39] Xiangyang Jia, Songqiang Chen,\
    \ Xingqi Zhou, Xintong Li, Run Yu, Xu Chen, Jifeng Xuan. Where to Handle an Exception?\
    \ Recommending Exception Handling Locations from a Global Perspective, 2021 IEEE/ACM\
    \ 29th International Conference on Program Comprehension (ICPC), pp. 369- 380,\
    \ 2021.\n\n[40] Hao Zhong. 2023. Which Exception Shall We Throw? In Proceedings\
    \ of the 37th IEEE/ACM International Conference on Automated Software Engineering\
    \ (ASE '22). Article 116, 1–12, 2022.\n\n<span id=\"page-17-0\"></span>[41] Exception\
    \ handling. Wikipedia. 2023.\n\n[https://en.wikipedia.org/wiki/Exception\\\\_handling](https://en.wikipedia.org/wiki/Exception_handling)\n\
    \n<span id=\"page-17-4\"></span>[42] Java Exception, Oracle.\n\n<https://docs.oracle.com/javase/8/docs/api/java/lang/Exception.html>\n\
    \n<span id=\"page-17-5\"></span>[43] Eckel, Bruce, and 侯捷. Java 编程思想. Vol. 2.\
    \ No. 02. 机械工业 出版社, 2002.\n\n<span id=\"page-17-6\"></span>[44] Soot. 2023[. https://github.com/soot-oss/soot](https://github.com/soot-oss/soot)\n\
    \n<span id=\"page-17-7\"></span>[45] Use-define chain. 2023[. https://en.wikipedia.org/wiki/Use](https://en.wikipedia.org/wiki/Use-define_chain)[define\\\
    \\_chain.](https://en.wikipedia.org/wiki/Use-define_chain)\n\n<span id=\"page-17-3\"\
    ></span>[46] JavaExP, 2023[. https://github.com/hanada31/JavaExP](https://github.com/hanada31/JavaExP)\n\
    \n<span id=\"page-17-17\"></span>[47] Jiwei Yan, Miaomiao Wang, Yepang Liu, Jun\
    \ Yan, Long Zhang. Locating Framework-specific Crashing Faults with Compact and\
    \ Explainable Candidate Set. The 45th IEEE/ACM International Conference on Software\
    \ Engineering, ICSE, 2023.\n\n<span id=\"page-17-18\"></span>[48] Rongxin Wu,\
    \ Hongyu Zhang, Shing-Chi Cheung, and Sunghun Kim. CrashLocator: locating crashing\
    \ faults based on crash stacks. In Proceedings of the 2014 International Symposium\
    \ on Software Testing and Analysis, ISSTA 2014. 204–214,2014.\n\n<span id=\"page-17-9\"\
    ></span>[49] Apache Commons IO, 2023. <https://github.com/apache/commons-io>\n\
    \n[50] Leonardo Mendonça de Moura and Nikolaj Bjørner. Z3: an efficient SMT solver.\
    \ In C. R. Ramakrishnan and Jakob Rehof, editors, Tools and Algorithms for the\
    \ Construction and Analysis of Systems, 14th International Conference, TACAS 2008\
    \ , pages 337–340. 2008.\n\n<span id=\"page-17-8\"></span>[51] ExceptionBench,\n\
    \n[https://github.com/hanada31/JavaExP/tree/master/Evaluation/RQ1/Exceptio](https://github.com/hanada31/JavaExP/tree/master/Evaluation/RQ1/ExceptionBench%20Code)\
    \ [nBench%20Code](https://github.com/hanada31/JavaExP/tree/master/Evaluation/RQ1/ExceptionBench%20Code)\n\
    \n<span id=\"page-17-20\"></span>[52] Rak-Amnouykit, Ingkarat, et al. The raise\
    \ of machine learning hyperparameter constraints in Python code. Proceedings of\
    \ the 31st ACM SIGSOFT International Symposium on Software Testing and Analysis.\
    \ 2022. [53] Maven 仓库。<https://mvnrepository.com/>\n\n<span id=\"page-17-12\"\
    ></span><span id=\"page-17-11\"></span>[54] Blasi, Arianna, Alessandra Gorla,\
    \ Michael D. Ernst, and Mauro Pezzè. \"Call Me Maybe: Using NLP to Automatically\
    \ Generate Unit Test Cases Respecting Temporal Constraints.\" In Proceedings of\
    \ the 37th IEEE/ACM International Conference on Automated Software Engineering,\
    \ pp. 1-11. 2022.\n\n<span id=\"page-17-1\"></span>[55] Shaikh Mostafa, Rodney\
    \ Rodriguez, and Xiaoyin Wang. 2017. Experience paper: a study on behavioral backward\
    \ incompatibilities of Java software libraries. In Proceedings of the 26th ACM\
    \ SIGSOFT International Symposium on Software Testing and Analysis (ISSTA 2017).\
    \ Association for Computing Machinery, New York, NY, USA, 215–225.\n\n### 附中文参考文献:\n\
    \n[56] 姜淑娟,闫大顺. 一种快速测试Java异常处理机制的方法[J]. 小型 微型计算机系统,2005,26(10):1854-1857.\n\n\
    <span id=\"page-17-13\"></span>[57] 顾咏丰, 马萍, 贾向阳, 等. 软件崩溃研究进展. 中国科学: 信息 科学, 2019,\
    \ 49: 1383–1398.\n\n<span id=\"page-17-2\"></span>[58] 葛丽丽, 帅东昕, 谢金言, 张迎周, 薛渝川,\
    \ 杨嘉毅, 密杰, 卢跃. 面向软件供应链的异常分析方法综述. 软 件学报, 2023, 34(6): 2606– 2627."
- title: 'SliceLocator: Locating Vulnerable Statements with Graph-based Detectors'
  abstract: 'Vulnerability detection is a crucial component in the software development

    lifecycle. Existing vulnerability detectors, especially those based on deep

    learning (DL) models, have achieved high effectiveness. Despite their

    capability of detecting vulnerable code snippets from given code fragments, the

    detectors are typically unable to further locate the fine-grained information

    pertaining to the vulnerability, such as the precise vulnerability triggering

    locations. Although explanation methods can filter important statements based

    on the predictions of code fragments, their effectiveness is limited by the

    fact that the model primarily learns the difference between vulnerable and

    non-vulnerable samples. In this paper, we propose SliceLocator, which, unlike

    previous approaches, leverages the detector''s understanding of the differences

    between vulnerable and non-vulnerable samples, essentially,

    vulnerability-fixing statements. SliceLocator identifies the most relevant

    taint flow by selecting the highest-weighted flow path from all potential

    vulnerability-triggering statements in the program, in conjunction with the

    detector. We demonstrate that SliceLocator consistently performs well on four

    state-of-the-art GNN-based vulnerability detectors, achieving an accuracy of

    around 87% in flagging vulnerability-triggering statements across six common

    C/C++ vulnerabilities. It outperforms five widely used GNN-based explanation

    methods and two statement-level detectors.'
  url: http://arxiv.org/abs/2401.02737v4
  keywords: ''
  document: '# <span id="page-0-0"></span>SliceLocator: Locating Vulnerable Statements
    with Graph-based Detectors


    Baijun Cheng 1 , Kailong Wang2\*, Cuiyun Gao 3 , Xiapu Luo 4 , Li Li 5 , Yao Guo1\*,
    Xiangqun Chen 1 , Haoyu Wang2\*


    1\*School of Computer Science, Peking University, Beijing, China.


    2\*School of Cyber Science and Engineering, Huazhong University of Science and
    Technology, Wuhan, Hubei, China.


    <sup>3</sup>School of Computer Science and Technology, Harbin Institute of Technolgy,
    Shenzhen, Guangdong, China.


    <sup>4</sup>Department of Computing, The Hong Kong Polytechnic University, Hong
    Kong, China.


    <sup>5</sup>School of Software, Beihang University, Beijing, China.


    \*Corresponding author(s). E-mail(s): wangkl@hust.edu.cn ; yaoguo@pku.edu.cn ;
    haoyuwang@hust.edu.cn ; Contributing authors: prophecheng@stu.pku.edu.cn ;


    #### Abstract


    Vulnerability detection is a crucial component in the software development lifecycle.
    Existing vulnerability detectors, especially those based on deep learning (DL)
    models, have achieved high effectiveness. Despite their capability of detecting
    vulnerable code snippets from given code fragments, the detectors are typically
    unable to further locate the fine-grained information pertaining to the vulnerability,
    such as the precise vulnerability triggering locations. Although explanation methods
    can filter important statements based on the predictions of code fragments, their
    effectiveness is limited by the fact that the model primarily learns the difference
    between vulnerable and non-vulnerable samples. In this paper, we propose SliceLocator,
    which, unlike previous approaches, leverages the detector''s understanding of
    the differences between vulnerable and non-vulnerable samples—essentially, vulnerability-fixing
    statements. SliceLocator identifies the most relevant taint flow by selecting
    the highest-weighted flow path from all potential vulnerability-triggering statements
    in the program, in conjunction with the detector. We demonstrate that SliceLocator
    consistently performs well on four state-of-the-art GNN-based vulnerability detectors,
    achieving an accuracy


    of around 87% in flagging vulnerability-triggering statements across six common
    C/C++ vulnerabilities. It outperforms five widely used GNN-based explanation methods
    and two statement-level detectors.


    Keywords: vulnerability detection, deep learning, graph representation, vulnerability
    localization


    # 1 introduction


    The proliferation of modern software programs developed for diverse purposes and
    usage scenarios is inevitably and persistently coupled with intensified security
    threats from vulnerabilities, evidenced by the substantial surge in the volume
    of reported vulnerabilities via the Common Vulnerabilities and Exposures (CVE)
    [\[1\]](#page-19-0). To counteract the potential exploitation, both academia and
    industrial communities have proposed numerous techniques for identifying and locating
    those vulnerabilities.


    Traditional approaches, such as the rule-based analysis techniques (e.g., SVF
    [\[2\]](#page-19-1), Checkmarx [\[3\]](#page-19-2), Infer [\[4\]](#page-20-0),
    and clang static analyzer [\[5\]](#page-20-1)), leverage predefined signatures
    or rules to identify vulnerabilities. Unfortunately, similar to other static analysis
    techniques, they typically suffer from high false positive and negative rates
    [\[6\]](#page-20-2). More recently, DL-based detection techniques [\[6–](#page-20-2)[9\]](#page-20-3),
    which generally operate on extracted code feature representations, have shown
    great effectiveness in flagging vulnerabilitycontaining code fragments (i.e.,
    functions or slices). However, the coarse granularity and the black-box nature
    of the analysis renders poor interpretability in the detection results. For example,
    a function or a code snippet could contain over a dozen code lines, which remains
    challenging for the developers to understandthe root cause of the vulnerabilities
    and further take action to fix them. A recent work [\[10\]](#page-20-4) suggests
    that the bug trigger path is the key to locating and fixing a vulnerability.


    One promising way to tackle this problem is leveraging explanation approaches
    to select important features for the DL-based detectors, and then mapping them
    to the corresponding code lines. Recent rapid advances in graph-based explainability
    technology show great potential for this solution. In particular, the existing
    explanation methods commonly facilitate model interpretability from three angles:
    assigning numeric values to graph edges [\[11,](#page-20-5) [12\]](#page-20-6),
    computing importance scores for nodes [\[13\]](#page-20-7), and calculating scores
    for graph walks while traversing through GNNs [\[14\]](#page-20-8). Despite their
    success in tasks such as molecular graph classifications, current GNN-based explanation
    methodologies exhibit inherent limitations that impede their direct applicability
    in extracting fine-grained vulnerability-related information, particularly in
    identifying relevant statements.


    Limitations. The first limitation of GNN explanation methods lies in their reliance
    on selecting the most influential parts of the graph for model inference. However,
    they may not always accurately identify these critical components [\[15\]](#page-20-9).
    A thorough analysis of the GNN inference process and the explanation methods is
    required to further validate this point, which, however, falls beyond the scope
    of our work. More importantly, according to previous studies [\[16\]](#page-21-0),
    GNN-based detectors


    are likely to focus primarily on learning the differences between vulnerable and
    nonvulnerable samples for inference, rather than relying on domain-specific knowledge
    such as taint flow. Moreover, the differences between vulnerable and non-vulnerable
    samples may not be limited to the location of code fixes, but could also involve
    other structural changes in the graph, such as alterations in topology due to
    added conditional statements (e.g., if clauses). Explanation methods tend to amplify
    these differences.


    Insights. Graph-based detectors, while potentially learning irrelevant features,
    show high sensitivity to vulnerability fixes. For example, in Devign, masking
    vulnerable fixing statements (VFS) reduces the vulnerability probability by 0.32
    on average, while masking other locations causes a loss of no more than 0.15.
    Since VFS and vulnerable triggering statements (VTS) are strongly data-dependent,
    and data flow graphs are sparse [\[2\]](#page-19-1), this suggests that vulnerabilities
    are likely triggered at the VTS. The detector often assigns the flow linking VFS
    and VTS high weight, and due to the sparsity of data flows, the highest-weighted
    flow traced back from VTS is likely the vulnerable flow.


    Solution. In this work, we propose SliceLocator, a novel approach to identify
    fine-grained information from vulnerable code reported by GNN-based vulnerability
    detectors. Given a detected vulnerable code fragment, the key idea behind SliceLocator
    is to leverage GNN-based detectors to identify the highest-weighted taint flow
    from the VFS to the VTS. The core step of SliceLocator involves performing backward
    program slicing based on potential sink points (PSPs). First, a set of flow paths
    is extracted, and then, using GNN-based detectors, the weight of each path is
    predicted. The path with the highest weight is selected as the most relevant flow
    for vulnerability localization. Compared with prior works (e.g., DeepWukong [\[6\]](#page-20-2)),
    SliceLocator only preserves vulnerability-triggering and vulnerability-dependent
    program path-level information, rather than that of the full program. This significantly
    improves the analysis efficiency as program paths contain a smaller number of
    code lines. Leveraging the program slicing method, SliceLocator captures more
    semantic information encompassed in code lines. As a result, it can provide more
    accurate localization results than the approaches only focusing on topological
    features.


    Evaluation. We follow previous study [\[16\]](#page-21-0) to use vulnerability-triggering
    code line coverage (TLC) and vulnerability-fixing code line coverage (FLC) to
    evaluate the effectiveness of SliceLocator. We apply SliceLocator to four detectors,
    including DeepWukong [\[6\]](#page-20-2), Reveal [\[7\]](#page-20-10), IVDetect
    [\[8\]](#page-20-11), Devign [\[9\]](#page-20-3) and perform multi-dimensional
    evaluations. In the first phase, we assess the performance of SliceLocator by
    comparing it to the other five explanation methods, including PGExplainer [\[12\]](#page-20-6),
    GNNExplainer [\[11\]](#page-20-5), GNN-LRP [\[14\]](#page-20-8), GradCAM [\[13\]](#page-20-7),
    and DeepLift [\[17\]](#page-21-1). The experimental data indicate that the SliceLocator,
    combined with four detectors, achieves a TLC score ranging from 0.83 to 0.93 and
    an FLC score of at least around 0.7. This performance is not only superior to
    the other five explanation methods but also demonstrates minimal deviation across
    different detectors. In the second phase, we compare SliceLocator''s performance
    combined with four graph-based detectors against two deep learningbased statement-level
    detectors, LineVul [\[18\]](#page-21-2) and LineVD [\[19\]](#page-21-3). Experimental
    data demonstrate that SliceLocator consistently outperforms both LineVul and LineVD.


    <span id="page-3-0"></span>![](_page_3_Figure_0.jpeg)


    Fig. 1: General detection phase of deep-learning-based vulnerability detectors
    with graph representations


    This higher performance can be attributed to SliceLocator''s ability to effectively
    leverage both the detector''s sensitivity to VFS and heuristic taint flow knowledge.
    Unlike other explanation methods and statement-level detectors, which fail to
    fully exploit this critical information, SliceLocator combines these factors to
    enhance its vulnerability localization accuracy. The data supporting the paper
    can be accessed at [\[20\]](#page-21-4).


    In summary, we make the following main contributions:


    - A novel vulnerability statement locating technique via GNN-based vulnerability
    detectors. Given the inadequate explainability of the existing GNNbased vulnerability
    detectors, we propose the framework SliceLocator as a solution. It can identify
    important flow paths in a program that contain vulnerabilitytriggering statements,
    providing finer-grained semantics contexts for the identified vulnerabilities.

    - Approach effectiveness. Through a multi-dimensional evaluation of a comprehensive
    benchmark dataset, we demonstrate that SliceLocator outperforms existing explanation
    methods in terms of both TLC and FLC, which are crucial factors influencing vulnerability
    localization and fixing. On average, SliceLocator achieves a TLC of 0.89 and an
    FLC of 0.85 across all vulnerability detectors used in this study, highlighting
    its strong generalization ability across different GNN-based vulnerability detectors.


    # 2 Background


    ### 2.1 GNN-based Vulnerability Detectors


    Recently, GNNs have been utilized by security analysts and researchers in vulnerability
    detection tasks [\[6–](#page-20-2)[9,](#page-20-3) [21,](#page-21-5) [22\]](#page-21-6).
    They presume the graph representation of codes could better preserve critical
    semantic information of vulnerability-related programs, compared with traditional
    sequence-based representation. Typically, the most frequently used graph representation
    is code property graph (CPG) [\[23\]](#page-21-7), which is combined with abstract
    syntax tree (AST), control flow graph (CFG), control dependence graph (CDG), and
    data dependence graph (DDG). Generally, the detection phase of a GNN-based detector
    usually consists of three steps, as shown in Figure [1:](#page-3-0)


    (a) Parsing source code into a graph representation. Source code is typically
    in plain text, and must first be parsed into an AST, which can then be further


    transformed into other graph representations. This process can be accomplished
    using tools like Joern [\[23\]](#page-21-7).


    (b) Embedding code graph into vectorized representation. In a code graph, a node
    typically represents a program statement, while an edge indicates a relationship
    (such as execution order or def-use) between two statements. To generate the initial
    embeddings for the graph, each node needs to be vectorized. Following previous
    studies [\[7,](#page-20-10) [19,](#page-21-3) [22\]](#page-21-6), this can be
    achieved using techniques such as Word2Vec [\[24\]](#page-21-8), Doc2Vec [\[25\]](#page-21-9),
    or CodeBert [\[26\]](#page-21-10). The graph''s vectorized representation is then
    created by sequentially embedding all the nodes.


    (c) Using a well-trained GNN model to classify vectorized code graph. With vectorized
    graphs of code fragments and their labels, a GNN model, such as Graph Convolutional
    Networks (GCN) and Gated Graph Neural Networks (GGNN), could be trained to detect
    vectorized graph data from target programs.


    ### 2.2 Explanations approaches for vulnerability detection


    GNN-based detectors are capable of identifying vulnerable code snippets but fail
    to pinpoint the exact vulnerable statements. A direct solution to this issue is
    to employ instance-level explanation methods [\[15\]](#page-20-9). The basic principle
    of these methods is to identify and highlight the parts of a sample that are most
    critical to the model''s prediction, and then map them to the corresponding vulnerable
    statements for localization.


    Currently, instance-level explanation methods can be categorized into three main
    types: Gradients-based, Perturbation-based, and Decomposition-based, with prominent
    examples including GNNExplainer [\[11\]](#page-20-5), PGExplainer [\[12\]](#page-20-6),
    GradCAM [\[13\]](#page-20-7), DeepLIFT [\[17\]](#page-21-1), and GNNLRP [\[14\]](#page-20-8).
    While these methods appear promising, previous studies [\[16,](#page-21-0) [27,](#page-22-0)
    [28\]](#page-22-1) have shown that their effectiveness, stability, and robustness
    are often suboptimal. This can be attributed to the sometimes imperfect performance
    of GNN-based detectors, which, despite their high detection efficiency, may still
    overfit the differences between vulnerable and non-vulnerable samples, leading
    to poor explanation results. Overall, the poor performance of existing explanation
    methods can be attributed to their over-reliance on the model itself, without
    adequately considering the underlying semantics of vulnerabilities.


    # <span id="page-4-0"></span>3 Problem Formulation and Challenge


    ### 3.1 Problem Overview


    Considering the points raised in the previous section, one might wonder whether
    a more direct approach could be employed for vulnerability localization. The most
    straightforward method would involve slicing the program at all potential vulnerability
    trigger points. Approaches such as VulDeePecker [\[29\]](#page-22-2), SySeVR [\[30\]](#page-22-3),
    and DeepWuKong [\[6\]](#page-20-2) follow this strategy, training detectors after
    performing program slicing. However, because these methods include all statements
    with potential data dependencies in a saturated manner, the resulting slices remain
    quite large. Therefore, a more fine-grained approach is necessary. Specifically,
    one could perform a finer backward slicing within a given slice or function, focusing
    on all Vulnerability Triggering Statements (VTS). This process could yield multiple
    smaller slices, each containing only a subset of statements. Specifically, each
    slice could be a unique data-flow path. The critical challenge then becomes identifying
    the slice most likely to trigger the vulnerability.


    The idea can be illustrated with the following example, as shown in Figure [3.](#page-7-0)
    It involves a buffer overflow vulnerability triggered by copying more data (i.e.,
    100 bytes, defined on line 11 of the code fragment) than the maximum capacity
    of an array (i.e., 50 bytes, defined on line 2). A GNN-based vulnerability detector
    would simply output a binary detection result (1 indicating the code fragment
    is vulnerable, or 0 indicating it is not). The objective of the vulnerability
    localization task is to identify the VTS line 11 along with its related data dependencies.
    Since the vulnerability is triggered by array access or a copy function call,
    lines 5, 9, 10, 11, and 13 should be conservatively flagged as potential slicing
    starting points, with multiple slicing paths generated from these points. From
    the generated paths, we select those that align with our vulnerability localization
    objective. In the example shown in Figure [3,](#page-7-0) several flow paths can
    be extracted from the original code fragment, such as 8 --> 11, 2 --> 6 --> 7
    --> 13, and so on. Among these, the path 2 --> 6 --> 7 --> 11 is considered the
    most critical, as it includes both line 2 (where a critical variable is assigned)
    and line 11 (where the vulnerability is triggered).


    ### 3.2 Challenge


    The ideas outlined below are straightforward. However, the challenge lies in how
    to select the most important paths. Theoretically, more important paths should
    be assigned higher weights. Achieving this goal is difficult with current explanation
    approaches. However, a previous study [\[16\]](#page-21-0) has found that models
    tend to be more sensitive to vulnerability-fixing statements (VFS) than to VTS.
    One possible reason for this is that the code at VFS locations differs between
    vulnerable and non-vulnerable samples, making it easier for the model to determine
    whether the code is vulnerable based on the VFS. In contrast, VTS appear in both
    vulnerable and non-vulnerable samples, meaning that their presence does not necessarily
    have as strong an influence on the model''s decision-making process.


    To further investigate the significance of VFS in model predictions, we apply
    a method similar to that used in a previous study, utilizing the full dataset
    they employed [\[16\]](#page-21-0). Specifically, we mask individual code lines
    and calculate the change in vulnerability prediction probabilities, which serves
    as the importance score for each line with respect to the model. We then calculate
    the importance scores for VFS, along with the maximum importance scores for the
    non-VFS code lines. The experimental results for DeepWuKong, Devign, IVDetect,
    and Reveal are presented in Table [1.](#page-6-0) The results indicate that VFS
    tends to be more important to the model than other code lines. We conduct a manual
    analysis of several cases and found that there is typically a strong program dependency
    between VFS and VTS in many vulnerability samples. Moreover, the potential VTS
    within a sample rarely appears across multiple data


    <span id="page-6-0"></span>


    | Detector   | VFS  | max non-VFS |

    |------------|------|-------------|

    | DeepWuKong | 0.44 | 0.31        |

    | Reveal     | 0.2  | 0.09        |

    | IVDetect   | 0.13 | 0.1         |

    | Devign     | 0.32 | 0.14        |

    |            |      |             |


    Table 1: Importance Score of VFS and the maximum of non-VFS


    dependencies leading to the VFS. For example, in CVE-2013-2174[1](#page-0-0) which
    is shown in Figure [2,](#page-6-1) insufficient validation of the alloc variable
    leads to a potential buffer overflow at string[2] on line 7. To address this,
    developers add the condition alloc > 2 in line 5 to ensure proper validation.
    The VTS involves access to string[2], which is control-dependent on the condition
    in the VFS, specifically the if condition. Therefore, we propose using a trained
    detection model to predict the importance of each path and introduce SliceLocator
    as a solution for this task.


    <span id="page-6-1"></span>![](_page_6_Figure_3.jpeg)


    Fig. 2: Simplified code from the fix commit for CVE-2013-2174


    # 4 Approach


    The overall framework of SliceLocator is shown in Figure [4,](#page-7-1) which
    consists of two modules: flow path generation from the original code graph and
    critical path selection.


    Flow Path Generation. Given a vulnerable code fragment represented as a graph
    with its control- and data-dependence computed (in Figure [4\(](#page-7-1)a)),
    SliceLocator first identifies statements (i.e., nodes) in the program that might
    trigger the vulnerability, denoted as potential sink points (PSPs). Next, SliceLocator
    iteratively traverses backward from a PSP along a data- & control-dependence path
    (denoted as flow path


    <sup>1</sup><https://github.com/curl/curl/commit/192c4f788d48f82c03e9cef40013f34370e90737>


    <span id="page-7-0"></span>![](_page_7_Figure_0.jpeg)


    Fig. 3: A example extracted from SARD.


    <span id="page-7-1"></span>![](_page_7_Figure_2.jpeg)


    Fig. 4: Overview of SliceLocator.


    hereafter) in the program graph, until the source of the PSP (e.g., a node representing
    critical variable assignment) is reached. Similarly, SliceLocator generates all
    the qualified flow paths from the graph, each ending with a PSP.


    Flow Path Selection. SliceLocator first vectorizes each flow path and computes
    an importance score correlated to the vulnerability probability (in Figure [4\(](#page-7-1)b)).
    Next, SliceLocator selects the flow path with the highest importance score as
    the vulnerability data flow. Note that we do not directly train a classifier for
    the path selection as each path is regarded as a data flow rather than a code
    fragment.


    ### 4.1 Flow Path Generation


    To generate flow paths from the original code graph (i.e., PDG), we utilize the
    program slicing [\[31\]](#page-22-4) technique, which has been widely adopted
    in previous works such as DeepWukong and VulDeePecker. Unlike previous approaches,
    which focus on generating complete code fragments, our slicing technique emphasizes
    selecting a fine-grained set of flow paths. The slicing principle is based on
    both control and data dependence within the PDG, enabling more precise vulnerability
    localization. More specifically, the detailed flow path generation approach is
    outlined in the GENERATESLICE function in Algorithm [1.](#page-9-0)


    Algorithm [1](#page-9-0) Details. In line 2, the path set S for the current program
    is initialized as an empty set. In line 3, the algorithm extracts PSPs with the
    given code graph (Section [4.1.1\)](#page-8-0). Then the algorithm generates flow
    paths for each PSP with the following steps. In line 5, we initialize the current
    traversed path p with the corresponding PSP. Then in line 6, the current PSP''s
    flow-path set is initialized as an empty set. In line 7, flow paths are generated
    with a DFS algorithm (to be explained next). In line 8, we include all flow paths
    of the current PSP to the path set S.


    The function DFS describes the process of the backward traversing algorithm when
    generating flow paths. In lines 14-16, if the length of the current flow path
    p reaches the upper limit, then p will be appended to the path set S and the function
    will return. In lines 18-19, the algorithm extracts nodes on which the last node
    n of p is dependent. In lines 20-22, if p cannot continue to extend, then p will
    be appended to S. Otherwise, in lines 24-27, we repeat this DFS process for each
    node that n is dependent on.


    #### <span id="page-8-0"></span>4.1.1 Potential Sink Points (PSPs)


    PSPs are statements that are critically related to vulnerabilities. In Algorithm
    [1,](#page-9-0) they are extracted by the function ExtractSinkNode (line 3) which
    considers the following four types of PSPs in our program slicing. We adopt the
    same definition proposed by Li et al [\[30\]](#page-22-3).


    - Library/API Function Call (FC). This kind of PSP covers almost all vulnerability
    types except for integer overflow. Different types of vulnerabilities are triggered
    by various types of API calls. For example, OS command injection is usually triggered
    by APIs such as system and execl, while buffer overflow is normally triggered
    by data copy functions like memcpy.

    - Array Usage (AU). This kind of PSP usually appears in memory errors. In this
    study, AU only covers the buffer overflow vulnerability. For example, data[i]
    = 1; might cause a buffer overflow. Note that we do not consider trivial cases
    such as array accesses with constant indexes in this work.

    - Pointer Usage (PU). Similar to AU, PU usually appears in memory errors. This
    study only covers buffer overflow vulnerability.

    - Arithmetic Expression (AE). This type of PSP is usually an arithmetic expression
    like a + 1 or a++. AE is usually related to integer overflow and division-by-zero
    vulnerabilities. Here we mainly focus on the former. Note that we do not consider
    trivial cases such as self-increment and self-decrement operations with conditional
    checks in this work.


    <span id="page-9-0"></span>Algorithm 1 Slice Generation Algorithm.


    Input: code graph G,max length of path k Output: path set S 1: function GenerateSlice(G,
    k) 2: S ← ∅ 3: sink nodes ← ExtractSinkNodes(G) 4: for sink node ∈ sink nodes
    do 5: p ← {sink node} 6: S ′ ← ∅ 7: DFS(p, G, 1, k, S ′ ) 8: Append all slice
    in S ′ to S 9: end for 10: return S 11: end function 12: 13: function DFS(p, G,
    l, k, S) 14: if l = k then 15: Append p to S 16: return 17: end if 18: n ← last
    node in p 19: prec nodes ← ExtractPrecNodes(n, G) 20: if prec nodes is ∅ then
    21: Append p to S 22: return 23: end if 24: for prec node ∈ prec nodes do 25:
    Append prec node to p 26: DFS(p, G, 1 + 1, k, S) 27: pop the last node in p 28:
    end for 29: end function


    #### 4.1.2 Dependent Statements


    The function ExtractPrecNodes (line 19) in Algorithm [1](#page-9-0) establishes
    the dependence relation for the node n (i.e., identify nodes that the node n is
    dependent on). We find that not every dependence relation for node n is related
    to the vulnerability, as a source code statement might contain multiple expressions
    among which only one could trigger the vulnerability. Therefore, we only focus
    on the control and data dependence involving key variables related to each PSP
    when extracting dependent nodes. For illustration in Figure [5,](#page-10-0) our
    tool identified arithmetic operation CHAR ARRAY SIZE - 1 which might trigger integer
    underflow in statement S3. Although S3 is data-dependent with S1 via the variable
    connectSocket, they do not appear in arithmetic operations. We thus do not consider
    the data-dependence


    <span id="page-10-0"></span>![](_page_10_Figure_0.jpeg)


    Fig. 5: An example of ignored data-dependence edges.


    ![](_page_10_Figure_2.jpeg)


    Fig. 6: An example to demonstrate how slicing works by revisiting the code in
    Figure [3.](#page-7-0)


    edge S1 --> S3 when performing slicing. For other nodes, we consider all dependent
    statements of the current node.


    ### 4.2 Flow Path Selection


    Among the flow paths, we aim to select one that can best locate the vulnerabilitytriggering
    statements based on the prediction results. The key intuition is that if a path
    contains both the PSP and its source node, the path should be selected. For example,
    the path 2 --> 6 --> 7 --> 11 in the example in Section [3.](#page-4-0) If there
    is more than one qualified path, we further rank them based on the path importance
    (to be detailed below) and select the one with the highest importance score.


    More formally, given a code graph G, we extract flow paths from it and vectorize
    each path. The process of vectorizing a flow path is consistent with how detectors
    vectorize the corresponding code graph. We then compute the importance score for


    each flow path by treating each vectorized flow path as a subgraph of the original
    code graph and inputting it into a well-trained GNN-based vulnerability detector.
    This process could be formally described as:


    $$p\_g = \Phi(\text{vec}(g))\tag{1}$$


    where g is a flow path extracted from G, Φ is one of the GNN-based vulnerability
    detectors.Finally, we compute the importance score IS<sup>g</sup> for each path,
    measuring their contribution to the detector predicting the corresponding code
    fragment.


    $$\text{IS}\_g = 1 - \left(\Phi(\text{vec}(G)) - p\_g\right) \tag{2}$$


    Suppose there are n flow paths after slicing G and denoted as {g1, ..., g<sup>i</sup>
    , ...gn}. The vulnerability data flow g<sup>∗</sup> is denoted as:


    $$g^\* = \text{argmax } (\text{IS}\_{g\_i}) \tag{3}$$


    # 5 Study Design


    ### 5.1 Evaluation Methodology


    We evaluate the effectiveness of SliceLocator in locating vulnerability statements
    based on the prediction results from DeepWukong, Reveal, IVDetect, and Devign.
    Our evaluation addresses the following research questions:


    - RQ1 Can SliceLocator outperform existing instance-level explanation methods
    in vulnerability localization when combined with GNN-based detectors? We compare
    SliceLocator with five other instance-level explanation methods [\[11–](#page-20-5)
    [14,](#page-20-8) [17\]](#page-21-1) in terms of vulnerability localization performance
    on GNN-based detectors.

    - RQ2 Can SliceLocator outperform deep learning-based statement-level detectors
    in vulnerability localization? We compare SliceLocator, combined with four GNN-based
    detectors, to two deep learning-based statement-level detectors [\[18,](#page-21-2)
    [19\]](#page-21-3) for vulnerability localization performance.

    - RQ3 Is the trained detector crucial for path selection? In some of the experiments,
    we investigate this by replacing the path selection strategy that assigns the
    highest weight to the path identified by the detector with a random selection
    of paths. This allows us to examine the importance of the detector in the path
    selection process.


    For evaluating the explanation methods, we follow the approach in the previous
    study [\[16\]](#page-21-0), using two metrics: Vulnerability-Triggering Line Coverage
    (TLC) and Vulnerability-Fixing Line Coverage (FLC). Since the study also highlights
    that fidelity is not a reliable measure for assessing the effectiveness of explanation
    methods in vulnerability detection, we exclude fidelity from our evaluation. The
    line coverage (LC) can be calculated using the following equation, where s <sup>v</sup>
    denotes the set of labeled triggering statements and s e represents the set of
    statements predicted by statement-localization methods.


    $$\text{LC} = \frac{|s^e \cap s^v|}{|s^v|} \tag{4}$$


    $$^{12}$$


    For the vulnerability localization results, we present the top-k TLC or FLC score.
    For explanation methods, the top-k results refer to the k highest-weighted statements
    after the explanation method assigns weights to each statement. For both SliceLocator
    and random path selection, top-k represents selecting the highest-weighted path
    from those sliced paths with lengths less than k. Here, k can take values of 3,
    5, and 7.


    ### <span id="page-12-0"></span>5.2 Dataset Construction


    The dataset used for evaluation must support fine-grained vulnerability detection,
    which requires explicit annotations of vulnerable code lines. Many real-world
    datasets, such as Devign [\[9\]](#page-20-3), Reveal, and Big-Vul [\[32\]](#page-22-5),
    label flaw lines based on code change information extracted from committed version
    patches. While D2A [\[33\]](#page-22-6) constructs the dataset by comparing the
    vulnerability reports produced by Infer [\[4\]](#page-20-0) with GitHub commit
    information. Roland Croft et al. [\[34\]](#page-22-7) have reported that real-world
    datasets contain between 20-71% false positive samples, where code marked as vulnerable
    is actually safe. This might be because the fixing commits contain changes unrelated
    to vulnerability fixes. More importantly, datasets like Big-Vul and Devign, which
    annotate vulnerable functions based on fixing commits, only include information
    about modified code lines without indicating the locations where vulnerabilities
    are triggered. Additionally, even vulnerability-related code changes can include
    non-vulnerabilityrelated changes, leading to potential mislabeling of code lines.
    Due to these challenges, previous studies on vulnerability detection [\[7,](#page-20-10)
    [8,](#page-20-11) [19,](#page-21-3) [28\]](#page-22-1) have faced difficulties
    in training well-performing detectors on these datasets. Consequently, following
    prior research [\[16,](#page-21-0) [35\]](#page-22-8), we adopt the SARD dataset
    [\[36\]](#page-22-9), which offers more accurate vulnerability annotations and
    facilitates the training of effective detectors. Our focus is on six of the top
    30 most critical C/C++ software weaknesses identified in 2021, specifically CWE20,
    CWE119, CWE125, CWE190, CWE400, and CWE787 following those studies.


    We use the same crawler employed in DeepWuKong to download the SARD dataset. Following
    previous studies [\[6,](#page-20-2) [16,](#page-21-0) [35\]](#page-22-8), we use
    tools such as SVF [\[2\]](#page-19-1) and Joern [\[23\]](#page-21-7) to split
    the code into fragments, such as slices or functions, and then parse them into
    graph representations. The SARD dataset annotates certain VTS, and we match the
    parsed code fragments with these annotations to identify vulnerable code fragments
    and VTS. Next, we apply a heuristic automated labeling mechanism, as done in prior
    work [\[16\]](#page-21-0), to annotate the VFS. Finally, we remove duplicate code
    fragments by following the method outlined in previous studies [\[6\]](#page-20-2),
    which utilizes MD5 value comparison to identify and exclude duplicates. After
    the processing stage, we collect 73,750 vulnerable functions, 152,771 non-vulnerable
    functions, 138,360 slices, and 364,177 non-vulnerable slices from the SARD dataset,
    as listed in Table [2.](#page-13-0)


    # 6 Experiment


    ### 6.1 Experimental Setup


    The experiments are conducted on a machine with two NVIDIA GeForce GTX TitanX
    GPUs and an Intel Xeon E5-2603 CPU. Graph neural networks are implemented using


    <span id="page-13-0"></span>


    | Vulnerability Category | Code Fragment | # Vulnerable Samples | # Safe Samples
    | # Total |

    |------------------------|---------------|----------------------|----------------|---------|

    | CWE20                  | slice         | 58,350               | 174,250        |
    232,600 |

    |                        | function      | 25,829               | 54,842         |
    80,671  |

    | CWE119                 | slice         | 34,901               | 80,155         |
    115,056 |

    |                        | function      | 21,662               | 40,466         |
    62,128  |

    | CWE125                 | slice         | 6,147                | 12,469         |
    18,616  |

    |                        | function      | 4,315                | 7,907          |
    12,222  |

    | CWE190                 | slice         | 4,173                | 10,168         |
    14,341  |

    |                        | function      | 3,948                | 11,347         |
    15,295  |

    | CWE400                 | slice         | 11,296               | 37,417         |
    48,713  |

    |                        | function      | 2,199                | 10,831         |
    13,030  |

    | CWE787                 | slice         | 23,493               | 49,718         |
    73,211  |

    |                        | function      | 15,977               | 27,378         |
    43,355  |

    | Total                  | slice         | 138,360              | 364,177        |
    502,537 |

    |                        | function      | 73,750               | 152,771        |
    226,521 |


    Table 2: Distribution of labeled samples from SARD.


    PyTorch Geometric [\[37\]](#page-23-0). We train separate models for each of the
    six vulnerability categories, using 80% of the data for training, 10% for validation,
    and 10% for testing. The model implementation follows DeepWuKong [\[38\]](#page-23-1),
    IVDetect [\[39\]](#page-23-2), Devign [\[40\]](#page-23-3), and Reveal [\[41\]](#page-23-4),
    with hyperparameters consistent with the original works. Neural networks are trained
    in batches (batch size = 64) using Adam [\[42\]](#page-23-5) with a learning rate
    of 0.001. All models are initialized randomly via Torch initialization. For the
    result explanation, we implement five state-of-the-art methods—PGExplainer, GNNExplainer,
    GradCAM, DeepLift, and GNNLRP—following DIG [\[43\]](#page-23-6).


    Before presenting the experimental results for our three research questions, we
    first provide an overview of the average detection performance of the four detectors
    on the SARD dataset. We evaluate the performance of the detectors using four metrics:
    accuracy, recall, precision, and F1 score. The average results are summarized
    in Table [3.](#page-13-1) We observe that the performance of all four detectors
    is generally satisfactory, although Devign exhibits slightly lower performance
    compared to the other three detectors.


    | Detector   | Accuracy | Precision | Recall | F1   |

    |------------|----------|-----------|--------|------|

    | DeepWuKong | 0.97     | 0.95      | 0.98   | 0.95 |

    | Reveal     | 0.96     | 0.91      | 0.99   | 0.95 |

    | IVDetect   | 0.98     | 0.95      | 0.99   | 0.97 |

    | Devign     | 0.95     | 0.9       | 0.94   | 0.92 |


    <span id="page-13-1"></span>Table 3: Detection performance of four detectors.


    ### 6.2 RQ1: SliceLocator VS Explanation Approaches


    The comparison of vulnerability localization performance (TLC and FLC scores)
    between SliceLocator and the other five explanation approaches is shown in Figure
    [7](#page-14-0) and Figure [8,](#page-15-0) respectively. Overall, SliceLocator
    achieves average top-3 to top-7 TLC scores ranging from 0.87 to 0.89 and FLC scores
    ranging from 0.78 to 0.87 across the four detectors. In contrast, among the five
    instance-level explanation approaches, GradCAM achieves the highest TLC scores,
    with average top-3 to top-7 scores ranging from 0.55 to 0.76, while DeepLift achieves
    the highest FLC scores, with top-3 to top-7 scores ranging from 0.49 to 0.64.
    These results demonstrate that SliceLocator outperforms the explanation approaches
    by at least 0.22 in TLC scores and by at least 0.33 in FLC scores.


    To further evaluate the performance of SliceLocator and the explanation methods,
    we conduct a case study based on the example presented in Section [3,](#page-4-0)
    with the results shown in Figure [9.](#page-15-1) Here, SL, PE, GE, GR, DL, and
    GL represent SliceLocator, PGExplainer, GNNExplainer, GradCAM, DeepLift, and GNN-LRP,
    respectively. From the results, we observe that PGExplainer, GradCAM, and GNN-LRP
    fail to identify the statement triggering the vulnerability. Moreover, while GNNExplainer
    and DeepLift acknowledge that statement 11 is relevant to the vulnerability, they
    struggle to capture the connections between this triggering statement and other
    vulnerability-relevant statements. The limitations of these explanation methods
    stem from two key factors. First, their ability to explain deep learning models
    is inherently constrained. Second, their focus is on imitating the inference process
    of the model, which primarily learns the distinctions between vulnerable and normal
    samples. This approach hinders their capacity to derive the underlying semantics
    of vulnerabilities. In contrast, SliceLocator leverages the learned distinctions
    between different sample types, combined with relevant taint flow knowledge, to
    predict the most vulnerability-related taint flows, effectively identifying the
    taint flows linked to vulnerabilities.


    <span id="page-14-0"></span>


    |              | (a).DWK-TLC |                |      |      | (b).ReV-TLC    |      |      |
    (c).IVD-TLC    |      |      | (d).Dev-TLC    |      |

    |--------------|-------------|----------------|------|------|----------------|------|------|----------------|------|------|----------------|------|

    | SliceLocator | 0.91        | 0.93           | 0.93 | 0.83 | 0.86           |
    0.86 | 0.9  | 0.9            | 0.9  | 0.85 | 0.88           | 0.88 |

    | Random       | 0.73        | 0.73           | 0.73 | 0.72 | 0.72           |
    0.73 | 0.73 | 0.73           | 0.74 | 0.72 | 0.74           | 0.74 |

    | GNN-LRP      | 0.35        | 0.54           | 0.61 | 0.33 | 0.45           |
    0.5  | 0.17 | 0.33           | 0.4  | 0.4  | 0.56           | 0.61 |

    | GradCAM      | 0.6         | 0.74           | 0.81 | 0.51 | 0.65           |
    0.68 | 0.49 | 0.69           | 0.76 | 0.61 | 0.74           | 0.79 |

    | DeepLift     | 0.23        | 0.37           | 0.43 | 0.39 | 0.52           |
    0.56 | 0.08 | 0.15           | 0.18 | 0.24 | 0.34           | 0.41 |

    | PGExplainer  | 0.23        | 0.36           | 0.4  | 0.47 | 0.58           |
    0.63 | 0.39 | 0.55           | 0.6  | 0.33 | 0.49           | 0.54 |

    | GNNExplainer | 0.25        | 0.41           | 0.46 | 0.35 | 0.5            |
    0.56 | 0.4  | 0.58           | 0.64 | 0.35 | 0.51           | 0.57 |

    |              |             | Top3 Top5 Top7 |      |      | Top3 Top5 Top7 |      |      |
    Top3 Top5 Top7 |      |      | Top3 Top5 Top7 |      |


    Fig. 7: Comparsion between SliceLocator with explanation approaches and random
    path selection in TLC.


    <span id="page-15-0"></span>


    |                    |      | Top3 Top5 Top7 |      |                    | Top3
    Top5 Top7 |      |               | Top3 Top5 Top7 |      |               | Top3
    Top5 Top7 |      |

    |--------------------|------|----------------|------|--------------------|----------------|------|---------------|----------------|------|---------------|----------------|------|

    | GNNExplainer       | 0.26 | 0.4            | 0.47 | 0.33               | 0.48           |
    0.55 | 0.45          | 0.6            | 0.66 | 0.33          | 0.45           |
    0.51 |

    | PGExplainer        | 0.25 | 0.39           | 0.45 | 0.32               | 0.47           |
    0.53 | 0.56          | 0.67           | 0.72 | 0.43          | 0.59           |
    0.63 |

    | DeepLift           | 0.42 | 0.57           | 0.61 | 0.48               | 0.58           |
    0.62 | 0.45          | 0.6            | 0.66 | 0.6           | 0.65           |
    0.67 |

    | GradCAM            | 0.2  | 0.39           | 0.49 | 0.39               | 0.52           |
    0.57 | 0.6           | 0.68           | 0.72 | 0.19          | 0.38           |
    0.47 |

    | GNN-LRP            | 0.3  | 0.47           | 0.54 | 0.38               | 0.5            |
    0.56 | 0.57          | 0.78           | 0.82 | 0.43          | 0.58           |
    0.62 |

    | Random             | 0.34 | 0.37           | 0.38 | 0.38               | 0.38           |
    0.39 | 0.37          | 0.39           | 0.4  | 0.38          | 0.38           |
    0.4  |

    | SliceLocator       | 0.68 | 0.79           | 0.8  | 0.74               | 0.88           |
    0.89 | 0.85          | 0.85           | 0.87 | 0.86          | 0.87           |
    0.92 |

    | (a.1).DWK-Sard-FLC |      |                |      | (a.2).ReV-Sard-FLC |                |      |
    (a.3).IVD-FLC |                |      | (a.4).Dev-FLC |                |      |


    <span id="page-15-1"></span>Fig. 8: Comparsion between SliceLocator with explanation
    approaches and random path selection in FLC.


    ![](_page_15_Figure_2.jpeg)


    Fig. 9: Vulnerability locating results by different explainers for the prediction
    of Reveal in the motivating example.


    ANSWER: SliceLocator outperforms other explanation methods in vulnerability localization
    because it more effectively integrates the model''s understanding of the differences
    between vulnerable and non-vulnerable code, along with predefined taint flow knowledge.


    ### 6.3 RQ2: SliceLocator VS Statement-level Detectors


    Prior research has explored both the use of explanation methods for locating vulnerability
    code lines based on binary classification detectors [\[8,](#page-20-11) [44\]](#page-23-7)
    and the direct training of statement-level detectors. In this section, we select
    two representative detectors, LineVul [\[18\]](#page-21-2) and LineVD [\[19\]](#page-21-3),
    as baselines for comparison.


    • LineVul employs a straightforward vulnerability detection approach. It fine-tunes
    a pre-trained CodeBERT [\[26\]](#page-21-10) model on a vulnerability dataset
    to directly train a function-level binary classifier. For functions predicted
    as vulnerable, LineVul


    leverages CodeBERT''s attention mechanism to compute the weight of each statement,
    then selects the top-k statements based on their weights as the vulnerability
    localization results.


    • LineVD directly predicts vulnerability at the statement level. It leverages
    a pretrained CodeBERT model to generate embeddings for functions and statements,
    which are then processed using a Graph Attention Network (GAT) [\[45\]](#page-23-8).
    A classifier is trained to predict the vulnerability of both function and statement
    embeddings, with predictions of 1 indicating vulnerability.


    <span id="page-16-0"></span>We first present the function-level vulnerability
    detection results of LineVD and LineVul in Table [4.](#page-16-0) LineVul performs
    excellently, outperforming IVDetect and Reveal, while LineVD shows considerably
    lower effectiveness. One possible explanation for this difference is that LineVD
    uses a shared classifier for both function and statement-level predictions.


    Table 4: Detection performance of linelevel detectors.


    | Detector | Accuracy | Precision | Recall | F1   |

    |----------|----------|-----------|--------|------|

    | LineVul  | 0.99     | 0.99      | 0.99   | 0.99 |

    | LineVD   | 0.78     | 0.61      | 0.87   | 0.72 |


    The vulnerability localization results of SliceLocator combined with four detectors,
    compared to LineVul and LineVD, are shown in Figure [10.](#page-17-0) It can be
    observed that, regardless of the detector used, SliceLocator consistently outperforms
    both LineVul and LineVD. LineVul locates vulnerability statements by computing
    the statement weights using the attention mechanism. However, like other instance-level
    explanation approaches, LineVul is constrained by two factors: (1) the model learns
    only the differences between vulnerable and non-vulnerable samples without taint
    inference capabilities, and (2) the attention mechanism may not serve as a perfect
    explanation method [\[8\]](#page-20-11). On the other hand, LineVD combines CodeBert
    and GAT to train a statement-level classifier. However, at the statement level,
    the issue of dataset imbalance is more pronounced than at the function level,
    and statements inherently contain more complex features, making it difficult to
    improve the training process using dataset balancing strategies. As a result,
    the classifier trained by LineVD struggles to detect vulnerability statements,
    yielding a TLC of only 0.01 and an FLC close to zero.


    ANSWER: SliceLocator generally outperforms other statement-level detectors. Existing
    statement-level detectors are similarly constrained by two key factors: (1) the
    detector has not learned predefined taint flow knowledge, and (2) the dataset
    exhibits a significant imbalance between vulnerability and non-vulnerability samples
    at the statement level.


    <span id="page-17-0"></span>


    |               | Top3      | Top5 | Top7 |  | Top3       | Top5 | Top7 |  |

    |---------------|-----------|------|------|--|------------|------|------|--|

    | SL + DWK      | 0.91      | 0.93 | 0.93 |  | 0.68       | 0.79 | 0.8  |  |

    | SL + Reveal   | 0.83      | 0.86 | 0.86 |  | 0.74       | 0.88 | 0.89 |  |

    | SL + IVDetect | 0.9       | 0.9  | 0.9  |  | 0.85       | 0.85 | 0.87 |  |

    | SL + Devign   | 0.85      | 0.88 | 0.88 |  | 0.86       | 0.87 | 0.92 |  |

    | LineVul       | 0.52      | 0.7  | 0.81 |  | 0.33       | 0.47 | 0.58 |  |

    | lineVD        | 0.05      | 0.05 | 0.05 |  | 0.01       | 0.01 | 0.01 |  |

    |               | (a.1).TLC |      |      |  | (a.2). FLC |      |      |  |


    Fig. 10: Comparsion between SliceLocator with statement-level detectors.


    ### 6.4 RQ3: SliceLocator VS Random Path Selection


    To further investigate the role of GNN-based detectors in flow path selection,
    we implemented a random path selection as a baseline. In this approach, instead
    of selecting the flow path with the highest weight based on the detector''s prediction,
    we randomly select a flow path. A comparison between random path selection and
    SliceLocator is shown in Figure [7](#page-14-0) and Figure [8,](#page-15-0) where
    Random denotes random path selection. We observe that after replacing the path
    selection strategy with random path selection, the TLC scores decrease by 0.11
    to 0.2, while the drop in FLC scores is even more significant. This further emphasizes
    that a well-trained GNN detector can effectively assist in selecting the most
    vulnerability-relevant taint flows for vulnerability localization.


    ANSWER: GNN-based detectors are crucial for SliceLocator, as they assist in selecting
    the optimal flow path for vulnerability localization.


    # 7 Threats to Validity


    First, we only conduct experiments on the SARD dataset, which contains synthetic
    and academic programs, but it may not be representative of real-world software
    products. We have discussed the problems in existing real-world datasets in section
    [5.2.](#page-12-0) It remains an open problem to generate reliable datasets on
    a fine-grained granularity and train a high-performing detector.


    Second, our experiments are limited to six vulnerability types in C/C++ programs.
    Nonetheless, our methodology can be effortlessly expanded to encompass additional
    source-sink vulnerabilities and other programming languages.


    Third, our approach only considers locating vulnerable statements based on four
    graph-based vulnerability detectors. However, our approach is easily applicable
    to other detectors, and potentially to other program analysis tasks.


    # 8 related work


    Conventional static analysis tools. Several conventional static program analysis
    frameworks(e.g. clang static analyzer [\[5\]](#page-20-1), Infer [\[4\]](#page-20-0),
    SVF [\[2\]](#page-19-1), MalWuKong [\[46\]](#page-23-9)) have


    been designed to detect vulnerabilities or identify malicious behaviors in software
    systems. clang static analyzer [\[5\]](#page-20-1) is a constraint-based static
    analysis tool that performs symbolic execution to explore paths in the program''s
    control-flow graph and detect potential bugs. While Infer [\[4\]](#page-20-0)
    is a static program analysis tool for detecting security issues such as null-pointer
    dereference and memory leaks based on abstract interpretation. SVF [\[2\]](#page-19-1)
    first parses a program into a sparse value-flow graph (SVFG) and then conducts
    path-sensitive source-sink analysis by traversing SVFG. The effect of conventional
    approaches depends on two factors: static analysis theories and security rules.
    static analysis theories include but are not limited to, parsing code into abstract
    structures (such as SVFG), where a better abstract structure facilitates the development
    of more sophisticated rules for detecting vulnerabilities. The effectiveness of
    detection rules depends on the expertise of the person who writes the rules. The
    quantity of rules is restricted, and it is impossible to encompass all of the
    vulnerability patterns, which frequently results in high rates of false positives
    and false negatives when analyzing intricate programs [\[6,](#page-20-2) [30\]](#page-22-3).


    Deep learning based vulnerability detection. Compared to conventional static analysis,
    another field is machine/deep-learning-based analysis [\[47–](#page-23-10)[49\]](#page-24-0).
    DeepBugs [\[50\]](#page-24-1) represents code via text vector for detecting name-based
    bugs. VGDetector [\[51\]](#page-24-2) uses a control flow graph and graph convolutional
    network to detect control-flow-related vulnerabilities. In this field, Devign
    [\[9\]](#page-20-3) and Reveal [\[7\]](#page-20-10) utilize graph representations
    to represent source code to detect vulnerabilities. They aim to pinpoint bugs
    at the function level. VulDeePecker [\[29\]](#page-22-2) applies code embedding
    using the data-flow information of a program for detecting resource management
    errors and buffer overflows. SySeVR [\[30\]](#page-22-3) and µVulDeePecker [\[52\]](#page-24-3)
    extend VulDeePecker by combining both control and data flow and different Recurrent
    neural networks(RNN) to detect various types of vulnerability. DeepWuKong [\[6\]](#page-20-2)
    utilizes program slicing methods to generate code fragments that are vectorized
    to apply the GNN model for classification. Hao et al. [\[53\]](#page-24-4) extend
    CFG in the domain of exception handling, subsequently leveraging this extension
    to enhance the detection capability of existing DL-based detectors for exception-handling
    bugs. W Zheng et al. [\[21\]](#page-21-5) combine DDG, CDG, and function call
    dependency graph (FCDG) into slice property graph (SPG), which is materialized
    into the implementation of the detection tool vulspg. Bin Yuan et al. [\[54\]](#page-24-5)
    construct a behavior graph for each function and implement VulBG to enhance the
    performance of DL-based detectors by behavior graphs. All these solutions can
    only detect vulnerabilities on coarse granularity, and they can only tell whether
    a given code fragment is vulnerable.


    Statement-level vulnerability detection. On the basis of deep learning vulnerability
    detection, fine-grained vulnerability detection has received increasing attention
    in recent years. More recently, Zou et al. [\[44\]](#page-23-7) propose an explanation
    framework to select key tokens in code gadgets generated by VulDeePecker and SeVCs
    generated by SySeVR to locate the vulnerable lines. VulDeeLocator [\[55\]](#page-24-6)
    compiles source codes into LLVM IRs, performs program slicing, and uses a customized
    neural network to predict relevance to vulnerabilities. LineVul [\[18\]](#page-21-2)
    analyses each function with fine-tuned CodeBert and ranks each statement based
    on attention scores, a higher attention score


    implies a stronger relation with vulnerability. IVDetect [\[8\]](#page-20-11)
    attain this goal by first identifying vulnerabilities at the source code level
    and utilizing the existing explanation approach GNNExplainer to generate a subgraph
    of the PDG to locate vulnerabilities in the function subsequently. However, several
    recent studies [\[16,](#page-21-0) [27,](#page-22-0) [28\]](#page-22-1) have substantiated
    the inefficiency of current explanation approaches in vulnerability detection.
    proved the inefficiency of current explanation approaches in vulnerability detection.
    LineVD [\[19\]](#page-21-3) leverages CodeBert and GAT to directly train a statement-level
    classifier, aiming to simultaneously predict both vulnerable functions and statements.
    However, this approach is constrained by the significant imbalance between vulnerable
    and non-vulnerable statements in the dataset.


    Machine-learning for software engineering. In addition to vulnerability detection,
    deep learning has made significant progress in recent years in software engineering
    tasks such as code clone detection and code understanding, The main difference
    between these methods lies in the different vectorization processes proposed for
    their specific tasks. The vectorizing pipelines can be categorized into tokens-based
    [\[56–](#page-24-7)[59\]](#page-25-0), ASTs-based [\[60–](#page-25-1)[63\]](#page-25-2)
    and graphs-based [\[64–](#page-25-3)[69\]](#page-26-0). Complex vectorizing pipelines
    often yield better results on specific tasks, but also rely on more precise program
    analysis theories.


    # 9 Conclusion


    In this paper, we present SliceLocatr. A tool that leverages the insights of GNNbased
    vulnerability detectors, which capture the differences between vulnerable and
    non-vulnerable samples—essentially vulnerability-fixing statements. Additionally,
    it incorporates taint flow knowledge related to vulnerabilities. By directly utilizing
    the predictions from detectors, SliceLocator selects the most relevant taint flow
    paths by assigning weights to these paths. The method begins with program slicing
    to extract flow paths of a code fragment, where each flow path concludes at a
    potential sink point (PSP). Afterward, SliceLocator applies a scoring function
    to assign importance scores to each path and selects the highest-weighted path
    as the most relevant explanation for the vulnerability data flow. We demonstrate
    the effectiveness of SliceLocator across six of the 30 most critical C/C++ vulnerabilities,
    showing that it outperforms several state-of-the-art GNN-based explainers and
    statement-level detectors in vulnerability detection tasks.


    # References


    - <span id="page-19-0"></span>[1] American Information Technology Laboratory:
    NATIONAL VULNERABILITY DATABASE. <https://nvd.nist.gov/> (2020)

    - <span id="page-19-1"></span>[2] Sui, Y., Xue, J.: Svf: interprocedural static
    value-flow analysis in llvm. In: Proceedings of the 25th International Conference
    on Compiler Construction, pp. 265–266 (2016)

    - <span id="page-19-2"></span>[3] Checkmarx. <https://www.checkmarx.com/> (2020)


    - <span id="page-20-0"></span>[4] Infer. <https://fbinfer.com/> (2020)

    - <span id="page-20-1"></span>[5] Clang static analyzer. <https://clang-analyzer.llvm.org/scan-build.html>
    (2020)

    - <span id="page-20-2"></span>[6] Cheng, X., Wang, H., Hua, J., Xu, G., Sui, Y.:
    Deepwukong: Statically detecting software vulnerabilities using deep graph neural
    network. ACM Trans. Softw. Eng. Methodol. 30(3) (2021) <https://doi.org/10.1145/3436877>

    - <span id="page-20-10"></span>[7] Chakraborty, S., Krishna, R., Ding, Y., Ray,
    B.: Deep learning based vulnerability detection: Are we there yet? IEEE Transactions
    on Software Engineering 48(9), 3280–3296 (2021)

    - <span id="page-20-11"></span>[8] Li, Y., Wang, S., Nguyen, T.N.: Vulnerability
    detection with fine-grained interpretations. (2021)

    - <span id="page-20-3"></span>[9] Zhou, Y., Liu, S., Siow, J.K., Du, X., Liu,
    Y.: Devign: Effective vulnerability identification by learning comprehensive program
    semantics via graph neural networks. In: Wallach, H.M., Larochelle, H., Beygelzimer,
    A., d''Alch´e-Buc, F., Fox, E.B., Garnett, R. (eds.) Advances in Neural Information
    Processing Systems 32: Annual Conference on Neural Information Processing Systems
    2019, NeurIPS 2019, December 8-14, 2019, Vancouver, BC, Canada, pp. 10197–10207
    (2019). [https://proceedings.neurips.cc/paper/2019/](https://proceedings.neurips.cc/paper/2019/hash/49265d2447bc3bbfe9e76306ce40a31f-Abstract.html)
    [hash/49265d2447bc3bbfe9e76306ce40a31f-Abstract.html](https://proceedings.neurips.cc/paper/2019/hash/49265d2447bc3bbfe9e76306ce40a31f-Abstract.html)

    - <span id="page-20-4"></span>[10] Cheng, X., Nie, X., Li, N., Wang, H., Zheng,
    Z., Sui, Y.: How about bug-triggering paths? - understanding and characterizing
    learning-based vulnerability detectors. IEEE Transactions on Dependable and Secure
    Computing, 1–18 (2022) [https:](https://doi.org/10.1109/TDSC.2022.3192419) [//doi.org/10.1109/TDSC.2022.3192419](https://doi.org/10.1109/TDSC.2022.3192419)

    - <span id="page-20-5"></span>[11] Ying, R., Bourgeois, D., You, J., Zitnik, M.,
    Leskovec, J.: Gnnexplainer: Generating explanations for graph neural networks.
    Advances in neural information processing systems 32, 9240–9251 (2019)

    - <span id="page-20-6"></span>[12] Luo, D., Cheng, W., Xu, D., Yu, W., Zhang,
    .X.: Parameterized explainer for graph neural network (2020)

    - <span id="page-20-7"></span>[13] Pope, P.E., Kolouri, S., Rostami, M., Martin,
    C.E., Hoffmann, H.: Explainability methods for graph convolutional neural networks.
    In: 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
    (2020)

    - <span id="page-20-8"></span>[14] Schnake, T., Eberle, O., Lederer, J., Nakajima,
    S., Sch¨utt, K., M¨uller, K., Montavon, G.: Higher-order explanations of graph
    neural networks via relevant walks (2020)

    - <span id="page-20-9"></span>[15] Yuan, H., Yu, H., Gui, S., Ji, S.: Explainability
    in graph neural networks: A taxonomic survey. IEEE transactions on pattern analysis
    and machine intelligence 45(5), 5782–5799 (2022)

    - <span id="page-21-0"></span>[16] Cheng, B., Zhao, S., Wang, K., Wang, M., Bai,
    G., Feng, R., Guo, Y., Ma, L., Wang, H.: Beyond fidelity: Explaining vulnerability
    localization of learning-based detectors 33(5) (2024) <https://doi.org/10.1145/3641543>

    - <span id="page-21-1"></span>[17] Shrikumar, A., Greenside, P., Kundaje, A.:
    Learning important features through propagating activation differences. In: Precup,
    D., Teh, Y.W. (eds.) Proceedings of the 34th International Conference on Machine
    Learning. Proceedings of Machine Learning Research, vol. 70, pp. 3145–3153. PMLR,
    ??? (2017). [https:](https://proceedings.mlr.press/v70/shrikumar17a.html) [//proceedings.mlr.press/v70/shrikumar17a.html](https://proceedings.mlr.press/v70/shrikumar17a.html)

    - <span id="page-21-2"></span>[18] Fu, M., Tantithamthavorn, C.: Linevul: a transformer-based
    line-level vulnerability prediction. In: Proceedings of the 19th International
    Conference on Mining Software Repositories, pp. 608–620 (2022)

    - <span id="page-21-3"></span>[19] Hin, D., Kan, A., Chen, H., Babar, M.A.: Linevd:
    statement-level vulnerability detection using graph neural networks. In: Proceedings
    of the 19th International Conference on Mining Software Repositories, pp. 596–607
    (2022)

    - <span id="page-21-4"></span>[20] Dataset Repository <https://github.com/for-just-we/VulExplainerExp/>
    (2023)

    - <span id="page-21-5"></span>[21] Zheng, W., Jiang, Y., Su, X.: Vu1spg: Vulnerability
    detection based on slice property graph representation learning. In: 2021 IEEE
    32nd International Symposium on Software Reliability Engineering (ISSRE), pp.
    457–467 (2021). IEEE

    - <span id="page-21-6"></span>[22] Cheng, X., Wang, H., Hua, J., Zhang, M., Sui,
    Y.: Static detection of controlflow-related vulnerabilities using graph embedding.
    In: 2019 24th International Conference on Engineering of Complex Computer Systems
    (ICECCS) (2019)

    - <span id="page-21-7"></span>[23] Yamaguchi, F., Golde, N., Arp, D., Rieck, K.:
    Modeling and discovering vulnerabilities with code property graphs. In: 2014 IEEE
    Symposium on Security and Privacy (SP), pp. 590–604. IEEE Computer Society, Los
    Alamitos, CA, USA (2014). <https://doi.org/10.1109/SP.2014.44> . [https://doi.ieeecomputersociety.](https://doi.ieeecomputersociety.org/10.1109/SP.2014.44)
    [org/10.1109/SP.2014.44](https://doi.ieeecomputersociety.org/10.1109/SP.2014.44)

    - <span id="page-21-8"></span>[24] Mikolov, T., Sutskever, I., Chen, K., Corrado,
    G., Dean, J.: Distributed representations of words and phrases and their compositionality.
    In: Proceedings of the 26th International Conference on Neural Information Processing
    Systems - Volume 2. NIPS''13, pp. 3111–3119. Curran Associates Inc., USA (2013).
    <http://dl.acm.org/citation.cfm?id=2999792.2999959>

    - <span id="page-21-9"></span>[25] Le, Q.V., Mikolov, T.: Distributed representations
    of sentences and documents. In: ICML. JMLR Workshop and Conference Proceedings,
    vol. 32, pp. 1188– 1196. JMLR.org, ??? (2014). [http://dblp.uni-trier.de/db/conf/icml/icml2014.](http://dblp.uni-trier.de/db/conf/icml/icml2014.html#LeM14)
    [html#LeM14](http://dblp.uni-trier.de/db/conf/icml/icml2014.html#LeM14)

    - <span id="page-21-10"></span>[26] Feng, Z., Guo, D., Tang, D., Duan, N., Feng,
    X., Gong, M., Shou, L., Qin, B., Liu, T., Jiang, D., et al.: Codebert: A pre-trained
    model for programming and


    natural languages. arXiv preprint arXiv:2002.08155 (2020)


    - <span id="page-22-0"></span>[27] Ganz, T., H¨arterich, M., Warnecke, A., Rieck,
    K.: Explaining graph neural networks for vulnerability discovery. In: Proceedings
    of the 14th ACM Workshop on Artificial Intelligence and Security, pp. 145–156
    (2021)

    - <span id="page-22-1"></span>[28] Hu, Y., Wang, S., Li, W., Peng, J., Wu, Y.,
    Zou, D., Jin, H.: Interpreters for gnn-based vulnerability detection: Are we there
    yet? In: Proceedings of the 32nd ACM SIGSOFT International Symposium on Software
    Testing and Analysis, pp. 1407–1419 (2023)

    - <span id="page-22-2"></span>[29] Li, Z., Zou, D., Xu, S., Ou, X., Jin, H., Wang,
    S., Deng, Z., Zhong, Y.: Vuldeepecker: A deep learning-based system for vulnerability
    detection. The Network and Distributed System Security Symposium (NDSS) (2018)

    - <span id="page-22-3"></span>[30] Li, Z., Zou, D., Xu, S., Jin, H., Zhu, Y.,
    Chen, Z.: Sysevr: A framework for using deep learning to detect software vulnerabilities.
    IEEE Transactions on Dependable and Secure Computing, 1–1 (2021) [https://doi.org/10.1109/TDSC.](https://doi.org/10.1109/TDSC.2021.3051525)
    [2021.3051525](https://doi.org/10.1109/TDSC.2021.3051525)

    - <span id="page-22-4"></span>[31] Weiser, M.: Program slicing. In: Proceedings
    of the 5th International Conference on Software Engineering. ICSE ''81, pp. 439–449.
    IEEE Press, ??? (1981)

    - <span id="page-22-5"></span>[32] Fan, J., Li, Y., Wang, S., Nguyen, T.N.: A
    c/c++ code vulnerability dataset with code changes and cve summaries. In: MSR
    ''20: 17th International Conference on Mining Software Repositories (2020)

    - <span id="page-22-6"></span>[33] Zheng, Y., Pujar, S., Lewis, B., Buratti, L.,
    Epstein, E., Yang, B., Laredo, J., Morari, A., Su, Z.: D2a: A dataset built for
    ai-based vulnerability detection methods using differential analysis. In: Proceedings
    of the ACM/IEEE 43rd International Conference on Software Engineering: Software
    Engineering in Practice. ICSE-SEIP ''21. Association for Computing Machinery,
    New York, NY, USA (2021)

    - <span id="page-22-7"></span>[34] Croft, R., Babar, M.A., Kholoosi, M.M.: Data
    quality for software vulnerability datasets. In: 2023 IEEE/ACM 45th International
    Conference on Software Engineering (ICSE), pp. 121–133 (2023). IEEE

    - <span id="page-22-8"></span>[35] Nie, X., Li, N., Wang, K., Wang, S., Luo, X.,
    Wang, H.: Understanding and tackling label errors in deep learning-based vulnerability
    detection (experience paper). In: Proceedings of the 32nd ACM SIGSOFT International
    Symposium on Software Testing and Analysis, pp. 52–63 (2023)

    - <span id="page-22-9"></span>[36] Software Assurance Reference Dataset. [https://samate.nist.gov/SARD/index.](https://samate.nist.gov/SARD/index.php)
    [php](https://samate.nist.gov/SARD/index.php) (2017)

    - <span id="page-23-0"></span>[37] Fey, M., Lenssen, J.E.: Fast graph representation
    learning with PyTorch Geometric. In: ICLR Workshop on Representation Learning
    on Graphs and Manifolds (2019)

    - <span id="page-23-1"></span>[38] Cheng, Xiao and Wang, Haoyu and Hua, Jiayi
    and Xu, Guoai and Sui, Yulei <https://github.com/jumormt/DeepWukong> (2021)

    - <span id="page-23-2"></span>[39] Yi Li, Shaohua Wang, Tien N. Nguyen [https://github.com/](https://github.com/vulnerabilitydetection/VulnerabilityDetectionResearch)
    [vulnerabilitydetection/VulnerabilityDetectionResearch](https://github.com/vulnerabilitydetection/VulnerabilityDetectionResearch)
    (2021)

    - <span id="page-23-3"></span>[40] Yaqin Zhou and Shangqing Liu and Jing Kai Siow
    and Xiaoning Du and Yang Liu <https://github.com/vulnerabilitydetection/VulnerabilityDetectionResearch>
    (2019)

    - <span id="page-23-4"></span>[41] Chakraborty, Saikat and Krishna, Rahul and
    Ding, Yangruibo and Ray, Baishakhi <https://github.com/VulDetProject/ReVeal> (2020)

    - <span id="page-23-5"></span>[42] Kingma, D.P., Ba, J.: Adam: A method for stochastic
    optimization. In: Bengio, Y., LeCun, Y. (eds.) 3rd International Conference on
    Learning Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015, Conference
    Track Proceedings (2015). <http://arxiv.org/abs/1412.6980>

    - <span id="page-23-6"></span>[43] Liu, M., Luo, Y., Wang, L., Xie, Y., Yuan,
    H., Gui, S., Yu, H., Xu, Z., Zhang, J., Liu, Y., Yan, K., Liu, H., Fu, C., Oztekin,
    B.M., Zhang, X., Ji, S.: DIG: A turnkey library for diving into graph deep learning
    research. Journal of Machine Learning Research 22(240), 1–9 (2021)

    - <span id="page-23-7"></span>[44] Zou, D., Zhu, Y., Jin, H., Ye, H., Zhu, Y.,
    Ye, H., Xu, S., Li, Z.: Interpreting deep learning-based vulnerability detector
    predictions based on heuristic searching. ACM Transactions on Software Engineering
    and Methodology 30 (2020) [https:](https://doi.org/10.1145/3429444) [//doi.org/10.1145/3429444](https://doi.org/10.1145/3429444)

    - <span id="page-23-8"></span>[45] Velikovi, P., Cucurull, G., Casanova, A., Romero,
    A., Lio, P., Bengio, Y.: Graph attention networks. arXiv preprint arXiv:1710.10903
    (2017)

    - <span id="page-23-9"></span>[46] Li, N., Wang, S., Feng, M., Wang, K., Wang,
    M., Wang, H.: Malwukong: Towards fast, accurate, and multilingual detection of
    malicious code poisoning in oss supply chains. In: 2023 38th IEEE/ACM International
    Conference on Automated Software Engineering (ASE), pp. 1993–2005 (2023). IEEE

    - <span id="page-23-10"></span>[47] Neuhaus, S., Zimmermann, T.: The beauty and
    the beast: Vulnerabilities in red hat''s packages. In: In Proceedings of the 2009
    USENIX Annual Technical Conference (USENIX ATC (2009)

    - [48] Grieco, G., Grinblat, G.L., Uzal, L., Rawat, S., Feist, J., Mounier, L.:
    Toward large-scale vulnerability discovery using machine learning. In: Proceedings
    of the Sixth ACM Conference on Data and Application Security and Privacy.


    CODASPY ''16, pp. 85–96. ACM, New York, NY, USA (2016). [https://doi.org/](https://doi.org/10.1145/2857705.2857720)
    [10.1145/2857705.2857720](https://doi.org/10.1145/2857705.2857720) . <http://doi.acm.org/10.1145/2857705.2857720>


    - <span id="page-24-0"></span>[49] Yan, H., Sui, Y., Chen, S., Xue, J.: Machine-learning-guided
    typestate analysis for static use-after-free detection. In: Proceedings of the
    33rd Annual Computer Security Applications Conference. ACSAC 2017, pp. 42–54.
    Association for Computing Machinery, New York, NY, USA (2017). [https://doi.org/10.1145/3134600.](https://doi.org/10.1145/3134600.3134620)
    [3134620](https://doi.org/10.1145/3134600.3134620) . <https://doi.org/10.1145/3134600.3134620>

    - <span id="page-24-1"></span>[50] Pradel, M., Sen, K.: Deepbugs: A learning approach
    to name-based bug detection. Proc. ACM Program. Lang. 2(OOPSLA), 147–114725 (2018)
    [https://doi.org/10.](https://doi.org/10.1145/3276517) [1145/3276517](https://doi.org/10.1145/3276517)

    - <span id="page-24-2"></span>[51] Cheng, X., Wang, H., Hua, J., Zhang, M., Xu,
    G., Yi, L., Sui, Y.: Static detection of control-flow-related vulnerabilities
    using graph embedding. In: 2019 24th International Conference on Engineering of
    Complex Computer Systems (ICECCS), pp. 41–50 (2019). <https://doi.org/10.1109/ICECCS.2019.00012>

    - <span id="page-24-3"></span>[52] Zou, D., Wang, S., Xu, S., Li, Z., Jin, H.:
    muvuldeepecker: A deep learning-based system for multiclass vulnerability detection.
    IEEE Transactions on Dependable and Secure Computing 18(5), 2224–2236 (2021) <https://doi.org/10.1109/TDSC.2019.2942930>

    - <span id="page-24-4"></span>[53] Zhang, H., Luo, J., Hu, M., Yan, J., Zhang,
    J., Qiu, Z.: Detecting exception handling bugs in c++ programs. In: 2023 IEEE/ACM
    45th International Conference on Software Engineering (ICSE), pp. 1084–1095 (2023).
    IEEE

    - <span id="page-24-5"></span>[54] Yuan, B., Lu, Y., Fang, Y., Wu, Y., Zou, D.,
    Li, Z., Li, Z., Jin, H.: Enhancing deep learning-based vulnerability detection
    by building behavior graph model. In: 2023 IEEE/ACM 45th International Conference
    on Software Engineering (ICSE), pp. 2262–2274 (2023). IEEE

    - <span id="page-24-6"></span>[55] Li, Z., Zou, D., Xu, S., Chen, Z., Zhu, Y.,
    Jin, H.: Vuldeelocator: A deep learningbased fine-grained vulnerability detector.
    IEEE Transactions on Dependable and Secure Computing PP, 1–1 (2021) <https://doi.org/10.1109/TDSC.2021.3076142>

    - <span id="page-24-7"></span>[56] Kamiya, T., Kusumoto, S., Inoue, K.: Ccfinder:
    a multilinguistic token-based code clone detection system for large scale source
    code. IEEE Transactions on Software Engineering 28(7), 654–670 (2002) <https://doi.org/10.1109/tse.2002.1019480>

    - [57] Li, Z., Lu, S., Myagmar, S., Zhou, Y.: Cp-miner: finding copy-paste and
    related bugs in large-scale software code. IEEE Transactions on Software Engineering
    32(3), 176–192 (2006) <https://doi.org/10.1109/TSE.2006.28>

    - [58] Sajnani, H., Lopes, C.: A parallel and efficient approach to large scale
    clone detection. In: 2013 7th International Workshop on Software Clones (IWSC),
    pp. 46–52 (2013). <https://doi.org/10.1109/IWSC.2013.6613042>


    - <span id="page-25-0"></span>[59] Sajnani, H., Saini, V., Svajlenko, J., Roy,
    C.K., Lopes, C.V.: Sourcerercc: Scaling code clone detection to big-code. In:
    Proceedings of the 38th International Conference on Software Engineering. ICSE
    ''16, pp. 1157–1168. ACM, New York, NY, USA (2016). <https://doi.org/10.1145/2884781.2884877>
    . [http://doi.acm.org/10.](http://doi.acm.org/10.1145/2884781.2884877) [1145/2884781.2884877](http://doi.acm.org/10.1145/2884781.2884877)

    - <span id="page-25-1"></span>[60] Zhang, J., Wang, X., Zhang, H., Sun, H., Wang,
    K., Liu, X.: A novel neural source code representation based on abstract syntax
    tree. In: Proceedings of the 41st International Conference on Software Engineering.
    ICSE ''19, pp. 783–794. IEEE Press, Piscataway, NJ, USA (2019). <https://doi.org/10.1109/ICSE.2019.00086>
    . <https://doi.org/10.1109/ICSE.2019.00086>

    - [61] Wang, S., Liu, T., Tan, L.: Automatically learning semantic features for
    defect prediction. In: Proceedings of the 38th International Conference on Software
    Engineering. ICSE ''16, pp. 297–308. ACM, New York, NY, USA (2016). [https://doi.](https://doi.org/10.1145/2884781.2884804)
    [org/10.1145/2884781.2884804](https://doi.org/10.1145/2884781.2884804) . <http://doi.acm.org/10.1145/2884781.2884804>

    - [62] Alon, U., Zilberstein, M., Levy, O., Yahav, E.: Code2vec: Learning distributed
    representations of code. Proc. ACM Program. Lang. 3(POPL), 40–14029 (2019) <https://doi.org/10.1145/3290353>

    - <span id="page-25-2"></span>[63] Allamanis, M., Brockschmidt, M., Khademi, M.:
    Learning to represent programs with graphs. CoRR abs/1711.00740 (2017) [arXiv:1711.00740](https://arxiv.org/abs/1711.00740)

    - <span id="page-25-3"></span>[64] Chen, K., Liu, P., Zhang, Y.: Achieving accuracy
    and scalability simultaneously in detecting application clones on android markets.
    In: Proceedings of the 36th International Conference on Software Engineering.
    ICSE 2014, pp. 175–186. ACM, New York, NY, USA (2014). <https://doi.org/10.1145/2568225.2568286>
    . <http://doi.acm.org/10.1145/2568225.2568286>

    - [65] Gabel, M., Jiang, L., Su, Z.: Scalable detection of semantic clones. In:
    Proceedings of the 30th International Conference on Software Engineering. ICSE
    ''08, pp. 321–330. ACM, New York, NY, USA (2008). [https://doi.org/10.1145/1368088.](https://doi.org/10.1145/1368088.1368132)
    [1368132](https://doi.org/10.1145/1368088.1368132) . <http://doi.acm.org/10.1145/1368088.1368132>

    - [66] Komondoor, R., Horwitz, S.: Using slicing to identify duplication in source
    code. In: Cousot, P. (ed.) Static Analysis, pp. 40–56. Springer, Berlin, Heidelberg
    (2001)

    - [67] Krinke, J.: Identifying similar code with program dependence graphs. In:
    Proceedings of the Eighth Working Conference on Reverse Engineering (WCRE''01).
    WCRE ''01, p. 301. IEEE Computer Society, Washington, DC, USA (2001). <http://dl.acm.org/citation.cfm?id=832308.837142>

    - [68] Liu, C., Chen, F., Han, J., Yu, P.: Gplag: Detection of software plagiarism
    by program dependence graph analysis. In: Proceedings of the 12th ACM SIGKDD International
    Conference on Knowledge Discovery and Data Mining, vol. 2006, pp. 872–881 (2006).
    <https://doi.org/10.1145/1150402.1150522>


    <span id="page-26-0"></span>[69] Sui, Y., Cheng, X., Zhang, G., Wang, H.: Flow2vec:
    Value-flow-based precise code embedding. Proc. ACM Program. Lang. 4(OOPSLA) (2020)
    [https://doi.org/10.](https://doi.org/10.1145/3428301) [1145/3428301](https://doi.org/10.1145/3428301)'
- title: "\"My GitHub Sponsors profile is live!\" Investigating the Impact of\n  Twitter/X\
    \ Mentions on GitHub Sponsors"
  abstract: 'GitHub Sponsors was launched in 2019, enabling donations to open-source

    software developers to provide financial support, as per GitHub''s slogan:

    "Invest in the projects you depend on". However, a 2022 study on GitHub

    Sponsors found that only two-fifths of developers who were seeking sponsorship

    received a donation. The study found that, other than internal actions (such as

    offering perks to sponsors), developers had advertised their GitHub Sponsors

    profiles on social media, such as Twitter (also known as X). Therefore, in this

    work, we investigate the impact of tweets that contain links to GitHub Sponsors

    profiles on sponsorship, as well as their reception on Twitter/X. We further

    characterize these tweets to understand their context and find that (1) such

    tweets have the impact of increasing the number of sponsors acquired, (2)

    compared to other donation platforms such as Open Collective and Patreon,

    GitHub Sponsors has significantly fewer interactions but is more visible on

    Twitter/X, and (3) developers tend to contribute more to open-source software

    during the week of posting such tweets. Our findings are the first step toward

    investigating the impact of social media on obtaining funding to sustain

    open-source software.'
  url: http://arxiv.org/abs/2401.02755v1
  keywords: ''
  document: '# "My GitHub Sponsors profile is live!" Investigating the Impact of Twitter/X
    Mentions on GitHub Sponsors


    Youmei Fan Nara Institute of Science and Technology, Japan fan.youmei.fs2@is.naist.jp


    Tao Xiao Nara Institute of Science and Technology, Japan tao.xiao.ts2@is.naist.jp


    Christoph Treude University of Melbourne Australia christoph.treude@unimelb.edu.au


    Kenichi Matsumoto Nara Institute of Science and Technology, Japan matumoto@is.naist.jp


    Lisbon, Portugal. ACM, New York, NY, USA, [12](#page-11-0) pages. [https://doi.org/10.](https://doi.org/10.1145/3597503.3639127)
    [1145/3597503.3639127](https://doi.org/10.1145/3597503.3639127)


    Hideaki Hata Shinshu University Japan hata@shinshu-u.ac.jp


    # ABSTRACT


    GitHub Sponsors was launched in 2019, enabling donations to opensource software
    developers to provide financial support, as per GitHub''s slogan: "Invest in the
    projects you depend on". However, a 2022 study on GitHub Sponsors found that only
    two-fifths of developers who were seeking sponsorship received a donation. The
    study found that, other than internal actions (such as offering perks to sponsors),
    developers had advertised their GitHub Sponsors profiles on social media, such
    as Twitter (also known as X). Therefore, in this work, we investigate the impact
    of tweets that contain links to GitHub Sponsors profiles on sponsorship, as well
    as their reception on Twitter/X. We further characterize these tweets to understand
    their context and find that (1) such tweets have the impact of increasing the
    number of sponsors acquired, (2) compared to other donation platforms such as
    Open Collective and Patreon, GitHub Sponsors has significantly fewer interactions
    but is more visible on Twitter/X, and (3) developers tend to contribute more to
    open-source software during the week of posting such tweets. Our findings are
    the first step toward investigating the impact of social media on obtaining funding
    to sustain open-source software.


    ### CCS CONCEPTS


    • Social and professional topics → Sustainability; • Software and its engineering
    → Open source model.


    ### KEYWORDS


    Open-source Software, Sponsorship, Social Media


    #### ACM Reference Format:


    Youmei Fan, Tao Xiao, Hideaki Hata, Christoph Treude, and Kenichi Matsumoto. 2024.
    "My GitHub Sponsors profile is live!" Investigating the Impact of Twitter/X Mentions
    on GitHub Sponsors. In 2024 IEEE/ACM 46th International Conference on Software
    Engineering (ICSE ''24), April 14–20, 2024,


    ICSE ''24, April 14–20, 2024, Lisbon, Portugal


    © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
    ACM ISBN 979-8-4007-0217-4/24/04. . . \$15.00 <https://doi.org/10.1145/3597503.3639127>


    ### 1 INTRODUCTION


    Open-source software (OSS) is ubiquitous, but sustaining it is a challenge [\[28\]](#page-11-1).
    Maintaining an OSS project requires not only intrinsic motivation (e.g., joy of
    participation) but also extrinsic motivation (e.g., financial incentives) [\[49\]](#page-11-2).
    The last few years have seen the emergence of many platforms that allow open-source
    developers to receive donations for their work, such as PayPal [\[30\]](#page-11-3),
    Open Collective [\[11\]](#page-11-4), Patreon [\[29\]](#page-11-5), and GitHub
    Sponsors [\[37\]](#page-11-6). Several platforms support sponsoring OSS projects
    in cryptocurrencies, with the rise in popularity of cryptocurrencies today, e.g.,
    Gitcoin Grants [\[16\]](#page-11-7) and Giveth [\[20\]](#page-11-8). However,
    as Overney et al.''s paper title "How to not get rich: an empirical study of donations
    in open source" [\[28\]](#page-11-1) suggests, simply having a platform for donations
    is not enough. In a 2022 study on GitHub Sponsors, Shimada et al. [\[35\]](#page-11-9)
    found that out of approximately 9,000 developers who had activated their GitHub
    Sponsors profile, less than 40% had received a donation.


    If simply creating a sponsorship profile is not enough, what else can open-source
    software developers do to attract donations? Following the long line of work on
    studying the intersection between social media and software development [\[15,](#page-11-10)
    [38,](#page-11-11) [39\]](#page-11-12), in this paper, we investigate the impact
    of tweeting about a GitHub Sponsors profile on sponsorship. To make it easy for
    its users to reach a large audience, GitHub provides tweet templates that users
    can use to advertise a new GitHub Sponsors profile ("My GitHub Sponsors profile
    is live! You can sponsor me to support my open source work ") or to broadcast
    that they made a donation (" I''m sponsoring [username] because..."). The impact
    of tweets on open-source software development has been investigated before. Fang
    et al. [\[15\]](#page-11-10) found that tweets have a significant effect on obtaining
    new stars and new contributors for an open-source project and that the formation
    of an active Twitter/X community plays an important role in attracting new contributors.
    The role of tweets has also been studied in the context of bug fixing [\[24\]](#page-11-13)
    and trend awareness [\[36\]](#page-11-14). To the best of our knowledge, the role
    of Twitter/X in obtaining funding for open-source development has not yet been
    studied.


    We first characterize the state of the practice by quantitatively and qualitatively
    analyzing more than 10,000 tweets linking to GitHub Sponsors profiles to understand
    the context of such tweets.


    Permission to make digital or hard copies of all or part of this work for personal
    or classroom use is granted without fee provided that copies are not made or distributed
    for profit or commercial advantage and that copies bear this notice and the full
    citation on the first page. Copyrights for components of this work owned by others
    than the author(s) must be honored. Abstracting with credit is permitted. To copy
    otherwise, or republish, to post on servers or to redistribute to lists, requires
    prior specific permission and/or a fee. Request permissions from permissions@acm.org.


    We then measure the impact of the tweets in terms of their reception on Twitter/X
    and their effect on sponsorship. We found links to GitHub Sponsors profiles on
    Twitter/X are common and the majority of such tweets are written by users other
    than the profile owner, such as a sponsor. We identified a significant positive
    effect of GitHub Sponsor profile mentions in tweets on the number of sponsors
    acquired. Tweet mentions have the impact of increasing the number of sponsors
    by 1.22. Although GitHub Sponsors has surpassed other platforms such as Open Collective
    and Patreon in terms of visibility on Twitter/X, tweets about GitHub Sponsors
    received significantly fewer likes, retweets, and replies compared to other platforms.
    Developers tended to be more active during the week of a tweet, in particular,
    in terms of the number of commits.


    Significance of research contribution. The findings of our study have significant
    implications, indicating a strong interconnection between social media channels
    and donation pathways within the social programmer ecosystem [\[42\]](#page-11-15).
    Our research demonstrates that actively engaging on social media platforms to
    promote sponsorship opportunities for open-source development can yield fruitful
    outcomes. This suggests that open-source developers stand to benefit from expanding
    their presence and networking efforts beyond the GitHub platform. Furthermore,
    our study highlights the notion that publicity and visibility in the realm of
    open-source sponsorship need not be limited to a unidirectional flow. Rather,
    sponsors themselves have the potential to enhance the exposure and reach of open-source
    projects by publicizing their donations. In doing so, they serve as exemplars,
    setting a positive precedent and inspiring others to follow suit. By emphasizing
    these key findings, we provide compelling evidence to support the notion that
    using social media channels, diversifying online networks, and fostering mutual
    publicity between sponsors and developers can yield substantial advantages within
    the open-source community. These insights encourage open-source developers and
    sponsors alike to consider the broader potential of social media engagement and
    collaborative promotion to achieve their goals.


    #### 2 RESEARCH QUESTIONS


    The main objective of our study is to understand the state of practice and the
    impact of GitHub Sponsors profile mentions on Twitter/X. The insights drawn from
    this study will not only contribute to the academic understanding but also have
    practical implications for developers, sponsors, and platforms like GitHub. Furthermore,
    our findings can shed light on the relationship between social activities and
    monetary contributions, ultimately serving to augment the appeal of developers.
    To guide our investigation, we present main questions and sub-questions, along
    with motivations and relevance. RQ1: How are GitHub Sponsors profiles discussed
    on Twitter/X? The motivation behind RQ1 is to provide insights into the dynamics
    of GitHub Sponsors profile mentions, ultimately informing better strategies for
    developers seeking sponsorship.


    RQ1.1 What are the characteristics of tweets mentioning GitHub Sponsors profiles
    from organizational and personal accounts? Understanding the language, account
    types, and programming languages in these tweets will enable developers to craft
    more appealing content for potential sponsors, ultimately enhancing engagement.


    RQ1.2 Who mentions GitHub Sponsors profiles on Twitter/X? By


    identifying who engages with these profiles, sponsorship acquisition strategies
    can be tailored to target specific demographics.


    RQ1.3 What is the context of GitHub Sponsors profile mentions on Twitter/X? Investigating
    the context in which profiles are mentioned will shed light on why tweets are
    used in sponsorship communication, potentially informing strategies for developers
    seeking sponsorship.


    RQ1.4 When are GitHub Sponsors profiles mentioned on Twitter/X? Analyzing the
    timing of mentions can lead to the discovery of optimal moments for posting, which
    could help in securing sponsorship.


    RQ2: What is the impact of GitHub Sponsors profile mentions on Twitter/X? Building
    on RQ1, RQ2 explores the effects of the dynamics uncovered, allowing us to measure
    and interpret their impact.


    RQ2.1 How are GitHub Sponsors profile mentions received on Twitter/X? Understanding
    the reception will aid platforms like GitHub in providing targeted support and
    tools to developers, such as social media templates and guidelines.


    RQ2.2 How are GitHub Sponsors profile mentions discussed on Twitter/X? By examining
    engagement metrics and replies, we will gain a deeper understanding of the conversations,
    ultimately helping in crafting more effective strategies for community engagement.


    RQ2.3 How do GitHub Sponsors profile mentions impact sponsorship? Through a quasi-experimental
    approach, our goal is to provide quantitative evidence of the causal impact, which
    can guide both developers in improving their social media strategies and platforms
    in enhancing features that facilitate sponsorship acquisition.


    By addressing these research questions, we aim to provide insights into the dynamics
    and consequences of GitHub Sponsors mentions on Twitter/X. This exploration contributes
    to theoretical understanding and practical strategies, offering value to the broader
    Open Source community.


    #### 3 RESEARCH METHODS


    This section describes our methods for data collection and our quantitative and
    qualitative analyses.


    #### 3.1 Data Collection


    In this study, we examine tweets containing links to GitHub Sponsors profiles.
    We successfully applied for Twitter/X''s Academic Research Access [\[45\]](#page-11-16),
    which offers a higher limit on the number of tweets that can be retrieved per
    month, and we analyzed tweets from May 2019, when GitHub Sponsors was launched,
    through April 2022, using Twitter/X API v2 [\[44\]](#page-11-17) in May 2022.
    The Twitter/X API provides a search function that allows for a set of query mechanisms
    against tweets. We use the "url" query to retrieve tweets that contain links with
    the specific substring "github.com/ sponsors/" so that we ensure all the tweets
    are developer-related. We obtained 11,582 tweets that contain GitHub Sponsors
    profile links. Among these tweets, the majority (91%) were written in English,
    accounting for 10,531 tweets. We only use English tweets for the following quantitative
    and qualitative analyses, except RQ1.1.


    #### <span id="page-1-0"></span>3.2 Quantitative Analysis


    To understand the characteristics of tweets mentioning GitHub Sponsors profiles
    (RQ1.1), we investigate written languages, types of GitHub accounts, and primary
    programming languages of developers mentioned in the tweets. For written languages,
    we calculate the distribution of languages in tweets. In cases where Twitter/X
    cannot determine the language of a tweet (e.g., the tweet only contains hashtags,
    emojis, or links), Undetermined is used.


    Since one GitHub Sponsors profile may appear in different tweets, we obtained
    distinct GitHub Sponsors profiles in tweets to collect the types of GitHub accounts
    and the primary programming languages of the corresponding developers. We obtained
    3,766 distinct GitHub Sponsors profiles from the 11,582 tweets. For the types
    of GitHub accounts, we calculate the distribution of the types of GitHub accounts
    (i.e., personal or organizational) across all distinct GitHub Sponsors profiles
    in tweets. Since the URL of a GitHub Sponsors profile is organized as https://github.com/sponsors/
    [username], we can retrieve the corresponding GitHub account using username in
    the GitHub GraphQL API [\[19\]](#page-11-18).


    The primary programming languages of the repositories can also be retrieved using
    the GitHub GraphQL API. Same to the previous work [\[35\]](#page-11-9), we take
    the most common primary language of the repositories to which each developer contributed
    as the primary language of that developer. This is an approximation because we
    did not analyze whether the developer actually committed in that language. If
    the occurrences of each programming language per repository are the same, we consider
    the primary programming language to be Undetermined. The primary languages of
    developers identified in this way can be interpreted as the programming languages
    of the ecosystems to which the developers mainly contributed.


    To attract potential sponsors, developers might be particularly active on GitHub
    around the time they advertise their GitHub Sponsors profile on Twitter/X. To
    investigate whether such correlations exist, we considered three time periods
    related to a "My GitHub Sponsors profile is live!" tweet, i.e., a week before
    posting this tweet, the week in which the tweet was posted, and a week after posting
    this tweet (RQ1.4). For example, if a tweet has been posted on 15 June 2020, these
    three periods will be from 2020-06-05 to 2020-06-11, 2020-06-12 to 2020-06-18,
    and 2020-06-19 to 2020-06-25, respectively. Following the approach of related
    work [\[10\]](#page-11-19), which used a time frame of one week before and after,
    our decision to adopt a one-week duration allows us to quickly assess immediate
    changes in productivity, engagement, and quality. This analysis involves scrutinizing
    short-term developer activities before and after sponsorship, facilitating a timely
    evaluation. We obtained 810 distinct GitHub Sponsors profiles that were posted
    using that template from our data set. Then we investigate different categories
    of contribution activities in each period, as shown below. To collect these contribution
    activities in a week, we retrieve them from the profile pages of the GitHub accounts
    as https://github.com/[username] ?tab=overview& from=[time period]&to=[time period].


    - opening pull request: The profile page indicates that the GitHub account has
    opened pull requests, including substrings such as "Created a pull request", "Opened
    1 other pull request", "Opened [number] pull requests", and "Opened their first
    pull request".

    - submitting pull request review: The profile page indicates that the GitHub account
    has reviewed pull requests, including a substring such as "Reviewed [number] pull
    requests".

    - opening issue: The profile page indicates that the GitHub account has opened
    issues, including substrings such as "Created an issue", "Opened [number] other
    issues", "Opened their first issue", and "Opened [number] issues".

    - opening discussion: The profile page indicates that the GitHub account started
    a GitHub Discussion, including a substring such as "Started [number] discussions".

    - answering discussion: The profile page indicates that the GitHub account answered
    a GitHub Discussion, including a substring such as "Answered [number] discussions".

    - committing: The profile page indicates that the GitHub account has authored
    commits, including a substring such as "Created [number] commits".

    - contributing in private repository: The profile page indicates that the GitHub
    account contributed to private repositories, including a substring such as "[number]
    contributions in private repositories".

    - creating repository: The profile page indicates that the GitHub account created
    private repositories, including substrings such as "Created [number] other repositories",
    "Created [number] repositories", and "Created their first repository".

    - joining organization: The profile page indicates that the GitHub account joined
    an organization, including a substring such as "Joined the [name] organization".


    We conduct Mann-Whitney U tests to compare activities in these three periods,
    i.e., between a week before posting the tweet and the week when the tweet was
    posted, and between the week when the tweet was posted and a week after posting
    this tweet. To estimate the effect size of significant differences, we use Cliff''s
    delta with the following thresholds [\[34\]](#page-11-20): negligible for 0 ≤
    |delta| < 0.147, small for 0.147 ≤ |delta| < 0.33, medium for 0.33 ≤ |delta| <
    0.474, and large otherwise.


    To investigate the reception of tweets mentioning GitHub Sponsors profiles (RQ2.1),
    we analyze the popularity of tweets that mentioned GitHub Sponsors profiles on
    Twitter/X (number of likes, number of retweets, and number of replies). Then,
    we compare these interactions to tweets that contain links to other donation and
    crowd-funding platforms that are often used to obtain financial support for OSS
    development [\[28\]](#page-11-1): PayPal, Open Collective, and Patreon. To ensure
    that the tweets obtained are related to OSS, we collect tweets that contain links
    to at least one of these three platforms and GitHub (i.e., "github.com", except
    links to GitHub Sponsors) using Twitter/X API v2 in the same time period for which
    we collected GitHub Sponsors profile tweets. We consider a link to point to a
    PayPal profile when it contains "paypal.com/paypalme/", Open Collective when it
    contains "opencollective.com/", and Patreon when it contains "patreon.com/", except
    Patreon posts (i.e., "patreon.com/posts/"). We exclude tweets that contain links
    to "github.com/sponsors/" and at least one of these three platforms from the 10,531
    English tweets obtained. In the end, we obtained 10,440 tweets for GitHub Sponsors,
    four tweets for PayPal, 88 tweets for Open Collective, and 228 tweets for Patreon.
    Since only four tweets contain links to PayPal, we focus on comparisons between
    GitHub Sponsors, Open Collective, and Patreon.


    We also conduct Mann-Whitney U tests to compare Twitter/X interactions between
    GitHub Sponsors and Open Collective, and ICSE ''24, April 14–20, 2024, Lisbon,
    Portugal Youmei Fan, Tao Xiao, Hideaki Hata, Christoph Treude, and Kenichi Matsumoto


    between GitHub Sponsors and Patreon. We use Cliff''s delta with the same thresholds
    to estimate the effect size of significant differences.


    #### <span id="page-3-0"></span>3.3 Qualitative Analysis


    For our qualitative analyses, we randomly selected a statistically representative
    number of tweets with a confidence level of 95% and a confidence interval of 5
    to obtain 371 tweets from the initial population of 10,531 English-language tweets.


    Unsurprisingly, our initial analysis revealed differences between the dynamics
    around tweets from users looking for sponsorship and those from users who made
    donations. Therefore, we categorized the 371 tweets into three different behavioral
    groups based on the purpose of the tweet, so we could see what kind of tweets
    a user would make based on their behavior:


    - looking for sponsors: This tweet is posted by developers who publicized their
    profiles to look for sponsors, e.g.,"My GitHub Sponsors profile is live! You can
    sponsor me to support my open source work ".

    - sponsors: This tweet is posted by developers who sponsored others, e.g., " I''m
    sponsoring [username] because...".

    - no purpose: This tweet does not have sufficient information to decide, e.g.,
    "You guys make magic.".


    In the end, we identified 183 tweets from developers that were looking for sponsors,
    168 tweets from sponsors, and 20 tweets from no purpose. These 351 tweets (20
    tweets from no purpose are excluded) are used for answering RQ1.2–RQ1.4, and RQ2.2.


    Four of the authors collaboratively took an initial look at a randomly selected
    subset of 30 tweets from the sample of 351 tweets, discussed which themes were
    present in the data and how these themes related to the research questions, and
    then formalized this discussion into coding schemata. For each aspect that entailed
    manual coding, a total of 30 tweets were independently labeled by four annotators,
    resulting in Cohen''s kappa exceeding 0.6 for all parts and even reaching 0.94
    for RQ2.2.


    Encouraged by the initial kappa agreements, the first two authors independently
    coded the remaining sample of 321 tweets. Then, they recalculated kappa agreements
    to assess the improvement in understanding of the coding schemata after labeling
    the first 30 tweets. Finally, four authors engaged in collaborative discussions
    to attain a consensus in cases of disagreement. We attribute this stability to
    the fact that we had an initial discussion about all data, that tweets are relatively
    short, and that this particular team of authors has experience working together
    on qualitative data analysis from previous research projects. We describe the
    coding schemata related to each research question in the following paragraphs.


    To investigate who mentions GitHub Sponsors profiles on Twitter/X (RQ1.2), we
    analyze the relationship between the authors of the tweets and the GitHub accounts
    that are linked in the tweets. Furthermore, the rationale behind having a "user"
    category in the aforementioned code is rooted in the goal of acquiring insights
    into what extent users benefit from a developer''s project and are willing to
    voluntarily advertise the developer, thereby enabling the developer to obtain
    more sponsorship. The prevalence of the code "non-specific" in the results indicates
    that some users advertise for others without a specific purpose. Since the names
    of accounts on Twitter/X and GitHub do not necessarily have to be the same, we


    employed qualitative analysis for this investigation. It is important to highlight
    that our decision not to employ automated techniques for verifying the association
    between Twitter/X and GitHub accounts was motivated by the realization that these
    techniques often fail to account for certain scenarios. For example, when a GitHub
    account is classified as an organization type and one of its members posts a tweet,
    it should be regarded as emanating from the same user. Consequently, we opt for
    a cautious approach, acknowledging the limitations of automated techniques and
    acknowledging the need for context-sensitive judgment in determining the correspondence
    between Twitter/X and GitHub accounts. The four annotators independently labeled
    30 tweets. Then, we calculate the kappa agreement of our coding schemata from
    four annotators. The initial Cohen''s kappa for this qualitative analysis is 0.75,
    which indicates ''substantial'' agreement [\[46\]](#page-11-21). For the remaining
    sample of 321 tweets, Cohen''s kappa is 0.78, which also indicates ''substantial''
    agreement, from the first two authors. Examples of the following codes are covered
    in our replication package, aiming to facilitate the reader''s comprehension of
    this taxonomy.


    - same: The author of this tweet is the same as the GitHub account that is shown
    on the GitHub Sponsors profile linked in the tweet, or the content of the tweet
    implies that they are the same developer or the author belongs to the GitHub organizational
    account on that GitHub Sponsors profile.

    - user: The tweet explicitly indicates that the author of this tweet is a user
    of an open-source project that belongs to the GitHub account on the GitHub Sponsors
    profile.

    - non-specific: There is not sufficient information to determine the relationship
    between the tweet author and the GitHub account.


    To understand the context of tweets mentioning GitHub Sponsors profiles (RQ1.3),
    we analyze why GitHub Sponsors profiles were mentioned in tweets. Additionally,
    the reason to distinguish between the "advertisement with new information" and
    "advertisement with new functionality" categories in the aforementioned coding
    schemata is to enable a more nuanced analysis: the former encompasses a range
    of updates, including changes to users'' profile descriptions and tier information
    whereas the latter is related to functionality in the projects they are dedicated
    to. The four annotators independently coded 30 tweets, achieving the initial Cohen''s
    kappa of 0.66 or ''substantial'' agreement [\[46\]](#page-11-21). The first two
    authors then independently labeled the remaining sample of 321 tweets, finally
    reaching Cohen''s kappa of 0.84 or ''almost perfect'' agreement. The following
    list shows the coding schema that emerged from the data. Examples of the following
    codes are described in detail in our replication package to help the reader understand
    this taxonomy.


    - generic advertisement: This tweet advertises the tweet author''s own GitHub
    Sponsors profile (use this code if the tweet does not fit the other advertisement
    categories).

    - donation appreciation: This tweet explicitly expresses appreciation of a donation.

    - sponsor template: This tweet contains GitHub''s template for advertising one''s
    own GitHub Sponsors profile: "My GitHub Sponsors profile is live! You can sponsor
    me to support my open source work " with no or minor changes.

    - advertisement of developer: This tweet advertises the GitHub Sponsors profile
    of another personal GitHub account.

    - advertisement with new functionality: This tweet explicitly advertises the author''s
    own GitHub Sponsors profile while mentioning new functionality of an open-source
    project.

    - advertisement with new information: This tweet explicitly advertises the author''s
    own GitHub Sponsors profile with an update.

    - sustainability: This tweet explicitly indicates an appreciation or need for
    a donation for the sustainability of an open-source project, often associated
    with terms such as "sustainable".

    - advertisement with early access: This tweet explicitly advertises the author''s
    own GitHub Sponsors profile with early access to features (usually accompanied
    by a phrase such as "early access" and "insider")

    - income: This tweet explicitly indicates the need for income to support one''s
    daily life.

    - advertisement with event: This tweet explicitly advertises a GitHub Sponsors
    profile with an event.

    - set example / peer pressure: This tweet explicitly motivates others in either
    a positive or negative way.

    - advertisement of organization: This tweet advertises the GitHub Sponsors profile
    of another organizational GitHub account.

    - donation to developer announcement: This tweet explicitly indicates that the
    author of this tweet donated to the personal GitHub account in the GitHub Sponsors
    profile.

    - donation to organization announcement: This tweet explicitly indicates that
    the author of this tweet donated to the organizational GitHub account in the GitHub
    Sponsors profile.

    - donation to developer template: This tweet contains GitHub''s template that
    indicates donation to a personal GitHub account: " I''m sponsoring [username]
    because..." with no or minor changes.

    - donation to organization template: This tweet contains GitHub''s template that
    indicates donation to an organizational GitHub account: " I''m sponsoring [username]
    because..." with no or minor changes.


    To study when tweets related to GitHub Sponsors profiles occur in relation to
    other activities on GitHub (RQ1.4), we analyze the timing of such tweets. The
    four annotators independently coded 30 tweets, achieving the initial Cohen''s
    kappa of 0.62 or ''substantial'' agreement [\[46\]](#page-11-21). For the remaining
    321 tweets, the first two authors reached Cohen''s kappa of 0.85 or ''almost perfect''
    agreement. The following list shows the coding schemata that emerged from the
    data.


    - start: This tweet was posted when the GitHub Sponsors profile is activated (usually
    accompanied by a phrase like "profile is live").

    - no specific timing: This tweet was posted with no particular timing.

    - donation: This tweet was posted when the author of the tweet received a donation.

    - update: This tweet was posted when there was an update to a GitHub project or
    GitHub Sponsors profile.

    - reach goal: This tweet was posted in relation to reaching a goal.

    - release: This tweet explicitly indicates that a release of the software project
    has been delivered.

    - event: This tweet was posted when an event has been announced.

    - resignation / paycut: This tweet was posted during a change in the author''s
    work professional situation.

    - benefit: This tweet explicitly mentions a particular benefit.

    - activity spike: This tweet was posted to indicate the GitHub developer was particularly
    active and explicitly mentions the activity spike.


    To investigate the responses to tweets mentioning GitHub Sponsors profiles (RQ2.2),
    we analyze the replies to tweets mentioning GitHub Sponsors profiles. Four annotators
    independently annotated 30 tweets. The initial kappa agreement is 0.94, interpreted
    as ''almost perfect'' agreement [\[46\]](#page-11-21). The first two authors independently
    annotated the remaining 321 tweets, reaching the same kappa agreement. Our coding
    schemata emerged from the data and is as follows. Note that examples for these
    codes are described in detail in our replication package to help the reader understand
    this taxonomy.


    - support: The response to this tweet demonstrates endorsement or encouragement
    for the author, often extending beyond appreciation and indicating a willingness
    to assist or advocate for the author''s cause.

    - appreciation of work: The respondent acknowledges and values the author''s open-source
    contributions and their impact, without necessarily conveying explicit support
    or a commitment to assist in further efforts.

    - appreciation of donation: The respondent to this tweet appreciates the donation.

    - emoji only: The response to this tweet only contains emoji.

    - other: The response to this tweet does not fit into the categories above, or
    there is no response to this tweet.


    #### 3.4 Causal Inference


    We conduct a quasi-experiment to estimate the causal impact of GitHub Sponsors
    profile mentions in tweets on the number of sponsors acquired (RQ2.3). Unlike
    prior studies that have conducted quasi-experiments for causal inference in software
    engineering by employing difference-in-differences [\[15,](#page-11-10) [26,](#page-11-22)
    [47\]](#page-11-23) or CausalImpact [\[25\]](#page-11-24), we are unable to employ
    these methods. This is because these methods require the values of the outcome
    variables in the periods before and after the treatment, but data on the number
    of sponsors at a given point in time were not available at the time we conducted
    our analysis.[1](#page-4-0) Therefore, in this analysis, we apply a statistical
    matching method called propensity score matching (PSM), which attempts to estimate
    the effect of treatment by constructing a control group by matching each treated
    unit with a non-treated unit with similar characteristics [\[22\]](#page-11-25).
    PSM predicts the probability of belonging to


    <span id="page-4-0"></span><sup>1</sup>We contacted the GitHub team in a public
    forum and they responded that they would consider making the sponsor count data
    publicly available; we do not provide a link to that form because of the double-anonymous
    submission.


    ICSE ''24, April 14–20, 2024, Lisbon, Portugal Youmei Fan, Tao Xiao, Hideaki Hata,
    Christoph Treude, and Kenichi Matsumoto


    the treatment and control groups based on observed predictors. Some of the studies
    mentioned above used PSM to prepare data for the treatment and control groups
    [\[15,](#page-11-10) [26\]](#page-11-22).


    To collect developers as potential members of a control group, we contacted the
    authors of previous work [\[35\]](#page-11-9) to obtain the list of GitHub users
    who had participated in GitHub Sponsors. From 3,697 sponsored and 5,666 non-sponsored
    developers collected in July 2021 for the previous study, we identified 1,930
    and 4,913 developers who had not deleted their GitHub accounts and whose GitHub
    Sponsors profiles do not appear in our tweet data (neither in their own tweets
    nor in tweets from others). Potential members of the treatment group are developers
    whose GitHub Sponsors profiles appear in the "sponsor template" tweets, that is,
    "My GitHub Sponsors profile is live!". By targeting only "sponsor templates",
    the influence of wording differences can be eliminated. We observed that "sponsor
    template" appears most often after "sponsor template", which are free-text tweets
    (see Section [4.1.3\)](#page-6-0). To limit developers to those who started using
    GitHub Sponsors at the same period as control group developers, we collected only
    those developers whose GitHub Sponsors profiles appeared in such tweets by July
    2021 and identified 568 developers.


    The following are variables of developers used in the logistic regression to estimate
    the propensity score for PSM.


    These variables have been used in previous related studies: for example, sponsored
    developers sponsor more than non-sponsored developers [\[35\]](#page-11-9), sponsored
    developers form language-specific clusters that sponsor each other [\[35\]](#page-11-9),
    and the number of followers is the most important feature for predicting long-term
    contributors [\[3\]](#page-11-26). All values were measured in August 2022.


    - repositories: The number of public repositories created.

    - sponsoring: The number of developers sponsoring.

    - openedPRs: The number of opened pull requests.

    - reviewedPRs: The number of reviewed pull requests.

    - followers: The number of followers.

    - organizations: The number of joined organizations.

    - language: Categorical variable for the primary programming language determined
    by the method described in Section [3.2.](#page-1-0) The values are the top 10
    languages (JavaScript, Python, PHP, C#, Go, Java, TypeScript, C++, Ruby, and C)
    and others (including undetermined) seen in Table [2.](#page-6-1) In regression
    model building, dummy variables are prepared that take a value of 0 or 1 indicating
    the absence or presence of a particular language.


    We obtained 1,094 matched developers out of 7,411 (1, 930 + 4, 913 + 568) developers
    from the PSM. Figure [1](#page-5-0) shows how the absolute mean differences have
    decreased as a result of the matching, from unadjusted to adjusted (unadjusted
    indicates all developers before matching, and adjusted indicates matched developers).
    None of the absolute mean differences of adjusted exceeds 0.10, which means that
    we obtained developer matches for the treatment and control groups with a balanced
    distribution of covariates [\[22\]](#page-11-25). This balance is a measure of
    the quality of the propensity score matching and we achieved the well-established
    and well-cited threshold [\[2,](#page-11-27) [27\]](#page-11-28).


    To estimate the impact of GitHub Sponsors profile mentions in tweets, a linear
    regression is performed using the above variables


    <span id="page-5-0"></span>![](_page_5_Figure_15.jpeg)


    Figure 1: Covariate balance before (unadjusted) and after (adjusted) propensity
    score matching.


    <span id="page-5-1"></span>Table 1: Frequency of written languages of tweets that
    contain links to GitHub Sponsors profiles.


    | written languages | Person       | Organization |

    |-------------------|--------------|--------------|

    | English           | 3,074 (94%)  | 479 (97%)    |

    | Japanese          | 151 (5%)     | 5 (1%)       |

    | Undetermined      | 18 (0%)      | 1 (0%)       |

    | Spanish           | 8 (0%)       | 1 (0%)       |

    | Other             | 19 (0%)      | 4 (0%)       |

    | sum               | 3,270 (100%) | 496 (100%)   |


    and the variable treatment, which takes a value of 0 or 1 that indicates the presence
    or absence of general template tweets. The outcome variable is the number of sponsors
    obtained by each developer, measured in August 2022. Therefore, this analysis
    estimates the impact of tweeting "My GitHub Sponsors profile is live!" on the
    number of sponsors as of August 2022, for early adopters starting GitHub Sponsors
    and tweeting from May 2019 (GitHub Sponsors launched) through July 2021.


    #### 4 RESULTS


    This section presents answers to our research questions.


    ## 4.1 RQ1: How are GitHub Sponsors profiles discussed on Twitter/X?


    The results of the analysis of the characteristics, participants, context, and
    timing of tweets mentioning GitHub Sponsors profiles are presented in this section.


    4.1.1 RQ1.1: What are the characteristics of tweets mentioning GitHub Sponsors
    profiles from organizational and personal accounts? We investigated the written
    languages, GitHub account types, and the primary programming languages of the
    developers mentioned in the tweets. These elements were categorized based on whether
    they originated from personal or organizational accounts. This initial analysis
    serves as a foundation for our subsequent in-depth investigation, offering an
    initial understanding of the nature of these tweets.


    Written languages. Table [1](#page-5-1) presents the frequency of written languages
    in tweets that contain links to GitHub Sponsors profiles. <span id="page-6-1"></span>Table
    2: Frequency of GitHub account types and primary programming languages of distinct
    GitHub Sponsors profiles.


    | programming languages | Person       | Organization |

    |-----------------------|--------------|--------------|

    | JavaScript            | 816 (25%)    | 89 (18%)     |

    | Python                | 333 (10%)    | 47 (9%)      |

    | PHP                   | 309 (9%)     | 44 (9%)      |

    | C#                    | 228 (7%)     | 22 (4%)      |

    | Go                    | 180 (6%)     | 21 (4%)      |

    | Java                  | 153 (5%)     | 21 (4%)      |

    | Other                 | 1251 (38%)   | 252 (51%)    |

    | sum                   | 3,270 (100%) | 496 (100%)   |


    <span id="page-6-3"></span>Table 3: Frequency of relationships between tweet authors
    and linked GitHub Sponsors profiles.


    |                      | looking for sponsors | sponsors              |

    |----------------------|----------------------|-----------------------|

    | same                 | 169 (48%)            | -                     |

    | user<br>non-specific | -<br>14 (4%)         | 55 (16%)<br>113 (32%) |

    | sum                  | 183 (52%)            | 168 (48%)             |


    <span id="page-6-4"></span>


    | Table 4: Frequency of context of the GitHub Sponsors profile |  |

    |--------------------------------------------------------------|--|

    | mentions on Twitter/X.                                       |  |


    Compared to the ranks and portions of the written languages of general tweets
    [\[21\]](#page-11-29), in English GitHub Sponsors profile tweets, both personal
    and organizational accounts make up a significantly larger portion than general
    English tweets (51%). Japanese tweets rank second in general tweets, comprising
    5% of personal accounts and 1% of organizational accounts. Spanish also stands
    out as a top contributor among the top ten languages used frequently in general
    tweets.


    GitHub account types. As seen in Table [1](#page-5-1) and Table [2,](#page-6-1)
    most GitHub Sponsors profiles mentioned in tweets are associated with personal
    accounts, accounting for 87% of 3,766 distinct GitHub Sponsors profiles. Approximately
    a fifth of GitHub Sponsors profiles in tweets are associated with organizational
    accounts, representing 13% of distinct GitHub Sponsors profiles in the obtained
    tweets. According to GitHub''s advanced search engine [\[18\]](#page-11-30) in
    August 2022, 18,129 personal GitHub accounts had activated GitHub Sponsors, accounting
    for 91%. Furthermore, only 9% of all GitHub accounts (1,889) that activated GitHub
    Sponsors are organizational accounts. Comparing GitHub Sponsors profiles that
    were posted on Twitter/X and all GitHub Sponsors profiles on GitHub, they tend
    to share a similar trend for GitHub account types.


    Programming languages. Among the 3,766 distinct GitHub Sponsors profiles mentioned
    in the collected tweets, JavaScript stands out as the most prominent language,
    with 25% of personal accounts, suggesting its popularity among individual users.
    Conversely, its relatively lower representation in organizational accounts (18%)
    may indicate a preference for other languages in professional settings. Python,
    with 10% of usage among personal accounts, appears to be a language of choice
    for individual developers, potentially due to its versatility and readability.
    The prevalence of Python and PHP, both of them at 9%, among organizational accounts
    hints at their significance in enterprise-level development projects, as seen
    in Table [2.](#page-6-1) In the "other" category of coding repositories, where
    many instances are labeled as "None", there are organizations like PJSoftCo.[2](#page-6-2)
    They are a prime example of how GitHub organizations are using sponsorship funds
    to invest in their organization-wide documentation. Comparing these results with
    previous work [\[35\]](#page-11-9), we find that, except for Undetermined, the
    top four programming languages are exactly the same. The top ten primary programming
    languages are the same on individual GitHub Sponsors and GitHub Sponsors profiles
    that were posted on Twitter/X.


    |                                       | looking for sponsors | sponsors  |

    |---------------------------------------|----------------------|-----------|

    | generic advertisement                 | 72 (21%)             | -         |

    | donation appreciation                 | 34 (10%)             | -         |

    | sponsor template                      | 33 (9%)              | -         |

    | advertisement of developer            | 9 (3%)               | 7 (2%)    |

    | advertisement with new functionality  | 9 (3%)               | -         |

    | advertisement with new information    | 8 (2%)               | -         |

    | sustainability                        | 5 (1%)               | -         |

    | advertisement with early access       | 5 (1%)               | -         |

    | income                                | 2 (1%)               | -         |

    | advertisement with event              | 3 (1%)               | -         |

    | set example / peer pressure           | 2 (1%)               | 4 (1%)    |

    | advertisement of organization         | 1 (0%)               | 2 (1%)    |

    | donation to developer announcement    | -                    | 101 (29%) |

    | donation to organization announcement | -                    | 33 (9%)   |

    | donation to developer template        | -                    | 16 (5%)   |

    | donation to organization template     | -                    | 5 (1%)    |


    sum 183 (52%) 168 (48%)


    4.1.2 RQ1.2: Who mentions GitHub Sponsors profiles on Twitter/X? Table [3](#page-6-3)
    shows the results of the coding for RQ1.2. As mentioned in Section [3.3,](#page-3-0)
    we separated tweets by purpose, distinguishing developers who mention their GitHub
    Sponsors profiles to look for sponsors from those who are sponsors. Developers
    that were looking for sponsors mentioning their own GitHub Sponsors profiles in
    tweets is the most frequently occurring case, accounting for 48% of the sample.
    However, it is also common that sponsors mention GitHub Sponsors profiles of other
    GitHub accounts, accounting for 32% of the sample. We observe that sponsors also
    explicitly mentioned GitHub Sponsors profiles of others due to dependencies or
    other benefits, accounting for 16% of the sample. In previous work [\[35\]](#page-11-9),
    Shimada et al. showed that developers sponsoring others via GitHub Sponsors due
    to dependencies is the most frequent reason for sponsoring. In the context of
    Twitter/X, our result partially agrees with their observations.


    <span id="page-6-0"></span>4.1.3 RQ1.3: What is the context of GitHub Sponsors
    profile mentions on Twitter/X? In Table [4,](#page-6-4) the frequency of various
    GitHub Sponsors profile mentions on Twitter/X is presented. Most sponsors mentioned
    GitHub Sponsors profiles on Twitter/X in the context of donating to personal or
    organizational GitHub accounts, accounting for 29% and 9%, respectively. Sponsors
    also mentioned their donation to personal or organizational GitHub accounts using
    GitHub''s tweet templates, accounting for 5% and 1%, respectively.


    In addition to donations, developers looking for sponsors mentioned GitHub Sponsors
    profiles on Twitter/X to advertise their own profile (21%) or to advertise profiles
    of other personal GitHub accounts (3%). Specifically, developers looking for sponsors
    advertise


    <span id="page-6-2"></span><sup>2</sup>https://github.com/PJSoftCo


    <span id="page-7-0"></span>Table 5: Frequency of timing of tweets that contain
    links to GitHub Sponsors profiles.


    |                      | looking for sponsors | sponsors  |

    |----------------------|----------------------|-----------|

    | start                | 62 (18%)             | -         |

    | no specific timing   | 46 (13%)             | 111 (32%) |

    | donation             | 35 (10%)             | -         |

    | update               | 20 (6%)              | -         |

    | reach goal           | 8 (2%)               | -         |

    | release              | 6 (2%)               | -         |

    | event                | 3 (1%)               | -         |

    | resignation / paycut | 3 (1%)               | -         |

    | benefit              | -                    | 55 (16%)  |

    | activity spike       | -                    | 2 (1%)    |

    | sum                  | 182 (52%)            | 169 (48%) |


    their own profile with updates on the functionality of the project (3%), updates
    on the profile (2%), early access features (1%), and events (1%). As with the
    donation, developers looking for sponsors advertised their own profiles using
    GitHub''s tweet templates, accounting for 9%. Furthermore, a few developers looking
    for sponsors also posted tweets to encourage others to donate by setting an example
    or applying peer pressure, accounting for 1%.


    Some developers looking for sponsors use Twitter/X as a channel to express appreciation
    to sponsors (10%). Furthermore, a few tweets from developers looking for sponsors
    mention GitHub Sponsors profiles in the context of sustainability of the project
    or the financial income of developers. In particular, we see that several tweets
    are posted to share GitHub Sponsors updates in the context of the Log4j vulnerability
    [\[12\]](#page-11-31) that was exploited in December 2021. For example, "It''s
    nice to see that a month after the Log4Shell vulnerability Log4j''s maintainer
    has 101 GitHub Sponsors instead of 3, including corporate accounts such as Amazon
    Web Services".


    <span id="page-7-2"></span>4.1.4 RQ1.4: When are GitHub Sponsors profiles mentioned
    on Twitter/X? Table [5](#page-7-0) presents the frequency of different types of
    timing when different types of developers mentioned GitHub Sponsors profiles on
    Twitter/X. Regardless of the different types of developers, we find that most
    of the tweets (45%) do not specify an explicit explanation of the reason for the
    tweet''s posting at that particular time. However, we can see that some tweets
    (16%) were posted at a time when sponsors benefited from a project. Developers
    that were looking for sponsors posted those tweets during the initiation of GitHub
    Sponsors profiles (18%), at the time of donation (10%), or when updating projects
    or profiles (6%). Furthermore, some developers that were looking for sponsors
    posted tweets with GitHub Sponsors profile mentions when they need financial resources
    due to changes in their work arrangements.


    As seen in Table [5,](#page-7-0) we found an interesting type of timing with regard
    to when GitHub Sponsors profiles were mentioned in tweets: activity spikes, i.e.,
    a sponsor donated due to an activity spike of a developer. Inspired by this code,
    we conducted a quantitative study to analyze the correlations between contributions
    of developers and GitHub Sponsors profile mentions on Twitter/X. Table [6](#page-7-1)
    presents comparisons among three periods across a set of GitHub contribution types.
    Since the GitHub organization account lacks information on activity, we excluded
    tweets that contain GitHub Sponsors from organizations. Then, we focus on tweets
    from distinct developers that tweeted with "My GitHub Sponsors profile


    ICSE ''24, April 14–20, 2024, Lisbon, Portugal Youmei Fan, Tao Xiao, Hideaki Hata,
    Christoph Treude, and Kenichi Matsumoto


    is live!". Only 810 tweets were included out of the 10,531 English tweets. The
    rationale behind this choice was to specifically analyze the initial reactions
    and sentiments expressed by users who had just enabled their GitHub Sponsors account.
    Our primary goal was to capture the immediate activity of individuals in this
    specific context. Our sample is representative of GitHub Sponsors users'' initial
    tweets about their GitHub Sponsors account, but not of all tweets in our dataset.
    We observe that most of the mean values for the week in which a tweet was posted
    are higher than the corresponding values in the week before or after. For the
    contribution activities of Opening discussion, Committing, and Creating repository,
    there are significant differences between a week before posting this tweet and
    the week when the tweet was posted, and between the week when the tweet was posted
    and a week after posting this tweet, with at least negligible effect sizes (Committing
    shows small effect size). In addition to these activities, comparing a week before
    posting the tweet and the week when the tweet was posted, we find that developers
    proposed significantly more pull requests, with negligible effect size. These
    results indicate that when developers posted their GitHub Sponsors profile on
    Twitter/X, they generally contribute more actively to OSS projects.


    Summary: Of the GitHub Sponsors profiles mentioned in the tweets, 87% belong to
    individual developers, whose top primary languages were JavaScript, Python, and
    PHP. Such tweets were posted by the owners of the profiles or by others who depended
    on the work of the developer they sponsored. Developers looking for sponsors were
    more active on GitHub during the week in which tweets linking to their GitHub
    Sponsors profile were posted.


    <span id="page-7-1"></span>Table 6: Comparisons among three periods of GitHub
    contributions


    |                            | Before |   |                                                             |
    During |   |   | After |           |                     |

    |----------------------------|--------|---|-------------------------------------------------------------|--------|---|---|-------|-----------|---------------------|

    |                            |        |   | mean Q3 effect size mean Q3 effect
    size mean Q3 effect size |        |   |   |       |           |                     |

    | Opening PR                 | 1.12   |   | 1 0.0929*** 1.75 2                                          |        |   |
    - | 1.5   | 1         | -                   |

    | Subm. PR review            | 1.2    | 0 | -                                                           |
    1.28   | 0 | - | 1.19  | 0         | -                   |

    | Opening issue              | 0.61   | 0 | -                                                           |
    1.01   | 1 | - | 0.84  | 1         | -                   |

    | Opening disc.              | 0.03   |   | 0 0.0419*** 0.12                                            |        |
    0 | - | 0.06  | 0         | 0.0274**            |

    | Answering disc.            | 0.02   | 0 | -                                                           |
    0.03   | 0 | - | 0.04  | 0         | -                   |

    | Committing                 |        |   | 13.49 15 0.181*** 18.31 21                                  |        |   |
    - |       |           | 14.4 16.75 0.153*** |

    | Contr. to priv. repo. 7.69 |        | 6 | -                                                           |
    8.39 7 |   | - |       | 7.42 5.75 | -                   |

    | Creating repo.             | 0.52   |   | 0 0.0938*** 0.71 1                                          |        |   |
    - | 0.5   | 0         | 0.103***            |

    | Joining org.               | 0.01   | 0 | -                                                           |
    0.01   | 0 | - | 0.01  | 0         | -                   |


    \* p-value < 0.05; \*\* p-value < 0.01; and \*\*\* p-value < 0.001. The Cliff''s
    delta effect size with thresholds [\[34\]](#page-11-20) are highlighted in Negligible
    Small Medium Large. The hyphen (-) is used as a placeholder for cases where p-value
    ≥ 0.05 indicates there is no significant difference in the comparison or when
    comparing to itself.


    # 4.2 RQ2: What is the impact of GitHub Sponsors profile mentions on Twitter/X?


    4.2.1 RQ2.1: How are GitHub Sponsors profile mentions received on Twitter/X? Table
    [8](#page-9-0) presents comparisons between donation and crowd-funding platforms
    in Twitter interactions. For median values, Patreon tweets received the highest
    number of likes,


    Table 7: Frequency of response to tweets.


    |                          | looking for sponsors | sponsors  |

    |--------------------------|----------------------|-----------|

    | other                    | 165 (47%)            | 138 (39%) |

    | appreciation of work     | 9 (3%)               | -         |

    | support                  | 7 (2%)               | 3 (1%)    |

    | appreciation of donation | 2 (1%)               | 25 (7%)   |

    | emoji only               | -                    | 2 (1%)    |

    | sum                      | 183 (52%)            | 168 (48%) |


    accounting for six. Additionally, Patreon tweets were retweeted twice, which is
    the highest number of retweets in terms of median values. The median values of
    replies for the three platforms are zero. In terms of likes, the p-value of Patreon
    vs. GitHub Sponsors is less than 0.05 and Cliff''s delta is 0.265, indicating
    Patreon and GitHub Sponsors have a significant difference with a small effect
    size. In terms of retweets, Open Collective and GitHub Sponsors have a significant
    difference (i.e., p-value < 0.05) with a small effect size (i.e., 0.147 ≤ |delta|
    < 0.33). Comparing Patreon and GitHub Sponsors in terms of retweets, there is
    a significant difference with a small effect size. In terms of replies, we find
    that Patreon and GitHub Sponsors have a significant difference with a negligible
    effect size (i.e., Cliff''s delta is 0.132). In conclusion, while the number of
    tweets containing GitHub Sponsors profile mentions is much larger, tweets that
    link to Patreon or Open Collective in the context of OSS receive more likes and
    retweets.


    4.2.2 RQ2.2: How are GitHub Sponsors profile mentions discussed on Twitter/X?
    Table [9](#page-9-1) shows the results of our coding of replies to tweets that
    mentioned GitHub Sponsors profiles. We can see that most tweets (86%) do not receive
    a response on Twitter/X. For the remaining 14%, the majority consists of expressions
    of appreciation for donations (8%). Since Twitter/X is an informal communication
    channel, we observe that some responses consist only of one or more emoji.


    <span id="page-8-0"></span>4.2.3 RQ2.3: How do GitHub Sponsors profile mentions
    impact sponsorship? Table [10](#page-9-2) summarizes the regression result. As
    seen in the coefficient estimate of treatment, there is a statistically significant
    positive effect of GitHub Sponsors profile mentions in tweets on the number of
    sponsors acquired. As the average of the expected causal effect of treatment on
    individuals in the treatment group, called Average Treatment Effects on the Treated
    (ATT), we find that tweet mentions have an impact of increasing the number of
    sponsors by 1.22. However, note that the medians, Q3, and means for the matched
    treatment and control groups are {0, 2.00, 2.56} and {0, 1.00, 1.30}, respectively,
    indicating a skewness in the developers who obtained sponsorship, that is, the
    effects are not uniform.


    Summary: GitHub Sponsors profile mentions have a positive impact on the number
    of sponsors acquired, increasing the number of sponsors by 1.22. On Twitter/X,
    tweets mentioning GitHub Sponsors receive fewer interactions than those mentioning
    Patreon or Open Collective, and most tweets do not attract replies.


    #### 5 THREATS TO VALIDITY


    Subjective nature of coding. We conducted qualitative analyses of a statistically
    representative sample of tweets. The codes we assigned to different tweets may
    be inadequate due to the subjective nature of understanding the various coding
    schemata. To migrate this threat, we require kappa agreements of at least "substantial
    agreement" to ensure a common understanding of the coding schemata among all four
    annotators. Then, we initiated another round of coding between the first two authors
    for the remaining sample. By recalculating kappa agreements, we can see the improvement
    in understanding the various coding schemata. For example, Cohen''s kappa increased
    from 0.62 for the first 30 tweets to 0.85 for the reaming 321 tweets in the coding
    of the timing of tweets. The final results are based on the codes on which the
    authors, after discussion, reached a consensus and collectively agreed.


    Limitations in causal inference result. We compared developers with and without
    tweets who started GitHub Sponsors in the same period and engaged in similar activities,
    but we may have missed important developer characteristics other than the metrics
    we measured. The result is best interpreted as an increase in sponsors acquired
    through social activities on Twitter/X, rather than simply tweeting "My GitHub
    Sponsors profile is live!". In this study, we only analyzed the impact of tweets
    using such a template, so the impact of free-text tweets is unknown. In addition,
    since this analysis was conducted on early adopters, it is not possible to generalize
    whether similar effects will be seen in the future, so a continued analysis is
    needed.


    Multiple GitHub Sponsors profiles in the same tweet. There is a small number of
    cases where the same tweet contains multiple GitHub Sponsors profile links to
    different GitHub accounts. Since these cases are rare (i.e., only five tweets)
    and to avoid confusion in our analyses, we exclude these tweets from our analyses.


    Only tweets with GitHub Sponsors profiles links. Simple keyword searches would
    have introduced too much noise to our large-scale analysis. To avoid false positives,
    we only recovered tweets with GitHub Sponsors profile links, but we acknowledge
    that other relevant tweets without links may have been omitted.


    Primary programming languages of the developers. We considered the most common
    primary language of the repositories to which each developer contributed as the
    primary language of that developer. This means it could happen for some users,
    for example, that the most common language of a developer''s contributed repositories
    is Java, but the developer may only contribute the documentation of these Java
    repositories, whereas committing Python code to another project. Therefore, it
    is important to acknowledge this potential limitation in accurately capturing
    a developer''s primary programming language through this methodology.


    The number of tweets mentioning GitHub Sponsors has a different scale of data
    compared with other sponsorship platforms. We collected 10,440 tweets for GitHub
    Sponsors compared to other platforms: 4 for PayPal, 88 for Open Collective, and
    228 for Patreon. It is important to recognize that this difference in data size
    may affect the robustness and generalizability of our conclusions.


    External validity is concerned with our ability to generalize based on our results.
    In Section [4.1.4,](#page-7-2) we used a subset of 810 tweets from a pool of 10,531
    English tweets. It is crucial to acknowledge that the


    <span id="page-9-0"></span>Table 8: Comparisons among donation and crowd-funding
    platforms in Twitter interactions.


    |                 | like   |             |        | retweet     | reply  |             |        |

    |-----------------|--------|-------------|--------|-------------|--------|-------------|--------|

    |                 | median | effect size | median | effect size | median | effect
    size | #      |

    | Open Collective | 4      | -           | 1      | 0.216***    | 0      | -           |
    88     |

    | Patreon         | 6      | 0.265***    | 2      | 0.278***    | 0      | 0.132***    |
    228    |

    | GitHub Sponsors | 3      | -           | 0      | -           | 0      | -           |
    10,440 |


    \* p-value < 0.05; \*\* p-value < 0.01; and \*\*\* p-value < 0.001. The Cliff''s
    delta effect size with thresholds [\[34\]](#page-11-20) are highlighted in Negligible
    Small Medium Large. The hyphen (-) is used as a placeholder for cases where p-value
    ≥ 0.05 indicates there is no significant difference in the comparison or when
    comparing to itself (GitHub Sponsors).


    <span id="page-9-1"></span>Table 9: Frequency of response to tweets.


    | looking for sponsors | sponsors                                           |

    |----------------------|----------------------------------------------------|

    |                      | 130 (37%)                                          |

    |                      | 9 (3%)                                             |

    |                      | 2 (1%)                                             |

    |                      | -                                                  |

    |                      | 25 (7%)                                            |

    | -                    | 2 (1%)                                             |

    | 182 (52%)            | 169 (48%)                                          |

    |                      | 140 (40%)<br>27 (8%)<br>6 (2%)<br>6 (2%)<br>2 (1%) |


    <span id="page-9-2"></span>Table 10: Causal inference impact of GitHub Sponsors
    Profile Mentions in "My GitHub Sponsors Profile is Live!" Tweets.


    |                     | estimate  | std. error | p        |

    |---------------------|-----------|------------|----------|

    | treatment           | 1.22      | 0.452      | 0.00681  |

    | repositories        | -0.000818 | 0.00209    | 0.696    |

    | sponsoring          | 1.12      | 0.194      | 1.01e-8  |

    | openedPRs           | 0.000432  | 0.000457   | 0.345    |

    | reviewedPRs         | 0.00301   | 0.00140    | 0.0325   |

    | followers           | 0.00271   | 0.000345   | 8.42e-15 |

    | organizations       | -0.0637   | 0.0870     | 0.465    |

    | language_JavaScript | -1.45     | 0.657      | 0.0279   |

    | language_Python     | -1.18     | 0.856      | 0.168    |

    | language_PHP        | -0.343    | 0.906      | 0.705    |

    | language_C#         | 0.559     | 0.973      | 0.566    |

    | language_Go         | -0.933    | 1.02       | 0.360    |

    | language_Java       | -1.66     | 1.15       | 0.149    |

    | language_TypeScript | -0.692    | 1.04       | 0.505    |

    | language_C++        | -1.07     | 1.44       | 0.458    |

    | language_Ruby       | -1.01     | 1.50       | 0.500    |

    | language_C          | -0.659    | 1.21       | 0.586    |


    chosen subset may not fully represent the broader spectrum of reactions across
    all types of tweets related to GitHub Sponsors. Users who express their thoughts
    in different formats or use alternative phrases may not be fully captured in our
    analysis.


    #### 6 DISCUSSION


    This section presents implications and future work from this study.


    Implications. We categorized the practical implications for diverse groups of
    individuals by offering tailored guidance and recommendations that align with
    the specific concerns and interests of each stakeholder group.


    • Developers seeking sponsorship: our study shows that mentioning GitHub Sponsors
    profiles in tweets has a positive impact on the number of sponsors acquired. The
    finding that the number of sponsors acquired increased depending on whether they
    tweeted, is evidence of the importance of social


    media and should encourage developers to go beyond the GitHub platform in order
    to attract sponsorship. Additionally, our research reveals many different types
    of messages surrounding GitHub Sponsors in various contexts, providing insights
    that might assist others in crafting their own effective social media strategies
    for sponsorship engagement.


    - Developers interested in sponsoring: Within our sample, approximately half of
    the participants are sponsors. This finding underscores the importance of encouraging
    users who depend on OSS projects to actively promote the developers they rely
    on, even if the sponsorship amount is not substantial. Engaging in social media
    promotion can significantly enhance the visibility of these developers, allowing
    their exceptional work to reach a wider audience and garner increased recognition.

    - Companies: The relationship between companies and OSS projects is undergoing
    a pivotal change, largely driven by an expanding recognition of sustainability
    issues inherent in OSS. Instead of merely expressing dissatisfaction with the
    lack of sustainability in these projects, our study offers evidence that a two-pronged
    approach of corporate sponsorship and active social media engagement could be
    an effective strategy for businesses. This strategy allows them to constructively
    engage with OSS projects they rely upon, particularly those struggling with sustainability,
    thereby addressing their concerns and contributing to potential solutions.


    Future Work. As our study is positioned as an early adopter study, we have not
    yet obtained conclusive evidence of a significant impact of financial support
    on OSS sustainability at this stage. Therefore, further investigation of the potential
    impact of financial support on sustainability is needed.


    We have focused on Twitter/X as the starting point for our exploration. For future
    research, there is significant value in extending our analysis to encompass posts
    from multiple social media platforms (e.g., Facebook, Reddit) to gain a more comprehensive
    understanding of these dynamics.


    As part of our investigation into RQ2.1, we found that tweets linking exclusively
    to GitHub Sponsors were more common, and among those platforms, GitHub is the
    only one that provides Twitter/X templates for developers looking for sponsors
    and Twitter/X templates for sponsors. However, GitHub Sponsors received fewer
    responses compared to tweets promoting alternative sponsorship platforms. Since
    GitHub Sponsors launched 4–6 years later than Open Collective and Patreon, so
    it had less time to solidify its position and gain widespread awareness. Further
    research is needed


    to determine the importance of the template if such a sponsorship platform provides
    a template when users are trying to advertise on social media, and strategies
    for increasing the response and engagement of tweets containing only links to
    GitHub Sponsors.


    In light of our findings regarding the skewness in the developers who obtained
    sponsorship (Section [4.2.3\)](#page-8-0), factors other than tweets may play
    an important role in sponsor acquisition. Thus, further research is needed to
    explore and identify these additional factors that contribute to the sponsor acquisition
    process.


    In subsequent studies, it would be valuable to investigate the specific strategies
    and practices employed by organizations when leveraging social media platforms
    to disseminate project updates. By examining the relationship between these practices
    and the resulting engagement levels within the community, we can gain insights
    into the effectiveness of such approaches and their potential for enhancing community
    involvement. Moreover, it is worth considering a more in-depth investigation into
    how the domain and functionalities of open-source projects can impact and guide
    the dynamics of sponsorship, such as evaluations of a project''s sustainability
    and its sponsorship status [\[32\]](#page-11-32).


    #### 7 RELATED WORK


    In this section, we situate our work with respect to the literature on donations
    and one potential advertising channel, Social Media.


    Donation. OSS development heavily relies on volunteer contributions, as highlighted
    in a recent GitHub survey [\[17\]](#page-11-33), revealing that just 23% of respondents
    contribute to open source as part of their job description. Despite more employees
    being paid for contributing to OSS projects during work hours [\[33\]](#page-11-34),
    developers still perceive compensation asymmetry in OSS projects [\[1\]](#page-11-35).
    OSS projects that are distributed unequally may fail if they are mismanaged and
    financial benefits are a factor in the sustainability of OSS projects [\[1\]](#page-11-35).
    Donation is one of the common ways to obtain these financial benefits [\[13\]](#page-11-36)
    to support OSS projects, in addition to Bounty [\[13\]](#page-11-36). In a mixed-method
    empirical study, Overney et al. [\[28\]](#page-11-1) found that only a few projects
    (0.04–0.2%) ask for donations, primarily using platforms like PayPal and Patreon.
    These projects tend to be more active, more mature, and more popular.


    Recently, Zhou et al. [\[49\]](#page-11-2) explored donations on the Open Collective
    platform that support open-source projects. They indicated the influence of individual
    donors; although corporate donors tend to donate more money than individual donors
    for an individual donation, the total donation amount from individual donors is
    greater than corporate donors. However, corporate collectives are more likely
    to receive a larger total donation amount than individual collectives. Regarding
    the study on GitHub Sponsors, Shimada et al. [\[35\]](#page-11-9) revealed that
    developers typically do not have channels at their disposal to attract sponsors
    and communicate with those who might be interested in donating. Zhang et al. [\[48\]](#page-11-37)
    discovered that sponsorship through GitHub Sponsors has a short-term impact on
    developers'' activities. Their survey highlighted key challenges, including the
    difficulty of attracting sponsorship and the absence of corporate support.


    Social Media. Social media channels are one way of communicating and advertising
    in the world of developers. Different social media channels play different roles
    and have different impact on


    OSS projects, e.g., facilitating communication [\[5,](#page-11-38) [38\]](#page-11-11),
    awareness of the status of other developers [\[4,](#page-11-39) [6\]](#page-11-40),
    gaining attention [\[8,](#page-11-41) [23,](#page-11-42) [43\]](#page-11-43),
    and attracting new contributors [\[7,](#page-11-44) [23,](#page-11-42) [31\]](#page-11-45).


    Researchers studied the use of microblog services such as Twitter/X in software
    development [\[8\]](#page-11-41). The tweets of developers differ from those of
    the general public in terms of length, use of URLs, and @-mentions, and software
    microbloggers are more tightly knit than general microbloggers [\[9,](#page-11-46)
    [41\]](#page-11-47). Twitter/X is widely adopted in the software engineering community
    [\[5,](#page-11-38) [39\]](#page-11-12). Tian et al. [\[40\]](#page-11-48) found
    that knowledge sharing, technical discussion, and software product updates are
    the most frequent categories of developers'' tweets. Fang et al. [\[14\]](#page-11-49)
    proposed an approach to cross-link users on Twitter/X and GitHub; they observed
    that tweeting patterns appear in tweets from different developer roles when including
    GitHub links in their tweets (e.g., repository owners prompt their projects instead
    of discussing specific software artifacts).


    For the impact of Twitter/X, Singer et al. [\[36\]](#page-11-14) indicated that
    Twitter/X can help developers become aware of industry changes, learn, and build
    work relationships in communities. Mezouar et al. [\[24\]](#page-11-13) found
    that tweets from end users can lead to early discovery of bugs in web browsers.
    Fang et al. [\[15\]](#page-11-10) explored the causal effects of Twitter/X on
    the attraction of stars and contributors by analyzing tweets that contain links
    to GitHub repositories. They found that Twitter/X has a statistically significant
    and sizeable effect to help make projects popular (i.e., stars) but only a small
    effect to attract new contributors (i.e., commits). Moreover, these newly attracted
    contributors showed to be more active in OSS projects when they had prior Twitter/X
    interactions with the tweet authors.


    #### 8 CONCLUSION


    There are several platforms that enable contributions to opensource software developers,
    but attracting sponsors in order to ensure project sustainability remains a challenge.
    To understand the impact of Twitter/X on helping OSS developers attract sponsors,
    we conducted quantitative and qualitative analyses of more than 10,000 tweets
    containing links to GitHub Sponsors profiles. We find that such tweets have a
    significant positive effect on the acquisition of sponsors, and that developers
    contribute more OSS work than usual to attract potential sponsors during the week
    in which they posted tweets that link to their own GitHub Sponsors profile.


    Open-source developers who maintain an active presence on social media can attract
    donations that help sustain their projects. Our findings suggest that social media
    channels and donation channels are linked in the social programmer ecosystem and
    will continue to grow in importance for the sustainability of open source software.


    #### DATA AVAILABILITY


    The replication package includes scripts and data set, which is available at<https://doi.org/10.5281/zenodo.10461383>
    and [https://](https://github.com/NAIST-SE/GHSponsorsX) [github.com/NAIST-SE/GHSponsorsX](https://github.com/NAIST-SE/GHSponsorsX)


    #### ACKNOWLEDGEMENTS


    This work was supported by JSPS KAKENHI Grant Numbers JP20H00587 and JP20H05706,
    JSPS Grant-in-Aid for JSPS Fellows JP23KJ1589, and JST PRESTO Grant Number JPMJPR22P6.


    <span id="page-11-0"></span>ICSE ''24, April 14–20, 2024, Lisbon, Portugal Youmei
    Fan, Tao Xiao, Hideaki Hata, Christoph Treude, and Kenichi Matsumoto


    #### REFERENCES


    - <span id="page-11-35"></span>[1] Arzoo Atiq and Arvind Tripathi. 2016. Impact
    of financial benefits on open source software sustainability. In Proceedings of
    37th International Conference on Information Systems (ICIS ''16). 10.

    - <span id="page-11-27"></span>[2] Peter C. Austin. 2009. Balance diagnostics
    for comparing the distribution of baseline covariates between treatment groups
    in propensity-score matched samples. Statistics in Medicine 28, 25 (2009), 3083–3107.<https://doi.org/10.1002/sim.3697>
    arXiv[:https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.3697](https://arxiv.org/abs/https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.3697)

    - <span id="page-11-26"></span>[3] Lingfeng Bao, Xin Xia, David Lo, and Gail C.
    Murphy. 2021. A Large Scale Study of Long-Time Contributor Prediction for GitHub
    Projects. IEEE Transactions on Software Engineering 47, 6 (2021), 1277–1298. [https://doi.org/10.1109/TSE.2019.](https://doi.org/10.1109/TSE.2019.2918536)
    [2918536](https://doi.org/10.1109/TSE.2019.2918536)

    - <span id="page-11-39"></span>[4] Andrew Begel, Robert DeLine, and Thomas Zimmermann.
    2010. Social media for software engineering. In Proceedings of the FSE/SDP workshop
    on Future of software engineering research. 33–38.

    - <span id="page-11-38"></span>[5] Sue Black, Rachel Harrison, and Mark Baldwin.
    2010. A survey of social media use in software systems development. In Proceedings
    of the 1st Workshop on Web 2.0 for Software Engineering. 1–5.

    - <span id="page-11-40"></span>[6] Sue Black and Joanne Jacobs. 2010. Using Web
    2.0 to improve software quality. In Proceedings of the 1st Workshop on Web 2.0
    for Software Engineering. 6–11.

    - <span id="page-11-44"></span>[7] Kelly Blincoe, Jyoti Sheoran, Sean Goggins,
    Eva Petakovic, and Daniela Damian. 2016. Understanding the popular users: Following,
    affiliation influence and leadership on GitHub. Information and Software Technology
    70 (2016), 30–39.

    - <span id="page-11-41"></span>[8] Hudson Silva Borges and Marco Tulio Valente.
    2019. How do developers promote open source projects? Computer 52, 8 (2019), 27–33.

    - <span id="page-11-46"></span>[9] Gargi Bougie, Jamie Starke, Margaret-Anne Storey,
    and Daniel M German. 2011. Towards understanding twitter use in software engineering:
    preliminary findings, ongoing challenges and future questions. In Proceedings
    of the 2nd international workshop on Web 2.0 for software engineering. 31–36.

    - <span id="page-11-19"></span>[10] Andrea Capiluppi and Daniel Izquierdo-Cortázar.
    2013. Effort estimation of FLOSS projects: a study of the Linux kernel. Empirical
    Software Engineering 18 (2013), 60–88.

    - <span id="page-11-4"></span>[11] Open Collective. 2023. Raise and spend money
    with full transparency. — opencollective.com. [https://opencollective.com/.](https://opencollective.com/)
    [Accessed 28-Jun-2023].

    - <span id="page-11-31"></span>[12] CVE. 2021. CVE - CVE-2021-44228 — cve.mitre.org.
    [https://cve.mitre.org/cgi](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-44228)[bin/cvename.cgi?name=CVE-2021-44228.](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-44228)
    [Accessed 28-Jun-2023].

    - <span id="page-11-36"></span>[13] Nadia Eghbal. 2019. A handy guide to financial
    support for open source. [https://github.com/nayafia/lemonade-stand.](https://github.com/nayafia/lemonade-stand)
    Accessed: https://opensourcesurvey.org/2017/.

    - <span id="page-11-49"></span>[14] Hongbo Fang, Daniel Klug, Hemank Lamba, James
    Herbsleb, and Bogdan Vasilescu. 2020. Need for tweet: How open source developers
    talk about their github work on twitter. In Proceedings of the 17th International
    Conference on Mining Software Repositories. 322–326.

    - <span id="page-11-10"></span>[15] Hongbo Fang, Hemank Lamba, James Herbsleb,
    and Bogdan Vasilescu. 2022. "This is Damn Slick!": Estimating the Impact of Tweets
    on Open Source Project Popularity and New Contributors. In Proceedings of the
    44th International Conference on Software Engineering (ICSE ''22). 2116–2129.
    [https://doi.org/10.1145/](https://doi.org/10.1145/3510003.3510121) [3510003.3510121](https://doi.org/10.1145/3510003.3510121)

    - <span id="page-11-7"></span>[16] Gitcoin. 2023. Grants — gitcoin.co. [https://gitcoin.co/grants/.](https://gitcoin.co/grants/)
    [Accessed 28-Jun-2023].

    - <span id="page-11-33"></span>[17] GitHub. 2017. Open Source Survey 2017. [https://opensourcesurvey.org/2017/.](https://opensourcesurvey.org/2017/)
    Accessed: 2022-08-18.

    - <span id="page-11-30"></span>[18] GitHub. 2023. Build software better, together
    — github.com. [https://github.com/](https://github.com/search/) [search/.](https://github.com/search/)
    [Accessed 28-Jun-2023].

    - <span id="page-11-18"></span>[19] GitHub. 2023. GitHub GraphQL API documentation
    - GitHub Docs docs.github.com. [https://docs.github.com/en/graphql.](https://docs.github.com/en/graphql)
    [Accessed 28-Jun-2023].

    - <span id="page-11-8"></span>[20] Giveth. 2023. Giveth: Welcome to the Future
    of Giving — giveth.io. [https:](https://giveth.io) [//giveth.io.](https://giveth.io)
    [Accessed 28-Jun-2023].

    - <span id="page-11-29"></span>[21] Lichan Hong, Gregorio Convertino, and Ed Chi.
    2011. Language matters in twitter: A large scale study. In Proceedings of the
    international AAAI conference on web and social media, Vol. 5. 518–521.

    - <span id="page-11-25"></span>[22] Guido W. Imbens and Donald B. Rubin. 2015.
    Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction.
    Cambridge University Press. <https://doi.org/10.1017/CBO9781139025751>

    - <span id="page-11-42"></span>[23] Danaja Maldeniya, Ceren Budak, Lionel P Robert
    Jr, and Daniel M Romero. 2020. Herding a Deluge of Good Samaritans: How GitHub
    Projects Respond to Increased Attention. In Proceedings of The Web Conference
    2020. 2055–2065.

    - <span id="page-11-13"></span>[24] Mariam El Mezouar, Feng Zhang, and Ying Zou.
    2018. Are tweets useful in the bug fixing process? an empirical study on firefox
    and chrome. Empirical Software Engineering 23, 3 (2018), 1704–1742.

    - <span id="page-11-24"></span>[25] Emerson Murphy-Hill, Edward K. Smith, Caitlin
    Sadowski, Ciera Jaspan, Collin Winter, Matthew Jorde, Andrea Knight, Andrew Trenk,
    and Steve Gross. 2019. Do Developers Discover New Tools on the Toilet?. In Proceedings
    of the 41st International Conference on Software Engineering (Montreal, Quebec,
    Canada) (ICSE ''19). IEEE Press, 465–475.<https://doi.org/10.1109/ICSE.2019.00059>

    - <span id="page-11-22"></span>[26] Keitaro Nakasai, Hideaki Hata, and Kenichi
    Matsumoto. 2019. Are Donation Badges Appealing?: A Case Study of Developer Responses
    to Eclipse Bug Reports.


    IEEE Software 36, 03 (2019), 22–27.


    - <span id="page-11-28"></span>[27] Sharon-Lise T. Normand, Mary Beth Landrum,
    Edward Guadagnoli, John Z. Ayanian, Thomas J. Ryan, Paul D. Cleary, and Barbara
    J. McNeil. 2001. Validating recommendations for coronary angiography following
    acute myocardial infarction in the elderly: A matched analysis using propensity
    scores. Journal of Clinical Epidemiology 54, 4 (2001), 387–398. [https://doi.org/10.1016/S0895-4356\(00\)00321-8](https://doi.org/10.1016/S0895-4356(00)00321-8)

    - <span id="page-11-1"></span>[28] Cassandra Overney, Jens Meinicke, Christian
    Kästner, and Bogdan Vasilescu. 2020. How to Not Get Rich: An Empirical Study of
    Donations in Open Source. In Proceedings of ACM/IEEE 42nd International Conference
    on Software Engineering (ICSE ''20). 1209–1221.

    - <span id="page-11-5"></span>[29] Patreon. 2023. Creativity powered by membership
    | Patreon — patreon.com. [https://www.patreon.com/.](https://www.patreon.com/)
    [Accessed 28-Jun-2023].

    - <span id="page-11-3"></span>[30] PayPal. 2023. Digital Wallets, Money Management,
    and More — paypal.com. [https://www.paypal.com/.](https://www.paypal.com/) [Accessed
    29-Jun-2023].

    - <span id="page-11-45"></span>[31] Huilian Sophie Qiu, Yucen Lily Li, Susmita
    Padala, Anita Sarma, and Bogdan Vasilescu. 2019. The signals that potential contributors
    look for when choosing open-source projects. Proceedings of the ACM on Human-Computer
    Interaction 3, CSCW (2019), 1–29.

    - <span id="page-11-32"></span>[32] Uzma Raja and Marietta J. Tretter. 2012. Defining
    and Evaluating a Measure of Open Source Project Survivability. IEEE Transactions
    on Software Engineering 38, 1 (2012), 163–174.<https://doi.org/10.1109/TSE.2011.39>

    - <span id="page-11-34"></span>[33] Dirk Riehle, Philipp Riemer, Carsten Kolassa,
    and Michael Schmidt. 2014. Paid vs. volunteer work in open source. In Proceedings
    of 47th Hawaii International Conference on System Sciences (HICSS ''14). 3286–3295.

    - <span id="page-11-20"></span>[34] Jeanine Romano, Jeffrey D Kromrey, Jesse Coraggio,
    and Jeff Skowronek. 2006. Appropriate statistics for ordinal level data: Should
    we really be using t-test and Cohen''sd for evaluating group differences on the
    NSSE and other surveys. In annual meeting of the Florida Association of Institutional
    Research, Vol. 177. 34.

    - <span id="page-11-9"></span>[35] Naomichi Shimada, Tao Xiao, Hideaki Hata, Christoph
    Treude, and Kenichi Matsumoto. 2022. GitHub Sponsors: Exploring a New Way to Contribute
    to Open Source. In Proceedings of the 44th International Conference on Software
    Engineering (ICSE ''22). 1058–1069.<https://doi.org/10.1145/3510003.3510116>

    - <span id="page-11-14"></span>[36] Leif Singer, Fernando Figueira Filho, and
    Margaret-Anne Storey. 2014. Software engineering at the speed of light: how developers
    stay current using twitter. In Proceedings of the 36th International Conference
    on Software Engineering. 211–221.

    - <span id="page-11-6"></span>[37] GitHub Sponsors. 2023. GitHub Sponsors — github.com.
    [https://github.com/](https://github.com/sponsors) [sponsors.](https://github.com/sponsors)
    [Accessed 28-Jun-2023].

    - <span id="page-11-11"></span>[38] Margaret-Anne Storey, Christoph Treude, Arie
    van Deursen, and Li-Te Cheng. 2010. The impact of social media on software engineering
    practices and tools. In Proceedings of the FSE/SDP workshop on Future of software
    engineering research. 359–364.

    - <span id="page-11-12"></span>[39] Margaret-Anne Storey, Alexey Zagalsky, Fernando
    Figueira Filho, Leif Singer, and Daniel M German. 2016. How social and communication
    channels shape and challenge a participatory culture in software development.
    IEEE Transactions on Software Engineering 43, 2 (2016), 185–204.

    - <span id="page-11-48"></span>[40] Yuan Tian, Palakorn Achananuparp, Ibrahim
    Nelman Lubis, David Lo, and Ee-Peng Lim. 2012. What does software engineering
    community microblog about?. In 2012 9th IEEE Working Conference on Mining Software
    Repositories (MSR). IEEE, 247–250.

    - <span id="page-11-47"></span>[41] Yuan Tian and David Lo. 2014. An exploratory
    study on software microblogger behaviors. In 2014 IEEE 4th Workshop on Mining
    Unstructured Data. IEEE, 1–5.

    - <span id="page-11-15"></span>[42] Christoph Treude, Fernando Figueira Filho,
    Brendan Cleary, and Margaret-Anne Storey. 2012. Programming in a socially networked
    world: the evolution of the social programmer. In The Future of Collaborative
    Software Development. 1–3.

    - <span id="page-11-43"></span>[43] Asher Trockman, Shurui Zhou, Christian Kästner,
    and Bogdan Vasilescu. 2018. Adding sparkle to social coding: an empirical study
    of repository badges in the npm ecosystem. In Proceedings of the 40th international
    conference on software engineering. 511–522.

    - <span id="page-11-17"></span>[44] Twitter. 2022. Twitter API Documentation —
    developer.twitter.com. [https:](https://developer.twitter.com/en/docs/twitter-api)
    [//developer.twitter.com/en/docs/twitter-api.](https://developer.twitter.com/en/docs/twitter-api)
    [Accessed 28-Jun-2023].

    - <span id="page-11-16"></span>[45] Twitter. 2022. Twitter API for Academic Research
    | Products — developer.twitter.com. [https://developer.twitter.com/en/products/twitter-api/](https://developer.twitter.com/en/products/twitter-api/academic-research)
    [academic-research.](https://developer.twitter.com/en/products/twitter-api/academic-research)
    [Accessed 28-Jun-2023].

    - <span id="page-11-21"></span>[46] Anthony Viera and Joanne Garrett. 2005. Understanding
    Interobserver Agreement: The Kappa Statistic. Family medicine (2005).

    - <span id="page-11-23"></span>[47] Longqi Yang, David Holtz, Sonia Jaffe, Siddharth
    Suri, Shilpi Sinha, Jeffrey Weston, Connor Joyce, Neha Shah, Kevin Sherman, Brent
    Hecht, and Jaime Teevan. 2022. The effects of remote work on collaboration among
    information workers. Nature Human Behaviour 6, 1 (01 Jan 2022), 43–54. [https://doi.org/10.1038/s41562-021-](https://doi.org/10.1038/s41562-021-01196-4)
    [01196-4](https://doi.org/10.1038/s41562-021-01196-4)

    - <span id="page-11-37"></span>[48] Xunhui Zhang, Tao Wang, Yue Yu, Qiubing Zeng,
    Zhixing Li, and Huaimin Wang. 2022. Who, What, Why and How? Towards the Monetary
    Incentive in Crowd Collaboration: A Case Study of Github''s Sponsor Mechanism.
    In CHI Conference on Human Factors in Computing Systems. 1–18.

    - <span id="page-11-2"></span>[49] Jiayuan Zhou, Shaowei Wang, Yasutaka Kamei,
    Ahmed E Hassan, and Naoyasu Ubayashi. 2022. Studying donations and their expenses
    in open source projects: a case study of GitHub projects collecting donations
    through open collectives. Empirical Software Engineering 27, 1 (2022), 1–38.'
- title: "Guiding Effort Allocation in Open-Source Software Projects Using Bus\n \
    \ Factor Analysis"
  abstract: 'A critical issue faced by open-source software projects is the risk of
    key

    personnel leaving the project. This risk is exacerbated in large projects that

    have been under development for a long time and experienced growth in their

    development teams. One way to quantify this risk is to measure the

    concentration of knowledge about the project among its developers. Formally

    known as the Bus Factor (BF) of a project and defined as ''the number of key

    developers who would need to be incapacitated to make a project unable to

    proceed''. Most of the proposed algorithms for BF calculation measure a

    developer''s knowledge of a file based on the number of commits. In this work,

    we propose using other metrics like lines of code changes (LOCC) and cosine

    difference of lines of code (change-size-cos) to calculate the BF. We use these

    metrics for BF calculation for five open-source GitHub projects using the CST

    algorithm and the RIG algorithm, which is git-blame-based. Moreover, we

    calculate the BF on project sub-directories that have seen the most active

    development recently. Lastly, we compare the results of the two algorithms in

    accuracy, similarity in results, execution time, and trends in BF values over

    time.'
  url: http://arxiv.org/abs/2401.03303v1
  keywords: ''
  document: '# Guiding Effort Allocation in Open-Source Software Projects Using Bus
    Factor Analysis


    [Aliza Lisan](https://orcid.org/0002-1544-1493) Boyana Norris alisan@uoregon.edu
    norris@cs.uoregon.edu University of Oregon Eugene, Oregon, USA


    #### ABSTRACT


    A critical issue faced by open-source software projects is the risk of key personnel
    leaving the project. This risk is exacerbated in large projects that have been
    under development for a long time and experienced growth in their development
    teams. One way to quantify this risk is to measure the concentration of knowledge
    about the project among its developers. Formally known as the Bus Factor (BF)
    of a project and defined as "the number of key developers who would need to be
    incapacitated to make a project unable to proceed" [\[1\]](#page-7-0). Most of
    the proposed algorithms for BF calculation measure a developer''s knowledge of
    a file based on the number of commits. In this work, we propose using other metrics
    like lines of code changes (LOCC) and cosine difference of lines of code (change-size-cos)
    to calculate the BF. We use these metrics for BF calculation for five open-source
    GitHub projects using the CST algorithm and the RIG algorithm, which is git-blame-based.
    Moreover, we calculate the BF on project sub-directories that have seen the most
    active development recently. Lastly, we compare the results of the two algorithms
    in accuracy, similarity in results, execution time, and trends in BF values over
    time.


    ### CCS CONCEPTS


    • Software and its engineering → Risk management; Maintaining software; Software
    version control; Open source model; Programming teams.


    #### KEYWORDS


    Bus factor, Open-Source, Code ownership, Risk management, Mining GitHub repositories


    #### 1 INTRODUCTION


    If we look at our daily use of the Internet, we realize that we are consumed with
    the use of software and applications. The development and maintenance of all these
    software projects are based on the knowledge held by its developers. This makes
    the software development process the most dependent upon its developers. Given
    that, developers become an important asset for project organizations and open-source
    project teams. This also makes the rate at which developers leave a software project
    a critical matter and risk. To mitigate this risk, it is important that project
    managers or principal developers monitor and quantify the concentration of knowledge
    of the project among its developers [\[2\]](#page-7-1) An interesting measurement
    used in this regard is known as the Bus Factor (BF), which is defined as the minimum
    number of key developers whose departure


    would make a project unable or difficult to proceed [\[2\]](#page-7-1) A smaller
    bus factor value would mean that the maximum knowledge of the project is concentrated
    among them and the project is at a higher risk if some or all of these developers
    leave the project, company or go for a vacation, etc. A bus factor of one would
    be the worst-case scenario. Conversely, a high bus factor means a lesser risk
    is posed to the project in case some of the developers end up leaving.


    When it comes to open-source software projects, the bus factor is of much more
    importance. Most of the people working on these projects are making contributions
    voluntarily. Volunteering means that the developers or contributors do not have
    financial benefits associated with these projects. This puts open-source software
    projects at a higher risk of developer turnover [\[2\]](#page-7-1). Given the
    importance of bus factor measurement in open-source software development projects,
    algorithms have been proposed to calculate it using data gathered from version
    control systems such as GitHub [\[1,](#page-7-0) [3,](#page-7-2) [4\]](#page-7-3).
    To the best of our knowledge, most of these algorithms are commit-based, i.e.,
    the algorithms look at the commit data from version control repositories. Moreover,
    existing work mostly proposes bus factor calculation algorithms and presents tools
    for the same. Few studies attempt to validate the results of these algorithms.
    [\[2\]](#page-7-1) is an empirical and comparative study where three Bus Factor
    algorithms are validated, but they only used the tools and metrics provided by
    the original authors.


    Therefore, in this paper, we look at two algorithms (a) first one was proposed
    by Cosentino et al. [\[2\]](#page-7-1), which calculates the bus factor of each
    file and aggregates it up to branch, directory, or project level; (b) second one
    proposed by Rigby et al. [\[4\]](#page-7-3), which uses a git-blame-based approach
    to calculate the bus factor. The tool based on the first algorithm is publicly
    available [\[1\]](#page-7-0); however, the authors have only provided the pseudo-code
    of the second. Using the convention followed in [\[2\]](#page-7-1), we refer to
    the first algorithm as CST and the second one as RIG. Among the two algorithms,
    CST is a commit-based algorithm, and we wanted to use it with other metrics like
    lines of code changes (LOCC) and cosine difference of lines of code (change-size-cos).
    For that, we implemented it by understanding the algorithm mentioned in [\[1\]](#page-7-0).
    RIG algorithm had to be implemented as its code, or any related tool is not publicly
    available. We implemented and tested both algorithms on five opensource projects
    and compared their results. We also got feedback from the principal developers
    of these projects to validate the results. Lastly, we used the tool provided in
    [\[1\]](#page-7-0) to obtain bus factor results for the selected projects.


    To summarize, we seek to answer the following research questions:


    - (1) How do different metrics such as lines of changed code and cosine difference
    affect the bus factor computation?

    - (2) How can the bus factor guide principal developers or managers to allocate
    effort for hiring or knowledge transfer among the existing team of developers?

    - (3) How do bus factor algorithms differ in terms of accuracy and performance?


    As such, our contributions can be summarized as follows:


    - Implemented the CST algorithm (with lines of code changes and cosine difference
    of lines of code) and the RIG algorithm and compared their results.

    - Got feedback from the principal developers of the five selected projects to
    validate our results.

    - Calculated the BF of the selected projects using the commitbased CST algorithm
    tool provided in [\[1\]](#page-7-0) to compare with our results.

    - Calculated the bus factor for the selected projects for the last five years
    to see the trend in BF values.


    In Section [2,](#page-1-0) we review the existing literature for bus factor calculation.
    Section [3](#page-2-0) explains the design and steps involved in our study. We
    present our results in Section [4](#page-4-0) and conclude the paper in Section
    [6.](#page-7-4)


    #### <span id="page-1-0"></span>2 EXISTING LITERATURE


    In this section, first, we describe the two algorithms for measuring bus factors
    that we will be using as part of our study in this paper. Towards the end, we
    describe other algorithms that are part of the existing literature but not implemented
    in our study.


    #### <span id="page-1-2"></span>2.1 CST Algorithm


    The CST algorithm is proposed as part of a tool paper [\[1\]](#page-7-0) by Cosentino
    et al. The algorithm calculates the knowledge of developers on each file and determines
    the bus factor for each file based on that. Furthermore, aggregation is performed
    from file to directory, branch, or project level to get developer knowledge. The
    aggregation is done by simply adding the knowledge on each file and scaling with
    the number of files in the directory, branch, or project. The authors proposed
    four metrics to calculate a developer''s knowledge of a file. last change takes
    it all assigns 100% knowledge of a file to the last developer who modified it,
    and in multiple changes equally considered, the knowledge of a developer is calculated
    by dividing the number of commits made by the developer on a file by the total
    number of commits ever made on that file. The third metric is non-consecutive
    changes, which considers the developer''s non-consecutive commits on a file only
    and merges the consecutive commits into a single one. The last metric is an extension
    of the third metric, called the weighted non-consecutive changes, and assigns
    incremental weight to the later commits on the file.


    Once the developer''s knowledge of the artifacts, i.e., file, directory, branch,
    or project, has been calculated, the bus factor for each of these artifacts is
    measured by using two sets of developers. The first set is called the primary
    developers who have minimum knowledge of the artifact. The second set is called
    the secondary developers who at least have some knowledge of the artifact, where
    is less than . The threshold for the selection of primary developers is set to
    1/ where is the total number of developers that have made changes to the artifact
    till date. is set of half of for the selection of secondary developers. The number
    of developers in the union of both these sets gives us the bus factor for the
    particular artifact.


    Since, CST is a commit-based algorithm, we use the same algorithm with LOCC and
    change-size-cos. The details of how we collect and use this data for open-source
    projects on GitHub are provided in later sections.


    <span id="page-1-1"></span>


    | Algorithm 1 RIG Algorithm                        |

    |--------------------------------------------------|

    | Data git-blame data for each file in the project |

    | Result BFset (BF developers), g (Bus Factor)     |

    | 1: for 𝑔<br>← 1 𝑡𝑜<br>200 do                     |

    | for 𝑖<br>← 1 𝑡𝑜<br>1000 do<br>2:                 |

    | 𝐵𝐹𝑠𝑒𝑡<br>← random sample of g devs;<br>3:        |

    | remove-authors (BFset);<br>4:                    |

    | if abandoned-files() ≥ 50% then<br>5:            |

    | return g, BFset;<br>6:                           |

    | end if<br>7:                                     |

    | end for<br>8:                                    |

    | 9: end for                                       |

    | 10: return null, null;                           |

    |                                                  |

    |                                                  |


    #### <span id="page-1-3"></span>2.2 RIG Algorithm


    RIG algorithm was proposed by Rigby et al. [\[4\]](#page-7-3), in which they adapt
    the financial risk management measures to a developer turnover context to measure
    the risk posed to a project from developer turnover. Unlike the CST algorithm,
    RIG uses a blame-based approach to calculate code ownership of developers. The
    blame feature is implemented in version control systems such that a git-blame
    command assigns each line in a file to a developer who changed it last. The algorithm''s
    authors claim that this approach allows them to follow code ownership at a finer
    granularity. As per the algorithm, a line is considered abandoned if it is attributed
    to a developer who is no longer part of the project, and a file is considered
    abandoned when 90% of its files are abandoned. This high threshold makes sure
    that developers with trivial contributions are excluded. Algorithm [1](#page-1-1)
    shows the pseudo-code for the RIG algorithm. The algorithm starts by varying the
    size of developers from 1 to 200 who leave the project, as shown in line 1. Line
    3 shows the random sampling of developers of size who leave the project, and this
    random sampling is repeated 1,000 times for every value of . We limit these iterations
    to 10 instead of 1,000 because the algorithm takes a long time on relatively larger
    projects we chose. Moreover, following [\[2\]](#page-7-1), we return the lowest
    value of that resulted in the abandoned status of more than 50% of the files,
    as shown from lines 5-7. The authors in the original paper [\[4\]](#page-7-3)
    also calculate the likelihood of each group of developers leaving the project
    between lines 3-4, but we omit it since we are A noticeable characteristic of
    this algorithm is its non-deterministic nature, i.e., different results are produced
    for each execution of the algorithm because of the random sampling of the developers.
    Also, the algorithm may not


    return a valid result, as can be seen from line 10, which happens when no BFset
    results in more than 50% of abandon files.


    #### 2.3 Other Bus Factor Algorithms


    Another commit-based algorithm was proposed by Avelino et al. and computes the
    Degree of Authorship (DOA) of each file to identify the key developers [\[3\]](#page-7-2).
    The DOA value for a file is initialized when it is created by a certain developer
    . The DOA of increases when makes more commits on while it decreases if other
    developers commit to . Lastly, DOA values are normalized for each file with the
    developer with the highest DOA equal to 1. Developers with a DOA greater than
    0.75 are considered the authors of that file. We have not implemented this algorithm
    as part of our study and chose one commit-based algorithm only i.e., the CST algorithm
    explained in Section [2.1.](#page-1-2)


    The first algorithm for the automated calculation of BF from version control systems
    was proposed by Zazworka et al. [\[10\]](#page-7-5) in which each developer who
    made changes to a file, regardless of the number of commits, is considered the
    author of that file. Moreover, to find the BF, they look at each combination of
    developers ranging from 1 to (total developers). The BF is the largest combination
    of developers that a project may lose while the remaining developers still have
    knowledge of at least a part of the project''s files. Since the algorithm looks
    at each combination, it is shown in [\[11\]](#page-7-6) that the algorithm scales
    to a maximum of 30 developers only. It is also mentioned in [\[2\]](#page-7-1)
    that this algorithm did not terminate on projects even after running for more
    than three days. Hence, we did not include this algorithm in our study since all
    our projects'' total number of developers exceeds 30.


    #### <span id="page-2-0"></span>3 STUDY DESIGN


    In the following subsections, we will discuss in detail the database for GitHub
    projects that we use in this study, the bus factor algorithms that we implement,
    and how we validate the bus factor results. For the RIG algorithm, we executed
    our experimental runs in Google Colaboratory and on a server.


    ## 3.1 Database of GitHub data for HPC projects and other Metrics


    In this work, we used GitHub data from five open-source highperformance computing
    (HPC) software projects. Table [1](#page-3-0) shows some details about these projects.
    The GitHub data for a number of open-source projects, including these, has been
    stored, organized and parsed by us in a SQL database to be used for different
    research projects. The database contains computations for the lines of code changes
    (LOCC) and the cosine difference of code changes (changesize-cos), which are used
    for the bus factor calculation in our study for the CST algorithm.


    As mentioned in Section [2,](#page-1-0) AVL and CST algorithms are commitbased.
    However, commits are not a great metric to consider to measure code ownership.
    One reason is the difference in coding styles of different individuals, where
    some frequently commit after every small change while others prefer to commit
    once after completing the task. Moreover, a commit-based approach would consider
    a commit consisting of deletions equal to that of additions


    regardless of the actual contribution made [\[4\]](#page-7-3). Also, deletion
    removes the authorship of a certain piece of code from a developer and, hence,
    decreases the developer''s knowledge.


    With LOCC, each file is analyzed based on the number of lines the author has contributed
    with a commit. However, it will also consider the addition and deletion of blank
    spaces or comments as meaningful contributions. For the cosine difference of the
    changes, textdistance Python package is used to examine differences in text. It
    adds all the words from the changed lines to a word bank, places the added words
    in a column and deleted words in a row. Then it compares the columns and rows
    and assigns a numeric value of how much the line was changed. Given that, a change
    of variable name will be considered as a very small change under the cosine metric
    but may be a larger change under LOCC. Hence, using the cosine difference between
    the changed lines of code only considers the contributions with actual impact
    on the files, giving a comprehensive understanding of a developer''s contribution.


    The authors of the RIG algorithm give a similar reasoning for not using a commit-based
    approach and instead mention that a blame-based approach allows them to study
    code ownership at a finer granularity [\[4\]](#page-7-3).


    #### <span id="page-2-1"></span>Algorithm 2 CST Algorithm


    | Input cMetric, cstMetric, timeRange (opt.), directory (opt.), |

    |---------------------------------------------------------------|

    | branch(es) (opt.)                                             |

    | Result primaryDev, secondaryDev, busFactor                    |


    - 1: ← ;

    - 2: ← 1/;

    - 3: ← /2;

    - 4: Assign dataFrame for sum of cMetric values against each file to ;

    - 5: if == ℎ then

    - 6: for file in do

    - 7: ← () for ;

    - 8: ← () for on ;

    - 9: ← ;

    - 10: end for

    - 11: end if

    - 12: Assign a dataFrame for aggregated to directory/project level to ;

    - 13: for in do

    - 14: if ≥ then

    - 15: = + 1;

    - 16: else if ≥ then

    - 17: = + 1;

    - 18: end if

    - 19: end for

    - 20: ← +;


    #### 3.2 Implementation of Bus Factor Algorithms


    After reviewing the literature for the CST algorithm [\[1\]](#page-7-0), we aimed
    to use this algorithm on two new metrics. Before doing that, we decided to calculate
    BF on our selected projects using the tools provided by the authors of the CST
    algorithm. Two tools are needed to calculate the BF of a project, as provided
    by the authors. The


    <span id="page-3-0"></span>


    | Project   | Release Year | Contributors | Language | Description                                                |  |

    |-----------|--------------|--------------|----------|------------------------------------------------------------|--|

    | PETSc[5]  | 1994         | 207          | C        | Portable, Extensible Toolkit
    for Scientific Computation.   |  |

    | Spack[6]  | 2014         | 1,164        | Python   | Multi-platform package
    manager.                            |  |

    | Hypre[7]  | 2004         | 34           | C        | Library of high performance
    pre-conditioners and solvers.  |  |

    | Lammps[8] | 2016         | 224          | C++      | Large-scale Atomic/Molecular
    Massively Parallel Simulator. |  |

    | NWChem[9] | 1994         | 44           | Fortran  | Open Source High-Performance
    Computational Chemistry.      |  |


    ![](_page_3_Figure_1.jpeg)


    <span id="page-3-4"></span>![](_page_3_Figure_2.jpeg)


    <span id="page-3-6"></span>Table 2: Bus factors provided by the principal developers
    of the projects and the loss tolerance of each calculated using Equation [1.](#page-5-0)


    | Project | Key developers | Loss tolerance |  |  |

    |---------|----------------|----------------|--|--|

    | PETSc   | 7              | 4              |  |  |

    | Hypre   | 17             | 3              |  |  |

    | Lammps  | 4              | -              |  |  |

    | NWChem  | 4              | 2              |  |  |


    Figure 1: GReMCat Software Framework.


    first is called Gitana[1](#page-3-1) , which imports all the data from a GitHub
    repository to an SQL database and then exports it to a JSON file [\[12\]](#page-7-12).
    Second, the web-based bus factor calculating tool[2](#page-3-2) takes the JSON
    file as input and calculates BF based on the selected CST metric and thresholds.
    It is worth noting that exporting data from the database using Gitana takes a
    lot longer than importing the data from GitHub. For instance, running Gitana for
    the smallest project, Hypre took more than 8 hours.


    Moreover, we implemented the CST algorithm as part of the Git repository mining
    and analysis software (GReMCat)[3](#page-3-3) . The implementation design of the
    complete software framework can be seen in Figure [1.](#page-3-4) The CST algorithm
    is implemented in the patterns package and can be used from a Jupiter Notebook[4](#page-3-5)
    by calling the visualizer object. The authors of CST do not provide a pseudocode
    for their proposed algorithm in their paper [\[1\]](#page-7-0). We implemented
    it based on the explanation in [\[1\]](#page-7-0) and [\[2\]](#page-7-1) and its
    pseudocode for our implementation of multiple changes equally considered metric
    is presented in Algorithm [2.](#page-2-1) Instead of using the number of commits,
    we used the LOCC or change-size-cos values against each commit that is pre-computed
    in our database. The algorithm allows the user to input the branch, directory,
    time period, CST metric and the proposed data metrics they want to be used for
    the BF calculation. The time period can be year-year, month-month, a specific
    year or month.


    As mentioned in Section [2.2,](#page-1-3) the RIG algorithm is not commitbased,
    and due to the size and continuously changing nature of the git blame data, we
    do not store it in our database. In fact, we implemented RIG presented in Algorithm
    [1](#page-1-1) outside of GReMCat,


    <span id="page-3-5"></span><sup>4</sup>https://tinyurl.com/CSTnotebook


    and executed it on our selected projects in Google Colaboratory and on a server.
    The authors of the RIG algorithm do not provide a public tool or its code but
    it was fairly easy to understand and implement from their explanation in [\[4\]](#page-7-3)
    and also using the pseudocode provided in [\[2\]](#page-7-1).


    #### 3.3 Handling External Code and Aliases


    GReMCat already had its implementation of removing external code and libraries
    from the commits data of the projects in the database based on the names of directories.
    We used it for the CST algorithm and applied the same methodology to the RIG algorithm.
    Moreover, GReMCat uses Python fuzzywuzzy package [\[13\]](#page-7-13) for identifying
    multiple different names and emails associated with the same author. We used this
    implementation for both CST and RIG algorithms to handle aliases.


    #### <span id="page-3-7"></span>3.4 Validating Bus Factor Results


    In order to validate the Bus Factor results, we reached out to the principal developers
    of the five projects via email and asked them three questions: (a) Can you estimate
    the total number of key developers in the project? If your estimate is for a specific
    time period, please indicate the years. (b) Who do you consider your top project
    contributors overall or during a specific time period (please indicate which years)?
    (c) How many key developers could you lose (in a worst-case scenario) and still
    continue successfully with your project? We received answers from four out of
    five projects, while some chose not to name the developers. The answers we received
    are reported in Table [2,](#page-3-6) where the key developers correspond to answers
    to (a) while loss tolerance corresponds to answers to (c).


    Additionally, we also used the tool provided by the authors of the CST algorithm
    to get BF results for the projects. We were able to export GitHub data to JSON
    files for three of the projects while getting the BF results for only two of them.
    The tools continued


    <span id="page-3-1"></span><sup>1</sup>https://github.com/valeriocos/Gitana


    <span id="page-3-2"></span><sup>2</sup>https://github.com/SOM-Research/busfactor


    <span id="page-3-3"></span><sup>3</sup>https://github.com/HPCL/ideas-uo


    <span id="page-4-1"></span>Table 3: Bus Factor values calculated using change-size-cos
    and LOCC in CST, RIG, and the tools by the authors of commits-based CST.


    | Project | CST (cos) | CST (LOCC) | RIG | CST (commits) |

    |---------|-----------|------------|-----|---------------|

    | PETSc   | 32        | 28         | -   | -             |

    | Hypre   | 12        | 10         | 29  | 5             |

    | Lammps  | 24        | 23         | -   | -             |

    | NWChem  | 13        | 13         | -   | 7             |

    | Spack   | 211       | 172        | -   | -             |


    executing for larger projects like PETSc[\[5\]](#page-7-7) and Lammps[\[8\]](#page-7-10)
    for more than 48 hours without producing results.


    <span id="page-4-2"></span>![](_page_4_Figure_3.jpeg)


    ![](_page_4_Figure_4.jpeg)


    #### <span id="page-4-0"></span>4 RESULTS


    In this section, first we compare the project and directory-level BF results of
    the two algorithms with the feedback received from the principal developers and
    compare results from different CST metrics. Secondly, we look at the trend in
    bus factor values for the past five years. Lastly, we look into the performance
    of RIG algorithm by comparing its directory-level results.


    <span id="page-4-3"></span>![](_page_4_Figure_7.jpeg)


    ![](_page_4_Figure_8.jpeg)


    ![](_page_4_Figure_9.jpeg)


    Figure 3: Comparison between bus factor values for the combinations of the four
    CST metrics and the two data metrics.


    #### <span id="page-4-4"></span>4.1 Comparison for Accuracy of Results


    In this subsection, we answer the first of the research questions, which focuses
    on the impact of different metrics on the bus factor computation. The bus factors
    calculated by the CST algorithm with our proposed data metrics, the CST tool provided
    by the authors (commits-based), and our implementation of the RIG algorithm are
    reported in Table [3.](#page-4-1) The values reported are based on the mulchanges-equal
    CST metric. The tool for the CST algorithm took more than 8 hours to produce results
    for each of the two projects Hypre and NWChem. The calls to the SQL database containing
    the commits data timed out for the other three projects, given their large sizes.
    Moreover, the RIG algorithm only returned a bus factor for the Hypre project,
    which is the smallest in terms of the number of files and subsequently the git-blame
    data. For projects with many files and authors, the algorithm continued execution
    for more than 24 hours. Thus, the missing results in the Table [3](#page-4-1)
    highlight the limitations of the RIG algorithm and the tools of the CST algorithm
    given the large size of the projects.


    As mentioned in Section [3.4,](#page-3-7) for the accuracy of results and validation
    of the bus factor values in Table [3,](#page-4-1) we got in touch with the principal
    developers of each of the projects and recorded their responses in Table [2.](#page-3-6)
    By comparing the bus factor values in Table [2](#page-3-6) and [3,](#page-4-1)
    it can be seen that the values given by the developers do not exactly match the
    values by any of the algorithms. However, the error for the Hypre project, which
    is calculated as follows:


    <span id="page-5-0"></span>

    $$error = |BF\_{algorithm} - BF\_{prricipal\\_dev}|\tag{1}$$


    is the smallest for change-size-cos ( = 5) and LOCC ( = 7) based CST algorithm
    implemented as part of this study. = 12 for the commit-based CST [\[1\]](#page-7-0)
    and the RIG algorithm [\[4\]](#page-7-3). Lastly, we looked at the results from
    the commit-based CST algorithm and observed that the results were not in sync
    with the cut-offs mentioned in [\[1\]](#page-7-0) for primary and secondary developers,
    hence, the high error value.


    <span id="page-5-1"></span>![](_page_5_Figure_3.jpeg)


    ![](_page_5_Figure_4.jpeg)


    Figure 4: Trend in project level bus factors for last five years for LOCC and
    change-size-cos based CST. The yellow bars represent the total number of developers.
    The dotted lines represent the percentage of BF developers from the total corresponding
    to the right y-axis.


    Along with comparing the bus factor values, we also looked at their accuracy in
    identifying the developers who are part of the bus factor result by each algorithm.
    Only the principal developers of the Lammps and NWChem project shared the names
    of the developers constituting the bus factor. For privacy reasons, we won''t
    be sharing the names in this paper. However, from our comparative study, we can
    state that the developers identified by the principal developers for both Lammps
    and NWChem are at the top of the sorted list for change-size-cos and LOCC-based
    CST algorithm. The top developer identified by the tool in [\[1\]](#page-7-0)
    for NWChem is not even part of the developers named by the NWChem''s principal
    developer. This shows that the threshold for primary and secondary developers
    in [\[1\]](#page-7-0) is not the best case and also that change-size-cos and LOCCbased
    CST algorithm is more accurate. RIG performed the worst by identifying only 5
    out of 12 (change-size-cos) or 5 out of 10 (LOCC) developers correctly for the
    Hypre project. It is important to note that the five projects chosen for this
    study are large in terms of files, number of developers, commits, and git-blame
    data. This highlighted the limitation of [\[12\]](#page-7-12), [\[14\]](#page-7-14),
    and [\[15\]](#page-7-15) when it comes to large GitHub projects, as results were
    not returned for the three larger projects.


    In Figure [2,](#page-4-2) we look into the bus factors for the most recently updated
    directories of PETSc and NWChem projects. We compare the bus factor values of
    the change-size-cos and LOCC-based CST algorithm with the RIG algorithm. It can
    be clearly seen that the results from the RIG algorithm are significantly different
    and higher than not only the CST algorithm but also the data provided by the principal
    developers of the projects. Hence, we found the RIG algorithm to be the worst
    performer.


    Moreover, we present comparative plots for the four CST algorithm metrics explained
    in Section [2.1](#page-1-2) and also the two data metrics change-size-cos and
    LOCC in Figure [3](#page-4-3) for Hypre and PETSc. It can be seen from the graphs
    that there is not a significant variation in the results for each combination.
    Given that information, we focused our study on the mul-changes-equal metric.
    However, as mentioned in [\[1\]](#page-7-0), a CST metric can be chosen as per
    the requirements and processes followed by an organization for version control.


    #### 4.2 Trend in bus factors over time


    In this subsection, we seek the answer to the second research question, i.e.,
    the role of the bus factor in guiding effort allocation towards hiring and knowledge
    transfer. The intention is to study the applicability of the bus factor and the
    guidance these results provide to principal developers and managers. Intuitively,
    the bus factor of a project or directory will indicate the concentration of knowledge
    within a certain number of people. If that number is small, then principal developers
    or project managers can work on effort allocation for hiring new people to work
    on that project. Another thing that can be done is to ensure knowledge transfer
    to other developers within the organization. For our study, we looked at the trend
    in bus factor over the past five years for the selected projects. Figure [4](#page-5-1)
    shows the trend in bus factor since 2018 for PETSc and Spack. The yellow bars
    represent the total number of developers; the left y-axis, along with solid lines,
    represents the bus factor value, while the right y-axis and the dashed lines are
    for the percentage of developers that are part of the bus factor. For both projects,
    we can see that the developers with higher knowledge of the projects are decreasing
    in later years, reaching the minimum value in the year 2022. Knowledge of this
    trend can help the principal developers or managers hire new people or initiate
    the knowledge transfer process to other existing developers for these projects.


    Sometimes, looking at the trend in bus factor for the whole project does not provide
    the best view of the knowledge concentration and the risk of the project in terms
    of employee turnover.


    <span id="page-6-0"></span>![](_page_6_Figure_0.jpeg)


    ![](_page_6_Figure_1.jpeg)


    ![](_page_6_Figure_2.jpeg)


    (c) Spack: **var/spack/**


    Figure 5: Trend in directory level bus factors for last five years for LOCC and
    change-size-cos based CST. The yellow bars represent the total number of developers.
    The dotted lines represent the percentage of BF developers from the total corresponding
    to the right y-axis.


    Given that, looking at individual directories or important parts of the projects
    is more helpful. Figure [5](#page-6-0) shows the trend in bus factor values for
    major directories of PETSc and Spack. With this narrowed-down view, a more informed
    decision can be taken for the important parts of the projects. Figure [5](#page-6-0)
    (c) particularly shows a steep drop in the bus factor value for var/spack/ directory
    of the project, which cannot be picked up from the holistic view shown in Figure
    [4](#page-5-1) (b).


    #### 4.3 Performance comparison of BF Algorithms


    This subsection focuses on answering the research question about the accuracy
    of results and the performance of the bus factor algorithms. For that, we wanted
    to look at each algorithm to compare and contrast results. Most of this question
    is answered for the CST algorithm in Section [4.1,](#page-4-4) where we compared
    the results from the CST algorithm with RIG using Figure [2,](#page-4-2) so here
    we focused on the RIG algorithm and its non-deterministic nature.


    <span id="page-6-1"></span>![](_page_6_Figure_9.jpeg)


    ![](_page_6_Figure_10.jpeg)


    As mentioned in Section [2.2,](#page-1-3) the RIG algorithm is non-deterministic,
    i.e., it does not produce the same results for different executions. We collected
    data from two runs for different directories of the five projects to see the variation
    in results by the RIG algorithm. In Figure [6,](#page-6-1) we show results for
    two of the projects, PETSc and NWChem. It can be seen that none of the executions
    resulted in the same result for any of the directories. The difference is significant
    for some, including petsc/src/vec in (a) and nwchem/src/ccd


    in (b). We also looked at the developer names resulting from the algorithm for
    each execution and did not find a common pattern of similarity among results,
    which further confirms the random nature of the RIG algorithm.


    The non-deterministic and random nature of the RIG algorithm automatically makes
    the CST algorithm a better choice. This is further corroborated by the responses
    of the principal developers, as shown in Table [3](#page-4-1) and the lower errors
    for the CST algorithm. Moreover, Rigby et al. themselves claim in [\[4\]](#page-7-3)
    that bus factor scenarios computed using loss percentages are unrealistic.


    #### 5 FUTURE WORK


    There are many future dimensions to this work. One way to extend this work is
    to look at the impact of different threshold values for the algorithms with the
    proposed data metrics. Since authors of both CST and RIG algorithm do not give
    reasoning behind the choice of all the chosen threshold and cutoff values, this
    can be an interesting study. The results can help in making a more informed choice
    behind these values with reasoning provided. Moreover, using a more data-driven
    approach for the validation of results with trained machine learning models can
    help in eliminating the threats to correctness of the validation process. The
    large amount of mined GitHub data can be used for training purposes.


    #### <span id="page-7-4"></span>6 CONCLUSION


    It is common for open-source projects to face the risk of key developers leaving
    the project. This risk is even higher with long-term and large projects. To judge
    the risk posed to the projects or the severity of it, the concentration of knowledge
    among its developers can be measured. This measurement is known as the bus factor
    of the project and there are several algorithms proposed for its calculation.
    Most of these algorithms use the commits data from version control systems. We
    proposed the use of two other metrics i.e. lines of code changes (LOCC) and cosine
    difference of lines of code (change-size-cos) and tested them with the CST algorithm.
    We also used a git-blame based RIG algorithm on our use-case of five High Performance
    Computing projects on GitHub. Along with complete projects, we also looked at
    the bus factor values of the major directories in each. We did a comparative study
    for the accuracy, similarity in results and trend in BF values on the two algorithms
    and also the metrics proposed by us. We validated our results from the principal
    developers of the selected projects which showed LOCC and change-size-cos to be
    more accurate than commits. Our implementation of the CST algorithm is scalable
    when compared to the online available tools by Cosentino at el. Lastly, we demonstrated
    with examples how looking at the trend in bus factor values over time can guide
    principal developers in effort allocation.


    #### REFERENCES


    - <span id="page-7-0"></span>[1] Valerio Cosentino, Javier Canovas Izquierdo,
    and Jordi Cabot. Assessing the bus factor of git repositories. 03 2015.

    - <span id="page-7-1"></span>[2] Mívian Ferreira, Marco Tulio Valente, and Kecia
    Ferreira. A comparison of three algorithms for computing truck factors. In 2017
    IEEE/ACM 25th International Conference on Program Comprehension (ICPC), pages
    207–217, 2017.

    - <span id="page-7-2"></span>[3] G. Avelino, L. Passos, A. Hora, and M. Valente.
    A novel approach for estimating truck factors. In 2016 IEEE 24th International
    Conference on Program Comprehension (ICPC), pages 1–10, Los Alamitos, CA, USA,
    may 2016. IEEE Computer Society.

    - <span id="page-7-3"></span>[4] Peter C. Rigby, Yue Cai Zhu, Samuel M. Donadelli,
    and Audris Mockus. Quantifying and mitigating turnover-induced knowledge loss:
    Case studies of chrome and a project at avaya. In Proceedings of the 38th International
    Conference on Software Engineering, ICSE ''16, page 1006–1016, New York, NY, USA,
    2016. Association for Computing Machinery.

    - <span id="page-7-8"></span><span id="page-7-7"></span>[5] Petsc project. Available
    online at: [https://github.com/petsc/petsc.](https://github.com/petsc/petsc)

    - <span id="page-7-9"></span>[6] Spack project. Available online at: [https://github.com/spack/spack.](https://github.com/spack/spack)

    - <span id="page-7-10"></span>[7] Hypre project. Available online at: [https://github.com/hypre-space/hypre.](https://github.com/hypre-space/hypre)

    - <span id="page-7-11"></span>[8] Lammps project. Available online at: [https://github.com/lammps/lammps.](https://github.com/lammps/lammps)
    [9] Nwchem project. Available online at: [https://github.com/nwchemgit/nwchem.](https://github.com/nwchemgit/nwchem)

    - <span id="page-7-5"></span>[10] Nico Zazworka, Kai Stapel, Eric Knauss, Forrest
    Shull, Victor R. Basili, and Kurt Schneider. Are developers complying with the
    process: An xp study. In Proceedings of the 2010 ACM-IEEE International Symposium
    on Empirical Software Engineering and Measurement, ESEM ''10, New York, NY, USA,
    2010. Association for Computing Machinery.

    - <span id="page-7-6"></span>[11] Filippo Ricca, Alessandro Marchetto, and Marco
    Torchiano. On the difficulty of computing the truck factor. volume 6759, pages
    337–351, 06 2011.

    - <span id="page-7-12"></span>[12] Valerio Cosentino, Javier Canovas Izquierdo,
    and Jordi Cabot. Gitana: A software project inspector. Science of Computer Programming,
    153, 12 2017.

    - <span id="page-7-14"></span><span id="page-7-13"></span>[13] SeatGeek Inc. fuzzywuzzy:
    Fuzzy String Matching in Python, 2014. [14] Valerio Cosentino, Javier Canovas
    Izquierdo, and Jordi Cabot. Gitana: a sqlbased project activity inspector. Available
    online at: [https://github.com/SOM-](https://github.com/SOM-Research/Gitana)[Research/Gitana.](https://github.com/SOM-Research/Gitana)

    - <span id="page-7-15"></span>[15] Valerio Cosentino. Bus factor analyzer. Available
    online at: [https://github.com/](https://github.com/SOM-Research/busfactor) [SOM-Research/busfactor.](https://github.com/SOM-Research/busfactor)'
- title: "T-FREX: A Transformer-based Feature Extraction Method from Mobile App\n\
    \  Reviews"
  abstract: 'Mobile app reviews are a large-scale data source for software-related

    knowledge generation activities, including software maintenance, evolution and

    feedback analysis. Effective extraction of features (i.e., functionalities or

    characteristics) from these reviews is key to support analysis on the

    acceptance of these features, identification of relevant new feature requests

    and prioritization of feature development, among others. Traditional methods

    focus on syntactic pattern-based approaches, typically context-agnostic,

    evaluated on a closed set of apps, difficult to replicate and limited to a

    reduced set and domain of apps. Meanwhile, the pervasiveness of Large Language

    Models (LLMs) based on the Transformer architecture in software engineering

    tasks lays the groundwork for empirical evaluation of the performance of these

    models to support feature extraction. In this study, we present T-FREX, a

    Transformer-based, fully automatic approach for mobile app review feature

    extraction. First, we collect a set of ground truth features from users in a

    real crowdsourced software recommendation platform and transfer them

    automatically into a dataset of app reviews. Then, we use this newly created

    dataset to fine-tune multiple LLMs on a named entity recognition task under

    different data configurations. We assess the performance of T-FREX with respect

    to this ground truth, and we complement our analysis by comparing T-FREX with
    a

    baseline method from the field. Finally, we assess the quality of new features

    predicted by T-FREX through an external human evaluation. Results show that

    T-FREX outperforms on average the traditional syntactic-based method,

    especially when discovering new features from a domain for which the model has

    been fine-tuned.'
  url: http://arxiv.org/abs/2401.03833v1
  keywords: feature extraction, mobile apps, reviews, token classification, named
    entity recognition, large language models
  document: '# T-FREX: A Transformer-based Feature Extraction Method from Mobile App
    Reviews


    Quim Motger<sup>1</sup> , Alessio Miaschi<sup>2</sup> , Felice Dell''Orletta<sup>2</sup>
    , Xavier Franch<sup>1</sup> , Jordi Marco<sup>1</sup>


    <sup>1</sup>Universitat Politècnica de Catalunya, Barcelona


    {quim.motger,xavier.franch,jordi.marco}@upc.edu


    2 Institute for Computational Linguistics "A. Zampolli" (CNR-ILC), ItaliaNLP Lab,
    Pisa


    {alessio.miaschi,felice.dellorletta}@ilc.cnr.it


    *Abstract*—Mobile app reviews are a large-scale data source for software-related
    knowledge generation activities, including software maintenance, evolution and
    feedback analysis. Effective extraction of features (i.e., functionalities or
    characteristics) from these reviews is key to support analysis on the acceptance
    of these features, identification of relevant new feature requests and prioritization
    of feature development, among others. Traditional methods focus on syntactic pattern-based
    approaches, typically context-agnostic, evaluated on a closed set of apps, difficult
    to replicate and limited to a reduced set and domain of apps. Meanwhile, the pervasiveness
    of Large Language Models (LLMs) based on the Transformer architecture in software
    engineering tasks lays the groundwork for empirical evaluation of the performance
    of these models to support feature extraction. In this study, we present T-FREX,
    a Transformer-based, fully automatic approach for mobile app review feature extraction.
    First, we collect a set of ground truth features from users in a real crowdsourced
    software recommendation platform and transfer them automatically into a dataset
    of app reviews. Then, we use this newly created dataset to fine-tune multiple
    LLMs on a named entity recognition task under different data configurations. We
    assess the performance of T-FREX with respect to this ground truth, and we complement
    our analysis by comparing T-FREX with a baseline method from the field. Finally,
    we assess the quality of new features predicted by T-FREX through an external
    human evaluation. Results show that T-FREX outperforms on average the traditional
    syntacticbased method, especially when discovering new features from a domain
    for which the model has been fine-tuned.


    *Index Terms*—feature extraction, mobile apps, reviews, token classification,
    named entity recognition, large language models


    ## I. INTRODUCTION


    Mobile app repositories provide valuable access to timely large-scale datasets
    of software-related information [\[1\]](#page-10-0). These repositories include
    heterogeneous, multiple-purpose platforms, from app stores to sideloading repositories
    and search engines [\[2\]](#page-10-1). One of the most popular contributions
    across these platforms is the publication of app reviews, in which users express
    multiple facets such as personal opinions or experiences, bug reports, inquiries
    or requests [\[3\]](#page-10-2). This information is relevant to multiple software
    engineering processes, including requirements elicitation and prioritization,
    release planning, validation analysis and software evolution [\[3\]](#page-10-2)–[\[7\]](#page-10-3).


    App features are considered a core descriptor for understanding and categorizing
    app reviews [\[8\]](#page-10-4)–[\[10\]](#page-10-5). In this context, a feature
    is considered as a distinct function or capability within a mobile application
    serving a particular purpose or need [\[11\]](#page-10-6). App feature extraction
    supports featurerelated knowledge generation, in which mobile app developers can
    potentially rely on to improve user experience, enhance app functionality, identify
    user preferences, and make datadriven decisions for app development strategies
    [\[3\]](#page-10-2), [\[12\]](#page-10-7), [\[13\]](#page-10-8). Consequently,
    mining large amounts of app reviews to extract app features has become a relevant
    task. Nevertheless, mining features from app reviews presents particular challenges.
    It requires the daily analysis of thousands of short documents, each with a limited
    length, composed of an average of a few dozen words per review [\[14\]](#page-10-9).
    Beyond measurable characteristics, user-generated documents tend to present multiple
    informal writing styles and vocabulary, including misspelt words, repetitions
    or cross-language terminology [\[15\]](#page-10-10), polarized or biased information,
    or even noisy and spam content [\[16\]](#page-10-11).


    Consolidated approaches rely on syntactic pattern-matching techniques to retrieve
    features from app descriptions and reviews [\[11\]](#page-10-6). Nevertheless,
    several challenges emerge from their applicability, including limited replicability,
    unavailability of data and a lack of user evaluation [\[11\]](#page-10-6). Furthermore,
    rule-based strategies for knowledge generation can be brittle to identify complex
    patterns, domain-specific terminology, unexpected contents and contextual knowledge,
    which affects the generalization of these techniques [\[17\]](#page-10-12). To
    overcome these challenges, deep learning strategies, and in particular Large Language
    Models (LLMs) based on the Transformer architecture [\[18\]](#page-10-13), have
    shown promising results in multiple software-related data mining tasks. These
    approaches leverage the knowledge embedded in these pre-trained models by extending
    their capabilities through task-specific supervised fine-tuning tasks such as
    sentiment analysis, text classification or named-entity recognition (NER) [\[19\]](#page-10-14)–[\[22\]](#page-10-15).


    In this paper, we present T-FREX (*Transformer-based FeatuRe EXtraction*), a novel
    approach to support feature extraction from app reviews using LLMs. Our proposal
    redefines the app feature extraction problem as a NER task, a specific type of
    token classification in which tokens referring to a particular entity type (e.g.
    dates, geopolitical entities, features, etc.) are labelled as such. Our main contributions
    are[1](#page-0-0) : (1) a


    <span id="page-0-0"></span><sup>1</sup>GitHub repository:<https://github.com/gessi-chatbots/t-frex/>


    | Telegram Features                                                                       |
    Suggest and vote on featu                      |

    |-----------------------------------------------------------------------------------------|------------------------------------------------|

    | Lightweight<br>Telegram consumes less device resources compared to similar apps.        |                                                |

    | Ad-free<br>0<br>Telegram doesn''t contain any form of external advertising.              |                                                |

    | · End-to-End Encryption<br>Telegram has E2E Encryption, for entire or parts
    of the app. |                                                |

    | Dark Mode<br>Telegram supports dark mode for comfortable usage in low light
    conditions. |                                                |

    | Portable<br>Support for Themes<br>IFTTT Integration                                     |
    Self Destructing Messages<br>Works Offline     |

    | Cloud Sync   Multiple Account support   VoiP Calls<br>Two-factor Authentication         |
    Encrypted Chat                                 |

    | Stickers Chat Bot<br>Large File Transfer<br>Multi Device Support                        |
    Instant Messaging<br>Bots                      |

    | Video Calling<br>Channels<br>Share Videos<br>Secret chats                               |
    Cloud based<br>Animated stickers               |

    | Persistent History<br>Integrated File Sharing                                           |
    Folders Video Conferencing<br>Security focused |


    <span id="page-1-0"></span>Fig. 1. Sample of crowdsourced user annotated features
    in a software recommendation platform (https://alternativeto.net/) for the Telegram
    app.


    Transformer-based, fully automatic approach for the extraction of mobile app features
    from user reviews; (2) an extensive evaluation of the performance of multiple
    Transformer-based LLMs [\[18\]](#page-10-13) in different classification scenarios;
    (3) a reusable fine-tuned model and a ground-truth dataset of annotated app reviews,
    based on crowdsourced annotated app features extracted from a popular software
    recommendation platform and automatically transferred into the corpus of app reviews.


    ## II. BACKGROUND


    ## <span id="page-1-4"></span><span id="page-1-3"></span>*A. Mobile app features*


    There are multiple definitions of the term *feature* within related literature
    according to different dimensions: *(i)* scope: definitions refer to functionalities
    [\[11\]](#page-10-6) (e.g., *send message*), quality aspects [\[23\]](#page-10-16)
    (e.g., *lightweight*) or both [\[24\]](#page-10-17); *(ii)* abstraction: feature
    expressions vary from generic, high-level categories (e.g., *communication*) to
    specific, actionable aspects (e.g., *integrated file sharing*) [\[13\]](#page-10-8);
    *(iii)* formalization: definitions range from a particular focus on the requirements
    engineering field, using terms like *logically related system capabilities* and
    *set of functional requirements* [\[25\]](#page-10-18), to a more user-oriented
    perspective, referring to a *property* [\[26\]](#page-10-19) or *characteristic*
    [\[27\]](#page-10-20) of a mobile app. In the context of grey literature and industrial
    applications, both functional and quality *features* with different levels of
    abstraction and formalization are often presented as descriptors at the same hierarchical
    level. Figure [1](#page-1-0) illustrates the set of crowdsourced user annotated
    features (i.e., collaboratively labelled by multiple users) for a given mobile
    app in a software recommendation platform, for which we find different examples
    in terms of scope (e.g., *portable* vs. *instant messaging*), abstraction (e.g.,
    *channels* vs. *share videos*) and formalization (e.g., *file sharing* vs. *send
    file*).


    To accommodate our research to both scientific and industrial applications, in
    this research, we define a feature as a distinct functionality or capability within
    a mobile application that serves a particular purpose or provides a specific benefit
    to the user. It is a functional component or attribute of the software designed
    to perform a well-defined task or address a particular user need, enhancing the
    utility of the app.


    ## <span id="page-1-2"></span>*B. NER using LLMs*


    Our proposal is based on redefining feature extraction as a NER task, one of the
    most common token classification tasks in the context of natural language understanding
    (NLU) and for which LLMs have been largely used in the past few years [\[28\]](#page-10-21).
    Given a set of app reviews R of size n, the tokenized representation of a given
    r<sup>i</sup> ∈ R is expressed as T(ri) = [ti1, ti2, ..., tim], where each tij
    ∈ T(ri) represents a token from the original review r<sup>i</sup> . The *feature
    extraction* task consists in identifying sequences of contiguous tokens Tif ⊆
    T(ri) composing the written expression of a feature. Consequently, features are
    extracted within the context of a particular app review. This context dimension
    is key, as a particular sequence of tokens T<sup>f</sup> might refer to a feature
    within a given review for a given app, but the same sequence T<sup>f</sup> might
    not refer to a feature in another context. To this end, the dynamic attention
    mechanism enables LLMs to attend to crucial contextual information within the
    context of a review from a mobile app of a specific category. For example, in
    the review sentence "*I find that managing my channels is quite frustrating*",
    the word *channels* refers to an actual feature of a communication mobile app.
    Contrarily, in the review sentence "*This art app offers diverse channels for
    unleashing creativity*", which belongs to a mobile app from the arts and design
    category, *channels* is not an actual feature, despite having the same Part-of-Speech
    (PoS) tag (NOUN) and syntactic dependency role (direct object). Traditional syntactic-based
    approaches lack the potential to determine how contextual information suits a
    more fine-grained selection of features.


    In token-based classification tasks, the input can range from a sentence to a
    paragraph or even an entire document. Our approach is defined at the sentence
    level, allowing for more granular analysis and facilitating efficient processing.
    Therefore, tokenization is refined by splitting the reviews into sentences, T(ri)
    = [si1, si2, ..., sip], where each sentence is a subsequence of the original tokenization,
    sik ⊆ T(ri). Given a sentence input sik, a token classification model assigns
    one unique label to each token, indicating whether the token is the beginning
    of a feature named entity (*B-feature*), an internally contained element of a
    feature entity (*I-feature*), or none (*O*). Figure [2](#page-1-1) illustrates
    the NER output on a mobile app review. For simplicity, this example is architecture-agnostic,
    meaning that we consider each word from the original review individually, ignoring
    special tokens or multiple tokens referring to the same word. While numerous models
    are publicly available for generic types of NER (e.g., dates, locations, persons,
    e-mail addresses...) and for some specific domains (e.g. medical and legal domains)
    [\[29\]](#page-10-22)–[\[31\]](#page-10-23), to the best of our knowledge there
    are no proposals for the identification of app feature entities exploiting fine-tuned
    LLMs.


    <span id="page-1-1"></span>Fig. 2. Example of NER task on a mobile app review.


    ## III. RESEARCH METHOD


    <span id="page-2-2"></span>Our research aims to demonstrate the hypothesis that
    Transformer-based LLMs can significantly enhance mobile app feature extraction
    tasks by redefining this process as a token classification problem. Consequently,
    we conducted a sample study as defined by Stol and Fitzgerald [\[32\]](#page-10-24),
    which aims at maximizing the generalization of the feature extraction task over
    the population of mobile apps publicly available in mobile app repositories. To
    this end, we leverage crowdsourced annotated data from actual mobile app users,
    using AlternativeTo[2](#page-2-0) as the main source for ground-truth knowledge
    generation, as a relevant representative of search engines in the context of mobile
    app repositories [\[33\]](#page-10-25). This platform provides, for each mobile
    app, a list of features which have been suggested and ranked by real users, while
    they are being used for navigating the catalogue of mobile applications (as illustrated
    previously in Figure [1\)](#page-1-0). More details on the data collection and
    annotation processes are depicted in Section [IV-A.](#page-2-1)


    To assess the validity of T-FREX, we guide our research through the following
    research questions:


    RQ1) What is the effectiveness of T-FREX using different LLMs with respect to
    crowdsourced user-annotated features? RQ2) What is the effectiveness of T-FREX
    compared to traditional feature extraction methods (i.e., SAFE approach)? RQ3)
    What is the effectiveness of T-FREX with respect to new, undocumented features?


    RQ1 is defined to assess the effectiveness of our approach in terms of functional
    suitability. We present the design and development results of an end-to-end pipeline
    for finetuning and using different types of LLMs under different data configurations.
    This analysis will allow us to gain a deeper understanding of how different LLM
    architectures behave under different training datasets. Moreover, RQ1 provides
    token-level empirical evaluation results for the overall quality of the NER (i.e.
    token classification) task.


    RQ2 is intended to compare T-FREX performance at feature level with respect to
    a standard baseline method in the field of feature extraction. We selected the
    SAFE approach as a baseline for a comparative analysis [\[34\]](#page-10-26),
    as it is considered the most consolidated approach for mobile app feature extraction
    in the software engineering field (see Section [VII](#page-9-0) for more details
    on related work and comparison with other approaches). Given that the original
    study does not provide a publicly available replication package, we built on the
    work of Shahe et al. [\[17\]](#page-10-12), who conducted a replication study
    and distributed a replicated development of the SAFE approach.


    Finally, RQ3 is designed to analyse how T-FREX generalizes and overcomes the constraints
    of limited, domain-specific datasets. While the use of data generated and consumed
    by real users offers multiple advantages, we have no control in the extent and
    representativeness with respect to the complete set of features exposed by mobile
    apps. This entails that our model might predict features that are not included
    in the ground truth (i.e., *false positive*), while this might simply relate to
    incompleteness of user annotated data. Hence, we propose to overcome this limitation
    while also gaining deeper insights on generalization of our model by conducting
    a human evaluation on new features predicted by our model (i.e., features not
    included in the ground truth dataset).


    ## IV. DESIGN


    Figure [3](#page-3-0) shows an overview of our research. We elaborate the details
    in the upcoming subsections.


    ## <span id="page-2-1"></span>*A. Data Collection and Annotation*


    While there is related work publishing gold datasets with expert feature annotations
    [\[11\]](#page-10-6), our approach is intended to leverage real user crowdsourced
    annotation, as well as to assess its generalization and applicability in real,
    practical uses cases. However, published datasets are typically internally annotated
    by human coders, very limited in terms of number of applications (e.g., between
    8-10 mobile apps) and domains, and focused on productivity and communication apps,
    excluding more expert, domain-specific categories like navigation, sports or weather
    [\[11\]](#page-10-6), [\[13\]](#page-10-8), [\[17\]](#page-10-12), [\[34\]](#page-10-26),
    [\[35\]](#page-10-27). Therefore, we opted to build our own dataset of mobile
    app reviews with annotated features generated by real users. We built on the work
    of Motger et al. [\[33\]](#page-10-25), who collected and published a sample dataset
    of 639 mobile apps with 622,370 reviews from multiple categories, to which we
    applied the following extensions:


    - We extended the mobile app metadata with the official category from Google Play
    as gold knowledge for the category-based analysis of the feature extraction task.
    The original dataset included custom defined categories based on a keyword-based
    search of domain-related terms. Instead, we propose to use the taxonomy of categories
    defined by Google Play [\[36\]](#page-10-28), which is considered as the largest,
    most relevant mobile app store worldwide [\[2\]](#page-10-1).

    - We limited the mobile apps included in our study to the 10 most frequent Google
    Play categories in the original dataset in number of mobile apps, excluding those
    categories with a minimal representation (≤ 5 apps) to ensure relevant statistical
    inference. Exceptionally, we excluded "GAME" related categories, considered as
    a special kind of mobile apps with a different *feature* conception [\[11\]](#page-10-6).

    - We extended the annotated features for a given mobile app using AlternativeTo
    features as ground truth. These features are voted by logged-in users of the software
    recommendation platform, and they are ranked and sorted by absolute number of
    votes. To obtain this data, we reused the web scraping data collection mechanisms
    originally developed by Motger et al. [\[33\]](#page-10-25).


    Table [I](#page-4-0) summarizes the resulting dataset distributed according to
    the Google Play category to which the apps belong to. It is important to highlight
    that multiple distinct features might belong to multiple categories (e.g., *video
    call* is a feature for both SOCIAL and COMMUNICATION mobile apps). Notice that
    the last row refers to the total number


    <span id="page-2-0"></span><sup>2</sup>https://alternativeto.net/


    ![](_page_3_Figure_0.jpeg)


    <span id="page-3-0"></span>Fig. 3. Research design overview.


    of feature annotations in the complete corpus of annotated reviews, which we explain
    in more detail in Section [IV-B.](#page-3-1)


    ## <span id="page-3-1"></span>*B. Data Pre-processing and Feature Transfer*


    Let F = {f1, f2, ..., fq} be the set of crowdsourced feature annotations defined
    at app entity level. To train and evaluate our model, these features are transferred
    into the corpus of app reviews R. This results in the annotation of all tokens
    t ∈ T(r) for each review r ∈ R with the corresponding name entity label L = {*O*,
    *B-feature*, *I-feature*}. To this end, we used Stanza''s neural pipeline [\[37\]](#page-10-29)
    to pre-process and transform both corpus F and R into their correspondent CoNLL-U
    format representation [\[38\]](#page-10-30), which includes for each token t a
    list of syntactic and morphological features. We use this format to facilitate
    replicability of our approach and reusability of the resulting dataset. Specifically,
    the pre-processing pipeline included: (*i*) tokenization, (*ii*) multi-word token
    expansion, (*iii*) PoS tagging, (*iv*) morphological feature extraction, and (*v*)
    lemmatization. Feature transfer is then applied to exact matches between the CoNLL
    representation of a given feature f and a contiguous sequence of tokens of a given
    review r so that f ⊆ T(r) after pre-processing r and f. Given that not all features
    f ∈ F relate to actual features in different contexts, we scoped this label transfer
    to features originally extracted from the same application to which the review
    belonged to. This means that, for ground truth generation, the example used in
    Section [II-B](#page-1-2) for context-dependent features (i.e., use of *channels*
    as a feature from communication apps) is not considered as an actual feature in
    the context of a different app (i.e., the arts and design app). As a result, the
    CoNLL-U representation of R is extended with an additional annotation for each
    token t, represented by one of the labels in L = {*O*, *B-feature*, *I-feature*}.


    Table [I](#page-4-0) reports the total amount of feature annotations transferred
    into the corpus of reviews R (last row).


    ## *C. Model Fine-tuning*


    The pre-processed and annotated corpus R serves as the primary input for training
    various LLMs under diverse data configurations. In this section, we elaborate
    on the reasoning behind our choices regarding the selection, preparation, and
    training of these models.


    <span id="page-3-2"></span>*1) Model Selection:* State-of-the-art LLMs encompass
    multiple architectures (e.g., encoder-only, decoder-only, encoderdecoder), modelling
    paradigms (e.g., discriminative, generative), pre-training tasks (e.g., masked
    language modelling or MLM, permutation language modelling), size and scale, among
    other descriptors [\[39\]](#page-11-0). Appropriate model selection is not trivial
    and is often neglected or undermined. For our experiments, we opted for decoder-only
    models, due to their better suitability for handling classification tasks. Moreover,
    we avoided testing large-scale generative models due to their considerable dimensions
    and, therefore, their practical limitations in terms of memory and time constraints.
    Below we provide the selection of LLM for our research, including those features
    suited for our task and their role in the evaluation.


    - BERT, one of the first groundbreaking LLMs, is celebrated for its bidirectional
    nuanced contextual understanding [\[40\]](#page-11-1). Trained on a vast corpus
    using MLM as pre-training objective, it excels in capturing context from both
    left and right, empowering it for diverse token-level tasks [\[41\]](#page-11-2).
    Consequently, we select BERT as a baseline for the use of LLMs in the context
    of feature extraction.

    - RoBERTa is considered a refinement on BERT''s architecture and training process
    [\[42\]](#page-11-3). It achieves heightened performance through extended pre-training
    on a larger dataset and augmented data, resulting in more robust language representations.
    It also uses MLM for pretraining and outperforms BERT in various scenarios [\[42\]](#page-11-3),
    making it a valuable addition to our model evaluation.

    - XLNet combines autoregressive and bidirectional training by considering all
    possible permutations of a sentence''s words during pre-training [\[43\]](#page-11-4).
    This methodology fosters improved contextual understanding and dependency modelling
    among tokens, surpassing the conventional models. Unlike BERT and RoBERTa, XLNet
    uses a permutation-based training objective, allowing it to model token dependencies
    differently.


    For each of these models, we consider both base and large versions (i.e., in terms
    of number of model parameters).


    <span id="page-3-3"></span>*2) Data Preparation:* We split the dataset of annotated
    reviews (reported in Table [I\)](#page-4-0) under different data configurations
    to support different analytical perspectives.


    • Out-of-domain. The original dataset is split according to the category to which
    the app review belongs to. We then use these data partitions to run 10 different
    fine-tuning


    <span id="page-4-0"></span>TABLE I DISTRIBUTION OF MOBILE APPS, REVIEWS AND FEATURES
    IN THE DATASET, SORTED BY DECREASING ORDER BY NUMBER OF DISTINCT FEATURES. CATEGORY
    ABBREVIATIONS REFER TO: PRODUCTIVITY (PROD.), COMMUNICATION (COMM.), PERSONALIZATION
    (PERS.).


    | Metric                | PROD.   | COMM.   | TOOLS  | SOCIAL | HEALTH | PERS.
    | TRAVEL | MAPS  | LIFESTYLE | WEATHER | ALL     |

    |-----------------------|---------|---------|--------|--------|--------|-------|--------|-------|-----------|---------|---------|

    | #apps                 | 137     | 51      | 58     | 14     | 75     | 6     |
    19     | 31    | 12        | 65      | 468     |

    | #reviews              | 7,348   | 7,003   | 4,321  | 819    | 2,154  | 112   |
    530    | 284   | 344       | 901     | 23,816  |

    | #sentences            | 8,604   | 8,135   | 5,402  | 899    | 2,330  | 118   |
    602    | 315   | 391       | 984     | 27,780  |

    | #tokens               | 148,172 | 134,833 | 93,395 | 15,597 | 40,907 | 2,022
    | 11,105 | 5,868 | 8,044     | 15,439  | 475,382 |

    | #features (distinct)  | 77      | 54      | 50     | 26     | 23     | 19    |
    17     | 12    | 10        | 7       | 198     |

    | #features (annotated) | 9,866   | 9,800   | 6,626  | 1,049  | 2,524  | 127   |
    662    | 333   | 419       | 1,037   | 32,443  |


    processes, using 9 out of 10 categories for training the model and using the remaining
    category for testing. This setup evaluates the model''s capacity to generalize
    feature extraction to unfamiliar, new app domains.


    • In-domain. The original dataset is split under a 10-fold cross-validation setup
    with a balanced distribution of app reviews from each category, focusing on evaluating
    the model''s performance when predicting features within its domain of expertise.
    This setup assesses the model''s proficiency in feature extraction for categories
    closely aligned with its training data.


    We exclude from all training sets all references to features included in its corresponding
    testing set. This allows evaluation of the model''s performance to recognize tokens
    (extract features) for which it was not specifically fine-tuned.


    *3) Training Configuration:* For each model (Section [IV-C1\)](#page-3-2) and
    data setting (Section [IV-C2\)](#page-3-3), we configure and run a token classification
    fine-tuning process. First, we implement the preprocessing stage, which includes
    using a proper tokenizer according to the model architecture. BERT uses WordPiece
    tokenization and introduces [CLS] and [SEP] tokens for classification and separation.
    In contrast, RoBERTa and XLNet utilize SentencePiece tokenization, and they use
    only [SEP] tokens for separation while omitting the [CLS] token. Additionally,
    RoBERTa and XLNet employ a more aggressive subword tokenization approach, capturing
    finer linguistic details by breaking words into smaller subword units. This implies
    that a single word in the original review might be transformed into multiple tokens,
    which also affects the performance analysis and accuracy evaluation of the token
    classification (and ultimately, feature extraction) method. Second, we define
    the evaluation method for reporting and computing quality metrics (see Section
    [IV-D\)](#page-4-1). Third, in order to adjust the experiments to the available
    computational resources and model characteristics, we define the training parameters
    for each fine-tuning process (available in the replication package). Finally,
    the output of each fine-tuning process (including checkpoints, predictions and
    quality metrics) for the best performing checkpoint (i.e., with the lowest evaluation
    loss) are saved and reported.


    ## <span id="page-4-1"></span>*D. Evaluation design*


    We structure evaluation results in alignment with the formulation of research
    questions (Section [III\)](#page-2-2). In this section, we focus on the design
    of the evaluation plan.


    *1) Token-based ground-truth (RQ1):* Each fine-tuning process depicted in Section
    [IV-C2](#page-3-3) uses a token-level evaluation method for computing quality
    metrics for token prediction. This implies that results evaluate the model quality
    to predict whether a specific token is the beginning of a feature expression (*B-feature*),
    the inner part of a feature expression (*I-feature*) or none of the above (*O*).


    *2) Baseline feature extraction (RQ2):* Each fine-tuning process depicted in Section
    [IV-C2](#page-3-3) uses a feature-level evaluation method for computing quality
    metrics for feature extraction. Consequently, instead of computing prediction
    quality at token level, in this stage we evaluate the quality prediction of complete
    sequences of tokens T<sup>f</sup> composing a whole feature according to the ground-truth
    data set. We compare the performance of our approach with respect to the baseline
    method selected for feature extraction (i.e., SAFE [\[34\]](#page-10-26)).


    *3) New features (RQ3):* We select the best performing model to collect all new
    features predicted by our model. These features are then submitted to a human
    evaluation process to measure the prediction quality of new features. The human
    evaluation is composed of three main stages:


    - Data preparation. We collect all features predicted by the best-performing model
    (based on RQ1 and RQ2) for each test set under each data configuration scenario,
    as depicted in Section [IV-C2.](#page-3-3) We then remove all features included
    in the complete ground-truth annotated dataset, keeping exclusively newly reported
    features.

    - Set up. We iteratively elaborate and refine the guidelines, the selection of
    examples and the definition of feature annotation tasks. A task is defined as
    a sub set of review sentences, each one of them with a potential feature candidate
    which the annotator can either confirm (*Yes*), reject (*No*), or mark as not
    clear (*I don''t know*). Figure [4](#page-4-2) shows an example of a feature annotation
    question.


    | App name: Boosted Time Tracker<br>App category: PRODUCTIVITY                                                           |

    |------------------------------------------------------------------------------------------------------------------------|

    | Review: Timer is not included as a free feature but the app is very helpful
    .                                          |

    | Is the following expression mentioned as a reference to a feature of the<br>mobile
    application in the previous review? |

    | Feature: timer                                                                                                         |

    | O<br>Yes                                                                                                               |

    | O<br>No                                                                                                                |

    | I don''t know                                                                                                           |


    <span id="page-4-2"></span>Fig. 4. Example of a feature annotation question for
    human evaluation.


    <span id="page-5-0"></span>


    | Analysis      | Category  | Metric    | BERTbase | BERTlarge | RoBERTabase |
    RoBERTalarge | XLNetbase | XLNetlarge |

    |---------------|-----------|-----------|----------|-----------|-------------|--------------|-----------|------------|

    |               |           | precision | 0.799    | 0.734     | 0.539       |
    0.287        | 0.582     | 0.687      |

    |               | PROD.     | recall    | 0.343    | 0.320     | 0.244       |
    0.062        | 0.330     | 0.331      |

    |               |           | F1        | 0.480    | 0.445     | 0.335       |
    0.102        | 0.421     | 0.447      |

    |               |           | precision | 0.407    | 0.502     | 0.455       |
    0.384        | 0.438     | 0.412      |

    |               | COMM.     | recall    | 0.156    | 0.202     | 0.173       |
    0.276        | 0.261     | 0.317      |

    |               |           | F1        | 0.225    | 0.288     | 0.251       |
    0.321        | 0.327     | 0.358      |

    |               |           | precision | 0.513    | 0.570     | 0.462       |
    0.221        | 0.423     | 0.214      |

    |               | TOOLS     | recall    | 0.085    | 0.138     | 0.102       |
    0.065        | 0.204     | 0.026      |

    |               |           | F1        | 0.145    | 0.222     | 0.167       |
    0.100        | 0.275     | 0.046      |

    |               |           | precision | 0.606    | 0.696     | 0.621       |
    0.610        | 0.734     | 0.688      |

    |               | SOCIAL    | recall    | 0.513    | 0.410     | 0.462       |
    0.462        | 0.603     | 0.679      |

    |               |           | F1        | 0.556    | 0.516     | 0.529       |
    0.526        | 0.662     | 0.684      |

    |               |           | precision | 0.482    | 0.503     | 0.658       |
    0.584        | 0.710     | 0.663      |

    |               | HEALTH    | recall    | 0.179    | 0.240     | 0.127       |
    0.224        | 0.373     | 0.384      |

    | Out-of-domain |           | F1        | 0.261    | 0.325     | 0.213       |
    0.323        | 0.489     | 0.486      |

    |               | PERS.     | precision | 0.731    | 0.955     | 0.933       |
    0.973        | 0.972     | 1.000      |

    |               |           | recall    | 0.500    | 0.553     | 0.737       |
    0.947        | 0.921     | 0.684      |

    |               |           | F1        | 0.594    | 0.700     | 0.824       |
    0.960        | 0.946     | 0.813      |

    |               |           | precision | 0.773    | 0.647     | 0.720       |
    0.682        | 0.481     | 0.613      |

    |               | TRAVEL    | recall    | 0.708    | 0.458     | 0.750       |
    0.625        | 0.542     | 0.792      |

    |               |           | F1        | 0.739    | 0.537     | 0.735       |
    0.652        | 0.510     | 0.691      |

    |               |           | precision | 0.029    | 0.120     | 0.045       |
    0.077        | 0.560     | 0.467      |

    |               | MAPS      | recall    | 0.021    | 0.063     | 0.063       |
    0.063        | 0.292     | 0.146      |

    |               |           | F1        | 0.024    | 0.082     | 0.053       |
    0.069        | 0.384     | 0.222      |

    |               |           | precision | 0.500    | 0.400     | 0.600       |
    0.600        | 0.800     | 1.000      |

    |               | LIFESTYLE | recall    | 0.400    | 0.400     | 0.600       |
    0.600        | 0.800     | 0.200      |

    |               |           | F1        | 0.444    | 0.400     | 0.600       |
    0.600        | 0.800     | 0.333      |

    |               |           | precision | 0.619    | 0.642     | 0.273       |
    0.129        | 0.571     | 0.769      |

    |               | WEATHER   | recall    | 0.232    | 0.607     | 0.107       |
    0.071        | 0.500     | 0.179      |

    |               |           | F1        | 0.338    | 0.624     | 0.154       |
    0.092        | 0.533     | 0.290      |

    |               |           | precision | 0.546    | 0.577     | 0.531       |
    0.455        | 0.627     | 0.651      |

    |               | Average   | recall    | 0.314    | 0.339     | 0.336       |
    0.339        | 0.482     | 0.374      |

    |               |           | F1        | 0.381    | 0.414     | 0.386       |
    0.374        | 0.535     | 0.437      |

    |               |           | precision | 0.596    | 0.719     | 0.668       |
    0.688        | 0.679     | 0.761      |

    | In-domain     | Average   | recall    | 0.488    | 0.582     | 0.569       |
    0.509        | 0.519     | 0.573      |

    |               |           | F1        | 0.532    | 0.637     | 0.611       |
    0.571        | 0.582     | 0.646      |


    TABLE II TOKEN CLASSIFICATION EVALUATION RESULTS.


    This includes: app name, link to Google Play (for app context), category, review
    sentence, question and feature candidate. In this stage, we used a test task which
    is sequentially annotated by internal members of this research study, until an
    acceptable agreement is reached. After each annotation process, the collected
    feedback is used for refining the guidelines and list of examples used for designing
    the evaluation task.


    • Evaluation. The full data set of new features is submitted for human evaluation
    through sequential iterations in different batches. We used Prolific [\[44\]](#page-11-5)
    as a crowdsourced annotation platform to reach users worldwide and Quest-Base
    [\[45\]](#page-11-6) for the creation of the tasks. Each annotator is limited
    to participate in a single task. For each task, we include a subset of 5 control
    questions using ground-truth annotated features to reject low-confidence annotators.
    On each task, we measure the proportion of features confirmed (*Yes*), which relates
    to the precision of new features. Additionally, for inter-rater reliability, we
    report (1) the average pairwise agreement, and (2) F1, which has been used in
    related work as an appropriate and effective inter-rater agreement measure for
    the evaluation of text annotations such as features in app reviews [\[11\]](#page-10-6).


    ## V. EVALUATION


    ## *A. Token-based ground-truth*


    Table [II](#page-5-0) reports the precision, recall and F1 metrics for all data
    configurations and all selected models. Given that we do not have ground-truth
    data for non-feature entities (*true negatives*), we exclude accuracy from the
    results.


    *1) Out-of-domain Feature Extraction:* In this configuration, each block in Table
    [II](#page-5-0) for a given category C refers to the quality metrics reported
    when fine-tuning the specified model with the set of reviews from all categories
    from Table [I](#page-4-0) except C. Metrics refer then to the test set of reviews
    belonging to C. For example, the first 3 rows in Table [II](#page-5-0) report
    the performance of each model for predicting features included in app reviews
    from the PRODUCTIVITY when training the model with app reviews from all categories
    except PRODUCTIVITY. In this scenario, the best precision is reported by BERTbase
    (0.799), while the lowest is reported by RoBERTalarge (0.287). The last 3 rows
    in the *out-of-domain* block are the average value for each metric and each model
    configuration. For example, the highest average recall among all categories is
    reported by XLNetbase (0.482), followed by XLNetlarge (0.374).


    Complementarily, we extend the visualization of the results in two dimensions.
    A vertical analysis illustrates the comparison between different categories for
    a given model configuration. We use a colour-code pattern to highlight the best
    (green) and worst (red) performing category for each model. For example, for the
    baseline model (BERTbase), prediction of PRODUCTIVITY features reports the highest
    precision (0.799), while TRAVEL reports the highest recall (0.708), F1 (0.739)
    and accuracy (0.966). On the other hand, predicting new features from the MAPS
    domain reports the lowest overall accuracy for BERTbase. If we focus on F1, predicting
    PERSONALIZATION features under a set-up where the model was not trained under
    features of this domain reports the best results for 5 out of 6 model configurations.
    Contrarily, predicting MAPS features under the same set-up reports the lowest
    overall token-level prediction quality for 4 out of 6 model configurations. For
    a better understanding of this phenomenon, Figure [5](#page-6-0) showcases the
    degree (expressed in % of tokens) of lexical overlapping of the set of reviews
    of a given category (Y axis) with respect to the set of reviews from another category
    (X axis). We exclusively considered verbs, nouns and adjectives. For example,
    the cell on (0,0) coordinates illustrates the proportion of tokens from WEATHER
    apps that are also present in reviews from the COMMUNICATION app (around 15%).
    Consistently with our previous results, PERSONAL-IZATION presents a high overlap
    with all other categories (30- 35%), which showcases that the training set of
    reviews used for this configuration includes a high proportion of lexicon that
    the model has also been trained with. PERSONALIZATION apps often expose extended
    functions and customization capabilities to other apps, including widgets, wallpapers,
    stickers, themes and optimization tools. On the other hand, MAPS apps report a
    very low lexical overlap with respect to all categories (< 5%). This implies that
    the training set of reviews used for this setup did not include any of the category-specific
    lexicon from the navigational domain (e.g., GPS, GPX, POI...). Consequently, out-of-domain
    prediction of MAPS features becomes a challenging task. Similar conclusions can
    be reached by observing other categories. For example, PRODUCTIVITY apps include
    a large sub set of apps with features present in multiple categories (e.g., calling,
    note-taking, file-sharing).


    In addition, a horizontal analysis in Table [II](#page-5-0) illustrates the best-performing
    model for a given category. We use bold-face style and a special icon to highlight
    the best model for each category according to each metric. Additionally, we use
    the same strategy to report best average metrics for out-of-domain and in-domain
    analysis. Overall, RoBERTa models report the worst results for all metrics in
    almost each category, except for PERSONALIZATION apps when focusing on recall
    (0.947) and F1 (0.960). For BERT checkpoints, both base (PRODUC-TIVITY, TRAVEL)
    and large (COMMUNICATION, TOOLS) report the best metrics for precision. Nevertheless,
    XLNet variants excel in the majority of categories, especially if we focus on
    recall. Specifically, on average, XLNetbase reports the best recall (0.482) and
    F1 (0.535), while XLNetlarge reports the highest precision (0.652), but only by
    a small difference with respect to XLNetbase (+0.024).


    Given the limitations of the ground-truth generation, preci-


    ![](_page_6_Figure_3.jpeg)


    <span id="page-6-0"></span>Fig. 5. Lexical overlap between reviews from different
    categories.


    sion results must be interpreted under certain constraints. The lack of a guarantee
    of the exhaustivity of the crowdsourced features annotated by users implies that
    there might be tokens predicted by our model that are rejected as tokens from
    a feature (*false positives*), while they might be part of an actual feature (*true
    positives*) that was not indexed in the original set of features. Given that precision
    is the proportion of correct feature tokens with respect to all reported named
    entities, we argue that precision values reported above can be interpreted as
    the lower threshold of the minimum precision raised by our approach. On the other
    hand, recall (i.e., the proportion of retrieved named entities with respect to
    all ground-truth named entities) can be considered as a gold metric for quality
    analysis. All in all, for out-of-domain feature extraction, we argue that the
    best performing model is XLNetbase.


    *2) In-domain Feature Extraction:* The last rows in Table [II](#page-5-0) report
    average results for the 10-fold cross-validation analysis using the complete dataset
    in Table [I.](#page-4-0) While features in the test set for each data partition
    are not present in the training set (as explained in Section [IV-C2\)](#page-3-3),
    domain-related features from the same category are distributed in balance across
    all data splits. As expected, average results for all metrics are significantly
    higher in the in-domain analysis with respect to the out-ofdomain analysis. This
    result indicates that language models enhance their feature extraction capabilities
    for a specific category C when their training dataset includes reviews from that
    category, even if the predicted features are absent from the original training
    dataset. This underscores the relevance of domain-specific training data for the
    improvement of model performance in feature extraction tasks.


    XLNetlarge reports the best results for precision (0.761) and F1 (0.646). In addition,
    XLNetlarge recall (0.573) is only slightly below (−0.009) with respect to BERTlarge
    recall (0.582). Consequently, we argue that the best performing model for in-domain
    feature extraction is XLNetlarge.


    ## *B. Baseline feature extraction*


    Table [III](#page-7-0) reports out-of-domain and in-domain results for the selected
    feature extraction baseline method (i.e., SAFE),


    |                                                                            |
    TABLE III |  |  |

    |----------------------------------------------------------------------------|-----------|--|--|

    | FEATURE EXTRACTION EVALUATION RESULTS AND COMPARISON WITH BASELINE METHOD. |           |  |  |


    <span id="page-7-0"></span>


    |           |           | Out-of-domain |       |       |        |        |       |        |       |           |
    In-domain |         |         |

    |-----------|-----------|---------------|-------|-------|--------|--------|-------|--------|-------|-----------|-----------|---------|---------|

    | Method    | Metric    | PROD          | COMM  | TOOLS | SOCIAL | HEALTH | PERS  |
    TRAVEL | MAPS  | LIFESTYLE | WEATHER   | Average | Average |

    |           | precision | 0.309         | 0.235 | 0.299 | 0.286  | 0.298  | 0.195
    | 0.300  | 0.074 | 0.500     | 0.413     | 0.301   | 0.193   |

    | SAFE      | recall    | 0.300         | 0.229 | 0.292 | 0.329  | 0.274  | 0.229
    | 0.375  | 0.106 | 0.500     | 0.481     | 0.321   | 0.215   |

    |           | F1        | 0.304         | 0.232 | 0.295 | 0.306  | 0.285  | 0.211
    | 0.333  | 0.087 | 0.500     | 0.444     | 0.310   | 0.199   |

    |           | precision | 0.667         | 0.278 | 0.392 | 0.361  | 0.335  | 0.895
    | 0.591  | 0.000 | 0.500     | 0.690     | 0.471   | 0.575   |

    | BERTbase  | recall    | 0.128         | 0.131 | 0.222 | 0.385  | 0.186  | 0.447
    | 0.542  | 0.000 | 0.600     | 0.357     | 0.300   | 0.419   |

    |           | F1        | 0.215         | 0.178 | 0.284 | 0.373  | 0.240  | 0.596
    | 0.565  | 0.000 | 0.545     | 0.471     | 0.347   | 0.485   |

    |           | precision | 0.399         | 0.479 | 0.347 | 0.561  | 0.494  | 0.912
    | 0.538  | 0.200 | 0.600     | 0.502     | 0.503   | 0.631   |

    | XLNetbase | recall    | 0.244         | 0.145 | 0.168 | 0.590  | 0.402  | 0.816
    | 0.583  | 0.188 | 0.600     | 0.432     | 0.417   | 0.572   |

    |           | F1        | 0.303         | 0.222 | 0.226 | 0.575  | 0.443  | 0.861
    | 0.560  | 0.194 | 0.600     | 0.464     | 0.445   | 0.600   |


    our baseline model (i.e., BERTbase) and best-performing model (i.e., XLNetbase).
    Due to space constraints, we exclude results from other models (available in the
    replication package). Metrics in Table [III](#page-7-0) are computed using exact
    matches with the whole feature (i.e., *B-feature* tokens followed by none or any
    sequence of *I-feature* tokens). For presentation purposes, we invert the dimensions
    of Table [III](#page-7-0) with respect to Table [II,](#page-5-0) meaning that
    the horizontal dimensions relate to the comparison of categories (green/red),
    and the vertical dimension relates to different methods (bold and icon).


    On average, both the baseline model (BERTbase) and the best-performing model (XLNetbase)
    surpass SAFE''s quality metrics for out-of-domain and in-domain analyses. The
    only exception is the BERTbase recall (0.300), which is slightly below (−0.021)
    from SAFE. XLNetbase improves significantly the performance with respect to BERTbase,
    especially for recall (+0.117 for out-of-domain, +0.153 for in-domain). On a category-level,
    for the out-of-domain analysis, LLM-based approaches report a higher precision
    in all categories, and a higher recall for 6 out of 10 categories. On a horizontal
    analysis, similarly to results in Table [II,](#page-5-0) predicting out-of-domain
    features from MAPS reviews reports the worst results in all scenarios, while the
    best results are provided by LIFESTYLE and PERSONALIZATION. If we focus on the
    categories for which SAFE outperforms T-FREX on the out-of-domain analysis, we
    realize that the original SAFE approach was designed using feature syntactic patterns
    from apps belonging to these domains (PRODUCTIVITY, COMMUNICATION, TOOLS). Nevertheless,
    as the out-of-domain configuration implies that the model was not trained using
    any reviews from these categories, certain limitations are expected. However,
    the in-domain analysis, which illustrates the performance of T-FREX discovering
    new features from a domain for which it was fine-tuned, reports a substantial
    improvement for precision (+0.438), recall (+0.357) and F1 (+0.401).


    ## *C. New Features*


    Table [IV](#page-8-0) reports data and metrics resulted from the evaluation of
    new features. We discuss this results in alignment with the evaluation process
    depicted in Section [IV-D.](#page-4-1)


    *1) Data preparation:* We select XLNetbase as the best model for out-of-domain
    feature extraction (focusing on recall as the most reliable quality metric). After
    processing all reviews under each out-of-domain data configuration, we collected
    a total amount of 1,067 unique new features (1,956 annotations in total). We excluded
    3 out of 10 categories from this analysis (PERSONALIZATION, LIFESTYLE, WEATHER)
    where either 1 or even no new features were extracted. The whole set of 1,956
    review sentences was split into 21 annotation tasks. Each task included 95 new
    feature annotations (as in Figure [4\)](#page-4-2) plus 5 control questions, with
    100 annotations in total per task. Additionally, we prepared 2 ground-truth tasks
    of the same size containing at least 1 instance of each of the distinct features
    available in the crowdsourced data set in Table [I.](#page-4-0) The purpose of
    these tasks is to compare the overall precision of undocumented features with
    respect to the overall, perceived precision from users with respect to the ground-truth.


    *2) Evaluation set up:* We conducted up to 3 iterations of internal (i.e., expert)
    annotations for the test task. Each iteration was performed by a different annotator,
    providing feedback about the guidelines, the examples, the required time to conduct
    the task, and the difficulty. At the end of each iteration, we refined the guidelines
    (focusing on reducing ambiguity), extended the examples (focusing on covering
    exhaustively the different kinds of features) and adjusted the expected resolution
    time. As a result, we decided to keep task size to 100 features and an estimated
    average time of 15'' per task. On the test task, we report an average pairwise
    agreement between internal annotators of 73.3%, and an average F1 of 0.719. Complementarily,
    for internal evaluation, given that guidelines and annotators were selected and
    instructed under a test set-up, and all of them annotated the same features, we
    measured the Fleiss kappa agreement between all annotators, reporting a substantial
    degree of agreement (0.718).


    *3) Evaluation:* We set as acceptance criteria for annotators to reply correctly
    to 4 out of 5 control questions, and we ran multiple iterations until reaching
    5 accepted annotators for each task. We recruit participants by taking into consideration
    only fluent English speakers and without any language-related disorders. Each
    annotator is paid \$2 per task (around 15'') for their participation. Category-level
    and aggregated results are reported in Table [IV.](#page-8-0) The gold label for
    each feature was assigned using a voting-based approach between all annotators
    for each review sentence and feature (any ties were resolved as ''*I don''t know*''
    to reduce any biases of results). For the whole dataset, 61.2% of new features
    were confirmed as true features, which leads to a precision of 0.612 for new features.
    Results are generally balanced across categories with minor deviations, being
    TOOLS the category with less accepted features (58.4%)


    <span id="page-8-0"></span>


    | EVALUATION OF NEW FEATURES |       |                       |       |        |        |        |       |       |                      |                 |

    |----------------------------|-------|-----------------------|-------|--------|--------|--------|-------|-------|----------------------|-----------------|

    |                            |       | Evaluation (external) |       |        |        |        |       |       |
    Gr. truth (external) | Test (internal) |

    |                            | PROD. | COMM.                 | TOOLS | SOCIAL
    | HEALTH | TRAVEL | MAPS  | TOTAL | TOTAL                | TOTAL           |

    | #features (annotations)    | 459   | 643                   | 560   | 44     |
    218    | 8      | 29    | 1956  | 190                  | 95              |

    | #features (distinct)       | 294   | 383                   | 363   | 36     |
    155    | 8      | 19    | 1067  | 144                  | 17              |

    | % Yes                      | 68.6% | 62.3%                 | 58.4% | 63.6%  |
    59.4%  | 66.7%  | 58.6% | 61.2% | 77.0%                | 70.0%           |

    | % No                       | 28.8% | 35.0%                 | 41.7% | 34.1%  |
    39.3%  | 33.3%  | 41.4% | 37.0% | 23.0%                | 28.0%           |

    | % I don''t know             | 1.6%  | 2.7%                  | 1.8%  | 2.2%   |
    0.6%   | 0.0%   | 0.0%  | 1.9%  | 0.0%                 | 2.0%            |

    | Pairwise agreement         | 58.5% | 58.0%                 | 62.1% | 60.2%  |
    62.4%  | 57.7%  | 69.7% | 58.5% | 58.0%                | 73.3%           |

    | F1                         | 0.585 | 0.566                 | 0.622 | 0.594  |
    0.631  | 0.639  | 0.717 | 0.613 | 0.546                | 0.719           |


    TABLE IV EVALUATION OF NEW FEATURES


    and PRODUCTIVITY the category with more accepted features (68.6%). For the ground-truth
    validation with external annotators (including only actual features), 77.0% of
    feature annotations were accepted as true features, while 23.0% were rejected.
    While there is a difference of +15.8% with respect to the new features, this confirms
    the cognitive difficulty for actual users on the formalization of a *feature*.


    ## VI. DISCUSSION


    ## *A. Research Questions*


    Based on the evaluation results, we consolidate and report the response to each
    research question defined in Section [III.](#page-2-2)


    RQ1) Table [II](#page-5-0) provides a comprehensive empirical evaluation of the
    effectiveness of the T-FREX approach at tokenlevel. Among the different model
    configurations, XLNet approaches (benefitting from autoregressive methods to learn
    bidirectional contexts) seem to provide better results on average, especially
    for the out-of-domain analysis. Concerning data configurations, T-FREX proves
    to be significantly effective for an in-domain setting. Since mobile app markets
    are generally stable and the emergence of new domains is rare, the in-domain configuration
    is the most practical and common application for feature extraction tasks. Nevertheless,
    out-of-domain extraction also proves effective for certain domains and model configurations,
    particularly when the domain lexicon is not highly specialized. These results
    underscore T-FREX''s ability to discover new features even from an unknown domain.
    Consequently, the results for both in-domain and out-of-domain analyses highlight
    the adaptability and potential generalization of T-FREX across various settings.


    RQ2) Table [III](#page-7-0) presents a comprehensive empirical evaluation of the
    feature extraction method compared to the SAFE approach. On average, LLM-based
    token classification consistently outperforms SAFE across all metrics. Notably,
    there is a significant performance improvement when transitioning from the baseline
    model BERTbase to XLNetbase. The limitations of a deterministic approach, such
    as a nonspecialized vocabulary and context-agnostic behaviour, are particularly
    pronounced in specific domains or categories. This holds true even when the LLMs
    are evaluated in an out-ofdomain setting. Moreover, in an in-domain analysis,
    LLMs quickly overcome these limitations and significantly enhance their performance.
    They become adept at accurately predicting new features within domains they have
    been fine-tuned for. In addition to leveraging pre-trained LLMs, our supervised
    approach can be iteratively refined and tailored to specific domains, serving
    specialized markets and application categories. T-FREX enables the collection
    of recent app reviews and the integration of up-to-date crowdsourced features,
    continually enhancing feature extraction through subsequent fine-tuning iterations.
    This approach facilitates effective context integration, adaptation to new domains,
    and responsiveness to users'' vocabulary, syntax, and colloquial language—capabilities
    notably limited in SAFE and other feature extraction techniques.


    RQ3) Table [IV](#page-8-0) illustrates in detail the human evaluation process
    of new features. Results support the original hypothesis that the ground-truth
    dataset of features is limited. Despite these constraints, the human evaluation
    confirms the effectiveness of the model in the retrieval of new features. Furthermore,
    it is noteworthy that the precision of newly reported features surpasses the average
    precision of groundtruth features in the out-of-domain analysis. As knowledge
    from crowdsourced repositories is not typically exhaustive, results underscore
    T-FREX''s ability to automatically supplement feature annotations. Instead of
    relying on manual user input, user feedback (i.e., reviews) can serve as a valuable
    resource for suggesting features in a streamlined manner, employing a voting-based
    mechanism for automatically extracted features. This setting can potentially address
    the limitations of manual annotations and reduce the imbalance in feature representation
    across apps with similar user interaction levels.


    ## *B. Threats to Validity*


    We assess the constraints of our study by considering the validity threats as
    outlined by Wohlin et al. [\[46\]](#page-11-7).


    Concerning construct and internal validity, we mainly relate to the formalization
    of *features*, including its definition (used for the human evaluation in RQ3),
    exemplification and analysis. Related work illustrates cognitive differences in
    formalizing the limits of a natural language expression for a given feature (see
    Section [II-A\)](#page-1-3). This includes the generation of the ground-truth
    dataset by transferring app annotations to reviews. To mitigate internal bias,
    we use a reliable crowdsourced software recommendation platform with real user-annotated
    features that are used in practice for navigation, indexing, and software comparison.
    Moreover, we provide a detailed analysis (see Section [II\)](#page-1-4) to consolidate
    accepted criteria and descriptors for the formalization of a feature in the context
    of mobile apps.


    Concerning external validity, delegating the assignment of ground-truth feature
    annotations to an external entity leads to a lack of control of the annotation
    process and the annotators (i.e, the users). While this entails some risks, we
    argue that using annotations from real users in a practical environment provides
    significant benefits to an LLM-based feature extraction approach. This becomes
    especially relevant in the context of processing reviews generated by users themselves.
    Additionally, RQ3 is also designed to overcome and measure the impact of missing
    features in the ground truth. Concerning the latter, the human evaluation process
    also entails external validity concerns, especially for the lack of control of
    the human annotators and their potential bias. To reduce this risk, we included
    control questions to assess the reliability of each annotation task, and we used
    a voting-based approach to consider the most common prediction among all annotators.


    Concerning conclusion validity, the main concern is derived from the interpretation
    and generalization of the performance of each evaluation setting. For this reason,
    we included in this study two different analytical perspectives (i.e., out-of-domain
    and in-domain), each including a detailed perspective on the performance of all
    metrics for all selected models. For the out-of-domain analysis, we also include
    a detailed perspective on the performance of each category. Rather than providing
    a gold method in a one-fits-all fashion, we aim to provide researchers with enough
    information to interpret the strengths and limitations of each method under each
    configuration.


    ## VII. RELATED WORK


    <span id="page-9-0"></span>Dabrowski et al. recently conducted an evaluation and
    replication study focusing on mining techniques of app reviews for multiple tasks,
    including feature extraction [\[11\]](#page-10-6). Related work mainly refers
    to the SAFE approach as the most consolidated technique for feature extraction
    [\[34\]](#page-10-26). They identified and formalized a set of 18 common Part-of-Speech
    patterns from app descriptions and app reviews used to express app features. Through
    a pattern-matching approach, complemented by semantic similarity and synonymity
    resolution, they identify potential feature expressions. Nevertheless, reported
    performance in the original study is limited, especially when applying the technique
    to reviews, where a lot of noise features (i.e., false positives) are reported,
    leading to low precision. Furthermore, the original code and dataset are not publicly
    available. Consequently, replication studies have reimplemented and built new
    annotated data sets using groundtruth from instructed coders [\[11\]](#page-10-6),
    [\[47\]](#page-11-8), reporting lower quality than originally reported, especially
    for direct feature match.


    Similar conclusions apply to other related works applying the same syntactic-based
    strategy, either for early work [\[13\]](#page-10-8) or more up-to-date solutions
    like the ReUS approach [\[35\]](#page-10-27). In addition to previous limitations,
    evaluation strategies (including replication studies [\[11\]](#page-10-6)) are
    limited to instructed internal coders. The lack of the user perspective is key,
    especially when analysing user-generated documents (i.e., reviews). Moreover,
    they all focus on a reduced set of apps (8-10) and even fewer domains, and there
    is no formal evaluation of a categoryoriented analysis for their ability to generalize
    to new domains. Nevertheless, they are still used in practice for feature-based
    knowledge generation from mobile app repositories [\[48\]](#page-11-9), [\[49\]](#page-11-10).


    Few works can be found on the application of LLMs for the task of feature extraction.
    Similarly to previous studies [\[13\]](#page-10-8), [\[34\]](#page-10-26), [\[35\]](#page-10-27),
    the TransFeatEx tool applies PoS patterns by leveraging the knowledge embedded
    in a RoBERTa model to extract syntactic and semantic annotations [\[50\]](#page-11-11).
    Nevertheless, their contribution is presented as a tool without further evaluation
    or a concrete proposal for configuring the pattern template or the sentiment analysis
    thresholds. KEFE [\[51\]](#page-11-12) uses features extracted using PoS patterns
    as input to a BERT model for text classification of correct and incorrect features.
    However, they focus on the application of this technique for app descriptions,
    using the extracted features to transfer potential feature matches with user reviews.
    Consequently, feature knowledge is limited to developer-generated documentation.


    ## VIII. CONCLUSIONS AND FUTURE WORK


    In this research, we conducted an empirical evaluation of a token classification-based
    approach using LLMs to support feature extraction in the context of mobile app
    reviews. We explored and discussed in detail the performance of multiple models
    (BERT, RoBERTa, XLNet) under different data configurations (out-of-domain vs.
    in-domain) from multiple app categories. The evaluation provides a comprehensive
    perspective of the performance of each approach under each data configuration.
    Furthermore, ground-truth feature annotations by real users and external human
    evaluation contribute to extending the scope and body of knowledge of the feature
    landscape. All in all, our proposal leverages the potential of LLMs to benefit
    from contextualized knowledge and to overcome the limitations of syntactic-based
    approaches. Research and industrial applications focusing on software evolution
    analysis can benefit from the outcomes of this study, either by replicating T-FREX
    as a fully automatic process for feature extraction (either with different data
    sets or different models), by using the ground-truth data set of annotated reviews,
    or by using any of the fine-tuned models distributed for replication.


    As future work, we are currently working on the potential of extending the pre-training
    of the LLMs used for evaluation with a large data set of app reviews. Evaluation
    will focus on token classification and feature extraction metrics with respect
    to the original models. Furthermore, we plan to gain a better understanding of
    the inner workings of these models by analysing the embedded knowledge across
    multiple layers. To this end, hidden layers can be used as input for probing classifiers
    to determine to what extent the given layer embeds relevant knowledge to support
    feature extraction.


    ## ACKNOWLEDGMENTS


    With the support from the Secretariat for Universities and Research of the Ministry
    of Business and Knowledge of the Government of Catalonia and the European Social
    Fund. This paper has been funded by the Spanish Ministerio de Ciencia e Innovación
    under project / funding scheme PID2020-117191RB-I00 / AEI/10.13039/501100011033.
    Alessio Miaschi and Felice Dell''Orletta have also been supported by the PNRR
    project FAIR - Future AI Research (PE00000013), under the NRRP MUR program funded
    by the NextGenerationEU.


    ## REFERENCES


    - <span id="page-10-0"></span>[1] W. Martin, F. Sarro, Y. Jia, Y. Zhang, and M.
    Harman, "A survey of app store analysis for software engineering," *IEEE Transactions
    on Software Engineering*, vol. 43, no. 9, pp. 817–847, 2017.

    - <span id="page-10-1"></span>[2] Authority for Consumers & Markets, "Market study
    into mobile app stores (Report ACM/18/032693)," april 2019. [Online]. Available:
    [https://www.acm.nl/sites/default/files/documents/](https://www.acm.nl/sites/default/files/documents/market-study-into-mobile-app-stores.pdf)
    [market-study-into-mobile-app-stores.pdf](https://www.acm.nl/sites/default/files/documents/market-study-into-mobile-app-stores.pdf)

    - <span id="page-10-2"></span>[3] W. Maalej and H. Nabil, "Bug report, feature
    request, or simply praise? on automatically classifying app reviews," in *2015
    IEEE 23rd International Requirements Engineering Conference (RE)*, 2015, pp. 116–125.

    - [4] S. Hassan, H. Li, and A. E. Hassan, "On the importance of performing app
    analysis within peer groups," in *2022 IEEE International Conference on Software
    Analysis, Evolution and Reengineering (SANER)*, 2022, pp. 890–901.

    - [5] A. Yadav, R. Sharma, and F. H. Fard, "A semantic-based framework for analyzing
    app users'' feedback," in *2020 IEEE 27th International Conference on Software
    Analysis, Evolution and Reengineering (SANER)*, 2020, pp. 572–576.

    - [6] L. Guerrouj, S. Azad, and P. C. Rigby, "The influence of app churn on app
    success and stackoverflow discussions," in *2015 IEEE 22nd International Conference
    on Software Analysis, Evolution, and Reengineering (SANER)*, 2015, pp. 321–330.

    - <span id="page-10-3"></span>[7] S. Panichella, A. Di Sorbo, E. Guzman, C. A.
    Visaggio, G. Canfora, and H. C. Gall, "How can i improve my app? classifying user
    reviews for software maintenance and evolution," in *2015 IEEE International Conference
    on Software Maintenance and Evolution (ICSME)*, 2015, pp. 281–290.

    - <span id="page-10-4"></span>[8] J. D ˛abrowski, E. Letier, A. Perini, and A.
    Susi, "Analysing app reviews for software engineering: A systematic literature
    review," *Empirical Softw. Engg.*, vol. 27, no. 2, mar 2022.

    - [9] A. Begel and T. Zimmermann, "Analyze this! 145 questions for data scientists
    in software engineering," in *Proceedings of the 36th International Conference
    on Software Engineering*, 2014, p. 12–23.

    - <span id="page-10-5"></span>[10] R. P. L. Buse and T. Zimmermann, "Information
    needs for software development analytics," in *2012 34th International Conference
    on Software Engineering (ICSE)*, 2012, pp. 987–996.

    - <span id="page-10-6"></span>[11] J. Da¸browski, E. Letier, A. Perini, and A.
    Susi, "Mining and searching app reviews for requirements engineering: Evaluation
    and replication studies," *Information Systems*, vol. 114, p. 102181, 2023. [Online].
    Available:<https://doi.org/10.1016/j.is.2023.102181>

    - <span id="page-10-7"></span>[12] F. Palomba, M. Linares-Vásquez, G. Bavota,
    R. Oliveto, M. Di Penta, D. Poshyvanyk, and A. De Lucia, "User reviews matter!
    tracking crowdsourced reviews to support evolution of successful apps," in *2015
    IEEE International Conference on Software Maintenance and Evolution (ICSME)*,
    2015, pp. 291–300.

    - <span id="page-10-8"></span>[13] E. Guzman and W. Maalej, "How do users like
    this feature? A fine grained sentiment analysis of App reviews," *2014 IEEE 22nd
    International Requirements Engineering Conference, RE 2014 - Proceedings*, pp.
    153–162, 2014.

    - <span id="page-10-9"></span>[14] D. Pagano and W. Maalej, "User feedback in
    the appstore: An empirical study," in *2013 21st IEEE International Requirements
    Engineering Conference (RE)*, 2013, pp. 125–134.

    - <span id="page-10-10"></span>[15] C. Gao, J. Zeng, M. R. Lyu, and I. King, "Online
    app review analysis for identifying emerging issues," in *Proceedings of the 40th
    International Conference on Software Engineering*, 2018, p. 48–58.

    - <span id="page-10-11"></span>[16] N. Chen, J. Lin, S. C. H. Hoi, X. Xiao, and
    B. Zhang, "Ar-miner: Mining informative reviews for developers from mobile app
    marketplace," in *Proceedings of the 36th International Conference on Software
    Engineering*. New York, NY, USA: Association for Computing Machinery, 2014, p.
    767–778.

    - <span id="page-10-12"></span>[17] Shah, Faiz Ali and Sirts, Kairit and Pfahl,
    Dietmar, "Is the SAFE Approach Too Simple for App Feature Extraction? A Replication
    Study," in *Requirements Engineering: Foundation for Software Quality*, Knauss,
    Eric and Goedicke, Michael, Ed. Cham: Springer International Publishing, 2019,
    pp. 21–36.

    - <span id="page-10-13"></span>[18] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit,
    L. Jones, A. N. Gomez, Ł. Kaiser, and I. Polosukhin, "Attention is all you need,"
    *Advances in neural information processing systems*, vol. 30, 2017.

    - <span id="page-10-14"></span>[19] T. Zhang, B. Xu, F. Thung, S. A. Haryono,
    D. Lo, and L. Jiang, "Sentiment analysis for software engineering: How far can
    pre-trained


    transformer models go?" in *2020 IEEE International Conference on Software Maintenance
    and Evolution (ICSME)*, 2020, pp. 70–80.


    - [20] A. Ciborowska and K. Damevski, "Fast changeset-based bug localization with
    bert," in *Proceedings of the 44th International Conference on Software Engineering*.
    New York, NY, USA: Association for Computing Machinery, 2022, p. 946–957. [Online].
    Available: <https://doi-org.recursos.biblioteca.upc.edu/10.1145/3510003.3510042>

    - [21] C. Yang, B. Xu, J. Khan, G. Uddin, D. Han, Z. Yang, and D. Lo, "Aspect-based
    api review classification: How far can pre-trained transformer model go?" in *2022
    IEEE International Conference on Software Analysis, Evolution and Reengineering
    (SANER)*, 2022, pp. 385–395.

    - <span id="page-10-15"></span>[22] J. Tabassum, M. Maddela, W. Xu, and A. Ritter,
    "Code and named entity recognition in StackOverflow," in *Proceedings of the 58th
    Annual Meeting of the Association for Computational Linguistics*. Online: Association
    for Computational Linguistics, jul 2020, pp. 4913–4926. [Online]. Available:<https://aclanthology.org/2020.acl-main.443>

    - <span id="page-10-16"></span>[23] N. Jha and A. Mahmoud, "Mining non-functional
    requirements from app store reviews," *Empirical Software Engineering*, pp. 1–
    37, 2019. [Online]. Available: [https://api.semanticscholar.org/CorpusID:](https://api.semanticscholar.org/CorpusID:174802984)
    [174802984](https://api.semanticscholar.org/CorpusID:174802984)

    - <span id="page-10-17"></span>[24] K. C. Kang, S. G. Cohen, J. A. Hess, W. E.
    Novak, and A. S. Peterson, "Feature-oriented domain analysis feasibility study,"
    SEI Technical Report CMU/SEI-90-TR-21, Tech. Rep., 1990.

    - <span id="page-10-18"></span>[25] K. E. Wiegers and J. Beatty, *Software Requirements
    3*. USA: Microsoft Press, 2013.

    - <span id="page-10-19"></span>[26] M. Harman, Y. Jia, and Y. Zhang, "App store
    mining and analysis: Msr for app stores," in *2012 9th IEEE Working Conference
    on Mining Software Repositories (MSR)*, 2012, pp. 108–111.

    - <span id="page-10-20"></span>[27] K. Kang, S. Cohen, J. Hess, W. Novak, and
    A. Peterson, "Feature-oriented domain analysis (foda) feasibility study," Software
    Engineering Institute, Carnegie Mellon University, Pittsburgh, PA, Tech. Rep.
    CMU/SEI-90-TR-021, 1990. [Online]. Available: [http:](http://resources.sei.cmu.edu/library/asset-view.cfm?AssetID=11231)
    [//resources.sei.cmu.edu/library/asset-view.cfm?AssetID=11231](http://resources.sei.cmu.edu/library/asset-view.cfm?AssetID=11231)

    - <span id="page-10-21"></span>[28] B. Jehangir, S. Radhakrishnan, and R. Agarwal,
    "A survey on named entity recognition—datasets, tools, and methodologies," *Natural
    Language Processing Journal*, vol. 3, p. 100017, 2023.

    - <span id="page-10-22"></span>[29] K. Hakala and S. Pyysalo, "Biomedical named
    entity recognition with multilingual BERT," in *Proceedings of the 5th Workshop
    on BioNLP Open Shared Tasks*. Hong Kong, China: Association for Computational
    Linguistics, Nov. 2019, pp. 56–61. [Online]. Available: <https://aclanthology.org/D19-5709>

    - [30] A. K. Tarcar, A. Tiwari, D. Rao, V. N. Dhaimodker, P. Rebelo, and R. Desai,
    "Healthcare ner models using language model pretraining," in *HSDM@WSDM*, 2019.
    [Online]. Available: [https:](https://api.semanticscholar.org/CorpusID:210943047)
    [//api.semanticscholar.org/CorpusID:210943047](https://api.semanticscholar.org/CorpusID:210943047)

    - <span id="page-10-23"></span>[31] L. Gu, W. Zhang, Y. Wang, B. Li, and S. Mao,
    "Named entity recognition in judicial field based on bert-bilstm-crf model," in
    *2020 International Workshop on Electronic Communication and Artificial Intelligence
    (IWECAI)*. IEEE, 2020, pp. 170–174.

    - <span id="page-10-24"></span>[32] K.-J. Stol and B. Fitzgerald, "The abc of
    software engineering research," *ACM Trans. Softw. Eng. Methodol.*, vol. 27, no.
    3, sep 2018. [Online]. Available:<https://doi.org/10.1145/3241743>

    - <span id="page-10-25"></span>[33] Q. Motger, X. Franch, and J. Marco, "Mobile
    feature-oriented knowledge base generation using knowledge graphs," in *New Trends
    in Database and Information Systems - ADBIS 2023 Short Papers, Doctoral Consortium
    and Workshops: AIDMA, DOING, K-Gals, MADEISD, PeRS, Barcelona, Spain, September
    4-7, 2023, Proceedings*, ser. Communications in Computer and Information Science,
    vol. 1850. Springer, 2023, pp. 269–279. [Online]. Available: [https://doi.org/10.1007/978-3-031-42941-5\\_24](https://doi.org/10.1007/978-3-031-42941-5_24)

    - <span id="page-10-26"></span>[34] T. Johann, C. Stanik, A. M. Alizadeh, and
    W. Maalej, "SAFE: A Simple Approach for Feature Extraction from App Descriptions
    and App Reviews," *Proceedings - 2017 IEEE 25th International Requirements Engineering
    Conference, RE 2017*, pp. 21–30, 2017.

    - <span id="page-10-27"></span>[35] M. Dragoni, M. Federici, and A. Rexha, "An
    unsupervised aspect extraction strategy for monitoring real-time reviews stream,"
    *Information Processing & Management*, vol. 56, no. 3, pp. 1103–1118, 2019.

    - <span id="page-10-28"></span>[36] AppTweak, "Google Play Store Categories,"
    2022, Accessed 5th October, 2023. [Online]. Available: [https://developers.apptweak.com/](https://developers.apptweak.com/reference/google-play-store-categories)
    [reference/google-play-store-categories](https://developers.apptweak.com/reference/google-play-store-categories)

    - <span id="page-10-29"></span>[37] Stanford NLP Group, "Neural pipeline." [Online].
    Available: [https:](https://stanfordnlp.github.io/stanza/neural_pipeline.html)
    [//stanfordnlp.github.io/stanza/neural\\_pipeline.html](https://stanfordnlp.github.io/stanza/neural_pipeline.html)

    - <span id="page-10-30"></span>[38] Universal Dependencies, "CoNLL-U Format."
    [Online]. Available: <https://universaldependencies.org/format.html>

    - <span id="page-11-0"></span>[39] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang,
    Y. Hou, Y. Min, B. Zhang, J. Zhang, Z. Dong *et al.*, "A survey of large language
    models," *arXiv preprint arXiv:2303.18223*, 2023.

    - <span id="page-11-1"></span>[40] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova,
    "BERT: Pre-training of deep bidirectional transformers for language understanding,"
    in *Proceedings of the 2019 Conference of the North American Chapter of the Association
    for Computational Linguistics: Human Language Technologies, Volume 1 (Long and
    Short Papers)*. Minneapolis, Minnesota: Association for Computational Linguistics,
    Jun. 2019, pp. 4171–4186. [Online]. Available:<https://aclanthology.org/N19-1423>

    - <span id="page-11-2"></span>[41] S. Broscheit, "Investigating entity knowledge
    in BERT with simple neural end-to-end entity linking," in *Proceedings of the
    23rd Conference on Computational Natural Language Learning (CoNLL)*. Hong Kong,
    China: Association for Computational Linguistics, Nov. 2019, pp. 677–685. [Online].
    Available:<https://aclanthology.org/K19-1063>

    - <span id="page-11-3"></span>[42] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi,
    D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, "Roberta: A robustly
    optimized bert pretraining approach," 2019.

    - <span id="page-11-4"></span>[43] Z. Yang, Z. Dai, Y. Yang, J. Carbonell, R.
    R. Salakhutdinov, and Q. V. Le, "Xlnet: Generalized autoregressive pretraining
    for language understanding," *Advances in neural information processing systems*,
    vol. 32, 2019.

    - <span id="page-11-5"></span>[44] "Prolific · Quickly find research participants
    you can trust." [Online]. Available:<https://www.prolific.com/>

    - <span id="page-11-6"></span>[45] "QuestBase." [Online]. Available: [https://questbase.com/en/](https://questbase.com/en/home-questbase/)
    [home-questbase/](https://questbase.com/en/home-questbase/)

    - <span id="page-11-7"></span>[46] C. Wohlin, "Guidelines for snowballing in systematic
    literature studies and a replication in software engineering," in *Proceedings
    of the 18th International Conference on Evaluation and Assessment in Software
    Engineering*, 2014.

    - <span id="page-11-8"></span>[47] F. A. Shah, K. Sirts, and D. Pfahl, "Using
    app reviews for competitive analysis: Tool support," in *MAWA 2019*, 2019, pp.
    40–46.

    - <span id="page-11-9"></span>[48] S. Kumari and Z. A. Memon, "Extracting feature
    requests from online reviews of travel industry," *Acta Scientiarum - Technology*,
    vol. 44, 2022.

    - <span id="page-11-10"></span>[49] M. Kasri *et al.*, "A Comparison of Features
    Extraction Methods for Arabic Sentiment Analysis," in *4th International Conference
    on Big Data and Internet of Things*, 2020.

    - <span id="page-11-11"></span>[50] A. Gállego, J. Motger, X. Franch, and J. Marco,
    "TransFeatEx: a NLP pipeline for feature extraction," in *Joint proceedings of
    REFSQ-2023 Workshops, Doctoral Symposium, Posters & Tools Track and Journal Early
    Feedback: co-located with the 28th International Conference on Requirements Engineering:
    Foundation for Software Quality (REFSQ 2023): Barcelona, Catalunya, Spain, April
    17-20, 2023*. CEUR-WS.org, 2023. [Online]. Available:<https://ceur-ws.org/Vol-3378/PT-paper1.pdf>

    - <span id="page-11-12"></span>[51] H. Wu *et al.*, "Identifying key features
    from app user reviews," in *International Conference on Software Engineering*,
    2021.'
- title: What Is an App Store? The Software Engineering Perspective
  abstract: "\"App stores\" are online software stores where end users may browse,\
    \ purchase,\ndownload, and install software applications. By far, the best known\
    \ app stores\nare associated with mobile platforms, such as Google Play for Android\
    \ and\nApple's App Store for iOS. The ubiquity of smartphones has led to mobile\
    \ app\nstores becoming a touchstone experience of modern living. However, most\
    \ of app\nstore research has concentrated on properties of the apps rather than\
    \ the\nstores themselves. Today, there is a rich diversity of app stores and these\n\
    stores have largely been overlooked by researchers: app stores exist on many\n\
    distinctive platforms, are aimed at different classes of users, and have\ndifferent\
    \ end-goals beyond simply selling a standalone app to a smartphone\nuser.\n  We\
    \ survey and characterize the broader dimensionality of app stores, and\nexplore\
    \ how and why they influence software development practices, such as\nsystem design\
    \ and release management. We begin by collecting a set of app store\nexamples\
    \ from web search queries. By analyzing and curating the results, we\nderive a\
    \ set of features common to app stores. We then build a dimensional\nmodel of\
    \ app stores based on these features, and we fit each app store from our\nweb\
    \ search result set into this model. Next, we performed unsupervised\nclustering\
    \ to the app stores to find their natural groupings. Our results\nsuggest that\
    \ app stores have become an essential stakeholder in modern software\ndevelopment.\
    \ They control the distribution channel to end users and ensure that\nthe applications\
    \ are of suitable quality; in turn, this leads to developers\nadhering to various\
    \ store guidelines when creating their applications. However,\nwe found the app\
    \ stores operational model could vary widely between stores, and\nthis variability\
    \ could in turn affect the generalizability of existing\nunderstanding of app\
    \ stores."
  url: http://arxiv.org/abs/2401.04287v1
  keywords: ''
  document: "# What is an App Store? The Software Engineering Perspective\n\nWenhan\
    \ Zhu · Sebastian Proksch · Daniel M. German · Michael W. Godfrey · Li Li · Shane\
    \ McIntosh\n\nAuthor pre-print copy. The final publication is available at Springer\
    \ via: https://doi.org/ 10.1007/s10664-023-10362-3\n\nAbstract \"App stores\"\
    \ are online software stores where end users may browse, purchase, download, and\
    \ install software applications. By far, the best known app stores are associated\
    \ with mobile platforms, such as Google Play for Android and Apple's App Store\
    \ for iOS. The ubiquity of smartphones has led to mobile app stores becoming a\
    \ touchstone experience of modern living. App stores have been the subject of\
    \ many empirical studies. However, most of this research has concentrated on properties\
    \ of the apps rather than the stores themselves. Today, there is a rich diversity\
    \ of app stores and these stores have largely been overlooked by researchers:\
    \ app stores exist on many distinctive platforms, are aimed at different classes\
    \ of users, and have different end-goals beyond simply selling a standalone app\
    \ to a smartphone user.\n\nThe goal of this paper is to survey and characterize\
    \ the broader dimensionality of app stores, and to explore how and why they influence\
    \ software development practices, such as system design and release management.\
    \ We begin by collecting a set of app store examples from web search queries.\
    \ By analyzing and curating the results, we derive a set of features common to\
    \ app stores. We then build a dimensional model of app stores based on these features,\
    \ and we fit each app store from our web search result set into this model.\n\n\
    Wenhan Zhu · Michael W. Godfrey · Shane McIntosh\n\nSebastian Proksch Delft University\
    \ of Technology, Delft, Netherlands E-mail: s.proksch@tudelft.nl\n\nSchool of\
    \ Software, Beihang University, Beijing, China\n\nDaniel M. German Department\
    \ of Computer Science, University of Victoria, Victoria, Canada E-mail: dmg@uvic.ca\n\
    \nLi Li\n\nE-mail: lilicoding@ieee.org\n\narXiv:2401.04287v1 [cs.SE] 8 Jan 2024\n\
    \nDavid R. Cheriton School of Computer Science, University of waterloo, Waterloo,\
    \ Canada E-mail: {w65zhu, migod, shane.mcintosh}@uwaterloo.ca\n\nNext, we performed\
    \ unsupervised clustering to the app stores to find their natural groupings. Our\
    \ results suggest that app stores have become an essential stakeholder in modern\
    \ software development. They control the distribution channel to end users and\
    \ ensure that the applications are of suitable quality; in turn, this leads to\
    \ developers adhering to various store guidelines when creating their applications.\
    \ However, we found the app stores' operational model could vary widely between\
    \ stores, and this variability could in turn affect the generalizability of existing\
    \ understanding of app stores.\n\nKeywords app store, software release, software\
    \ distribution, empirical software engineering\n\n# 1 Introduction\n\nThe widespread\
    \ proliferation of smartphones and other mobile devices in recent years has in\
    \ turn produced an immense demand for applications that run on these platforms.\
    \ In response, online \"app stores\" such as Google Play and Apple's App Store\
    \ have emerged to facilitate the discovery, purchasing, installation, and management\
    \ of apps by users on their mobile devices. The success of mobile app stores has\
    \ enabled a new and more direct relationship between app creators and users. The\
    \ app store serves as a conduit between software creators (often, developers)\
    \ and their users, with some mediation provided by the app store. The app store\
    \ provides a \"one-stop shopping\" experience for users, who can compare competing\
    \ products and read reviews of other users. The app store might also acts as a\
    \ quality gatekeeper for the platform, providing varying levels of guarantees\
    \ about the apps, such as easy installation and removal, expected functionality,\
    \ and malware protection. To the software creator, the app store provides a centralized\
    \ marketplace for their app, where potential users can find, purchase, and acquire\
    \ the app easily; the app store also relieves the developer from basic support\
    \ problems related to distribution and installation, since apps must be shown\
    \ to install easily during the required approval process. Indeed, one of the key\
    \ side effects of mobile app stores is that it has forced software developers\
    \ to streamline their release management practices and ensure hassle-free deployment\
    \ at the user's end.\n\nThe success of mobile app stores has also led to the establishment\
    \ of a plethora of other kinds of app store, often for non-mobile platforms, serving\
    \ diverse kinds of user communities, offering different kinds of services, and\
    \ using a variety of monetization strategies. Many technical platforms now operate\
    \ in a store-centric way: essential services and functionality are provided by\
    \ the platform while access to extensions/add-ons is offered only through interaction\
    \ with the app store. For instance, Google Play, the app store, operates on top\
    \ of the technical platform Android, which provides the runtime environment for\
    \ the applications. When new technical platforms are introduced, an app store\
    \ is often expected to serve as a means to host and deliver products to its users\
    \ [1]. Example technical platforms that use app store-like approaches\n\ninclude\
    \ Steam [2], GitHub Marketplace [3], the Chrome Web Store [4], Word-Press [5],\
    \ AutoDesk [6], DockerHub [7], Amazon Web Services (AWS) [8], Homebrew [9], or\
    \ Ubuntu Packages [10].\n\nFor platforms that operate in this way, the app store\
    \ is an essential part of the platform's design. For example, consider source\
    \ code editors, such as VSCode and IntelliJ. The tool itself — which we consider\
    \ to be a technical platform in this context — offers the essential functionality\
    \ of a modern source code editor; however, many additional services are available\
    \ through the associated app store that are not included by default. Thus, extensions\
    \ that allow for language-specific syntax highlighting or version control integration\
    \ must be added manually by the user through interaction with the tool's app store.\
    \ We conjecture that the app store has fundamentally changed how some classes\
    \ of software systems are designed, from the overall ecosystem architecture of\
    \ the technical platform to the way in which add-ons are engineered to fit within\
    \ its instances.\n\nIn this work, we will explore the general space of app stores,\
    \ and also consider how app store-centric design can affect software development\
    \ practices. Previous research involving app stores has focused mainly on mobile\
    \ app stores, often concentrating on properties of the apps rather than properties\
    \ of the stores. For example, Harman et al. performed one of the first major studies\
    \ of app stores in 2012, focusing on the BlackBerry App World [11]. However, concentrating\
    \ the investigative scope so narrowly may lead to claims that do not generalize\
    \ well across the space of all app stores. For example, Lin et al. found that\
    \ reviews of games that appeared in mobile app stores differed significantly from\
    \ the reviews of the same game that appeared within the Steam platform's own app\
    \ store [12]. In our work, we aim to take a more holistic approach to studying\
    \ app stores by considering both mobile and non-mobile variants. In so doing,\
    \ we hope to create a more general model of app stores that fits this broader\
    \ space.\n\nTo achieve a holistic view, we start from the definition of an app\
    \ store. A precise definition of the term \"app store\" has been omitted in much\
    \ of the previous research in this area. Currently, Google Play and Apple's App\
    \ Store dominate the market and are the main targets of research on app stores;\
    \ in the past, the BlackBerry App World and Microsoft's Windows Phone Store were\
    \ also important players, but these stores are now defunct.<sup>1</sup> Wikipedia\
    \ recognizes Electronic AppWrapper [13] as the first true platform-specific electronic\
    \ marketplace for software applications, but the term became popular when Apple\
    \ introduced its App Store along with the iPhone 3G in 2008. Since then, the term\
    \ has largely come to refer to any centralized store for mobile applications.\
    \ We present our own working definition of the term \"app store\" in Sec. 2.4.\n\
    \nThe goal of this work is to survey and characterize the broader dimensionality\
    \ of app stores, and also to explore how and why they may feed back into software\
    \ development practices, such as release management. As a step toward\n\n<sup>1</sup>\
    \ The Windows Phone Store was absorbed into the broader Windows Store in 2015.\n\
    \nthis goal, we focus on two research questions (RQs) that aim to explore the\
    \ space of app stores:\n\n# RQ1: What fundamental features describe the space\
    \ of app stores?\n\nTo understand app stores, we first need a way to describe\
    \ them. It would be especially useful if this description framework would highlight\
    \ the similarities and differences of app stores. We start by collecting a set\
    \ of app store examples, and then extract from them a set of features that illustrate\
    \ important differences between them. We then expand this list of app stores with\
    \ search queries to derive a larger set of example stores. We explicitly seek\
    \ generalized web queries to broaden our search space beyond the common two major\
    \ mobile app stores of Apple and Google. By combining the web queries and the\
    \ initial set of app stores, we selected a representative set of app stores and\
    \ extracted their features. In the end, we first surveyed app stores and derived\
    \ a feature-based model to describe them; we then expanded the set of app stores\
    \ through web queries; and finally, we extracted features based on the model for\
    \ a representative set of app stores.\n\n#### RQ2: Are there groups of stores\
    \ that share similar features?\n\nDespite the ability to describe individual stores,\
    \ it is also important to understand the relationships between different stores.\
    \ Having a understanding of the natural groupings can help us gain insights into\
    \ the understanding of the generalizability of results gathered for different\
    \ app stores. We perform a K-means [14] clustering based on the extracted features\
    \ of the expanded set of app stores collected previously. The optimal k value\
    \ is determined by the Silhouette method [15]. The clustering results suggest\
    \ that there are 8 groups in the expanded set of app stores. The differences can\
    \ be observed in the type of application offered, standalone or extension, and/or\
    \ type of operation, business or community-oriented.\n\nIn this study, we make\
    \ several contributions towards a better understanding of the app store ecosystem.\n\
    \n- We identified a set of descriptive features that can be used to characterize\
    \ app stores.\n- We identified a set of 291 app stores and mapped 53 of them into\
    \ the feature space.\n- We identified 8 coherent groups of app stores based on\
    \ the similarity of features.\n- We discuss our insights on how the features and\
    \ the diversity of app stores can impact software engineering practices.\n\nOverall,\
    \ our study contributes towards a holistic view of app stores within software\
    \ engineering, which can form the basis for subsequent study of app stores in\
    \ general.\n\n# 2 Background and Related Work\n\n#### 2.1 Early App Store Research\n\
    \nTo date, research in this area has concentrated on a narrow set of app stores\
    \ that primarily involves mobile platforms. Harman et al. [11] proposed app stores\
    \ as a valid kind of software repository worthy of formal study within the broader\
    \ research area of mining software repositories; while their work was not specific\
    \ to mobile app stores, they used BlackBerry App World as their canonical example.\
    \ Ruiz et al. [16] studied the topic of reuse within app stores, focusing their\
    \ work on Android Marketplace. 2 In both cases, these early works did not provide\
    \ a formal definition of \"app store\", and tacitly used only app stores for mobile\
    \ platforms in their studies.\n\nIn their 2016 survey on app store research, Martin\
    \ et al. [17] observed that studies have often focused on only a few specific\
    \ app stores, and have ignored comparisons between app stores. In a recent literature\
    \ survey, Dąbrowski et al. [18] found the median number of app stores studied\
    \ to be 1, with the maximum being 3. We also note that results from one app store\
    \ study may not generalize to another store since the two stores may differ in\
    \ significant ways; for example, if a store does not allow users to provide their\
    \ own reviews of the apps within the store, app creators will have to rely on\
    \ other means to gain popularity and trust from users, such as promotion outside\
    \ of the app store. The same trend can be observed in more specific app store\
    \ topics such as app reviews; for example, Lin et al. [12] found that reviews\
    \ of games within the Steam app store can be dramatically different from reviews\
    \ of the same game in mobile app stores.\n\nExisting work has yet to explore the\
    \ full diversity of app stores, concentrating on Google Play and Apple's App Store,\
    \ and largely ignoring those such as Steam, AWS, and GitHub Marketplace that are\
    \ not specific to mobile platforms. With the heterogeneity of app stores and their\
    \ typical uses, we believe that the research in this area can be strengthened\
    \ by expanding the breadth to encompass a more diverse perspective on app stores;\
    \ in turn, this breadth can help to validate the generalizability of the study\
    \ findings.\n\n#### 2.2 App Stores in Recent Software Engineering Research\n\n\
    To better understand the involvement of app stores in recent research, we reviewed\
    \ relevant recent papers from the two flagship software engineering research conferences:\
    \ the ACM/IEEE International Conference on Software Engineering (\"ICSE\") and\
    \ the ACM SIGSOFT International Symposium on the Foundations of Software Engineering\
    \ (\"FSE\") We used Google Scholar to find papers containing the keyword \"app\
    \ store\" between January 2020 and April 2022 for the two conferences. We found\
    \ a total of 34 such papers (listed in Table 2.1). After reading through all of\
    \ them, we found that each paper\n\n<sup>2</sup> Android Marketplace has since\
    \ been re-branded as Google Play.\n\nfit into one of two broad categories: mining\
    \ software applications (20/34) and mining app store artifacts (14/34). We note\
    \ that our efforts do not constitute a comprehensive literature survey; instead,\
    \ our goal was to gain an overview of how app stores are involved in recent research,\
    \ and why app stores matter in their context.\n\n| Loc                  | Paper\
    \                                                                            \
    \                                                                       | Store\
    \                                         |\n|----------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------|\n\
    |                      | Mining software applications                        \
    \                                                                            \
    \                        |                                               |\n|\
    \ ICSE '21             | Atvhunter: Reliable version detection of third-party\
    \ libraries for vulnerability<br>identification in android applications [19] \
    \                        | Google Play                                   |\n|\
    \ ICSE '20             | How does misconfiguration of analytic services compromise\
    \ mobile privacy? [20]                                                       \
    \                   | Google Play                                   |\n| FSE '21\
    \              | Algebraic-datatype taint tracking, with applications to understanding\
    \ Android<br>identifier leaks [21]                                           \
    \       | Google Play                                   |\n| FSE '20         \
    \     | Code recommendation for exception handling [22]                      \
    \                                                                            \
    \       | Google Play                                   |\n| FSE '20         \
    \     | Static asynchronous component misuse detection for Android applications\
    \ [23]                                                                       \
    \     | F-Droid, Google Play, Wan<br>doujia App Store |\n| ICSE '21          \
    \   | Sustainable Solving: Reducing The Memory Footprint of IFDS-Based Data Flow<br>Analyses\
    \ Using Intelligent Garbage Collection [24]                        | Google Play\
    \                                   |\n| ICSE '22             | DescribeCtx: Context-Aware\
    \ Description Synthesis for Sensitive Behaviors in Mo<br>bile Apps [25]      \
    \                                                  | Google Play             \
    \                      |\n| ICSE '20             | Time-travel testing of android\
    \ apps [26]                                                                  \
    \                                              | Google Play                 \
    \                  |\n| ICSE '20             | An empirical assessment of security\
    \ risks of global android banking apps [27]                                  \
    \                                         | Play, APKMonk,<br>Google<br>and others\
    \        |\n| ICSE '21             | Too Quiet in the Library: An Empirical Study\
    \ of Security Updates in Android<br>Apps' Native Code [28]                   \
    \                                | Google Play                               \
    \    |\n| ICSE '20             | Accessibility issues in android apps: state of\
    \ affairs, sentiments, and ways for<br>ward [29]                             \
    \                              | Google Play                                 \
    \  |\n| ICSE '21             | Don't do that! hunting down visual design smells\
    \ in complex uis against design<br>guidelines [30]                           \
    \                            | Android                                       |\n\
    | ICSE '21             | Identifying and characterizing silently-evolved methods\
    \ in the android API [31]                                                    \
    \                     | Google Play                                   |\n| ICSE\
    \ '21             | Layout and image recognition driving cross-platform automated\
    \ mobile test<br>ing [32]                                                    \
    \               | Apple's App Store, Google<br>Play             |\n| FSE '21 \
    \             | An empirical study of GUI widget detection for industrial mobile\
    \ games [33]                                                                 \
    \            | Android Games                                 |\n| ICSE '21   \
    \          | Fine with \"1234\"? An Analysis of SMS One-Time Password Randomness\
    \ in An<br>droid Apps [34]                                                   \
    \           | Play,<br>Tencent<br>Google<br>Myapp           |\n| ICSE '21    \
    \         | IMGDroid: Detecting Image Loading Defects in Android Applications\
    \ [35]                                                                       \
    \           | Android                                       |\n| ICSE '21    \
    \         | GUIGAN: Learning to Generate GUI Designs Using Generative Adversarial\
    \ Net<br>works [36]                                                          \
    \       | Android                                       |\n| ICSE '20        \
    \     | Unblind your apps: Predicting natural-language labels for mobile gui components<br>by\
    \ deep learning [37]                                                | Google Play\
    \                                   |\n| FSE '21              | Frontmatter: mining\
    \ Android user interfaces at scale [38]                                      \
    \                                                         | Google Play      \
    \                             |\n|                      | Mining app store non-technical\
    \ attributes                                                                 \
    \                                              |                             \
    \                  |\n| ICSE '20             | Schrödinger's security: Opening\
    \ the box on app developers' security rationale [39]                         \
    \                                             | Apple's App Store, Google<br>Play\
    \             |\n| ICSE '20             | Scalable statistical root cause analysis\
    \ on app telemetry [40]                                                      \
    \                                    | Facebook App                          \
    \        |\n| ICSE '21<br>ICSE '21 | An empirical assessment of global COVID-19\
    \ contact tracing applications [41]<br>We'll Fix It in Post: What Do Bug Fixes\
    \ in Video Game Update Notes Tell | Android<br>Steam                         \
    \     |\n| ICSE '21             | Us? [42]<br>Automatically matching bug reports\
    \ with related app reviews [43]                                              \
    \                              | Google Play                                 \
    \  |\n| ICSE '21             | Prioritize crowdsourced test reports via deep screenshot\
    \ understanding [44]                                                         \
    \                    | Android                                       |\n| ICSE\
    \ '21             | A first look at human values-violation in app reviews [45]\
    \                                                                            \
    \                  | Google Play                                   |\n| ICSE '21\
    \             | Does culture matter? impact of individualism and uncertainty avoidance\
    \ on app                                                                     \
    \      | Apple's App Store                             |\n| ICSE '21         \
    \    | reviews [46]<br>COVID-19 vs social media apps: does privacy really matter?\
    \ [47]                                                                       \
    \  | Google Play, Apple's App                      |\n| ICSE '20             |\
    \ Society-oriented applications development: Investigating users' values from\
    \                                                                            \
    \ | Store<br>Google Play                          |\n| FSE '21              |\
    \ bangladeshi agriculture mobile applications [48]<br>Checking conformance of\
    \ applications against GUI policies [49]                                     \
    \ | Android                                       |\n| ICSE '21             |\
    \ Identifying key features from app user reviews [50]                        \
    \                                                                            \
    \ | Apple's App Store                             |\n| ICSE '21             |\
    \ Champ: Characterizing undesired app behaviors from user comments based on<br>market\
    \ policies [51]                                                       | Google\
    \ Play, Chinese an<br>droid app stores   |\n| ICSE '20             | Caspar: extracting\
    \ and synthesizing user stories of problems from app reviews [52]            \
    \                                                          | Apple's App Store\
    \                             |\n|                      |                    \
    \                                                                            \
    \                                                         |                  \
    \                             |\n\n> Mining software applications — App stores\
    \ have been extensively used as a mining source of software applications. In these\
    \ papers, the major focus is often on another subject and app stores provide a\
    \ source where they can collect applications for either a data source or verification\
    \ dataset. For example, Zhan et al. [19] proposed an approach to detect software\
    \ vulnerabilities in third-party libraries of Android applications. They leveraged\
    \ the app store to collect a dataset to verify the effectiveness of their approach.\
    \ In these studies, the app store is both a convenient and practical source of\
    \ data collection. However, the involvement of app stores may not be necessary\
    \ since the purpose is to gather a dataset of application. In Yang et al.'s work\
    \ [30], they leveraged Android applications from an existing dataset without the\
    \ need to collect from an app store. We argue that the importance of app stores\
    \ in these types of studies is the selection criteria used by the researchers\
    \ to collect applications from app stores. These features can include star ratings,\
    \ total downloads, and app category.\n\n> Mining app store artifacts — In these\
    \ studies, researchers focused on unique software artifacts that come from the\
    \ operation of the app stores. App stores have a much heavier involvement in these\
    \ studies compared to the previous group. App reviews is the major software artifact\
    \ the researchers focused on, where they leverage the data to identify features\
    \ of applications [50], locating bug reports [43], and detect undesired app behaviors\
    \ [51]. One interesting research practice we observed is where van der Linden\
    \ et al. [39] leveraged the developer contact information shared on app stores\
    \ to send out surveys related to security practices.\n\n#### 2.3 Store-Focused\
    \ Research\n\nAs stated above, we found that most recent research involving app\
    \ stores focuses on the applications they offer rather than on studying the app\
    \ stores themselves; in particular, most research in the domain focuses on the\
    \ development of mobile applications. Meanwhile, a few papers have specifically\
    \ considered app stores and their effects on software engineering, but again these\
    \ works focus heavily on mobile app stores.\n\nIn a recent paper, Al-Subaihin\
    \ et al. [53] interviewed developers about how app stores affect their software\
    \ engineering tasks. They found that developers often leverage the review section\
    \ from similar applications to help with understanding the expected user experience\
    \ and anticipated features. App stores also provides a kind of playground for\
    \ releasing beta version of apps to receive feedback from users. The built-in\
    \ communication channels also play a large role in informing development. The\
    \ interviews suggest that developers pay attention to viewing user requests in\
    \ app store via channels such as reviews and forums. The approval period of app\
    \ stores affects how developers plan their release. App stores introduce non-technical\
    \ challenges in the development process. Given the app store model of release,\
    \ app store-specific metrics, such as total number of downloads, are considered\
    \ highly important to developers.\n\nRunning an app store presents both technical\
    \ and non-technical challenges to the store owner. Technical challenges include\
    \ verifying that each app will install correctly, while non-technical challenges\
    \ include ensuring that the promotional information in the app's product page\
    \ adheres to store guidelines. Wang et al. [54] investigated several Android app\
    \ stores in China and compared them to Google Play. Their study showed that these\
    \ stores were much less diligent in screening the apps they offered, with a significantly\
    \ higher presence of fake, cloned, and malicious apps than Google Play.\n\nJansen\
    \ and Bloemendal surveyed the landscape of app stores from the perspective of\
    \ the business domain [55]. They selected 6 app stores — 5 mobile stores and 1\
    \ Windows store — at the time of publication (2013), and investigated each store\
    \ manually to find features (i.e., those actors can interact with) and policies\
    \ (i.e., rules, regulations and governing processes that limit the functional\
    \ reach of the features) from each app store. The actors they define are the same\
    \ as the three major stakeholders of the app store model (i.e., the store owner,\
    \ users, and developers). Our study further contributes to the understanding of\
    \ app stores. First, we studied a significantly larger set of app stores: our\
    \ methodology was focused towards the identification of as many different types\
    \ of stores as possible. In total, we studied 53 stores in various domains including\
    \ mobile, embedded systems, computer games, application add-ons, and open source\
    \ distributions and packaging systems. Second, Jansen and Bloemendal studied app\
    \ stores from the perspective of a software business; for example, in their work\
    \ they would consider features and policies on whether users are able to generate\
    \ affiliate links to earn revenue through sharing applications. In contrast, our\
    \ work focuses on app stores in the perspective of their role in the software\
    \ engineering process.\n\nIn our study, we approach app stores from a broad landscape\
    \ not limited to mobile app stores. We focus on the similarity of features offered\
    \ between stores to understand their natural groupings and discuss the challenges\
    \ in the diversity of app stores.\n\n#### 2.4 Working Definition of an App Store\n\
    \nPrevious researchers have often taken a casual approach to defining the term\
    \ \"app store\", when a definition has been provided at all. For example, in their\
    \ survey paper, Martin et al. define an app store as \"A collection of apps that\
    \ provides, for each app, at least one non-technical attribute\", with an app\
    \ defined as \"An item of software that anyone with a suitable platform can install\
    \ without the need for technical expertise\" [17]. However, we feel that this\
    \ definition is too generous. For example, consider a static website called Pat's\
    \ Apps that lists of a few of someone's (Pat's) favourite applications together\
    \ with their personalized ratings and reviews; superficially, this would satisfy\
    \ Martin et al.'s requirements as it is a collection of apps together with Pat's\
    \ own reviews (which are non-technical attributes). We feel that this kind of\
    \ \"store\" is outside our scope of study for several reasons: Pat's software\
    \ collection is not comprehensive, it is unlikely that Pat provides any technical\
    \ guarantees about quality of the apps, and a passive list of apps on a web page\
    \ does not constitute an automated \"store\".\n\n![](_page_8_Figure_1.jpeg)\n\n\
    Fig. 2.1 Three major stakeholders of most app stores\n\nJansen and Bloemendal\
    \ [55] define app store as \"An online curated marketplace that allows developers\
    \ to sell and distribute their products to actors within one or more multi-sided\
    \ software platform ecosystems.\" We note that this definition ignores that app\
    \ stores are expected to provide infrastructure for the deployment, installation,\
    \ and maintenance of the apps, which impacts the software development process.\
    \ Their model also ignores marketplaces that do not have payment mechanisms, such\
    \ as the Google Chrome Extensions store and the various open source apps stores,\
    \ where all of the software products may be free to download and install.\n\n\
    In our work, we seek to define an idea of app store beyond the well-known mobile\
    \ ones and with an emphasis on how their existence may affect the software development\
    \ cycle. Because we are focused on exploring the notion of what app stores are,\
    \ we formulate a working definition of the term; we did so to provide clear inclusion/exclusion\
    \ criteria for the candidate app stores that we discover in Sec. 3.\n\nOur working\
    \ definition was influenced by considering the three major stakeholders of the\
    \ app store model: the app creators who create and submit applications to the\
    \ store; the app stores themselves, and the organizations behind their operation\
    \ who curate the app collection and coordinate both the store and installation\
    \ mechanisms; and the end users who browse, download, review, and update their\
    \ applications through the app store (see Figure 2.1).\n\nWe thus arrived at the\
    \ following working definition for app store as an online distribution mechanism\
    \ that:\n\n- 1. offers access to a comprehensive collection of software or software-based\
    \ services (henceforth, \"apps\") that augment an existing technical infrastructure\
    \ (i.e., the runtime environment),\n- 2. is curated, i.e., provides some level\
    \ of guarantees about the apps, such as ensuring basic functionality and freedom\
    \ from malware, and\n- 3. provides an end-to-end automated \"store\" experience\
    \ for end users, where\n\t- (a) the user can acquire the app directly through\
    \ the store,\n- (b) users trigger store events, such as browsing, ordering, selecting\
    \ options, arranging payment, etc., and\n- (c) the installation process is coordinated\
    \ automatically between the store and the user's own instance of the technical\
    \ platform.\n\nWe can see that using this working definition, our Pat's Apps example\
    \ fails to meet all three of our main criteria.\n\nWe note that our working definition\
    \ above evolved during our investigations; it represents our final group consensus\
    \ on what is or is not an app store for the purposes of doing the subsequent exploratory\
    \ study. The steps by which the representation is finalized are discussed in Sec.\
    \ 3.1.2. For example, our working definition implicitly includes package managers\
    \ such as the Debian-Linux apt tool and Javascript's NPM tool. It is true that\
    \ package managers are typically non-commercial, and so are \"stores\" only in\
    \ a loose sense of the term; furthermore, they usually lack a mechanism for easy\
    \ user browsing of apps and do not provide a facility for user reviews. However,\
    \ at the same time, they are a good fit conceptually: they tend to be comprehensive,\
    \ curated, and offer an automated user experience for selection and installation.\
    \ Furthermore, some package managers serve as the backend to a more traditional\
    \ store-like experience; for example, the Ubuntu Software Center builds on a tool\
    \ aptitude, which interacts with software repositories to provide a user experience\
    \ similar to that of Google Play.\n\n### 3 Research Methodology\n\nTo investigate\
    \ the research questions, we designed a three-stage methodology that is illustrated\
    \ in Figure 3.1. The goal of the first two stages is to answer RQ1, while the\
    \ third stage addresses RQ2.\n\nIn the first stage (Step ○1 and ○2 ) we identified\
    \ our initial list of features using a small set of well-known app stores (Apple's\
    \ App Store, Google Play, Steam etc.) In the second stage (Steps ○3 , ○4 , and\
    \ ○5 ) we methodically expanded our list to a conceptually wider ranging set of\
    \ 53 app stores. We then described these stores using the features identified\
    \ in the first stage. A major goal of this stage was to evaluate whether the set\
    \ of available features was sufficient to describe the characteristics of all\
    \ these stores. This set of features forms the answer to RQ1.\n\nIn the third\
    \ stage (Step ○6 ), we took advantage of the labeling of the 53 stores. We used\
    \ K-means clustering analysis to identify groups of stores that shared similar\
    \ features. These groupings form the answer to RQ2.\n\nWe now describe our methodology\
    \ in more detail.\n\n#### 3.1 Extracting Features Describing App Stores\n\nOur\
    \ basic assumption is that an app store can be categorized based on a finite set\
    \ of features. The features would correspond to traits of the app store where\n\
    \n![](_page_10_Figure_1.jpeg)\n\nFig. 3.1 Methodology overview: There are three\
    \ main stages, further broken down into six steps.\n\nthey describe the distinguishing\
    \ qualities or functional characteristics of the app store. We encode these features\
    \ as binary values, i.e., each store has or does not have a given feature.\n\n\
    In order to identify such features, we first created a seeding set of representative\
    \ app stores. We started by enumerating well-known app stores that we were aware\
    \ of (Step ○1 ). Once this set of representative app stores was created, we used\
    \ an iterative process to identify the features that we felt best characterized\
    \ these stores (Step ○2 ). We then used these features to describe each store.\n\
    \n#### 3.1.1 Stage 1: Identifying Features\n\nFirst, each of the six authors was\
    \ tasked with identifying representative characteristics of five stores and the\
    \ possible features for each. Each author worked alone in this step; however,\
    \ to seek better reliability as well as encourage diverse opinions, each store\
    \ was assigned to two authors. We list the 15 stores that were assigned in this\
    \ step with a short description in Table 3.1. After that, all of the authors met\
    \ as a group to discuss their findings and further refine the proposed feature\
    \ set.\n\nIn the subsequent iterations, the authors worked in pairs, and the pairings\
    \ were reassigned after each iteration (Step ○2 ). In these iterations, each authorpair\
    \ was assigned a set of 2–3 app stores and was asked to describe them using the\
    \ current set of features; a key concern was to evaluate whether the existing\
    \ features were sufficient or needed refinement. For each store, each author-pair\
    \ analyzed both its store-front and its documentation; in some cases, we could\
    \ navigate the store as users but not as developers, in these cases, we relied\
    \ on the store's supporting documentation.\n\nAfter this step, the six authors\
    \ discussed their findings as a group and updated the set of features. The features\
    \ were discussed in detail to ensure that they were conceptually independent from\
    \ each other. We also made sure that each feature applied to at least one store\
    \ to ensure that it was relevant.\n\nOur process leveraged ideas from the coding\
    \ process of Grounded theory [56] to extract the features of app stores, and followed\
    \ the practice of open card sorting [57] to create the categorized feature set.\
    \ Similar to prior work [58–60], we followed practices of Grounded theory's coding\
    \ process to extract the features— where we consider codes as a specific feature\
    \ of app store operation — and stopped when we reached saturation with no new\
    \ features added after a new round of describing app stores. Similar to prior\
    \ work [61–63], we applied card sorting to the collected features so inter-related\
    \ features are grouped together. The authors formed a group in this process and\
    \ discussed how different features belong to the same conceptual group and stopped\
    \ when consensus was reached.\n\n| Store                  | Description      \
    \                                                                            \
    \              |\n|------------------------|------------------------------------------------------------------------------------------------------------|\n\
    | Google Play Store      | Google's app store for Android                    \
    \                                                         |\n| Apple App Store\
    \        | Store for Apple devices                                           \
    \                                         |\n| Samsung GalaxyApps     | Store\
    \ specifically for Samsung devices                                           \
    \                          |\n| GitHub Marketplace     | Providing applications\
    \ and services to integrate with GitHub plat<br>form                         \
    \         |\n| Atlassian Marketplace  | Providing applications and services to\
    \ integrate with various At<br>lassian products                       |\n| Homebrew\
    \               | Package manager for MacOS                                  \
    \                                                |\n| MacPorts               |\
    \ A package manager for MacOS                                                \
    \                                |\n| Ubuntu Packages        | Software repository\
    \ for the Ubuntu Linux distribution, with a<br>official front end Ubuntu Software\
    \ Center |\n| Steam                  | Gaming focused app store running on multiple\
    \ operating systems<br>(e.g., Windows, Linux)                   |\n| Nintendo\
    \ EShop         | Provides applications for Nintendo devices (e.g., Nintendo Switch,<br>Nintendo\
    \ 3DS)                        |\n| GoG                    | Gaming focused store\
    \ focusing on providing DRM free games                                       \
    \           |\n| JetBrains Plugin Store | Provides plugins to enhance the behavior\
    \ of JetBrains IDEs                                                 |\n| VSCode\
    \ Marketplace     | Provides plugins to enhance the editor                   \
    \                                                  |\n| Chrome Web Store     \
    \  | Provides extensions to enhance Chromium based web browsers              \
    \                                   |\n| AWS Marketplace        | Provides servers\
    \ and cloud services                                                         \
    \               |\n\nTable 3.1 Investigated stores for feature extraction\n\n\
    3.1.2 Stage 2: Expanding Our Set of App Stores and Further Evaluation and Refinement\
    \ the Features\n\nOnce we had agreed on the features, our next goal was to verify\
    \ that these features were capable of describing other app stores that were not\
    \ part of the initial seed, or if features were missing or needed refinement.\
    \ We used a common search engine, Google, to expand our set of app stores in a\
    \ methodical manner (Step ○3 ). To achieve the goal of including a broad range\
    \ of yet undiscovered app stores, we first derived general search terms by combining\
    \ synonyms for \"app\" and \"store\". More specifically, we have built all possible\
    \ combinations of the following terms to construct our search queries:\n\n# First\
    \ half software, (extension -hair -lash), (addon OR add-on), solution, plugin\
    \ OR plug-in, install, app, package\n\nSecond half repository, shop, (\"app store\"\
    \ OR store), (\"market place\" OR marketplace), manager\n\nFor example, a concrete\
    \ query was created by combining app and (\"app store\" OR store). For some queries,\
    \ it was necessary to refine the term to avoid noise in the results; for example,\
    \ searching for the term extension would mainly return results related to hair\
    \ product or eye lashes. In total, with 8 synonyms for app and 5 synonyms for\
    \ store we were able to create 40 unique Google search queries. We felt confident\
    \ that these search terms were representative when we found that the initial seed\
    \ list had been exhaustively covered.\n\nOur Google search was performed in November\
    \ 2020. We queried and stored the search results for each search query. Two authors\
    \ classified each result as to whether or not it corresponded to an app store.\
    \ We devised two inclusion criteria for this decision: 1) the store in question\
    \ should offer software or software-based services, and 2) the store in question\
    \ should offer an end-toend experience for users (ordering, delivery, installation).\
    \ We considered only direct hits to the store (e.g., product page), and we explicitly\
    \ excluded results that contain only indirect references to a store, such as blog\
    \ posts, videos, or news. Any disagreements were resolved through discussion.\
    \ However, despite our initial effort of maintaining a clear set of inclusion\
    \ criteria for app stores, several corner cases became apparent during the labeling\
    \ process. The first two authors discussed these cases as they arose, and continually\
    \ updated the inclusion criteria throughout the labeling process. In a few special\
    \ cases no agreement could be reached, so another author acted as a moderator\
    \ and resolved the disagreement by a majority vote. Over time, the inclusion criteria\
    \ and features evolved and eventually reached a stable state (in Step ○3 ). Our\
    \ final state of the inclusion/exclusion criteria is presented as the working\
    \ definition for app stores defined in Sec. 2.4.\n\nThe classification of search\
    \ results was stopped when a new results page did not contain any new links to\
    \ app stores, or once all 10 retrieved pages were analyzed. Initially, 586 URLs\
    \ were examined by the first two authors until a saturation of agreement was reached\
    \ (90.7% agreement rate). The first author continued to label the rest. In the\
    \ end, a total of 1,600 URLs were labeled. Multiple search results can refer to\
    \ the same store; these duplicates were detected and eliminated by using the root\
    \ domain of the URL. The most common duplicate references were found for the domains\
    \ google. com (61), apple. com (22), and microsoft. com (18). In the end, we found\
    \ 291 stores. We note that the exact number of unique stores may differ since\
    \ two root domains can point to the same store, kodi. tv and kodi. wiki , or the\
    \ same root domain may contain multiple stores, chrome. google. com and play.\
    \ google. com .\n\nIn the next step (Step ○5 ), we constructed and labeled a set\
    \ of app stores based on our identified features from Step ○2 . We began from\
    \ the URLs labeled in the last step and selected the first three occurring stores\
    \ for each search term; this resulted in 104 URLs pointing to 48 unique stores.\
    \ Two of the stores were could not be accessed by the authors: ASRock App Shop\
    \ requires physical hardware to use it, and PLCnext Store's website was unresponsive\
    \ at the time of labeling. These stores were removed from the list. In addition,\
    \ we discussed several more stores that we felt deserved explicit investigation:\
    \ AWS, Flatpak, GoG, MacPorts, Nintendo eShop, Steam, and Samsung's Galaxy Store.\
    \ These are the stores that the authors investigated in Step ○2 but did not show\
    \ up in the first three occurring results from the search terms. Meanwhile, the\
    \ added stores all show up in the list of 291 stores identified by all labeled\
    \ URLs.\n\nWe thus selected and labeled a total of 53 app stores. This sample\
    \ is nonexhaustive, but we believe that our wide range of search queries has created\
    \ a representative sample of the population of app stores that enables our experiments.\n\
    \nThe first two authors proceeded to describe 12 app stores, selected as the first\
    \ from each search query, using the set of features. This was done to make sure\
    \ there was consistency in the interpretation and use of each feature. After that,\
    \ the first author labeled the remaining stores.\n\nTo check the applicability\
    \ of our dimensions and the labeling guidelines, we have measured the inter-rater\
    \ agreement between two authors on the 12 stores. We used the Cohen's Kappa [64]\
    \ as a measurement for our inter-rater agreement. The Cohen's Kappa is widely\
    \ used in software engineering research [65]. We have reached an agreement of\
    \ 86.3% with Cohen's Kappa [64] of 0.711). Our agreement based on the Cohen's\
    \ Kappa is considered as a substantial [66] inter-rater agreement suggesting a\
    \ high confidence of agreement between the two raters.\n\nThe outcomes of RQ1\
    \ were a list of features that describe the main characteristics of app stores\
    \ grouped by dimensions, and a set of 53 App Stores, each labeled using these\
    \ features.\n\n#### 3.2 Finding Natural Groupings of App Stores\n\nWith the outcomes\
    \ of RQ1, we next performed a K-means clustering analysis to identify groups of\
    \ similar stores. K-means is a well known clustering algorithm widely used in\
    \ software engineering research [67–70]. It groups vectorized data points iteratively\
    \ until k centroids are formed. We used the K-means++ implementation [71] to conduct\
    \ the clustering process.\n\n#### 3.2.1 Stage 3: Cluster Analysis\n\nTo identify\
    \ related app stores, we decided to cluster them using the K-means algorithm (Step\
    \ ○6 ).\n\nTo prepare our labels for the K-means clustering process, we converted\
    \ each label of the feature to a binary value: 1 if the store has the feature,\
    \ and 0 if it does not. Having binary-encoded data ensured that we do not suffer\
    \ from having categorical values that do not make sense in the scope of K-means.\
    \ However, performing K-means on binary data can also be problematic, since the\
    \ initial centroids selected will be binary. To mitigate this issue, we applied\
    \ Principal Component Analysis (PCA) [72] to both reduce the dimensional space\
    \ and to produce a mapping in the continuous range. We kept all principal components\
    \ that explained a variance of at least 0.05. Finally, we used the Silhouette\
    \ method [15] to determine the best number of clusters within a range of 1 to\
    \ 20. To identify the features that best characterize each cluster, we have calculated\
    \ the deviation of each cluster centroid (i.e, the center of the cluster) from\
    \ the centroid-of-centroids (C ) over all clusters.\n\nAs an unsupervised method,\
    \ the result of K-means provides only the clustering result with the stores in\
    \ each cluster. We then further discussed the results of the K-means process and\
    \ categorized the clusters by the properties of the contained stores. Following\
    \ our discussion and categorization, we assigned groupings and names to each of\
    \ the clusters.\n\n#### 4 Results\n\nIn this section, we present the results of\
    \ our investigations into each of the research questions. The results are organized\
    \ based on the three stages discussed in Sec. 3.\n\n### RQ1: What fundamental\
    \ features describe the space of app stores?\n\n#### Stage 1: Features characterizing\
    \ app stores\n\nAs discussed in Sec. 3.1, we derived a set of features and organizational\
    \ categories that describe the set of studied app stores; the results of these\
    \ efforts are summarized in Table 4.1. We have modelled the features as a binary\
    \ representation; thus, each store either has or does not have this feature. We\
    \ note that for some categories, the features are mutually exclusive; for example,\
    \ in the category Rights Management, a store can have either Creator managed DRM\
    \ or Store-enforced DRM, but not both. In other categories, an app store may have\
    \ several of the features within a given category; for example, there may be several\
    \ kinds of communication channels between users, app creators, and the store owner\
    \ for a given app store. We now describe each high-level category in detail.\n\
    \n> Monetization — describes what, if any, payment options are provided to the\
    \ user directly by the store. If a product is offered free within the store, but\
    \ requires an activation key obtained elsewhere, we consider that the product\
    \ is free. While most of the options are self-explanatory, some may be less obvious.\
    \ For example, GitHub Marketplace offers seat-based subscriptions where app pricing\
    \ is calculated by the number of installations made to individual machines; usually,\
    \ this occurs within the context of enterprise purchase. Also, AWS offers resource-based\
    \ subscription where the price charged is determined by the amount of resources\
    \ — such as cloud storage and CPU time — that are used during the execution of\
    \ the service.\n\n> Rights Management — describes the Digital Rights Management\
    \ (DRM) policy of the store; the values describe whether the store uses a store-wide\
    \ DRM feature. For example, for Steam, all games have DRM encryption, whereas\
    \ the F-Droid store contains only open source apps, so there is no need for DRM.\n\
    \n> Do I need an account? — describes whether a user can access and use the store\
    \ without being registered with the app store. We find that most stores are either\
    \ account required (e.g., Apple's App Store) or no registration possible (e.g.,\
    \ Snapcraft). However, we also found that some stores can be used without an account\
    \ for some purposes, with other features requiring explicit\n\n|  |  |  | Table\
    \ 4.1 Features for describing app stores |  |  |\n|--|--|--|----------------------------------------------|--|--|\n\
    |--|--|--|----------------------------------------------|--|--|\n\n| Feature \
    \                                               | Description                \
    \                                                                            \
    \                                                                   |\n|--------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | Monetization                                           | The type of payment\
    \ options directly offered by the app store.                                 \
    \                                                                           |\n\
    | Free                                                   | Free as in in the product\
    \ can be directly acquired                                                   \
    \                                                                     |\n| One-time\
    \ payment                                       | A single payment needed for\
    \ the product                                                                \
    \                                                                   |\n| Seat-based\
    \ subscription                                | The subscription is based on the\
    \ number of products provided                                                \
    \                                                              |\n| Time-based\
    \ subscription                                | A payment is needed by a set time\
    \ interval (e.g.\" monthy, yearly)                                           \
    \                                                              |\n| Resourced-based\
    \ subscription                           | A payment is needed by the amount of\
    \ resource used (e.g., API calls, CPU time)                                  \
    \                                                          |\n| Micro-transaction\
    \                                      | Additional payment can be collected based\
    \ on additional feature offered in a product                                 \
    \                                                     |\n| Custom pricing (i.e.,\
    \ \"Contact us for price\")          | The actual price is based on a per case\
    \ situation; this happens mostly in business-focused<br>app stores           \
    \                                                       |\n| Rights Management*\
    \                                     | How does the store take care of DRM on\
    \ the product provided.                                                      \
    \                                                        |\n| Creator-managed\
    \ DRM                                    | No DRM is offered by the store and\
    \ is taken care of by the creator                                            \
    \                                                            |\n| Store-enforced\
    \ DRM                                     | Store wide DRM for every product offered\
    \ in the store                                                               \
    \                                                      |\n| Do I need an account?*\
    \                                 | Whether it is possible to use the app store\
    \ without registration.                                                      \
    \                                                   |\n| Account required    \
    \                                   | An account is required to use the store\
    \                                                                            \
    \                                                       |\n| No registration possible\
    \                               | The store does not have an account system  \
    \                                                                            \
    \                                                   |\n| Some features requires\
    \ registration                    | Some content of the store is locked behind\
    \ an account, but the store can be used without<br>one.                      \
    \                                                    |\n| Product type       \
    \                                    | The type of product the store offers. \
    \                                                                            \
    \                                                        |\n| Standalone apps\
    \                                        | The product operates by itself    \
    \                                                                            \
    \                                                            |\n| Extension/add-ons\
    \ to apps/hardware                     | The product acts as a feature extension\
    \ to another application/hardware                                            \
    \                                                       |\n| Service/resources\
    \                                      | The software product is a service   \
    \                                                                            \
    \                                                          |\n| Package/library\
    \                                        | The product is not an end-user product,\
    \ but offers functionality to other products                                 \
    \                                                       |\n| Target audience*\
    \                                       | The intended users of the app store.\
    \                                                                            \
    \                                                          |\n| General purpose\
    \                                        | The app store is intended to be used\
    \ by everyone.                                                               \
    \                                                          |\n| Domain-specific<br>Type\
    \ of product creators            | The app store have a specific focus and is\
    \ very unlikely to be used by a normal person<br>The type of creators who submits\
    \ products to the app store.                     |\n| Business               \
    \                                | The creators mostly have a commercial or business\
    \ focus                                                                      \
    \                                             |\n| Community                 \
    \                             | The creators are from the community (e.g., open\
    \ source developers)                                                         \
    \                                               |\n| Intent of app store     \
    \                               | The reason why the app store exists from the\
    \ app stores' perspective.                                                   \
    \                                                  |\n| Community building/support\
    \                             | The app store aims to serve a technical community\
    \                                                                            \
    \                                             |\n| Profit                    \
    \                             | The app store aims to earn money             \
    \                                                                            \
    \                                                 |\n| Centralization of product\
    \ delivery                     | The app store aims to provide a way for customer\
    \ to gather apps in a centralized way                                        \
    \                                              |\n| Expanding a platform popularity/usefulness\
    \             | The app store aims to extend functionality from the platform it\
    \ is based on                                                                \
    \                               |\n| Role of intermediary                    \
    \               | The role app store play between the creator of products and\
    \ the customer of the app store.                                             \
    \                                   |\n| Embedded advertisement API          \
    \                   | Provides an advertisement method for creators to take advantage\
    \ of                                                                         \
    \                               |\n| CI/CD                                   \
    \               | Offers continuous integration/continuous deployment for creators\
    \                                                                            \
    \                              |\n| Checks at run time                       \
    \              | Provide checks when apps installed from the app store is ran\
    \                                                                            \
    \                                  |\n| Checks before making available to the\
    \ customer         | Provide checks when an app is submitted to the app store\
    \ for quality reasons                                                        \
    \                                      |\n| Composability*                   \
    \                      | The relationship between products provided in the app\
    \ store.                                                                     \
    \                                         |\n| Independent<br>Vendor internal\
    \ add-on/extension/unlock | The products in the app store are unrelated to each\
    \ other<br>Some products can be based on other products from the same creator\
    \ (e.g., game DLC,                          |\n|                             \
    \                           | app feature packs)                             \
    \                                                                            \
    \                                               |\n| Package manager type of app\
    \ relationship               | A dependency relationship exists between products\
    \ in the app store                                                           \
    \                                             |\n| Analytics                 \
    \                             | The type of analytical data provided by the app\
    \ store.                                                                     \
    \                                               |\n| Sentiment and popularity\
    \ ratings                       | Information related to the popularity of a product\
    \ (e.g., downloads, score ratings)                                           \
    \                                            |\n| Marketing feedback         \
    \                            | Information related to marketing for the creator\
    \ (e.g., sales, conversion, retention)                                       \
    \                                              |\n| Product usage data<br>Communication\
    \ channels           | Information related to the usage of the product. (e.g.,\
    \ logging, user profiling)<br>The methods where different parties of the app store\
    \ can communicate with each other. |\n| Documentation                        \
    \                  | Information related to the operation of the store (e.g.,\
    \ instructions to install applications)                                      \
    \                                      |\n| Product homepage                 \
    \                      | A homepage for a specific product in the app store  \
    \                                                                            \
    \                                          |\n| Ratings                      \
    \                          | Any form of rating customers can give to a product\
    \ (e.g., star, score, up/down vote)                                          \
    \                                            |\n| Written reviews (in text)  \
    \                            | A written viewer where customers can write their\
    \ experience to the product.                                                 \
    \                                              |\n| Community forum          \
    \                              | A forum like feature offered by the store where\
    \ people can discuss things related to the                                   \
    \                                               |\n|                         \
    \                               | store/product.                             \
    \                                                                            \
    \                                                   |\n| Support ticket      \
    \                                   | A system where customers can inquiry for\
    \ support questions related to the product offered<br>by the store.          \
    \                                                      |\n| Promotion/marketing\
    \                                    | The store offers a way to provide promotional/marketing\
    \ feature to the products in the<br>app store (e.g., featured apps, top downloads\
    \ of the month).                    |\n\n\\*: Categorical values are mutually\
    \ exclusive; one and only one categorical value in the dimension can apply to\
    \ a given store.\n\nregistration; for example, the Microsoft Store allows users\
    \ to download free applications without an account, but to purchase an app or\
    \ leave a review, an account is required.\n\n> Product type — describes the kinds\
    \ of applications that are offered by the store. For example, Google Play and\
    \ Steam focus on standalone apps, the VSCode Marketplace store offers add-ons\
    \ to an existing tool, and AWS allows users to \"rent\" web-based resources and\
    \ services.\n\n> Target audience — describes the intended user base of the store.\
    \ Generalpurpose stores offer products aimed at the broad general public of everyday\
    \ technology users; this includes stores such as Google Play, Steam, and the Chrome\
    \ Web Store. Domain-specific stores, on the other hand, have a dedicated focus\
    \ on a specialized field; for example, Adobe Magento focuses on building e-commerce\
    \ platforms.\n\n> Type of product creators — describes the typical focus of creators\
    \ submitting applications to the store. We distinguish between two groups of creators:\
    \ those with a commercial or business focus, and those with community focus such\
    \ as open source developers.\n\n> Intent of app store — describes the perceived\
    \ high-level goals of the app store. The values are derived from the app stores'\
    \ own descriptions of their goals, often found in \"About us\" web pages. For\
    \ example, both F-Droid and ApkPure are Android app stores; however, F-Droid's\
    \ focus is to provide a location to download and support FOSS software, while\
    \ ApkPure's goal is to provide a location for users to be able to download Android\
    \ apps when Google Play may be unavailable.\n\n> Role of intermediary — describes\
    \ the roles that the app store plays in mediating between the users and creators;\
    \ these are software engineering-related services that are mostly independent\
    \ of each other. For example, checks at run time tracks if the app store ensures\
    \ that its products function correctly (e.g., Steam tracking game stats). Also,\
    \ CI/CD indicates that the app store provides explicit support for continuous\
    \ integration and deployment of the apps, which may be linked to specific development\
    \ tools used by the creator.\n\n> Composability — describes the relationship between\
    \ products offered by the store. App stores of independent composability offer\
    \ products that have no relationship with each other, such as Firefox Add-ons.\
    \ Vendor internal add-on/extension/unlock means that the products within the app\
    \ store can be based on each other, but only when they are from the same vendor,\
    \ such as game DLC and micro-transaction unlocks. Package managers contain apps\
    \ that can have complicated dependency relationships regardless of the creator\
    \ of the products, such as the Ubuntu package management tool apt.\n\n> Analytics\
    \ — describes what kind of diagnostic information is provided by the store. We\
    \ distinguish between three kinds: Sentiment and popularity ratings offer user-based\
    \ information related to store products, such as number of installs in Home Assistant.\
    \ Marketing feedback tracks telemetry information for creators on the performance\
    \ of their product, such as GitHub Marketplace tracking retention rate for their\
    \ products for creators. Product usage data details the observed usage of the\
    \ products; for example, Steam tracks the average number of hours users spend\
    \ on each product.\n\n> Communication channels — tracks the types of methods the\
    \ store directly offers for communications between both users and creators. Since\
    \ most stores offer a product homepage for each of their products, the app creators\
    \ are largely free to put any information here. This means that if a creator wishes,\
    \ they can put links to other communication methods external to the store. We\
    \ do not track such information here since it is product dependent instead of\
    \ store dependent. While ratings and reviews/comments are often paired together,\
    \ during our exploration, we found cases where user ratings were permitted but\
    \ user reviews were not; thus, we have separate values for ratings and reviews.\
    \ Communication channels can take various forms with different variability, for\
    \ example, some stores allow responses for reviews. For this aspect, we stay at\
    \ a high level based on the functionality of the communication channels and consider\
    \ the variations as detailed implementation for each functionality.\n\nStage 2:\
    \ Expanded collection of app stores and labeled set of representative stores\n\
    \nIn stage 1, we identified 53 store candidates. To provide the required data\
    \ for our experiments, two authors explored these stores to identify which of\
    \ the fundamental features of the previous stage are true for each store. The\
    \ query results are summarized in Table 4.2, where we list the search term construction\
    \ keywords and the first 3 occurrence of stores by the search term. For example,\
    \ in search term constructed from (addon OR add-on) and (\"market place\") OR\
    \ marketplace, the first 3 occurrences are Google Play, PrestaShop, and CS-Cart.\n\
    \nThere are many app stores beyond Google Play and Apple's App Store. These app\
    \ stores exhibit a diverse set of features.\n\n#### RQ2: Are there groups of stores\
    \ that share similar features?\n\nUsing the labeled data of the 53 stores, we\
    \ were able to perform the K-means cluster analysis that we have introduced in\
    \ Sec. 3.2. With the number of clusters guided by the Silhouette method to choose\
    \ the best K value for Kmeans, our clustering resulted in eight clusters.\n\n\
    Due to the nature of unsupervised methods, K-means is able to identify only the\
    \ clusters and their members; no real-world meanings are extracted for why the\
    \ cluster members belong together. It is also important to note that the K-means\
    \ algorithm performs hard clustering; that is, it creates a partitioning of the\
    \ stores into mutually exclusive groups that together span the whole space. Thus\
    \ each store will be assigned to the unique cluster that the algorithm considers\
    \ to best represent it. For this reason, the raw results from K-means should not\
    \ be seen as authoritative, but rather as a vehicle for identifying groups of\
    \ stores with similar characteristics. Therefore, we leverage the K-means clustering\
    \ and further examine the clusters in detail to try to derive a human understandable\
    \ categorization of the stores.\n\nWe start by analyzing the differences between\
    \ clusters by analyzing the definitive characteristics of each cluster. In Sec.\
    \ 4, we show the details of the top 10 features that deviate the most from the\
    \ C. Column C contains\n\n|                                | store)<br>OR<br>store\"\
    <br>(\"app                                      | OR<br>place\"<br>marketplace)<br>(\"\
    market                                   | shop                              \
    \                                   | repository                             \
    \              | manager                                   |\n|--------------------------------|----------------------------------------------------------------------|----------------------------------------------------------------------------|----------------------------------------------------------------------|------------------------------------------------------|-------------------------------------------|\n\
    | app                            | Store,<br>App<br>Play<br>Google<br>Apple  \
    \                           | Google<br>BigCommerce,<br>HubSpot<br>Play,     \
    \                            | Store<br>App<br>Apple                         \
    \                       | Guardian<br>IzzyOn-<br>F-Droid,<br>Project,<br>Droid\
    \ | Play<br>Google                            |\n| software                  \
    \     | Store<br>App<br>Mac                                                  |\
    \ Sella-<br>MarketPlaceKit,<br>CS-Cart<br>cious,                             |\
    \ ϕ                                                                    | ϕ   \
    \                                                 | ϕ                        \
    \                 |\n| add-on)<br>OR<br>(addon        | Home<br>Add-<br>Firefox<br>Store,<br>App<br>Assistant,<br>Mac<br>ons\
    \ | Play,<br>CS-Cart<br>PrestaShop,<br>Google                                \
    \  | Chrome<br>PrestaShop,<br>Store<br>Web                                | Kodi\
    \                                                 | Ajour,<br>CurseForge,<br>Minion\
    \           |\n| plug-in)<br>OR<br>(plugin      | SketchUca-<br>THETA<br>RICOH<br>Play,<br>Google<br>tion,\
    \             | JetBrains<br>WordPress,                                      \
    \              | Bou-<br>Plugin<br>Bukkit,<br>tique                          \
    \         | Jet-<br>WordPress,<br>Brains                         | JMeter,<br>Autodesk<br>Jenkins,\
    \           |\n| -lash)<br>-hair<br>(extension  | Mi-<br>Store,<br>Web<br>Edge<br>Chrome<br>crosoft\
    \                    | Market-<br>Magento,<br>Store<br>Adobe<br>Web<br>VSCode<br>Chrome<br>place,\
    \ | Store<br>Web<br>Chrome                                               | GNOME<br>TYPO3,<br>SHELL\
    \                             | Store<br>Web<br>Chrome                    |\n\
    | install                        | App<br>Apple<br>Play,<br>Google<br>Store  \
    \                           | Eclipse<br>Play,<br>Google                     \
    \                            | Store,<br>Mi-<br>Play,<br>Store<br>App<br>Google<br>crosoft<br>Apple\
    \ | Assis-<br>DockerHub<br>Home<br>Kodi,<br>tant,        | AP-<br>Daz3D<br>Play,<br>Google<br>KPure,\
    \ |\n| solution                       | Mi-<br>Store,<br>Store<br>App<br>crosoft<br>Mac\
    \                      | CS-Cart                                             \
    \                       | ϕ                                                  \
    \                  | ϕ                                                    | ϕ\
    \                                         |\n| -book)<br>library<br>(software\
    \ | Store<br>Microsoft                                                   | GitHub<br>Marketplace,<br>Extensions,<br>Marketplace<br>VSCode<br>QT\
    \       | ϕ                                                                  \
    \  | ϕ                                                    | ϕ                \
    \                         |\n| package                        | Store,<br>Snapcraft<br>App<br>Play,<br>Google<br>Apple\
    \               | concrete5<br>CS-Cart,                                      \
    \                | Play<br>Google                                            \
    \           | PyPI,<br>Packages<br>Packagist,<br>Ubuntu            | NPM,<br>Chocolatey,<br>NuGet\
    \              |\n|                                |                         \
    \                                             |                              \
    \                                              |                             \
    \                                         |                                  \
    \                    |                                           |\n\nTable 4.2First\
    \ three identified stores for eachGooglequery Table 4.3 The 8 clusters found by\
    \ the K-means algorithm, with top deviated features from the centroid of centroids\
    \ (C). Each cell with a value represents one of the ten most influential features\
    \ of the corresponding cluster. The number indicates the percentage of stores\
    \ with the specific feature. The color encodes whether stores in that cluster\
    \ are less (magenta) or more (green) likely to have the feature, compared to the\
    \ centroid.\n\n|                                       |      |      |      |\
    \      |      | Cluster Index |      |      |      |\n|---------------------------------------|------|------|------|------|------|---------------|------|------|------|\n\
    | Features                              | C    | 1    | 2    | 3    | 4    | 5\
    \             | 6    | 7    | 8    |\n| Monetization                         \
    \ |      |      |      |      |      |               |      |      |      |\n\
    | Free                                  | 1.00 |      |      |      |      | \
    \              |      |      |      |\n| One-time payment                    \
    \  | 0.35 | 0.00 |      | 0.00 | 0.00 |               |      |      | 1.00 |\n\
    | Seat-based subscription               | 0.09 |      | 0.50 |      |      | \
    \              |      |      |      |\n| Time-based subscription             \
    \  | 0.30 |      | 0.75 | 0.00 |      |               |      |      | 0.86 |\n\
    | Resource-based subscription           | 0.05 |      |      |      |      | \
    \              |      |      |      |\n| Micro-transactions                  \
    \  | 0.11 |      |      |      |      |               |      |      | 0.86 |\n\
    | Custom Pricing                        | 0.01 |      |      |      |      | \
    \              |      |      |      |\n| Rights Management                   \
    \  |      |      |      |      |      |               |      |      |      |\n\
    | Creator managed DRM                   | 0.72 |      | 0.25 | 1.00 |      | \
    \              |      |      | 0.14 |\n| Store-enforced DRM                  \
    \  | 0.27 |      | 0.75 |      |      |               |      |      | 0.86 |\n\
    | Do I need an account to use the store |      |      |      |      |      | \
    \              |      |      |      |\n| Account Required                    \
    \  | 0.33 |      |      | 0.00 |      | 0.75          | 1.00 |      | 0.86 |\n\
    | No registration possible              | 0.35 | 1.00 | 0.00 |      | 0.00 | \
    \              | 0.00 | 1.00 |      |\n| Some features require registration  \
    \  | 0.30 |      | 1.00 |      | 1.00 |               |      |      |      |\n\
    | Product Type                          |      |      |      |      |      | \
    \              |      |      |      |\n| Standalone apps                     \
    \  | 0.42 |      | 0.00 |      |      |               |      | 1.00 |      |\n\
    | Extension/add-ons to apps/hardware    | 0.68 | 0.33 |      |      |      | \
    \              |      | 0.00 |      |\n| Service/Resources                   \
    \  | 0.08 |      |      |      |      |               |      |      |      |\n\
    | Package/Library                       | 0.17 | 0.89 |      |      |      | \
    \              |      |      |      |\n| Target audience                     \
    \  |      |      |      |      |      |               |      |      |      |\n\
    | General purpose                       | 0.33 |      |      | 0.00 | 0.83 | \
    \              | 0.00 | 1.00 |      |\n| Domain-specific                     \
    \  | 0.67 |      |      | 1.00 | 0.17 |               | 1.00 | 0.00 |      |\n\
    | Type of product creators              |      |      |      |      |      | \
    \              |      |      |      |\n| Business                            \
    \  | 0.67 | 0.22 |      | 0.00 |      |               | 1.00 |      |      |\n\
    | Community                             | 0.67 |      |      | 1.00 |      | \
    \              | 0.11 |      |      |\n| Intent of app store                 \
    \  |      |      |      |      |      |               |      |      |      |\n\
    | Community building / support          | 0.52 |      | 1.00 |      | 1.00 | 0.00\
    \          | 0.11 |      |      |\n| Profit                                | 0.38\
    \ | 0.00 |      | 0.00 | 0.00 |               | 0.78 | 0.00 | 1.00 |\n| Centralization\
    \ of product delivery    | 0.84 |      |      |      |      |               |\
    \      |      |      |\n| Expanding the platform                | 0.76 |     \
    \ |      |      |      |               |      | 0.17 |      |\n| Role of intermediary\
    \                  |      |      |      |      |      |               |      |\
    \      |      |\n| Embedded Advertisement API            | 0.16 |      |     \
    \ |      |      |               |      |      | 0.71 |\n| CI/CD              \
    \                   | 0.05 |      |      |      |      |               |     \
    \ |      |      |\n| Checks at run time                    | 0.14 |      | 0.50\
    \ |      |      |               |      |      |      |\n| Quality/security checks\
    \               | 0.74 |      |      |      |      | 0.25          |      |  \
    \    |      |\n| Composability                         |      |      |      |\
    \      |      |               |      |      |      |\n| Independent          \
    \                 | 0.56 | 0.00 |      |      | 1.00 | 1.00          |      |\
    \      | 0.00 |\n| Vendor internal                       | 0.15 |      |     \
    \ |      |      |               |      |      | 1.00 |\n| Package manager type\
    \                  | 0.19 | 1.00 |      |      |      |               |      |\
    \      |      |\n| Analytics                             |      |      |     \
    \ |      |      |               |      |      |      |\n| Sentiment and popularity\
    \ ratings      | 0.73 |      |      |      |      | 0.00          |      | 0.33\
    \ |      |\n| Marking feedback                      | 0.25 |      |      |   \
    \   |      |               |      |      |      |\n| Product Usage data      \
    \              | 0.33 |      |      |      |      |               |      |   \
    \   |      |\n| Communication channels                |      |      |      | \
    \     |      |               |      |      |      |\n| Documentation (wikis, FAQs)\
    \           | 0.81 |      |      |      |      | 0.25          |      |      |\
    \      |\n| Product homepage                      | 0.97 |      |      |     \
    \ |      |               |      |      |      |\n| Star/Score/Up/Downvote rating\
    \         | 0.57 | 0.11 | 1.00 |      | 1.00 | 0.00          | 1.00 | 0.00 | \
    \     |\n| Written reviews (in text)             | 0.47 | 0.00 |      |      |\
    \ 1.00 | 0.00          | 0.89 | 0.00 |      |\n| Community Forum             \
    \          | 0.45 |      |      | 0.75 |      | 0.00          |      |      |\
    \      |\n| Support Ticket                        | 0.35 |      |      |     \
    \ |      |               |      |      |      |\n| Promotion/Marketing       \
    \            | 0.71 |      |      |      |      | 0.25          |      |     \
    \ |      |\n\nthe centroid-of-centroids with values for each feature. The remaining\
    \ columns represent each cluster by an index from 1 to 8. The values in these\
    \ columns represent the proportion of app stores in the cluster with a specific\
    \ feature, the mean, and the background color of each cell represent the deviation\
    \ of the particular cluster centroid (i.e., difference between the centroid of\
    \ this cluster and the centroid-of-centroids for the feature). Each row corresponds\
    \ to a feature of the stores, which makes it easy to understand which features\
    \ are descriptive of a cluster.\n\nThe table only shows the top 10 deviations\
    \ per cluster (i.e., column) to focus on the most important contributors to each\
    \ cluster. Since all features are binary — each store has or does not have the\
    \ feature— all values of the centroid-of-centroids are between [0, 1]; thus, a\
    \ positive deviation (shown with a green background) implies that the stores in\
    \ the cluster are more likely to have the attribute, and a negative deviation\
    \ (shown with a magenta background) implies that the stores are less likely to\
    \ have the attribute.\n\nFor example, for cluster 8 the most important contributor\
    \ is [Composability] Vendor internal add-on/extension/unlock where the centroid\
    \ of the cluster is 1. When comparing against the centroid-of-centroids (at 0.15),\
    \ the deviation is at 0.85; this implies that all stores in this cluster have\
    \ this feature. On the other hand, an example of negative deviation for cluster\
    \ 1 is the feature [Composability] Independent with a centroid of 0 indicating\
    \ that no stores in this cluster have this feature. Since the centroid-of-centroids\
    \ for this features is at 0.56, this implies the deviation for stores in this\
    \ cluster is −0.56.\n\nAfter the top characteristics that make each cluster distinctive\
    \ had been identified, we leveraged this information to name and describe each\
    \ cluster accordingly. Using the information from Sec. 4 which shows the defining\
    \ features of each cluster, we derived an organization of the clusters based on\
    \ several dimensions. The results are described in Table 4.4.\n\nOne important\
    \ dimension focuses on the type of application served by stores in the cluster.\
    \ We identified three major types of applications that differentiate the clusters:\
    \ General, where the store offers stand-alone programs that run without the need\
    \ of specific software (aside from a specific operating system, e.g., Google Play,\
    \ AWS, Steam); Extensions, where the store offers extensions to a specific program\
    \ or platform e.g., VSCode Marketplace for VSCode, Chrome Web Store for Google\
    \ Chrome; and Package manager, where the store offers stand-alone programs, but\
    \ also manages dependencyrelationships and requirements between different applications\
    \ in the store e.g., NPM, MacPorts, Ubuntu Packages. Another dimension in which\
    \ these clusters can be organized is whether they are Commercial (business-oriented)\
    \ or Community-managed (no money is involved).\n\nApp stores are not all alike.\
    \ Intuitive groupings emerge naturally from the data. Their differences can be\
    \ due to the type of application they offer standalone or extensions — and their\
    \ operational model, either business- or community-oriented. We found that app\
    \ stores in different groups of our clustering have different properties, and\
    \ these properties may have bearing on empirical studies involving app stores.\n\
    \nTable 4.4List of stores and descriptions by cluster, with the example store\
    \ that is closest to cluster centroid\n\n| Type                              \
    \      | Cluster<br>in<br>Stores                                             \
    \                                                                            |\
    \ Store<br>Example                                                           \
    \                                                                            \
    \                 | Description<br>Cluster                                   \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                      | Index |\n|-----------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|-------|\n\
    | specialized<br>Commercial<br>Extensions | Hub-<br>AutoDesk,<br>Boutique,<br>SketchUcation,<br>GoG,<br>Magento,<br>Plugin<br>BigCommerce,<br>Shop,<br>CS-Cart<br>Adobe<br>Presta<br>Spot,\
    \  | addons<br>solution<br>offers<br>ecommerce<br>Shop<br>platform.<br>Presta<br>the<br>to\
    \                                                                            \
    \       | Creators<br>sys-<br>rating<br>specific.<br>offers<br>front<br>domain<br>store<br>very<br>their<br>are<br>reviews.<br>and<br>stores<br>business<br>written<br>the<br>in<br>mostly<br>and<br>Products<br>tems<br>are\
    \                                                                            \
    \                                     | 6     |\n| specialized<br>Community  \
    \              | Docker<br>Jme<br>VSCode<br>Assistant,<br>CurseForge,<br>Minion,<br>Marketplace<br>Home<br>Kodi,<br>Bukkit,<br>Hub,<br>ter,\
    \                      | center.<br>components<br>the<br>entertainment<br>to<br>extensions<br>add-on<br>offers<br>Kodi<br>Kodi\
    \                                                                   | prod<br>domain.<br>free<br>offers<br>specific<br>that<br>stores<br>a<br>to<br>tailor<br>focused<br>also<br>community<br>Stores<br>users.<br>are<br>to<br>These<br>ucts\
    \                                                                            \
    \                                                                            \
    \     | 3     |\n| non-specialized<br>Community            | Web<br>Marketplace,<br>Gnome,<br>Chrome<br>Add-ons,<br>Eclipse<br>Wordpress<br>Apkpure,<br>Firefox<br>Store,\
    \                                    | using<br>platform.<br>free<br>users<br>offers<br>for<br>wordpress<br>Wordpress<br>extensions<br>the\
    \                                                                     | in<br>generic<br>platform.<br>(e.g.,<br>a<br>face<br>the<br>registration<br>other.<br>to<br>stores<br>extensions<br>each<br>the<br>from<br>need<br>in<br>offered<br>independent<br>offers<br>not<br>do<br>stores<br>Products<br>operations<br>these<br>are<br>apps).<br>and<br>in<br>Products<br>Essential<br>audience<br>stalling\
    \ | 4     |\n| Commercial<br>General                   | Nintendo<br>Samsung<br>App<br>Store,<br>Apple<br>Play<br>Store,<br>Steam,<br>Store,<br>Google<br>Microsoft<br>Galaxy<br>eShop,<br>AWS,<br>Store\
    \ | offers<br>the<br>platform.<br>Store<br>for<br>applications<br>MicroSoft<br>windows\
    \                                                                            \
    \          | run<br>supporting<br>They<br>everyday.<br>products<br>encounter<br>internal<br>options.<br>people<br>vendor<br>many<br>offer<br>monetization<br>stores<br>and<br>profit<br>Typical<br>most<br>for\
    \                                                                            \
    \                                                      | 8     |\n| Community\
    \                               | Flat<br>Project<br>IzzyOnDroid,<br>F-Droid,<br>Guardian<br>Chocolatey,<br>Repository,<br>Snapcraft<br>pak,\
    \                                      | open<br>store.<br>and<br>only<br>application<br>free<br>software<br>a<br>is<br>Android<br>F-Droid<br>source\
    \                                                             | Cre<br>and<br>community<br>only.<br>products<br>the<br>source.<br>free<br>from<br>standalone<br>open<br>mostly<br>majority<br>are<br>contain<br>stores<br>are<br>the<br>products<br>stores<br>for<br>These<br>ators<br>the\
    \                                                                            \
    \                             | 7     |\n| Manager<br>Package                \
    \      | Packagist,<br>pack<br>MacPorts,<br>Ubuntu<br>Jenkins,<br>NuGet,<br>Typo3,<br>Ajour,<br>NPM,<br>PyPI,<br>ages\
    \                                    | main<br>PHP<br>the<br>for<br>is<br>repository<br>Packagist<br>packages.\
    \                                                                            \
    \                     | Products<br>inter-dependency<br>limited<br>also<br>stores.<br>stores.<br>are<br>most<br>these<br>channels<br>with<br>for<br>for<br>style<br>missing<br>involved<br>Communication<br>package<br>reviews<br>is<br>in<br>system<br>most<br>and<br>relationships.<br>ratings<br>and<br>account<br>free<br>with<br>are<br>No\
    \            | 1     |\n| oriented<br>Subscription                | Jet<br>con<br>Marketplace,<br>Marketplace,<br>marketplace<br>Qt<br>Github<br>Brains,<br>crete5\
    \                                                  | to<br>offers<br>repositories<br>actions<br>workflow<br>Marketplace<br>GitHub<br>and<br>git<br>applications<br>the<br>to<br>on<br>improve<br>Github<br>related<br>hosted\
    \ | DRM<br>standalone<br>plat<br>a<br>supports<br>extends<br>not<br>or<br>are<br>and<br>service<br>Products<br>services<br>provide<br>store.<br>subscription<br>either<br>the<br>and<br>by<br>management<br>offers<br>applications<br>Often<br>form.\
    \                                                                            \
    \       | 2     |\n| Other                                   | RICOH<br>daz3D<br>Sellacious,<br>MarketPlaceKit,<br>THETA,\
    \                                                                            \
    \          | platform.<br>ecommerce<br>provides<br>the<br>a<br>and<br>to<br>is<br>Sellacious<br>extensions<br>platform\
    \                                                               | stores<br>the<br>offered.<br>to<br>The<br>centrally<br>channels<br>stores.<br>communication<br>extensions<br>the<br>in<br>exist<br>distribute<br>on.<br>not<br>based<br>much<br>do<br>reviews<br>have<br>are<br>to<br>they<br>exists<br>not<br>and<br>platform<br>do<br>Rating<br>mostly<br>They\
    \                                   | 5     |\n\n#### What is an App Store? The\
    \ Software Engineering Perspective 23\n\n# 5 Discussion\n\nIn this section, we\
    \ discuss our findings regarding what we consider app stores to be based on our\
    \ clustering results, and we describe various research opportunities involving\
    \ the influence of app stores on software engineering practices.\n\n# 5.1 What\
    \ Is an App Store?\n\nThe term app store became popular largely through Apple's\
    \ App Store, which launched in 2008 along with the iPhone 3G [73]. Other online\
    \ software stores have also appeared and have had the term applied to them. Originally,\
    \ the term usually referred to stores of applications for mobile devices, but\
    \ we have found that today there is ample diversity of the type of applications\
    \ that app stores offer and in the features they provide to app developers and\
    \ users. App Stores are also dynamic: features are continually being added, removed,\
    \ and altered by store owners in response to changes in their goals and feedback\
    \ from their socio-technical environments. For example, the Chrome Web Store initially\
    \ introduced a built-in monetization option that provided a mechanism for applications\
    \ to receive payments from its users; however, the store later decided to deprecate\
    \ this monetization option [74] and suggested developers to switch to alternative\
    \ payment-handling options.\n\nIn our work, we have employed a working definition\
    \ through our inclusion/exclusion criteria for app stores to be included in our\
    \ research. However, due to the complexity, diversity, and constantly evolving\
    \ nature of app stores, we have decided not to attempt a firm, prescriptive definition\
    \ of the term. Instead, in the following paragraphs, we will discuss each of several\
    \ aspects of app stores in detail, and hope that in the future, a more robust\
    \ definition and operating model can emerge.\n\n#### 5.1.1 Common Features of\
    \ App Stores\n\nAlthough we found significant diversity among the example app\
    \ stores we studied, we were able to identify a set of three common features that\
    \ appear to span the space of app stores.\n\n> Simple installation and updates\
    \ of apps — An app store facilitates simple installation of a selected application,\
    \ and can also enable simple updating. For some stores, apps are expected to run\
    \ on the hardware of the client; in others, the app store provides and manages\
    \ the hardware where the app runs. In both cases, the app store frees the user\
    \ from worrying about the technical details of installation, including compatibility\
    \ with their specific hardware and software configuration, as well as the installation\
    \ of the app and its dependencies, if any. Typically, app stores will also automate\
    \ the installation of updates to the application, again freeing the user from\
    \ worrying about if they have the latest version of the app with the latest features\
    \ and bug fixes.\n\n> App exploration and discovery — App Stores provide mechanisms\
    \ that allow users to find apps they might want to use. In its simple form, this\
    \ mechanism might be a search engine that returns a list of apps that match a\
    \ given set of keywords (such as homebrew, PyPI). In the labeled app stores, 73%\
    \ of stores provide some kind of aggregated recommendations (e.g., advertisement\
    \ and trends in WordPress), up to personal recommendations that are based on other\
    \ apps the user has installed before (e.g., Apple's App Store). User feedback\
    \ via reviews (present in 47% of the labeled app stores) and forums (present in\
    \ 45% of the labeled app stores) can provide further information to aid other\
    \ users in identifying apps of possible interest to them.\n\n> The app store guarantees\
    \ the runtime environment — In practice, app stores often execute within a runtime\
    \ environment (RTE), such as an operating system (e.g., Google Play on Android)\
    \ or an extensible software application (e.g., Firefox Add-ons on Firefox ). Many\
    \ app stores simply sit on top of the RTE, acting primarily as a gatekeeper for\
    \ adding and deleting apps. However, some app stores are more tightly integrated\
    \ with the RTE; in extreme cases, the app store can extend the RTE with the app\
    \ store's own functionality and together provide an augmented RTE for the applications\
    \ managed through the app store. Steam is a good example for extending the RTE\
    \ with its own features; developers can integrate with many services offered by\
    \ Steam, such as an achievement system that offers players recognition when they\
    \ fulfill certain requirements in the game. Figure 5.1 illustrates the situation\
    \ where a product may integrate with additional store-added features to the RTE,\
    \ which in turn enriches the user experience of the store users. When Product\
    \ B is offered in App Store Y, it will not have the features provided by App Store\
    \ X.\n\nThe app store ensures that apps are installed only when their runtime\
    \ requirements are satisfied. The process is often done through running checks\
    \ on apps submitted to the app store, which 74% of the labeled app stores perform\
    \ specifically. By specifying the runtime requirements, the assumption for both\
    \ the developer and the user is that if the application is installed implying\
    \ that the requirements are satisfied — it is expected to run properly. This is\
    \ usually achieved by a software layer on top of the RTE, provided by either the\
    \ app store or the user. In its simplest form, this software layer is responsible\
    \ for installing and updating apps (see \"Simple installation and updates of apps\"\
    \ above). In some cases, this software layer might also include a set of libraries\
    \ that the apps can use to provide features specific to the app store thus forming\
    \ part of the RTE for the applications. These libraries might range in purpose\
    \ (domain specific, common GUI, resource management, etc.). In extreme cases,\
    \ this layer includes the operating system, as it is the case with Apple's App\
    \ Store. However, checks during runtime is a very rare feature, which only 14%\
    \ of the labeled app stores provides.\n\nSome hardware platforms have become so\
    \ tightly integrated to the software layer of the app store that they can be considered\
    \ monolithic: the hardware is rendered unusable without the app store. This is\
    \ exemplified by the Apple's\n\n![](_page_25_Figure_1.jpeg)\n\nFig. 5.1 Stores\
    \ may offer optional extensions to the runtime environment for applications\n\n\
    App Store, where one cannot use the hardware without first having an account in\
    \ the app store; even operating system upgrades are distributed via the store.\n\
    \nThis tight level of integration has clear benefits for all three stakeholders:\
    \ end users have fewer installation technical details to worry about; app developers\
    \ can be assured that users will be able to install their apps without the need\
    \ for technical support; and app store owners can strictly manage who has access\
    \ to the user's RTE and how. However, such tight integration is technically unnecessary\
    \ and may even be undesirable. From a software engineering perspective, such tight\
    \ coupling could be seen as a \"design smell\", since the operating system and\
    \ the app store layers address fundamentally different concerns. Also, tight integration\
    \ can create an artificial barrier to competition, effectively establishing a\
    \ quasi-monopoly for the store owner; the store owner may assume the role of gatekeeper\
    \ not only for streamlining technical issues, but also for business reasons, requiring\
    \ a kind of toll to be paid by app developers for access to the store. A recent\
    \ initiative in the European Union [75] aims to enable fair competition by enforcing\
    \ that ecosystems are opened up, which will likely also allow the installation\
    \ of alternative software layers for other app stores, a term called side-loading.\
    \ In contrast to the Apple's tight control of the operating system as part of\
    \ its app store, Android allows third-party app store software (e.g., F-Droid\
    \ [76]) to be installed in co-existence with the system default (often Google\
    \ Play).\n\nAs mentioned above, some stores distribute software that runs on hardware\
    \ owned by the App Store itself; in these cases, the RTE is fully managed and\
    \ controlled by the store. For example GitHub Marketplace and Atlassian Marketplace\
    \ offer applications that run on GitHub and Atlassian servers respectively. In\
    \ most cases, these applications are not deployed to the user's computers.\n\n\
    #### 5.1.2 Different Types of App Stores\n\nWhile some features are broadly shared\
    \ by all app stores, in Sec. 4, we identified different groups of app stores based\
    \ on their features. For stores within the same group, they often share common\
    \ features, whereas across different groups, the stores tend to have less in common.\
    \ We now discuss the differences across the groups in detail.\n\n> Diversity in\
    \ goals — As a platform focusing on delivering products to customers, the high-level\
    \ goal of one app store can be dramatically different from the other. Even app\
    \ stores providing software for the same underlying RTE can have radically different\
    \ purposes. For example, consider the app stores that run on Android. Google Play\
    \ is the de facto store for Android applications. F-Droid store, on the other\
    \ hand, offers only free and open source Android applications, and APKPure offers\
    \ multiple versions of the same software so the user can decide which version\
    \ they would like to install.\n\nApple's app store offers applications for all\
    \ its RTEs: MacOS (laptop and desktops), iOS (phones and tables), and the Safari\
    \ browser. In contrast, Google has different stores for AndroidOS and for its\
    \ web browser, Chrome. The Microsoft Store sells hardware and apps for Windows\
    \ and XBox. Alexa Skills offers skills that enhance the voice agent Alexa's capabilities.\n\
    \nIn many program language ecosystems, the core language development (focusing\
    \ on the language features) and packaging system (focusing on extending the functionality\
    \ of the language) are led by separate organizations (e.g., NPM [77] and JavaScript\
    \ [78]).\n\n> Diversity in business model — Another important difference we observed\
    \ is between business-managed and community-managed stores. In businessmanaged\
    \ stores (with few exceptions), a primary goal is to generate a profit. These\
    \ stores provide a payment mechanism between the app creator and the purchaser,\
    \ with the store keeping a percentage of any sales. These stores have to solve\
    \ three key concerns: first, implementing registration and authentication of users\
    \ and developers; second, some type of digital rights management, so only users\
    \ who have acquired the software can use it; and third, a payment mechanism e.g.,\
    \ subscription, one-time payment, and advertisement.\n\nCommunity-managed stores,\
    \ on the other hand, are often run by volunteers, and their features focus on\
    \ facilitating not-for-profit product delivery from developer to user. Many community\
    \ stores offer limited community interactions compared to business stores where\
    \ customer feedback is important. For example, in the Kodi store, add-ons have\
    \ a web page (e.g., The Movie Database Python [79]). This page provides information\
    \ regarding installation of the add-on, such as known compatibility concerns,\
    \ download links, and installation requirements. Meanwhile, most communication\
    \ channels about the add-on are hosted elsewhere; for example, installation and\
    \ usage instructions, extended descriptions, and screenshots can be found in the\
    \ community forum instead.\n\nIt is important to note that the products contained\
    \ in community-oriented stores are not limited to open source software; some community-managed\
    \ app store policies often permit the distribution of proprietary software. In\
    \ the natural groupings we observed, no rights management is enforced from the\
    \ store side for Cluster 3; at the same time, most stores in Cluster 8 have some\
    \ form of rights management built-in to the store. For example, Homebrew permits\
    \ apps that are not open source if the apps are free to use; these apps might\
    \ include in-app purchases — such as an upgrade to a full-feature app — that are\
    \ handled outside of Homebrew.\n\n5.2 Implications for the Main Participant Stakeholders\n\
    \nThe results of our study includes an evidence-based detailed view of the broad\
    \ landscape of app stores. This view can help us improve the understanding of\
    \ the realities and potentialities of app stores in general. Meanwhile, the results\
    \ of our work can also benefit the different stakeholders involved with app stores,\
    \ including app creators, app stores themselves, users, and researchers.\n\n>\
    \ Application creators — Those who create applications — including those who design,\
    \ develop, test, and market apps — benefit from a holistic view of other stores\
    \ that will allow them identify potential new markets (stores where they can offer\
    \ their software) and to understand changing and emerging features that could\
    \ eventually come to their app store of choice. For new creators, this research\
    \ emphasizes that a software store has both technical requirements — such as the\
    \ use of a specific software development kit — and non-technical ones — such as\
    \ restrictions on what applications can do, approval processes and timelines —\
    \ and that these requirements vary significantly from one store to another.\n\n\
    > App Stores — The overview presented herein provides a framework for comparison\
    \ between app stores, particularly those that operate on the same market, such\
    \ as Android application stores. It can also help promote wide adoption of features\
    \ that are not universal, such as communication channels between users and developers.\n\
    \n> Users — With the diversity in app stores, especially when multiple app stores\
    \ are competing in the same domain, it allows users the chose of where to acquire\
    \ their applications. This allows for more diversity for how the apps are distributed\
    \ and the user's choice also affect the competition.\n\n> Researchers — As discussed\
    \ in Sec. 2, most prior research has focused on the applications offered in app\
    \ stores, and there is a need for research that focuses on studying the store\
    \ themselves. This emphasis could aid researchers in considering different points\
    \ of view when conducting app store-centric studies, and also suggest avenues\
    \ of exploration concerning how the development process is affected by the existence\
    \ of app stores.\n\nWe describe this point in detail in the next sections.\n\n\
    # 5.3 App Store Features\n\nIn this section, we discuss how each of feature groups\
    \ from Table 4.1 has been addressed by current SE research and we suggest some\
    \ possible future directions.\n\n> Monetization — App development can be affected\
    \ by their pricing strategy. For example different software architecture to support\
    \ a different system of monetization (e.g., locking functionality behind microtransactions)\
    \ [80]. Studies have shown a correlation between app features and pricing [11,\
    \ 81, 82]. Moreover, in many studies on apps [29, 83], free apps and charged apps\
    \ are often considered as different types of applications. Future work could further\
    \ explore how different monetization options affect app development.\n\n> Rights\
    \ management — Digital rights management is still an ongoing challenge in software\
    \ engineering. Existing studies have explored the options of implementing different\
    \ DRM systems to support developers [84,85]. DRM can also add challenges in other\
    \ development activities such as complicating the testing procedure [86] and affect\
    \ performance [87]. Often we can observe the store offering means for providing\
    \ and enforcing DRM. Because DRM is still a nascent technology within software\
    \ engineering, it remains an open area to explore for future study and how app\
    \ stores can play a role.\n\n> Account requirement — User identity enables telemetry\
    \ of user behavior. An account system is also the prerequisite of a store-wide\
    \ DRM system as discussed in the previous paragraph. Existing research has focused\
    \ on how to leverage the user identity information to create targeted recommender\
    \ systems [88] and also investigated the concerns of privacy-related issues [89].\
    \ The interest of developers (detailed tracing data) and users (privacy) are in\
    \ conflict, app stores that require user identification could prove to be an excellent\
    \ study subject for future research in that area.\n\n> Product type — Existing\
    \ research has already shown different software engineering practices based on\
    \ the software product. For example, gaming development is very different from\
    \ traditional software development and open source development [90, 91]. Research\
    \ have shown that different types of software can introduce specific challenges\
    \ unique to them [92,93]. Future research should better understand how the product\
    \ type affects user expectations and development practices, for example, with\
    \ respect to the delivery of software or the way creators and users can interact.\n\
    \n> Target audience — When an app developer decides on a specific app store to\
    \ sell their app, they are also effectively selecting for a specific type of user\
    \ [94– 96]. Users of a general-purpose store such as Google Play are different\
    \ and much more diverse than the user population [97] in very specialized stores,\
    \ such as the add-on store for a particular game. Research needs to understand\
    \ better which features are relevant in each specific context [41], so the experience\
    \ can be tailored to the concrete situation.\n\n> Type of product creators — Existing\
    \ research has shown many differences between open source and industrial software\
    \ development [91,98]. Some studies have touched the aspect of release engineering\
    \ in open source development [99], where developers would strategically select\
    \ which versions to release on the app store. However, we believe that there is\
    \ still room for more understanding in how targeting releases towards app stores\
    \ affects software development.\n\n> Intent of app store — While in most domains,\
    \ there exists a dominant app store, we can also observe situations where multiple\
    \ app stores compete in the same domain (e.g., game stores on PC, mobile app stores\
    \ in China [54]). In these situations, users have a choice of which app store\
    \ to use when the same application is offered. In practice, some studies have\
    \ explored how the high level operation of app stores can affect the software\
    \ delivery process especially involving security concerns [41, 51]. Competition\
    \ between app stores within the same domain remains largely unstudied, as does\
    \ how their operations can affect both developers and users.\n\n> Role of intermediary\
    \ — App stores provide a platform for users and developers. Researchers have explored\
    \ how it affects software development processes such as testing and release management\
    \ [100, 101]. There are many opportunities for security [102] and quality assurance\
    \ [53, 103] to be ensured on the app store side. Future study can explore how\
    \ the differences between apps managed through an app store and apps that are\
    \ not. For example, studying the difference between open-source web extensions\
    \ that are in and not in app stores.\n\n> Composability — Existing research has\
    \ explored co-installability in the scope of package manager systems [104, 105].\
    \ However, we only have limited understanding of co-installability for standalone\
    \ applications in an extension system. For example, if two standalone extensions\
    \ were to modify the same component of the underlying software, a potential incompatibility\
    \ could occur. Future research can explore this area by performing empirical studies\
    \ on existing systems to understand the issue of conflicts.\n\n> Analytics — App\
    \ stores as the central hub between developers and users have access to rich information\
    \ useful for analytics. Previous studies have taken advantage of the app store\
    \ specific information to help software developers [106–108]. For example, Ullmann\
    \ et al. [109] leveraged records of rating statistics and downloaded information\
    \ to study the factors in developing successful video games. Another study leveraged\
    \ analytic information collected by the app store to identify incompatible builds\
    \ of application and physical devices [110]. Future work can explore what are\
    \ the possible data to collect and form analytics, and how can the analytic data\
    \ be leveraged to help developers and users.\n\n> Communication channels — Communication\
    \ channels are the most studied area of app store features. Specifically, there\
    \ has been a heavy focus on app reviews, where researchers have leveraged the\
    \ information in app reviews to aid software development in areas such as extracting/locating\
    \ bug reports [43], discover feature requests [50] and collect user feedback [52].\
    \ However, existing studies also suggest that the use of communication channels\
    \ in app stores are often multi-purpose [18]. Researchers also find that some\
    \ interaction requirements between interested parties are relegated to other platforms\
    \ such as Twitter [111]. Future work can explore different types of communication\
    \ channels in their functionality and how they can integrate with app stores.\
    \ The corpora from communication channels are also rich information sources where\
    \ researchers can leverage to extract information about developer-user interactions.\n\
    \n#### 5.4 Research Opportunities Involving App Stores\n\nApp Stores are becoming\
    \ the primary channel for software delivery and exert considerable influence in\
    \ many aspects of the software development process. A previous study by Rosen\
    \ and Shihab [112] on Stack Overflow questions by mobile developers has shown\
    \ that app delivery is one of the biggest challenges developers face. Our results\
    \ in Sec. 4 demonstrate that there is a wide variety of types of stores, each\
    \ with different features and goals. Today, app stores encompass many kinds of\
    \ applications, from games running on the hardware of the user to add-ons for\
    \ applications that run on corporate servers such as GitHub. However, existing\
    \ research often focuses heavily on the applications offered inside app stores,\
    \ especially those of the two major mobile app stores. In the following paragraphs,\
    \ we discuss several research opportunities to study how app stores can affect\
    \ software development.\n\n#### 5.4.1 App Stores as Actors in Software Development\n\
    \n> App Stores affect the software product cycle — Researchers need to consider\
    \ how and why app stores can affect the software development life cycle. For example,\
    \ we know that app stores can constrain and sometimes even dictate software release\
    \ processes. Some stores go beyond this and exert a kind of socio-technical environmental\
    \ pressure on other software development practices, becoming a de facto stakeholder\
    \ in app development. Sometimes these environmental pressures are technical in\
    \ nature, where the app store might dictate the programming language or deployment\
    \ platform/OS; some app stores go further and create RTEs, software development\
    \ kits (SDKs), and user interface (UI) libraries that must be used by all app\
    \ developers. Sometimes these environmental pressures are non-technical in nature,\
    \ such as when the app store prescribes the kinds of application that is allowed\
    \ in the store. For example, Microsoft recently announced that it will not permit\
    \ app developers to profit from open source applications.<sup>3</sup> When an\
    \ app store operates in a manner such that it has control over what kind of application\
    \ to include, it creates a software ecosystem and as such, it faces the same challenges\
    \ that any other ecosystem has: how to thrive. In particular, stores need to understand\
    \ the needs of their developers and users to retain existing ones and attract\
    \ new ones. However, suggested by what we have observed in Sec. 4, app stores\
    \ are diverse with a large number of features that characterize and differentiate\
    \ between them. While stores are experimenting and evolving, each action is likely\
    \ to have an effect on the ecosystems they formed, both positively and negatively.\
    \ Thus, the impact of app stores in the economy and their markets is worthy of\
    \ further study.\n\n> An app may be offered in several app stores — Developers\
    \ want to run their software on the platform that is provided or supported by\
    \ the store, and as such they must accept the requirements and limitations that\
    \ such a store may impose. This issue is compounded when the app is being offered\
    \ in more than one store, as the developers might have to adapt their processes\
    \ to different sets of requirements, some of which might be conflicting. For instance,\
    \ an app can be both available in F-Droid (in Cluster 7) and Google Play (in Cluster\
    \ 8). In Google Play, it is common for applications to collect telemetry data\
    \ to better understand typical user behaviour; however, in F-Droid — an open source\
    \ and privacy-oriented store — such data collection is highly discouraged. Furthermore,\
    \ developers must also adapt to the features and limitations that a store provides\
    \ regarding software deployment, communication with users and — when they exist\
    \ — the mechanism available to profit from their software and to use digital rights\
    \ management. This is particularly interesting if the targeted app stores are\
    \ in different natural groupings. This introduces new areas of studies such as\
    \ how store policies propagate to applications over time, and how violations of\
    \ store policies can be detected automatically. Researchers have already begun\
    \ to investigate this topic through qualitative approaches to identify how applications\
    \ comply with specific policies that concern accessibility [29] and human values\
    \ [45].\n\n> App stores strongly affect the release engineering process — App\
    \ Stores are especially important in release engineering. Specifically, the release\
    \ process needs to consider how the application is to be packaged, deployed, and\
    \ updated. The heterogeneity of the platform provided by RTEs might also affect\
    \ the number of versions of the application that need to be deployed, e.g., variety\
    \ of target CPUs, different screen sizes and orientations, and amount of available\
    \ memory.\n\nWhen an application is developed for multiple stores, it must effectively\
    \ be managed as a product line; this is because multiple deliverables must be\
    \ created, one for each platform-store combination [113]. Multiple deliverables\
    \ can also help for telemetry reasons such as tracking the installation source\
    \ of the application [114]. The differences between packaged versions might be\n\
    \n<sup>3</sup> See Update to 10.8.7 https://docs.microsoft.com/en-us/windows/uwp/publish/\
    \ store-policies-change-history\n\nas significant as requiring the source code\
    \ to be written in different programming languages, using different frameworks;\
    \ also, each store is likely to require different deployment processes.\n\nFor\
    \ example, when cross-releasing browser add-ons, developers may have to rewrite\
    \ part of the functionality in Swift/Objective-C for better integration with Safari\
    \ (in the Apple's App Store), while at the same time maintaining a fully JavaScript\
    \ version for Chrome Web Store. Also, the scheduling of release activities is\
    \ often dictated by the release processes of the stores. A previous study has\
    \ showed that taking into consideration of app review times is an important factor\
    \ when planning releases [53]. The app store standardizes, and often simplifies,\
    \ the release engineering processes for its store; but it also becomes a potential\
    \ roadblock that might delay or even reject a new release.\n\n#### 5.4.2 The Challenge\
    \ of Transferring Understanding Between Stores\n\nAs noted above, prior work has\
    \ examined many aspects of app stores, yet the app store itself has rarely been\
    \ the focus of the research. In many studies, the app store serves as a convenient\
    \ collection of apps, and the research focuses on mobile development concerns\
    \ such as testing and bug localization. Even when research focuses on the app\
    \ store itself, the scope rarely extends beyond Google Play and Apple's App Store.\
    \ Based on our observations, the diversity of app stores in their operational\
    \ goals, business models, delivery channels, and feature sets can affect the generalizability\
    \ of research outcomes. For example, there have recently been many studies [12,18,43,45,46,50,52]\
    \ that focus on app reviews. However, for an app store that does not have reviews\
    \ (e.g., Nintendo eShop) none of the findings and tools can be leveraged (e.g.,\
    \ stores in Cluster 1, 5, and 7).\n\n> App Stores that have the same features\
    \ may still differ significantly — Depending on the problem domain, the details\
    \ of software development practices can vary dramatically. For example, game development\
    \ has been compared to both more traditional industrial software development [90]\
    \ and to open source software development [91]; in both cases, the development\
    \ processes can differ greatly. We conjecture that the same may also occur across\
    \ app stores, where despite the same feature is being offered in the different\
    \ stores, the convention of using them could be different. As mentioned above,\
    \ one specific observation has been made between the gaming-focused store Steam\
    \ and mobile stores (e.g., Google Play) in Cluster 8, where Lin et al. [12] found\
    \ that reviews across the platforms for the same app were often quite different\
    \ in tone. Such uncertainly invites future research to validate their findings\
    \ in one store to another to improve the generalizability of the results, and\
    \ also encourages replication studies to verify existing results on other stores.\n\
    \n> A feature not in the app store does not mean the functionality is missing\
    \ — While some app stores aim to provide a complete experience, where all interactions\
    \ from the developers and users are expected to be performed within the store,\
    \ some app stores export part of the work to other platforms. This can even occur\
    \ for common features that one might find essential. For instance, starred reviews\
    \ are universal in Cluster 2, 4, and 6 where typical users leverage this information\
    \ to decide whether an application is good; starred reviews are uncommon for other\
    \ stores in Cluster 1, 5, 7. The specialized store may have some other metric\
    \ to indicate popularity or quality, such as total number of downloads, but the\
    \ focus of the store is often to offer a managed way of installation. Other features,\
    \ such as application support, are left to other platforms such as social media.\
    \ Research can further explore the integration between app stores and other platforms.\n\
    \n#### 6 Threats to Validity\n\n> Internal Validity — Our initial seeding of app\
    \ stores comes from personal experience of app stores by the authors of the paper.\
    \ Personal bias could cause us to miss other types of app stores. However, given\
    \ the number of authors on this paper and our initial effort to consider as many\
    \ stores as possible, we feel that have created a wide, deep, and collaborative\
    \ \"best effort\". When we labeled app stores by their dimensions, it is a qualitative\
    \ process. As with any qualitative process, the results could be biased by the\
    \ authors performing the task. We tackled this issue by first labeling a few stores\
    \ separately by all authors and discussing the results until a consensus was achieved;\
    \ thus, we started with a set of \"gold standard\" labels. Then the labeling task\
    \ was delegated to two authors who continued to label the stores separately with\
    \ a portion of the store overlapping. The overlapping labels are then verified\
    \ by the Cohen's Kappa between the two authors to measure the agreement.\n\nWe\
    \ leveraged the K-means algorithm for the clustering process. We first applied\
    \ PCA techniques to reduce the dimensions of the initial labeling and provide\
    \ an orthogonal basis to feed the K-means clustering. When using other clustering\
    \ algorithms (e.g., Mean-shift, DBSCAN ), the clustering result might change;\
    \ while K-means is widely adopted for clustering process in SE research, by nature,\
    \ determining the proper k value is still a challenge. We followed common best\
    \ practice to use metrics (i.e., the Silhouette method) to determine the best\
    \ value k. Despite our efforts, the output of the K-means clustering is not perfect.\
    \ We mainly leveraged the K-means clustering as the first step to illustrate that\
    \ app stores forms natural clusters which are different from each other. Based\
    \ on the K-means output, we further grouped the clusters into types based on our\
    \ qualitative understanding of the app store space.\n\n> External Validity — During\
    \ the process of expanding app stores, we relied on the Google Search Engine to\
    \ find web results based on keywords. The results of this step rely on the capability\
    \ of Google and are subject to change over time as Google updates its search algorithms.\
    \ The order may also be affected by SEO operations. Combining results from other\
    \ search engines (e.g., DuckDuckGo, Bing) can help to reduce the bias.\n\nWhen\
    \ we applied our inclusion criteria, 1) app stores must contain software products\
    \ and 2) should offer an end-to-end experience for users (ordering, delivery,\
    \ installation), we excluded stores that focus on digital assets that are not\
    \ software, such as a pure assets store that offers cosmetic enhancements to desktop\
    \ environments; we also excluded stores that offer software products but in a\
    \ way such that installation is completely managed by users. An extreme example,\
    \ would be the software section of Amazon where software is sold as an activation\
    \ key which users would input to activate the software that they need to install\
    \ themselves. A more general inspection of all means of distribution software\
    \ can be performed to gain a broader understanding of software distribution.\n\
    \nWe relied on only publicly available information to label each store. So if\
    \ some functionality (e.g., analytics information) is not documented publicly,\
    \ we were unable to confirm whether the store has such functionality. We also\
    \ set a time limit to label each store so in case we were unable to find information\
    \ about the store, with each store receives the same amount of attention.\n\n\
    One of the main challenges for reproducibility and replicability is that the Google\
    \ Search results and app stores can change overtime. New app stores are likely\
    \ to emerge and existing app stores may introduce and remove features. The focus\
    \ of our study is not to establish an exhaustive catalog of app stores, nor to\
    \ study the historic evolution of a store. Our goal is to establish a framework\
    \ that can describe app stores and to understand whether the operations of app\
    \ stores follow different patterns. Based on the granularity which we extracted\
    \ features from app stores, we expect the majority of the feature groups will\
    \ remain stable over time. In the future, if researchers would like to repeat\
    \ our study, the labeling results may differ due to updates in the app store.\
    \ To mitigate this issue, we have included a snapshot of all Google Search results,\
    \ and documented how we would perform the labeling. So while the final labels\
    \ may differ, by applying the same process, a replication study would be possible\
    \ with updated data.\n\n#### 7 Summary\n\nIn this paper, we have explored the\
    \ idea of what an app store is and what features make app stores unique from each\
    \ other. We labeled a set of representative stores, curated from web search queries,\
    \ by their features to study the natural groupings of the stores. Our analysis\
    \ suggests that app stores can differ in the type of product offered in the store,\
    \ and whether the store is business oriented or community oriented. These natural\
    \ groupings of the stores challenge the manner in which app store research has\
    \ largely been mobile focused. Previous studies have already shown empirical differences\
    \ in activities in mobile app stores and game stores [12]. Our study further suggests\
    \ that in the future, when we study app stores, we will need to consider the generalizability\
    \ of the results across app stores. Since one type of app store may operate under\
    \ different constraints than another kind, results observed in one app store setting\
    \ may not generalize to others.\n\n# Conflict of Interests\n\nThe authors declared\
    \ that they have no conflict of interest.\n\n# Data Availability Statement\n\n\
    A dataset consists of the Google query results and the app store labeling results\
    \ are available on Zenodo. 4\n\nAcknowledgements We would like to thank the attendees\
    \ of the Shonan meeting [115] on \"Release Engineering for Mobile Applications\"\
    , where the paper's idea was conceived.\n\nOne of the authors has received funding\
    \ from the European Union's Horizon 2020 research and innovation programme under\
    \ grant agreement number 825328 (FASTEN).\n\n#### References\n\n- 1. C. Dixon,\
    \ R. Mahajan, S. Agarwal, A. Brush, B. Lee, S. Saroiu, and V. Bahl, \"The home\
    \ needs an operating system (and an app store),\" in SIGCOMM Workshop on Hot Topics\
    \ in Networks, ACM, 2010.\n- 2. Valve, \"Welcome to Steam.\" https://store.steampowered.com/,\
    \ 2022. Accessed: Jun. 22 2022.\n- 3. GitHub, \"GitHub Marketplace · to improve\
    \ your workflow · GitHub.\" https://github. com/marketplace?type=, 2022. Accessed:\
    \ Jun. 06 2022.\n- 4. Google, \"Chrome Web Store Extensions.\" https://chrome.google.com/webstore/\
    \ category/extensions, 2022. Accessed: Jun. 22, 2022.\n- 5. WordPress, \"WordPress\
    \ Plugins | WordPress.org.\" https://wordpress.org/plugins/, 2022. Accessed: Jun.\
    \ 22, 2022.\n- 6. Autodesk, \"Autodesk App Store : Plugins, Add-ons for Autodesk\
    \ software, AutoCAD, Revit, Inventor, 3ds Max, Maya ....\" https://apps.autodesk.com/,\
    \ 2022. Accessed: Jun. 22, 2022.\n- 7. Docker, \"Explore Docker's Container Image\
    \ Repository | Docker Hub.\" https://hub. docker.com/search?q=, 2022. Accessed:\
    \ Jun. 22, 2022.\n- 8. Amazon, \"AWS Marketplace: Homepage.\" https://aws.amazon.com/marketplace/,\
    \ 2022. Accessed: Jun. 22, 2022.\n- 9. Rémi Prévost, Mike McQuaid, and Danielle\
    \ Lalonde, \"The Missing Package Manager for macOS (or Linux) — Homebrew.\" https://brew.sh/,\
    \ 2022. Accessed: Jun. 22, 2022.\n- 10. Canonical, \"Ubuntu Software Center in\
    \ Launchpad.\" https://launchpad.net/ software-center, 2009. Accessed: Jun. 22,\
    \ 2022.\n- 11. M. Harman, Y. Jia, and Y. Zhang, \"App store mining and analysis:\
    \ MSR for App Stores,\" in Int. Conf. on Mining Software Repositories, IEEE, 2012.\n\
    - 12. D. Lin, C.-P. Bezemer, Y. Zou, and A. E. Hassan, \"An empirical study of\
    \ game reviews on the steam platform,\" in Empirical Software Engineering, Springer,\
    \ 2019.\n- 13. Wikipedia, \"Electronic AppWrapper Wikipedia.\" https://en.wikipedia.org/wiki/\
    \ Electronic\\_AppWrapper, 2022. Accessed: Jun. 22, 2022.\n- 14. J. MacQueen et\
    \ al., \"Some methods for classification and analysis of multivariate observations,\"\
    \ in Proceedings of the fifth Berkeley symposium on mathematical statistics and\
    \ probability, Oakland, CA, USA, 1967.\n- 15. P. J. Rousseeuw, \"Silhouettes:\
    \ a graphical aid to the interpretation and validation of cluster analysis,\"\
    \ in Journal of computational and applied mathematics, Elsevier, 1987.\n\n<sup>4</sup>\
    \ https://zenodo.org/record/7968192\n\n- 16. I. J. M. Ruiz, M. Nagappan, B. Adams,\
    \ and A. E. Hassan, \"Understanding reuse in the android market,\" in Int. Conf.\
    \ on Program Comprehension, IEEE, 2012.\n- 17. W. Martin, F. Sarro, Y. Jia, Y.\
    \ Zhang, and M. Harman, \"A survey of app store analysis for software engineering,\"\
    \ in Transactions on Software Engineering, IEEE, 2016.\n- 18. J. Dąbrowski, E.\
    \ Letier, A. Perini, and A. Susi, \"Analysing app reviews for software engineering:\
    \ a systematic literature review,\" in Empirical Software Engineering, Springer,\
    \ 2022.\n- 19. X. Zhan, L. Fan, S. Chen, F. Wu, T. Liu, X. Luo, and Y. Liu, \"\
    Atvhunter: Reliable version detection of third-party libraries for vulnerability\
    \ identification in android applications,\" in Int. Conf. on Software Engineering,\
    \ IEEE, 2021.\n- 20. X. Zhang, X. Wang, R. Slavin, T. Breaux, and J. Niu, \"How\
    \ does misconfiguration of analytic services compromise mobile privacy?,\" in\
    \ Int. Conf. on Software Engineering, IEEE, 2020.\n- 21. S. Rahaman, I. Neamtiu,\
    \ and X. Yin, \"Algebraic-datatype taint tracking, with applications to understanding\
    \ Android identifier leaks,\" in Joint Meeting on European Software Engineering\
    \ Conference and Symposium on the Foundations of Software Engineering, ACM, 2021.\n\
    - 22. T. Nguyen, P. Vu, and T. Nguyen, \"Code recommendation for exception handling,\"\
    \ in Joint Meeting on European Software Engineering Conference and Symposium on\
    \ the Foundations of Software Engineering, ACM, 2020.\n- 23. L. Pan, B. Cui, H.\
    \ Liu, J. Yan, S. Wang, J. Yan, and J. Zhang, \"Static asynchronous component\
    \ misuse detection for Android applications,\" in Joint Meeting on European Software\
    \ Engineering Conference and Symposium on the Foundations of Software Engineering,\
    \ ACM, 2020.\n- 24. S. Arzt, \"Sustainable Solving: Reducing The Memory Footprint\
    \ of IFDS-Based Data Flow Analyses Using Intelligent Garbage Collection,\" in\
    \ Int. Conf. on Software Engineering, IEEE, 2021.\n- 25. S. Yang, Y. Wang, Y.\
    \ Yao, H. Wang, Y. F. Ye, and X. Xiao, \"DescribeCtx: Context-Aware Description\
    \ Synthesis for Sensitive Behaviors in Mobile Apps,\" in Int. Conf. on Software\
    \ Engineering, IEEE, 2022.\n- 26. Z. Dong, M. Böhme, L. Cojocaru, and A. Roychoudhury,\
    \ \"Time-travel testing of android apps,\" in Int. Conf. on Software Engineering,\
    \ IEEE, 2020.\n- 27. S. Chen, L. Fan, G. Meng, T. Su, M. Xue, Y. Xue, Y. Liu,\
    \ and L. Xu, \"An empirical assessment of security risks of global android banking\
    \ apps,\" in Int. Conf. on Software Engineering, IEEE, 2020.\n- 28. S. Almanee,\
    \ A. Ünal, M. Payer, and J. Garcia, \"Too Quiet in the Library: An Empirical Study\
    \ of Security Updates in Android Apps' Native Code,\" in Int. Conf. on Software\
    \ Engineering, IEEE, 2021.\n- 29. A. Alshayban, I. Ahmed, and S. Malek, \"Accessibility\
    \ issues in android apps: state of affairs, sentiments, and ways forward,\" in\
    \ Int. Conf. on Software Engineering, IEEE, 2020.\n- 30. B. Yang, Z. Xing, X.\
    \ Xia, C. Chen, D. Ye, and S. Li, \"Don't do that! hunting down visual design\
    \ smells in complex uis against design guidelines,\" in Int. Conf. on Software\
    \ Engineering, IEEE, 2021.\n- 31. P. Liu, L. Li, Y. Yan, M. Fazzini, and J. Grundy,\
    \ \"Identifying and characterizing silently-evolved methods in the android API,\"\
    \ in Int. Conf. on Software Engineering: Software Engineering in Practice, IEEE,\
    \ 2021.\n- 32. S. Yu, C. Fang, Y. Yun, and Y. Feng, \"Layout and image recognition\
    \ driving crossplatform automated mobile testing,\" in Int. Conf. on Software\
    \ Engineering, IEEE, 2021.\n- 33. J. Ye, K. Chen, X. Xie, L. Ma, R. Huang, Y.\
    \ Chen, Y. Xue, and J. Zhao, \"An empirical study of GUI widget detection for\
    \ industrial mobile games,\" in Joint Meeting on European Software Engineering\
    \ Conference and Symposium on the Foundations of Software Engineering, ACM, 2021.\n\
    - 34. S. Ma, J. Li, H. Kim, E. Bertino, S. Nepal, D. Ostry, and C. Sun, \"Fine\
    \ with \"1234\"? An Analysis of SMS One-Time Password Randomness in Android Apps,\"\
    \ in Int. Conf. on Software Engineering, IEEE, 2021.\n- 35. W. Song, M. Han, and\
    \ J. Huang, \"IMGDroid: Detecting Image Loading Defects in Android Applications,\"\
    \ in Int. Conf. on Software Engineering, IEEE, 2021.\n- 36. T. Zhao, C. Chen,\
    \ Y. Liu, and X. Zhu, \"GUIGAN: Learning to Generate GUI Designs Using Generative\
    \ Adversarial Networks,\" in Int. Conf. on Software Engineering, IEEE, 2021.\n\
    - 37. J. Chen, C. Chen, Z. Xing, X. Xu, L. Zhut, G. Li, and J. Wang, \"Unblind\
    \ your apps: Predicting natural-language labels for mobile gui components by deep\
    \ learning,\" in Int. Conf. on Software Engineering, IEEE, 2020.\n- 38. K. Kuznetsov,\
    \ C. Fu, S. Gao, D. N. Jansen, L. Zhang, and A. Zeller, \"Frontmatter: mining\
    \ Android user interfaces at scale,\" in Joint Meeting on European Software Engineering\
    \ Conference and Symposium on the Foundations of Software Engineering, ACM, 2021.\n\
    - 39. D. Van Der Linden, P. Anthonysamy, B. Nuseibeh, T. T. Tun, M. Petre, M.\
    \ Levine, J. Towse, and A. Rashid, \"Schrödinger's security: Opening the box on\
    \ app developers' security rationale,\" in Int. Conf. on Software Engineering,\
    \ IEEE, 2020.\n- 40. V. Murali, E. Yao, U. Mathur, and S. Chandra, \"Scalable\
    \ statistical root cause analysis on app telemetry,\" in Int. Conf. on Software\
    \ Engineering: Software Engineering in Practice, IEEE, 2021.\n- 41. R. Sun, W.\
    \ Wang, M. Xue, G. Tyson, S. Camtepe, and D. C. Ranasinghe, \"An empirical assessment\
    \ of global COVID-19 contact tracing applications,\" in Int. Conf. on Software\
    \ Engineering, IEEE, 2021.\n- 42. A. Truelove, E. S. de Almeida, and I. Ahmed,\
    \ \"We'll Fix It in Post: What Do Bug Fixes in Video Game Update Notes Tell Us?,\"\
    \ in Int. Conf. on Software Engineering, IEEE, 2021.\n- 43. M. Haering, C. Stanik,\
    \ and W. Maalej, \"Automatically matching bug reports with related app reviews,\"\
    \ in Int. Conf. on Software Engineering, IEEE, 2021.\n- 44. S. Yu, C. Fang, Z.\
    \ Cao, X. Wang, T. Li, and Z. Chen, \"Prioritize crowdsourced test reports via\
    \ deep screenshot understanding,\" in Int. Conf. on Software Engineering, IEEE,\
    \ 2021.\n- 45. H. O. Obie, W. Hussain, X. Xia, J. Grundy, L. Li, B. Turhan, J.\
    \ Whittle, and M. Shahin, \"A first look at human values-violation in app reviews,\"\
    \ in Int. Conf. on Software Engineering: Software Engineering in Society, IEEE,\
    \ 2021.\n- 46. R. A.-L. Fischer, R. Walczuch, and E. Guzman, \"Does culture matter?\
    \ impact of individualism and uncertainty avoidance on app reviews,\" in Int.\
    \ Conf. on Software Engineering: Software Engineering in Society, IEEE, 2021.\n\
    - 47. O. Haggag, S. Haggag, J. Grundy, and M. Abdelrazek, \"COVID-19 vs social\
    \ media apps: does privacy really matter?,\" in Int. Conf. on Software Engineering:\
    \ Software Engineering in Society, IEEE, 2021.\n- 48. R. A. Shams, W. Hussain,\
    \ G. Oliver, A. Nurwidyantoro, H. Perera, and J. Whittle, \"Society-oriented applications\
    \ development: Investigating users' values from bangladeshi agriculture mobile\
    \ applications,\" in Int. Conf. on Software Engineering: Software Engineering\
    \ in Society, IEEE, 2020.\n- 49. Z. Zhang, Y. Feng, M. D. Ernst, S. Porst, and\
    \ I. Dillig, \"Checking conformance of applications against GUI policies,\" in\
    \ Joint Meeting on European Software Engineering Conference and Symposium on the\
    \ Foundations of Software Engineering, ACM, 2021.\n- 50. H. Wu, W. Deng, X. Niu,\
    \ and C. Nie, \"Identifying key features from app user reviews,\" in Int. Conf.\
    \ on Software Engineering, IEEE, 2021.\n- 51. Y. Hu, H. Wang, T. Ji, X. Xiao,\
    \ X. Luo, P. Gao, and Y. Guo, \"Champ: Characterizing undesired app behaviors\
    \ from user comments based on market policies,\" in Int. Conf. on Software Engineering,\
    \ IEEE, 2021.\n- 52. H. Guo and M. P. Singh, \"Caspar: extracting and synthesizing\
    \ user stories of problems from app reviews,\" in Int. Conf. on Software Engineering,\
    \ IEEE, 2020.\n- 53. A. A. Al-Subaihin, F. Sarro, S. Black, L. Capra, and M. Harman,\
    \ \"App Store Effects on Software Engineering Practices,\" in Transactions on\
    \ Software Engineering, IEEE, 2021.\n- 54. H. Wang, Z. Liu, J. Liang, N. Vallina-Rodriguez,\
    \ Y. Guo, L. Li, J. Tapiador, J. Cao, and G. Xu, \"Beyond google play: A large-scale\
    \ comparative study of chinese android app markets,\" in Internet Measurement\
    \ Conference 2018, 2018.\n- 55. S. Jansen and E. Bloemendal, \"Defining app stores:\
    \ The role of curated marketplaces in software ecosystems,\" in ICSOB, Springer,\
    \ 2013.\n- 56. D. Walker and F. Myrick, \"Grounded theory: An exploration of process\
    \ and procedure,\" in Qualitative health research, Sage, 2006.\n- 57. A. P. M.\
    \ Coxon et al., Sorting data: Collection and analysis. Sage, 1999.\n- 58. S. Adolph,\
    \ W. Hall, and P. Kruchten, \"Using grounded theory to study the experience of\
    \ software development,\" in Empirical Software Engineering, Springer, 2011.\n\
    - 59. R. Hoda, J. Noble, and S. Marshall, \"Developing a grounded theory to explain\
    \ the practices of self-organizing Agile teams,\" in Empirical Software Engineering,\
    \ Springer, 2012.\n- 60. Z. Masood, R. Hoda, and K. Blincoe, \"How agile teams\
    \ make self-assignment work: a grounded theory study,\" in Empirical Software\
    \ Engineering, Springer, 2020.\n- 61. C. Vassallo, S. Panichella, F. Palomba,\
    \ S. Proksch, H. C. Gall, and A. Zaidman, \"How developers engage with static\
    \ analysis tools in different contexts,\" in Empirical Software Engineering, Springer,\
    \ 2020.\n- 62. J. Chen, X. Xia, D. Lo, J. Grundy, and X. Yang, \"Maintenance-related\
    \ concerns for post-deployed Ethereum smart contract development: issues, techniques,\
    \ and future challenges,\" in Empirical Software Engineering, Springer, 2021.\n\
    - 63. P. Wang, C. Brown, J. A. Jennings, and K. T. Stolee, \"Demystifying regular\
    \ expression bugs,\" in Empirical Software Engineering, Springer, 2022.\n- 64.\
    \ J. Cohen, \"A coefficient of agreement for nominal scales,\" in Educational\
    \ and psychological measurement, Sage, 1960.\n- 65. J. Pérez, J. Díaz, J. Garcia-Martin,\
    \ and B. Tabuenca, \"Systematic literature reviews in software engineering—Enhancement\
    \ of the study selection process using Cohen's kappa statistic,\" in Journal of\
    \ Systems and Software, Elsevier, 2020.\n- 66. C. A. Lantz and E. Nebenzahl, \"\
    Behavior and interpretation of the κ statistic: Resolution of the two paradoxes,\"\
    \ in Journal of clinical epidemiology, Elsevier, 1996.\n- 67. P. Pickerill, H.\
    \ J. Jungen, M. Ochodek, M. Maćkowiak, and M. Staron, \"Phantom: Curating github\
    \ for engineered software projects using time-series clustering,\" Empirical Software\
    \ Engineering, 2020.\n- 68. V. Khatibi Bardsiri, D. N. A. Jawawi, S. Z. M. Hashim,\
    \ and E. Khatibi, \"A flexible method to estimate the software development effort\
    \ based on the classification of projects and localization of comparisons,\" Empirical\
    \ Software Engineering, 2014.\n- 69. A. Al-Subaihin, F. Sarro, S. Black, and L.\
    \ Capra, \"Empirical comparison of textbased mobile apps similarity measurement\
    \ techniques,\" Empirical Software Engineering, 2019.\n- 70. T. Kuchta, T. Lutellier,\
    \ E. Wong, L. Tan, and C. Cadar, \"On the correctness of electronic documents:\
    \ studying, finding, and localizing inconsistency bugs in PDF readers and files,\"\
    \ Empirical Software Engineering, 2018.\n- 71. D. Arthur and S. Vassilvitskii,\
    \ \"k-means++: The advantages of careful seeding,\" tech. rep., Stanford, 2006.\n\
    - 72. S. Wold, K. Esbensen, and P. Geladi, \"Principal component analysis,\" in\
    \ Chemometrics and intelligent laboratory systems, Elsevier, 1987.\n- 73. Apple,\
    \ \"Apple Introduces the New iPhone 3G.\" https://www.apple.com/ca/newsroom/ 2008/06/09Apple-Introduces-the-New-iPhone-3G/,\
    \ 2008. Accessed: Jul. 17, 2022.\n- 74. Google, \"Chrome Web Store payments deprecation.\"\
    \ https://developer.chrome.com/ docs/webstore/cws-payments-deprecation/, 2022.\
    \ Accessed: Mar. 16, 2022.\n- 75. E. Commission, \"Digital Markets Act: Commission\
    \ welcomes political agreement on rules to ensure fair and open digital markets.\"\
    \ https://ec.europa.eu/commission/ presscorner/detail/en/IP\\_22\\_1978, 2022.\
    \ Accessed: Jul. 13, 2022.\n- 76. F-Droid, \"F-Droid Free and Open Source Android\
    \ App Repository.\" https:// f-droid.org/, 2022. Accessed: Oct. 02, 2022.\n- 77.\
    \ npm, \"npm About.\" https://www.npmjs.com/about, 2022. Accessed: Oct. 02, 2022.\n\
    - 78. E. International, \"TC39 Specifying JavaScript..\" https://tc39.es/, 2022.\
    \ Accessed: Oct. 02, 2022.\n- 79. T. Kodi, \"The Movie Database Python | Matrix\
    \ | Addons | Kodi.\" https://kodi.tv/ addons/matrix/metadata.themoviedb.org.python,\
    \ 2022. Accessed: Jul. 13, 2022.\n- 80. V. V. H. Pham, X. Liu, X. Zheng, M. Fu,\
    \ S. V. Deshpande, W. Xia, R. Zhou, and M. Abdelrazek, \"PaaS-black or white:\
    \ an investigation into software development model for building retail industry\
    \ SaaS,\" in Int. Conf. on Software Engineering Companion (ICSE-C), IEEE, 2017.\n\
    - 81. A. Finkelstein, M. Harman, Y. Jia, W. Martin, F. Sarro, and Y. Zhang, \"\
    Investigating the relationship between price, rating, and popularity in the Blackberry\
    \ World App Store,\" Information and Software Technology, 2017.\n- 82. F. Sarro,\
    \ A. A. Al-Subaihin, M. Harman, Y. Jia, W. Martin, and Y. Zhang, \"Feature lifecycles\
    \ as they spread, migrate, remain, and die in app stores,\" in Int. requirements\
    \ engineering conference (RE), IEEE, 2015.\n- 83. W. Aljedaani, M. Nagappan, B.\
    \ Adams, and M. Godfrey, \"A comparison of bugs across the ios and android platforms\
    \ of two open source cross platform browser apps,\" in Int. Conf. on Mobile Software\
    \ Engineering and Systems, IEEE, 2019.\n- 84. Z. Lu, Y. Shi, R. Tao, and Z. Zhang,\
    \ \"Blockchain for digital rights management of design works,\" in Int. Conf on\
    \ Software Engineering and Service Science (ICSESS), IEEE, 2019.\n- 85. T. Gaber,\
    \ A. Ahmed, and A. Mostafa, \"Privdrm: A privacy-preserving secure digital right\
    \ management system,\" in Evaluation and Assessment in Software Engineering, ACM,\
    \ 2020.\n- 86. A. Sung, S. Kim, Y. Kim, Y. Jang, and J. Kim, \"Test automation\
    \ and its limitations: a case study,\" in Int. Conf. on Automated Software Engineering\
    \ (ASE), IEEE, 2019.\n- 87. M. Lemon, \"Two Point Hospital no longer uses Denuvo\
    \ DRM.\" https://www.vg247. com/two-point-hospital-no-longer-uses-denuvo-drm,\
    \ 2018. Accessed: Mar. 31, 2023.\n- 88. X. He, W. Dai, G. Cao, R. Tang, M. Yuan,\
    \ and Q. Yang, \"Mining target users for online marketing based on app store data,\"\
    \ in Int. Conf. on Big Data (Big Data), IEEE, 2015.\n- 89. G. L. Scoccia, M. Autili,\
    \ G. Stilo, and P. Inverardi, \"An empirical study of privacy labels on the Apple\
    \ iOS mobile app store,\" in Int. Conf. on Mobile Software Engineering and Systems,\
    \ 2022.\n- 90. E. Murphy-Hill, T. Zimmermann, and N. Nagappan, \"Cowboys, ankle\
    \ sprains, and keepers of quality: How is video game development different from\
    \ software development?,\" in Int. Conf. on Software Engineering, 2014.\n- 91.\
    \ L. Pascarella, F. Palomba, M. Di Penta, and A. Bacchelli, \"How is video game\
    \ development different from software development in open source?,\" in Int. Conf.\
    \ on Mining Software Repositories, IEEE, 2018.\n- 92. D. Lee, G. K. Rajbahadur,\
    \ D. Lin, M. Sayagh, C.-P. Bezemer, and A. E. Hassan, \"An empirical study of\
    \ the characteristics of popular Minecraft mods,\" Empirical Software Engineering,\
    \ 2020.\n- 93. M. H. Ibrahim, M. Sayagh, and A. E. Hassan, \"Too many images on\
    \ dockerhub! how different are images for the same system?,\" Empirical Software\
    \ Engineering, 2020.\n- 94. G. H. Subramanian, P. C. Pendharkar, and M. Wallace,\
    \ \"An empirical study of the effect of complexity, platform, and program type\
    \ on software development effort of business applications,\" Empirical Software\
    \ Engineering, 2006.\n- 95. I. Manotas, C. Bird, R. Zhang, D. Shepherd, C. Jaspan,\
    \ C. Sadowski, L. Pollock, and J. Clause, \"An empirical study of practitioners'\
    \ perspectives on green software engineering,\" in Int. Conf. on Software Engineering,\
    \ 2016.\n- 96. S. Gholami, H. Khazaei, and C.-P. Bezemer, \"Should you upgrade\
    \ official docker hub images in production environments?,\" in Int. Conf. on Software\
    \ Engineering: New Ideas and Emerging Results (ICSE-NIER), IEEE, 2021.\n- 97.\
    \ E. Guzman, L. Oliveira, Y. Steiner, L. C. Wagner, and M. Glinz, \"User feedback\
    \ in the app store: a cross-cultural study,\" in Int. Conf. on Software Engineering:\
    \ Software Engineering in Society, 2018.\n- 98. D. Lee, D. Lin, C.-P. Bezemer,\
    \ and A. E. Hassan, \"Building the perfect game–an empirical study of game modifications,\"\
    \ Empirical Software Engineering, 2020.\n- 99. M. Nayebi, H. Farahi, and G. Ruhe,\
    \ \"Which version should be released to app store?,\" in Int. Symposium on Empirical\
    \ Software Engineering and Measurement (ESEM), IEEE, 2017.\n- 100. M. Nayebi,\
    \ B. Adams, and G. Ruhe, \"Release Practices for Mobile Apps–What do Users and\
    \ Developers Think?,\" in Int. Conf. on software analysis, evolution, and reengineering\
    \ (saner), IEEE, 2016.\n- 101. S. Shen, X. Lu, Z. Hu, and X. Liu, \"Towards release\
    \ strategy optimization for apps in Google Play,\" in Proceedings of the 9th Asia-Pacific\
    \ Symposium on Internetware, 2017.\n- 102. G. Ferreira, L. Jia, J. Sunshine, and\
    \ C. Kästner, \"Containing malicious package updates in npm with a lightweight\
    \ permission system,\" in Int. Conf. on Software Engineering (ICSE), IEEE, 2021.\n\
    - 103. C. Tang, S. Chen, L. Fan, L. Xu, Y. Liu, Z. Tang, and L. Dou, \"A large-scale\
    \ empirical study on industrial fake apps,\" in Int. Conf. on Software Engineering:\
    \ Software Engineering in Practice (ICSE-SEIP), IEEE, 2019.\n- 104. J. Vouillon\
    \ and R. D. Cosmo, \"On software component co-installability,\" Transactions on\
    \ Software Engineering and Methodology (TOSEM), 2013.\n- 105. M. Claes, T. Mens,\
    \ R. Di Cosmo, and J. Vouillon, \"A historical analysis of Debian package incompatibilities,\"\
    \ in Int. Conf. on Mining Software Repositories, IEEE, 2015.\n- 106. C. McMillan,\
    \ M. Grechanik, and D. Poshyvanyk, \"Detecting similar software applications,\"\
    \ in Int. Conf. on Software Engineering (ICSE), IEEE, 2012.\n- 107. W. Martin,\
    \ F. Sarro, and M. Harman, \"Causal impact analysis for app releases in google\
    \ play,\" in Int. Symposium on Foundations of software engineering, 2016.\n- 108.\
    \ W. Maalej, M. Nayebi, and G. Ruhe, \"Data-driven requirements engineering-an\
    \ update,\" in Int. Conf. on Software Engineering: Software Engineering in Practice\
    \ (ICSE-SEIP), IEEE, 2019.\n- 109. G. C. Ullmann, C. Politowski, Y.-G. Guéhéneuc,\
    \ and F. Petrillo, \"What makes a game high-rated? towards factors of video game\
    \ success,\" in Int. ICSE Workshop on Games and Software Engineering: Engineering\
    \ Fun, Inspiration, and Motivation, 2022.\n- 110. H. Khalid, M. Nagappan, E. Shihab,\
    \ and A. E. Hassan, \"Prioritizing the devices to test your app on: A case study\
    \ of android game apps,\" in Int. Symposium on Foundations of Software Engineering,\
    \ 2014.\n- 111. M. Nayebi, H. Cho, H. Farrahi, and G. Ruhe, \"App store mining\
    \ is not enough,\" in Int. Conf. on Software Engineering Companion (ICSE-C), IEEE,\
    \ 2017.\n- 112. C. Rosen and E. Shihab, \"What are mobile developers asking about?\
    \ a large scale study using stack overflow,\" in Empirical Software Engineering,\
    \ Springer, 2016.\n- 113. H. Wang, X. Wang, and Y. Guo, \"Characterizing the global\
    \ mobile app developers: a large-scale empirical study,\" in Int. Conf. on Mobile\
    \ Software Engineering and Systems, IEEE, 2019.\n- 114. Y. Y. Ng, H. Zhou, Z.\
    \ Ji, H. Luo, and Y. Dong, \"Which Android app store can be trusted in China?,\"\
    \ in Computer Software and Applications Conference, IEEE, 2014.\n- 115. S. McIntosh,\
    \ Y. Kamei, and M. Nagappan, Release Engineering for Mobile Applications — Communications\
    \ of NII Shonan Meetings. Springer, 2019."
- title: "How Dataflow Diagrams Impact Software Security Analysis: an Empirical\n\
    \  Experiment"
  abstract: 'Models of software systems are used throughout the software development

    lifecycle. Dataflow diagrams (DFDs), in particular, are well-established

    resources for security analysis. Many techniques, such as threat modelling, are

    based on DFDs of the analysed application. However, their impact on the

    performance of analysts in a security analysis setting has not been explored

    before. In this paper, we present the findings of an empirical experiment

    conducted to investigate this effect. Following a within-groups design,

    participants were asked to solve security-relevant tasks for a given

    microservice application. In the control condition, the participants had to

    examine the source code manually. In the model-supported condition, they were

    additionally provided a DFD of the analysed application and traceability

    information linking model items to artefacts in source code. We found that the

    participants (n = 24) performed significantly better in answering the analysis

    tasks correctly in the model-supported condition (41% increase in analysis

    correctness). Further, participants who reported using the provided

    traceability information performed better in giving evidence for their answers

    (315% increase in correctness of evidence). Finally, we identified three open

    challenges of using DFDs for security analysis based on the insights gained in

    the experiment.'
  url: http://arxiv.org/abs/2401.04446v1
  keywords: security, analysis, dataflow diagrams, microservices, model-based, empirical
    experiment
  document: '# How Dataflow Diagrams Impact Software Security Analysis: an Empirical
    Experiment


    Simon Schneider<sup>∗</sup> , Nicolas E. D ´ ´ıaz Ferreyra<sup>∗</sup> , Pierre-Jean
    Queval ´ † , Georg Simhandl† ,


    Uwe Zdun† , Riccardo Scandariato<sup>∗</sup>


    <sup>∗</sup>Hamburg University of Technology, *firstname.lastname@tuhh.de* †University
    of Vienna, *firstname.lastname@univie.ac.at*


    *Abstract*—Models of software systems are used throughout the software development
    lifecycle. Dataflow diagrams (DFDs), in particular, are well-established resources
    for security analysis. Many techniques, such as threat modelling, are based on
    DFDs of the analysed application. However, their impact on the performance of
    analysts in a security analysis setting has not been explored before. In this
    paper, we present the findings of an empirical experiment conducted to investigate
    this effect. Following a within-groups design, participants were asked to solve
    security-relevant tasks for a given microservice application. In the control condition,
    the participants had to examine the source code manually. In the model-supported
    condition, they were additionally provided a DFD of the analysed application and
    traceability information linking model items to artefacts in source code. We found
    that the participants (n = 24) performed significantly better in answering the
    analysis tasks correctly in the model-supported condition (41% increase in analysis
    correctness). Further, participants who reported using the provided traceability
    information performed better in giving evidence for their answers (315% increase
    in correctness of evidence). Finally, we identified three open challenges of using
    DFDs for security analysis based on the insights gained in the experiment.


    *Index Terms*—security, analysis, dataflow diagrams, microservices, model-based,
    empirical experiment


    #### I. INTRODUCTION


    Dataflow Diagrams (DFDs) are integral to many software security analysis techniques.
    For instance, they are required by prominent security assessment techniques [\[1\]](#page-10-0)–[\[4\]](#page-10-1).
    They are also the program representation chosen in many model-based security approaches
    [\[5\]](#page-10-2)–[\[12\]](#page-10-3). As such, they can help software engineers
    build more secure software systems. However, their impact on security analysis
    by their mere provision has not been investigated before to the best of our knowledge.
    DFDs offer a high-level yet detailed representation of applications'' architecture.
    Enriched with annotations representing, e.g., employed security mechanisms, they
    offer easy accessibility of the architectural security. We hypothesize that providing
    users with a DFD of an application enables them to analyse the application''s
    security properties with higher correctness.


    To investigate this hypothesis, we conducted an empirical experiment. This paper
    reports on our findings. The experiment was performed with master students who
    solved tasks related to software security analysis activities. For this, they
    received the source code and a textual description of an open-source microservice
    application, and six tasks to answer. We chose microservice applications as the
    target of analysis because the distributed nature of this architectural style
    poses additional challenges in terms of cognitive load to security analysts. Systems
    following the microservice architecture split their codebase into multiple independent
    microservices, where each fulfils a part of the business functionality and can
    be independently developed and deployed [\[13\]](#page-10-4), [\[14\]](#page-10-5).
    The resulting codebase can be challenging to oversee in analysis scenarios.


    The experiment followed a within-groups design. In the model-supported condition,
    participants received a DFD and traceability information of the analysed application
    in addition to the source code and textual description provided in the control
    condition. We chose DFDs created by *Code2DFD*, a tool for the automatic extraction
    of DFDs from source code [\[15\]](#page-10-6), as these contain extensive security
    annotations. We infer insights on the impact of DFDs on security analysis by comparing
    the participants'' performance in analysis correctness, correctness of evidence,
    and time in the two conditions. Specifically, we answer the following research
    questions:


    ® RQ 1: Do security-annotated architectural models of applications, specifically
    DFDs, support developers in the security analysis of the applications?


    A crucial part of security analysis is identifying and localizing security (and
    other) features in source code. To assess whether models with extensive security
    annotations can support developers and security experts in this activity, the
    participants in our experiment solved tasks that require the identification of
    implemented security mechanisms and other relevant system properties. We quantified
    their answers and compared the scores between the two conditions. Additionally,
    we asked them about the perceived usefulness and analysed the answers.


    ® RQ 2: Does access to and use of traceability information improve the ability
    of the security analysts to provide correct evidence for their analysis findings?


    Traceability information establishes the validity of model items by referencing
    corresponding artefacts in the source code. It can provide value for security
    analysis, since in scenarios such as software security assessment or certification,
    evidence has to be given for the reached findings. The participants provided evidence
    for their answers in the form of locations in the source code. We examined its
    correctness and compared the scores of those participants who reported using the
    traceability information frequently and those who did not. ® RQ 3: What is the
    experience in using security-annotated DFDs for security analysis, specifically
    concerning the usefulness and accessibility?


    Users'' acceptance of offered tools and techniques is crucial for using resources
    such as DFDs for security analysis. Thus, the participants'' perceived usefulness
    of the DFDs is essential to judge their suitability for real-world application.
    Further, the information presented by DFDs has to be conveyed to the users efficiently
    and accessible. To judge this aspect, we asked the participants about their experience
    using the DFDs in the model-supported condition and analysed their responses.


    ® RQ 4: What are the open challenges of using securityannotated DFDs in the context
    of security analysis?


    Based on the insights gained during the empirical experiment and the analysis
    of the results, we identified and formulated open challenges that should be addressed
    in future work.


    The rest of this paper is structured as follows: Section [II](#page-1-0) introduces
    the used DFDs; Section [III](#page-1-1) describes the experiment''s design, i.e.,
    the methodology; the results are presented in Section [IV](#page-4-0) and discussed
    in Section [V;](#page-7-0) Section [VI](#page-8-0) describes limitations of this
    work; Section [VII](#page-9-0) presents related work; and Section [VIII](#page-9-1)
    concludes the paper.


    #### II. CHARACTERISTICS OF THE USED DFDS


    <span id="page-1-0"></span>Since no standard specification for DFDs exists, the
    various styles of DFDs found in the model-based literature differ in their characteristics.
    Here, *style* refers to the types of model items, their presentation and richness
    of detail, and the scope of considered system components. All DFD styles share
    the four base item groups *external entities*, *data flows*, *processes*, and
    *data stores* [\[16\]](#page-10-7). Many approaches include additional model items
    to increase the models'' expressivity [\[1\]](#page-10-0), [\[9\]](#page-10-8),
    [\[17\]](#page-10-9). In our experiment, we used DFDs from a dataset published
    by Schneider et al. [\[18\]](#page-10-10). An example is shown in Figure [1.](#page-1-2)
    The style is the same as those generated by an automatic extraction approach by
    Schneider and Scandariato [\[15\]](#page-10-6). Two of the DFDs'' properties stand
    out compared to other styles, the included *annotations* and the *traceability
    information* for model items. Annotations in the DFDs provide information about
    the corresponding system''s security and other properties. The annotations represent
    implemented security mechanisms (e.g., encryption or authorization mechanisms),
    deployment information (e.g., ports or addresses), or other system properties
    (e.g., used technologies and frameworks). Annotations are associated with model
    items from the four base item groups mentioned above. That means that base model
    items (such as, e.g., a service) are augmented with the annotations. Figure [1](#page-1-2)
    shows examples of this (see the *--annotation-* and *Key: Value* annotations).
    Traceability information links model items to source code by pointing to code
    snippets that prove the existence of the model item. Figure [2](#page-1-3) shows
    as an example the traceability information for the annotation *authorization server*
    as well as a screenshot of the target of the contained URL, i.e., the line of
    code on GitHub.


    ![](_page_1_Figure_7.jpeg)


    Fig. 1. Example DFD provided to participants in model-supported condition.


    <span id="page-1-2"></span>![](_page_1_Figure_9.jpeg)


    <span id="page-1-3"></span><span id="page-1-1"></span>Fig. 2. Screenshots of an
    example traceability information for the annotation *authorization server* (top)
    and the target of the URL (bottom).


    #### III. STUDY DESIGN


    We designed and conducted an empirical experiment to answer the formulated research
    questions. We consulted established sources of guidelines for empirical research
    in the design of the experiment ( [\[19\]](#page-10-11)–[\[21\]](#page-10-12)).
    All materials as well as the results are available in the replication package
    [\[22\]](#page-10-13).


    #### *A. Setup*


    The experiment followed a within-groups design, where participants participated
    in both conditions. The study was performed in two 90-minutes lab sessions of
    a master''s course at a university in subsequent weeks. The participants were
    randomly assigned to one of the two groups, G1 and G2. A different application
    was given as the target of analysis in the two weeks to mitigate learning effects,
    *App 1* in week 1 and *App 2* in week 2. The two sessions were structured as follows:


    |    | Week 1                    | Week 2                    |

    |----|---------------------------|---------------------------|

    |    | App 1                     | App 2                     |

    | G1 | control condition         | model-supported condition |

    | G2 | model-supported condition | control condition         |


    In the *model-supported condition*, the participants performed tasks with access
    to a DFD and corresponding traceability information, whereas in the *control condition*,
    they performed a similar set of tasks without this additional support. They were
    supervised during the sessions and were discouraged from talking to each other
    about the experiment. Google Forms surveys were used to provide the tasks and
    gather the answers.


    # *B. Tasks*


    Table [I](#page-3-0) lists the analysis tasks given to the participants. They
    were chosen such that they resemble common security analysis activities. The first
    two tasks are not specific to security but are relevant nevertheless since they
    foster a required comprehension of the analysed system. The tasks cover three
    different kinds of questions, the participants had to find:


    - general information about single services (tasks 1 & 2)

    - information about security mechanisms of single services (tasks 3 & 4)

    - information about system-wide security mechanisms (tasks 5 & 6)


    For all tasks, the participants were asked to provide evidence for their answers
    via a reference to the code.


    After completion of the technical tasks, the participants were also posed an open
    question about their experience with using the resources they had been provided.
    In the first week, they were further asked questions concerning their expertise.


    As the target of evaluation for the security analysis, we chose two open-source
    applications from a list published by Schneider et al. [\[18\]](#page-10-10).
    The applications are referred to as App1 [1](#page-2-0) and App2 [2](#page-2-1)
    . These applications were selected based on two properties: (i) high architectural
    similarity between the two in order to enable an accurate comparison of participants''
    performance between the two sessions, and (ii) sufficient architectural complexity
    to allow insightful and relevant tasks. The two applications exhibit a high degree
    of similarity concerning their architecture, size, and used technologies. They
    incorporate some of the most prevalent microservice patterns and employ widely
    adopted technology solutions for Java-based microservice development. For instance,
    they both realize an API Gateway with Zuul, authentication with OAuth 2.0, a load
    balancer with Ribbon, and service discovery with Eureka. Consequently, the applications
    are a suitable representation of open-source microservice applications developed
    in Java.


    #### *C. Provided Application Artefacts*


    All participants were provided the source code and a basic textual description
    of the analysed application. The textual description is an explanatory document
    that was created based on the code and information provided by the developers
    of the applications. To mitigate a potential influence on the experiment''s outcome
    based on different qualities of the textual descriptions of the two applications,
    they were created in identical structure and contain the same basic information
    about the corresponding application. They illustrate the basic architectural design
    of the applications. We remark that some tasks could be answered based on these
    documents. The code was provided via GitHub. Specifically, the applications''
    repositories were forked to remove the original documentation, which could otherwise
    influence the outcome.


    In addition to the code and textual description, the participants in the model-supported
    condition received the DFD and the traceability information of the application
    to be analysed.


    #### <span id="page-2-2"></span>*D. Participants*


    The experiment''s participants comprised 24 students enrolled in a master''s level
    software security course at *Hamburg University of Technology*. They originate
    from various disciplines, all incorporating computer science to a large degree.
    The students were informed about the empirical experiment two months in advance
    and were invited to participate. Figure [3](#page-3-1) shows the participants''
    programming knowledge (a), experience with reading Java code (b), and work experience
    (c). This information was reported in a self-assessment at the end of the first
    week''s session. Based on the results ("intermediate level" being the answer most
    often given to the question of programming skills; little experience with reading
    Java code; and an average work experience of 1.1 years), we deduced that the participants
    were on average advanced beginners in software development and had moderate experience
    in analysing Java code. Accordingly, they represent well the target population
    of the experiment. The goal of the experiment was to investigate the effect of
    architectural models on the performance of users with low expertise in software
    security analysis, for example novice developers. The metrics in Figure [3](#page-3-1)
    fit well to such users. Furthermore, using students as proxies for the target
    population is a common practice in empirical software engineering and has been
    shown to be a suitable method [\[19\]](#page-10-11), [\[23\]](#page-10-14)–[\[25\]](#page-10-15).


    *1) Incentives:* The students were generally incentivized to participate in the
    course''s lab sessions, independent of the empirical experiment. For this, they
    were rewarded with a 5% bonus on their final exam, granted upon attending all
    of the lab sessions in the semester except for one (a common practice at the university).
    Further, they were encouraged to participate because the sessions were relevant
    for the final exam, and the participants could hone the required skills there.
    The lab sessions where the empirical experiment was conducted were akin to all
    other lab sessions in these regards. Consequently, the experiment''s impact on
    students'' grades was consistent


    <span id="page-2-0"></span><sup>1</sup>github.com/anilallewar/microservices-basics-spring-boot


    <span id="page-2-1"></span><sup>2</sup>github.com/piomin/sample-spring-oauth2-microservices/tree/with
    database


    TABLE I TASKS FOR APP 2. SERVICE NAMES AND NUMBER OF CONNECTIONS SLIGHTLY DIFFER
    FOR APP 1.


    <span id="page-3-0"></span>![](_page_3_Figure_1.jpeg)


    <span id="page-3-1"></span>Fig. 3. Participants'' (a) programming skills, (b)
    experience in reading Java code, and (c) work experience as developers. All self-reported.


    with that of the other lab sessions in this course. No other incentives were pledged
    or given.


    *2) Preparation:* To prepare the participants, a 90-minute lecture before the
    lab sessions was dedicated to introducing them to the topic (available in this
    paper''s replication package [\[22\]](#page-10-13)). The lecture covered key concepts
    relevant to the experiment. The primary focus was on the origin of software vulnerabilities
    and methods for detecting them. The lecture also encompassed topics such as DFDs,
    microservice architectures, and security considerations in microservice applications.
    Following this lecture, the students were expected to possess the required knowledge
    to undertake the experiment. Their attendance at the lecture was recorded and
    was a prerequisite for participating in the experiment.


    *3) Informed consent and ethical assessment:* All participants read and signed
    an informed consent form before the experiment, informing them that they are the
    subjects of an empirical experiment, that they participate voluntarily, that they
    do not have to expect any negative consequences whatsoever if they do not participate,
    and that they can retract their consent at any time. To ensure the experiment''s
    ethical innocuity, it was assessed by the *German Association for Experimental
    Economic Research e.V.* before execution. A description of the planned experiment
    and its design was approved under grant nr. *2pxo1bap*. The certificate can be
    accessed via [https://gfew.de/ethik/2pxo1bap.](https://gfew.de/ethik/2pxo1bap)


    #### *E. Measurement*


    To evaluate the participants'' performance, three metrics were introduced. The
    *analysis correctness* represents the ability to provide correct answers to the
    tasks. The *correctness of evidence* measures whether the evidence that the participants
    provided as support for their answers points to a code snippet that justifies
    their answer. Both are numerical scores derived from the participants'' responses.
    Additionally, we measured the time spent on solving the tasks. The three metrics
    (analysis correctness, correctness of evidence, and time) were calculated for
    each participant in both conditions separately.


    *1) Analysis Correctness:* We quantified the given answers concerning the analysis
    correctness by manually checking the participants'' responses. To remove subjectivity,
    we created a reference solution that was used to check the answers. It was created
    prior to the execution of the experiment. The DFDs and source code of the applications
    have been analysed to create the reference answers, which were afterwards confirmed
    by conducting technical documentation of the code libraries used in the applications,
    information provided by the developers of the applications, and other typical
    online resources. This process was performed by the first author and validated
    afterwards by two additional authors. After the experiment, the participants''
    responses were mapped via the reference solution to a table indicating correct
    and incorrect answers. Each response was examined manually, compared against the
    reference solution, and true answers were marked in the table. We further reviewed
    answers that did not match the reference solution to check whether they were correct.
    For this, various typical online resources were conducted to verify whether the
    specific answer applies to the task. Each correctly given answer gives a score
    of 1. There is a peculiarity for some tasks. Task 3 asks for a list of connections
    between services, and tasks 4 and 5 ask whether a property applies to each item
    on a given list. Consequently, these tasks each required multiple distinct responses.
    All responses were checked individually. Then, to allow a more detailed and nuanced
    evaluation, we converted the results to scores. A score of 0 was assigned for
    no correct responses, a score of 1 was given for partially correct responses (meaning
    that some but not all responses of a task were correct), and a score of 2 was
    awarded when all responses were correct. With three tasks giving a maximum of
    one point and three tasks giving a maximum of two points, the overall highest
    achievable score in analysis correctness is 9.


    *2) Correctness of Evidence:* The traceability information that is contained in
    the used DFDs constitutes a reference solution for quantifying the correctness
    of the evidence given by the participants. Each given evidence was checked manually
    for matches to this reference solution. Here, we employed some tolerance in accepting
    evidence as correct. For example, when participants referred to a block of code
    slightly larger than the lines of code needed to prove an answer, we still accepted
    this as correct (e.g., referring to a method consisting of some lines of code
    instead of referring to a single line of code in that method). We carried out
    a further validation check, similar to the quantification of the analysis correctness.
    Each provided evidence that differed from the reference solution was checked manually
    whether it supported the given answer or not. The first author carried out the
    above steps. As for the analysis correctness, each correct evidence gives a score
    of 1. Again, for tasks 3, 4, and 5, the multiple distinct responses were converted
    into a score of 0, 1, or 2 for no correct, partially correct, and all correct
    responses, respectively.


    *3) Time:* To measure the time spent on solving the tasks, the participants were
    asked to record the current time when starting and finishing to work on the tasks.
    We calculated the time metric based on these answers (i.e., the period of time
    between the start and finish of solving the tasks).


    *4) Reported Usefulness:* The DFDs'' usefulness as reported by the participants
    was assessed via the open question about the participants'' experience in using
    the DFDs that was posed after the technical tasks. We qualitatively analysed all
    answers'' general intents (positive/negative feedback) and identified recurring
    topics manually. This analysis was performed by the first author and verified
    by two further authors.


    #### <span id="page-4-2"></span>*F. Statistical Tests*


    Throughout the analysis, the difference of scores between two groups was checked
    for statistical significance with a Wilcoxon-Mann-Whitney test. Before, a Shapiro-Wilke
    test was used to verify that the data does not follow a normal distribution. Hence,
    no parametric tests could be used. The assumptions for the Wilcoxon-Mann-Whitney
    test (the samples are independent, random, and continuous and the sample size
    is sufficiently large) are met in our experiment.


    #### IV. RESULTS


    #### <span id="page-4-0"></span>*A. Analysis Correctness*


    Figure [4](#page-4-1) presents the average score in analysis correctness that
    the participants achieved in the two conditions. The figure shows that the participants
    performed better in the modelsupported condition, both overall and in every individual
    task. For all tasks, the average score is 6.75 out of a possible 9 in the model-supported
    condition compared to 4.79 in the control condition, a 41% higher average. The
    applied statistical test (compare Section [III-F\)](#page-4-2) indicates a statistically
    significant difference between the two conditions'' average scores in analysis
    correctness overall (p = 0.0025). These results provide the following answer to
    RQ1:


    ![](_page_4_Figure_8.jpeg)


    <span id="page-4-1"></span>Fig. 4. Comparison across the two treatments of the
    participants'' average score in analysis correctness. Per task and overall.


    ![](_page_4_Figure_10.jpeg)


    <span id="page-4-3"></span>Fig. 5. Comparison across the two treatments of the
    participants'' average score in correctness of evidence. Per task and overall.


    - RQ 1: In the context of our experiment, providing a security-annotated DFD of
    the system to be analysed improved participants'' analysis correctness in solving
    security analysis tasks. We observed a statistically significant (p = 0.0025)
    improvement of 41% on average.


    For some individual tasks, the difference in the average scores is only marginal
    (task 2: 0.42 vs. 0.46 <sup>∧</sup>= 10% improvement in model-supported condition;
    task 6: 0.75 vs. 0.79 <sup>∧</sup>= 5.6% improvement). In Section [V,](#page-7-0)
    we discuss whether the nature of the tasks might be an indication of the extent
    to which a DFD improves the score in analysis correctness. However, even though
    the improvement is not statistically significant for all individual tasks (statistical
    significance only for task 3 with a p-value of 0.0003), Figure [4](#page-4-1)
    clearly shows a trend of improved performance in the model-supported condition.


    #### *B. Correctness of Evidence*


    Figure [5](#page-4-3) presents the average score in correctness of evidence achieved
    by the participants. There are only small differences in the average scores for
    the model-supported and control condition. With an average of 3.08 out of a possible
    9 in the control condition compared to an average of 2.71 in the modelsupported
    condition (-12%), the participants performed better in the control condition,
    albeit without statistical significance (p = 0.52). Task 4 has the lowest average
    correctness of evidence of the individual tasks (average of 0.29 out of 2 in the
    control condition and 0.13 in the model-supported condition),


    ![](_page_5_Figure_0.jpeg)


    <span id="page-5-0"></span>Fig. 6. Reported usage of provided artefacts per task
    (in the model-supported condition, where all artefacts were available).


    while task 1 has the highest average (0.58 out of 1 in the control condition and
    0.63 in the model-supported condition).


    #### *C. Use of Provided Artefacts*


    After each task, the participants were asked to name all provided artefacts that
    they used to answer the task. Figure [6](#page-5-0) shows the reported usage per
    task in the model-supported condition. We focus on this condition because, there,
    the participants had access to all artefacts. Note that the participants had the
    possibility to name multiple artefacts per task. Overall, the DFD was used the
    most, with a total of 88 answers. The source code was used 55 times, the traceability
    information 43 times, and the textual description 21 times. The numbers show,
    that the participants did not solely rely on the provided DFD, but instead also
    referred to the source code in many cases and the textual descriptions in some
    cases. This could indicate, that the participants verified information they found
    in the DFD by checking the corresponding part of the code.


    #### *D. Influence of Use of Artefacts on Scores*


    We investigated whether the participants'' usage of the provided artefacts had
    an influence on their performance. Although they were provided more artefacts
    in the modelsupported condition, this does not necessarily mean that they used
    them all. The answers to the tasks could be found with more than one of the artefacts.
    Thus, the influence of single artefacts on the performance is not necessarily
    reflected in the comparison of outcomes between the two conditions. For example,
    participants in the model-supported condition could have not used the provided
    DFD to answer the tasks. Consequently, we compared the average scores in analysis
    correctness and in the correctness of evidence between two groups of participants
    for each artefact. To the group *Using Artefact* we assigned all participants
    that reported using the artefact in more than 50% of the tasks (4 or more). The
    group *Not Using Artefact* contains those participants who reported using it less
    (3 or fewer). We considered only the outcomes from the participants in the model-supported
    condition, since only here they had access to all artefacts. The grouping and
    analysis were done separately for each artefact, thus, the cardinality and members
    of the groups differ between artefacts. Not Using Using


    ![](_page_5_Figure_7.jpeg)


    <span id="page-5-1"></span>Fig. 7. Average scores in analysis correctness of those
    participants that reported using an artefact in more than 50% of the tasks (Using
    Artefact) and those that reported using it less (Not Using Artefact).


    ![](_page_5_Figure_9.jpeg)


    <span id="page-5-2"></span>Fig. 8. Average scores in the correctness of evidence
    of those participants that reported using an artefact in more than 50% of the
    tasks (Using Artefact) and those that reported using it less (Not Using Artefact).


    Figure [7](#page-5-1) presents the average scores in analysis correctness of the
    two groups per application artefact. The figure shows that the Using Artefact
    group performed better compared to the Not Using artefact group for the artefacts
    DFD (+23% in score) and traceability information (+12%), while they performed
    worse for the source code (-17%). Figure [8](#page-5-2) presents the results of
    this analysis for the correctness of evidence. For the artefact source code, the
    Using Artefact group achieved a 15% higher score in correctness of evidence than
    the Not Using Artefact group. For the use of DFD, they performed worse than the
    Not Using Artefact group (-20%). The highest difference, however, is seen in the
    traceability information. The Using Artefact group achieved a 315% higher average
    score in correctness of evidence than the Not Using Artefact group. We answer
    RQ2 based on these results since they distinguish between the use of the DFD and
    traceability information. In the results above, this distinction could not be
    made because the traceability information is an integral part of the DFDs and
    its isolated impact on the analysis could not be measured.


    - RQ 2: Using traceability information significantly improved the correctness
    of evidence given for answers. On average, participants that used this artefact
    in more than half of the tasks achieved a 315% higher correctness of evidence
    compared to participants that used it less than that.


    # *E. Time*


    All participants were able to complete the tasks in the allotted 90 minutes. Their
    average time to complete all tasks was 34 minutes in the control condition and
    35 minutes in the modelsupported condition. No notable difference was observed.
    To examine a possible correlation between performance and time spent to finish
    the tasks, we also created a scatter plot visualizing their scores against their
    time. No correlation between scores and time could be visually identified.


    # *F. Perceived Usefulness and Usability of DFDs*


    The answers given to the open question at the end of the analysis sessions provide
    insights into the participants'' perceived usefulness of the DFDs. The question
    asked about positive or negative observations during the experiment. For participants
    in the model-supported condition, it explicitly mentioned the usefulness of the
    DFDs and traceability information.


    Out of 23 answers given by participants in the modelsupported condition, two were
    negative, stating that thorough documentation would be preferred and that the
    DFD was "*a little bit hard to understand at first*". Three answers listed both
    positive and negative experiences, where the negative points were two mentions
    that finding implementation details was hard (both participants reported using
    the traceability only in one task) and one that the participant lacked domain
    knowledge. A further 14 answers were predominantly positive.


    # *"Dataflow Diagrams were incredibly helpful, and all questions were answered
    almost completely from it."*


    Of the 23 answers, 9 mentioned specific beneficial scenarios for the use of DFDs.
    The ability to provide an overview of the system was mentioned 8 times, the benefit
    of referring to the important places in source code and use of the models as interface
    to the code was mentioned 3 times, and the reduction of the required domain knowledge
    was mentioned once.


    Mild critique about the accessibility of the DFDs or traceability information
    was raised in 4 responses, for example:


    *"[...] the transfer from the DFD to the traceability information could be made
    easier by clickable links in the DFD [...]"*


    In summary, the statements made by participants in the model-supported condition
    include descriptions of the general usefulness of the DFDs, of benefits in finding
    implementation details via the model items and traceability information, and of
    their usefulness for architectural details and providing an overview. The positive
    feedback outweighed the few negative comments. Most participants reported the
    DFDs to be of help in the analysis and to be accessible to use.


    Of the answers given after the control condition, only one was positive, stating
    that the textual description was helpful. Four others referred to the DFDs (these
    answers were given in the second week, the participants had thus already performed
    the session with the DFD), stating that, in comparison, the lack of a DFD was
    an obstacle during the analysis. Specifically, they raised concerns about the
    correctness of their given answers and stated that finding the required features
    directly in source code was challenging.


    *"The traceability file and the DFD were a big help last time, this time I wasn''t
    really sure if I even answered correctly and didn''t really know if the evidence
    I gave was correct. [...]"*


    Six further answers of participants in the control condition in the first week
    (and thus without the comparison to the model-supported condition) reported negatively
    about their experience in the experiment. Specifically, they mentioned a lack
    of expertise, uncertainty about the given answers, and general difficulties in
    answering the tasks. Interestingly, two participants criticized the lack of a
    "*CFG*" or "*some kind of map of the architecture*". This could have been sparked
    by the introductory lecture where DFDs were addressed but is still seen as an
    interesting comment. The obstacles reported by the participants in the control
    condition give further weight to the positive feedback of those in the model-supported
    condition.


    Based on a qualitative analysis of the participants'' statements, we can cautiously
    judge the perceived usefulness and accessibility of the DFDs to answer RQ3:


    - RQ 3: In our experiment, the perceived usefulness and accessibility reported
    by the participants varied from very positive feedback to mild critiques reporting
    some confusion. Overall, the statements focussed on usefulness and were predominantly
    positive.


    #### *G. Open Challenges of DFDs*


    The above observations of the quantitative and qualitative results allowed us
    to distill a number of open challenges of DFDs, i.e., current obstacles that would
    increase the DFDs'' positive impact further if solved. Although these challenges
    were not explicitly investigated as independent variables in our experiment, they
    became evident from the results of the experiment, explicit answers given by participants,
    and observations made during the analysis of the tasks.


    *Open Challenge 1: Understandability of Models* The participants in our experiment
    performed with statistical significance better in the model-supported condition
    and they reported a generally good accessibility. Nevertheless, concerns were
    raised about the understandability of the models. Some participants commented,
    that they did not understand the model initially or that they did not know what
    some annotations mean. A more usable model representation of software systems
    should consider the accessibility for human users, especially those with lower
    domain knowledge.


    *Open Challenge 2: Presenting Missing Features* The DFDs in their current form
    do not support the explicit presentation of the absence of features or properties.
    In the context of security analysis, these could be security mechanisms that are
    not implemented by a given application. To enable more comprehensive analysis
    and increase users'' trust, it is important to show that such mechanisms were
    investigated and are not implemented in the analysed application. In this context,
    the challenges are to prove the absence, to decide what features to consider,
    and how to convey this information to the user. We see this open challenge as
    the hardest one to solve, both conceptually and practically.


    *Open Challenge 3: Accessibility of Traceability Information* The quantitative
    results of our experiment show, that the traceability information has a positive
    impact on the correctness of evidence provided for answers to the tasks. While
    this is an expected observation, multiple participants also mentioned the usefulness
    of the traceability information for navigating the source code. However, it was
    also mentioned in some answers that the connection to the source code was difficult
    to follow. Also, the traceability information was not used by everyone even when
    it was provided. We conclude that the ease of use can be improved and that navigating
    the links to source code should be simplified. This challenge is of more practical
    nature and can likely be solved with some clever engineering.


    - RQ 4: We identified three open challenges of DFDs (understandability of models,
    presenting missing features, and accessibility of traceability information). If
    any of these are solved, the positive impact of DFDs on security analysis can
    be expected to further increase.


    # V. DISCUSSION


    <span id="page-7-0"></span>At the heart of the conducted experiment lay the question
    of the impact of providing DFDs and traceability information on the participants''
    performance. The results presented in Section [IV](#page-4-0) indicate an overall
    positive impact on the analysis correctness. The scores improved with statistical
    significance in the model-supported condition. Figure [7](#page-5-1) emphasizes
    this finding. Participants in the model-supported condition who reported using
    the provided DFD in more than half of the tasks had a 23% higher score on average
    than those who reported using it less. A 12% higher average score for participants
    using the traceability information is further proof of the usefulness of the DFDs,
    since the traceability information is one of their core features. The observed
    17% lower score in analysis correctness for participants who reported using the
    source code in more than half of the tasks was an unexpected outcome at first
    sight. A closer look at the usage of the source code as artefact revealed, that
    out of 55 responses that mentioned using the source code, 34 (this corresponds
    to 62%) did not use the DFD or traceability information in conjunction. In other
    words, the source code was predominantly not used alongside the models, but instead
    as the only artefact to answer a task. Consequently, in our experiment, many participants
    who reported using the source code could also be described as not using the provided
    models. With this re-phrasing, the results are another indication of the models''
    positive impact.


    Looking at the individual tasks, the increase in scores differed between them.
    This suggests the question of which type of tasks the DFDs have the most impact
    on, and how exactly they impact different types of tasks. We investigated whether
    the nature of the tasks could be an explanation for the observations, i.e. whether
    the type of task can indicate how the score is influenced. We found that the DFDs
    impacted the analysis tasks in our experiment in different ways. They are described
    in the following. Please refer to Table [I](#page-3-0) for the tasks.


    *Providing an Overview:* Tasks 1, 2, and 6 have fairly simple answers in comparison
    to the other tasks. The answer for task 1 (in which the analysis correctness improved
    by 33% in the model-supported condition) could be found at two places in the code,
    either a deployment file indicating the container''s port, or a configuration
    file indicating the service''s port. Both answers were accepted as correct. In
    the DFD, the port is shown as annotation to the corresponding node. Interestingly,
    the wrong answers given are one of two options. One is the port number of a different
    microservice, which likely showed up when searching for "port" with GitHub''s
    search function. The other is the port of a database that is only visible in the
    code as part of the database''s URL. How this answer was reached by participants
    is puzzling. For task 6, the improvement of the average score was the lowest of
    all tasks (0.75 in the control condition and 0.79 in the modelsupported condition;
    5.6% increase). The task has the overall best average scores, likely, because
    the authorization service''s name ("auth server") hints towards the answer of
    which of the services handles the authorization. Task 2 could be answered based
    on the textual description, on the Java annotation that implements the API gateway
    in code, or on an annotation in the DFD. A 10% improvement in average score in
    analysis correctness was observed from the control condition (0.42) to the model-supported
    condition (0.46). The answers lead us to believe that the question might have
    been formulated such that participants did not fully understand it. Many of the
    wrong answers in both conditions stated the used framework (Spring) instead of
    the library that was asked for (Zuul). Further, this task had the lowest reported
    number of usages of the DFD as well as traceability information (compare Figure
    [6\)](#page-5-0).


    The answers and evidences indicate, that DFDs are helpful in providing an overview
    and presenting the answers to simple questions such as the port number of a microservice.
    Evidently, finding *any* port in the code is a simple task in many systems'' codebases,
    however, the answers suggest that finding the *correct* one can be challenging.
    Likely, this is heightened by the complexity that the microservice architecture
    adds to an application''s codebase due to its decoupling. The answers given by
    participants in the model-supported condition further emphasize this quality of
    DFDs to provide an overview of the important system components (compare Section
    [IV,](#page-4-0) where this was the benefit most often mentioned by participants).
    Simultaneously, for simple tasks with a fairly easy answer, good coding practice
    such as choosing descriptive identifiers seems to support the analysts well and
    there is no pressing need to provide a DFD. Whether this holds true in the analysis
    of larger applications should be investigated in future work. The results of task
    2 indicate problems in the DFDs'' accessibility. The presented information seems
    to not be selfexplanatory enough for the participants to answer this task reliably,
    even when the information is contained in the DFDs.


    \$ The results indicate, that DFDs serve as a means to "navigate the jungle" that
    is the application''s codebase. They provide an overview of the application''s
    architecture and (security and other) features. At the same time, wellchosen identifiers
    in code can support the solving of simple analysis tasks and the DFDs add less
    value in this scenario.


    *Reducing Required Domain Knowledge:* To answer tasks 3 and 5 in the control condition,
    some domain knowledge was needed to correctly grasp the functionality of the relevant
    code. Task 3 required the participants to identify three outgoing connections
    (for App 1, two for App 2) of a microservice. One is a direct API call implemented
    with Spring Boot''s RestTemplate, another a registration with a service discovery
    service, and the third a registration with a tracing server (similar for App 2).
    Some domain knowledge about these technologies or Java was required to identify
    them. With the DFD at hand, answer the task came down to identifying the correct
    node in the diagram and noting the three nodes to which there was an information
    flow. To answer task 5 without the DFD, participants had to check whether three
    services (for App 1, two for App 2) refer to the authorization service in a configuration
    file under an authorization section. In the DFD, a connection to the authorization
    server indicated this. Again, knowledge about Spring or Java made it easier to
    find the correct answers without the support of the DFDs.


    Task 3 showed the biggest impact of the models, with a doubled average score in
    analysis correctness (0.875 in control condition and 1.75 in model-supported condition;
    100% increase). While this task was more difficult to answer than the others without
    a DFD and the required domain knowledge, the magnitude of the difference is still
    substantial. For task 5, the average score in analysis correctness was 1.29 in
    the control condition and 1.58 in the model-supported condition, a 23% increase.
    The differences show how the DFDs reduce the domain knowledge required for analysis
    activities. However, we hypothesize, that the participants without the DFD could
    answer the task simply by identifying the keyword "authorization" in the configuration
    files without checking if the implementation is correct and behaves in the way
    that is asked for. We believe, that this led them to achieve an average score
    without the DFDs that is still high. Given the scenario in which they solved the
    tasks (empirical experiment, where answers are expected), this was likely sufficient
    evidence for them to answer, independent of whether their domain knowledge was
    profound enough to fully understand the workings.


    \$ Our interpretation of the results is that DFDs are especially helpful in scenarios
    where a lack of domain knowledge about the analysed application''s framework,
    libraries, etc. hinders the identification of features and system components.
    The DFDs'' ability to shed light on properties shaded by a curtain of domain knowledge
    seems to be one of their core virtues.


    *Indicating Absence of Features:* Despite the open challenge 2 (presenting missing
    features in the DFDs, see Section [IV\)](#page-4-0), the results also indicate
    that the DFDs in their current form already support users in answering tasks concerning
    the absence of features in the code. Task 4 was different from the other ones
    in that the challenge lay not in finding an artefact in the code but instead the
    absence of it. The task asked for the presence of encryption in two connections
    (for App 1, three for App 2) between services. The correct answer to all of them
    was "No". The average score in analysis correctness was 0.83 in the control condition
    and 1.33 in the model-supported condition out of a possible score of 2 (60% increase).
    The difficulty in this task also became apparent when looking at the results for
    the evidence. The participants achieved an average score in correctness of evidence
    of 0.042 in both conditions.


    \$ Although the DFDs still face the open challenge of presenting missing features,
    their current form already supports users in answering tasks that require identifying
    the absence of features in code.


    In summary of the discussion of the results, we see that the DFDs had a positive
    impact on the scores in different types of tasks. Specifically, they provide an
    overview of the analysed application, they reduce the required domain knowledge,
    and they can indicate the absence of features in the application. The highest
    increase in scores is seen for tasks where some domain knowledge was needed to
    answer them without the DFDs. The only task where the improvement of the analysis
    correctness in the model-supported condition was neglectable was a simple task
    where descriptive identifiers in code indicated the answer.


    # VI. THREATS TO VALIDITY


    <span id="page-8-0"></span>*Internal validity:* With a large group of university
    students as participants, collaborations during or between the sessions and resulting
    cross-contamination cannot be ruled out completely. As mitigation, we strictly
    discouraged collaborations and conversations about the study and supervised the
    analysis sessions. Learning effects or the possibility of preparing for the tasks
    were mitigated with the employed within-groups design where the scenarios switched
    over the two sessions and with the use of different applications. With 90-minute
    long sessions, experimental fatigue is limited. The random assignment to the groups
    G1 and G2 limits selection bias. Some of the analysed data (timestamps, experience,
    resource usage) is self-reported, and we have to rely on its correctness. The
    encouragement of positive as well as negative feedback and the often-repeated
    reassurance of full anonymity of the answers were used to increase the reliability
    of the data. By making participation voluntary and using only the standard incentive
    for attending the lab sessions, it is possible that we have attracted mainly students
    who show high motivation and are at the top of their class. This could have had
    distorting effects on the results and could not be reasonably mitigated.


    *External validity:* The conclusions drawn in this paper might not entirely map
    to other scenarios or populations. The tasks used as examples of security analysis
    activities might differ from real-world use cases and thus influence the shown
    effects. Further, the experiment focused on microservice applications written
    in Java. We chose Java applications because it is the most used programming language
    for open-source microservice applications. The analysis of systems that follow
    a different architectural style or are written in another programming language
    could show other outcomes. The number of participants (24) is relatively small.
    We chose robust statistical methods that are suitable for the sample size and
    discussed the impact of the participants'' experience and the choice of tasks.
    The participants'' expertise in security analysis is rather low. Thus, the effects
    described in this paper might not be observed for other users, e.g., with more
    experience. However, the use of DFDs is not confined to security experts, hence
    rendering the participants a suited population for the experiment. Finally, experiments
    with practitioners instead of students could lead to different results, however,
    it is a common practice and has been shown to produce valid results as well (see
    Section [III-D\)](#page-2-2).


    *Construct validity:* We measured the participants'' performance in terms of correctness
    and time, which are common and objective metrics for such experiments. They relate
    to the practical use-case of the investigated effects directly. The analysis correctness
    is crucial in security analysis to ensure accurate security evaluations and, consequently,
    secure systems. The time serves as a measure of productivity and efficiency. Other
    constructs were disregarded but could be suited as well.


    *Content validity:* The tasks concerned the key security mechanisms implemented
    in the analysed applications. These or similar tasks would be part of a real-world
    security analysis. However, other tasks might also be important in this context.


    *Conclusion validity:* The responses to the tasks were given in free-text fields.
    Although we did not identify such ambiguities in quantifying the responses, it
    is possible that some answers were phrased in a way that was interpreted incorrectly.
    A more restrictive way of collecting the answers could have increased the conclusion''s
    validity.


    #### VII. RELATED WORK


    <span id="page-9-0"></span>Although DFDs are used for different aspects of security
    analysis, no related work could be found that investigates their direct impact
    on the correctness of the analysis. Publications for other model types exist.
    For example, a considerable body of empirical research on Unified Modeling Language
    (UML) diagrams has been published [\[26\]](#page-10-16). A number of experiments
    have been conducted to investigate whether users'' comprehension of the modelled
    systems increases with UML diagrams. Gravino et al. [\[27\]](#page-10-17), [\[28\]](#page-10-18)
    observed a positive impact of the models, while experiments by Scanniello et al.
    [\[29\]](#page-10-19) did not show such an improvement (the authors attribute
    this to the type of UML diagrams, which had little connection to the code since
    they had been created in the initial requirements elicitation phase of the development
    process). In an experiment by Arisholm et al. [\[30\]](#page-10-20), code changes
    performed by participants with access to UML documentations showed significantly
    improved functional correctness. Other researchers investigated the impact of
    specific properties of UML diagrams on users'' comprehension. For example, Cruz-Lemus
    et al. [\[31\]](#page-10-21), [\[32\]](#page-10-22), Ricca et al. [\[33\]](#page-10-23),
    and Staron et al. [\[34\]](#page-10-24), [\[35\]](#page-10-25) found that stereotypes
    (which are similar to annotations in DFDs in our experiment) increased users''
    efficiency and effectiveness in code comprehension. Some publications found alternative
    model representations to yield better comprehension among participants in empirical
    experiments: Otero and Dolado [\[36\]](#page-10-26) reported that OPEN Modelling
    Language (OML) models led to faster and easier comprehension than UML diagrams,
    while Reinhartz-Berger and Dori [\[37\]](#page-11-0) reported Object-Process Methodology
    (OPM) models to be better suited than UML diagrams for modelling dynamic aspects
    of applications.


    Bernsmed et al. [\[38\]](#page-11-1) presented insights into the use of DFDs in
    agile teams by triangulating four studies on the adoption of DFDs. In the studies,
    software engineers were confused about the structure, granularity, and what to
    include in the models, because no formal specification of DFDs exists. The participants
    in our experiment also showed some difficulties that could be resolved by a clear
    definition and well-established documentation of DFDs. Regarding DFDs'' structure,
    Faily et al. [\[39\]](#page-11-2) argued that they should not be enriched with
    additional groups of model items, since their simplicity and accessibility for
    human users might suffer. Instead, they proposed to use them together with other
    system representations. In contrast, Sion et al. argued in a position paper [\[40\]](#page-11-3)
    that using DFDs in their basic form is insufficient for threat modelling. Based
    on our findings, we argue that adding annotations to DFDs does not impede their
    accessibility and that security-enriched DFDs are well suited to support security
    analysis activities.


    In conclusion, no publications were found that empirically investigate the impact
    of DFDs (or other model representations) on the security analysis (or related
    activities) of microservice applications.


    # VIII. CONCLUSION


    <span id="page-9-1"></span>This paper presents the results of an empirical experiment
    conducted to investigate the impact of DFDs on software security analysis tasks.
    DFDs are widely used for security analysis and their varied adoption indicates
    a high confidence in their usefulness. To the best of our knowledge, the presented
    results are the first to investigate these assumptions and can confirm a positive
    impact of DFDs in the given context. We found, that participants performed significantly
    better concerning the analysis correctness of security analysis tasks when they
    were provided a DFD of the analysed application. Additionally, traceability information
    that links model items to artefacts in source code significantly improved their
    ability to provide correct evidence for their answers. Consequently, this paper
    serves as a basis for future research on specific applicabilities and properties
    of DFDs. Further, it can provide guidance in decisions on the adoption of model-based
    practices.


    #### ACKNOWLEDGEMENT


    This work was partly funded by the European Union''s Horizon 2020 programme under
    grant agreement No. 952647 (Assure-MOSS).


    #### REFERENCES


    - <span id="page-10-0"></span>[1] L. Sion, K. Yskout, D. Van Landuyt, W. Joosen,
    Solution-aware data flow diagrams for security threat modeling, in: Proceedings
    of the 33rd Annual ACM Symposium on Applied Computing, SAC ''18, Association for
    Computing Machinery, New York, NY, USA, 2018, p. 1425–1432. [doi:10.1145/3167132.3167285](https://doi.org/10.1145/3167132.3167285).

    - [2] S. Hernan, S. Lambert, T. Ostwald, A. Shostack, Threat modelinguncover security
    design flaws using the stride approach, MSDN Magazine (2006) 68–75.

    - [3] Microsoft Corporation, [Microsoft threat modeling tool 2016](https://www.microsoft.com/en-us/download/details.aspx?id=49168)
    (2016). URL<https://www.microsoft.com/en-us/download/details.aspx?id=49168>

    - <span id="page-10-1"></span>[4] P. Torr, Demystifying the threat modeling process,
    IEEE Security & Privacy 3 (5) (2005) 66–70. [doi:10.1109/MSP.2005.119](https://doi.org/10.1109/MSP.2005.119).

    - <span id="page-10-2"></span>[5] M. Abi-Antoun, D. Wang, P. Torr, Checking threat
    modeling data flow diagrams for implementation conformance and security, in: Proceedings
    of the 22nd IEEE/ACM International Conference on Automated Software Engineering,
    ASE ''07, Association for Computing Machinery, New York, NY, USA, 2007, p. 393–396.
    [doi:10.1145/1321631.](https://doi.org/10.1145/1321631.1321692) [1321692](https://doi.org/10.1145/1321631.1321692).

    - [6] M. Abi-Antoun, J. M. Barnes, Analyzing security architectures, in: Proceedings
    of the IEEE/ACM International Conference on Automated Software Engineering, ASE
    ''10, Association for Computing Machinery, New York, NY, USA, 2010, p. 3–12. [doi:10.1145/1858996.](https://doi.org/10.1145/1858996.1859001)
    [1859001](https://doi.org/10.1145/1858996.1859001).

    - [7] B. Berger, K. Sohr, R. Koschke, Automatically Extracting Threats from Extended
    Data Flow Diagrams, in: Engineering Secure Software and Systems, Vol. 9639, 2016,
    pp. 56–71. [doi:10.1007/](https://doi.org/10.1007/978-3-319-30806-7_4) [978-3-319-30806-7\\\_4](https://doi.org/10.1007/978-3-319-30806-7_4).

    - [8] C. Cao, S. Schneider, N. Diaz Ferreyra, S. Verweer, A. Panichella, R. Scandariato,
    CATMA: Conformance Analysis Tool For Microservice Applications, in: 2024 IEEE/ACM
    46th International Conference on Software Engineering: Companion Proceedings (ICSE-Companion),
    2024.

    - <span id="page-10-8"></span>[9] K. Tuma, R. Scandariato, M. Balliu, Flaws in
    Flows: Unveiling Design Flaws via Information Flow Analysis, in: 2019 IEEE International
    Conference on Software Architecture (ICSA), 2019, pp. 191–200. [doi:](https://doi.org/10.1109/ICSA.2019.00028)
    [10.1109/ICSA.2019.00028](https://doi.org/10.1109/ICSA.2019.00028).

    - [10] R. Chen, S. Li, Z. E. Li, From monolith to microservices: A dataflowdriven
    approach, in: 2017 24th Asia-Pacific Software Engineering Conference (APSEC),
    2017, pp. 466–475. [doi:10.1109/APSEC.](https://doi.org/10.1109/APSEC.2017.53)
    [2017.53](https://doi.org/10.1109/APSEC.2017.53).

    - [11] T. D. Stojanovic, S. D. Lazarevic, M. Milic, I. Antovic, Identifying microservices
    using structured system analysis, in: 2020 24th International Conference on Information
    Technology (IT), 2020, pp. 1–4. [doi:10.1109/IT48810.2020.9070652](https://doi.org/10.1109/IT48810.2020.9070652).

    - <span id="page-10-3"></span>[12] S. Li, H. Zhang, Z. Jia, Z. Li, C. Zhang, J.
    Li, Q. Gao, J. Ge, Z. Shan, A dataflow-driven approach to identifying microservices
    from monolithic applications, Journal of Systems and Software 157 (2019) 110380.
    [doi:](https://doi.org/10.1016/j.jss.2019.07.008) [10.1016/j.jss.2019.07.008](https://doi.org/10.1016/j.jss.2019.07.008).

    - <span id="page-10-4"></span>[13] N. Dragoni, S. Giallorenzo, A. Lluch-Lafuente,
    M. Mazzara, F. Montesi, R. Mustafin, L. Safina, Microservices: yesterday, today,
    and tomorrow, Springer International Publishing, 2016, Ch. 12, pp. 195–216. [doi:](https://doi.org/10.1007/978-3-319-67425-4_12)
    [10.1007/978-3-319-67425-4\\\_12](https://doi.org/10.1007/978-3-319-67425-4_12).

    - <span id="page-10-5"></span>[14] J. Lewis, M. Fowler, Microservices: a definition
    of this new architectural term, MartinFowler.com 25 (14-26) (2014) 12.

    - <span id="page-10-6"></span>[15] S. Schneider, R. Scandariato, Automatic extraction
    of security-rich dataflow diagrams for microservice applications written in java,
    Journal of Systems and Software 202 (2023) 111722. [doi:10.1016/j.jss.](https://doi.org/10.1016/j.jss.2023.111722)
    [2023.111722](https://doi.org/10.1016/j.jss.2023.111722).

    - <span id="page-10-7"></span>[16] T. DeMarco, Structure Analysis and System Specification,
    Springer Berlin Heidelberg, 1979. [doi:10.1007/978-3-642-48354-7\](https://doi.org/10.1007/978-3-642-48354-7_9)
    [\\_9](https://doi.org/10.1007/978-3-642-48354-7_9).

    - <span id="page-10-9"></span>[17] K. Tuma, R. Scandariato, M. Widman, C. Sandberg,
    Towards security threats that matter, in: S. K. Katsikas, F. Cuppens, N. Cuppens,
    C. Lambrinoudakis, C. Kalloniatis, J. Mylopoulos, A. Anton, S. Gritzalis (Eds.),
    ´ Computer Security, Springer International Publishing, Cham, 2018, pp. 47–62.
    [doi:10.1007/978-3-319-72817-9\\_4](https://doi.org/10.1007/978-3-319-72817-9_4).

    - <span id="page-10-10"></span>[18] S. Schneider, T. Ozen, M. Chen, R. Scandariato,
    microsecend: A dataset ¨ of security-enriched dataflow diagrams for microservice
    applications, in: 2023 IEEE/ACM 20th International Conference on Mining Software
    Repositories (MSR), 2023, pp. 125–129. [doi:10.1109/MSR59073.](https://doi.org/10.1109/MSR59073.2023.00030)
    [2023.00030](https://doi.org/10.1109/MSR59073.2023.00030).

    - <span id="page-10-11"></span>[19] B. Kitchenham, S. Pfleeger, L. Pickard, P.
    Jones, D. Hoaglin, K. El Emam, J. Rosenberg, Preliminary guidelines for empirical
    research in software engineering, IEEE Transactions on Software Engineering 28
    (8) (2002) 721–734. [doi:10.1109/TSE.2002.1027796](https://doi.org/10.1109/TSE.2002.1027796).

    - [20] N. Juristo, A. Moreno, Basics of Software Engineering Experimentation,
    2001. [doi:10.1007/978-1-4757-3304-4](https://doi.org/10.1007/978-1-4757-3304-4).

    - <span id="page-10-12"></span>[21] C. Wohlin, P. Runeson, M. Host, M. Ohlsson,
    B. Regnell, A. Wessl ¨ en, ´ Experimentation in Software Engineering, Springer,
    Germany, 2012. [doi:10.1007/978-3-642-29044-2](https://doi.org/10.1007/978-3-642-29044-2).

    - <span id="page-10-13"></span>[22] S. Schneider, N. E. Diaz Ferreyra, P.-J. Queval,
    G. Simhandl, U. Zdun, R. Scandariato, [Replication package,](https://github.com/tuhh-softsec/SANER2024_empirical_experiment_DFDs)
    2024. URL [https://github.com/tuhh-softsec/SANER2024](https://github.com/tuhh-softsec/SANER2024_empirical_experiment_DFDs)
    empirical [experiment](https://github.com/tuhh-softsec/SANER2024_empirical_experiment_DFDs)
    DFDs

    - <span id="page-10-14"></span>[23] I. Salman, A. T. Misirli, N. Juristo, Are
    students representatives of professionals in software engineering experiments?,
    in: Proceedings of the 37th International Conference on Software Engineering -
    Volume 1, ICSE ''15, IEEE Press, 2015, p. 666–676.

    - [24] M. Svahnberg, A. Aurum, C. Wohlin, Using students as subjects an empirical
    evaluation, in: Proceedings of the Second ACM-IEEE International Symposium on
    Empirical Software Engineering and Measurement, ESEM ''08, Association for Computing
    Machinery, New York, NY, USA, 2008, p. 288–290. [doi:10.1145/1414004.1414055](https://doi.org/10.1145/1414004.1414055).

    - <span id="page-10-15"></span>[25] D. Falessi, N. Juristo, C. Wohlin, B. Turhan,
    J. Munch, A. Jedlitschka, ¨ M. Oivo, Empirical software engineering experts on
    the use of students and professionals in experiments, Empirical Softw. Engg. 23
    (1) (2018) 452–489. [doi:10.1007/s10664-017-9523-3](https://doi.org/10.1007/s10664-017-9523-3).

    - <span id="page-10-16"></span>[26] D. Budgen, A. J. Burn, O. P. Brereton, B.
    A. Kitchenham, R. Pretorius, Empirical evidence about the uml: a systematic literature
    review, Software: Practice and Experience 41 (4) (2011) 363–392. [doi:https:](https://doi.org/https://doi.org/10.1002/spe.1009)
    [//doi.org/10.1002/spe.1009](https://doi.org/https://doi.org/10.1002/spe.1009).

    - <span id="page-10-17"></span>[27] C. Gravino, G. Scanniello, G. Tortora, Source-code
    comprehension tasks supported by uml design models: Results from a controlled
    experiment and a differentiated replication, Journal of Visual Languages & Computing
    28 (2015) 23–38. [doi:https://doi.org/10.1016/j.](https://doi.org/https://doi.org/10.1016/j.jvlc.2014.12.004)
    [jvlc.2014.12.004](https://doi.org/https://doi.org/10.1016/j.jvlc.2014.12.004).

    - <span id="page-10-18"></span>[28] C. Gravino, G. Tortora, G. Scanniello, An
    empirical investigation on the relation between analysis models and source code
    comprehension, in: Proceedings of the 2010 ACM Symposium on Applied Computing,
    SAC ''10, Association for Computing Machinery, New York, NY, USA, 2010, p. 2365–2366.
    [doi:10.1145/1774088.1774576](https://doi.org/10.1145/1774088.1774576).

    - <span id="page-10-19"></span>[29] G. Scanniello, C. Gravino, M. Risi, G. Tortora,
    G. Dodero, Documenting design-pattern instances: A family of experiments on source-code
    comprehensibility, ACM Trans. Softw. Eng. Methodol. 24 (3) (may 2015). [doi:10.1145/2699696](https://doi.org/10.1145/2699696).

    - <span id="page-10-20"></span>[30] E. Arisholm, L. Briand, S. Hove, Y. Labiche,
    The impact of uml documentation on software maintenance: an experimental evaluation,
    IEEE Transactions on Software Engineering 32 (6) (2006) 365–381. [doi:10.1109/TSE.2006.59](https://doi.org/10.1109/TSE.2006.59).

    - <span id="page-10-21"></span>[31] J. A. Cruz-Lemus, M. Genero, D. Caivano, S.
    Abrahao, E. Insfr ˜ an, ´ J. A. Cars´ı, Assessing the influence of stereotypes
    on the comprehension of uml sequence diagrams: A family of experiments, Information
    and Software Technology 53 (12) (2011) 1391–1403. [doi:10.1016/j.](https://doi.org/10.1016/j.infsof.2011.07.002)
    [infsof.2011.07.002](https://doi.org/10.1016/j.infsof.2011.07.002).

    - <span id="page-10-22"></span>[32] M. Genero, J. A. Cruz-Lemus, D. Caivano, S.
    Abrahao, E. Insfran, ˜ J. A. Cars´ı, Assessing the influence of stereotypes on
    the comprehension of uml sequence diagrams: A controlled experiment, in: K. Czarnecki,
    I. Ober, J.-M. Bruel, A. Uhl, M. Volter (Eds.), Model Driven Engi- ¨ neering Languages
    and Systems, Springer Berlin Heidelberg, Berlin, Heidelberg, 2008, pp. 280–294.

    - <span id="page-10-23"></span>[33] F. Ricca, M. Di Penta, M. Torchiano, P. Tonella,
    M. Ceccato, How developers'' experience and ability influence web application
    comprehension tasks supported by uml stereotypes: A series of four experiments,
    IEEE Transactions on Software Engineering 36 (1) (2010) 96–118. [doi:10.1109/TSE.2009.69](https://doi.org/10.1109/TSE.2009.69).

    - <span id="page-10-24"></span>[34] M. Staron, L. Kuzniarz, C. Wohlin, Empirical
    assessment of using stereotypes to improve comprehension of uml models: A set
    of experiments, Journal of Systems and Software 79 (5) (2006) 727–742, quality
    Software. [doi:10.1016/j.jss.2005.09.014](https://doi.org/10.1016/j.jss.2005.09.014).

    - <span id="page-10-25"></span>[35] M. Staron, L. Kuzniarz, C. Thurn, An empirical
    assessment of using stereotypes to improve reading techniques in software inspections,
    SIGSOFT Softw. Eng. Notes 30 (4) (2005) 1–7. [doi:10.1145/](https://doi.org/10.1145/1082983.1083308)
    [1082983.1083308](https://doi.org/10.1145/1082983.1083308).

    - <span id="page-10-26"></span>[36] M. C. Otero, J. J. Dolado, An empirical comparison
    of the dynamic


    modeling in oml and uml, Journal of Systems and Software 77 (2) (2005) 91–102.
    [doi:10.1016/j.jss.2004.11.022](https://doi.org/10.1016/j.jss.2004.11.022).


    - <span id="page-11-0"></span>[37] I. Reinhartz-berger, D. Dori, Opm vs. uml—experimenting
    with comprehension and construction of web application models, Empirical Software
    Engineering 10 (2005) 57–80. [doi:10.1023/B:EMSE.](https://doi.org/10.1023/B:EMSE.0000048323.40484.e0)
    [0000048323.40484.e0](https://doi.org/10.1023/B:EMSE.0000048323.40484.e0).

    - <span id="page-11-1"></span>[38] K. Bernsmed, D. Cruzes, M. Jaatun, M. Iovan,
    Adopting threat modelling in agile software development projects, Journal of Systems
    and Software 183 (2021) 111090. [doi:10.1016/j.jss.2021.](https://doi.org/10.1016/j.jss.2021.111090)
    [111090](https://doi.org/10.1016/j.jss.2021.111090).

    - <span id="page-11-2"></span>[39] S. Faily, R. Scandariato, A. Shostack, L. Sion,
    D. Ki-Aries, Contextualisation of data flow diagrams for security analysis, in:
    H. Eades III, O. Gadyatskaya (Eds.), Graphical Models for Security, Springer International
    Publishing, Cham, 2020, pp. 186–197.

    - <span id="page-11-3"></span>[40] L. Sion, K. Yskout, D. Van Landuyt, A. van
    den Berghe, W. Joosen, Security threat modeling: Are data flow diagrams enough?,
    in: Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering
    Workshops, ICSEW''20, Association for Computing Machinery, New York, NY, USA,
    2020, p. 254–257. [doi:10.1145/3387940.](https://doi.org/10.1145/3387940.3392221)
    [3392221](https://doi.org/10.1145/3387940.3392221).'
- title: "Formal Modelling of Safety Architecture for Responsibility-Aware\n  Autonomous\
    \ Vehicle via Event-B Refinement"
  abstract: 'Ensuring the safety of autonomous vehicles (AVs) is the key requisite
    for

    their acceptance in society. This complexity is the core challenge in formally

    proving their safety conditions with AI-based black-box controllers and

    surrounding objects under various traffic scenarios. This paper describes our

    strategy and experience in modelling, deriving, and proving the safety

    conditions of AVs with the Event-B refinement mechanism to reduce complexity.

    Our case study targets the state-of-the-art model of goal-aware

    responsibility-sensitive safety to argue over interactions with surrounding

    vehicles. We also employ the Simplex architecture to involve advanced black-box

    AI controllers. Our experience has demonstrated that the refinement mechanism

    can be effectively used to gradually develop the complex system over scenario

    variations.'
  url: http://arxiv.org/abs/2401.04875v1
  keywords: ''
  document: "# Formal Modelling of Safety Architecture for Responsibility-Aware Autonomous\
    \ Vehicle via Event-B Refinement<sup>⋆</sup>\n\nTsutomu Kobayashi1[0000−0002−8795−3183],\
    \ Martin Bondu<sup>2</sup> , and Fuyuki Ishikawa3[0000−0001−7725−2618]\n\n> 1\
    \ Japan Aerospace Exploration Agency, Tsukuba, Japan kobayashi.tsutomu@jaxa.jp\
    \ <sup>2</sup> Sorbonne University, Paris, France martin.bondu@etu.sorbonne-universite.fr\n\
    \n<sup>3</sup> National Institute of Informatics, Tokyo, Japan\n\nf-ishikawa@nii.ac.jp\n\
    \nAbstract. Ensuring the safety of autonomous vehicles (AVs) is the key requisite\
    \ for their acceptance in society. This complexity is the core challenge in formally\
    \ proving their safety conditions with AI-based black-box controllers and surrounding\
    \ objects under various traffic scenarios. This paper describes our strategy and\
    \ experience in modelling, deriving, and proving the safety conditions of AVs\
    \ with the Event-B refinement mechanism to reduce complexity. Our case study targets\
    \ the state-of-the-art model of goal-aware responsibility-sensitive safety to\
    \ argue over interactions with surrounding vehicles. We also employ the Simplex\
    \ architecture to involve advanced black-box AI controllers. Our experience has\
    \ demonstrated that the refinement mechanism can be effectively used to gradually\
    \ develop the complex system over scenario variations.\n\nKeywords: Autonomous\
    \ driving · AI safety · Responsibility-sensitive safety · Safety architecture\
    \ · Event-B · Refinement\n\n## 1 Introduction\n\nThe safety of automated vehicles\
    \ has been attracting increased interest in society. In addition to the intensive\
    \ effort of simulation-based testing, there is a key approach based on formal\
    \ reasoning called responsibility-sensitive safety (RSS) [\\[13\\]](#page-16-0).\
    \ RSS defines the minimum rules that traffic participants should comply with for\
    \ safety, i.e., no collisions. This rule-based approach has recently recently\
    \ been extended to goal-aware RSS (GA-RSS) to deal with the goal-achievement,\
    \ i.e., the driving goal of the ego-vehicle is eventually achieved such as pulling\
    \ over\n\n<sup>⋆</sup> The first author is supported by JSPS KAKENHI grant number\
    \ 19K20249 and JST ERATO-MMSD (JPMJER1603) project. The third author is supported\
    \ by JST MIRAI-eAI (JPMJMI20B8) project.\n\nupon emergency [\\[7\\]](#page-16-1).\
    \ GARSS is effective for formally limiting liabilities, which is vital for AV\
    \ manufacturers.\n\nThe challenge lies in deriving the necessary GARSS conditions\
    \ and formally checking the compliance of the design of the ego vehicle over various\
    \ scenarios under different environmental conditions. In addition, there is increasing\
    \ demand to consider complex behaviours of black-box AI-based advanced controllers\
    \ backed up with safety-ensured controllers, e.g., the Simplex architecture [\\\
    [10\\]](#page-16-2).\n\nExisting efforts have clarified the principles to derive\
    \ and argue conditions that ego-vehicles should comply with in example scenarios.\
    \ However, the engineering aspect has yet to be investigated. Specifically, we\
    \ need a systematic modelling design that accepts the flexibility to mitigate\
    \ the complexity in dealing with multiple aspects of scenario variations and architectural\
    \ design.\n\nTo this end, we report our experience in modelling, deriving, and\
    \ proving the safety conditions of autonomous vehicles (AVs). We follow the GA-RSS\
    \ approach to define and derive the safety conditions to be checked with architectural\
    \ design with black-box advanced controllers. We propose a strategy for using\
    \ the refinement mechanism of Event-B [\\[2\\]](#page-16-3) to gradually argue\
    \ the complex aspects including the scenario variations. Our experience has shown\
    \ the potential of the refinement mechanism for the flexible design of models\
    \ and proofs to mitigate the complexity in a gradual manner. To the best of our\
    \ knowledge, this is the first attempt to focus on the model engineering aspect\
    \ over scenario variations in the deductive approach for AV safety.\n\nThe rest\
    \ of this paper is structured as follows: In § [2,](#page-1-0) we describe the\
    \ safety architecture, RSS, and Event-B. § [3](#page-3-0) introduces GA-RSS and\
    \ a case study example. We elaborate on our approach and its application to the\
    \ case studies in § [4–](#page-6-0)[5.](#page-11-0) We discuss the approach in\
    \ § [6](#page-13-0) before concluding the paper in § [7.](#page-15-0)\n\n## <span\
    \ id=\"page-1-0\"></span>2 Preliminaries\n\n### 2.1 Safety Architecture\n\nContemporary\
    \ software systems often have black-box modules, such as machine learning modules,\
    \ in which their safety is essentially difficult to verify.\n\nA safety architecture,\
    \ such as Simplex architecture (Fig. [1\\)](#page-2-0) [\\[10\\]](#page-16-2),\
    \ is a fundamental approach to guaranteeing the safety of such systems while benefitting\
    \ from the high performance and functionality of black-box modules. It models\
    \ interactions between a controller and a plant. The controller part has two different\
    \ controllers: the baseline controller (BC), which is designed to force safe behaviour,\
    \ and the advanced controller (AC), which aims at satisfying various requirements\
    \ (e.g., comfort and progress) in addition to safety. The decision module (DM)\
    \ switches between the BC and AC in accordance with the state of the plant. BC\
    \ may fail to satisfy requirements other than safety, but it has a simple white-box\
    \ behaviour enabling the safety to be easily verified. In contrast, although AC\
    \ usually gives better user experiences, guaranteeing its safety is difficult\
    \ due to its complicated black-box behaviour. For example, a typical\n\n![](_page_2_Figure_1.jpeg)\n\
    \n<span id=\"page-2-0\"></span>Fig. 1. Component-based simplex architecture [\\\
    [10\\]](#page-16-2)\n\nBC for an AV may drive by following a predefined rule that\
    \ is guaranteed to be safe in certain situations. A typical AC, on the other hand,\
    \ would be one that uses machine learning for motion planning.\n\n#### 2.2 Responsibility-Sensitive\
    \ Safety (RSS)\n\nRSS is an approach to determining the safety of AVs by formal\
    \ proof. The core idea is to derive conditions that should be satisfied by the\
    \ current state of the traffic participants such that safety, or no collisions,\
    \ is ensured in the future.\n\nAn RSS rule consists of an assertion φ called an\
    \ RSS condition and a control strategy α called a proper response. They are defined\
    \ for particular traffic scenarios. For example, a subject vehicle (SV), i.e.,\
    \ the ego vehicle, is following a preceding vehicle on a one-way road. We consider\
    \ this preceding vehicle as the sole traffic participant called a principal other\
    \ vehicle (POV). The SV must satisfy the RSS condition φ regarding the minimum\
    \ relative distance from the POV. The distance is defined by considering the response\
    \ time for braking and the distance necessary for the maximum comfortable braking\
    \ to stop. The proper response α of the SV is to engage the maximum comfortable\
    \ braking when the distance condition φ is about to be violated. The proof should\
    \ show the RSS condition φ is preserved through the execution with the proper\
    \ response α.\n\nIn a general setting, RSS considers the SV and POV in the target\
    \ scenario and determines the RSS condition and proper response. To prove the\
    \ condition is preserved through the execution, a certain set of constraints must\
    \ be satisfied by not only the SV but also all traffic participants (POVs), called\
    \ RSS responsibility principles. Examples of the principles include \"do not cut\
    \ in recklessly\" and \"be cautious in areas with limited visibility\", intuitively.\n\
    \nOur focus is not on the core responsibility principles of RSS but on the RSSdriven\
    \ framework for proving safety of AVs. We are interested in the formal engineering\
    \ aspect to model and verify scenario variations.\n\n### 2.3 Modelling and Proving\
    \ in Event-B\n\nIn this section, we describe the concepts of modelling and theorem\
    \ proving in Event-B [\\[2\\]](#page-16-3) that are used in our case study [4](#page-2-1)\
    \ .\n\n<span id=\"page-2-1\"></span><sup>4</sup> For simplicity, we do not cover\
    \ the \"full\" Event-B (described in [\\[2\\]](#page-16-3)). For instance, our\
    \ concrete machines inherit all variables and parameters from abstract machines,\
    \ which is not necessary in general Event-B machines.\n\n![](_page_3_Figure_1.jpeg)\n\
    \n<span id=\"page-3-1\"></span>Fig. 2. Structure of Event-B model components\n\
    \nEvent-B Model Components. Event-B models are structured as shown in Fig. [2.](#page-3-1)\
    \ The static aspects of the target system are specified as contexts, which consist\
    \ of constants and their properties (axioms). The dynamic aspects are specified\
    \ as machines, which consist of variables, invariant predicates, and a set of\
    \ events. An event e has parameters pe, guard condition Ge, and before-after predicate\
    \ BA<sup>e</sup> that explains the assignment performed in e in terms of variables'\
    \ current values v and next values v ′ . A significant feature of Event-B is a\
    \ flexible refinement mechanism that enables declaring a machine M<sup>c</sup>\
    \ as a refinement of another machine Ma. Every event in M<sup>c</sup> should be\
    \ seen as a refinement of events in M<sup>a</sup> (including the implicit skip\
    \ event). M<sup>c</sup> does not need to inherit predicates of Ma, but those two\
    \ machines should be compatible as described in the following.\n\nProving Consistency\
    \ of Models. Constructed models should be verified by discharging proof obligations\
    \ (POs) generated with predicates in the models. Primary POs include the following:\n\
    \n- Invariant Preservation (for an abstract machine): Invariant predicates are\
    \ inductive ones, i.e., they must hold after every occurrence of events, given\
    \ that they hold beforehand. Formally, invariant preservation by an event e<sup>a</sup>\
    \ is: A(c) ∧ Ia(c, va) ∧ G<sup>e</sup><sup>a</sup> (c, va, p<sup>e</sup><sup>a</sup>\
    \ ) ∧ BA<sup>e</sup><sup>a</sup> (c, va, p<sup>e</sup><sup>a</sup> , v′ a ) ∧\
    \ . . . =⇒ Ia(c, v′ a ).\n- Invariant Preservation (for concrete machines): Formally,\
    \ invariant preservation by an event e<sup>c</sup> is: A(c) ∧ Ia(c, va) ∧ Ic(c,\
    \ va, vc) ∧ G<sup>e</sup><sup>c</sup> (c, vc, p<sup>e</sup><sup>c</sup> ) ∧ BA<sup>e</sup><sup>c</sup>\
    \ (c, vc, p<sup>e</sup><sup>c</sup> , v′ c ) ∧ . . . =⇒ Ic(c, v′ a , v′ c ).\n\
    - Guard Strengthening: For an event e<sup>c</sup> to be a refinement of an event\
    \ ea, the guard of e<sup>c</sup> must be stronger than that of ea's. Formally,\
    \ guard strengthening of e<sup>c</sup> is: A(c)∧Ic(c, va, vc)∧Ia(c, va)∧Ge<sup>c</sup>\
    \ (c, vc, pe<sup>c</sup> )∧. . . =⇒ G<sup>e</sup><sup>a</sup> (c, va, p<sup>e</sup><sup>a</sup>\
    \ ).\n\n## <span id=\"page-3-0\"></span>3 Example: Goal-Aware RSS for Pull Over\
    \ Scenario\n\nGoal-aware RSS (GA-RSS) [\\[7\\]](#page-16-1) is an extension of\
    \ RSS for dealing with complex scenarios that require planning over multiple manoeuvres\
    \ to achieve particular\n\n![](_page_4_Figure_1.jpeg)\n\n<span id=\"page-4-0\"\
    ></span>Fig. 3. Pull over scenario [\\[7\\]](#page-16-1)\n\ngoals. For instance,\
    \ consider the scenario shown in Fig. [3](#page-4-0) (pull over scenario) [\\\
    [7\\]](#page-16-1): the SV needs to stop at a designated location (xT gt) on the\
    \ shoulder lane while keeping safe distances from POVs as required by RSS. Following\
    \ only the original RSS rules for avoiding collisions is necessary but not enough\
    \ to achieve the goal. The goal should be decomposed into several subgoals, such\
    \ as (1) getting ready to merge between two POVs by changing the velocity, (2–3)\
    \ changing lanes, and (4) stopping at xT gt. Different proper responses are required\
    \ for different subgoals as well. However, for example, the SV can be trapped\
    \ in Lane 1 if it is concerned about only the distance from the car ahead.\n\n\
    The workflow of GA-RSS is based on their extension of Floyd-Hoare logic. Given\
    \ a driving scenario S composed of the goal condition Goal and safety condition\
    \ Safety, the workflow is first used to decompose S into subscenarios S1,...,n\
    \ and identify the proper response α<sup>i</sup> for each subscenario S<sup>i</sup>\
    \ . [5](#page-4-1)\n\nThen, the precondition φ<sup>i</sup> for each subscenario\
    \ is calculated as the precondition for establishing Goali∧φ<sup>i</sup>+1 while\
    \ satisfying Safety<sup>i</sup> , by performing α<sup>i</sup> . Here, by seeing\
    \ the (grand) goal of S as the postcondition of the final subscenario Sn, the\
    \ preconditions of all subscenarios are derived in a backward manner, à la Floyd-Hoare\
    \ logic, and then integrated into the precondition of S.\n\nFor instance, Fig.\
    \ [4](#page-5-0) shows the subgoals, safety conditions, proper responses, and\
    \ preconditions of a subscenario chain (defined and derived in [\\[7\\]](#page-16-1))\
    \ where the SV goes between POV1 and POV2 and changes lanes.\n\nVariables are\
    \ as follows: xSV and x1,2,<sup>3</sup> are the lateral positions of the SV and\
    \ the three POVs; vSV and v1,2,<sup>3</sup> are their lateral velocities; aSV\
    \ and a1,2,<sup>3</sup> are their lateral acceleration rates; L and L1,2,<sup>3</sup>\
    \ for set of lanes they are on. Constants are as follows: xT gt is the position\
    \ of the final goal position; vmin and vmax are the legal speed limits; bmin and\
    \ bmax are the minimum (comfortable) and maximum (emergency) braking deceleration\
    \ rates; amax is the maximum acceleration rate.\n\n<span id=\"page-4-1\"></span><sup>5</sup>\
    \ To be precise, with case distinctions, a tree of subscenarios is derived.\n\n\
    | Subscenario S4 (Stop at the target)                                        \
    \                                                                            \
    \                                                                            \
    \                      | Subgoal Goal4: xSV = xT gt ∧ vSV = 0                \
    \                       |\n|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------|\n\
    | Safety Safety4<br>: L = {3} ∧ 0 ≤ vSV ≤ vmax ∧ −bmin ≤ aSV ≤ amax<br>Proper\
    \ Response α4: Cruise for timeT oCruise4(xSV 0, vSV 0), then<br>brake with bmin\
    \ for timeT oBrake4(vSV 0)<br>2<br>Precondition φ4: Env ∧ L = {3} ∧ xT gt − xSV\
    \ ≥ v<br>SV /2bmin |                                                         \
    \                   |\n| Subscenario S3 (Change to Lane 3)                   \
    \                                                                            \
    \                                                                            \
    \                                             | Subgoal Goal3: L = {3}       \
    \                                              |\n| Safety Safety3<br>−bmin ≤\
    \ aSV ≤ amax                                                                 \
    \                                                                            \
    \                                                                        | : (L\
    \ = {3} ∨ L = {2, 3}) ∧ 0 ≤ vSV ≤ v2 ∧ x2 − xSV ≥ dRSS(v2, vSV ) ∧      |\n| Proper\
    \ Response α3: Cruise for timeT oCruise3(xSV 0, vSV 0,), then<br>brake with bmin\
    \ for timeT oBrake3(xSV 0, vSV 0,)                                           \
    \                                                                            \
    \            |                                                               \
    \             |\n| 2<br>xT gt − xSV ≥ v<br>SV /2bmin                         \
    \                                                                            \
    \                                                                            \
    \                                       | Precondition φ3: Env ∧ L = {2} ∧ 0 <\
    \ vSV ≤ v2 ∧ x2 − xSV ≥ dRSS(v2, vSV )∧ |\n| Subscenario S2 (Change to Lane 2)\
    \                                                                            \
    \                                                                            \
    \                                                                | Subgoal Goal2:\
    \ lanes = {2}                                                 |\n| Safety Safety2<br>x3\
    \ − xSV ≥ dRSS(v3, vSV ) ∧ −bmin ≤ aSV ≤ amax                                \
    \                                                                            \
    \                                                                            \
    \ | : (L = {2} ∨ L = {1, 2}) ∧ 0 ≤ vSV ≤ v2 ∧ x2 − xSV ≥ dRSS(v2, vSV ) ∧    \
    \  |\n| Proper Response α2: Cruise for timeT oCruise2(xSV 0, vSV 0,), then<br>brake\
    \ with bmin for timeT oBrake2(xSV 0, vSV 0,)                                 \
    \                                                                            \
    \                      |                                                     \
    \                       |\n| Precondition φ2:                                \
    \                                                                            \
    \                                                                            \
    \                                                 |                          \
    \                                                  |\n\nSubscenario S<sup>1</sup>\
    \ (Get ready to merge)\n\nSubgoal Goal1: x<sup>2</sup> − xSV ≥ dRSS(v2, vSV )\
    \ ∧ xSV − x<sup>1</sup> ≥ dRSS(vSV , v1) ∧ v<sup>2</sup> = vSV Safety Safety<sup>1</sup>\
    \ : L = {1} ∧ x<sup>3</sup> − xSV ≥ dRSS(v3, vSV ) ∧ 0 ≤ vSV ≤ vmax ∧ −bmin ≤\
    \ aSV ≤ amax\n\nProper Response α1: Combinations of acceleration, cruising, and\
    \ braking depending on the situation. See § [6.2](#page-13-1) for details.\n\n\
    Precondition φ1: . . .\n\n<span id=\"page-5-0\"></span>Fig. 4. Subscenarios of\
    \ pull over scenario with proper response and precondition\n\nThe condition of\
    \ environment Env is as follows:\n\n$$\\begin{aligned} \\mathsf{Env} &= \\bigwedge\\\
    _{i=1,2,3} (v\\_{min} \\le v\\_i \\le v\\_{max} \\land a\\_i = 0) \\\\ &\\wedge\
    \ L\\_1 = \\{2\\} \\land L\\_2 = \\{2\\} \\land L\\_3 = \\{1\\} \\land x\\_2 >\
    \ x\\_1. \\end{aligned}$$\n\nThis condition includes the assumption that POVs\
    \ are supposed to run at constant velocity.\n\nThe RSS safety distance that the\
    \ SV running at vSV should keep from the POVi ahead running at v<sup>i</sup> is\
    \ defined as follows:\n\n$$\\text{dPRS}(v\\_i, v\\_{SV}) = \\max\\left(0, \\frac{v\\\
    _{SV}^2}{2b\\_{min}} - \\frac{v\\_i^2}{2b\\_{max}}\\right). \\tag{1}$$\n\nThe\
    \ times the SV should cruise, brake, or accelerate in subscenario S<sup>i</sup>\
    \ for proper response α<sup>i</sup> are derived in the GA-RSS workflow [\\[7\\\
    ]](#page-16-1). For instance,\n\n$$timeToCruise\\_4(x\\_{SV0}, v\\_{SV0}) = \\\
    frac{x\\_{Tgt} - x\\_{SV0}}{v\\_{SV0}} - \\frac{v\\_{SV0}}{2b\\_{min}},\\tag{2}$$\n\
    \n$$timeToBrake\\_4(v\\_{SV0}) = \\frac{v\\_{SV0}}{b\\_{min}},\\tag{3}$$\n\nwhere\
    \ xSV <sup>0</sup> and vSV <sup>0</sup> are the position and velocity of the SV,\
    \ respectively, when the switching occurs.\n\nGA-RSS is designed to be integrated\
    \ with the Simplex architecture. The identified scenarios are used to construct\
    \ the BC that performs the derived proper response α in the situation compatible\
    \ with the scenario, and thus the BC is guaranteed to be safe and goal-achieving.\
    \ While the correctness of the DM is not covered with the method in [\\[7\\]](#page-16-1),\
    \ their experiment used their implementation of a Simplex-based controller, where\
    \ the AC is black-box.\n\nMotivation of our case study. Even with the BC specifications\
    \ identified with the GA-RSS workflow, a formal model of the whole Simplex architecture\
    \ closer to the implementation is desired to construct safe and goal-achieving\
    \ controllers of AVs. Such models should at least take into account the behaviour\
    \ of the DM and the monitor-decide-control loop (Fig. [1\\)](#page-2-0).\n\nThe\
    \ challenge here is the model's complexity; for example, in addition to DM-related\
    \ elements, we need to take switching time delays into consideration.\n\nTo overcome\
    \ this, we exploit the refinement mechanism of Event-B, which distributes the\
    \ complexity of modelling and verification over multiple steps.\n\nThe rest of\
    \ this paper discusses our case study, where we constructed and verified Event-B\
    \ models of Simplex-based controllers for pull over subscenarios.\n\n## <span\
    \ id=\"page-6-0\"></span>4 Case Study 1: Modelling Subscenario S<sup>4</sup>\n\
    \nIn this section, we introduce our modelling strategy, where elements of systems\
    \ should be specified in each refinement step by using our model for subscenario\
    \ S<sup>4</sup> of the pull over scenario as an example. We model the entire safety\
    \ architecture and verify its safety in three refinement steps as follows:\n\n\
    Machine M4,0: Whole controller-level. This is the most abstract machine. The properties\
    \ of the whole controller's\n\n(AC+BC+DM) behaviour at every cycle are modelled.\
    \ We focus on physical requirements that should be satisfied due to the controller's\
    \ behaviour.\n\n- Machine M4,1: Module-level. This machine refines M4,0. This\
    \ machine is aware of the safety architecture; behavioural properties of AC, BC,\
    \ and DM are specified separately. We checked that the switching by the DM satisfies\
    \ the requirements in M4,<sup>0</sup> by proving the correctness of M4,0–M4,<sup>1</sup>\
    \ refinement.\n- Machine M4,2: Manoeuvre-level. This machine refines M4,1. Details\
    \ of the BC's behaviour (proper responses) are specified. By checking the correctness\
    \ of M4,1–M4,<sup>2</sup> refinement, we check that the proper responses satisfy\
    \ the requirements.\n\n<span id=\"page-6-2\"></span><span id=\"page-6-1\"></span>\n\
    \n```\nvar iab les xSV , vSV\nEvent initialisation\n   any ( ) where ⊤ then\n\
    \     init_sv : (x\n                  ′\n                  SV , v′\n         \
    \              SV ) =\n          (xSV 0, vSV 0) end\n                        \
    \             invar iants\n                                    types : xSV ∈ R\
    \ ∧ vSV ∈ R\n                                    no_overrun : 0 ≤ xSV ≤ xT gt\n\
    \                                    v_regulated : 0 ≤ vSV ≤ vmax\n          \
    \                          precond : xT gt − xSV ≥ v\n                       \
    \                                       2\n                                  \
    \                            SV /2bmin\nEvent run\n  any px , pv where\n     preserve_no_overrun\
    \ : 0 ≤ px ≤ xT gt\n     preserve_v_regulated : 0 ≤ pv ≤ vmax\n     preserve_precond\
    \ : xT gt − px ≥ p\n                                       2\n               \
    \                        v/2bmin\n     x_physical_constr : xSV ≤ px ≤ xSV +\n\
    \                                             R 1\n                          \
    \                    t=0(vSV + amaxt)dt\n     v_physical_constr : vSV −\n    \
    \                             R 1\n                                  t=0 bmaxdt\
    \ ≤ pv ≤ vSV +\n                                                           R 1\n\
    \                                                            t=0 amaxdt\n  then\n\
    \     update_xv : (x\n                    ′\n                    SV , v′\n   \
    \                      SV ) = (px, pv) end\n```\n<span id=\"page-7-0\"></span>Fig.\
    \ 5. M<sup>4</sup>,<sup>0</sup>: Abstract, whole controller-level machine for\
    \ subscenario S<sup>4</sup>\n\n# 4.1 Machine <sup>M</sup>4,0: Whole Controller-Level\
    \ Behaviour\n\nMachine M4,<sup>0</sup> is shown in Fig. [5.](#page-7-0) In this\
    \ machine, we abstract away details of the controller and focus on the SV's position\
    \ (xSV ) and velocity (vSV ) as the result of the controller's behaviour.\n\n\
    Invariant predicates no\\_overrun and v\\_regulated express basic requirements.\n\
    \nThe precondition φ<sup>4</sup> derived from the GA-RSS workflow is designed\
    \ to be an invariant that the safety architecture should preserve; the DM enables\
    \ using the AC while φ<sup>4</sup> is robustly satisfied, but it switches to the\
    \ control using the BC once φ<sup>4</sup> is about to be violated. Therefore,\
    \ we specify φ<sup>4</sup> as an invariant predicate (precond).\n\nThere is only\
    \ a single non-initialisation event named run. It has parameters p<sup>x</sup>\
    \ and pv, which are specified as values of xSV and vSV at the next cycle (update\\\
    _xv). The parameters are constrained by the guard predicates preserve\\_\\* required\
    \ for the event's invariant preservation and those for the constraints related\
    \ to physics (\\*\\_physical\\_constr). With these constraints as guard predicates\
    \ of the event, we declare that every detailed behavioural description specified\
    \ as events in concrete machines (M4,<sup>1</sup> and M4,2) should satisfy the\
    \ constraints.\n\nThe guard predicate preserve\\_precond states that the controller\
    \ somehow produces the result (i.e., p<sup>x</sup> and pv) such that precond is\
    \ satisfied. Indeed, the preservation of the precondition φ<sup>4</sup> is trivial\
    \ because:\n\n$$\\begin{aligned} \\left(x\\_{Tgt} - p\\_x \\ge p\\_v^2 / 2b\\\
    _{min}\\right) \\land & \\dots \\land \\left(\\left(x\\_{SV}', v\\_{SV}'\\right)\
    \ = \\left(p\\_x, p\\_v\\right)\\right) \\\\ \\implies x\\_{Tgt} - x\\_{SV}' \\\
    ge v\\_{SV}'^2 / 2b\\_{min} .\\end{aligned}$$\n\nNote that how the controller\
    \ works to produce the invariant-satisfying result is not yet specified and deferred\
    \ to concrete machines; how the DM prevents the\n\n```\nvar iab les xSV , vSV\
    \ , ctrl , vBC0\ninvar iants\ntypes : ctrl ∈ {AC, BC} ∧ vBC0 ∈ R\nvsvbcinit_regulated\
    \ : 0 ≤ vBC0 ≤ vmax\nbc_no_accel : ctrl = BC =⇒ vSV ≤ vBC0\nswitching : ctrl =\
    \ AC =⇒ φ4(xSV +\n                                     R 1\n                 \
    \                     t=0(vSV + amaxt)dt, vSV +\n                            \
    \                                      R 1\n                                 \
    \                                  t=0 amaxdt)\nEvent AC → BC r e f in e s run\n\
    \  any px , pv where\n     . . . ( guard p r e d i c a t e s o f run e x c e p\
    \ t preserve_precond ) . . .\n     AC_operating : ctrl = AC\n     maybe_unsafe_next\
    \ : ¬φ4(xSV +\n                                       R 2\n                  \
    \                      t=0(vSV + amax)dt, vSV +\n                            \
    \                                      R 2\n                                 \
    \                                  t=0 amaxdt)\n  then\n     . . . ( a c t i o\
    \ n s o f run) . . .\n     switch_to_bc : ctrl′ = BC\n     vsvbcinit_update :\
    \ v\n                           ′\n                           BC0 = pv end\nEvent\
    \ BC → AC r e f in e s run\n  any px , pv where\n     . . . ( guard p r e d i\
    \ c a t e s o f run) . . .\n     BC_operating : ctrl = BC\n     no_acceleration\
    \ : pv ≤ vBC0\n     surely_safe_next : φ4(xSV +\n                            \
    \        R 2\n                                     t=0(vSV + amax)dt, vSV +\n\
    \                                                               R 2\n        \
    \                                                        t=0 amaxdt)\n  then\n\
    \     . . . ( a c t i o n s o f run) . . .\n     switch_to_ac : ctrl′ = AC end\n\
    ```\n<span id=\"page-8-0\"></span>Fig. 6. (A part of) M<sup>4</sup>,<sup>1</sup>:\
    \ Intermediate, module-level machine for subscenario S<sup>4</sup>\n\nAC from\
    \ violating it is specified in machine M4,1, and how the BC's behaviour (proper\
    \ responses) satisfies it is specified in machine M4,2.\n\n# <span id=\"page-8-1\"\
    ></span>4.2 Machine <sup>M</sup>4,1: Module-Level Behaviour\n\nIn machine M4,<sup>1</sup>\
    \ (Fig. [6\\)](#page-8-0), which refines M4,0, we focus on the requirements on\
    \ white-box modules of the architecture, namely the BC and DM, particularly the\
    \ condition for switching; through the proof attempt, we derived the switching\
    \ condition such that the precondition is always satisfied. Note that we assume\
    \ that the AC's behaviour is arbitrary as long as it satisfies run's guard. Details\
    \ of the BC's behaviour that should be specified using the time spent for each\
    \ manoeuvre are introduced in machine M4,2.\n\nThere are two new variables: ctrl,\
    \ for the currently active controller, and vBC0, which stores the velocity at\
    \ the time when switching to the BC occurs.\n\nInvariant predicates are in regard\
    \ to the requirements on the BC and DM. vsvbcinit\\_regulated requests that vBC<sup>0</sup>\
    \ should not exceed vmax like vSV , and bc\\_no\\_accel expresses that the BC\
    \ does not accelerate in the proper response.\n\nswitching states that if the\
    \ AC is active, then the SV will be goal-achieving and safe after a cycle even\
    \ if the SV accelerated with the maximum rate amax. The contraposition of switching\
    \ means that the BC is used if the precondition φ<sup>4</sup> may be violated\
    \ at the next cycle.\n\nThere are four events for cases of switching: AC → AC,\
    \ AC → BC, BC → BC, and BC → AC. They all refine the run event of the previous\
    \ machine M4,0. For instance, AC → BC is for the case where the current controller\
    \ is the AC (AC\\_operating) and switching can be violated after the event (maybe\\\
    _unsafe\\_next; note that the integrals are from t = 0 to 2 to look ahead for\
    \ two cycles). Note that, however, switching is guaranteed to hold before the\
    \ event since it is an invariant predicate. In addition to actions of run, the\
    \ controller is switched to the BC (switch\\_to\\_bc) and vBC<sup>0</sup> is updated\
    \ (vsvbcinit\\_update). On the other hand, BC → AC is the case where the controller\
    \ is switched from the BC to AC because the invariant switching will be satisfied\
    \ after the occurrence of the event (surely\\_safe\\_next).\n\nThe main POs are\
    \ as follows:\n\n1. Do the events AC → ∗ preserve the invariant precond? This\
    \ corresponds to the guard strengthening PO of AC → ∗. The intuition of the proof\
    \ is because the AC is operating only if the precondition is guaranteed to hold\
    \ after two cycles (surely\\_safe\\_next), and it is guaranteed to hold after\
    \ one cycle as well.\n\n2. Do events ∗ → AC preserve the invariant switching?\
    \ It is preserved because the AC will be used only if surely\\_safe\\_next holds\
    \ at the current state. In fact, we derived the switching condition surely\\_safe\\\
    _next through the attempt to discharge this PO.\n\n# 4.3 Machine <sup>M</sup>4,2:\
    \ Manoeuvre-Level Behaviour\n\nIn machine M4,<sup>2</sup> (Fig. [7\\)](#page-10-0),\
    \ which refines M4,1, we focus on the details of the behaviour with the notion\
    \ of time to spend on each manoeuvre to verify that the BC's behaviour satisfies\
    \ the requirements specified in machines M4,<sup>0</sup> and M4,1.\n\nTwo new\
    \ variables about the remaining time for cruising (tBCCruise) and braking (tBCBrake)\
    \ are introduced. The unit of time here is the cycle, e.g., the value of tBCCruise\
    \ is the number of the controller's cycles spent for cruising.\n\nInvariant predicates\
    \ are in regard to the detailed properties of the BC's behaviour: cruise\\_before\\\
    _brake expresses that the proper response α<sup>4</sup> is cruising and then braking,\
    \ and \\*\\_in\\_BC\\* states that the velocity and position should follow the\
    \ proper response α<sup>4</sup> as shown in Fig. [8.](#page-11-1)\n\nEvents of\
    \ M4,<sup>2</sup> refine those of M4,<sup>1</sup> as shown in Fig. [9.](#page-11-2)\n\
    \nThree events that refine AC → ∗ are mostly the same as M4,1, but events regarding\
    \ switching to the BC (such as AC\\_run → BC) are extended with actions of calculating\
    \ tBCCruise and tBCBrake as equations [2](#page-6-1) and [3](#page-6-2) (derived\
    \ in the GA-RSS workflow) because the BC should calculate them every time it get\
    \ activated.\n\nUnlike events that refine AC → ∗, six events that refine BC →\
    \ ∗ do not inherit all of the guard predicates and actions of corresponding events\
    \ in machine M4,1. For example, the differences between the event BC\\_cruise\
    \ → AC in M4,<sup>2</sup> and\n\n![](_page_10_Figure_1.jpeg)\n\n<span id=\"page-10-0\"\
    ></span>Fig. 7. (A part of) M<sup>4</sup>,<sup>2</sup>: Concrete, manoeuvre-level\
    \ machine for subscenario S<sup>4</sup>\n\nthe corresponding event BC → AC in\
    \ M4,<sup>1</sup> is as shown in Fig. [10.](#page-12-0) The removed guard predicates\
    \ (lines with red background) are requirements on the values of the SV's position\
    \ and velocity after the occurrence of the event (p<sup>x</sup> and pv), while\
    \ introduced guard predicates (lines with green background) include the concrete\
    \ behaviour of the BC (cruise\\_xv), namely running with the constant velocity.\
    \ By changing events in this way and checking that the guard of BC\\_cruise →\
    \ AC is stronger than that of BC → AC, we can verify that the BC's concrete behaviour\
    \ satisfies the requirements specified in machines M4,<sup>0</sup> and M4,1.\n\
    \nIn addition to the consistency between the BC's concrete behaviour specified\
    \ in M4,<sup>2</sup> and requirements on the BC specified in M4,1, we checked\
    \ that events ∗ → BC and BC → ∗ preserve the invariant.\n\n![](_page_11_Figure_1.jpeg)\n\
    \n<span id=\"page-11-2\"></span><span id=\"page-11-1\"></span>\n\nFig. 8. Proper\
    \ response α<sup>4</sup> Fig. 9. Event refinement relationship\n\n## <span id=\"\
    page-11-0\"></span>5 Case Study 2: Modelling Subscenario S<sup>3</sup>\n\nIn this\
    \ section, we use subscenario S<sup>3</sup> to demonstrate how our modelling strategy\
    \ (§ [4\\)](#page-6-0) is applicable to other subscenarios. subscenario S<sup>3</sup>\
    \ has new aspects; the SV is changing lanes and the leading vehicle POV2.\n\n\
    # 5.1 Machine <sup>M</sup>3,0: Whole Controller-Level Behaviour\n\nFollowing machine\
    \ M4,<sup>0</sup> of subscenario S4, we focus only on the physical results of\
    \ the controller behaviour.\n\nPOV2's variable position (x2) and constant velocity\
    \ (v2) are used in addition to SV's position and velocity.\n\nAs the SV is changing\
    \ lanes, we assume that this action will be done in an exact amount of time modelled\
    \ as a constant tLC (the time for lane changing), and therefore we introduce another\
    \ variable tLCe (the time for lane changing elapsed) so that when the time elapsed\
    \ reaches tLC , the SV should have finished switching lanes and the subscenario\
    \ is over. We modelled lanes in this style instead of introducing another physical\
    \ coordinate for simplicity.\n\nA new invariant predicate no\\_overtime regarding\
    \ the time limit of this subscenario is also introduced as a replacement for no\\\
    _overrun of subscenario S4. The corresponding guard predicates of the event run\
    \ are specified so that no event can occur once the lane switching is over.\n\n\
    $$\\text{no\\\\_overturetime: } t\\_{LCe} \\le t\\_{LC}$$\n\nThe precondition\
    \ for subscenario S<sup>3</sup> (φ<sup>3</sup> derived in [\\[7\\]](#page-16-1))\
    \ takes into consideration the RSS safety distance between the SV and the leading\
    \ vehicle POV2.\n\n$$\\begin{array}{c} \\hline \\textbf{precond:} \\ x\\_{Tgt}\
    \ - x\\_{SV} \\ge v\\_{SV}^2 / 2b\\_{min} \\land x\\_{SV} < x\\_2\\\\ \\land 2(x\\\
    _{SV} - x\\_2) + \\frac{v\\_{SV}^2}{b\\_{min}} \\le \\frac{v\\_2^2}{b\\_{max}}\
    \ \\end{array}$$\n\nAs in subscenario S4, the run event has guard predicates to\
    \ preserve invariant predicates. The event also has new actions for updating x<sup>2</sup>\
    \ and tLCe:\n\n$$\\begin{array}{|c|}\\hline \\text{update\\\\_xLead: } x\\_2'\
    \ = x\\_2 + \\int\\_{t=0}^1 (v\\_2 t) dt\\\\ \\text{update\\\\_xLС: } t\\_{LCe}'\
    \ = \\min(t\\_{LC}, t\\_{LCe} + 1) \\\\\\hline \\end{array}$$\n\n![](_page_12_Figure_1.jpeg)\n\
    \n<span id=\"page-12-0\"></span>Fig. 10. Differences between BC → AC (in M<sup>4</sup>,<sup>1</sup>)\
    \ and BC\\_cruise → AC (in M<sup>4</sup>,<sup>2</sup>)\n\n# 5.2 Machine <sup>M</sup>3,1:\
    \ Module-Level Behaviour\n\nThis machine is also similar to M4,1, but the invariant\
    \ switching and guard predicates surely\\_safe\\_next (and its negation maybe\\\
    _unsafe\\_next) take into account the distance between the SV and POV2.\n\n$$\\\
    begin{array}{c} \\text{switching:} \\; ctl = AC \\Longrightarrow \\phi\\_3(x\\\
    _{SV} + \\int\\_{t=0}^1 (v\\_{SV} + a\\_{max}t)dt, \\\\\\ v\\_{SV} + \\int\\_{t=0}^1\
    \ a\\_{max}dt, \\; x\\_2 + \\int\\_{t=0}^1 (v\\_2t)dt, \\; v\\_2) \\\\\\ \\hline\
    \ \\text{surely\\\\_safe\\\\_next:} \\; \\phi\\_3(x\\_{SV} + \\int\\_{t=0}^2 (v\\\
    _{SV} + a\\_{max}t)dt, \\; v\\_{SV} + \\int\\_{t=0}^2 a\\_{max}dt, \\\\\\ x\\\
    _2 + \\int\\_{t=0}^2 (v\\_2t)dt, \\; v\\_2) \\end{array}$$\n\nAs subscenario S<sup>4</sup>\
    \ (§ [4.2\\)](#page-8-1), the POs are in regard to the preservations of invariants\
    \ precond and switching.\n\n# 5.3 Machine <sup>M</sup>3,2: Manoeuvre-Level Behaviour\n\
    \nCompared with M4,<sup>2</sup> for subscenario S4, there are two major differences:\
    \ when switching to the BC, the calculation of tBCCruise and tBCBrake (derived\
    \ in [\\[7\\]](#page-16-1)) is different because the velocity of the SV should\
    \ not be zero by the end of the subscenario S<sup>3</sup> but only low enough\
    \ to satisfy the goal invariant.\n\n![](_page_12_Picture_9.jpeg)\n\nThe six events\
    \ that refine BC\\_∗ → ∗ have to satisfy machine M3,0's precond that now includes\
    \ the safety distance to the leading vehicle POV2.\n\nThe POs in regard to this\
    \ invariant were discharged in the following way:\n\n- 1. BC\\_∗ → BC The idea\
    \ behind this proof is that BC's proper response does not include accelerating\
    \ and the leading vehicle's velocity is constant, so the distance between these\
    \ two may only increase.\n- 2. BC\\_∗ → AC The guard predicate surely\\_safe\\\
    _next states that the invariant will be satisfied in two cycles without having\
    \ to break in the next cycle because the controller will be in the AC.\n\n## <span\
    \ id=\"page-13-0\"></span>6 Discussion\n\n### 6.1 Model Engineering\n\nIn the\
    \ case studies, we have used the refinement mechanism of Event-B to gradually\
    \ model and verify the different aspects. Specifically, we separated the argument\
    \ over the definition of safe and goal-achieving behaviour, architecture for switching\
    \ behaviours, and concrete behaviour design. The refinement mechanism limits the\
    \ complexity of modelling and proof in each step, which was essential in handling\
    \ the increasing complexity in proving continuous properties.\n\nWe did not directly\
    \ reuse the models between subscenarios, e.g., sharing the abstract steps between\
    \ subscenarios. This is our explicit choice as the key safety properties and involved\
    \ variables for the POVs are unique to each subscenario. We instead used the common\
    \ refinement strategy as well as the model representations. We believe this experience\
    \ enables us to demonstrate the know-how for scenarios other than the pull over\
    \ scenario. The generality of the approach is further discussed in the following.\n\
    \n#### <span id=\"page-13-1\"></span>6.2 Generality of Approach\n\nWe have described\
    \ how the same refinement strategy can deal with subscenarios S<sup>3</sup> and\
    \ S4. We describe how the other subscenarios can be modelled as well as the omitted\
    \ aspect of perception errors.\n\nSubscenario S2. The machines for subscenario\
    \ S<sup>2</sup> are similar to that for subscenario S3. The main difference between\
    \ them is the presence of a leading vehicle in the next lane in subscenario S<sup>2</sup>\
    \ while there is none in subscenario S3.\n\nSubscenario S1. In this subscenario,\
    \ the SV needs to prepare to switch lanes and merge into the next lane. There\
    \ are three POVs to take into account: one ahead of the SV in the current lane\
    \ (POV3) and two others in the next lane (POV 1 and 2). This subscenario thus\
    \ involves multiple (in this case, four) proper responses: an example is accelerating\
    \ to pass POV1 in the next lane, and another example is decelerating to match\
    \ the velocity of POV2 in the next lane. To handle multiple proper responses in\
    \ a unified manner, we modelled them as a sequence of proper responses with variable\
    \ durations as follows: (1) Accelerate for tBCAccel (2) Cruise for tBCCruise (3)\
    \ Brake for tBCBrake. Moreover, we needed to take into account different precondition\
    \ for each proper response. Therefore, we introduced a variable to record which\
    \ proper response was taken the last time the BC got activated.\n\nPerceptual\
    \ Uncertainty Another aspect not included in the case studies is perceptual uncertainty\
    \ or the possibility of errors in sensing. A basic approach to this issue would\
    \ be adding safety margins to the behaviour of the controller. For instance, introducing\
    \ a variable <sup>x</sup>dT gt for the perceived value of target location (xT\
    \ gt) and discussing assumptions on the difference between xT gt and <sup>x</sup>dT\
    \ gt enables us to derive the appropriate amount of the safety margin for this\
    \ uncertainty.\n\n#### 6.3 Using Event-B for Modelling and Proving\n\nFeatures\
    \ of Event-B and its modelling environment Rodin [\\[1\\]](#page-15-1) were useful\
    \ for modelling and proving the safety architecture for GA-RSS. Rodin generated\
    \ POs and helped interactive proof of them. The refinement mechanism of Event-B\
    \ was effective for distributing the complexity of modelling and proving over\
    \ multiple steps. In addition, as we discussed in [§4.2,](#page-8-0) we derived\
    \ the correct behaviour of DM from generated POs.\n\nOur contributions in this\
    \ paper, namely strategies of modelling and refinement, provide a guide to the\
    \ effective use of Event-B's features for the rigorous and systematic construction\
    \ of controllers for different subscenarios.\n\nOn the other hand, although Rodin\
    \ has proof tactics and provers for automatically discharging POs, we had to manually\
    \ discharge all POs. It is because we needed an extension of Event-B language\
    \ [\\[4\\]](#page-16-4) to use real numbers in models, and Rodin's current automatic\
    \ proof functionalities are not strong when the language is extended. However,\
    \ we expect that this problem will be solved; for instance, there are studies\
    \ aiming at assisting automatic proof of hybrid systems by bridging Rodin with\
    \ external solvers [\\[3\\]](#page-16-5).\n\n### 6.4 Related Work\n\nRSS was originally\
    \ proposed as the formal approach for AVs, but the paper did not include any machine-processible\
    \ models [\\[13\\]](#page-16-0). The work on GA-RSS extended the framework of\
    \ RSS with formal specifications and partial calculations supported by Mathematica\
    \ [\\[7\\]](#page-16-1). Other studies only used the resulting RSS conditions,\
    \ for example, encoding them in signal temporal logic for runtime verification\
    \ [\\[8\\]](#page-16-6). To the best of our knowledge, this is the first attempt\
    \ to make use of formal modelling for the RSS scheme. The study in [\\[12\\]](#page-16-7)\
    \ demonstrated the difficulty in checking RSS properties with automated \"one\
    \ button\" tools for reachability analysis and model checking.\n\nOther formal\
    \ attempts for AVs include proofs with the Isabelle/HOL prover [\\[11\\]](#page-16-8)\
    \ with support of MATLAB. The focus was on the detailed computation including\
    \ floating-point errors while the driving behaviour was rather simple; avoidance\
    \ of one static object with a white-box controller.\n\nVerification over RSS is\
    \ intrinsically hybrid, i.e., including continuous aspects such as velocity and\
    \ distance. Proofs over hybrid models have been actively investigated in the Hoare-style\
    \ reasoning, not only for Event-B but also in other formalisms such as KeYmaera\
    \ X [\\[6\\]](#page-16-9). Our case study did not focus on the continuous aspects\
    \ and used rather simple theories for handling real arithmetic. Our future work\
    \ includes the use of more sophisticated support for discharging the proof obligations.\
    \ It is notable that refining continuous models in the physics world into discrete\
    \ software controllers has been actively investigated for Event-B, e.g., [\\[5\\\
    ]](#page-16-10). Models obtained in our approach can be further refined with such\
    \ techniques into concrete designs of discrete software controllers.\n\nGuidelines\
    \ with a focus on refinement strategies have been considered useful for Event-B\
    \ as reusable know-how for specific types of systems [\\[14\\]](#page-17-0). Our\
    \ case study has the potential to be elaborated into such guidelines. Although\
    \ the effectiveness of refinement strategies has been discussed qualitatively\
    \ in most cases, there have been efforts on quantitative analysis [\\[9\\]](#page-16-11).\
    \ Our future work will include analysis of refinement strategies in this work\
    \ in a more systematic way.\n\n## <span id=\"page-15-0\"></span>7 Conclusion\n\
    \nIn this paper, we reported our case study to model, derive, and prove the safety\
    \ conditions of AVs in the RSS scheme. We target a state-of-the-art problem with\
    \ the goal-aware version of RSS as well as the Simplex architecture to consider\
    \ black-box AI controllers. We proposed a strategy for leveraging the refinement\
    \ mechanism of Event-B and demonstrated how it mitigates the complexity over scenario\
    \ variations. We will continue studying other scenarios to convert the obtained\
    \ lessons into more concrete and general guidelines for formal modelling and verification\
    \ of AVs.\n\n## Acknowledgements\n\nWe thank our industrial partner Mazda for\
    \ discussions of realistic problems in the safety assurance of autonomous driving.\
    \ We also thank members of JST ERATO HASUO Metamathematics for Systems Design\
    \ Project for discussions of Goal-Aware RSS and the safety architecture.\n\n##\
    \ References\n\n<span id=\"page-15-1\"></span>1. Abrial, J.R., Butler, M., Hallerstede,\
    \ S., Hoang, T.S., Mehta, F., Voisin, L.: Rodin: an open toolset for modelling\
    \ and reasoning in Event-B. International Journal on Software Tools for Technology\
    \ Transfer 12(6), 447–466 (2010). <https://doi.org/10.1007/s10009-010-0145-y>\n\
    \n- <span id=\"page-16-5\"></span><span id=\"page-16-3\"></span>2. Abrial, J.R.:\
    \ Modeling in Event-B: System and software engineering. Cambridge University Press\
    \ (2010)\n- 3. Afendi, M., Mammar, A., Laleau, R.: Building correct hybrid systems\
    \ using Event-B and Sagemath: Illustration by the hybrid smart heating system\
    \ case study. In: 26th International Conference on Engineering of Complex Computer\
    \ Systems (ICECCS). pp. 91–96. Hiroshima, Japan (2022). <https://doi.org/10.1109/ICECCS54210.2022.00019>\n\
    - <span id=\"page-16-4\"></span>4. Butler, M., Maamria, I.: Practical theory extension\
    \ in Event-B. In: Liu, Z., Woodcock, J., Zhu, H. (eds.) Theories of Programming\
    \ and Formal Methods. pp. 67–81. Springer, Berlin, Heidelberg (2013). [https://doi.org/10.1007/978-3-642-39698-4\\\
    \\_5](https://doi.org/10.1007/978-3-642-39698-4_5)\n- <span id=\"page-16-10\"\
    ></span>5. Dupont, G., Ait-Ameur, Y., Singh, N.K., Pantel, M.: Event-B hybridation:\
    \ A proof and refinement-based framework for modelling hybrid systems. ACM Transactions\
    \ on Embedded Computing Systems 20(4) (2021). <https://doi.org/10.1145/3448270>\n\
    - <span id=\"page-16-9\"></span>6. Fulton, N., Mitsch, S., Quesel, J.D., Völp,\
    \ M., Platzer, A.: KeYmaera X: An axiomatic tactical theorem prover for hybrid\
    \ systems. In: Felty, A.P., Middeldorp, A. (eds.) Automated Deduction - CADE-25.\
    \ pp. 527–538. Springer, Cham (2015). [https://doi.org/10.1007/978-3-319-21401-6\\\
    \\_36](https://doi.org/10.1007/978-3-319-21401-6_36)\n- <span id=\"page-16-1\"\
    ></span>7. Hasuo, I., Eberhart, C., Haydon, J., Dubut, J., Bohrer, R., Kobayashi,\
    \ T., Pruekprasert, S., Zhang, X.Y., Pallas, E.A., Yamada, A., Suenaga, K., Ishikawa,\
    \ F., Kamijo, K., Shinya, Y., Suetomi, T.: Goal-aware RSS for complex scenarios\
    \ via program logic. IEEE Transactions on Intelligent Vehicles pp. 1–33 (2022).\
    \ <https://doi.org/10.1109/TIV.2022.3169762>\n- <span id=\"page-16-6\"></span>8.\
    \ Hekmatnejad, M., Yaghoubi, S., Dokhanchi, A., Amor, H.B., Shrivastava, A., Karam,\
    \ L., Fainekos, G.: Encoding and monitoring responsibility sensitive safety rules\
    \ for automated vehicles in signal temporal logic. In: 17th ACM-IEEE International\
    \ Conference on Formal Methods and Models for System Design (MEMOCODE). ACM, New\
    \ York, NY, USA (2019). <https://doi.org/10.1145/3359986.3361203>\n- <span id=\"\
    page-16-11\"></span>9. Kobayashi, T., Ishikawa, F.: Analysis on strategies of\
    \ superposition refinement of Event-B specifications. In: Sun, J., Sun, M. (eds.)\
    \ Formal Methods and Software Engineering (ICFEM). pp. 357–372. Springer, Cham\
    \ (2018). [https://doi.org/10.1007/978-3-030-02450-5\\\\_21](https://doi.org/10.1007/978-3-030-02450-5_21)\n\
    - <span id=\"page-16-2\"></span>10. Phan, D., Yang, J., Clark, M., Grosu, R.,\
    \ Schierman, J., Smolka, S., Stoller, S.: A component-based simplex architecture\
    \ for high-assurance cyberphysical systems. In: 17th International Conference\
    \ on Application of Concurrency to System Design (ACSD). pp. 49–58. Zaragoza,\
    \ Spain (2017). <https://doi.org/10.1109/ACSD.2017.23>\n- <span id=\"page-16-8\"\
    ></span>11. Rizaldi, A., Immler, F., Schürmann, B., Althoff, M.: A formally verified\
    \ motion planner for autonomous vehicles. In: Lahiri, S.K., Wang, C. (eds.) Automated\
    \ Technology for Verification and Analysis (ATVA). pp. 75–90. Springer, Cham (2018).\
    \ [https://doi.org/10.1007/978-3-030-01090-4\\\\_5](https://doi.org/10.1007/978-3-030-01090-4_5)\n\
    - <span id=\"page-16-7\"></span>12. Roohi, N., Kaur, R., Weimer, J., Sokolsky,\
    \ O., Lee, I.: Self-driving vehicle verification towards a benchmark. CoRR abs/1806.08810\
    \ (2018), <http://arxiv.org/abs/1806.08810>\n- <span id=\"page-16-0\"></span>13.\
    \ Shalev-Shwartz, S., Shammah, S., Shashua, A.: On a formal model of safe and\
    \ scalable self-driving cars. CoRR abs/1708.06374 (2017), <http://arxiv.org/abs/1708.06374>\n\
    - <span id=\"page-17-0\"></span>18 Tsutomu Kobayashi, Martin Bondu, and Fuyuki\
    \ Ishikawa\n- 14. Yeganefard, S., Butler, M.J., Rezazadeh, A.: Evaluation of a\
    \ guideline by formal modelling of cruise control system in Event-B. In: Muñoz,\
    \ C.A. (ed.) the Second NASA Formal Methods Symposium (NFM). NASA Conference Proceedings,\
    \ vol. NASA/CP-2010-216215, pp. 182–191 (2010)"
- title: Finding XPath Bugs in XML Document Processors via Differential Testing
  abstract: 'Extensible Markup Language (XML) is a widely used file format for data

    storage and transmission. Many XML processors support XPath, a query language

    that enables the extraction of elements from XML documents. These systems can

    be affected by logic bugs, which are bugs that cause the processor to return

    incorrect results. In order to tackle such bugs, we propose a new approach,

    which we realized as a system called XPress. As a test oracle, XPress relies on

    differential testing, which compares the results of multiple systems on the

    same test input, and identifies bugs through discrepancies in their outputs. As

    test inputs, XPress generates both XML documents and XPath queries. Aiming to

    generate meaningful queries that compute non-empty results, XPress selects a

    so-called targeted node to guide the XPath expression generation process. Using

    the targeted node, XPress generates XPath expressions that reference existing

    context related to the targeted node, such as its tag name and attributes,

    while also guaranteeing that a predicate evaluates to true before further

    expanding the query. We tested our approach on six mature XML processors,

    BaseX, eXist-DB, Saxon, PostgreSQL, libXML2, and a commercial database system.

    In total, we have found 20 unique bugs in these systems, of which 25 have been

    verified by the developers, and 12 of which have been fixed. XPress is

    efficient, as it finds 12 unique bugs in BaseX in 24 hours, which is 2x as fast

    as naive random generation. We expect that the effectiveness and simplicity of

    our approach will help to improve the robustness of many XML processors.'
  url: http://arxiv.org/abs/2401.05112v1
  keywords: ''
  document: "# Finding XPath Bugs in XML Document Processors via Differential Testing\n\
    \n[Shuxin Li](https://orcid.org/0009-0003-0468-2029)<sup>∗</sup>\n\nshuxin.li.lv@gmail.com\
    \ Southern University of Science and Technology China\n\nABSTRACT\n\nExtensible\
    \ Markup Language (XML) is a widely used file format for data storage and transmission.\
    \ Many XML processors support XPath, a query language that enables the extraction\
    \ of elements from XML documents. These systems can be affected by logic bugs,\
    \ which are bugs that cause the processor to return incorrect results. In order\
    \ to tackle such bugs, we propose a new approach, which we realized as a system\
    \ called XPress. As a test oracle, XPress relies on differential testing, which\
    \ compares the results of multiple systems on the same test input, and identifies\
    \ bugs through discrepancies in their outputs. As test inputs, XPress generates\
    \ both XML documents and XPath queries. Aiming to generate meaningful queries\
    \ that compute non-empty results, XPress selects a so-called targeted node to\
    \ guide the XPath expression generation process. Using the targeted node, XPress\
    \ generates XPath expressions that reference existing context related to the targeted\
    \ node, such as its tag name and attributes, while also guaranteeing that a predicate\
    \ evaluates to true before further expanding the query. We tested our approach\
    \ on six mature XML processors, BaseX, eXist-DB, Saxon, PostgreSQL, libXML2, and\
    \ a commercial database system. In total, we have found 27 unique bugs in these\
    \ systems, of which 25 have been verified by the developers, and 20 of which have\
    \ been fixed. XPress is efficient, as it finds 12 unique bugs in BaseX in 24 hours,\
    \ which is 2× as fast as naive random generation. We expect that the effectiveness\
    \ and simplicity of our approach will help to improve the robustness of many XML\
    \ processors.\n\n## CCS CONCEPTS\n\n• Software and its engineering → Software\
    \ testing and debugging.\n\n### KEYWORDS\n\nXML processors, XPath generation,\
    \ differential testing\n\n#### ACM Reference Format:\n\nShuxin Li and Manuel Rigger.\
    \ 2024. Finding XPath Bugs in XML Document Processors via Differential Testing.\
    \ In 2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE\
    \ '24), April 14–20, 2024, Lisbon, Portugal. ACM, New York, NY, USA, [12](#page-11-0)\
    \ pages. [https://doi.org/10.1145/3597503.3639208](https://doi.org/10.1145/3597503.3639208\
    \ )\n\n© 2024 Copyright held by the owner/author(s).\n\n[Manuel Rigger](https://orcid.org/0000-0001-8303-2099)\
    \ rigger@nus.edu.sg National University of Singapore Singapore\n\n### 1 INTRODUCTION\n\
    \nExtensible Markup Language (XML) is a widely used file format for data storage\
    \ and transmission. XPath is an expression language, which provides the ability\
    \ to navigate through XML documents to select wanted nodes. XPath is also at the\
    \ core of other XML query language standards such as XSLT [\\[7\\]](#page-10-0)\
    \ and XQuery [\\[6\\]](#page-10-1), making it a fundamental XML query language.\n\
    \nVarious XML document processors have been developed for extracting information\
    \ from XML documents efficiently. We loosely categorize them depending on whether\
    \ they can store XML documents in addition to processing them—that is, whether\
    \ they are Database Management Systems (DBMSs), or provide only processing functionality.\
    \ In terms of DBMSs specialized for XML, popular examples include BaseX [\\[8\\\
    ]](#page-10-2) and eXist-DB [\\[10\\]](#page-10-3). Many generalpurpose DBMSs\
    \ such as Oracle Database [\\[14\\]](#page-10-4), MySQL [\\[13\\]](#page-10-5),\
    \ and PostgreSQL [\\[15\\]](#page-10-6) have adopted support for processing XML\
    \ documents. In fact, out of the 10 most popular DBMSs according to the DB-engines\
    \ ranking [\\[9\\]](#page-10-7), 6 support at least partial XML document parsing.\
    \ A popular example of a processor without storage functionality is Saxon. Saxon\
    \ [\\[18\\]](#page-11-1) is an in-memory XML processor that can be either used\
    \ in a standalone way or embedded as a library. Finally, libxml2 [\\[12\\]](#page-10-8)\
    \ is a popular XML processing library written in C. XPath is supported by all\
    \ of these processors.\n\nXML document processors can be affected by logic bugs.\
    \ Logic bugs are bugs that cause the XML processor to produce incorrect results\
    \ without crashing the system, meaning that they can often go unnoticed. In order\
    \ to find such bugs, developers mainly rely on test suites such as the XPathMark\
    \ test suite for XPath [\\[25\\]](#page-11-2), the W3C qt3 test suite [\\[19\\\
    ]](#page-11-3), or hand-written unit tests. Manually writing tests requires much\
    \ effort, and it is challenging to comprehensively cover the XML processors' functionality.\
    \ To find logic bugs automatically, a so-called test oracle is required that can\
    \ determine whether the system's output is correct in order to find logic bugs.\
    \ Todic and Uzelac have proposed an automated testing technique for SQLServer's\
    \ index support; their test oracle compared the results of a given query with\
    \ and without index definition [\\[41\\]](#page-11-4). A limitation of this technique\
    \ is that it is applicable only to finding index-related bugs in DBMSs. To the\
    \ best of our knowledge, no other test oracles have been proposed in this context.\n\
    \nIn order to detect XPath-related bugs in XML processors, we propose differential\
    \ testing as an oracle. The core idea of differential testing is to use one input\
    \ that is executed using multiple systems; any discrepancy in the results indicates\
    \ a potential bug in the system. For testing XML processors, the input for the\
    \ XML processors under test is an XML document and XPath expression, and the results\
    \ are a sequence of XML nodes or values. Differential testing has been successfully\
    \ applied in various related domains,\n\n<sup>∗</sup>Work done during an internship\
    \ at the National University of Singapore.\n\nICSE '24, April 14–20, 2024, Lisbon,\
    \ Portugal\n\nThis is the author's version of the work. It is posted here for\
    \ your personal use. Not for redistribution. The definitive Version of Record\
    \ was published in 2024 IEEE/ACM 46th International Conference on Software Engineering\
    \ (ICSE '24), April 14–20, 2024, Lisbon, Portugal, [https://doi.org/10.1145/3597503.3639208.](https://doi.org/10.1145/3597503.3639208\
    \ )\n\nsuch as relational DBMSs [\\[38\\]](#page-11-5), compilers [\\[43,](#page-11-6)\
    \ [45\\]](#page-11-7), JVM implementations [\\[23\\]](#page-11-8), ORM systems\
    \ [\\[39\\]](#page-11-9), and graph DBMSs [\\[44,](#page-11-10) [46\\]](#page-11-11).\
    \ Its effectiveness hinges on two main requirements. First, multiple systems to\
    \ be compared must be available. As discussed above, various XML processors with\
    \ XPath support exist. Second, for any valid input, the systems should produce\
    \ the same result, since otherwise, a differential-testing approach raises many\
    \ false alarms. This requirement is not always met, for example, when applying\
    \ differential testing to relational DBMSs, where the \"common SQL subset is relatively\
    \ small and changes with each release\" and NULL handling differs between DBMSs\
    \ [\\[38\\]](#page-11-5). As we found, XPath is a well-defined language by the\
    \ W3C standard, and XPath implementations of the same standard follow the same\
    \ language rules, making differential testing highly applicable.\n\nTo generate\
    \ test cases, we propose an approach that selects a so-called targeted node from\
    \ the XML document, based on which we generate a query that is guaranteed to fetch\
    \ at least that node. As such, it tackles two challenges that might prevent testing\
    \ from exercising interesting behaviors. First, by generating the query based\
    \ on the targeted node, we can guarantee that we access a tag name, attributes,\
    \ and relative paths that exist with respect to at least the targeted node. Second,\
    \ by rectifying predicates so that they evaluate to true for the targeted node,\
    \ we can ensure that the result set is non-empty even for complex queries. A similar\
    \ highlevel idea has been proposed in the context of testing relational DBMSs,\
    \ called Pivoted Query Synthesis (PQS) [\\[36\\]](#page-11-12), where a pivot\
    \ row was selected, based on which predicates were rectified to return true. Apart\
    \ from applying that idea in a different context, we also propose a different\
    \ rectification strategy that eschews mirroring the predicate's execution logic\
    \ in the testing tool, which was required for realizing PQS.\n\nWe implemented\
    \ our approach as a tool named XPress,[1](#page-1-0) which, to the best of our\
    \ knowledge, is the first general automated testing tool for XML processors, and\
    \ tested our method on six mature and widely-used XML processors BaseX, eXist-DB,\
    \ Saxon, PostgreSQL, libXML2 and a commercial DBMS. The experimental results show\
    \ that our approach is effective in detecting XPath-related logic bugs in XML\
    \ processors. We found 27 previously unknown unique bugs, not covered by existing\
    \ test suites, of which 19 were logic bugs. 25 of them have been confirmed, and\
    \ 20 of them have been fixed. Furthermore, these test cases have been integrated\
    \ into the aforementioned qt3 test suite, so that they can detect potential bugs\
    \ in XML processors that we have not tested. Our experiments demonstrate that\
    \ our proposed guided query generation process improves testing efficiency by\
    \ finding 2× more unique bugs within 24 hours in BaseX as compared to random generation.\
    \ Given the high effectiveness and efficiency of the approach, we believe it will\
    \ likely be adopted by developers of XML processors to improve their systems.\n\
    \nTo summarize, we make the following contributions:\n\n- We propose the first\
    \ general approach for automatically testing XML processors in order to find logic\
    \ bugs.\n- We implemented and evaluated our approach on six widelyused XML process\
    \ systems, which successfully found 27 previously-unknown unique bugs.\n\n```\n\
    <Books>\n   ① <Book id=\"1\" year=\"2020\">\n       <Author name=\"Sam\"/>\n \
    \      <Author name=\"Bob\"/>\n       A fairy tale.\n     </Book>\n   ② <Book\
    \ id=\"2\">\n       <Author name=\"Alice\"/>\n       Fiction.\n     </Book>\n\
    \   ③ <Book id=\"3\" year=\"2023\">\n       History of fairy kingdom.\n     </Book>\n\
    </Books>\n                                 XPath:\n                          \
    \        //*[@id*(-1)<2]\n                                   BaseX: {}\n     \
    \                              Saxon: ①②③\n                                  \
    \ eXist: ①②③\n```\nFigure 1: Example XML and motivating example.\n\n### <span\
    \ id=\"page-1-3\"></span>2 BACKGROUND\n\nRunning example. Figure [1](#page-1-1)\
    \ shows a running example that we will subsequently use to explain basic XML and\
    \ XPath concepts and outline the challenges of automated testing as applied in\
    \ this context. The left shows an XML document with the root node Books, while\
    \ the right shows an XPath expression //\\*[@id \\* -1 < 2]. We adapted this example\
    \ from a bug-inducing test case that XPress discovered.[2](#page-1-2) As shown,\
    \ for the query on the document, BaseX returned an empty result, while both Saxon\
    \ and eXist returned all three Book nodes.\n\nXML. Extensible Markup Language\
    \ (XML) is a text format for describing structured data. XML documents are trees\
    \ that consist of nodes, as illustrated in Figure [1.](#page-1-1) An XML document\
    \ has a single root element node (see <Books>). Each element node has a tag name\
    \ (see Books, Book, and Author). Element nodes can include attribute nodes. For\
    \ example, two of the <Book> nodes have both attribute nodes id and year. An element\
    \ node can also include child element nodes; in the example, the <Books> node\
    \ contains three child element nodes <Book>. Element nodes can hold text contents,\
    \ which can be of any defined data type. For the <Book> node with attribute id\
    \ = 1, the text content it holds is \"A fairy tale\". Attribute nodes are disallowed\
    \ from holding child nodes. In the example, id and year are integer-typed attribute\
    \ nodes and the name attributes are string-typed attribute nodes.\n\nXPath. The\
    \ XPath language is an expression language that allows navigating the XML tree\
    \ and hierarchic addressing of the element nodes. XPath is at the core of both\
    \ eXtensible Stylesheet Language - Transformation (XSLT) [\\[7\\]](#page-10-0)\
    \ and XQuery, a more expressive query language for XML [\\[6\\]](#page-10-1).\
    \ XSLT transforms XML documents into other formats and the XQuery language is\
    \ a super-set of XPath expressions. XQuery extends XPath to provide functionalities\
    \ such as node constructors and SQL-like clauses.\n\nXPath structure. An XPath\
    \ expression describes the selection and transformation of nodes of the XML tree.\
    \ Figure [2](#page-2-0) shows a simplified XPath 3.0 [\\[4\\]](#page-10-9) grammar\
    \ using EBNF notation from the W3C XML 1.0 standard [\\[3\\]](#page-10-10). We\
    \ introduce the non-established terms Section and Section Prefix to describe our\
    \ generation approach in\n\n<span id=\"page-1-0\"></span><sup>1</sup>Our artifact\
    \ is publicly available at<https://zenodo.org/records/10473926>\n\n<span id=\"\
    page-1-2\"></span><sup>2</sup><https://github.com/BaseXdb/basex/issues/2188>\n\
    \n<span id=\"page-2-0\"></span>**XPathExpression** ::= Section+ **SectionPrefix**\
    \ ::= (\"/\" | \"//\") AxisStep **AxisStep** ::= Axis\\* NameTest **Section**\
    \ ::= SectionPrefix Predicate\\*\n\nFigure 2: Simplified structure of XPath expressions.\n\
    \nSection [3.2.](#page-3-0) XPath expressions consist of one or more sections,\
    \ and a section contains one section prefix followed by zero or more predicates.\
    \ In Figure [1,](#page-1-1) the XPath expression //\\*[@id\\*(-1)<2] consists\
    \ of a single section with section prefix //\\* and a single predicate [@id\\\
    *(-1)<2]. Each section prefix starts with either / or //. / is called the path\
    \ operator, which accepts a node sequence as the left-hand operand and orders\
    \ it in document order while eliminating duplicate nodes. // represents the abbreviated\
    \ relative path /descendant-or-self::node()/, which matches the current context\
    \ and all descendant nodes of the current context, regardless of the intermediate\
    \ path. An axis step consists of an optional axis and a name test.\n\nXPath axes.\
    \ Axes define the relationship between selected nodes and current context nodes.\
    \ For example, the axis parent:: selects all parent nodes of current context nodes.\
    \ If omitted, it is equivalent to child::, which selects all direct children nodes\
    \ of current context nodes. A name test is a string literal to fetch only nodes\
    \ with the same tag name. It could also be a wildcard \\*, which matches all nodes\
    \ without applying filters. The section prefix //\\* in the example selects all\
    \ descendant nodes of the document node, which is all element nodes in the document.\n\
    \nXPath predicates. Predicates in XPath include positional predicates and boolean\
    \ predicates. Positional predicates contain an expression that evaluates to a\
    \ single integer and select only values whose position in the context matches\
    \ the integer value. In the XPath expression /Books/Book[1], [1] is a positional\
    \ predicate and selects only the first child of <Books>, which is the <Book> node\
    \ with @id=1. Boolean predicates evaluate current context nodes to a boolean value\
    \ according to a given expression and only nodes for which the predicate evaluates\
    \ to true are selected. In Figure [1,](#page-1-1) [@id \\* -1 < 2] is a boolean\
    \ predicate. The query //\\*[@id \\* -1 < 2] selects all nodes in the XML document\
    \ with attribute id that satisfy id \\* -1 < 2. The three nodes with tag name\
    \ Book in the document have attribute id, and all satisfy the condition. Therefore,\
    \ if correctly evaluated, this query should return all three Book nodes.\n\nLogic\
    \ bug. For the test input in Figure [1,](#page-1-1) systems like Saxon and eXist-DB\
    \ both returned a result set with three Book nodes, while BaseX returned an empty\
    \ result set. The difference between the processors indicates a potential bug.\
    \ Based on our manual analysis, we suspected that BaseX computed an incorrect\
    \ result, which is why we reported it to the BaseX developers. They fixed the\
    \ bug quickly. The reason for this bug was an incorrect simplification of the\
    \ arithmetic expression x \\* a > b to x > b / a. When the divisor is a negative\
    \ number, the original operator > should be reversed to <.\n\nXPath standard.\
    \ There are majorly two different standards of XPath implementations in use today,\
    \ which we need to consider in our work. The XPath 1.0 standard was the first\
    \ version. As a superset of XPath 1.0, the XPath 3.0 standard is the latest standard\
    \ of the XPath language and provides more functionalities such as advanced data\
    \ types and functions [\\[5\\]](#page-10-11). Most multi-model DBMSs, which support\
    \ XPath queries, support only XPath 1.0 [\\[1\\]](#page-10-12) (e.g., Oracle,\
    \ MySQL, and PostgreSQL). While some specialized XML processors support also only\
    \ XPath 1.0 (e.g., libXML2), others support the more recent XPath 3.0 standard\
    \ (e.g., BaseX, eXist-DB, and Saxon).\n\nXPath versions and differential testing.\
    \ The same queries might produce different results under different standards.\
    \ For example, for the XPath expression Book/@name = false(), under the XPath\
    \ 1.0 standard, the expression is expected to return true. @name is first cast\
    \ into its equivalent boolean value. In the current case <Book> has no name attribute,\
    \ therefore, an empty node set is returned. The equivalent boolean value evaluates\
    \ to false for empty nodes. Comparing false to false is equal, therefore true\
    \ is returned. Under the XPath 3.0 standard, however, the result is expected to\
    \ be false. @name returns an empty sequence and equality comparison between an\
    \ empty sequence and a boolean value false would evaluate to false. Thus, applying\
    \ differential testing to XML processors supporting different standards is infeasible.\n\
    \n### 3 APPROACH\n\nFigure [3](#page-3-1) shows an overview of the approach using\
    \ the same example as in Figure [1.](#page-1-1) At a high level, our approach\
    \ consists of three main steps. First, we randomly generate an XML document as\
    \ the context for the following queries (step ○1 ). We then generate an XPath\
    \ expression that we will subsequently validate (step ○2 to step ○5 ). Finally,\
    \ we execute the XPath expression on the XML document using all engines under\
    \ test and compare the resulting outputs to detect potential bugs (step ○6 ).\
    \ In the subsequent subsections, we explain these steps in reverse order to reflect\
    \ their importance.\n\nWe guide the XPath expression generation towards queries\
    \ that reference nodes and attributes present in the XML document and result in\
    \ non-empty result sets based on the intuition that they are more likely to stress\
    \ the underlying logic of the tested systems. To generate XPath expressions with\
    \ non-empty result sets, we construct the query section-by-section and ensure\
    \ that a non-empty result set is produced before proceeding with the next section.\
    \ Each section consists of a section prefix and predicates, and we first generate\
    \ the prefix (step ○2 ) and then the predicate. By restricting the section prefix,\
    \ we guarantee that the result contains at least one node. From the nodes selected\
    \ by the section prefix, we randomly select a node as a target (step ○3 ). We\
    \ then generate a predicate aiming to select the targeted node using a bottom-up\
    \ tree construction method (step ○4 ). We rectify the predicate to ensure that\
    \ the result set contains the targeted node (step ○5 ). We repeat this process\
    \ until the XPath query reaches the desired length.\n\n### <span id=\"page-2-1\"\
    ></span>3.1 Differential Testing for XML Processors\n\nAs detailed subsequently,\
    \ differential testing enables us to find both logic bugs as well as internal\
    \ errors when comparing the results of XML processors implementing the same XPath\
    \ standard.\n\nQuery execution. When passing XML documents and XPath queries to\
    \ different systems, we must account for the different\n\n<span id=\"page-3-1\"\
    ></span>![](_page_3_Figure_2.jpeg)\n\n**Repeat process until generated XPath reaches\
    \ specified length**\n\nFigure 3: Overview of the approach implemented in XPress.\n\
    \nListing 1: Execution of XPath using Oracle Database\n\n```\nCREATE TABLE t (a\
    \ XMLType);\nINSERT INTO t VALUES (XMLType(XML)));\nSELECT XMLQuery(XPATH PASSING\
    \ a RETURNING CONTENT) FROM t;\n```\nListing 2: Execution of XPath using Saxon\
    \ in Java\n\n```\nXQueryExecutable exec = compiler.compile(XPATH);\nXQueryEvaluator\
    \ query = exec.load();\nquery.setContextItem(XML);\nXdmValue result = query.evaluate();\n\
    ```\ninput interfaces. For example, DBMSs use database connection interfaces to\
    \ store and query data, while Saxon can be used as a library. To abstract this,\
    \ we treat every XML processor implementation as a function that returns a result\
    \ set and expects two string values, namely an XML document XML and an XPath query\
    \ XPATH. Listing [1](#page-3-2) shows an implementation of this interface for\
    \ Oracle Database using SQL statements. It creates a table t, inserts the XML\
    \ document—the XMLType constructor is used to convert the string to an XML data\
    \ type—and uses an XMLQuery function call in a SELECT statement to compute the\
    \ result set. For BaseX and eXist-db, similar to the commands shown for Oracle\
    \ Database, we also start with an empty database and subsequently insert an XML\
    \ document. Listing [2](#page-3-3) shows an excerpt of the Java code for Saxon.\
    \ First, the call to compile converts the textual XPath query to an executable\
    \ object, which is then loaded. Unlike for the DBMSs, which require inserting\
    \ data into a database, for Saxon, the XML document is simply associated with\
    \ the query using the setContextItem call. The evaluate call computes the result,\
    \ which is returned for comparison.\n\nBug identification. We identify both logic\
    \ bugs and internal errors by comparing the returned results of different processors\
    \ on the same XML document and query. We identify logic bugs when the tested systems\
    \ return different node-set outputs for the same test cases. To parse and track\
    \ the results easily under different output formats, we use unique node ids to\
    \ identify element nodes. We detect internal errors as discrepancies with respect\
    \ to errors. Rather than checking for an exact error message match, we validate\
    \ whether all the systems produce an error, or all execute the XPath query successfully.\
    \ If only a subset of the systems report an error for the same XPath query, we\
    \ found a potential bug.\n\nDifferent XPath standards. Our approach and tool are\
    \ applicable to both XPath 1.0 and XPath 3.0. However, due to the differences\
    \ in the formats, only processors using the same standard can be tested. Functionality\
    \ that is supported only in XPath 3.0, can be disabled while generating test cases\
    \ for processors that implement XPath 1.0. For example, sequence functions, such\
    \ as subsequence, are defined only for the XPath 3.0 standard. When generating\
    \ test cases for XPath 1.0 processors, we omit to generate subsequence function\
    \ nodes for predicates. We did not encounter any functions or operators that were\
    \ removed in the XPath 3.0 standard, so all expressions that we generate when\
    \ testing XPath 1.0 processors can be used also when testing XPath 3.0 processors.\
    \ By comparing only processors with the same XPath standard against each other,\
    \ the difference in the results between different XPath standards (see Section\
    \ [2\\)](#page-1-3) has no influence on the testing process.\n\n### <span id=\"\
    page-3-0\"></span>3.2 XPath Expression Generation\n\nIn this section, we introduce\
    \ how we generate XPath queries. We encountered two main challenges that we had\
    \ to tackle when generating XPath expressions.\n\nNon-existent elements. Randomly\
    \ generated queries could be semantically correct, but reference non-existent\
    \ nodes or attributes. For the document in Figure [1,](#page-1-1) //Author[@id\
    \ < 1] is a valid XPath expression. However, none of the Author nodes contain\
    \ an id attribute. Thus, XPath returns an empty sequence for each node, causing\
    \ the predicate @id < 1 to evaluate to false. We believe that queries, where only\
    \ non-existent attributes or nodes are referenced, are less likely to exercise\
    \ the logic of the processors under test, as subsequent operations are likely\
    \ to evaluate to an empty sequence as well. Thus, we aim to avoid generating such\
    \ queries.\n\nEmpty results. Randomly generated predicates might likely evaluate\
    \ to false and cause queries to generate empty result sets. For the document in\
    \ Figure [1,](#page-1-1) the XPath predicate starts-with(text(), x) identifies\
    \ nodes whose text starts with x. If x is a randomly generated string, the possibility\
    \ is high that no nodes in the current result set match the condition. Consequently,\
    \ any use of the predicate would yield an empty result. Any subsequently added\
    \ section would yield an empty result as well, meaning that such queries would\
    \ be less likely to exercise the processor under test. Consequently, we want to\
    \ avoid generating such predicates, in particular, when\n\nthey involve multiple\
    \ sections. This relates to the first problem, as non-existent nodes or attributes\
    \ can also introduce empty results.\n\nApproach overview. We designed the XPath\
    \ generation process of XPress tackling the two aforementioned issues. To create\
    \ XPath expressions that refer to valid nodes and attributes to trigger deeper\
    \ logic of the system under test, we generate queries that reference existent\
    \ context relative to the so-called targeted node, such as its tag name and attributes\
    \ (steps ○3 and ○4 ). Since randomly generated predicates might miss the targeted\
    \ node from the result set, we rectify the generated expressions to ensure the\
    \ inclusion of the targeted node (step ○5 ).\n\nIterative section generation.\
    \ We create XPath expressions sectionby-section by executing step ○2 to step ○5\
    \ for each section, which allows us to ensure non-empty results after generating\
    \ each section. In the example, we first generate section /Books by selecting\
    \ <Books> as the targeted node, and after executing steps ○2 to step ○5 , the\
    \ result of /Books is non-empty—containing the node <Books>. Based on this, we\
    \ further proceed to generate the next section /Book[count(Author) > 1] starting\
    \ at step ○2 .\n\nSection prefix. We randomly generate one of the applicable section\
    \ prefixes. First, we randomly select the start of the section to be / or //.\
    \ We then retrieve the current context node sequence by executing the expression—/Books\
    \ in the example—on a processor. Based on the result, we include all possible\
    \ axes that would not lead to an empty result set by simple conditional checks.\
    \ We support all 11 axes described in the XPath 3.0 standard [\\[4\\]](#page-10-9).\
    \ For example, applying the axis /descendants:: will lead to a non-empty result,\
    \ if at least one non-leaf node exists in the current selection. From the possible\
    \ axes, we select a random one and apply it. When generating the section prefix\
    \ /Book, the axis step is implicit. It is equivalent to /Books/child::Book, which\
    \ selects all child nodes of the previously selected nodes. We again execute the\
    \ query and retrieve the result node-set. We use the result for the name test,\
    \ for which we either select a tag name from the result node-set, or use the wildcard\
    \ \\*. By doing so, we are again guaranteed a non-empty result set. In the example,\
    \ the tag name Book is selected and applied, resulting in the selection of all\
    \ three Book nodes. In our artifact, we include a table that details the conditional\
    \ checks for all 11 axes.\n\nTarget node selection. To generate targeted queries\
    \ that fetch at least one node, we select a so-called targeted node to guide the\
    \ predicate generation process. We use information about the target node, such\
    \ as its text content, the attributes it holds, and its relationship to other\
    \ nodes during the predicate generation. This is similar to the concept of the\
    \ pivot row in PQS [\\[36\\]](#page-11-12), which is a technique that has been\
    \ proposed to test relational DBMSs. After the generated predicate is applied,\
    \ we expect the target node to be included in the result node-set. In step ○3\
    \ , we select node 1 as the target node for the predicate generation process.\
    \ Constraining the context to exist for the targeted node does not affect the\
    \ evaluation of the expression on other candidate nodes and, therefore, still\
    \ allows finding bugs that are triggered only when referring to nodes' non-existing\
    \ attributes or child nodes.\n\nPredicate generation. We use a tree structure\
    \ to represent the predicate and take a bottom-up construction approach to enable\
    \ tracking of expression results along tree construction. We start generating\
    \ the predicate from a specific subject, which is either the targeted node or\
    \ a node sequence derived from the targeted node with equal probability. In the\
    \ example, we select the <Author> child node sequence from the targeted node as\
    \ the subject. We then iteratively apply random function nodes and supply function\
    \ parameters to construct the predicate, until the predicate reaches a desired\
    \ length. We keep track of the data type and value of the current subexpression\
    \ when constructing the predicate, by executing the subexpression on one randomly\
    \ chosen XML processor—we use this XML processor also for predicate rectification\
    \ and we subsequently refer to this XML processor as the designated XML processor.\
    \ We use the value and data type of the current sub-expression in the following\
    \ two ways: by (1) selecting function nodes of according data types and (2) supplying\
    \ arguments to reference existent context and triggering corner cases. Specifically,\
    \ we select a random function node from functions that could accept the value\
    \ of the current data type as input. A function node can either represent a function\
    \ or an operation. In the example, Author is a node sequence and count is a randomly\
    \ selected function from functions that accept node sequence as input. For function\
    \ nodes that require additional arguments, we supply arguments while taking the\
    \ current result value into consideration. As an example, when selecting attribute\
    \ values from node sequences, we use name tests referencing existent attributes.\
    \ For the = operator, we choose an operand that is equal to the current value\
    \ with a high probability of triggering the equal case which is of low probability\
    \ under random generation. Aside from constants, we also set the possibility for\
    \ operands to be other predicate trees. Through this, we support the generation\
    \ of expressions with multiple subject occurrences. Besides boolean predicates,\
    \ we also apply positional predicates to the XPath expression randomly.\n\nPredicate\
    \ rectification. Lastly, we rectify the generated predicate to guarantee that\
    \ the targeted node is contained in the final result set. We first execute the\
    \ generated predicate on the designated XML processor. If the result set misses\
    \ the targeted node, we rectify the predicate. To negate the predicate's result,\
    \ we can always apply a not operator. However, as shown in Algorithm [1,](#page-5-0)\
    \ we probabilistically apply more specific rectification for certain operators\
    \ to uncover additional potential bugs. For logical operators such as and, both\
    \ child expressions need to be modified to evaluate to true to contain the targeted\
    \ node, while or needs only modification of one random child expression. For comparison\
    \ operators, such as <=, we replace them with their opposite operators, which,\
    \ in the example, is >. Thus, the targeted node is guaranteed to be contained\
    \ in the result set.\n\n### 3.3 XML Generation\n\nIn this section, we outline\
    \ how we generate XML documents (step ○1 ), which we do not consider part of our\
    \ core contribution.\n\nTree creation. We use a bottom-up approach to generate\
    \ XML documents. We first generate a number of node templates, which we use to\
    \ generate XML nodes that have overlaps in terms of structure, as detailed below.\
    \ We select one of these nodes as a root element. For the remaining nodes, we\
    \ randomly assign each node to a parent. As XML documents support recursive structure,\
    \ we allow cyclic\n\n<span id=\"page-5-0\"></span>\n\n|  |  | Algorithm 1 Predicate\
    \ Rectification |\n|--|--|-------------------------------------|\n|--|--|-------------------------------------|\n\
    \n|     | 1: function RectifyPredicate(\U0001D45D\U0001D45F\U0001D452\U0001D451\
    \U0001D456\U0001D450\U0001D44E\U0001D461\U0001D452_\U0001D45B\U0001D45C\U0001D451\
    \U0001D452,<br>\U0001D461\U0001D44E\U0001D45F\U0001D454\U0001D452\U0001D461\U0001D452\
    \U0001D451_\U0001D45B\U0001D45C\U0001D451\U0001D452) |\n|-----|----------------------------------------------------------------|\n\
    | 2:  | \U0001D4501<br>← \U0001D45D\U0001D45F\U0001D452\U0001D451\U0001D456\U0001D450\
    \U0001D44E\U0001D461\U0001D452_\U0001D45B\U0001D45C\U0001D451\U0001D452.\U0001D459\
    \U0001D452 \U0001D453 \U0001D461\U0001D436ℎ\U0001D456\U0001D459\U0001D451    \
    \                         |\n| 3:  | \U0001D4502<br>← \U0001D45D\U0001D45F\U0001D452\
    \U0001D451\U0001D456\U0001D450\U0001D44E\U0001D461\U0001D452_\U0001D45B\U0001D45C\
    \U0001D451\U0001D452.\U0001D45F\U0001D456\U0001D454ℎ\U0001D461\U0001D436ℎ\U0001D456\
    \U0001D459\U0001D451                              |\n| 4:  | if targeted_node\
    \ in GetResult(\U0001D45D\U0001D45F\U0001D452\U0001D451\U0001D456\U0001D450\U0001D44E\
    \U0001D461\U0001D452_\U0001D45B\U0001D45C\U0001D451\U0001D452)<br>then       \
    \   |\n| 5:  | return                                                        \
    \ |\n| 6:  | if RandomProb() < 0.5 then                                     |\n\
    | 7:  | AddNot(\U0001D45D\U0001D45F\U0001D452\U0001D451\U0001D456\U0001D450\U0001D44E\
    \U0001D461\U0001D452_\U0001D45B\U0001D45C\U0001D451\U0001D452)               \
    \                          |\n| 8:  | return                                 \
    \                        |\n| 9:  | switch \U0001D45D\U0001D45F\U0001D452\U0001D451\
    \U0001D456\U0001D450\U0001D44E\U0001D461\U0001D452_\U0001D45B\U0001D45C\U0001D451\
    \U0001D452<br>do                                    |\n| 10: | case \U0001D45C\
    \U0001D45F \U0001D45C\U0001D45D\U0001D452\U0001D45F\U0001D44E\U0001D461\U0001D45C\
    \U0001D45F                                               |\n| 11: | if RandomProb()\
    \ < 0.5 then                                     |\n| 12: | RectifyPredicate(\U0001D450\
    1)                                           |\n| 13: | else                 \
    \                                          |\n| 14: | RectifyPredicate(\U0001D450\
    2)                                           |\n| 15: | end case             \
    \                                          |\n| 16: | case \U0001D44E\U0001D45B\
    \U0001D451 \U0001D45C\U0001D45D\U0001D452\U0001D45F\U0001D44E\U0001D461\U0001D45C\
    \U0001D45F                                              |\n| 17: | RectifyPredicate(\U0001D450\
    1)                                           |\n| 18: | RectifyPredicate(\U0001D450\
    2)                                           |\n| 19: | end case             \
    \                                          |\n| 20: | case \U0001D450\U0001D45C\
    \U0001D45A\U0001D45D\U0001D44E\U0001D45F\U0001D456\U0001D460\U0001D45C\U0001D45B\
    \ \U0001D45C\U0001D45D\U0001D452\U0001D45F\U0001D44E\U0001D461\U0001D45C\U0001D45F\
    \                                       |\n| 21: | ChangeToOpposite(\U0001D45D\
    \U0001D45F\U0001D452\U0001D451\U0001D456\U0001D450\U0001D44E\U0001D461\U0001D452\
    _\U0001D45B\U0001D45C\U0001D451\U0001D452)                               |\n|\
    \ 22: | end case                                                       |\n| 23:\
    \ | default:                                                       |\n| 24: |\
    \ AddNot(\U0001D45D\U0001D45F\U0001D452\U0001D451\U0001D456\U0001D450\U0001D44E\
    \U0001D461\U0001D452_\U0001D45B\U0001D45C\U0001D451\U0001D452)               \
    \                          |\n| 25: | end switch                             \
    \                        |\n| 26: | return                                   \
    \                      |\n\nrelationships. In Section 4, we provide details on\
    \ how we configured the number of nodes in a document.\n\nNode generation. We\
    \ introduce how each element node is instantiated. By default, XML documents do\
    \ not have to adhere to a specific schema, which is unlike, for example, relational\
    \ DBMSs. Nevertheless, we want to generate element nodes that have overlaps in\
    \ terms of structure, to test for more interesting behaviors. To that end, we\
    \ generate element nodes based on so-called node templates that we randomly generate.\
    \ A node template represents a type of node. For example, in Figure [1,](#page-1-1)\
    \ Book is a node template whose tag name is Book, has attributes id and year,\
    \ and has text content of string data type. To instantiate the template, we fill\
    \ in values for the attributes and text contents. For each node we created in\
    \ the aforementioned XML tree, we instantiate it with a randomly assigned template.\
    \ In the example of Figure [1,](#page-1-1) we generated three nodes using the\
    \ Book template. We assign random values for element nodes and their attributes\
    \ according to the associated data types except id, to which we assign a unique\
    \ identifier, which we use to unambiguously identify the processors' outputs (see\
    \ Section [3.1\\)](#page-2-1). For the <Book> node with id = 1, we assign the\
    \ random integer value 2020 to year and the random string value \"A fairy tale\"\
    \ as its text content. Similar strategies have been applied also to other schema-less\
    \ systems such as graph DBMSs [\\[26,](#page-11-13) [29\\]](#page-11-14).\n\n\
    ### 4 EVALUATION\n\nIn the evaluation, we sought to investigate whether our technique\
    \ is effective and efficient in finding bugs for XPath expression processors.\
    \ Specifically, we were interested in the following questions:\n\n- Q1. Is XPress\
    \ effective in finding new XPath-related bugs in established XML processors (see\
    \ Section [4.1\\)](#page-5-1)?\n- Q2. Does the query generation approach described\
    \ in Section [3.2](#page-3-0) improve the bug-finding efficiency of XPress with\
    \ respect to real-world baselines and a random generation approach (see Section\
    \ [4.2\\)](#page-7-0)?\n- Q3. How does the differential testing test oracle compare\
    \ to the state-of-the-art oracle (see Section [4.3\\)](#page-8-0)?\n- Q4. What\
    \ kind of XPath-related bugs might be overlooked by XPress (see Section [4.4\\\
    )](#page-9-0)?\n\nTested XML Processors. We tested our method on six mature, wellknown,\
    \ and actively maintained XPath processors: BaseX, exist-DB, Saxon-HE, PostgreSQL,\
    \ libXML2, and a commercial DBMS, whose name we have omitted due to its \"DeWitt\
    \ clause\" [\\[24\\]](#page-11-15). We started testing on BaseX 10.4, eXist-DB\
    \ 6.2.0, Saxon Home Edition 12.2, PostgreSQL version 15, and libXML2 commit version\
    \ 106153. As bugs were resolved, we constantly updated to the latest available\
    \ version. We selected BaseX, eXist-DB, and Saxon to be our main testing targets,\
    \ because they all implement the more recent XPath 3.0 standard. BaseX ranks as\
    \ the most popular Native XML DBMS on the DB-Engines Ranking [\\[9\\]](#page-10-7).\
    \ eXist-DB is widely applied in data centers, systems, and platforms, as referenced\
    \ on the eXist-DB reference page [\\[11\\]](#page-10-13). Saxon is an in-memory\
    \ processor and therefore is not included in the DB-Engines rankings. However,\
    \ the official website of Saxon [\\[16\\]](#page-10-14) states: \"More than 170\
    \ software vendors have built Saxon into their own applications\" and \"6 of the\
    \ world's top 10 software vendors are Saxonica clients\", demonstrating that Saxon\
    \ is a widely-used and popular XML processor. For XPath 1.0 standard implementations,\
    \ we tested PostgreSQL, libXML2, and the commercial DBMS. PostgreSQL is a popular\
    \ open-source DBMS, which ranks 4 on the DB-Engines ranking and has 12.8k stars\
    \ on GitHub. libXML2 is a software library developed for the GNOME project. The\
    \ commercial DBMS is often considered the most popular and important DBMS overall,\
    \ as also reflected in various rankings. All XML processors have been actively\
    \ maintained for over 15 years.\n\nExperimental setup. We implemented the tool,\
    \ XPress, in around 8,000 LOC in Java. In our experiments, we configured it to\
    \ generate XML documents that contain 1 to 50 nodes. We create half as many node\
    \ templates as element nodes. For each XML document, we generated 200 XPath expressions.\
    \ Each XPath expression had an equal possibility to hold 1 to 7 sections. We set\
    \ one predicate to hold at most 10 subjects (see Section [3.2\\)](#page-3-0) and\
    \ the depth of the predicate tree to be at most 10. We used the default settings\
    \ of each XML processor. We conducted all our experiments using a personal computer\
    \ with a 64-Core AMD EPYC 7763 CPU at 2.45GHz and 512GB memory running Ubuntu\
    \ 22.04.\n\n### <span id=\"page-5-1\"></span>4.1 Effectiveness\n\nIn this section,\
    \ we show XPress' effectiveness through the number of bugs found, developer feedback,\
    \ and illustrative examples.\n\n<span id=\"page-6-0\"></span>Finding XPath Bugs\
    \ in XML Document Processors via Differential Testing ICSE '24, April 14–20, 2024,\
    \ Lisbon, Portugal\n\nTable 1: Bugs found by XPress\n\n| XML Processor   | Fixed\
    \ | Confirmed | Reported | Total |\n|-----------------|-------|-----------|----------|-------|\n\
    | BaseX           | 15    | 0         | 0        | 15    |\n| eXist-DB       \
    \ | 1     | 5         | 0        | 6     |\n| Saxon           | 4     | 0    \
    \     | 0        | 4     |\n| Commercial DBMS | 0     | 0         | 2        |\
    \ 2     |\n\nTable 2: Category of Bugs found by XPress\n\n| XML Processor   |\
    \ Logic Bugs | Internal Errors |\n|-----------------|------------|-----------------|\n\
    | BaseX           | 10         | 5               |\n| eXist-DB        | 5    \
    \      | 1               |\n| Saxon           | 2          | 2               |\n\
    | Commercial DBMS | 2          | 0               |\n\nMethodology. We implemented\
    \ the tool while intermittently testing the systems over a period of 3 months.\
    \ For every found discrepancy, we reduced the test case. If the test case exhibited\
    \ an unreported pattern, we considered it likely to be an unknown bug and reported\
    \ it to the developers. Note that this was a best-effort approach, and that it\
    \ is an unsolved problem of how to identify duplicate bugs effectively. Whether\
    \ we considered a bug as unique was based on the developers' verdict; we considered\
    \ a bug only as unique if an issue was addressed through an independent bug fix.\
    \ Unfixed bugs hinder testing, as the duplicates tend to be repeatedly triggered.\
    \ To tackle this, we attempted to disable the construction of bug-inducing elements,\
    \ and also ignored known discrepancy patterns before the reported bug was resolved.\n\
    \nFound bugs overview. As shown in Table [1,](#page-6-0) we successfully found\
    \ 27 unique bugs in total, 15 in BaseX, 6 in eXist-DB, 4 in Saxon, and 2 in the\
    \ commercial DBMS. As detailed subsequently, we could have reported additional\
    \ bugs for eXist-DB and the commercial DBMS, but refrained from doing so due to\
    \ the high number of unfixed bugs for eXist-DB, and lack of developer feedback\
    \ for the commercial DBMS. The bug-inducing test cases we found were not covered\
    \ by the W3C qt3 test suite [\\[19\\]](#page-11-3), which contains around 30,000\
    \ tests for XPath and XQuery—Saxon 11.1 passes all applicable tests in the W3C\
    \ qt3 test suite [\\[17\\]](#page-11-16). Out of the 27 bugs found, the majority,\
    \ 19 bugs, were logic bugs. Based on developer feedback, we learned that among\
    \ the 20 fixed bugs, at least 8 bugs were due to incorrect optimizations. We detected\
    \ the remaining bugs through unexpected errors. All systems we tested were implemented\
    \ in Java, so we did not observe any crash bugs. We did not find any bugs in PostgreSQL\
    \ and libXML2, both of which are known to be robust systems. For example, previous\
    \ bug-finding efforts on testing DBMSs using SQL queries also found no logic bug\
    \ in PostgreSQL [\\[34,](#page-11-17) [35\\]](#page-11-18).\n\nSmall-scope hypothesis.\
    \ We observed that the reported bugs are mainly reproducible by short test cases.\
    \ 70% of all the reported cases can be reproduced with an XML document that consists\
    \ of only one node and 91% of XPath expression consists of only one section. The\
    \ average length of the XML documents in the reported test cases was 12 characters\
    \ and XPath expressions 30 characters. This\n\n<span id=\"page-6-4\"></span>\n\
    \n| XML:       | XPath:                      |  |\n|------------|-----------------------------|--|\n\
    | <T>1</T>   | //T[(@t >= 0) or (@t <= 1)] |  |\n| Result: {} | <T>1</T>     \
    \               |  |\n\nFigure 4: Incorrect optimization of comparison conditions.\n\
    \n<span id=\"page-6-6\"></span>\n\n| XML:         | XPath: |    |  |  |      \
    \                              |  |\n|--------------|--------|----|--|--|------------------------------------|--|\n\
    | <S/>         |        |    |  |  | //S[last() * 150000 >= position()] |  |\n\
    | Result: <S/> |        | {} |  |  |                                    |  |\n\
    \nFigure 5: Arithmetic overflow in pre-check conditions.\n\nphenomenon is known\
    \ as the small-scope hypothesis [\\[21\\]](#page-11-19), and this observation\
    \ has been exploited in testing work that systematically generates small test\
    \ inputs [\\[33\\]](#page-11-20).\n\nDeveloper reception. Developer feedback is\
    \ an important indicator of the bugs' importance. A core developer of BaseX stated\
    \ \"Thanks for sharing the bug reports with us. I appreciate that, they're definitely\
    \ helpful.\"[3](#page-6-1) All 15 bugs reported to BaseX were resolved within\
    \ one month—10 bugs were resolved even within 24 hours. This indicates not only\
    \ that the team was fast in resolving bugs, but also that the bug reports were\
    \ considered valuable. Due to the timely fixes of the BaseX team, we invested\
    \ most time and effort in testing BaseX. After encouragement from the developers\
    \ of BaseX, we contributed the bug-inducing test cases to the W3C XQuery and XPath\
    \ test suite [\\[19\\]](#page-11-3). Most bugs submitted to eXist-DB have not\
    \ yet been fixed, which is likely the result of the many open issues (over 400).\
    \ Nevertheless, the developers from eXist-DB confirmed the bugs quickly and also\
    \ expressed appreciation towards the bug reports \"thank you for finding and reporting.\"\
    [4](#page-6-2)[5](#page-6-3) Because the reported bugs remained unfixed for over\
    \ two months, we stopped testing and reporting to eXist-DB after reporting the\
    \ first few found inconsistencies due to the difficulties of filtering out duplicate\
    \ bugs. We believe that XPress has the ability to find more bugs in eXist-DB after\
    \ the known bugs are resolved. Similarly, for the commercial DBMS, since the developers\
    \ did not follow up on the bugs that we reported, we stopped testing this DBMS.\
    \ For Saxon, all four bugs reported were resolved quickly within one week's time.\n\
    \nSelected bugs. Below, we give a few selected examples of bugs found by XPress\
    \ to illustrate its bug-finding capability.\n\nIncorrect optimization of comparison\
    \ conditions. Figure [4](#page-6-4) shows a fixed bug that we reported to BaseX.[6](#page-6-5)\
    \ The XPath expression selects all T nodes with attribute @t that satisfies @t\
    \ >= 0 or @t <= 1. When @t exists and is a numeric value, this is a condition\
    \ that always evaluates to true. Therefore, an optimization in BaseX rewrote the\
    \ predicate to true. However, when @t does not exist for node T, @t evaluates\
    \ to an empty sequence and returns false for both @t >= 0 and @t <= 1. Before\
    \ we reported this bug, this case was overlooked and resulted in an incorrect\
    \ optimization.\n\n<span id=\"page-6-1\"></span><sup>3</sup>[https://www.mail-archive.com/basex-talk@mailman.uni-konstanz.de/msg15173.](https://www.mail-archive.com/basex-talk@mailman.uni-konstanz.de/msg15173.html)\
    \ [html](https://www.mail-archive.com/basex-talk@mailman.uni-konstanz.de/msg15173.html)\n\
    \n<span id=\"page-6-2\"></span><sup>4</sup>[https://www.mail-archive.com/basex-talk@mailman.uni-konstanz.de/msg15204.](https://www.mail-archive.com/basex-talk@mailman.uni-konstanz.de/msg15204.html)\
    \ [html](https://www.mail-archive.com/basex-talk@mailman.uni-konstanz.de/msg15204.html)\n\
    \n<span id=\"page-6-3\"></span><sup>5</sup><https://github.com/eXist-db/exist/issues/4830>\n\
    \n<span id=\"page-6-5\"></span><sup>6</sup><https://github.com/BaseXdb/basex/issues/2190>\n\
    \n<span id=\"page-7-2\"></span>**Result**: \"2\" | {} **XPath:** tail(subsequence(**(1\
    \ to 2)**,1,2))\n\nFigure 6: Result of tail after subsequence off by one.\n\n\
    <span id=\"page-7-4\"></span>\n\n| XML:        | XPath:                      \
    \                     |  |  |  |\n|-------------|--------------------------------------------------|--|--|--|\n\
    | <A><B/></A> | //*[((.,.)/parent::*/last() ! (. > 1)) = true()] |  |  |  |\n\
    | Result: {}  | <B/>                                             |  |  |  |\n\n\
    Figure 7: Incorrect reduce in positional expressions.\n\nArithmetic overflow in\
    \ pre-check conditions. Figure [5](#page-6-6) shows a fixed bug that we reported\
    \ to BaseX.[7](#page-7-1) last() and position() returns the context size and the\
    \ context position from the dynamic context respectively. In the context XML document,\
    \ the prefix //S selects only one node, and therefore both last() and position()\
    \ return 1. Therefore, the condition is true and node S should be selected. In\
    \ BaseX, an empty result set was returned. The problem was related to optimization\
    \ for positional arguments in conditional comparisons. BaseX substituted last()\
    \ with the greatest theoretical last() value and checked if the condition could\
    \ evaluate to true. If not, the condition could not be satisfied regardless of\
    \ the actual context and could be rewritten to false to reduce context analysis.\
    \ When calculating the multiplication, as the theoretical maximum value for last()\
    \ is a big integer, calculating the expression with long instead of double caused\
    \ an overflow and produced the incorrect result.\n\nResult of tail after subsequence\
    \ off by one. Figure [6](#page-7-2) shows a fixed bug that we reported to eXist-DB.[8](#page-7-3)\
    \ 1 to 2 creates an integer sequence consisting of 1 and 2. The subsequence()\
    \ function in this example selects two elements starting from index 1, and the\
    \ tail() function returns a new sequence excluding the first element of the input\
    \ sequence. The correct result is to return 2. Unexpectedly, eXist-DB returned\
    \ an empty result set. This was caused by a mistake when processing a call to\
    \ tail that has a call to subsequence as an argument, which incorrectly reduced\
    \ the ending index by 1.\n\nIncorrect reduce in positional expressions. Figure\
    \ [7](#page-7-4) shows a fixed bug that we reported to Saxon.[9](#page-7-5) The\
    \ dot (.) stands for the current context in XPath expressions. For node B, (.,\
    \ .)/parent::\\* selects the single node A as the parent. Therefore, last() =\
    \ 1 and the condition evaluates to false. Saxon unexpectedly returned the node\
    \ B. The = operator is considered to be an unordered operator, which does not\
    \ require operands to be sorted. In Saxon, an optimization was applied to eschew\
    \ removing duplicate nodes when evaluating the sub-expression, which resulted\
    \ in A being selected twice and last() evaluated to 2. After we found and reported\
    \ the bug, a patch was applied by the developers to remove the duplicates, when\
    \ the left operand of = is positional sensitive.\n\n### <span id=\"page-7-0\"\
    ></span>4.2 Efficiency\n\nExisting-generator baselines. We considered the only\
    \ two—to the best of our knowledge—approaches to generate XPath expressions. Neither\
    \ of them was specifically designed to be combined with a\n\nXPath test oracle.\
    \ XQgen [\\[42\\]](#page-11-21) generates XPath queries for microbenchmarking.\
    \ Its generated predicates only check for sub-element existence. The XQuery generator\
    \ designed by Todic and Uzelac [\\[41\\]](#page-11-4) generates XPath queries\
    \ for automatically testing index support in DBMSs. Given that indexes apply only\
    \ to sargable queries (i.e., simple comparisons), the expressions it generates\
    \ are simple. Both approaches generate XPath expressions based on an XML schema,\
    \ while XPress generates XPath expressions based on the actual XML document. Based\
    \ on this, we expect both of them to have low applicability for our differential-testing\
    \ approach. Given that neither implementations are publicly available, we re-implemented\
    \ them based on the description in the papers.\n\nSelf-constructed baselines.\
    \ We also constructed our own baselines to investigate the efficiency of the separate\
    \ components of XPress. XPress has two main components, namely (1) the targeted\
    \ predicate generation by using the targeted node to refer to existing nodes and\
    \ attributes and (2) the predicate rectification to avoid empty result sets. To\
    \ evaluate the effect of the components individually, we enabled them individually\
    \ to test whether they improve XPress's bug detection efficiency.\n\nConfigurations.\
    \ We considered four configurations for our selfconstructed baselines. Apart from\
    \ our proposed approach introduced in Section [3.2](#page-3-0) as (1) Targeted,\
    \ we derive configuration (2) Targeted without Rectification, (3) Untargeted with\
    \ Rectification, and (4) Untargeted without Rectification. In (2) Targeted without\
    \ Rectification, we disable the rectification process, which would otherwise ensure\
    \ targeted node selection. Since selecting a targeted node for predicate generation\
    \ guidance always requires at least one node in the result set, we stop generating\
    \ new sections after an empty result set is produced. In (3) Untargeted with Rectification,\
    \ we generate predicates without using targeted node information to supply parameters\
    \ that reference existent context and trigger corner cases for function nodes,\
    \ while keeping the rectification to ensure that at least one node from the candidate\
    \ set is included in the result set. In (4) Untargeted without rectification,\
    \ we remove both components to generate predicates randomly, while omitting rectification.\n\
    \nMethodology. We set each baseline to run for 24 hours [\\[30\\]](#page-11-22).\
    \ We repeated each experiment 10 times to account for potential performance deviations,\
    \ and report the arithmetic mean for all metrics. As our testing target, we selected\
    \ BaseX 10.4, which is the BaseX version that we first started testing. The reason\
    \ for selecting BaseX as a representative is that we found most bugs in BaseX\
    \ and all bugs were fixed, allowing us to determine the number of unique bugs\
    \ we found in a testing campaign by deduplicating bug-inducing test cases automatically.\
    \ Specifically, given two bug-inducing test cases, we could determine whether\
    \ they trigger the same underlying bug by identifying their fix commits; only\
    \ if their associated fix commit are different, do we consider the bugs unique.\
    \ This is a best-effort technique, as, for example, one fix commit might address\
    \ multiple bugs. We disabled the generation of the has-children functions as well\
    \ as using relative XPath expressions in predicates, as they consistently lead\
    \ to crashes, triggering known bugs.\n\nResults of existing generators. Neither\
    \ XQGen nor the Combined XML/XQuery generator found bugs in our experiment. This\
    \ is expected, as previously proposed approaches were not designed for\n\n<span\
    \ id=\"page-7-1\"></span><sup>7</sup><https://github.com/BaseXdb/basex/issues/2220>\n\
    \n<span id=\"page-7-3\"></span><sup>8</sup><https://github.com/eXist-db/exist/issues/4830>\n\
    \n<span id=\"page-7-5\"></span><sup>9</sup><https://saxonica.plan.io/issues/6093?pn=1#change-24136>\n\
    \n<span id=\"page-8-1\"></span>![](_page_8_Figure_1.jpeg)\n\nFigure 8: Average\
    \ number of unique bugs found under different configurations in 24 hours across\
    \ 10 runs.\n\n<span id=\"page-8-2\"></span>Table 3: Average bug report collection\
    \ under different configurations in 24 hours across 10 runs.\n\n| Config     \
    \         | Total<br>cases | Differences<br>detected | Unique<br>bugs | Non-empty<br>result\
    \ |\n|---------------------|----------------|-------------------------|----------------|---------------------|\n\
    | Targeted            | 6.6M           | 11.8K                   | 12.5      \
    \     | 100%                |\n| Targeted w/o Rect   | 9.4M           | 10.2K\
    \                   | 12             | 66%                 |\n| Untargeted w/\
    \ Rect  | 8.8M           | 1.4K                    | 6.5            | 100%   \
    \             |\n| Untargeted w/o Rect | 13.5M          | 0.6K               \
    \     | 6.1            | 44%                 |\n\nautomated testing. As mentioned\
    \ above, XQGen generates predicates that only check for element existence. The\
    \ XQuery generator designed by Todic and Uzelac generates simple predicates that\
    \ include at most one comparison operator.\n\nResults of different configurations.\
    \ As Figure [8](#page-8-1) shows, our proposed approach, Targeted outperforms\
    \ the other configurations. Within 24 hours, it found the most number of unique\
    \ bugs (namely 12.5). Both configurations with targeted generation clearly outperformed\
    \ the untargeted approaches, while rectification shows a similar performance in\
    \ the speed of bug detection. As shown in Table [3,](#page-8-2) both targeted\
    \ generation and rectification reduce the testing throughput, as they obtain intermediate\
    \ results using the XML processor under test. Despite generating only 50% of the\
    \ number of test cases as compared to (4) Untargeted without Rectification, (1)\
    \ Targeted detected 20× more bug-inducing test cases and 2× more unique bugs.\
    \ The results show that selecting a target node to guide the XPath generation\
    \ process improves testing efficiency significantly. As observed above when discussing\
    \ the small-scope hypothesis, most of the bugs that we found can be reproduced\
    \ using a single section, explaining the limited effectiveness of rectification.\
    \ However, we still believe that rectification is an important component, since\
    \ without it, bugs requiring multiple sections with non-empty results could hardly\
    \ be found.\n\nCode coverage. We collected code coverage for three processors'\
    \ core modules for XPress for 24 hours [\\[30\\]](#page-11-22) of execution. The\
    \ result is shown in Table [4.](#page-8-3) To put the numbers in relation, we\
    \ collected coverage also for the projects' test suites; Saxon has no publicly\
    \ available test suites and is therefore excluded. For the three XML processors,\
    \ the line coverage ranged from 15% to 20%, and the\n\n<span id=\"page-8-3\"></span>Table\
    \ 4: Code coverage of tested systems in 24 Hours\n\n| Approach   |      | BaseX\
    \  |      | eXist  | Saxon |        |  |\n|------------|------|--------|------|--------|-------|--------|--|\n\
    |            | Line | Branch | Line | Branch | Line  | Branch |  |\n| XPress \
    \    | 20%  | 16%    | 18%  | 10%    | 15%   | 10%    |  |\n| Unit Tests | 67%\
    \  | 58%    | 52%  | 47%    | -     | -      |  |\n\nbranch coverage ranged from\
    \ 10% to 16%. The coverage percentages are low, which is expected. The main reason\
    \ for low code coverage is that XML processors typically also have other components\
    \ than XPath processing. Taking BaseX as an example, around 21% of uncovered code\
    \ was GUI-related, 10% was due to lack of full-text functionality support, and\
    \ 5% were database commands. In Saxon, as another example, XSLT modules have not\
    \ been covered. A further 18% uncovered code in BaseX involved unimplemented functions;\
    \ it would be straightforward to implement many additional ones, such as math\
    \ functions, but the many functions available would make this a tedious task.\
    \ In Section [4.4,](#page-9-0) we detail unsupported XPath features, implementing\
    \ which might allow us to find more bugs. XPress's test-case generation process\
    \ primarily aims at generating semantically valid expressions, which results in\
    \ low error-checking branch coverage, quantifying which is difficult, as the relevant\
    \ code is spread throughout the code base.\n\n### <span id=\"page-8-0\"></span>4.3\
    \ Comparison to the State of the Art\n\nWe are aware of only one automated testing\
    \ approach that has been proposed to test XML processors [\\[41\\]](#page-11-4).\
    \ It tackled the test oracle problem by using differential testing by comparing\
    \ the results of Microsoft's SQLServer with and without using indexes. Their approach\
    \ was specifically designed to test SQLServer's index support and is not publicly\
    \ available. Due to the narrow testing scope, and since the tool is not publicly\
    \ available, we could not conduct experiments to directly compare the approaches.\
    \ However, we further extended our tool to support differential testing with index\
    \ configurations. Both approaches are complementary, as XPress could not only\
    \ use differential testing among various XML processors, but also create or omit\
    \ indexes to find additional bugs.\n\nIndex support in BaseX, eXist-DB, Saxon,\
    \ and libxml2. Database indexes are data structures built to speed up data retrieval\
    \ [\\[31\\]](#page-11-23) and are DBMS-specific. Not all XML processors are DBMSs—as\
    \ in-memory processors, Saxon and libxml2 lack support for indexes. BaseX and\
    \ eXist-DB both enable structural indexes, such as storing all distinct paths\
    \ of nodes by default. For value indexes to optimize querying on content values,\
    \ BaseX creates text index and attribute index automatically. Users can further\
    \ define additional indexes. Additionally, BaseX provides token indexes, which\
    \ apply to specific functions, such as contains-token. eXist supports range indexes,\
    \ which could be defined for specific nodes or attributes to speed up related\
    \ comparison searches on their contents.\n\nMethodology. We tested eXist's range\
    \ index and BaseX's token index using the XPath expression generation approach\
    \ as described in Section [3.2.](#page-3-0) Due to the found unfixed bugs in eXist,\
    \ we conducted differential testing within eXist by checking the results with\
    \ and\n\n|  |  |  |  |  |  | Shuxin Li and Manuel Rigger |\n|--|--|--|--|--|--|-----------------------------|\n\
    |--|--|--|--|--|--|-----------------------------|\n\n<span id=\"page-9-2\"></span>\n\
    \n| XML:         | XPath:                                             |  |\n|--------------|----------------------------------------------------|--|\n\
    | <M v=\"a\"/>   | //M/descendant-or-self::M[contains-token(@v, \"a\")] |  |\n\
    | Result: <M/> | {} (create index token)                            |  |\n\nFigure\
    \ 9: Found bug with token index in BaseX.\n\nwithout range index definition. For\
    \ BaseX, we defined a token index and compared its results directly with the results\
    \ of Saxon.\n\nResults. Throughout the testing method, we detected one additional\
    \ bug for BaseX[10](#page-9-1) and found no additional bugs in eXist. We reported\
    \ the found bug shown in Figure [9](#page-9-2) to the BaseX developers, who quickly\
    \ fixed it. The query selects all nodes with tag name M in the document which\
    \ holds attribute v that contains token \"a\". BaseX returned node M without token\
    \ index, as expected, while unexpectedly returning an empty result set when not\
    \ using an index. Overall, while the results suggest that using or removing indexes\
    \ might find additional bugs, doing so had low effectiveness. A potential explanation\
    \ could be that our test-case generation approach does not consider when indexes\
    \ could be applied, which might result in low testing efficiency.\n\n### <span\
    \ id=\"page-9-0\"></span>4.4 Analysis of BaseX Historical Bug Reports\n\nUnlike\
    \ formal verification approaches, automatic testing approaches might miss bugs\
    \ in the system tested. Due to the lack of ground truth, we cannot generally determine\
    \ which bugs are overlooked by our approach. However, as a best-effort approach,\
    \ we studied historical bug reports in order to determine whether XPress could\
    \ have found them.\n\nBug reports. We analyzed all historical BaseX bug reports\
    \ in its GitHub bug tracker. We selected BaseX, because the majority of issues\
    \ are closed (1618 out of 1640). The issue tracker of BaseX is used for confirmed\
    \ bug reports filtered from reports from the mailing list, and the BaseX maintainers\
    \ carefully label and document them. For these reasons, it was easy to identify\
    \ and classify the underlying problem of each bug report.\n\nMethodology. We manually\
    \ analyzed all historical bug issues until 2023 Apr 17 in BaseX, which were 1597\
    \ issues, after excluding the issues we reported. To confine the study of bug\
    \ reports within the scope of XPath, we selected bug reports triggered by only\
    \ XPath expressions. To determine whether a bug could be theoretically found by\
    \ XPress, we mainly checked three aspects of the reports. For XPress to cover\
    \ the test case, both the XML document and the XPath expression in the test case\
    \ should not include any unimplemented functions or language features. Second,\
    \ we could construct the sections and the predicate tree structure of XPress for\
    \ involved predicates to form the pattern of the bug-inducing XPath expression.\
    \ Third, XML processors should disagree on the result set. Note that this is a\
    \ best-effort approach, because we might both incorrectly conclude that XPress\
    \ might find a bug (e.g., it might be unlikely that the test case would be generated\
    \ in practice) or incorrectly conclude that a bug cannot be found even when a\
    \ different test-case within the reach of XPress would trigger the same underlying\
    \ bug.\n\nResults. Out of the total 78 bugs that we collected, we identified 20\
    \ bugs that could have been detected by XPress. For the other 58 bugs, we identified\
    \ 4 kinds of bugs that XPress would have failed to find, namely due to (1) unimplemented\
    \ functionalities (51 cases), (2) invalid inputs where the expected result would\
    \ be an error (6 cases), (3) processors producing different results (2 cases),\
    \ and (4) miscellaneous other issues (6 cases). Bugs belonging to more than one\
    \ group are included in all involved groups. The differential testing oracle fails\
    \ to detect the bugs with processors producing different results, while we consider\
    \ the other categories mostly as implementation limitations in test-case generation.\
    \ Therefore, out of all 78 bugs, 76 bugs (97%) could be detected through differential\
    \ testing. This further demonstrates the effectiveness of employing a differential\
    \ testing oracle for XPath-related testing.\n\nUnimplemented functionalities.\
    \ Most uncovered bug reports are due to unimplemented functionalities. Unsupported\
    \ functions include constructors defined by the XML or XPath language standards,\
    \ array and map functions, and also constructors of derived datatypes [\\[2\\\
    ]](#page-10-15), such as xs:NMtokens. Given enough time, it would be straightforward\
    \ to implement them in XPress. For/while loops, variable declaration, if-else\
    \ conditional expressions, and self-defined functions are also unimplemented.\
    \ These could be supported based on approaches that have been proposed in the\
    \ context of compiler testing [\\[32,](#page-11-24) [43\\]](#page-11-6). Neither\
    \ the XML documents nor XPath expressions that XPress constructs involve namespaces,\
    \ which allow distinguishing items with the same tag name. They could be integrated\
    \ into the XPress test-case generator. By implementing all these features, an\
    \ additional 38 bugs (48%) could have been found.\n\nExpected errors. Bug reports\
    \ grouped into expected is error refers to invalid test cases, which are successfully\
    \ executed instead of throwing an error. XPress constructs both syntactically\
    \ and semantically valid expressions and therefore could not detect bugs within\
    \ this category. However, the differential testing oracle could detect these bugs\
    \ by comparing the errors of the different XML processors.\n\nDifferent results.\
    \ The different result category contains queries for which different processors\
    \ intentionally produce different results, which shows the limitation of the differential\
    \ testing oracle. One example is the function id, which selects nodes with xml:id\
    \ attributes. BaseX takes attributes named as id as xml:id attributes, while Saxon\
    \ and eXist-DB require an explicit declaration.\n\n### 5 RELATED WORK\n\nWhile\
    \ various related approaches to our work exist, to the best of our knowledge,\
    \ we propose the first general approach to testing XML processors to find logic\
    \ bugs. As discussed above, the most closely related work proposed testing the\
    \ index support of SQLServer in the context of XPath and XQuery [\\[41\\]](#page-11-4),\
    \ which, to the best of our knowledge, is the only work that has tackled the test-oracle\
    \ problem for XML processors, but is limited in scope.\n\nTesting XPath functionality.\
    \ Various approaches to benchmarking XPath implementations or test suites for\
    \ them have been proposed, the most representative being XPathMark and the W3C\
    \ qt3 test suite. XPathMark [\\[25\\]](#page-11-2) is a benchmark for testing\
    \ XML processors' XPath standard 1.0 functionality, containing both correctness\n\
    \n<span id=\"page-9-1\"></span><sup>10</sup><https://github.com/BaseXdb/basex/issues/2222>\n\
    \nas well as performance tests. The W3C qt3 test suite developed by the W3C XQuery\
    \ and XSLT Working Groups [\\[19\\]](#page-11-3) contains around 30,000 tests\
    \ for XPath and XQuery targeting XPath 3.0 and later versions, which cover a broad\
    \ range of functions and expressions.\n\nXML-related automated synthetic data\
    \ generation. Previous works have proposed approaches for automatically generating\
    \ XML-related data, such as XML documents, XPath, and XQuery expressions. Aboulnaga\
    \ et al. proposed an XML document generator to generate synthetic, but complex,\
    \ structured XML data by introducing recursion and repetition on tag name assignment\
    \ and controlling the element frequency distribution [\\[20\\]](#page-11-25).\
    \ Rychnovský and Holubová proposed an approach to generate XML documents related\
    \ to given XPath queries from a specific XML schema to improve query efficiency\
    \ [\\[37\\]](#page-11-26), which is useful for developers to create micro-benchmarks\
    \ for testing performance over certain XPath expressions. XQGen [\\[42\\]](#page-11-21)\
    \ is a tool for generating XPath queries that conform to a given XML schema, allowing\
    \ users to specify multiple parameters, such as the percentage of empty queries\
    \ desired and the percentage of queries with predicates. XPath generated by XQ-Gen\
    \ includes only direct node tests without introducing complex expressions, such\
    \ as axes or function transformations. Similarly, the XQuery generator designed\
    \ by Todic and Uzelac [\\[41\\]](#page-11-4) includes XQuery FLWOR expressions,\
    \ but the logic predicate consists only of simple operations, such as value comparisons.\
    \ Neither of these works tackled the test oracle problem, and, as indicated by\
    \ the results in Section [4.3,](#page-8-0) given their different focus, they cannot\
    \ be effectively combined with a differential testing oracle.\n\nTargeted test\
    \ case generation. Many testing tools guide their test case generation process\
    \ to improve testing efficiency, for random approaches such as random byte mutation\
    \ used in fuzzing approaches generate a large proportion of invalid queries [\\\
    [47\\]](#page-11-27). DynSQL [\\[27\\]](#page-11-28) guides the fuzzing process\
    \ of DBMSs towards increased code coverage and high statement validity. APOLLO\
    \ [\\[28\\]](#page-11-29) is a system for detecting performance regression bugs\
    \ in DBMSs. It increases the probability of including components from previously\
    \ encountered performance issues. Cynthia [\\[39\\]](#page-11-9) was proposed\
    \ to test Object Relational Mappers (ORMs) and generates targeted databases dependent\
    \ on generated abstract SQL queries, which are likely to return non-empty results.\
    \ Query Plan Guidance (QPG) [\\[22\\]](#page-11-30) guides testing towards exploring\
    \ more unique query plans.\n\nPivoted Query Synthesis. The targeted node in XPress\
    \ was inspired by the pivot row in Pivoted Query Synthesis (PQS) [\\[36\\]](#page-11-12),\
    \ which was originally proposed to test relational DBMSs. PQS' and XPress' commonality\
    \ is that they select a random element, in PQS, a row in the database, while for\
    \ XPress, a node in an XML document, based on which they generate a query that\
    \ is guaranteed to fetch the element. However, both the purpose and use of the\
    \ targeted node and pivot row differ. In PQS, the pivot row is used both for test-case\
    \ generation and to construct the test oracle, by evaluating an expression and\
    \ ensuring that it evaluates to true for the pivot row so that it can be used\
    \ in a query that is guaranteed to fetch the row. Doing so requires a naive reimplementation\
    \ of all the DBMSs' operators that should be tested, which incurs a high implementation\
    \ effort, as highlighted in follow-up work [? ]. In XPress, the targeted node\
    \ is used only for test-case generation, to improve\n\ntesting efficiency and\
    \ to ensure non-empty intermediate results; to this end, XPress uses the XML processor\
    \ to determine the result of the expression, rather than requiring the reimplementation\
    \ of operators. In addition, for predicate rectification, XPress provides operator-specific\
    \ rules, rather than relying on a generic one, aiming to generate more interesting\
    \ test cases. The high-level idea of a pivot element also inspired other works;\
    \ for example, recent work on Android testing introduced the concept of a pivot\
    \ layout [\\[40\\]](#page-11-31).\n\n### 6 CONCLUSION\n\nThis paper has presented\
    \ a general automated testing approach for detecting XPath-related logic bugs\
    \ in XML processors. We demonstrate that differential testing is applicable in\
    \ this domain, since XML processors widely adhere to the XPath standards. To generate\
    \ interesting XPath queries, our approach selects a so-called targeted node to\
    \ guide predicate generation and predicate rectification to ensure the inclusion\
    \ of that node. Our evaluation shows that this improves the number of bugs detected\
    \ in 24 hours to 2× as compared to random generation. More importantly, we have\
    \ successfully detected 27 previously unknown, unique bugs in six mature XML processing\
    \ systems. We believe that this high number is surprising, given that XML processors\
    \ are an essential part of our computing infrastructure, with the first XPath\
    \ standard having been proposed more than 20 years ago, and the systems that we\
    \ have tested having been maintained for at least 15 years. We believe that XPress,\
    \ given its simplicity and generality, has a high chance of being integrated into\
    \ the toolbox of XML processor developers. Furthermore, we believe that our work\
    \ might inspire testing approaches for other XML standards, such as XQuery or\
    \ XSLT.\n\n### ACKNOWLEDGMENTS\n\nThis research was supported by a Ministry of\
    \ Education (MOE) Academic Research Fund (AcRF) Tier 1 grant.\n\n### REFERENCES\n\
    \n- <span id=\"page-10-12\"></span>[1] 1999. XML Path Language (XPath) Version\
    \ 1.0 W3C Recommendation. Retrieved July 17, 2023 from<https://www.w3.org/TR/1999/REC-xpath-19991116/>\n\
    - <span id=\"page-10-15\"></span>[2] 2004. XML Schema Part 2: Datatypes Second\
    \ Edition - Built-in datatypes. Retrieved July 17, 2023 from<https://www.w3.org/TR/xmlschema-2/#built-in-datatypes>\n\
    - <span id=\"page-10-10\"></span>[3] 2008. EBNF notation from the W3C Extensible\
    \ Markup Language (XML) 1.0 (Fifth Edition). Retrieved July 17, 2023 from<https://www.w3.org/TR/REC-xml/>\n\
    - <span id=\"page-10-9\"></span>[4] 2014. XML Path Language (XPath) 3.0 W3C Recommendation.\
    \ Retrieved July 17, 2023 from<https://www.w3.org/TR/xpath-30/>\n- <span id=\"\
    page-10-11\"></span>[5] 2014. XPath and XQuery Functions and Operators 3.0 W3C\
    \ Recommendation. Retrieved July 17, 2023 from<https://www.w3.org/TR/xpath-functions-30/>\n\
    - <span id=\"page-10-1\"></span>[6] 2017. XQuery 3.1: An XML Query Language W3C\
    \ Recommendation. Retrieved July 17, 2023 from<https://www.w3.org/TR/xquery-31/>\n\
    - <span id=\"page-10-0\"></span>[7] 2017. XSL Transformations (XSLT) Version 3.0\
    \ W3C Recommendation. Retrieved July 17, 2023 from<https://www.w3.org/TR/xslt-30/>\n\
    - <span id=\"page-10-2\"></span>[8] 2023. BaseX. Retrieved July 31, 2023 from<https://basex.org/>\n\
    - <span id=\"page-10-7\"></span>[9] 2023. DB-Engines Ranking. Retrieved July 6,\
    \ 2023 from [https://db-engines.com/](https://db-engines.com/en/ranking) [en/ranking](https://db-engines.com/en/ranking)\n\
    - <span id=\"page-10-3\"></span>[10] 2023. eXist-DB. Retrieved July 31, 2023 from\
    \ [http://exist-db.org/exist/apps/](http://exist-db.org/exist/apps/homepage/index.html)\
    \ [homepage/index.html](http://exist-db.org/exist/apps/homepage/index.html)\n\
    - <span id=\"page-10-13\"></span>[11] 2023. eXist DB reference page. Retrieved\
    \ July 6, 2023 from [http://exist-db.org/](http://exist-db.org/exist/apps/homepage/references.html)\
    \ [exist/apps/homepage/references.html](http://exist-db.org/exist/apps/homepage/references.html)\n\
    - <span id=\"page-10-8\"></span>[12] 2023. libXML2. Retrieved July 31, 2023 from\
    \ [https://gitlab.gnome.org/GNOME/](https://gitlab.gnome.org/GNOME/libxml2) [libxml2](https://gitlab.gnome.org/GNOME/libxml2)\n\
    - <span id=\"page-10-5\"></span>[13] 2023. MySQL. Retrieved July 31, 2023 from<https://www.mysql.com/>\n\
    - <span id=\"page-10-4\"></span>[14] 2023. Oracle Database. Retrieved July 31,\
    \ 2023 from [https://www.oracle.com/](https://www.oracle.com/database/) [database/](https://www.oracle.com/database/)\n\
    - <span id=\"page-10-14\"></span><span id=\"page-10-6\"></span>[15] 2023. PostgreSQL.\
    \ Retrieved July 31, 2023 from<https://www.postgresql.org/>\n- [16] 2023. Saxon\
    \ home page. Retrieved July 6, 2023 from [https://saxonica.com/html/](https://saxonica.com/html/welcome/welcome.html)\
    \ [welcome/welcome.html](https://saxonica.com/html/welcome/welcome.html)\n- <span\
    \ id=\"page-11-16\"></span><span id=\"page-11-0\"></span>[17] 2023. Saxon XQuery\
    \ 3.1 conformance page. Retrieved July 13, 2023 from [https:](https://www.saxonica.com/documentation12/#!conformance/xquery31)\
    \ [//www.saxonica.com/documentation12/#!conformance/xquery31](https://www.saxonica.com/documentation12/#!conformance/xquery31)\n\
    - <span id=\"page-11-1\"></span>[18] 2023. Saxonica. Retrieved July 31, 2023 from<https://saxonica.com/>\n\
    - <span id=\"page-11-3\"></span>[19] 2023. W3C qt3 test suite github repository.\
    \ Retrieved July 11, 2023 from [https:](https://github.com/w3c/qt3tests) [//github.com/w3c/qt3tests](https://github.com/w3c/qt3tests)\n\
    - <span id=\"page-11-25\"></span>[20] Jeffrey F. Naughton Aboulnaga, Ashraf and\
    \ Chun Zhang. 2001. Generating Synthetic Complex-Structured XML Data. WebDB. 1\
    \ (2001), 79–84.\n- <span id=\"page-11-19\"></span>[21] Alexandr Andoni, Dumitru\
    \ Daniliuc, Sarfraz Khurshid, and Darko Marinov. 2003. Evaluating the \"small\
    \ scope hypothesis\".\n- <span id=\"page-11-30\"></span>[22] Jinsheng Ba and Manuel\
    \ Rigger. 2023. Testing Database Engines via Query Plan Guidance. In 2023 IEEE/ACM\
    \ 45th International Conference on Software Engineering (ICSE). 2060–2071.<https://doi.org/10.1109/ICSE48619.2023.00174>\n\
    - <span id=\"page-11-8\"></span>[23] Yuting Chen, Ting Su, Chengnian Sun, Zhendong\
    \ Su, and Jianjun Zhao. 2016. Coverage-Directed Differential Testing of JVM Implementations.\
    \ In Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design\
    \ and Implementation (Santa Barbara, CA, USA) (PLDI '16). Association for Computing\
    \ Machinery, New York, NY, USA, 85–99.<https://doi.org/10.1145/2908080.2908095>\n\
    - <span id=\"page-11-15\"></span>[24] Timothy Dyck. 2002. DB Test Pioneer Makes\
    \ History. Retrieved July 31, 2023 from<https://www.eweek.com/development/db-test-pioneer-makes-history/>\n\
    - <span id=\"page-11-2\"></span>[25] Massimo Franceschet. 2005. XPathMark: An\
    \ XPath Benchmark for the XMark Generated Data. In Database and XML Technologies,\
    \ Stéphane Bressan, Stefano Ceri, Ela Hunt, Zachary G. Ives, Zohra Bellahsène,\
    \ Michael Rys, and Rainer Unland (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg,\
    \ 129–143.\n- <span id=\"page-11-13\"></span>[26] Ziyue Hua, Wei Lin, Luyao Ren,\
    \ Zongyang Li, Lu Zhang, Wenpin Jiao, and Tao Xie. 2023. GDsmith: Detecting Bugs\
    \ in Cypher Graph Database Engines. Association for Computing Machinery, New York,\
    \ NY, USA. [https://doi.org/10.1145/3597926.](https://doi.org/10.1145/3597926.3598046)\
    \ [3598046](https://doi.org/10.1145/3597926.3598046)\n- <span id=\"page-11-28\"\
    ></span>[27] Zu-Ming Jiang, Jia-Ju Bai, and Zhendong Su. 2023. DynSQL: Stateful\
    \ Fuzzing for Database Management Systems with Complex and Valid SQL Query Generation.\
    \ In Proceedings of the 32nd USENIX Conference on Security Symposium (Anaheim,\
    \ CA, USA) (SEC '23). USENIX Association, USA, Article 277, 17 pages.\n- <span\
    \ id=\"page-11-29\"></span>[28] Jinho Jung, Hong Hu, Joy Arulraj, Taesoo Kim,\
    \ and Woonhak Kang. 2019. APOLLO: Automatic Detection and Diagnosis of Performance\
    \ Regressions in Database Systems. Proc. VLDB Endow. 13, 1 (sep 2019), 57–70.\
    \ [https:](https://doi.org/10.14778/3357377.3357382) [//doi.org/10.14778/3357377.3357382](https://doi.org/10.14778/3357377.3357382)\n\
    - <span id=\"page-11-14\"></span>[29] Matteo Kamm, Manuel Rigger, Chengyu Zhang,\
    \ and Zhendong Su. 2023. Testing Graph Database Engines via Query Partitioning.\
    \ Association for Computing Machinery, New York, NY, USA.<https://doi.org/10.1145/3597926.3598044>\n\
    - <span id=\"page-11-22\"></span>[30] George Klees, Andrew Ruef, Benji Cooper,\
    \ Shiyi Wei, and Michael Hicks. 2018. Evaluating Fuzz Testing. Proceedings of\
    \ the 2018 ACM SIGSAC conference on computer and communications security (2018).\
    \ [https://doi.org/10.1145/3243734.](https://doi.org/10.1145/3243734.3243804)\
    \ [3243804](https://doi.org/10.1145/3243734.3243804)\n- <span id=\"page-11-23\"\
    ></span>[31] Quanzhong Li and Bongki Moon. 2001. Indexing and Querying XML Data\
    \ for Regular Path Expressions. In Proceedings of the 27th International Conference\
    \ on Very Large Data Bases (VLDB '01). Morgan Kaufmann Publishers Inc., San Francisco,\
    \ CA, USA, 361–370.\n- <span id=\"page-11-24\"></span>[32] Vsevolod Livinskii,\
    \ Dmitry Babokin, and John Regehr. 2023. Fuzzing Loop Optimizations in Compilers\
    \ for C++ and Data-Parallel Languages. Proc. ACM Program. Lang. 7, PLDI, Article\
    \ 181 (jun 2023), 22 pages.<https://doi.org/10.1145/3591295>\n- <span id=\"page-11-20\"\
    ></span>[33] Jayashree Mohan, Ashlie Martinez, Soujanya Ponnapalli, Pandian Raju,\
    \ and Vijay Chidambaram. 2018. Finding Crash-Consistency Bugs with Bounded Black-Box\
    \ Crash Testing. In 13th USENIX Symposium on Operating Systems Design and Implementation\
    \ (OSDI 18). 33–50.\n- <span id=\"page-11-17\"></span>[34] Manuel Rigger and Zhendong\
    \ Su. 2020. Detecting Optimization Bugs in Database Engines via Non-Optimizing\
    \ Reference Engine Construction. In Proceedings of the 28th ACM Joint Meeting\
    \ on European Software Engineering Conference and\n\nSymposium on the Foundations\
    \ of Software Engineering (Virtual Event, USA) (ESEC/FSE 2020). Association for\
    \ Computing Machinery, New York, NY, USA, 1140–1152.<https://doi.org/10.1145/3368089.3409710>\n\
    \n- <span id=\"page-11-18\"></span>[35] Manuel Rigger and Zhendong Su. 2020. Finding\
    \ Bugs in Database Systems via Query Partitioning. Proc. ACM Program. Lang. 4,\
    \ OOPSLA, Article 211 (nov 2020), 30 pages.<https://doi.org/10.1145/3428279>\n\
    - <span id=\"page-11-12\"></span>[36] Manuel Rigger and Zhendong Su. 2020. Testing\
    \ Database Engines via Pivoted Query Synthesis. In Proceedings of the 14th USENIX\
    \ Conference on Operating Systems Design and Implementation (OSDI'20). USENIX\
    \ Association, USA, Article 38, 16 pages.\n- <span id=\"page-11-26\"></span>[37]\
    \ Dušan Rychnovský and Holubová. 2015. Generating XML Data for XPath Queries.\
    \ Association for Computing Machinery. (2015). [https://doi.org/10.1145/2695664.](https://doi.org/10.1145/2695664.2695691)\
    \ [2695691](https://doi.org/10.1145/2695664.2695691)\n- <span id=\"page-11-5\"\
    ></span>[38] Donald R. Slutz. 1998. Massive Stochastic Testing of SQL. In Proceedings\
    \ of the 24rd International Conference on Very Large Data Bases (VLDB '98). Morgan\
    \ Kaufmann Publishers Inc., San Francisco, CA, USA, 618–622.\n- <span id=\"page-11-9\"\
    ></span>[39] Thodoris Sotiropoulos, Stefanos Chaliasos, Vaggelis Atlidakis, Dimitris\
    \ Mitropoulos, and Diomidis Spinellis. 2021. Data-Oriented Differential Testing\
    \ of Object-Relational Mapping Systems. In 2021 IEEE/ACM 43rd International Conference\
    \ on Software Engineering (ICSE). 1535–1547. [https://doi.org/10.1109/ICSE43902.2021.](https://doi.org/10.1109/ICSE43902.2021.00137)\
    \ [00137](https://doi.org/10.1109/ICSE43902.2021.00137)\n- <span id=\"page-11-31\"\
    ></span>[40] Ting Su, Yichen Yan, Jue Wang, Jingling Sun, Yiheng Xiong, Geguang\
    \ Pu, Ke Wang, and Zhendong Su. 2021. Fully Automated Functional Fuzzing of Android\
    \ Apps for Detecting Non-Crashing Logic Bugs. Proc. ACM Program. Lang. 5, OOPSLA,\
    \ Article 156 (oct 2021), 31 pages.<https://doi.org/10.1145/3485533>\n- <span\
    \ id=\"page-11-4\"></span>[41] Milos Todic and Branislav Uzelac. 2012. Combined\
    \ XML/XQuery generator. Proceedings of the Fifth International Workshop on Testing\
    \ Database Systems (2012). <https://doi.org/10.1145/2304510.2304519>\n- <span\
    \ id=\"page-11-21\"></span>[42] Yuqing Wu, Namrata Lele, Rashmi Aroskar, Sharanya\
    \ Chinnusamy, and Sofia Brenes. 2009. XQGen: An Algebra-Based XPath Query Generator\
    \ for Micro-Benchmarking. In Proceedings of the 18th ACM Conference on Information\
    \ and Knowledge Management (Hong Kong, China) (CIKM '09). Association for Computing\
    \ Machinery, New York, NY, USA, 2109–2110. [https://doi.org/10.1145/1645953.](https://doi.org/10.1145/1645953.1646328)\
    \ [1646328](https://doi.org/10.1145/1645953.1646328)\n- <span id=\"page-11-6\"\
    ></span>[43] Xuejun Yang, Yang Chen, Eric Eide, and John Regehr. 2011. Finding\
    \ and Understanding Bugs in C Compilers. Association for Computing Machinery,\
    \ New York, NY, USA.<https://doi.org/10.1145/1993498.1993532>\n- <span id=\"page-11-10\"\
    ></span>[44] Hua Z, Lin W, Ren L, Li Z, Zhang L, Jiao W, and Xie T. 2023. GDsmith:\
    \ Detecting bugs in Cypher graph database engines. Proceedings of ACM SIG-SOFT\
    \ International Symposium on Software Testing and Analysis (2023). [https:](https://doi.org/10.48550/arXiv.2206.08530)\
    \ [//doi.org/10.48550/arXiv.2206.08530](https://doi.org/10.48550/arXiv.2206.08530)\n\
    - <span id=\"page-11-7\"></span>[45] Qirun Zhang, Chengnian Sun, and Zhendong\
    \ Su. 2017. Skeletal Program Enumeration for Rigorous Compiler Testing. In Proceedings\
    \ of the 38th ACM SIGPLAN Conference on Programming Language Design and Implementation\
    \ (Barcelona, Spain) (PLDI 2017). Association for Computing Machinery, New York,\
    \ NY, USA, 347–361.<https://doi.org/10.1145/3062341.3062379>\n- <span id=\"page-11-11\"\
    ></span>[46] Yingying Zheng, Wensheng Dou, Yicheng Wang, Zheng Qin, Lei Tang,\
    \ Yu Gao, Dong Wang, Wei Wang, and Jun Wei. 2022. Finding bugs in Gremlin-based\
    \ graph database systems via randomized differential testing. Proceedings of the\
    \ 31st ACM SIGSOFT International Symposium on Software Testing and Analysis (2022).\
    \ <https://doi.org/10.1145/3533767.3534409>\n- <span id=\"page-11-27\"></span>[47]\
    \ Rui Zhong, Yongheng Chen, Hong Hu, Hangfan Zhang, Wenke Lee, and Dinghao Wu.\
    \ 2020. Squirrel: Testing database management systems with language validity and\
    \ coverage feedback. In Proceedings of the 2020 ACM SIGSAC Conference on Computer\
    \ and Communications Security. 955–970."
- title: 'Code Review Automation: Strengths and Weaknesses of the State of the Art'
  abstract: 'The automation of code review has been tackled by several researchers
    with

    the goal of reducing its cost. The adoption of deep learning in software

    engineering pushed the automation to new boundaries, with techniques imitating

    developers in generative tasks, such as commenting on a code change as a

    reviewer would do or addressing a reviewer''s comment by modifying code. The

    performance of these techniques is usually assessed through quantitative

    metrics, e.g., the percentage of instances in the test set for which correct

    predictions are generated, leaving many open questions on the techniques''

    capabilities. For example, knowing that an approach is able to correctly

    address a reviewer''s comment in 10% of cases is of little value without knowing

    what was asked by the reviewer: What if in all successful cases the code change

    required to address the comment was just the removal of an empty line? In this

    paper we aim at characterizing the cases in which three code review automation

    techniques tend to succeed or fail in the two above-described tasks. The study

    has a strong qualitative focus, with ~105 man-hours of manual inspection

    invested in manually analyzing correct and wrong predictions generated by the

    three techniques, for a total of 2,291 inspected predictions. The output of

    this analysis are two taxonomies reporting, for each of the two tasks, the

    types of code changes on which the experimented techniques tend to succeed or

    to fail, pointing to areas for future work. A result of our manual analysis was

    also the identification of several issues in the datasets used to train and

    test the experimented techniques. Finally, we assess the importance of

    researching in techniques specialized for code review automation by comparing

    their performance with ChatGPT, a general purpose large language model, finding

    that ChatGPT struggles in commenting code as a human reviewer would do.'
  url: http://arxiv.org/abs/2401.05136v1
  keywords: '*—Automated code review, Empirical study'
  document: "# Code Review Automation: Strengths and Weaknesses of the State of the\
    \ Art\n\nRosalia Tufano, Ozren Dabic, Antonio Mastropaolo, Matteo Ciniselli, and\
    \ Gabriele Bavota ´\n\n**Abstract**—The automation of code review has been tackled\
    \ by several researchers with the goal of reducing its cost. The adoption of deep\
    \ learning in software engineering pushed the automation to new boundaries, with\
    \ techniques *imitating* developers in generative tasks, such as commenting on\
    \ a code change as a reviewer would do or addressing a reviewer's comment by modifying\
    \ code. The performance of these techniques is usually assessed through quantitative\
    \ metrics, *e.g.,* the percentage of instances in the test set for which correct\
    \ predictions are generated, leaving many open questions on the techniques' capabilities.\
    \ For example, knowing that an approach is able to correctly address a reviewer's\
    \ comment in 10% of cases is of little value without knowing what was asked by\
    \ the reviewer: What if in all successful cases the code change required to address\
    \ the comment was just the removal of an empty line? In this paper we aim at characterizing\
    \ the cases in which three code review automation techniques tend to succeed or\
    \ fail in the two above-described tasks. The study has a strong qualitative focus,\
    \ with ∼105 man-hours of manual inspection invested in manually analyzing correct\
    \ and wrong predictions generated by the three techniques, for a total of 2,291\
    \ inspected predictions. The output of this analysis are two taxonomies reporting,\
    \ for each of the two tasks, the types of code changes on which the experimented\
    \ techniques tend to succeed or to fail, pointing to areas for future work. A\
    \ result of our manual analysis was also the identification of several issues\
    \ in the datasets used to train and test the experimented techniques. Finally,\
    \ we assess the importance of researching in techniques specialized for code review\
    \ automation by comparing their performance with ChatGPT, a general purpose large\
    \ language model, finding that ChatGPT struggles in commenting code as a human\
    \ reviewer would do.\n\n✦\n\n**Index Terms**—Automated code review, Empirical\
    \ study\n\n# **1 INTRODUCTION**\n\nThe benefits of code review are well-known\
    \ and supported by empirical evidence [\\[8\\]](#page-13-0), [\\[9\\]](#page-13-1),\
    \ [\\[26\\]](#page-14-0), [\\[28\\]](#page-14-1), [\\[38\\]](#page-14-2). However,\
    \ works in the literature also documented the non-trivial costs of such a process\
    \ [\\[11\\]](#page-13-2), [\\[35\\]](#page-14-3), [\\[36\\]](#page-14-4). To bring\
    \ down such a cost, researchers proposed techniques to (partially) automate code\
    \ review tasks. Originally, most of the approaches aimed at recommending appropriate\
    \ reviewers for a given code change [\\[5\\]](#page-13-3), [\\[7\\]](#page-13-4),\
    \ [\\[19\\]](#page-13-5), [\\[20\\]](#page-13-6), [\\[27\\]](#page-14-5), [\\\
    [29\\]](#page-14-6), [\\[34\\]](#page-14-7), [\\[42\\]](#page-14-8), [\\[50\\\
    ]](#page-14-9), [\\[54\\]](#page-14-10), [\\[55\\]](#page-14-11). With the rise\
    \ of Deep Learning (DL) in software engineering, researchers started addressing\
    \ more challenging generative tasks aimed at *imitating* human developers. Two\
    \ concrete examples are the tasks automated by Tufano *et al.* [\\[47\\]](#page-14-12)[1](#page-0-0)\
    \ using a Transformer model. The first, named *code & comment-to-code*, aims at\
    \ automatically implementing a revised code (Cr) given the code submitted for\
    \ review (Cs) and a reviewer comment\n\n- *O. Dabi´c is with SEART @ Software\
    \ Institute, Università della Svizzera italiana, Switzerland.*\n- *E-mail: ozren.dabic@usi.ch*\
    \ • *A. Mastropaolo is with SEART @ Software Institute, Università della Svizzera\
    \ italiana, Switzerland.*\n- *E-mail: antonio.mastropaolo@usi.ch* • *M. Ciniselli\
    \ is with SEART @ Software Institute, Università della Svizzera*\n\n*italiana,\
    \ Switzerland. E-mail: matteo.ciniselli@usi.ch*\n\n• *G. Bavota is with SEART\
    \ @ Software Institute, Università della Svizzera italiana, Switzerland. E-mail:\
    \ gabriele.bavota@usi.ch*\n\n<span id=\"page-0-0\"></span>\n\n1. We refer to our\
    \ previous works in the area as Tufano *et al.* because the set of authors only\
    \ partially overlaps.\n\n(Rnl). Thus, the input of the approach is represented\
    \ by a pair ⟨Cs, Rnl⟩, while the output is Cr.\n\nThe second, named *code-to-comment*,\
    \ aims at commenting a code submitted for review as a reviewer would do: The input\
    \ of the approach is Cs, while the expected output is Rnl (*i.e.,* a natural language\
    \ comment asking for changes to Cs).\n\nThe work by Tufano *et al.* [\\[47\\]](#page-14-12)\
    \ is only the first of several focusing on automating one or both of these tasks\
    \ [\\[18\\]](#page-13-7), [\\[22\\]](#page-14-13), [\\[23\\]](#page-14-14), [\\\
    [47\\]](#page-14-12). These techniques have been evaluated on test sets containing\
    \ hundreds of instances representative of the automated tasks. For example, for\
    \ the *code & comment-tocode* task, the test sets feature ⟨Cs, Rnl⟩ pairs which\
    \ are fed to the approach to assess whether it can address the reviewer's comment\
    \ Rnl and generate the expected Cr. The outcome of these evaluations is a mostly\
    \ quantitative report showing, *e.g.,* the percentage of instances in the test\
    \ set for which the approach successfully generated a prediction. However, such\
    \ quantitative measures only tell part of the story. Indeed, it could happen that\
    \ the approach is targeting the *low-hanging fruits*, being successful in only\
    \ simple code review scenarios which are unlikely to save developers' time. For\
    \ the *code & comment-to-code* task this might mean successfully addressing mostly\
    \ comments requiring minor changes to C<sup>s</sup> (*e.g.,* addition/removal\
    \ of whitespaces to improve the formatting). Similarly, for the *code-to-comment*\
    \ task the approach could overfit and mostly be successful in posting comments\
    \ related to *e.g.,* replacing the == operator in Java with an equals invocation\
    \ when needed. In other words, little is known about the code review scenarios\
    \ in which these techniques succeed or fail.\n\nTo fill this gap, we manually\
    \ analyzed 2,291 predictions generated by three state-of-the-art techniques [\\\
    [18\\]](#page-13-7), [\\[23\\]](#page-14-14), [\\[47\\]](#page-14-12)\n\n<sup>•</sup>\
    \ *R. Tufano is with SEART @ Software Institute, Università della Svizzera italiana,\
    \ Switzerland. E-mail: rosalia.tufano@usi.ch*\n\nautomating the code review tasks\
    \ previously described. The predictions have been generated on the original test\
    \ sets used in the papers presenting the subject techniques.\n\nThe result of\
    \ such an analysis are two taxonomies (one per task) featuring a total of 120\
    \ types of code changes requested during code review (*e.g., extract method refactoring*,\
    \ *add thrown exception*) with indication about the extent to which stateof-the-art\
    \ techniques are successful in (i) requesting their implementation when needed\
    \ by properly commenting the submitted code as a human reviewer would do (*codeto-comment*\
    \ task); (ii) automatically implementing them to address a reviewer's comment\
    \ (*code & comment-to-code* task).\n\nWe found that the proposed techniques can\
    \ provide support in a wide variety of code changes. However, there are areas\
    \ of our taxonomies in which the approaches consistently fail, pointing to the\
    \ need for more research. As a concrete example, the experimented techniques struggle\
    \ when they need to recommend (*code-to-comment* task) or implement (*code & comment-to-code*\
    \ task) complex code changes spanning across several code components. This is\
    \ due to the \"view\" they have of the code base, usually limited to a single\
    \ function or diff hunk submitted for review. This indicates the need for enriching\
    \ the contextual information provided to these techniques.\n\nDuring our manual\
    \ analysis we also found that ∼25% of the instances in the inspected datasets\
    \ are the result of data extraction errors possibly undermining the techniques'\
    \ performance and questioning the validity of the evaluation performed on the\
    \ test set. We discuss the reasons for such problematic instances.\n\nFinally,\
    \ given the recent proposal of general purpose Large Language Models (LLMs) such\
    \ as ChatGPT [\\[1\\]](#page-13-8), it is unclear what the actual need is for\
    \ code review automation via specialized techniques. We compared the three subject\
    \ approaches with ChatGPT, showing that, while the latter represents a competitive\
    \ solution for the *code & comment-tocode* task, it suffers in the *code-to-comment*\
    \ task.\n\nWe release [\\[4\\]](#page-13-9) all data used in and output of our\
    \ study.\n\n# **2 RELATED WORK**\n\nMost of the works in code review automation\
    \ aim at recommending the most suited reviewer for a given change [\\[5\\]](#page-13-3),\
    \ [\\[7\\]](#page-13-4), [\\[12\\]](#page-13-10), [\\[19\\]](#page-13-5), [\\\
    [20\\]](#page-13-6), [\\[27\\]](#page-14-5), [\\[29\\]](#page-14-6), [\\[34\\\
    ]](#page-14-7), [\\[40\\]](#page-14-15), [\\[42\\]](#page-14-8), [\\[50\\]](#page-14-9),\
    \ [\\[51\\]](#page-14-16), [\\[52\\]](#page-14-17), [\\[54\\]](#page-14-10), [\\\
    [55\\]](#page-14-11). These works differ in the features and algorithms used for\
    \ the recommendation. Other techniques focus on the binary classification of the\
    \ quality of the code submitted for review (*i.e.,* whether the change should\
    \ be accepted or not) using machine [\\[12\\]](#page-13-10) or deep [\\[23\\]](#page-14-14),\
    \ [\\[39\\]](#page-14-18) learning. Our work is however mostly related to the\
    \ techniques aimed at *imitating* human reviewers by automatically reviewing the\
    \ submitted code. Thus, we focus our discussion on these techniques which are\
    \ summarized in Table [1.](#page-2-0)\n\nTufano M. *et al.* [\\[45\\]](#page-14-19)\
    \ proposed the usage of Neural Machine Translation (NMT) to learn how to automatically\
    \ modify a given Java method as developers would do during a pull request (PR):\
    \ The NMT model takes as input a method submitted in a PR and implements code\
    \ changes likely to be required during the review of the PR.\n\nTufano R. *et\
    \ al.* [\\[48\\]](#page-14-20) built on top of this idea by presenting two transformer-based\
    \ models to automate two code review tasks. The first, named *code-to-code*, is\
    \ a replica of the task automated by Tufano M. *et al.* [\\[45\\]](#page-14-19):\
    \ It takes as input a Java method submitted for review (Cs) and implements changes\
    \ likely to be required during code review, producing a revised method Cr. The\
    \ second is the already discussed *code & comment-to-code* task.\n\nBoth of the\
    \ aforementioned works suffered of a major limitation: They relied on a code abstraction\
    \ process to reduce the vocabulary size and simplify the learning of the DL models.\
    \ This means that the models did not work on raw code, but on an abstracted version\
    \ of it in which, for example, variable names were replaced with a VAR\\_ID token,\
    \ with ID being a progressive number going from 1 to n (n = number of variables\
    \ declared in the method). However, such an abstraction had a cost to pay, since\
    \ the models were not able to implement code changes requiring the introduction\
    \ of new identifiers and literals. To understand this point let us consider the\
    \ *code-to-code* task, in which the model takes as input a submitted method C<sup>s</sup>\
    \ and generates a revised method Cr. Both the input and the generated method are\
    \ abstracted. The abstraction process applied to C<sup>s</sup> allows to map each\
    \ identifier to its abstracted version. For example, it is possible to know that\
    \ a variable sum in C<sup>s</sup> has been mapped to VAR\\_1. Thus, if the generated\
    \ C<sup>r</sup> method features VAR\\_1, it can be mapped back to sum, making\
    \ C<sup>r</sup> understandable by the developer receiving such a recommendation.\
    \ Differently, if C<sup>r</sup> features a new identifier VAR\\_4 which was not\
    \ present in Cs, it is not possible to map it to raw code, making the recommendation\
    \ useless. For this reason, both of these works [\\[45\\]](#page-14-19), [\\[48\\\
    ]](#page-14-20) only automated very simple code review tasks, mostly requiring\
    \ re-arranging the code tokens in C<sup>s</sup> and avoiding the introduction\
    \ of new identifiers and literals.\n\nTo address this limitation, Tufano R. *et\
    \ al.* [\\[47\\]](#page-14-12) proposed a new approach which exploited the Text-To-Text\
    \ Transfer Transformer (T5) model [\\[33\\]](#page-14-21) and adopted a SentencePiece\
    \ tokenizer [\\[21\\]](#page-14-22), allowing the model to work with raw source\
    \ code by keeping under control the vocabulary size, avoiding the need for abstraction.\
    \ Besides reporting better performance as compared to their previous approach\
    \ [\\[48\\]](#page-14-20), this work is also the first one attempting the automation\
    \ of the *code-to-comment* task (*i.e.,* commenting the code to request changes\
    \ as a human reviewer would do).\n\nThongtanunam *et al.* [\\[41\\]](#page-14-23)\
    \ also used transformers to automate code review. They focused on the *code-to-code*\
    \ task, comparing with the original work by Tufano M. *et al.* [\\[45\\]](#page-14-19)\
    \ and showing the superiority of their approach.\n\nLi L. *et al.* [\\[22\\]](#page-14-13)\
    \ relied on pre-trained DL models to improve the performance achieved by Tufano\
    \ R. *et al.* [\\[47\\]](#page-14-12) on the *code & comment-to-code* and the\
    \ *code-to-comment* tasks. Hong *et al.* [\\[18\\]](#page-13-7) showed instead\
    \ that a simpler approach based on IR can achieve competitive performance as compared\
    \ to DL models when it comes to the *code-to-comment* task: Rather than generating\
    \ a reviewer's comment for a submitted Java method (as done by the DL-based techniques),\
    \ the approach by Hong *et al.* [\\[18\\]](#page-13-7) identifies in the \"training\
    \ set\" the method Cms being most similar to the C<sup>s</sup> submitted for review.\
    \ Based on this information, it retrieves review comments which have been posted\
    \ in the past for Cms, assuming they would be valuable for C<sup>s</sup> as well.\
    \ Both Li L. *et al.* [\\[22\\]](#page-14-13) and Hong *et al.* [\\[18\\]](#page-13-7)\
    \ show the superiority of their technique as compared to the approach by Tufano\
    \ R. *et al.* [\\[47\\]](#page-14-12).\n\nTABLE 1 Summary of related work. For\
    \ Li Z. *et al.* [\\[23\\]](#page-14-14) the size of the test set refers to Java\
    \ instances only.\n\n<span id=\"page-2-0\"></span>\n\n| Reference            \
    \    | Venue       | Task                                                    \
    \             | Granularity | Underlying<br>technique | # Training<br>instances\
    \    | # Test<br>instances   |\n|--------------------------|-------------|----------------------------------------------------------------------|-------------|-------------------------|----------------------------|-----------------------|\n\
    | Tufano M. et al. [45]    | ICSE'19     | code-to-code                      \
    \                                   | method      | NMT                     |\
    \ 8.6k                       | 1k                    |\n| Tufano R. et al. [48]\
    \    | ICSE'21     | code-to-code<br>code & comment-to-code                  \
    \             | method      | NMT                     | 13.7k                \
    \      | 1.7k                  |\n| Tufano R. et al. [47]    | ICSE'22     | code-to-code<br>code\
    \ & comment-to-code<br>code-to-comment            | method      | T5 (pre-trained)\
    \        | 134.2k                     | 16.7k                 |\n| Thongtanunam\
    \ et al. [41] | ICSE'22     | code-to-code                                   \
    \                      | method      | NMT                     | 118k        \
    \               | 14.7k                 |\n| Li L. et al. [22]        | ESEC/FSE'22\
    \ | code & comment-to-code<br>code-to-comment                            | method\
    \      | T5 (pre-trained)        | 87k                        | 1k           \
    \         |\n| Hong et al. [18]         | ESEC/FSE'22 | code-to-comment      \
    \                                                | method      | IR          \
    \            | 13.7k                      | 1.7k                  |\n| Li Z. et\
    \ al. [23]        | ESEC/FSE'22 | code & comment-to-code<br>code-to-comment<br>code\
    \ quality estimation | diff hunk   | T5 (pre-trained)        | 117.7k<br>150.4k<br>265.8k\
    \ | 2.2k<br>1.6k<br>66.4k |\n\nFinally, Li Z. *et al.* [\\[23\\]](#page-14-14)\
    \ targeted the automation of three code review tasks. The first among these represent\
    \ the binary classification of submitted code to decide whether it needs a review\
    \ or can be accepted as is. The other two tasks are *codeto-comment* and *code\
    \ & comment-to-code*. One aspect makes this work particularly novel as compared\
    \ to those previously discussed: While all previous techniques work at methodlevel\
    \ granularity (*i.e.,* they take as input a method submitted for review), the\
    \ approach by Li Z. *et al.* [\\[23\\]](#page-14-14) takes a \"diff hunk\", namely\
    \ an area of a specific file modified in a code change to be reviewed. This allows\
    \ the model to generate filelevel \"reviewers' comments\" such as those asking\
    \ changes to the import statements, which are ignored by previous techniques.\
    \ Given also its ability to work with code written in nine different programming\
    \ languages, this is currently considered the state-of-the-art technique.\n\n\
    # **3 STUDY DESIGN**\n\nThe *goal* of this study is to assess the capabilities\
    \ of state-ofthe-art techniques for code review automation. The *context* consists\
    \ of: (i) three techniques, *i.e.,* Tufano R. *et al.* [\\[47\\]](#page-14-12)\
    \ (T5CR), Li Z. *et al.* [\\[23\\]](#page-14-14) (CODEREVIEWER), and Hong *et\
    \ al.* [\\[18\\]](#page-13-7) (COMMENTFINDER); (ii) two code review tasks for\
    \ which the subject techniques provide automation, *i.e., code-to-comment* and\
    \ *code & comment-to-code*; and (iii) instances featured in the test datasets\
    \ on which the techniques have been evaluated in the papers presenting them. We\
    \ do not aim at comparing the performance of the three techniques to understand\
    \ which one is the best. Rather, we look at them as a whole to understand the\
    \ status of code review automation.\n\nWe address the following research questions\
    \ (RQs):\n\n**RQ**1**:** *What are the characteristics of correct and wrong recommendations\
    \ generated by techniques for code review automation?* We cluster the predictions\
    \ generated by the experimented techniques into two sets representing instances\
    \ for which the approaches generated a correct or a wrong prediction. Then, we\
    \ quantitatively compare these two sets. For the *code-to-comment* task we compare\
    \ the \"complexity\" of the comments to automatically generate (*i.e.,* those\
    \ present in the ground truth). Similarly, for the *code & comment-tocode* task,\
    \ we compare the \"complexity\" of the code changes\n\nto implement. Such an analysis\
    \ will shed some light on the extent to which the state-of-the-art techniques\
    \ overfit towards the low-hanging fruits of the datasets.\n\nOn top of this, we\
    \ qualitatively analyze 2,291 predictions generated by the three approaches (equally\
    \ distributed between correct and wrong predictions) to characterize the type\
    \ of code change they were able to request (*code-tocomment* task) or to automatically\
    \ implement (*code & commentto-code* task). The objective is to understand the\
    \ scenarios in which these techniques are successful *vs* those in which they\
    \ tend to fail. For example, if the outcome reveals that for the *code & comment-to-code*\
    \ task the techniques are mostly successful in implementing formatting changes,\
    \ but tend to fail when dealing with more challenging code changes (*e.g.,* fixing\
    \ a bug), this would question their usefulness.\n\n**RQ**2**:** *To what extent\
    \ are the datasets used to train and test techniques for code review automation\
    \ suitable for such a scope?* Through qualitative analysis we unveil the presence\
    \ of problematic instances in the datasets used in the subject studies, calling\
    \ for better dataset-cleaning pipelines.\n\n**RQ**3**:** *How do techniques for\
    \ code review automation proposed in the literature compare to state-of-the-art\
    \ large language models?* We compare the three subject techniques with ChatGPT\
    \ [\\[1\\]](#page-13-8) as representative of LLMs. Such a comparison informs the\
    \ need to further invest in automating code review through specialized models\
    \ rather than relying on general-purpose LLMs.\n\n#### **3.1 Study Context**\n\
    \nWe present the study context in terms of experimented techniques and datasets/predictions\
    \ we analyzed.\n\n#### <span id=\"page-2-1\"></span>*3.1.1 Techniques for Code\
    \ Review Automation*\n\nOur work focuses on techniques aimed at *imitating* human\
    \ reviewers, thus automating the *code-to-comment* and/or *code & comment-to-code*\
    \ task. Based on our analysis of the literature, five approaches target these\
    \ tasks: Tufano R. *et al.* [\\[48\\]](#page-14-20), T5CR [\\[47\\]](#page-14-12),\
    \ COMMENTFINDER [\\[18\\]](#page-13-7), CODEREVIEWER [\\[23\\]](#page-14-14),\
    \ and Li L. *et al.* [\\[22\\]](#page-14-13). Tufano R. *et al.* [\\[48\\]](#page-14-20)\
    \ has been excluded since in their followup work [\\[47\\]](#page-14-12) the authors\
    \ showed the superiority of the newly presented technique (T5CR) as compared to\
    \ their first attempt [\\[48\\]](#page-14-20) in automating code\n\nreview. Li\
    \ L. *et al.* [\\[22\\]](#page-14-13), instead, has been excluded after inspecting\
    \ the replication package shared by the authors: We rely on the authors' replication\
    \ packages to download (and then inspect) the predictions generated by their model\
    \ on the test set. The replication package for Li L. *et al.* [\\[22\\]](#page-14-13)\
    \ featured 987 predictions for the 1,055 instances in the test set, casting doubts\
    \ on the mapping between test instances and predictions. Also, 7 of these predictions\
    \ had one or more \"partial duplicate\" in the training set, meaning that the\
    \ training set featured the same code instance (*i.e.,* the same code for which\
    \ the technique had to automatically generate \"reviewer's comments\") of an entry\
    \ in the test set with a different target message. While this is not a problem\
    \ in principle, this plays a role in our qualitative evaluation, where we analyze\
    \ whether the comments generated by these techniques are semantically equivalent\
    \ to the expected one (despite they might use a different wording). Having the\
    \ same code instance in the training set allows the approach by Li L. *et al.*\
    \ [\\[22\\]](#page-14-13) to \"reuse\" the reviewer's comment from the training\
    \ set, thus generating something that, for sure, will be meaningful. For these\
    \ reasons we discarded this technique from our study. This left us with the three\
    \ techniques.\n\nFor the *code-to-comment* task, we consider predictions generated\
    \ by all three approaches with: T5CR [\\[47\\]](#page-14-12) being representative\
    \ of DL-based techniques working at methodlevel granularity and not considering\
    \ the code diff as an input; COMMENTFINDER [\\[18\\]](#page-13-7) being representative\
    \ of IRbased techniques also working at method-level granularity; and CODEREVIEWER\
    \ [\\[23\\]](#page-14-14) being representative of DL-based techniques working\
    \ at \"diff hunk\" granularity and considering the code diff as an input. For\
    \ the *code & comment-to-code* task we only consider T5CR and CODEREVIEWER, since\
    \ COMMENTFINDER does not provide support for such a task.\n\n#### *3.1.2 Datasets\
    \ and Predictions*\n\nFrom the replication packages of the three techniques [\\\
    [18\\]](#page-13-7), [\\[23\\]](#page-14-14), [\\[47\\]](#page-14-12) we collected\
    \ the test sets used for their evaluation and the corresponding predictions. The\
    \ size of the test datasets is reported in Table [1.](#page-2-0) There are two\
    \ main differences among the datasets. The first is in the representation of the\
    \ code submitted for review that is provided as input to the technique (Cs). While\
    \ for T5CR [\\[47\\]](#page-14-12) and COMMENTFINDER [\\[18\\]](#page-13-7) C<sup>s</sup>\
    \ is a Java method, for CODEREVIEWER [\\[23\\]](#page-14-14) is a diff hunk. The\
    \ second concerns the fact that T5CR and COMMENTFINDER only work with Java code,\
    \ while CODERE-VIEWER supports nine languages, including Java. In our study we\
    \ only considered Java instances for consistency and to simplify the following\
    \ described manual analysis.\n\n#### **3.2 Data Collection and Analysis**\n\n\
    ## *3.2.1 RQ*1*: Correct* vs *wrong recommendations*\n\nTo answer RQ<sup>1</sup>\
    \ the first step is to classify the predictions by the three approaches as correct\
    \ or wrong. We considered a prediction as correct if it represents an exact match\
    \ (EM) with the target (*i.e.,* the expected output). This means that for the\
    \ *code-to-comment* task the model generated a comment identical to the one written\
    \ by human reviewers, while for the *code & comment-to-code* task the model implemented\
    \ a code change required by the reviewer exactly as the human contributor did.\
    \ For each pair of technique and automated\n\ntask, such a process resulted in\
    \ the identification of the buckets of correct and wrong predictions reported\
    \ in Table [2](#page-4-0) (columns \"# correct (%)\" and \"# wrong (%)\"). While\
    \ the EM metric has been used in the evaluation of the three techniques, we acknowledge\
    \ that it has strong limitations, since it provides quite a strict definition\
    \ of correctness. For example, an automatically generated natural language comment\
    \ requesting the same code changes of the target comment with different wording\
    \ is considered wrong. While this undermines a purely quantitative assessment\
    \ of performance, in our study we use EM only as a mean to identify *candidate*\
    \ correct and wrong predictions. The predictions will undergo a manual analysis\
    \ which, for example, considers correct generated messages being semantically\
    \ equivalent to those posted by the human reviewers.\n\n**Qualitative Analysis.**\
    \ The goal of the manual analysis was to characterize the type of code change\
    \ the experimented techniques were (or were not) able to request (*code-to-comment*\
    \ task) or to automatically implement (*code & comment-to-code* task). For each\
    \ of the above-described buckets of correct and wrong predictions (as identified\
    \ via the EM analysis), we targeted the manual inspection of 167 valid instances,\
    \ corresponding to a statistically significant sample with at least a confidence\
    \ level of 99% and confidence interval of ±10% for each bucket. The target of\
    \ 167 instances was defined by computing a sample size (SS) calculation formula\
    \ [\\[37\\]](#page-14-24) on the bucket having the largest \"population\" (*i.e.,*\
    \ wrong predictions generated by T5CR for the *code-to-comment* task, with 16'426\
    \ instances):\n\n$$SS = \\frac{\\frac{z^2 \\times p(1-p)}{e^2}}{1 + \\left(\\\
    frac{z^2 \\times p(1-p)}{e^2 \\cdot N}\\right)}$$\n\nwhere p is the predicted\
    \ probability of the observation event to occur, set to 0.5 when not known a priori\
    \ (as in our case), N is the population size, e is the estimated margin of error\
    \ (±10%), z is the z-score for a given confidence level (in our case, 2.58 for\
    \ the 99% confidence). As it can be seen from the formula, the larger N, the larger\
    \ the sample size. Thus, using the largest \"population\" to compute the number\
    \ of instances to inspect is a conservative choice, ensuring even better confidence\
    \ when working on smaller buckets.\n\nWe use the term \"valid\" instances to account\
    \ for the following scenarios. First, when inspecting a prediction falling in\
    \ one of the *wrong* buckets it is possible that we realize that the prediction\
    \ is actually correct (*e.g.,* the comment generated/retrieved by the technique\
    \ uses different wording as compared to the target, but it is semantically equivalent).\
    \ In this case, while we inspected a *wrong* instance, it will actually fall into\
    \ the corresponding *correct* bucket. Second, we discarded several problematic\
    \ instances we found in the test sets of the experimented techniques. For example,\
    \ we found instances in the *code & comment-to-code* task for which, given the\
    \ input code as context, it was impossible even for a human to understand the\
    \ associated reviewer's comment (*i.e.,* what the reviewer was asking to change\
    \ in the input code). Indeed, the reviewer's comment referred to a wider context\
    \ (*e.g.,* parts of the code base not provided as input to the model), making\
    \ the prediction impossible for the automated technique. These are problematic\
    \ instances in the test set rather than failure cases of the technique, and we\
    \ document\n\n<span id=\"page-4-0\"></span>\n\n| Reference          | Task   \
    \              | # correct (%)  | # wrong (%)     | Inspected correct | Inspected\
    \ wrong | Valid correct | Valid wrong |\n|--------------------|----------------------|----------------|-----------------|-------------------|-----------------|---------------|-------------|\n\
    | T5CR [47]          | code&comment-to-code | 2'363 (14.08%) | 14'417 (85.92%)\
    \ | 178               | 272             | 199           | 167         |\n|   \
    \                 | code-to-comment      | 354 (2.11%)    | 16'426 (97.89%) |\
    \ 200               | 227             | 169           | 189         |\n| COMMENTFINDER\
    \ [18] | code-to-comment      | 479 (2.85%)    | 16'301 (97.15%) | 234       \
    \        | 254             | 169           | 176         |\n| CODEREVIEWER [23]\
    \  | code&comment-to-code | 599 (27.15%)   | 1'607 (72.85%)  | 197           \
    \    | 317             | 197           | 176         |\n|                    |\
    \ code-to-comment      | 0 (0%)         | 1'611 (100%)    | -                \
    \ | 412             | 50            | 179         |\n\nTABLE 2 Inspected instances\n\
    \nthem in RQ2. In summary, an instance was considered \"valid\" if, given the\
    \ input information (*i.e.,* C<sup>s</sup> for the *code-to-comment* task, and\
    \ ⟨Cs, Rnl⟩ for the *code & comment-to-code* task), it was possible for a human\
    \ to understand the rationale for the related output: For the *code-to-comment*\
    \ task, this means that the human evaluator was able to understand what the Rnl\
    \ comment to generate refers to (*i.e.,* what the problem in the submitted code\
    \ C<sup>s</sup> spotted by the reviewer is); for the *code & comment-to-code*\
    \ task, the evaluator considers an instance valid if the changes resulting in\
    \ the revised code C<sup>r</sup> to generate actually address the reviewer comment\
    \ Rnl posted for the submitted code Cs. The instances to inspect were randomly\
    \ selected from each bucket until the target number of valid instances was reached.\n\
    \nThe columns \"Inspected correct\" and \"Inspected wrong\" in Table [2](#page-4-0)\
    \ report, for each bucket, the number of instances we ended up manually inspecting\
    \ to reach our target of 167 valid instances per bucket. Overall, we inspected\
    \ 2,291 instances. Each instance has been independently inspected by two authors\
    \ (from now on, evaluators) who were tasked with classifying the type of change\
    \ to request (*code-to-comment*) or to implement (*code & comment-to-code*). Five\
    \ authors were involved in the manual analysis. On average, the authors have 13.4\
    \ years of programming experience (min=6) and 9.2 years of experience with Java\
    \ (min=5), the language used in the inspected datasets. One of them holds a PhD\
    \ in software engineering, and three more are currently pursuing a PhD in software\
    \ engineering. One is a software engineer.\n\nThe whole process was supported\
    \ by a web app we developed that implemented the required logic and provided a\
    \ handy interface to visualize the instance to label. For each instance, the evaluator\
    \ was presented with: (i) the input provided to the approach; (ii) the generated\
    \ prediction; and (iii) the expected output. As a result of the inspection, the\
    \ evaluator could classify the instance or discard it as nonvalid, providing an\
    \ explanation as to why it was discarded.\n\nThe classification required to assign\
    \ the instance one or more labels describing the change (*e.g., refactoring* →\
    \ *extract method*). Each evaluator was free to define their own label(s) (*i.e.,*\
    \ open coding procedure), as they felt it was needed to properly describe the\
    \ change: For this specific task, it was not possible to define upfront all possible\
    \ labels, making card sorting [\\[13\\]](#page-13-11) not suitable for our study.\
    \ Indeed, while there are taxonomies of issues identified during the code review\
    \ process [\\[10\\]](#page-13-12), [\\[24\\]](#page-14-25), [\\[32\\]](#page-14-26)\
    \ their abstraction level is not suitable for our goal. For example, the taxonomy\
    \ by Mäntylä *et al.* [\\[24\\]](#page-14-25) includes a category named *evolvability\
    \ defects* → *structure* which is too coarse grained to investigate the automation\
    \ capabilities of the subject techniques. To provide a concrete example, the taxonomy\
    \ depicting the types of changes that\n\nthe three techniques were (or were not)\
    \ able to automatically request in the *code-to-comment* task (Fig. [1\\)](#page-7-0)\
    \ we have an entire tree dedicated to the recommendation of refactoring operations\
    \ (which would fall under the *evolvability defects* → *structure* taxonomy from\
    \ [\\[24\\]](#page-14-25)). Our taxonomy includes concrete refactoring operations\
    \ (*e.g., Extract method*, *Change variable/constant type*), some of which are\
    \ successfully recommended by the experimented techniques, while others consistently\
    \ represent failing scenarios. The fine-grained nature of our taxonomy allows\
    \ to observe these differences.\n\nThe agreement among the authors was to define\
    \ each label in the form *parent* → *child*, where *parent* was a coarsegrained\
    \ description of the change while *child* was a more specific, fine-grained description.\
    \ New labels defined by an evaluator were made available in the web application\
    \ to the other evaluators. While this goes against the notion of open coding,\
    \ this allows to reduce the chance of multiple evaluators defining similar labels\
    \ to describe the same type of change while not substantially biasing the process.\
    \ The evaluator was also in charge of flagging instances in the wrong buckets\
    \ as \"actually correct\" in case they felt that the prediction, while different\
    \ from the target, was correct.\n\nThe manual evaluation was performed in three\
    \ rounds. A first round asked each evaluator to inspect 30 instances. This round\
    \ resulted in a set of labels that has been inspected by the authors with the\
    \ goal of merging similar labels and come up with a common strategy to categorize\
    \ the instances in the next rounds. Then, a second round was performed in which\
    \ the authors targeted the labeling of 30% of the overall instances assigned to\
    \ them. Again, such a round was followed by a further inspection of the defined\
    \ labels, with grouping of similar labels and further discussion on strategies\
    \ to improve agreement. The rationale for the number of instances to inspect in\
    \ each of the three rounds was the following. We wanted to label very few instances\
    \ in the first round (30) since we expected several inconsistencies in the way\
    \ in which the authors were going to perform the labeling and, thus, we targeted\
    \ a short dry run to test the adopted web application, the clarity of the overall\
    \ process and, at least in part, the type of labels assigned by the authors (*e.g.,*\
    \ their granularity). Then, we decided to follow with a larger second batch (30%)\
    \ which allowed to spot more corner cases worth to be discussed among the authors\
    \ (*e.g.,* instances for which an author was unsure about the type of label to\
    \ assign). Finally, since we felt that the labeling process was well-defined and\
    \ clarified among the authors, we decided to move on labeling the whole dataset.\
    \ Once all 2,291 instances have been inspected by two evaluators, we solved conflicts\
    \ that arose in 1,225 cases[2](#page-5-0) . Such a number may look high, since\
    \ it represents 53% of the inspected instances. However, the high rate of conflicts\
    \ is explained by three design decisions. First, we considered all conflicts,\
    \ also the ones resulting in the first and second round in which the set of possible\
    \ labels was not stable at all. Second, the labels in our study emerged from the\
    \ data and were not pre-defined. To get an idea of the complexity of this task\
    \ the whole process resulted in a total of 120 different labels. Third, we were\
    \ conservative in our definition of conflict, which occurred if: (i) two evaluators\
    \ assigned a different set of labels to the instance, even if the two sets partially\
    \ overlapped; (ii) two evaluators assigned the exact same set of labels to a *wrong*\
    \ instance with only one of the two reporting the instance as \"actually correct\"\
    ; (iii) only one of the two evaluators labeled the instance, while the other one\
    \ discarded it. Each conflict has been inspected by two additional authors, who\
    \ discussed and solved it.\n\nFinally, we used the assigned labels to build hierarchical\
    \ taxonomies showing the types of changes in which the three techniques tend to\
    \ succeed and fail for the two automated tasks. Such a process required additional\
    \ inspections of the considered instances. Indeed, once all categories in the\
    \ taxonomies have been defined, two of the authors rechecked that all instances\
    \ were assigned to the most proper category. Indeed, it is possible that a category\
    \ C added during the very last labeling round would be more suitable for instances\
    \ inspected at the very beginning of the manual process, when C was not available\
    \ (since no one came up with that label while inspecting the instance). This resulted\
    \ in the re-assignment of 16 instances (∼1%).\n\nThe final number of valid instances\
    \ (*i.e.,* non-discarded) within each bucket is reported in the columns \"Valid\
    \ correct\" and \"Valid wrong\" in Table [2.](#page-4-0) A few clarifications\
    \ are needed for values which are different from 167, which was our original target.\
    \ First, we did not have correct (EM) predictions generated by CODEREVIEWER [\\\
    [23\\]](#page-14-14) for the *code-to-comment* task. Thus, we applied the following\
    \ procedure to collect instances for the corresponding bucket. We selected among\
    \ the *wrong* predictions generated by CODEREVIEWER, the top-100 in terms of BLEU-4\
    \ (Bilingual Evaluation Understudy) score [\\[31\\]](#page-14-27). BLEU measures\
    \ how similar the candidate (predicted) and reference (oracle) comments are in\
    \ terms of overlapping 4-grams. A value of 1.0 indicates that the candidate and\
    \ the predicted comment are identical. The selected top-100 predictions have a\
    \ BLEU-4 ranging between 0.28 and 0.72.\n\nOur assumption is that *wrong* predictions\
    \ having a high BLEU score are likely to be correct, since they closely resemble\
    \ the target comment. During the manual analysis, we discarded the instances that\
    \ despite the high BLEU score, were actually wrong, since they did not belong\
    \ to the \"correct bucket\". This process led us to 50 valid instances in this\
    \ bucket, which is the only one being underrepresented (see Table [2\\)](#page-4-0).\
    \ Second, as it can be seen from Table [2,](#page-4-0) in several buckets we collected\
    \ more than the targeted 167 valid instances. This is due to the conflict resolution\
    \ phase in which some instances discarded by one of the two evaluators were considered\
    \ valid and re-introduced.\n\nThe output of this analysis are two taxonomies reporting,\n\
    \nfor each of the two tasks, the types of code changes on which the experimented\
    \ techniques tend to succeed or to fail.\n\n**Quantitative Analysis.** We contrast\
    \ the complexity of the test set instances resulting in correct and wrong predictions\
    \ of the experimented techniques. For the *code-to-comment* task, we used as proxy\
    \ for complexity the number of words featured in the comment to generate, under\
    \ the assumption that longer comments are likely more complex.\n\nFor the *code\
    \ & comment-to-code* task, we measure the number of AST-level changes required\
    \ to convert C<sup>s</sup> (*i.e.,* the code submitted for review) into C<sup>r</sup>\
    \ (*i.e.,* the revised code addressing the reviewer's comment). We expect a higher\
    \ number of changes to indicate a higher complexity of the comment to implement.\
    \ The AST-level changes have been extracted using Gumtree Spoon AST Diff [\\[14\\\
    ]](#page-13-13).\n\nFor the *code-to-comment* task, we used as proxy for complexity\
    \ (i) the number of words featured in the comment to generate, under the assumption\
    \ that longer comments are likely more complex, and (ii) the number of AST-level\
    \ changes required to address the reviewer's comment (as done for the *code &\
    \ comment-to-code* task). The latter was only computed for the predictions generated\
    \ by T5CR and by COMMENTFINDER, since for CODEREVIEWER we did not manage to retrieve\
    \ from the dataset the code implementing the required change, but only the submitted\
    \ code with the posted reviewer's comment.\n\nFor both tasks, we report boxplots\
    \ of the distribution of the complexity proxies for correct and wrong predictions\
    \ both overall and by approach. We also statistically compare the two distributions\
    \ assuming a significance level of 95% and using the Wilcoxon test [\\[49\\]](#page-14-28).\
    \ The Cliff's Delta (d) is used as effect size [\\[16\\]](#page-13-14), and it\
    \ is considered: negligible for |d| < 0.10, small for 0.10 ≤ |d| < 0.33, medium\
    \ for 0.33 ≤ |d| < 0.474, and large for |d| ≥ 0.474 [\\[16\\]](#page-13-14). We\
    \ adjust pvalues using Holm's correction procedure [\\[17\\]](#page-13-15). We\
    \ compare the complexity proxies only on the predictions we manually validated.\
    \ The reason is that, as explained, relying on EM to identify correct predictions\
    \ could lead to false negatives, thus invalidating our quantitative analysis.\n\
    \n## *3.2.2 RQ*2*: Datasets quality*\n\nThe datasets used to train and test the\
    \ experimented techniques have been automatically mined from GitHub. The authors\
    \ applied a number of heuristics to filter-out problematic instances. For example,\
    \ in the *code-to-comment* task efforts have been made to remove review comments\
    \ posted by bots. Similarly, in the *code & comment-to-code* task in which ⟨Cs,\
    \ Rnl⟩ → C<sup>r</sup> triplets are involved, checks are performed to make sure\
    \ that C<sup>r</sup> (the code which should implement the reviewer's comment Rnl)\
    \ is different from Cs. Indeed, C<sup>s</sup> = C<sup>r</sup> =⇒ Rnl not addressed.\n\
    \nDespite the effort in cleaning the datasets, in our manual analysis we found\
    \ ∼25% of the inspected instances representing noise in the datasets, posing questions\
    \ on the reliability of the evaluations reported in the literature. As previously\
    \ explained, when discarding an instance during the manual analysis the evaluators\
    \ had to report the reason why said instance was discarded. After such a process,\
    \ the five authors looked at the provided motivations and distilled them into\
    \ four main categories representing errors introduced during\n\n<span id=\"page-5-0\"\
    ></span><sup>2.</sup> Given the open nature of the coding, it was not possible\
    \ to compute a meaningful inter-rater agreement (*e.g.,* Cohen's kappa).\n\nthe\
    \ automated mining of the data from GitHub. We answer RQ2 by presenting statistics\
    \ summarizing such an analysis.\n\n## <span id=\"page-6-0\"></span>*3.2.3 RQ*3*:\
    \ Comparison with LLMs*\n\nWe assess the performance of ChatGPT [\\[1\\]](#page-13-8)\
    \ on the two tasks focus of our study. We limited the number of samples to 250\
    \ for ChatGPT, due to the high cost of running such an evaluation. Indeed, there\
    \ were two manual steps to perform. First, we needed to interact with the ChatGPT\
    \ GUI to manually prompt each instance on which we wanted to run ChatGPT. Based\
    \ on some tests we performed, we ended up selecting the following two prompts\
    \ for our tasks:\n\n*code-to-comment*: Write a code review of the following code\
    \ \"{inputCode}\".\n\n*code & comment-to-code*: Revise this code \"{inputCode}\"\
    \ given this comment \"{inputComment}\".\n\nIn the prompts {inputCode} and {inputComment}\
    \ represent the C<sup>s</sup> and Rnl, respectively, in the test datasets used\
    \ for the two tasks. The replies provided by ChatGPT when using these prompts\
    \ made it clear that it properly interpreted the task to perform.\n\nSecond, once\
    \ ChatGPT generates an answer, we cannot rely on EM to check if it is correct,\
    \ since ChatGPT has not been trained to generate answers in the same format used\
    \ in the test sets. For this reason we had to manually inspect the generated answers\
    \ to assess their correctness. Each generated answer was independently inspected\
    \ by two authors, who classified it as correct or wrong. For the *code-to-comment*\
    \ task we considered the code review generated by ChatGPT as correct if it contains\
    \ the target comment. For *code & commentto-code*, we verified whether ChatGPT\
    \ properly addressed the reviewer's comment, even with the coding solution being\
    \ different to the target one. Conflicts (*i.e.,* the two authors disagreed on\
    \ the correctness of ChatGPT's answer), which arose in 18% of cases, were solved\
    \ by a third author.\n\nFor the *code-to-comment* task we randomly selected 50\
    \ instances from the test set of each of the experimented techniques (150 instances\
    \ in total). The 50 instances included 25 correct (*i.e.,* the corresponding technique\
    \ generated a correct solution) and 25 wrong predictions. The same approach has\
    \ been used for the *code & comment-to-code* task which, however, is only automated\
    \ by two of the three subject techniques, thus resulting in 100 randomly selected\
    \ instances.\n\nWe answer RQ<sup>3</sup> by reporting the percentage of cases\
    \ in which ChatGPT was successful in both tasks. We also analyze the overlap between\
    \ the state-of-the-art techniques and ChatGPT by reporting the percentage of cases\
    \ in which (i) both succeed; (ii) at least one of the two succeeds; and (iii)\
    \ none of the two succeeds.\n\n# **4 RESULTS DISCUSSION**\n\nWe discuss the achieved\
    \ results by RQ. We use the icon to mark lessons learned and directions for future\
    \ work.\n\n## **4.1 RQ**1**: Correct** *vs* **wrong recommendations**\n\nFig.\
    \ [1](#page-7-0) and Fig. [2](#page-8-0) report the taxonomies of \"types of code\
    \ changes\" involved in the predictions generated by the subject techniques. Fig.\
    \ [1](#page-7-0) refers to the *code-to-comment* task, depicting types of changes\
    \ that the techniques were supposed to ask for in generated comments, as a human\
    \ reviewer would do. Fig. [2](#page-8-0) refers to the *code & comment-to-code*\
    \ task, reporting types of changes that the techniques were required to automatically\
    \ implement.\n\nThe taxonomies include several trees, each one representing a\
    \ generic set of code changes specified in the root category (*e.g., refactoring*,\
    \ *bug-fix*). The number on the topright corner of each label reports the number\
    \ of instances we manually assigned to that change type (*e.g.,* 503 refer to\
    \ *refactoring* in Fig. [1\\)](#page-7-0).\n\nThree clarifications are needed\
    \ on this point. First, one instance we analyzed (*i.e.,* a prediction generated\
    \ by an approach for a test entry) could have been assigned to multiple categories\
    \ since requiring multiple types of changes. Second, for readability reasons,\
    \ we decided to not report in the picture all categories of code changes that\
    \ have been assigned to less than ten instances. Indeed, it is difficult to draw\
    \ any conclusion with so few data points. The full data is available in our replication\
    \ package [\\[4\\]](#page-13-9).\n\nThird, being a hierarchical taxonomy, one\
    \ may expect the number of elements in a parent category to match the sum of the\
    \ number of elements in its child categories. However, this is not the case due\
    \ to two reasons. First, sometimes the parent category has been used as a label\
    \ when we did not manage to clearly identify the required code change, but only\
    \ its overall goal (*e.g.,* using *bug fix* → *fix wrong behavior* instead of\
    \ its child *modify if condition*). Second, as previously explained, we do not\
    \ depict in the taxonomies categories featuring less than 10 instances. However,\
    \ we still count their instances in the parent category (*e.g., refactoring* →\
    \ *renaming* has a *rename class* child which has not been depicted but contributes\
    \ with 6 instances).\n\nIn this scenario, the parent category has been used as\
    \ a label when we did not manage to clearly identify the required code change,\
    \ but only its overall goal (*i.e.,* fixing wrong behavior). This is another reason\
    \ why parent categories can have a higher counting than the sum of their child\
    \ categories.\n\nThe color assigned to each label reflects the ability of the\
    \ techniques to automate the code review task in the context of such a change\
    \ type. Since we manually analyzed ∼50% of correct and ∼50% of wrong predictions\
    \ generated by each approach, a success rate around 50% for a change type indicates\
    \ that the techniques do not tend to perform particularly well or bad for that\
    \ change type.\n\nIndeed, the goal of this analysis is to see if the correct (wrong)\
    \ predictions are polarized by specific categories. For these reasons, we defined\
    \ the color schema as follows:\n\nA gray label indicates a change type for which\
    \ the automation level aligns with what expected based on our sample of correct\
    \ and wrong predictions. Looking at Table [2](#page-4-0) it can be seen that,\
    \ for the *code-to-comment* task, we inspected a total of 388 correct and 544\
    \ wrong instances. Such an imbalance is due, as previously explained, to the CODEREVIEWER\
    \ technique which generated 0 EMs and for which we decided to manually inspect\
    \ 100 wrong predictions looking for actually correct ones (50 identified). This\
    \ means that we should expect an average performance per change type close to\
    \ (388\\*100)/(544+388)=42%. For this reason, Fig. [1](#page-7-0) features a grey\
    \ category if the techniques succeeded for such a change type in 32% to 52% of\
    \ cases (*i.e.,* 42% ± 10%). With\n\n![](_page_7_Figure_1.jpeg)\n\n<span id=\"\
    page-7-0\"></span>Fig. 1. Taxonomy of types of changes for the *code-to-comment*\
    \ task. The color assigned to each label reflects the ability of the techniques\
    \ to automate the code review task in the context of such a change type ( white\
    \ best, black worst). We report the percentage of successful predictions by each\
    \ approach for each change type as bars below the corresponding category: T5CR\
    \ (blue bar), CODEREVIEWER (green), and COMMENTFINDER (red).\n\na similar computation,\
    \ Fig. [2](#page-8-0) features a grey category if the techniques succeed in 43%\
    \ to 63% of cases (since an average of 53% correct predictions has been analyzed\
    \ per approach). Note that the \"± 10% choice\" has been done to simplify the\
    \ results discussion and visualization. We acknowledge that other choices are\
    \ possible (*e.g.,* ± 20%); raw data with exact percentages are available in our\
    \ replication package [\\[4\\]](#page-13-9).\n\nA black label indicates a change\
    \ type for which the automation tends to fail, thus in which the techniques are\
    \ struggling. This means a success rate lower than 32% for the *code-to-comment*\
    \ task, and lower than 43% for the *code & comment-to-code* task.\n\nA white label\
    \ indicates a change type for which the automation succeeds more than expected,\
    \ namely in at least 53% of cases for *code-to-comment* and 64% of cases for *code\
    \ & comment-to-code*.\n\nWhile this 3-level color schema represents the capabilities\
    \ of the experimented techniques as a whole, Fig. [1](#page-7-0) and Fig. [2](#page-8-0)\
    \ also report the percentage of successful predictions generated by each approach\
    \ for each change type as bars below the corresponding category. In Fig. [1](#page-7-0)\
    \ the three bars are ordered from top to bottom as: T5CR (blue bar), CODEREVIEWER\
    \ (green), and COMMENTFINDER (red). In Fig. [2](#page-8-0) the bars are only two,\
    \ corresponding to T5CR (blue) and CODEREVIEWER (green). An empty bar indicates\
    \ that the approach always failed for instances of that type. Instead, the filling\
    \ of the bar with a zig-zag pattern indicates that the manually inspected test\
    \ set entries on which the corresponding technique has\n\n![](_page_8_Figure_1.jpeg)\n\
    \n<span id=\"page-8-0\"></span>Fig. 2. Taxonomy of types of changes for the *code\
    \ & comment-to-code* task. The color assigned to each label reflects the ability\
    \ of the techniques to automate the code review task in the context of such a\
    \ change type ( white best, black worst). We report the percentage of successful\
    \ predictions by each approach for each change type as bars below the corresponding\
    \ category: T5CR (blue bar), CODEREVIEWER (green).\n\nbeen experimented did not\
    \ contain any instance of that type.\n\nOn top of the two taxonomies, Fig. [3](#page-9-0)\
    \ depicts the boxplots showing the computed \"complexity\" of the test instances\
    \ on which the experimented techniques succeed (blue) or fail (orange). We discuss\
    \ our qualitative and quantitative results by automated task.\n\n#### *4.1.1 Code-to-comment*\n\
    \nBefore looking at characteristics of correct and wrong predictions, Table [3](#page-8-1)\
    \ reports, for each approach and for each task, the percentage of non-EM predictions\
    \ that we classified as actually correct. As it can be seen, 21.83% of non-EM\
    \ predictions generated by CODEREVIEWER are actually correct for the *code-to-comment*\
    \ task. The percentage is smaller for the other two techniques for which we did\
    \ not focus the inspection on predictions having a high BLEU, but still non-negligible\
    \ (∼2.5%). For example, in the case of COMMENTFINDER the EM predictions are 2.85%\
    \ of the test set instances, while we found an additional 2.22% of non-EM predictions\
    \ which are actually correct, almost doubling the approach's correctness. A manual\
    \ analysis of (a sample of) non-EM predictions is needed to better assess the\
    \ capabilities of an automated technique. An example of non-EM generated by CODEREVIEWER\
    \ and being actually correct belongs to the *other* → *reuse existing code* category:\
    \ The target comment was \"Use IOUtils instead\", while CODEREVIEWER generated\
    \ the equivalent \"Can we use Guava's IOUtils here?\". This is a first important\
    \ outcome of our study: Using EM to assess the automation of the *code-to-comment*\
    \ task might be unfair.\n\nTABLE 3 Non-EM classified as correct during manual\
    \ analysis\n\n<span id=\"page-8-1\"></span>\n\n| Reference     | Task        \
    \                              | % correct non-EM |\n|---------------|-------------------------------------------|------------------|\n\
    | T5CR          | code & comment-to-code<br>code-to-comment | 15.66%<br>2.58%\
    \  |\n| COMMENTFINDER | code-to-comment                           | 2.22%    \
    \        |\n| CODEREVIEWER  | code & comment-to-code<br>code-to-comment | 17.37%<br>21.83%\
    \ |\n\nNot surprisingly the white categories (*i.e.,* the techniques tend to succeed)\
    \ are characterized by simple requests to include in the generated message, and\
    \ in particular the *removal/addition of a thrown exception*, and the *replacement\
    \ of an operator*. The excellent performance achieved in these change categories\
    \ are usually driven by the success of the COMMENTFINDER IR-based technique. The\
    \ latter has 100% accuracy in recommending the addition/removal of exceptions,\
    \ thanks to the retrieval from the training set of past reviewers' comments requiring\
    \ such a change for similar methods. Looking at the taxonomy, it is clear that\
    \ for code change types which are quite general, simple, and thus likely to be\
    \ requested over and over again in different code review instances (*e.g.,* the\
    \ addition/removal of exceptions, asking to *revert a code change*), an IR-based\
    \ approach can be a trump card. Differently, comments requiring the description\
    \ of more complex changes are challenging to retrieve or synthesize. The *refactoring*\
    \ tree provides interesting examples.\n\nSimple refactorings such as *changing\
    \ variable/constant*\n\n![](_page_9_Figure_1.jpeg)\n\n<span id=\"page-9-0\"></span>Fig.\
    \ 3. Task complexity for correct and wrong predictions\n\n*type* or *renaming\
    \ variable/constant* are overall well-supported (*e.g.,* COMMENTFINDER: \"qry\
    \ − > query\"). When it comes to refactorings involving complex code changes,\
    \ possibly impacting multiple code components, the techniques tend to fail. This\
    \ is the case for refactorings *extracting* or *moving* code elements. This is\
    \ likely due to the limited contextual information provided to code review automation\
    \ techniques. Among the experimented techniques, T5CR and COMMENTFINDER work at\
    \ method-level granularity, meaning that the method provided as input represents\
    \ everything the model knows about the system. Similarly, the \"view\" of CODEREVIEWER\
    \ is limited to a diff hunk. Such an issue does also affect the performance of\
    \ the techniques for apparently simple changes to require, such as those asking\
    \ to *change the method visibility*. Indeed, without additional knowledge of the\
    \ system it is difficult to judge what the correct visibility of a method should\
    \ be. Pushing the boundaries of code review automation for these types of changes\
    \ requires enriching the contextual information provided to the techniques, similarly\
    \ to what observed for other software engineering tasks [\\[43\\]](#page-14-29).\n\
    \nA negative exception in the refactoring tree is the *renaming of methods* which\
    \ one could expect to be on a similar level of difficulty as compared to the *renaming\
    \ of variable/constants* which is, instead, quite successful. We inspected these\
    \ instances and we noticed that, while renaming variables/constants may just require\
    \ a term expansion (as in the qry example previously reported), methods' names\
    \ are more expressive and challenging and, while the techniques are sometimes\
    \ able to capture the need for a renaming, they fail in recommending meaningful\
    \ alternatives.\n\nThe techniques also have a hard time automating logging activities,\
    \ especially when it comes to suggest the *introduction of a log statement* or\
    \ the need to *change the log level* (*e.g.,* from error to warning). Interestingly,\
    \ for both method renaming and recommendation of log-related changes, specialized\
    \ DLbased techniques have been proposed in the literature (see *e.g.,* Alon *et\
    \ al.* [\\[6\\]](#page-13-16) for renaming, and Mastropaolo *et al.* [\\[25\\\
    ]](#page-14-30) for logging). Based on the reported empirical evaluations, those\
    \ techniques proven to be quite effective in these tasks. For example, Mastropaolo\
    \ *et al.* [\\[25\\]](#page-14-30) presented LANCE, an approach able to correctly\
    \ recommend fixes to the level of log statements in 66% of cases. While the code\
    \ review automation techniques proposed in the literature target the automation\
    \ of generic code changes, the adoption of specialized techniques might be more\
    \ effective for specific change types. However, this might not be straightforward\
    \ to do in the context of the *code-to-comment* task. Indeed, assuming the will\
    \ to specialize a model for \"commenting\" on a\n\nspecific type of issue, the\
    \ first needed ingredient is a training dataset, which might not be easy to collect.\
    \ One may think to cluster reviewers' comments via lexical analysis and train\
    \ a specialized model on each of those clusters. Nevertheless, a trade-off between\
    \ cohesiveness of the clusters and availability of training data soon becomes\
    \ evident: very cohesive clusters will result in highly specialized models which,\
    \ however, are likely to benefit from very little training data (*e.g.,* only\
    \ a few instances in which a reviewer's comment is suggesting to introduce a log\
    \ statement). Larger clusters featuring more training data are instead unlikely\
    \ to specialize the model for specific types of recommendation, thus again pushing\
    \ it towards a generic recommender. A more promising approach might be to manually\
    \ define \"commenting patterns\" for a specific type of change (*i.e.,* a standard\
    \ sentence expressing the need for improving a certain aspect of the code, such\
    \ as introducing a log statement). In this case, the training dataset could be\
    \ built by parsing code changes performed during the change history of a project\
    \ (*e.g.,* commits introducing a new log statement), independently from the availability\
    \ of code review information for these changes. This implies the possibility to\
    \ reliably identifying code changes in which the target issue has been fixed.\
    \ For some of the \"black categories\" in our taxonomy this can be easily achieved\
    \ (*e.g.,* lack of log statement, need for changing the method visibility, etc.).\
    \ Others would require more advanced solutions, like the usage of tools to detect\
    \ refactoring operations [\\[44\\]](#page-14-31). Negative instances, *i.e.,*\
    \ code components on which the target issue does not manifest (*e.g.,* no need\
    \ to add log statements), might be needed as well. Once trained, specialized models\
    \ can be triggered on the code change submitted for review, reporting the improvement\
    \ recommendations (if any) to the developer.\n\nNot surprisingly, the experimented\
    \ techniques do not shine in recommending types of code changes which are likely\
    \ to be system-specific and, thus, difficult to learn/retrieve from other sources.\
    \ This is the case for the *performance optimizations* comments that the techniques\
    \ were required to emulate (*e.g.,* TARGET: \"We should use keyService here, intention\
    \ is to cache key temporary so under heavy load we don't download keys all the\
    \ time\"). A possible strategy to overcome this limitation could be to fine-tune\
    \ the techniques to a specific software project or, at least, to a set of projects\
    \ falling in the same domain (*e.g.,* DB engines). For example, after a pre-training\
    \ performed on generic code review data, a DL-based approach could be fine-tuned\
    \ to specifically support code review in a project. A major obstacle is the possible\
    \ lack of fine-tuning training data, since a single project is unlikely to provide\
    \ enough training instances. This may be partially overcome through data augmentation\
    \ techniques [\\[53\\]](#page-14-32).\n\nT5CR and COMMENTFINDER achieve good performance\
    \ when it comes to asking for *testing*-related changes, correctly generating\
    \ comments aimed at both improving the test coverage/logic (*e.g.,* T5CR: \"add\
    \ a check here to verify that the serialDataReceived method was not called\")\
    \ and cleaning/refining them, *e.g.,* T5CR suggested to replace an empty String\
    \ passed as parameter in an assert statement with an EMPTY\\_VALUE constant already\
    \ used in other statements of the test. In general, the changes to recommend in\
    \ the *testing* category are very specific and tend to focus on a single code\
    \ statement.\n\n Still, this shows the potential of these techniques as possible\
    \ \"refinement tools\" for approaches supporting the automated generation of test\
    \ cases [\\[15\\]](#page-13-17), [\\[30\\]](#page-14-33).\n\nFrom the quantitative\
    \ perspective, the boxplots in Fig. [3](#page-9-0) for the *code-to-comment* task\
    \ suggest, as expected, that the techniques tend to succeed in the generation\
    \ of simple reviewers' comments, having a median of 6 words composing them. As\
    \ a comparison, the failing cases are more than twice longer (in terms of median),\
    \ with 14 words. Such a trend holds, with minor differences, for all approaches.\
    \ Also, it is interesting to notice that, when considering all techniques together,\
    \ the first quartile of the wrong predictions is very close to the third quartile\
    \ of the correct predictions, indicating a strong difference between the two sets\
    \ that is confirmed by the statistical analysis with a p-value<0.001 accompanied\
    \ by a large effect size (test results in [\\[4\\]](#page-13-9)). Similar observations\
    \ can be drawn when using the AST changes required to implement the reviewer's\
    \ comment as a complexity proxy. Future work should focus on boosting performance\
    \ in these challenging scenarios, since the approaches seems to work pretty well\
    \ in the generation of simple comments (<20% of wrong predictions have less than\
    \ 6 words).\n\n#### *4.1.2 Code & comment-to-code*\n\nAlso for this task, we start\
    \ by observing the substantial percentage of non-EM predictions which are actually\
    \ correct — 15.66% for T5CR and 17.37% for CODEREVIEWER. This reinforces the need\
    \ for manual analysis when assessing the performance of techniques for code review\
    \ automation.\n\nThe taxonomy depicted in Fig. [2](#page-8-0) is smaller as compared\
    \ to the previous one, since a higher number of categories (91) count less than\
    \ 10 instances (for the full taxonomy see [\\[4\\]](#page-13-9)). It is interesting\
    \ to see some major differences as compared to the previous taxonomy. Changes\
    \ which were trivial to ask for in a comment to generate (*e.g.,* \"please revert\
    \ this change\") are challenging to automatically implement, as required in the\
    \ *code & comment-to-code* task. Indeed, the reverting may require several code\
    \ changes which are not necessarily easy to predict, especially if the full code\
    \ diff is not part of the information available to the model.\n\nInteresting is\
    \ the complementarity between the two techniques that support this task. T5CR\
    \ is very effective in changes related to *object design principles*, *e.g.,*\
    \ handling issues related to *encapsulation and scope* of variables/methods, which\
    \ usually require minor code changes. Also, T5CR works well in implementing changes\
    \ *ensuring adherence to the code base* in terms of *coding style*, *e.g.,* addressing\
    \ comments like \"String.isEmpty() is used in other places\" pointing to an inappropriate\
    \ if condition checking coverageId.length() == 0. CODEREVIEWER, instead, is the\
    \ only approach supporting documentation changes, and can achieve excellent performance\
    \ even for less-trivial code changes requiring *e.g.,* to *merge multiple code\
    \ statements* (in order to improve readability) or to migrate towards more appropriate\
    \ types (*refactoring* → *typing*). Considering that both techniques are built\
    \ on top of a transformerbased architecture, such a complementarity can be partially\
    \ explained by the different code representation they use, one looking at a single\
    \ method at a time (T5CR) and one taking a diff hunk into account (CODEREVIEWER),\
    \ possibly with a partial view of specific code components (*e.g.,* only the\n\
    \nchanged lines of a method are visible in the diff hunk). A hybrid representation\
    \ including both the full representation of the involved code entities and the\
    \ changed lines might help in getting the best of both worlds.\n\nAs expected,\
    \ both approaches are effective in the automation of very simple changes related\
    \ to *improve the formatting* of code (*e.g., add/remove parentheses*, *add/remove\
    \ white spaces*). The automation of these changes can be easily performed by a\
    \ code formatter (*e.g.,* [\\[3\\]](#page-13-18)), without the need for expensive\
    \ DL models. Such instances should be removed from the test sets used in the evaluation\
    \ of techniques automating the *code & comment-to-code* task, to avoid inflating\
    \ the percentage of EM predictions they generate.\n\nThe two techniques struggle\
    \ to automatically implement complex *bug-fixes* requiring major code changes\
    \ (*e.g., fix wrong behavior*) and/or changes to the code logic (*e.g., modify\
    \ if condition*). This result is inline with what observed for techniques specialized\
    \ in automated bug-fixing [\\[46\\]](#page-14-34), which also tend to be successful\
    \ in a minority of cases (usually <30%) confirming the need for more work in the\
    \ area.\n\nFinally, we want to comment on the performance of the two techniques\
    \ on the 87 types of code changes which are not represented in Figure 2, since\
    \ counting less than 10 instances each. Overall these 87 categories feature 132\
    \ of the predictions we inspected for the *code & comment-to-code* task.\n\nOut\
    \ of those, 69 (52%) were correct predictions, which matches the expected success\
    \ rate and seems to suggest that the two state-of-the-art techniques do not really\
    \ struggle in automatically implementing code changes which are likely to be less\
    \ represented in the training set. However, by inspecting the predictions in these\
    \ categories, we found out that a \"good\" level of performance (*i.e.,* ≥52%\
    \ correct predictions) is only obtained for 48% of these poorly represented categories\
    \ (*e.g.,* for 18 of them we observed 0% of correct predictions). It is thus possible\
    \ that, in some cases, the models learn from similar and related categories in\
    \ a sort of transfer learning fashion. For example, training on instances of the\
    \ well-represented category \"*remove unneeded statement*\" might have played\
    \ a role in achieving good performance on the five instances belonging to the\
    \ code change type \"*remove final modifier*\". However, given the low number\
    \ of instances in each of these categories (at most 9), we cannot draw any conclusion\
    \ based on these findings.\n\nThe results of the quantitative analysis (right\
    \ side of Fig. [3\\)](#page-9-0) show an interesting trend: while the correct\
    \ predictions by T5CR require substantially simpler changes as compared to the\
    \ wrong predictions (median of 2 AST changes *vs* 4, p-value < 0.001 with medium\
    \ effect size), this is not the case for CODEREVIEWER. Here the two sets are basically\
    \ equivalent in terms of code change complexity (negligible effect size). Looking\
    \ at the boxplots it is clear that T5CR tends to overfit to simpler changes, while\
    \ CODEREVIEWER, possibly thank to the diff hunk representation, is able to cope\
    \ with more complex code changes as well, supporting its status as state-of-the-art\
    \ approach.\n\n## **4.2 RQ**2**: Datasets quality**\n\nTable [4](#page-11-0) reports\
    \ the number of instances that we discarded as being problematic together with\
    \ the reason why they have been discarded. For the sake of space, we shortened\
    \ the *code*\n\nTABLE 4 Categories of discarded instances\n\n<span id=\"page-11-0\"\
    ></span>\n\n| #<br>Reason     |     | T5CR   |      | COMMENTFINDER | CODEREVIEWER\
    \ |      |\n|-----------------|-----|--------|------|---------------|--------------|------|\n\
    |                 |     | C&NL2C | C2NL | C2NL          | C&NL2C       | C2NL\
    \ |\n| Unclear comment | 281 | 32     | 55   | 97            | 57           |\
    \ 40   |\n| No change asked | 182 | 24     | 13   | 44            | 30       \
    \    | 71   |\n| Ignored comment | 74  | 25     | 0    | 0             | 49  \
    \         | 0    |\n| Wrong linking   | 16  | 1      | 0    | 1             |\
    \ 4            | 10   |\n| Other           | 16  | 2      | 1    | 1         \
    \    | 1            | 11   |\n\n*& comment-to-code* task as C&NL2C and the *code-to-comment*\
    \ as C2NL. While Table [4](#page-11-0) shows also the results by test set of each\
    \ technique, we focus the discussion on the overall trend (#). The \"Other\" category\
    \ contains 16 instances discarded for various but rare reasons, that we do not\
    \ discuss but document in [\\[4\\]](#page-13-9). The remaining \"discarding reasons\"\
    \ are sorted based on their frequency from top to bottom.\n\nFor 281 cases, we\
    \ assigned the *unclear comment* label to discard the instance since it was impossible\
    \ even for a human to understand what to implement (*code & comment-to-code*)\
    \ or what the target comment to generate was actually asking to the developer\
    \ (*code-to-comment*). For the *code & comment-tocode* task, this was due to the\
    \ limited contextual information provided to the model (*i.e.,* the input). For\
    \ the *code-to-comment* task, a recurring problem is again the lack of context\
    \ but, this time, related to the conversation that happened between the contributor\
    \ and the reviewer(s), which is not visible to the techniques. For example, a\
    \ comment saying \"ah, ok, that would be clearer\" is meaningless without knowing\
    \ the previous exchanged messages. As already observed in RQ1, increasing the\
    \ contextual information is a must to push the boundaries of code review automation.\n\
    \nIn 182 instances we inspected the reviewer's comment was not requesting any\
    \ change. For the *code & comment-tocode* task, this means that the approaches\
    \ could not really address the comment by modifying the code (*e.g.,* \"Awesome\
    \ work so far, Eli!\"). For the *code-to-comment* task this means training and\
    \ testing the technique for the generation of comments which are uninteresting\
    \ given the automation goal. Indeed, these techniques aim at generating comments\
    \ asking for code changes targeting the improvement of source code. Thus, comments\
    \ like \"I am not sure what GitHub wants to tell me with this icon here :)\" should\
    \ not be considered relevant for these approaches. The cleaning pipelines employed\
    \ in the works presenting the experimented techniques fail in filtering out those\
    \ meaningless instances.\n\nIn 74 cases (all related to the *code & comment-to-code*\
    \ task), while the reviewer's comment was asking for a change, the contributor\
    \ was changing the code but not to address the comment. These instances penalize\
    \ both the learning and the evaluation of the models. Indeed, even assuming that\
    \ the model correctly implements the change required by the reviewer, during training\
    \ the weights of the network will be revised to steer the prediction towards a\
    \ different (wrong) target and, during evaluation, any quantitative metric is\
    \ likely to point to a wrong prediction.\n\nFinally, 16 instances result from\
    \ errors while mining the dataset, since the code has been linked to a wrong code,\
    \ *e.g.,* \"there's no need for final in interfaces\" for an input code not being\
    \ an interface.\n\nWorth noticing is the overall number of discarded\n\nTABLE\
    \ 5 Manual analysis of ChatGPT predictions\n\n<span id=\"page-11-1\"></span>\n\
    \n|                                           | ËState-of-the-art |          \
    \  | éState-of-the-art |            |  |\n|-------------------------------------------|-------------------|------------|-------------------|------------|--|\n\
    | Task                                      | ËChatGPT          | éChatGPT   |\
    \ ËChatGPT          | éChatGPT   |  |\n| code & comment-to-code<br>code-to-comment\
    \ | 66%<br>19%        | 34%<br>81% | 44%<br>7%         | 56%<br>93% |  |\n\ninstances\
    \ (574) out of the 2,291 manually analyzed (25%). Since the test set is just a\
    \ random selection of 10% of data, we can assume a similar distribution in the\
    \ training sets of the subject techniques. Thus, all discussed instances have\
    \ the potential to hinder the training and bias the testing, since it is unreasonable\
    \ to expect them to result in a correct prediction given the target. Supervised\
    \ or unsupervised techniques aimed at removing these problematic instances are\
    \ needed to make a further step ahead on code review automation thanks to higher-quality\
    \ datasets.\n\n## **4.3 RQ**3**: State-of-the-art** *vs* **ChatGPT**\n\nTable\
    \ [5](#page-11-1) shows the results of the manual analysis assessing ChatGPT in\
    \ automating code review: For each task (rows) we report the percentage of cases\
    \ in which ChatGPT succeeds (Ë) or fail (é) for instances on which the state-of-theart\
    \ (SOTA) techniques were correct or wrong. Results are aggregated for the three\
    \ approaches, with raw data available in our replication package [\\[4\\]](#page-13-9).\n\
    \nChatGPT performs slightly better than the SOTA in the *code & comment-to-code*\
    \ task, being able to address the reviewer's comment in 55/100=55% of cases, as\
    \ compared to the 50% of the three techniques (we selected half instances on which\
    \ they work, and half on which they fail — see Section [3.2.3\\)](#page-6-0).\
    \ Interesting is the complementarity between ChatGPT and the SOTA: ChatGPT succeeds\
    \ in 44% of cases in which the SOTA techniques fail. These are mostly instances\
    \ in which the reviewer's comment provides little information about the change\
    \ to implement. For example, ChatGPT addressed a reviewer's comment pointing to\
    \ a \"*wrong formula*\" in the code (\"wrong formula\" is the full content of\
    \ the reviewer's comment) by applying the following change: forward \\* strikesLike.\
    \ get(i) + shiftOutput; → forward \\* Math.exp- (strikesLike.get(i)) + shiftOutput;.\
    \ This is a failing instance for the SOTA.\n\nConcerning the *code-to-comment*\
    \ task, ChatGPT succeeds in 19/150=13% of cases, being less performant than the\
    \ SOTA. Only 5 of those instances are failure cases for the SOTA. For this task\
    \ the output of ChatGPT is not a single comment (as for the SOTA techniques) but\
    \ a list of observations regarding the submitted code. In most of cases, we found\
    \ these comments to be meaningful, but they often miss or are in contrast with\
    \ the point raised by the human reviewer.\n\nThis is the case for an instance\
    \ in which the diff hunk reported a change from trace to info for the level of\
    \ a logging statement. While the reviewer complained about this change (and the\
    \ SOTA technique agreed with the human reviewer), ChatGPT was in favor of it,\
    \ commenting: \"*an info level logging statement would be more applicable*\").\n\
    \nSince there is evidence in the literature about the major role played by the\
    \ provided prompt on the output produced\n\nby large language models when dealing\
    \ with code-related tasks [**?**], we further investigated whether it is possible\
    \ to improve the performance of ChatGPT by exploiting different and more advanced\
    \ prompts. We took the failure cases of ChatGPT (*i.e.,* 131 cases for the *code-to-comment*\
    \ task and 45 cases for the *code & comment-to-code* task) and we provided them\
    \ again as input to ChatGPT, but with different promptings also exploiting information\
    \ from our taxonomy. In particular, our taxonomies feature five root categories\
    \ classifying the types of changes reviewers usually ask to implement in a code\
    \ review process: *Bug-Fixing*, *Object-Design Principles*, *Testing*, *Refactoring*,\
    \ *Logging*. On top of that there is the *Other* category grouping change types\
    \ which cannot be attributed to any of the five above categories. We use these\
    \ root categories to define two prompts (one for each of the two tasks), inspired\
    \ by the chain-of-thought prompting methodology [**?**] which has been successfully\
    \ applied in natural language processing:\n\n#### *code & comment-to-code* **task**\n\
    \nGiven this code \"{inputCode}\" and this comment \"{inputComment}\" and assuming\
    \ you are an expert developer:\n\n- 1) Identify/Classify the type of code changes\
    \ requested in the comment. Answer with one or more of the following:\n\t- Changes\
    \ have been required to refactor the code to improve its quality;\n\t- Changes\
    \ have been required since tests for this code must be written;\n\t- Changes have\
    \ been required to better align this code to good object-oriented design principles;\n\
    \t- Changes have been required to fix one or more bugs;\n\t- Changes have been\
    \ required to improve the logging of its execution;\n\t- Changes have been required\
    \ for other reasons not listed above.\n- 2) Implement the required code changes.\n\
    \n#### *code-to-comment* **task**\n\nGiven this code \"{inputCode}\" and assuming\
    \ you are an expert code reviewer:\n\n- 1) Decide whether the code needs to be\
    \ revised or not. Answer True or False.\n- 2) If the response to the above point\
    \ is True, then identify/classify the type of code change(s) required. Answer\
    \ with one or more of the following:\n\t- Changes are needed to refactor the code\
    \ to improve its quality;\n\t- Changes are needed since tests for this code must\
    \ be written;\n\t- Changes are needed to better align this code to good object-oriented\
    \ design principles;\n\t- Changes are needed to fix one or more bugs;\n\t- Changes\
    \ are needed to improve the logging of its execution;\n\t- Changes are needed\
    \ for other reasons not listed above.\n- 3) Write a code review (i.e., explain\
    \ the changes to be performed, if any) based on your answers to the questions\
    \ above.\n\n<span id=\"page-12-0\"></span>TABLE 6 Failure cases made successful\
    \ via more advanced prompting\n\n| Task                                      \
    \       | Prompt                          | ËChatGPT (%)               |\n|--------------------------------------------------|---------------------------------|----------------------------|\n\
    | code & comment-to-code<br>code & comment-to-code | Chain-of-Thought<br>Label-Aware\
    \ | 23/45 (51%)<br>25/45 (55%) |\n| code-to-comment                          \
    \        | Chain-of-Thought                | 13/131 (10%)               |\n\n\
    As it can be seen, both prompts guide the large language model towards the solution\
    \ of the task without, however, giving it any extra information besides what would\
    \ be available during the review process.\n\nAs for the *code & comment-to-code*\
    \ **task**, we also experimented an additional prompt, which classifies the reviewer's\
    \ comment into one of the categories in our taxonomies before asking the model\
    \ to automatically implement the code changes required to address the comment:\n\
    \nAssume you are an expert developer. Given this code \"{inputCode}\" implement\
    \ the code changes requested by a code reviewer in this comment \"{inputComment}\"\
    , considering that the change requested is asking to [category from our taxonomy\
    \ to which the comment has been manually assigned].\n\nFor example, assuming that\
    \ the assigned category in our taxonomy *logging*, the prompt will end with: considering\
    \ that the change requested is asking to improve the logging of its execution.\n\
    \nIn other words, we are simulating the scenario in which, besides providing a\
    \ comment explaining the change to perform, the reviewer also provides a label\
    \ classifying the type of code change required. Note that such a prompting cannot\
    \ be experimented in the *code-to-comment* task, since in that case the reviewer\
    \ comment is the output of the model rather than the input.\n\nAs previously done,\
    \ two authors independently assessed the correctness of ChatGPT output, and conflicts\
    \ have been solved by a third author. Table [6](#page-12-0) reports the achieved\
    \ results. For the *code & comment-to-code* task, depending on the used prompt,\
    \ we managed to make ChatGPT correctly predicting up to 25 of the previously identified\
    \ 45 failure cases. It is quite interesting to see that just providing the model\
    \ with an explicit label taken from our taxonomy and describing the type of change\
    \ required in the reviewer's comment substantially helps the model in correctly\
    \ implementing the required changes. As for the *code-to-comment* task, the chainof-thought\
    \ prompt helped the model only 13 of the 131 failure cases, confirming that generic\
    \ large language models not specifically trained for this task struggles in dealing\
    \ with it.\n\nFor completeness, we also provide in our replication package [\\\
    [4\\]](#page-13-9) two files mapping the ChatGPT success and failure cases to\
    \ categories in our taxonomy. We do not discuss the findings in terms of coverage\
    \ of the different categories in our taxonomy since the number of instances we\
    \ analyzed in RQ<sup>3</sup> is quite low, resulting in few data points for each\
    \ category (*i.e.,* it is difficult to judge whether CHatGPT works well for specific\
    \ code change types).\n\n# ChatGPT is a very competitive baseline for the *code\
    \ & comment-to-code* task, with prompting playing a major role in boosting the\
    \ model's performance. However, it is important to consider the fact that ChatGPT\
    \ may have seen the code addressing the reviewer's comment during training, questioning\
    \ the extent to which such a comparison is fair. When it comes to generating reviewers'\
    \ comments, SOTA techniques are superior, supporting the worth of further research\
    \ in this direction.\n\n# **5 THREATS TO VALIDITY**\n\n**Construct validity.**\
    \ In RQ<sup>1</sup> we classified the change type based on what was visible in\
    \ the test set instance. For example, we did not see the conversation between\
    \ the contributor and the reviewers, which could allow to better understand the\
    \ reviewers' requests. However, this was done by design to identify \"unclear\"\
    \ instances in RQ2.\n\nAlso, we considered the predictions of the three techniques\
    \ on the test sets used in the original papers presenting them. This means that\
    \ they have not been assessed on the same dataset. However, as previously explained,\
    \ our goal was not to compare the capabilities of the three approaches, but rather\
    \ to look at their strengths and weaknesses as representative of the state-of-the-art\
    \ in code review automation.\n\n**Internal validity.** There are possible subjectiveness\
    \ issues in the manual analyses. We mitigated this threat by always involving\
    \ multiple authors inspecting the same instance. Still, as for any manual process,\
    \ imprecisions are possible.\n\n**External validity.** In terms of studied techniques,\
    \ we considered all those focusing on the automation of the two targeted tasks;\
    \ we only excluded the approach by Li L. *et al.* [\\[22\\]](#page-14-13) for\
    \ the reasons explained in Section [3.1.1.](#page-2-1) All our RQs required manual\
    \ analysis, resulting in limitations on the number of data points collected. Given\
    \ the expense of the manual investigation, we targeted the inspection of a sample\
    \ of instances ensuring at least a confidence level of 99% and a confidence interval\
    \ of ±10% on each of the analyzed bucket of predictions. More conservative choices\
    \ (*e.g.,* 95%±5% confidence) would have required a much higher number of inspected\
    \ instances (more than twice). Replications are needed to corroborate/revise our\
    \ findings.\n\n# **6 CONCLUSION AND FUTURE WORK**\n\nWe assessed the capabilities\
    \ of three state-of-the-art techniques for code review automation [\\[18\\]](#page-13-7),\
    \ [\\[23\\]](#page-14-14), [\\[47\\]](#page-14-12). Differently from the mostly\
    \ quantitative evaluations available in the literature our study has a strong\
    \ qualitative focus. Our study disclosed the scenarios in which state-of-the-art\
    \ approaches tend to succeed and fail (RQ1) and identified major issues in the\
    \ quality of the datasets used for their training and evaluation (RQ2). Finally,\
    \ we showed that ChatGPT [\\[1\\]](#page-13-8), as representative of Large Language\
    \ Models, is a competitive technique for code review automation, but still struggles\
    \ in several scenarios, justifying the need for more research on models specialized\
    \ for such automation (RQ3).\n\nFuture work will focus on assessing (i) the usefulness\
    \ of code review automation from the practitioners' perspective, and (ii) the\
    \ code review automation opportunities offered by other state-of-the-practice\
    \ techniques (*e.g.,* Copilot [\\[2\\]](#page-13-19)).\n\n# **ACKNOWLEDGMENT**\n\
    \nWe acknowledge funding from the European Research Council (ERC) under the European\
    \ Union's Horizon 2020 research and innovation programme (agreement No. 851720).\n\
    \n# **REFERENCES**\n\n- <span id=\"page-13-8\"></span>[1] \"Chatgpt,\" [https://openai.com/blog/chatgpt,](https://openai.com/blog/chatgpt)\
    \ accessed: 2023-03- 27.\n- <span id=\"page-13-19\"></span>[2] \"Copilot website,\"\
    \ [https://copilot.github.com,](https://copilot.github.com) accessed: 2022-11-\
    \ 10.\n- <span id=\"page-13-18\"></span>[3] \"Prettier,\" [https://prettier.io,](https://prettier.io)\
    \ accessed: 2023-03-25.\n- <span id=\"page-13-9\"></span>[4] [\"https://github.com/CodeReviewAutomationSota/code\\\
    \\_](https://github.com/CodeReviewAutomationSota/code_review_automation_sota)\
    \ [review\\\\_automation\\\\_sota.](https://github.com/CodeReviewAutomationSota/code_review_automation_sota)\"\
    \n- <span id=\"page-13-3\"></span>[5] W. H. A. Al-Zubaidi, P. Thongtanunam, H.\
    \ K. Dam, C. Tantithamthavorn, and A. Ghose, \"Workload-aware reviewer recommendation\
    \ using a multi-objective search-based approach,\" in *16th ACM International\
    \ Conference on Predictive Models and Data Analytics in Software Engineering,\
    \ PROMISE*, 2020, pp. 21–30.\n- <span id=\"page-13-16\"></span>[6] U. Alon, M.\
    \ Zilberstein, O. Levy, and E. Yahav, \"Code2vec: Learning distributed representations\
    \ of code,\" *Proc. ACM Program. Lang.*, vol. 3, no. POPL, pp. 40:1–40:29, 2019.\n\
    - <span id=\"page-13-4\"></span>[7] S. Asthana, R. Kumar, R. Bhagwan, C. Bird,\
    \ C. Bansal, C. S. Maddila, S. Mehta, and B. Ashok, \"Whodo: Automating reviewer\
    \ suggestions at scale,\" in *27th ACM Joint Meeting on European Software Engineering\
    \ Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE*,\
    \ 2019, p. 937–945.\n- <span id=\"page-13-0\"></span>[8] A. Bacchelli and C. Bird,\
    \ \"Expectations, outcomes, and challenges of modern code review,\" in *Proceedings\
    \ of the 2013 international conference on software engineering*. IEEE Press, 2013,\
    \ pp. 712–721.\n- <span id=\"page-13-1\"></span>[9] G. Bavota and B. Russo, \"\
    Four eyes are better than two: On the impact of code reviews on software quality,\"\
    \ in *31th IEEE International Conference on Software Maintenance and Evolution,\
    \ ICSME*, 2015, pp. 81–90.\n- <span id=\"page-13-12\"></span>[10] M. Beller, A.\
    \ Bacchelli, A. Zaidman, and E. Juergens, \"Modern code reviews in open-source\
    \ projects: Which problems do they fix?\" in *11th IEEE/ACM Working Conference\
    \ on Mining Software Repositories, MSR*, 2014, pp. 202–211.\n- <span id=\"page-13-2\"\
    ></span>[11] A. Bosu and J. C. Carver, \"Impact of peer code review on peer impression\
    \ formation: A survey,\" in *7th IEEE/ACM International Symposium on Empirical\
    \ Software Engineering and Measurement, ESEM*, 2013, pp. 133–142.\n- <span id=\"\
    page-13-10\"></span>[12] M. Chouchen, A. Ouni, M. W. Mkaouer, R. G. Kula, and\
    \ K. Inoue, \"Whoreview: A multi-objective search-based approach for code reviewers\
    \ recommendation in modern code review,\" *Applied Soft Computing*, vol. 100,\
    \ p. 106908, 2021.\n- <span id=\"page-13-11\"></span>[13] A. Coxon, *Sorting Data:\
    \ Collection and Analysis*, ser. Quantitative Applications in the Social Sciences,\
    \ 1999, no. no. 127.\n- <span id=\"page-13-13\"></span>[14] J. Falleri, F. Morandat,\
    \ X. Blanc, M. Martinez, and M. Monperrus, \"Fine-grained and accurate source\
    \ code differencing,\" in *29th IEEE/ACM International Conference on Automated\
    \ Software Engineering, ASE*, 2014, pp. 313–324.\n- <span id=\"page-13-17\"></span>[15]\
    \ G. Fraser and A. Arcuri, \"Evosuite: automatic test suite generation for object-oriented\
    \ software,\" in *21st ACM Joint Meeting of the European Software Engineering\
    \ Conference and the ACM/SIGSOFT Symposium on the Foundations of Software Engineering,\
    \ ESEC-FSE*, 2011, pp. 416–419.\n- <span id=\"page-13-14\"></span>[16] R. J. Grissom\
    \ and J. J. Kim, *Effect sizes for research: A broad practical approach.*, 2005.\n\
    - <span id=\"page-13-15\"></span>[17] S. Holm, \"A simple sequentially rejective\
    \ bonferroni test procedure,\" *Scandinavian Journal on Statistics*, vol. 6, no.\
    \ 2, pp. 65–70, 1979.\n- <span id=\"page-13-7\"></span>[18] Y. Hong, C. Tantithamthavorn,\
    \ P. Thongtanunam, and A. Aleti, \"Commentfinder: A simpler, faster, more accurate\
    \ code review comments recommendation,\" in *30th ACM Joint European Software\
    \ Engineering Conference and Symposium on the Foundations of Software Engineering,\
    \ ESEC-FSE*, 2022, p. 507–519.\n- <span id=\"page-13-5\"></span>[19] J. Jiang,\
    \ D. Lo, J. Zheng, X. Xia, Y. Yang, and L. Zhang, \"Who should make decision on\
    \ this pull request? analyzing time-decaying relationships and file similarities\
    \ for integrator prediction,\" *J. Syst. Softw.*, vol. 154, no. C, p. 196–210,\
    \ 2019.\n- <span id=\"page-13-6\"></span>[20] J. Jiang, Y. Yang, J. He, X. Blanc,\
    \ and L. Zhang, \"Who should comment on this pull request? analyzing attributes\
    \ for more accurate commenter recommendation in pull-based development,\" *Inf.\
    \ Softw. Technol.*, vol. 84, no. C, p. 48–62, apr 2017. [Online]. Available:<https://doi.org/10.1016/j.infsof.2016.10.006>\n\
    - <span id=\"page-14-22\"></span>[21] T. Kudo and J. Richardson, \"Sentencepiece:\
    \ A simple and language independent subword tokenizer and detokenizer for neural\
    \ text processing,\" in *8th Conference on Empirical Methods in Natural Language\
    \ Processing, EMNLP*, 2018, pp. 66–71.\n- <span id=\"page-14-13\"></span>[22]\
    \ L. Li, L. Yang, H. Jiang, J. Yan, T. Luo, Z. Hua, G. Liang, and C. Zuo, \"Auger:\
    \ Automatically generating review comments with pretraining models,\" in *30th\
    \ ACM Joint European Software Engineering Conference and Symposium on the Foundations\
    \ of Software Engineering, ESEC/FSE*, 2022, p. 1009–1021.\n- <span id=\"page-14-14\"\
    ></span>[23] Z. Li, S. Lu, D. Guo, N. Duan, S. Jannu, G. Jenks, D. Majumder, J.\
    \ Green, A. Svyatkovskiy, S. Fu, and N. Sundaresan, \"Automating code review activities\
    \ by large-scale pre-training,\" in *30th ACM Joint European Software Engineering\
    \ Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE*,\
    \ 2022, pp. 1035–1047.\n- <span id=\"page-14-25\"></span>[24] M. V. Mäntylä and\
    \ C. Lassenius, \"What types of defects are really discovered in code reviews?\"\
    \ *IEEE Transactions on Software Engineering*, vol. 35, no. 3, pp. 430–448, 2009.\n\
    - <span id=\"page-14-30\"></span>[25] A. Mastropaolo, L. Pascarella, and G. Bavota,\
    \ \"Using deep learning to generate complete log statements,\" in *44th IEEE/ACM\
    \ International Conference on Software Engineering, ICSE*, 2022, pp. 2279–2290.\n\
    - <span id=\"page-14-0\"></span>[26] S. McIntosh, Y. Kamei, B. Adams, and A. E.\
    \ Hassan, \"The impact of code review coverage and code review participation on\
    \ software quality: A case study of the qt, vtk, and itk projects,\" in *11th\
    \ IEEE/ACM Working Conference on Mining Software Repositories, MSR*, 2014, pp.\
    \ 192–201.\n- <span id=\"page-14-5\"></span>[27] E. Mirsaeedi and P. C. Rigby,\
    \ \"Mitigating turnover with code review recommendation: Balancing expertise,\
    \ workload, and knowledge distribution,\" in *42nd ACM/IEEE International Conference\
    \ on Software Engineering, ICSE*, 2020, p. 1183–1195.\n- <span id=\"page-14-1\"\
    ></span>[28] R. Morales, S. McIntosh, and F. Khomh, \"Do code review practices\
    \ impact design quality? a case study of the qt, vtk, and itk projects,\" in *Proc.\
    \ of the 22nd Int'l Conf. on Software Analysis, Evolution, and Reengineering (SANER)*,\
    \ 2015, pp. 171–180.\n- <span id=\"page-14-6\"></span>[29] A. Ouni, R. G. Kula,\
    \ and K. Inoue, \"Search-based peer reviewers recommendation in modern code review,\"\
    \ in *32nd IEEE International Conference on Software Maintenance and Evolution,\
    \ ICSME*, 2016, pp. 367–377.\n- <span id=\"page-14-33\"></span>[30] C. Pacheco\
    \ and M. D. Ernst, \"Randoop: feedback-directed random testing for Java,\" in\
    \ *ACM/SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections\
    \ on Programming and Software, OOPSLA*, 2007, pp. 815–816.\n- <span id=\"page-14-27\"\
    ></span>[31] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu, \"Bleu: A method\
    \ for automatic evaluation of machine translation,\" in *40th Annual Meeting on\
    \ Association for Computational Linguistics, ACL*, 2002, pp. 311–318.\n- <span\
    \ id=\"page-14-26\"></span>[32] L. Pascarella, D. Spadini, F. Palomba, M. Bruntink,\
    \ and A. Bacchelli, \"Information needs in contemporary code review,\" vol. 2,\
    \ no. CSCW, 2018.\n- <span id=\"page-14-21\"></span>[33] C. Raffel, N. Shazeer,\
    \ A. Roberts, K. Lee, S. Narang, M. Matena, Y. Zhou, W. Li, and P. J. Liu, \"\
    Exploring the limits of transfer learning with a unified text-to-text transformer,\"\
    \ *J. Mach. Learn. Res.*, vol. 21, pp. 140:1–140:67, 2020.\n- <span id=\"page-14-7\"\
    ></span>[34] M. M. Rahman, C. K. Roy, and J. A. Collins, \"Correct: code reviewer\
    \ recommendation in github based on cross-project and technology experience,\"\
    \ in *38th International Conference on Software Engineering, ICSE*, 2016, pp.\
    \ 222–231.\n- <span id=\"page-14-3\"></span>[35] P. C. Rigby and C. Bird, \"Convergent\
    \ contemporary software peer review practices,\" in *21st ACM/SIGSOFT Joint Meeting\
    \ of the European Software Engineering Conference and the Symposium on the Foundations\
    \ of Software Engineering, ESEC-FSE*, 2013, pp. 202–212.\n- <span id=\"page-14-4\"\
    ></span>[36] P. C. Rigby, D. M. Germán, L. L. E. Cowen, and M. D. Storey, \"Peer\
    \ review on open-source software projects: Parameters, statistical models, and\
    \ theory,\" *ACM Trans. Softw. Eng. Methodol.*, vol. 23, no. 4, pp. 35:1–35:33,\
    \ 2014.\n- <span id=\"page-14-24\"></span>[37] B. Rosner, *Fundamentals of Biostatistics*,\
    \ 7th ed. Brooks/Cole, Boston, MA, 2011.\n- <span id=\"page-14-2\"></span>[38]\
    \ C. Sadowski, E. Söderberg, L. Church, M. Sipko, and A. Bacchelli, \"Modern code\
    \ review: a case study at google,\" in *40th International Conference on Software\
    \ Engineering: Software Engineering in Practice, ICSE (SEIP)*, 2018, pp. 181–190.\n\
    - <span id=\"page-14-18\"></span>[39] S. Shi, M. Li, D. Lo, F. Thung, and X. Huo,\
    \ \"Automatic code review by learning the revision of source code,\" in *The Thirty-Third\
    \ AAAI Conference on Artificial Intelligence, AAAI 2019*, 2019, pp. 4910–4917.\n\
    - <span id=\"page-14-15\"></span>[40] A. Strand, M. Gunnarson, R. Britto, and\
    \ M. Usman, \"Using a context-aware approach to recommend code reviewers: findings\
    \ from an industrial case study,\" in *42nd International Conference on Software\
    \ Engineering, Software Engineering in Practice, ICSE-SEIP*, 2020, pp. 1–10.\n\
    - <span id=\"page-14-23\"></span>[41] P. Thongtanunam, C. Pornprasit, and C. Tantithamthavorn,\
    \ \"Autotransform: Automated code transformation to support modern code review\
    \ process,\" in *2022 IEEE/ACM 44th International Conference on Software Engineering\
    \ (ICSE)*, 2022, pp. 237–248.\n- <span id=\"page-14-8\"></span>[42] P. Thongtanunam,\
    \ C. Tantithamthavorn, R. G. Kula, N. Yoshida, H. Iida, and K. Matsumoto, \"Who\
    \ should review my code? A file location-based code-reviewer recommendation approach\
    \ for modern code review,\" in *22nd IEEE International Conference on Software\
    \ Analysis, Evolution, and Reengineering, SANER*, 2015, pp. 141–150.\n- <span\
    \ id=\"page-14-29\"></span>[43] F. Tian and C. Treude, \"Adding context to source\
    \ code representations for deep learning,\" in *IEEE International Conference\
    \ on Software Maintenance and Evolution, ICSME*, 2022, pp. 374–378.\n- <span id=\"\
    page-14-31\"></span>[44] N. Tsantalis, A. Ketkar, and D. Dig, \"Refactoringminer\
    \ 2.0,\" *IEEE Trans. Software Eng.*, vol. 48, no. 3, pp. 930–950, 2022.\n- <span\
    \ id=\"page-14-19\"></span>[45] M. Tufano, J. Pantiuchina, C. Watson, G. Bavota,\
    \ and D. Poshyvanyk, \"On learning meaningful code changes via neural machine\
    \ translation,\" in *41st IEEE/ACM International Conference on Software Engineering,\
    \ ICSE*, 2019, pp. 25–36.\n- <span id=\"page-14-34\"></span>[46] M. Tufano, C.\
    \ Watson, G. Bavota, M. Di Penta, M. White, and D. Poshyvanyk, \"An empirical\
    \ study on learning bug-fixing patches in the wild via neural machine translation,\"\
    \ *ACM Trans. Softw. Eng. Methodol.*, vol. 28, no. 4, pp. 19:1–19:29, 2019.\n\
    - <span id=\"page-14-12\"></span>[47] R. Tufano, S. Masiero, A. Mastropaolo, L.\
    \ Pascarella, D. Poshyvanyk, and G. Bavota, \"Using pre-trained models to boost\
    \ code review automation,\" in *44th IEEE/ACM International Conference on Software\
    \ Engineering, ICSE*, 2022, pp. 2291–2302.\n- <span id=\"page-14-20\"></span>[48]\
    \ R. Tufano, L. Pascarella, M. Tufano, D. Poshyvanyk, and G. Bavota, \"Towards\
    \ automating code review activities,\" in *43rd IEEE/ACM International Conference\
    \ on Software Engineering, ICSE*, 2021, pp. 163– 174.\n- <span id=\"page-14-28\"\
    ></span>[49] F. Wilcoxon, \"Individual comparisons by ranking methods,\" *International\
    \ Biometric Society, Wiley*, vol. 1, no. 6, pp. 80–83, 1945.\n- <span id=\"page-14-9\"\
    ></span>[50] X. Xia, D. Lo, X. Wang, and X. Yang, \"Who should review this change?:\
    \ Putting text and file location analyses together for more accurate recommendations,\"\
    \ in *31th IEEE International Conference on Software Maintenance and Evolution,\
    \ ICSME*, 2015, pp. 261–270.\n- <span id=\"page-14-16\"></span>[51] Z. Xia, H.\
    \ Sun, J. Jiang, X. Wang, and X. Liu, \"A hybrid approach to code reviewer recommendation\
    \ with collaborative filtering,\" in *6th International Workshop on Software Mining,\
    \ SoftwareMining*, 2017, pp. 24–31.\n- <span id=\"page-14-17\"></span>[52] H.\
    \ Ying, L. Chen, T. Liang, and J. Wu, \"Earec: leveraging expertise and authority\
    \ for pull-request reviewer recommendation in github,\" in *3rd International\
    \ Workshop on CrowdSourcing in Software Engineering, CSI-SE@ICSE*, 2016, pp. 29–35.\n\
    - <span id=\"page-14-32\"></span>[53] S. Yu, T. Wang, and J. Wang, \"Data augmentation\
    \ by program transformation,\" *J. Syst. Softw.*, vol. 190, p. 111304, 2022.\n\
    - <span id=\"page-14-10\"></span>[54] Y. Yu, H. Wang, G. Yin, and T. Wang, \"\
    Reviewer recommendation for pull-requests in github: What can we learn from code\
    \ review and bug assignment?\" *Inf. Softw. Technol.*, vol. 74, pp. 204–218, 2016.\n\
    - <span id=\"page-14-11\"></span>[55] M. B. Zanjani, H. Kagdi, and C. Bird, \"\
    Automatically recommending peer reviewers in modern code review,\" *IEEE Transactions\
    \ on Software Engineering*, vol. 42, no. 6, pp. 530–543, 2016.\n\n#### JOURNAL\
    \ OF LATEX CLASS FILES, VOL. XX, NO. X, MONTH XXXX 16\n\n![](_page_15_Picture_1.jpeg)\n\
    \n**Rosalia Tufano** is a Ph.D student in the Faculty of Informatics at the Università\
    \ della Svizzera Italiana (USI), Switzerland, and part of the Software Analytics\
    \ Research Team (SEART). She received her MSc. in Applied Mathematics from Università\
    \ degli Studi di Napoli Federico II , Italy, in March 2019. Her research interests\
    \ mainly include the study and the application of machine learning techniques\
    \ to support code-related tasks. More information available at: [https://www.inf.usi.ch/](https://www.inf.usi.ch/phd/tufanr/)\
    \ [phd/tufanr/](https://www.inf.usi.ch/phd/tufanr/)\n\n![](_page_15_Picture_3.jpeg)\n\
    \n**Matteo Ciniselli** is a Ph.D. student in the Faculty of Informatics at the\
    \ Università della Svizzera Italiana (USI), Switzerland. He received his MSc.\
    \ in Mathematical Engineering from Politecnico di Milano, Italy, in April 2015.\
    \ His research interests mainly include the study of deep-learning models to improve\
    \ the performances of coderelated tasks. More information available at: [https:](https://www.inf.usi.ch/phd/cinism/)\
    \ [//www.inf.usi.ch/phd/cinism/](https://www.inf.usi.ch/phd/cinism/)\n\n![](_page_15_Picture_5.jpeg)\n\
    \n**Ozren Dabic´** is a Research Assistant and Software Engineer for the Software\
    \ Analytics Research Team (SEART) of the Software Institute in Lugano. As a Full\
    \ Stack Developer, his work primarily revolves around creating software solutions\
    \ and web platforms for academia, intended to streamline the research process.\
    \ He also participates in research focusing on the usage of Deep Learning models\
    \ to automate various software engineering tasks.\n\n![](_page_15_Picture_7.jpeg)\n\
    \n**Gabriele Bavota** is an associate professor at the Faculty of Informatics\
    \ of the Università della Svizzera italiana (USI), Switzerland, where he is part\
    \ of the Software Institute and he leads the SEART research group. He received\
    \ the PhD in Computer Science from the University of Salerno, Italy, in 2013.\
    \ His research interests include software maintenance and evolution, code quality,\
    \ mining software repositories, and empirical software engineering. On these topics,\
    \ he authored over 150 papers appeared\n\n![](_page_15_Picture_9.jpeg)\n\n**Antonio\
    \ Mastropaolo** is a Ph.D. student in the Faculty of Informatics at the Università\
    \ della Svizzera italiana (USI), Switzerland, where he is part of the Software\
    \ Institute. He received his MSc. in Software System Security from Università\
    \ degli studi del Molise, Italy, in July 2020. His research interests include\
    \ the study and the application of deep-learning techniques to foster code-related\
    \ tasks. More information available at: [https://antoniomastropaolo.com.](https://antoniomastropaolo.com)\n\
    \nin international journals and conferences and has received four ACM Sigsoft\
    \ Distinguished Paper awards at the three top software engineering conferences:\
    \ ASE 2013 and 2017, ESEC-FSE 2015, and ICSE 2015. He also received the best/distinguished\
    \ paper award at SCAM 2012, ICSME 2018, MSR 2019, and ICPC 2020. He is the recipient\
    \ of the 2018 ACM Sigsoft Early Career Researcher Award for outstanding contributions\
    \ in the area of software engineering as an early career investigator and the\
    \ principal investigator of the DEVINTA ERC project. More information is available\
    \ at: [https://www.inf.usi.ch/faculty/bavota/.](https://www.inf.usi.ch/faculty/bavota/)"
- title: 'MicroFuzz: An Efficient Fuzzing Framework for Microservices'
  abstract: 'This paper presents a novel fuzzing framework, called MicroFuzz, specifically

    designed for Microservices. Mocking-Assisted Seed Execution, Distributed

    Tracing, Seed Refresh and Pipeline Parallelism approaches are adopted to

    address the environmental complexities and dynamics of Microservices and

    improve the efficiency of fuzzing. MicroFuzz has been successfully implemented

    and deployed in Ant Group, a prominent FinTech company. Its performance has

    been evaluated in three distinct industrial scenarios: normalized fuzzing,

    iteration testing, and taint verification.Throughout five months of operation,

    MicroFuzz has diligently analyzed a substantial codebase, consisting of 261

    Apps with over 74.6 million lines of code (LOC). The framework''s effectiveness

    is evident in its detection of 5,718 potential quality or security risks, with

    1,764 of them confirmed and fixed as actual security threats by software

    specialists. Moreover, MicroFuzz significantly increased program coverage by

    12.24% and detected program behavior by 38.42% in the iteration testing.'
  url: http://arxiv.org/abs/2401.05529v1
  keywords: ''
  document: '# MicroFuzz: An Efficient Fuzzing Framework for Microservices


    Peng Di Ant Group Hangzhou, China dipeng.dp@antgroup.com


    Bingchang Liu Ant Group Beijing, China bingchang.lbc@antgroup.com


    Yiyi Gao Ant Group Hangzhou, China gaoyiyi.gyy@antgroup.com


    ## ABSTRACT


    Fuzzing is a widely adopted technique in the software industry to enhance security
    and software quality. However, most existing fuzzers are specifically designed
    for monolithic software architectures and face significant limitations when it
    comes to serving distributed Microservices applications (Apps). These limitations
    primarily revolve around issues of inconsistency, communication, and applicability
    which arise due to the differences in monolithic and distributed software architecture.


    This paper presents a novel fuzzing framework, called Micro-Fuzz, specifically
    designed for Microservices. Mocking-Assisted Seed Execution, Distributed Tracing,
    Seed Refresh and Pipeline Parallelism approaches are adopted to address the environmental
    complexities and dynamics of Microservices and improve the efficiency of fuzzing.
    MicroFuzz has been successfully implemented and deployed in AntGroup [1](#page-0-0)
    , a prominent FinTech company. Its performance has been evaluated in three distinct
    industrial scenarios: normalized fuzzing, iteration testing, and taint verification.


    Throughout five months of operation, MicroFuzz has diligently analyzed a substantial
    codebase, consisting of 261 Apps with over 74.6 million lines of code (LOC). The
    framework''s effectiveness is evident in its detection of 5,718 potential quality
    or security risks, with 1,764 of them confirmed and fixed as actual security threats
    by software specialists. Moreover, MicroFuzz significantly increased line coverage
    by 12.24% and detected new paths by 38.42% in the iteration testing.


    #### ACM Reference Format:


    Peng Di, Bingchang Liu, and Yiyi Gao. 2024. MicroFuzz: An Efficient Fuzzing Framework
    for Microservices. In 46th International Conference on Software Engineering: Software
    Engineering in Practice (ICSE-SEIP ''24), April 14–20, 2024, Lisbon, Portugal.
    ACM, New York, NY, USA, [12](#page-11-0) pages. <https://doi.org/10.1145/3639477.3639723>


    ### <span id="page-0-0"></span>1 INTRODUCTION


    Fuzzing is a widely adopted technique in the software industry to enhance security
    and ensure software quality. Several fuzzers such as AFL [\[49\]](#page-11-1),
    libFuzzer [\[31\]](#page-10-0), honggfuzz [\[18\]](#page-10-1) and their extensions
    [\[7,](#page-10-2) [8,](#page-10-3) [16,](#page-10-4) [27,](#page-10-5) [30,](#page-10-6)
    [38\]](#page-10-7) have successfully uncovered numerous bugs in both open-source
    and commercial programs [\[19\]](#page-10-8). However, the existing fuzzers primarily
    focus on monolithic software


    ICSE-SEIP ''24, April 14–20, 2024, Lisbon, Portugal


    © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.
    ACM ISBN 979-8-4007-0501-4/24/04. . . \$15.00 <https://doi.org/10.1145/3639477.3639723>


    wherein the program''s components or functions are tightly coupled. They are not
    readily applicable to fuzzing Microservices software, which has emerged as one
    of the most popular software architectures in the industry [\[35,](#page-10-9)
    [46\]](#page-11-2). The adaptation of fuzzing techniques for microservices faces
    obstacles due to the differences between monolithic and distributed software architectures
    [\[10,](#page-10-10) [43,](#page-11-3) [51,](#page-11-4) [52\]](#page-11-5).


    Inconsistency. Existing fuzzers struggle to adapt to the intricate Microservices
    in the industry, primarily due to their inability to address Microservices'' inconsistency
    issue that refers to the execution paths that are not repeated or predictable.
    The inconsistency arises from the unpredictable runtime logic of Microservice
    frameworks [\[3\]](#page-10-11). Additionally, the independent development and
    redeployment of Microservice Applications (abbr. Apps) can result in temporary
    failures in cross-App invocations [\[55\]](#page-11-6). These factors contribute
    to the inconsistency observed in Microservices, posing a challenge for enabling
    existing fuzzers in Microservices.


    Communication. Given that Microservice Apps are often deployed separately in different
    containers, the communication overhead between the target Apps and the fuzzer
    is essential for efficiency [\[35,](#page-10-9) [46\]](#page-11-2). Traditional
    fuzzers often overlook the network consumption considerations specific to Microservices.
    Coordinating different fuzzing components and hiding the substantial time delay
    caused by such architectural disparities remains a daunting and challenge task
    for Microservice fuzzers.


    Applicability. Existing fuzzers fail to meet the cost requirements associated
    with the extensive code bases prevalent in the industry. For instance, the Microservices
    software in AntGroup <sup>1</sup> comprises more than 3,000 Microservices Apps
    and encompasses hundreds of millions of lines of code. To minimize the cost of
    fuzzing, it is crucial to determine when to terminate the fuzzing process across
    thousands of Apps and assess the impact of termination on fuzzing effectiveness.


    In this paper, we introduce MicroFuzz, a novel fuzzing framework specifically
    designed and implemented to tackle the challenges associated with Microservices
    architecture. For Inconsistency, we overcome the oracles of environmental complexities
    and dynamics using Mocking-Assisted Seed Execution and Seed Refresh techniques,
    and propose a Microservice testing harness by virtue of the above two and Distributed
    Tracing techniques. To address Communication, we decouple different fuzzing components,
    making each of them parallel work in pipelines, to mitigate the low efficiency
    caused by the across-App network communication in Microservice software. Besides,
    for Applicability, we utilized the ecological idea of the study [\[6\]](#page-10-12)
    to fuzz the industrial-level Microservice software, greatly saving the CPU consumption,
    and make our Microservice fuzzing framework cut out for large-scale industrial
    scenarios: we take Iteration Testing and Taint Verification, two important software


    Permission to make digital or hard copies of all or part of this work for personal
    or classroom use is granted without fee provided that copies are not made or distributed
    for profit or commercial advantage and that copies bear this notice and the full
    citation on the first page. Copyrights for components of this work owned by others
    than the author(s) must be honored. Abstracting with credit is permitted. To copy
    otherwise, or republish, to post on servers or to redistribute to lists, requires
    prior specific permission and/or a fee. Request permissions from permissions@acm.org.


    <sup>1</sup>AntGroup is a prominent FinTech company that serves billions of users
    worldwide and processes 1 million user requests per minute on average.


    quality assurance processes used in enterprises, as examples to demonstrate MicroFuzz''s
    applicability in industrial fields.


    We successfully deployed MicroFuzz in AntGroup to evaluate a total of 261 representative
    Apps from a pool of over 3,000 Microservice Apps. These Apps spanned various business
    domains, including e-commerce, insurance, and investments, and encompassed commonly
    used Apps such as account, trade, and payment. These Apps generated significant
    traffic and had substantial representations within the FinTech Microservices.
    Over five months, MicroFuzz uncovered 5,718 potential security risks, out of which
    1,764 risks were confirmed through internal cybersecurity exercises, highlighting
    the effectiveness of the tool in identifying genuine vulnerabilities. Furthermore,
    MicroFuzz significantly increased line coverage by an average of 12.24% across
    the tested applications. MicroFuzz also enhanced the richness of testing in the
    Iteration Testing scenario by 38.42% more program paths.


    In summary, we make the following contributions:


    - We have developed an innovative fuzzing framework called MicroFuzz specifically
    designed for Microservices Software. Our framework, MicroFuzz, is tailored to
    effectively and efficiently fuzz Microservice software deployed in cloud environments.

    - We have employed the Mocking-Assisted Seed Execution, Distributed Tracing and
    Seed Refresh techniques to tackle the complexities and dynamics of Microservice
    software and facilitate Microservice fuzzing. Furthermore, we have leveraged Pipeline
    Parallelism to decouple fuzzer components and improve the overall efficiency of
    Microservice fuzzing.

    - MicroFuzz has been successfully deployed at AntGroup and utilized for evaluating
    hundreds of Microservices Apps. Over five months, it has effectively identified
    and confirmed 1,764 quality issues and security threats, resulting in significant
    improvements to program coverage with an average increase of 12.24%. Moreover,
    MicroFuzz provides support for various program assurance processes, as it exhibits
    38.42% more program paths in the iteration testing scenario.


    ### 2 BACKGROUND


    In this section, we describe some key features of Microservices and some challenges
    posed by these features to fuzzing.


    ### 2.1 Microservices


    Microservices [\[35,](#page-10-9) [46\]](#page-11-2) is an architecture pattern
    that arranges an application as a collection of loosely coupled, fine-grained
    services, communicating through network protocols. In this paper, a system implemented
    with this architecture is called Microservices Software, while each service working
    as a component is called Microservices Applications (abbr. App). Figure [1](#page-2-0)
    depicts an example of Microservices Software for processing goods purchases. The
    software consists of six Microservices Apps, each with a specific and bounded
    functionality. For instance, service C handles account-related transactions, while
    service B manages order-related transactions. This architecture promotes modularity
    and specialization within the system.


    Microservices has several key features:


    - Independence. Each App usually is developed and maintained by an independent
    team and is independently deployed. This makes the development of a Microservice
    software more flexible than a monolithic software.

    - Interactivity. While Microservices Apps can be developed and deployed independently,
    they still require communication with each other through network protocols like
    HTTP and RPC (Remote Procedure Call) to collaborate on user requests. In other
    words, from the perspective of effectively handling user requests, there is interdependence
    and interactivity among the Microservices Apps.

    - Relative Complexity. In contrast to a monolithic software with equivalent functionality,
    each individual Microservices App has a smaller size and lower complexity. However,
    when considering the Microservices Software as a whole, it is different. Microservices
    in AntGroup typically comprise thousands of Apps, encompassing hundreds of millions
    of lines of code. This indicates that the overall complexity is considerably high.

    - Rapid Evolution. Development-independence of each App makes Microservice Software
    (as a whole) always be in a stage of evolution in industrial scenes, even if each
    App is relatively stable. In AntGroup, for instance, there are thousands of merge
    requests (MR) being committed daily, and an average of one new version of an App
    is released every 4.3 days.


    ## <span id="page-1-0"></span>2.2 Challenges


    The above features of Microservices bring the convenience of deployment and development,
    but pose some challenges to fuzzing:


    • Challenge 1. How to enable a fuzzer for Microservices? Problem 1 (Inconsistency)
    remains a significant obstacle for existing fuzzing techniques when it comes to
    testing complex Microservice software. The fuzzing technique was originally designed
    for testing deterministic programs, where multiple runs of an input consistently
    follow the same program path. For programs with uncertain attributes (e.g., decision
    conditions determined by random numbers), traditional fuzzers are not suitable
    because the inconsistent program behaviors are hugely disruptive to the functions
    of seed selection and trimming, two important phases of the fuzzing workflow.
    To solve this issue, we adopt the Mocking-assisted seed execution approach to
    approximately guarantee a consistent behavior (more detailed in [§3.2\)](#page-2-1).


    Problem 2 (Incomplete Program Coverage) Fuzzing technique requires a total program
    coverage as the feedback of each fuzzing iteration. In monolithic software, coverage
    information is typically collected by directly reading the local memory. However,
    due to the distributed nature of Microservices, the coverage collection can only
    achieve multiple partial and disconnected coverages instead of obtaining a complete
    coverage view across all Microservices. (more detailed in [§3.3\)](#page-3-0).
    In a word, the lack of microservice testing harness disables traditional fuzzing
    techniques to test Microservice software.


    • Challenge 2. How to make Microservice fuzzing efficient? Taking each App of
    an industrial-level Microservice software as a target, fuzzing faces two efficiency
    problems, caused by environmental complexities, dynamics, and architectural differences.


    <span id="page-2-0"></span>![](_page_2_Figure_1.jpeg)


    Figure 1: An example of Microservices and its Apps.


    Problem 3 (Inconsistency-derived Inefficiency) The adoption of the mocking-assisted
    technique helps address Problem 1, but it is not a perfect solution. Striving
    for strict consistency in fuzzing requires frequent replay of existing seeds,
    which can impact performance. To balance consistency and performance in an efficient
    manner, we propose Seed Refresh & Life-cycle Management that involves periodically
    refreshing seed inputs during the fuzzing process (more detailed in [§3.4\)](#page-4-0).


    Problem 4 (High Network Cost) Due to inherent architectural differences, fuzzing
    an App deployed in a cloud environment poses distinct challenges compared to fuzzing
    desktop software or client-server-style protocol applications, e.g. AFL [\[49\]](#page-11-1).
    The fuzzer and the target App need to be deployed in separate containers, often
    residing on different hosts. This implies that communication between the fuzzer
    and the target App occurs through network protocols rather than the low-cost Inter-Process
    Communication (IPC) mechanism used by AFL and similar tools.


    An App typically exposes interfaces used for transmitting requests to other Apps
    and receiving their corresponding responses. To ensure efficiency, it is imperative
    to design a novel fuzzing framework that addresses the inefficiencies arising
    from network communication between Apps. To solve it, we redesign the fuzzing
    workflow by decoupling various fuzzing phases (more detailed in [§3.5\)](#page-4-1).


    • Challenge 3. How to scale Microservice fuzzing to real industrial scenarios?
    Fuzzing is costly due to the continuous seed generation and execution. When to
    terminate it and whether the termination impacts the fuzzing effectiveness or
    not are important applicable metrics in the enterprise. For applicability, our
    approach is inspired by the concept of ecology-based fuzzing [\[6\]](#page-10-12)
    and implemented for the normalized fuzzing (more detailed in [§4.1\)](#page-4-2).
    Besides, we explore the combination of our MicroFuzz with other techniques to
    assure program quality and make two real practices in AntGroup (more detailed
    in [§4\)](#page-4-3).


    ### 3 APPROACHES AND DESIGNS


    We propose and develop a fuzzing framework targeting at Microservices Software,
    named MicroFuzz. In this section, we will describe the overall architecture of
    MicroFuzz and detail our solutions to address the identified challenges.


    ## 3.1 MicroFuzz''s Architecture


    Figure [2](#page-3-1) shows the overall architecture of MicroFuzz. It comprises
    an intelligent switch and five core modules: seed selection, seed mutation, trace
    analysis, mocking-assisted seed execution, and distributed tracing. While the
    first three modules are traditional components, the latter two are newly designed
    modules serving as microservice testing harnesses, specifically enabling microservice
    fuzzing.


    ○1 Seed selection module is responsible for selecting the optimal initial seeds
    from a large set. These seeds are obtained from real Internet traffic or generated
    by our fuzzing tool in previous iterations.


    ○2 Seed mutation module is responsible for generating new test cases using mutation
    strategies commonly employed in traditional fuzzing techniques.


    - Bit/Byte Mutation: bit or byte-level flip

    - Arithmetic Mutation: add/subtract one on original integer

    - Interesting Replacement: replace some bytes with the interesting integer value
    belonging to (0, INT\_MAX)

    - Havoc Mutation: set random bytes to random values; delete or duplicate some
    byte sequences

    - Splice Mutation: splice two seeds at an arbitrary midpoint


    ○3 Mocking-assisted seed execution module is responsible for executing a seed
    by invoking either real or mocked services (more detailed in [§3.2\)](#page-2-1).


    ○4 Distributed tracing module is responsible for collecting comprehensive coverage
    information during the execution of a seed in a cluster environment (more detailed
    in [§4\)](#page-4-4).


    ○5 Trace analysis module is responsible for analyzing the execution trace of a
    seed and deciding whether to store it in databases or not. Similar to traditional
    fuzzing techniques, only seeds that trigger new crashes or cover unique program
    locations are typically stored for further investigation and utilization.


    ### <span id="page-2-1"></span>3.2 Mocking-Assisted Seed Execution


    Microservice software is highly complex and undergoes rapid evaluation due to
    frequent releases and interactivity-dependency among its component Apps. This
    inconsistency poses a challenge for traditional fuzzing techniques, making them
    unsuitable for testing Microservice software. To tackle this challenge, we utilize
    the mocking method [\[29\]](#page-10-13) to ensure approximate seed consistency,
    which allows multiple runs of a seed to follow the same program path within a
    short time period. The consistency is maintained by replacing the values of each
    mocking point with the recorded values from the previous version. The process
    begins with static analysis, where three types of mocking points are identified
    and collected:


    • System Dependencies. An App usually calls some library methods closely related
    to the operating system. Outputs of these methods are actually decided by the
    underlying OS, such


    #### <span id="page-3-1"></span>ICSE-SEIP ''24, April 14–20, 2024, Lisbon, Portugal
    Peng Di, Bingchang Liu, and Yiyi Gao


    ![](_page_3_Figure_2.jpeg)


    Figure 2: MicroFuzz''s architecture and application scenarios.


    as Math.random() method and System.currentTimeMillis() method. We call them system
    dependencies.


    - Internal Dependencies. In an App, some static fields and fields of some singleton
    beans are usually used to maintain some global (internal) states. For instance,
    the counter variable in Figure [3](#page-3-2) will be increased by one every time
    when getValue() method is called, making any seed that reaches this location be
    inconsistent due to the different counter of each run.

    - External Dependencies. One App usually refers to the exposed interfaces (e.g.
    RPC Reference of Spring) of other Apps to transfer some sub-requests to them and
    cooperate to finish user requests. Because the dependent Apps may release new
    versions during fuzzing, improper processing on these external dependencies also
    easily causes inconsistency issues.


    Corresponding to the above dependencies, we refer to the program locations involved
    as mocking points, denoted as , , and for brevity. Using the static analysis approach
    presented in [\[29\]](#page-10-13), we identify these mocking points and establish
    a consistent execution of seeds by following the steps outlined below.


    Mocking Points Collection. Given a Microservices App, all its mocking points =
    {1,2, · · · } are recursively gathered from its bytecode, using [\[29\]](#page-10-13)''s
    method: (1) are collected if the called functions are from or tainted from the
    third libraries; (2) are collected if they are static/Spring bean fields or tainted
    by any static/Spring bean fields; (3) are collected if they are the database access
    objects (DAO) invoking the Mybatis mapper interfaces, or the RPC references configured
    in the XML files via the tags of sofa:reference or sofa:binding.tr.RPC or tainted
    by DAOs and RPC references.


    Seed Record. JVM injector is utilized to record a seed''s execution. For any seed
    , the input and output at each mocking point are recorded in format of = ( , ),
    and its execution can be described using = { 1 , 2 · · · }. Note that if a mocking
    point is not covered in that run, both its input and output will be set to NULL
    as = (NULL, NULL).


    <span id="page-3-2"></span>


    | public class InternalExample {                               |  |  |  |  |  |  |

    |--------------------------------------------------------------|--|--|--|--|--|--|

    | private<br>static<br>Integer counter = 0;                    |  |  |  |  |  |  |

    | private<br>static Map<String, String> kvmap = new HashMap(); |  |  |  |  |  |  |

    | public<br>static<br>Integer getCounter() {                   |  |  |  |  |  |  |

    | return counter;                                              |  |  |  |  |  |  |

    | }                                                            |  |  |  |  |  |  |

    | public<br>static<br>String getValue( String key) {           |  |  |  |  |  |  |

    | counter++;                                                   |  |  |  |  |  |  |

    | return kvmap.getOrDefault(key, "") ;                         |  |  |  |  |  |  |

    | }                                                            |  |  |  |  |  |  |

    | public<br>static void putValue( String key, String value) {  |  |  |  |  |  |  |

    | kvmap.put(key, value) ;                                      |  |  |  |  |  |  |

    | }                                                            |  |  |  |  |  |  |

    | }                                                            |  |  |  |  |  |  |


    #### Figure 3: An example of static fields influencing the internal state.


    Seed Replay. Based on the latest = { 1 , 2 · · · }, a JVM injector is used to
    perform the value replacement in seed ''s replay: At each mocking point , the
    JVM injector captures the current input value in real-time, and then will be directly
    returned, rather than be really executed, if and only if a same input is observed
    in this execution (i.e. = ); Otherwise, a real execution will be performed, without
    any value replaced. We have established rules for assessing equality. If the features
    extracted from two inputs are categorized as similar (not necessarily identical),
    then we define them as equal.


    ## <span id="page-3-0"></span>3.3 Distributed Tracing


    Problem 2 highlights the difficulty of achieving comprehensive coverage information
    in Microservice software, which is distributedly deployed in a cluster. Traditional
    fuzzing techniques struggle to


    <span id="page-4-4"></span>MicroFuzz: An Efficient Fuzzing Framework for Microservices
    ICSE-SEIP ''24, April 14–20, 2024, Lisbon, Portugal


    ![](_page_4_Figure_1.jpeg)


    Figure 4: Distributed tracing architecture.


    accomplish their testing goals under such circumstances. To overcome this challenge,
    we propose the utilization of the distributed tracing technique.


    Our approach involves deploying agents throughout the cluster to collect coverage
    information during seed execution in Microservice software. Agents record covered
    probes and assign unique traceId to request contexts. The recorded coverage is
    hashed into coverDigest and stored locally. Unique coverDigest is transferred
    to the central Trace Collector, signaling the discovery of new program behavior
    (i.e., program path). Users can query the complete program coverage using traceId.
    The Trace Collector retrieves relevant covered probes from agents, splices them
    based on timing sequences, and generates an entire coverage description following
    the OpenTracing specification [\[36\]](#page-10-14). Figure [4](#page-4-4) illustrates
    this process.


    ### <span id="page-4-0"></span>3.4 Seed Refresh & Life-cycle Management


    In an industrial scene, Microservices exhibit high complexity and dynamics, where
    a single request to an App can trigger a sequence of service invocations. When
    focusing on a specific App, modifications to its upstream services can potentially
    impact its behavior. This is because the App relies on the output of upstream
    Apps as input to execute its own business logic. This situation is illustrated
    as Problem 1. In an enterprise setting, it is common to see hundreds to thousands
    of merge requests (MRs) being committed on a daily basis, further contributing
    to the dynamic nature of Microservices. Consider a target App with upstream services,
    where each service undergoes an average of changes per day. As a result, the program
    behaviors of the target App can potentially change up to times daily. To accurately
    capture and describe the program behaviors of the latest version of each App,
    it becomes necessary to refresh all the App''s seeds in the seed database whenever
    the target App or its upstream Apps release new versions. This process may involve
    performing seed replay up to a maximum of times per day.


    Considering the frequent software version evolution and huge amount of seeds,
    -times seed re-execution is definitely unacceptable in practice, as Problem 3
    shows. Instead of this accurate but expensive method, we propose an industrially
    degraded approach.


    <span id="page-4-5"></span>![](_page_4_Figure_9.jpeg)


    Figure 5: Pipeline parallelism.


    We make use of an event listener and two crontabs to approximately enable the
    Seed Refresh & Life-cycle Management. As Figure [2,](#page-3-1) triggered by Seed
    Refresh or Software Version Evolution, any seed in the seed database will be replayed
    by Seed Execution module every 12 hours or once the given App releases a new version.
    During such replay, those seeds will be run on the latest version of the target
    App, and invocations to other Apps will be concretely transferred to these dependent
    Apps to get real responses instead of using the mocking value stored in the database
    (i.e. Mocking-Assisted Seed Execution). The real responses will then be used to
    update the mocking database. Besides, Seed Life-cycle Management module cleanups
    all the seeds, created three days ago, together with their outdated mocking values.


    ### <span id="page-4-1"></span>3.5 Pipeline Parallelism


    Fuzz testing typically involves several steps, such as seed mutation, seed execution,
    and coverage collection. In traditional monolithic fuzzing techniques, these steps
    are performed sequentially. This means that the next fuzzing iteration can only
    begin once the current iteration is complete and coverage has been obtained. However,
    Problem 4 highlights the presence of high network costs between Microservice Apps.
    The sequential nature of traditional fuzzing significantly hampers the fuzzing
    process and reduces its efficiency. To address this issue, we have decoupled all
    the fuzzing phases, as depicted in Figure [5.](#page-4-5) In this decoupled work
    mode, the fuzzing process no longer needs to wait for the return of distributed
    tracing and analysis results. This greatly improves the efficiency of the fuzzing
    process, as it can continue without delay.


    ### <span id="page-4-3"></span>4 APPLICATIONS


    We have applied MicroFuzz in practical industrial scenarios, including normal
    fuzzing scenario to find bugs and improve coverage ([§4.1\)](#page-4-2), iteration
    testing scenario to find more behaviors manifested in an iteration ([§4.2\)](#page-5-0),
    and taint verification scenario to confirm data leakage risks found by dynamic
    taint analysis ([§4.3\)](#page-6-0). In this section, we show the details of these
    three application scenarios.


    ### <span id="page-4-2"></span>4.1 S1: Normal Fuzzing Scenario


    Fuzz testing often wastes computational power on ineffective exploration, where
    no new coverage or crashes are found. Based on the


    insights gained from AFL''s fuzzing exploration [\[49\]](#page-11-1), it has been
    observed that most program locations are covered in the early stages, with only
    a few new discoveries made later on. Therefore, an Intelligent Switch is introduced
    into MicroFuzz to control core modules (e.g. Seed Scheduler and others) and make
    power-aware decisions. Once this switch identifies the fuzzing progress trapped
    and stuck in the above inefficient loops, it will terminate the working of each
    fuzzing module immediately. The extended Fuzzing Monitor collects and analyzes
    exploration information, while the switch is activated during software updates,
    inconsistent behavior, or user commands. It can be turned off by user commands
    or the Fuzzing Monitor to optimize computational resource usage.


    Böhme et al. [\[6\]](#page-10-12) draw a strong similarity between fuzzing exploration
    and species discovery in ecology. Both involve mutation strategies, spatial distribution,
    and temporal dynamics. Statistical methods used in species discovery can be applied
    to answer key questions in fuzzing campaigns, such as the presence of undetected
    bugs, maximum program coverage achievable, and the number of additional test cases
    required to reach desired coverage.


    In the normalized fuzzing scenario, the Fuzzing Monitor is specifically designed
    to collect the information, shown in Table [1,](#page-5-1) during the whole fuzzing
    exploration.


    ### Table 1: Tracking factors and estimation.


    <span id="page-5-1"></span>


    | Tracking factors |                                                                                |  |  |  |  |  |

    |------------------|--------------------------------------------------------------------------------|--|--|--|--|--|

    | 𝑛                | the number of seeds replayed                                                   |  |  |  |  |  |

    | ˆ𝑆               | the number of all statements in target App                                     |  |  |  |  |  |

    | 𝑆<br>(𝑛)         | the number of statements covered by 𝑛<br>seeds                                 |  |  |  |  |  |

    | 𝑓1               | the number of singletons* detected                                             |  |  |  |  |  |

    | 𝑓2               | the number of doubletons* detected                                             |  |  |  |  |  |

    | 𝑄0               | the number of undiscovered statements,𝑄0<br>= ˆ𝑆<br>− 𝑆<br>(𝑛)                 |  |  |  |  |  |

    | 𝑄1               | the number of statements only executed by singleton                            |  |  |  |  |  |

    | 𝐶                | the number of stored seeds with different coverDigest                          |  |  |  |  |  |

    |                  | * singleton/doubleton mean the seed whose coverDigest has
    occurred once/twice. |  |  |  |  |  |


    We utilize the method proposed in [\[6\]](#page-10-12) to estimate our framework.


    - 1/ represents the ratio or proportion of new crashes or coverage discovered.

    - () = ()/(() + (−1) 2 1 /(2 2)) represents the upper bound of potential program
    coverage or vulnerabilities that can be discovered by continuous fuzzing exploration.

    - ( <sup>+</sup> ) <sup>=</sup> () + <sup>0</sup> [<sup>1</sup> − (<sup>1</sup>
    <sup>−</sup> 1/(<sup>0</sup> <sup>+</sup> 1))]) is the expected program coverage
    or vulnerability count after executing more seeds.


    The Fuzzing Monitor utilizes statistical estimations to make decisions regarding
    the Intelligent Switch behavior. If no new crashes or coverage are expected, indicated
    by either a low value of 1/ or () − ˆ ( + ) compared to a threshold , the monitor
    turns the switch off. Conversely, if inconsistencies are detected during seed
    replay or software version evolution, the monitor turns the switch back on. The
    intelligent on-off control optimizes computing resources without compromising
    fuzzing effectiveness. Figure [7](#page-7-0) demonstrates the successful balance
    achieved, where resources are efficiently allocated while maintaining the ability
    to discover crashes and coverage during fuzzing.


    ## <span id="page-5-0"></span>4.2 S2: Iteration Testing Scenario


    Software evolves by new feature import or logic update in each iteration. To plan
    tests for an iteration, two aspects should be considered. One is regression test
    which reruns the prior test cases to ensure the previous functions performed as
    expected after a change [\[26\]](#page-10-15). Another is to test the given software
    as thoroughly as possible to ensure that the new features are free from any residual
    vulnerabilities before release. From the above aspects, this section will detail
    the extensions of the proposed microservice fuzzing technology and introduce its
    application in iteration testing scenario.


    #### Aspect of Regression Testing.


    Due to shorter software delivery life cycles and the presence of large test suites,
    re-running all test cases for a given software under test (SUT) after each change
    can be costly [\[48\]](#page-11-7). To address this, a technique called dynamic
    regression test selection (RTS) is employed to select a subset of test cases from
    the test suite. These selected test cases are then executed on the latest version
    of the SUT to verify different program behaviors by comparing the new code changes
    with per-test execution traces [\[32,](#page-10-16) [50,](#page-11-8) [54\]](#page-11-9).
    MicroFuzz is extended with Change Impact Analysis, as depicted in Figure [2,](#page-3-1)
    to associate each execution trace with line-, block-, or method-level coverage.
    These traces are indexed based on commit information, such as the commitId or
    the name and branch of the Microservice App. This indexing allows for quick retrieval
    of relevant traces from a large set, enabling efficient test selection and execution.
    Further implementation details will be discussed in [§5.](#page-6-1)


    For an iteration where a merge request (MR) is committed from branch A to branch
    B, regression testing will be planned on test suite ∪, which is accomplished by
    following the steps:


    - Change Impact Analysis collects each different block between branch and branch
    , and then puts it into .

    - From traces database, select each trace covering any different block ∈ , and
    put it into set or if it was previously executed on branch A or branch B.

    - Based on the mapping between traces and seeds database, the corresponding seed
    for each selected trace ∈ ∪ is retrieved and stored in sets or accordingly, if
    the trace is derived from or .


    ### Aspect of New Features Testing.


    In an iteration, testing efforts are focused on exploring new basic block ∈ that
    have not been associated with any traces yet. MicroFuzz utilizes directed fuzzing
    techniques and incorporates Call Graph Analysis to obtain the call graph of the
    latest Microservice Software after each software version evolution. This is an
    incremental analysis process [\[53\]](#page-11-10). It also includes a Seed Scheduler
    and Trace Analysis, which select seeds based on the closest prior execution traces
    and calculate the shortest distances between methods using Dijkstra''s algorithm
    [\[45\]](#page-11-11). These techniques optimize seed selection for effective
    testing and exploration of new features.


    Figure [6](#page-6-2) illustrates the target method C1 for directed fuzzing exploration.
    The Seed Scheduler module assigns decreasing priority to seed3, seed1, and seed2.
    Preference is given to seed3 and seed1 as they provide better coverage or proximity
    to the target method. This preference is also extended to the Trace Analysis module
    during


    MicroFuzz: An Efficient Fuzzing Framework for Microservices ICSE-SEIP ''24, April
    14–20, 2024, Lisbon, Portugal


    <span id="page-6-2"></span>![](_page_6_Figure_2.jpeg)


    Figure 6: Shortest distance calculation in directed fuzzing technique.


    iteration testing, where seeds that can adequately cover or closely match the
    target are prioritized.


    ### <span id="page-6-0"></span>4.3 S3: Taint Verification Scenario


    Taint information plays a critical role in ensuring program quality and safeguarding
    data privacy within the industry. To capture taint information, dataflow and taint
    analysis techniques are commonly employed, allowing for the monitoring and tracing
    of data propagation from specific sources. However, existing traffic volumes often
    fall short in providing sufficient data for accurate verification. To overcome
    this limitation, our MicroFuzz bolsters verification capabilities by significantly
    increasing the volume of traffic available for analysis. In comparison to static
    taint analyzers with lower precision [\[4,](#page-10-17) [42\]](#page-11-12) and
    dynamic taint analyzers with higher costs [\[5,](#page-10-18) [11\]](#page-10-19),
    the combination of our MicroFuzz with static analyzers has demonstrated its effectiveness
    and practicality. We have successfully validated this approach through two real
    industrial practices, and further results can be found in Table [2.](#page-7-1)


    To establish the taint verification, MicroFuzz works as follows:


    - from seeds database, Seed Selection picks a seed whose prior execution trace
    reaches the source''s method entry.

    - Seed Mutation generates new seeds = {1, 2, · · · } by only performing mutations
    on the source parameter of .

    - in each ''s execution, Trace Analysis observes the sink''s value and denotes
    it as . Using the variable-controlling approach, <source,sink> is verified if
    ≠ , ≠ . Otherwise, the taint-relation is uncertain (e.g., neither existence nor
    inexistence can be decided).


    ### <span id="page-6-1"></span>5 IMPLEMENTATION


    We have successfully developed and deployed our proposed microservice fuzzing
    framework as a SOFABoot [\[23\]](#page-10-20) microservice App, named MicroFuzz.
    It comprises primarily of 263K lines of Java code. MicroFuzz can receive requests
    from either human users or CI/CD platforms, and it will commence fuzzing the designated
    Microservice App once receives a request. In the following section, we will provide
    a thorough exposition of several pivotal components.


    Seeds & Mocks Storage. In MicroFuzz,seeds and mocks databases serve as repositories
    for the respective seed and concomitant mock


    data. Similar to the fuzzing queue, the seeds database facilitates frequent CRUD
    (Create, Read, Update, and Delete) operations throughout the fuzz exploration
    process, including the data access of Seed Mutation in each fuzzing iteration
    and the bulk updating/deleting of data in regards to seed refresh and seed life-cycle
    management.


    To ensure storage durability and efficiency, our MicroFuzz utilizes the Cache-Aside
    pattern [\[34\]](#page-10-21) in conjunction with Ocean-Base [\[2\]](#page-10-22)
    and Redis [\[33\]](#page-10-23). Seeds and mocks are stored using Ocean-Base as
    the main store and Redis as the cache. Read-through and write-through strategies
    are implemented to load data from Ocean-Base into Redis on demand. Seeds are initially
    grouped by the application information, such as name, branch, or commitId, of
    the corresponding Microservice Software in OceanBase. In Redis, each seed is stored
    with its associated mocks to optimize Distributed Tracing. The framework uses
    the <coverDigest, seed> pair to associate coverage information with each seed
    in Redis, enabling faster Trace Analysis by querying coverDigest for new program
    coverage.


    ### Seed Management and Software Version Evolution.


    In MicroFuzz, the functionalities of seed refresh and seed lifecycle management
    are facilitated by an event listener and two crontabs, respectively. The periodic
    tasks of seed replay and cleanup are carried out with the aid of AntScheduler
    [\[21\]](#page-10-24). Furthermore, the feature of software version evolution
    is implemented through a callback handler instance that is embedded in the CI/CD
    pipeline and will trigger upon the merging of a new commit.


    #### Intelligent Switch.


    In MicroFuzz, the Intelligent Switch serves as the primary controller for fuzzing
    exploration. It receives signals, such as on/off commands, from various sources
    including users, software version evolution, and the Fuzzing Monitor. This functionality
    is implemented using Distributed Resource Management (DRM) [\[20\]](#page-10-25),
    which enables dynamic modification of the entrance state of each core module while
    the Microservice Software is running. By setting the state of an entrance to off,
    the corresponding fuzzing module becomes inaccessible unless it is reset to on
    again. This capability allows the Intelligent Switch to initiate or terminate
    a fuzzing exploration in real time based on the received signals.


    Trace-Block Association.


    <span id="page-7-1"></span>


    | Microservice | Effectiveness |         |      |            | Efficiency |          |          |          |          |         |

    |--------------|---------------|---------|------|------------|------------|----------|----------|----------|----------|---------|

    |              | #LOC          | COV (%) | VUL  | New Traces | Taints     | #TT
    (ms) | #TS (ms) | #TO (ms) | #TD (ms) | SAV (X) |

    | M1           | 306K          | +23.88% | 3    | #          | 9          | 55.26    |
    3.06     | 172.32   | 117.32   | 0.46    |

    | M2           | 704K          | +19.96% | 2    | #          | 90         | 66.64    |
    2.74     | 139.64   | 73.62    | 0.89    |

    | M3           | 31K           | +8.54%  | 0    | #          | 28         | 54.35    |
    3.18     | 93.26    | 39.18    | 1.38    |

    | M4           | 94K           | +17.83% | 0    | #          | 33         | 57.13    |
    2.23     | 89.4     | 32.19    | 1.78    |

    | M5           | 818K          | +21.05% | 3    | #          | 56         | 49.7     |
    3.02     | 190.28   | 140.9    | 0.35    |

    | M6           | 156K          | +17.48% | 0    | 46.42%     | 8          | 51.86    |
    2.32     | 63.64    | 12.17    | 4.22    |

    | M7           | 273K          | +18.29% | 1    | 22.99%     | 6          | 53.43    |
    2.14     | 89.67    | 35.89    | 1.5     |

    | M8           | 504K          | +13.03% | 3    | 307.59%    | 6          | 52.72    |
    2.29     | 100.04   | 47.92    | 1.09    |

    | M9           | 75K           | +16.12% | 0    | 176.72%    | 467        | 49.52    |
    2.79     | 97.38    | 47.14    | 1.07    |

    | M10          | 120K          | +19.67% | 0    | 109.09%    | 15         | 62.2     |
    2.22     | 71.2     | 9.02     | 6.89    |

    | 10 Aggs      | 24.96M        | +17.59% | 12   | 135.54%    | 718        | 55.28    |
    2.60     | #        | #        | 1.96    |

    | 261 Aggs     | 74.6M         | +12.24% | 3831 | 38.42%     | 5718       | 52.72    |
    2.89     | #        | #        | 2.67    |


    Table 2: Experimental results on 10 example Microservice Apps.


    To establish associations between traces and blocks, which is crucial for both
    regression testing and directed fuzzing, we employ Geabase [\[15\]](#page-10-26),
    a graph database, in MicroFuzz. When each software version evolves, a new call
    graph will be stored in Geabase and named using its git commit information. This
    allows for the identification and differentiation of different versions of the
    Microservice App. Each seed is associated with node of this graph once it reaches
    the corresponding basic block of during execution on the commitId version.


    #### Data Flow Monitor.


    To implement the lightweight dynamic taint verification approach discussed in
    [§4.3,](#page-6-0) a JVM injector is utilized as part of the Distributed Tracing
    process. This injector is responsible for gathering the values of service inputs
    and data access objects (DAOs) during the execution of the system. The purpose
    of this is to verify the taint relations between services or between services
    and the database. These taint relations are represented as <source, sink>, where
    the source indicates the taint position of the inputs (such as the parameters
    of a service), and the sink represents either the same position or a database
    operation. SOFAMQ [\[22\]](#page-10-27), a distributed message middleware that
    builds upon RocketMQ [\[1\]](#page-10-28), is employed to decouple the key fuzzing
    modules, allowing the seamless and concurrent operations of the key fuzzing modules.


    ### 6 EVALUATION


    In this section, we present our evaluation setup and performance of our tool,
    MicroFuzz, corresponding to the 3 key challenges defined in § [2.2.](#page-1-0)
    That''s to say, we try to answer three questions:


    - Q1: Can MicroFuzz effectively fuzz Microservice Apps deployed in an industrial
    environment, and what is its performance?

    - Q2: How efficient MicroFuzz is at fuzzing Microservice Apps?

    - Q3: How does MicroFuzz perform when applied in other scenarios except normal
    fuzzing?


    It is worth noting that, to the best of our knowledge, MicroFuzz is likely the
    first practical fuzzer for industrial-level Microservice software. As a result,
    when establishing baseline comparisons, we rely on user-provided data and feedback.
    Indeed, checking all the


    #### **Power-Saving of Intelligent Switch**


    <span id="page-7-0"></span>![](_page_7_Figure_14.jpeg)


    Figure 7: Experimental results of Intelligent Switch.


    results from MicroFuzz can be a challenging task, even for developers. This is
    primarily due to the large volume of data generated by the fuzzing process, often
    reaching thousands of entries for each Microservice App. Reviewing and analyzing
    such a vast amount of data can be time-consuming and resource-intensive.


    ## 6.1 Setup


    We have deployed MicroFuzz on a cluster of elastic cloud instances, each equipped
    with eight 2.5GHz cores and 32GB of RAM. Within the same cloud environment, we
    have deployed over 3,000 targeted Microservice Apps. MicroFuzz has been running
    continuously for more than five months under this specific setup.


    ### 6.2 Q1 - Effectiveness


    ### Vulnerability Discovery Scenario.


    In order to assess the efficacy of MicroFuzz in fuzzing Microservice Apps within
    an industrial cloud environment, we conducted


    <span id="page-8-0"></span>Table 3: Vulnerability types on 261 target Microservice
    Apps.


    | Vul Type | Vul Detail                 | Count |

    |----------|----------------------------|-------|

    |          | Biz_Exception              | 254   |

    | Biz_Vul  | Biz_Error                  | 3548  |

    |          | Null Pointer Exception     | 3     |

    |          | SQL Exception              | 22    |

    | Sys_Vul  | NumberFormatException      | 1     |

    |          | UncleardThrowableException | 1     |

    |          | IOException                | 2     |


    a random selection process. Out of the over 3,000 Apps available, we chose 261
    Apps to serve as our fuzzing targets. These selected Apps hold significant importance
    as they are fundamental, hightraffic, and heavily relied upon by other Apps in
    the ecosystem. Compared with others, they are more mature and fully tested in
    various business domains.


    After five months of intensive fuzzing, 3,831 exception reports were uncovered.


    Table [3](#page-8-0) presents a breakdown of the reported exception types, revealing
    Biz\_Error (a type of business error) as the most prevalent. Additionally, critical
    exceptions such as Null Pointer Exception have been identified during the evaluation
    process. Most of Sys\_Vul exceptions have been patched by Apps'' developers.


    Furthermore, we specifically chose 10 sample Apps to present a more comprehensive
    overview of the effectiveness of MicroFuzz, as shown in Table [2.](#page-7-1)
    These Apps have a line of code (LoC) ranging from 31,000 to 818,000. The added
    code coverage achieved by MicroFuzz ranges from 8.54% to 23.88%, with an average
    of 17.59%, and 12 exceptions were found among these 10 Apps. In total, the collective
    code coverage of the 261 Apps is 12.24% on average, and 3,831 exception reports
    have been submitted.


    Overall, we conclude that MicroFuzz is effective in improving code coverage and
    discovering potential vulnerabilities.


    ## 6.3 Q2 - Efficiency


    In addition to effectiveness, we also evaluated the efficiency of MicroFuzz. For
    illustration purposes, we still take the selected 10 Apps as examples and present
    the results in Table [2.](#page-7-1) The #TT column denotes the average time taken
    for Distributed Tracing, which is responsible for collecting runtime information
    during the fuzzing process for each App. The average time duration for Distributed
    Tracing across the 10 Apps is 52.72ms, ranging from 49.7ms to 66.64ms. This duration
    includes both the coverDigest query and crash capture procedures. #TS denotes
    the time consumption of Distributed Tracing spent for data collection at each
    service entry or data access point. Each time takes around 2~3 ms on average,
    which proves our Distributed Tracing technique is efficient in the industrial
    scene. The results demonstrate that our Distributed Tracing technique efficiently
    collects runtime information while maintaining the fuzzing performance at a satisfactory
    level.


    The columns labeled #TO and #TD represent the total time required for a single
    fuzzing iteration with and without Pipeline Parallelism respectively. The SAV
    column denotes the improved efficiency achieved through Pipeline Parallelism,
    calculated as SAV = #TD/#TO - 1. The efficiency improvement achieved through the


    use of Pipeline Parallelism varies. For example, App M6 and M10 experienced a
    4.22x and 6.89x improvement. Conversely, the improvement for App M1 was relatively
    modest, with only a 0.46x increase. The difference comes from each App''s characteristics.
    On average, however, the efficiency improvement across all Apps was notable, with
    a factor of 2.67x improvement achieved when employing the Pipeline Parallelism
    mechanism.


    We evaluated the resource efficiency of the Intelligent Switch mechanism, which
    optimizes computing resources by assessing the need for further fuzzing based
    on monitoring results. To demonstrate its effectiveness, we conducted a comparative
    study using M1 fuzzing as a case study, as depicted in Figure [7.](#page-7-0)
    In this study, we performed two experiments: one with the Intelligent Switch enabled
    and another with it disabled. We plotted the changes in the proportion of discovered
    vulnerabilities over time (represented by the red line) and the code coverage
    ratio (represented by the blue line). With the Intelligent Switch enabled, the
    fuzzer terminated after 4.6 hours as the mechanism determined that no new paths
    could be discovered, thus conserving computational resources. Conversely, in the
    control experiment without the Intelligent Switch, the fuzzer continued running,
    but no new paths were found, resulting in wasted resources. On average, enabling
    the Intelligent Switch allowed for a 61.7% reduction in computing resources while
    maintaining virtually no loss in path coverage. We have observed similar phenomena
    across nine other Apps as well. This showcases the significant resource savings
    achieved by leveraging the effectiveness of the Intelligent Switch mechanism.


    In summary, our adapted mechanism incorporating Distributed Tracing, Pipeline
    Parallelism, and Intelligent Switch demonstrates high efficiency in terms of both
    time and computing resources. This outstanding performance establishes MicroFuzz
    as an efficient tool for fuzzing Microservice Apps within an industrial cloud
    environment.


    ### 6.4 Q3 - Applicability


    We assessed the applicability of MicroFuzz in two additional scenarios: iteration
    testing and taint verification.


    ### Iteration Testing Scenario.


    When a code change is made to a Microservice App, it is crucial to generate relevant
    test cases that cover the modified code blocks to uncover any potential bugs,
    called iteration testing. To address this, MicroFuzz leverages directed fuzzing
    techniques. In this specific use case, we evaluate MicroFuzz''s ability to generate
    new traces specifically targeting the modified code segments. To achieve this,
    we select traffic data that includes the code blocks affected by the changes as
    initial fuzzing seeds. We then analyze the number of newly discovered traces produced
    by MicroFuzz as a measure of its effectiveness in capturing the behavior of the
    modified code segments.


    Figure [8](#page-9-0) presents the average count of newly generated traces during
    the fuzzing process of the 10 selected Apps using Micro-Fuzz, as depicted in Table
    [2.](#page-7-1) #RI represents the count of initial seeds, while #RT indicates
    the number of traces discovered during the fuzzing process, including the initial
    seeds. Taking the example of the M6 App, there were initially 280 seeds, and after
    the fuzzing process, a total of 410 traces were discovered. This indicates that


    <span id="page-9-0"></span>![](_page_9_Figure_1.jpeg)


    **Fuzzing Effectiveness**


    Figure 8: Experimental results in iteration testing scenario.


    MicroFuzz uncovered 130 new paths, resulting in an effectiveness rate of 46.24%.
    The average effectiveness of the M6-M10 Apps, as depicted in the Traces column
    of Table [2,](#page-7-1) was computed. Overall, MicroFuzz demonstrated the capability
    to discover 38.42% of new paths during each App''s iteration. It is important
    to note that the M1-M5 Apps do not have historical traffic data covering the changed
    code blocks. Therefore, in cases where a new functional module is introduced in
    a single iteration, the initial seed numbers for these modules in Figure [8](#page-9-0)
    would be 0, and there would be no corresponding effectiveness measure data in
    Table [2.](#page-7-1)


    In summary, MicroFuzz demonstrates its effectiveness in iteration testing by successfully
    identifying new coverage paths.


    Taint Verification Scenario.


    In this particular scenario, we utilized MicroFuzz to validate the findings of
    static taint analysis, a technique prone to false positives. The testing results
    are presented in Table [2,](#page-7-1) where the Taints column represents the
    cumulative number of taint-relations confirmed by MicroFuzz. Additionally, the
    TS column indicates the time required for Distributed Tracing to collect data
    at each service entry or data access point.


    Overall, MicroFuzz identified a total of 5,718 unique possible instances of quality
    issues and security risks, of which 1,764 were confirmed by software specialists.
    These results demonstrate the effectiveness of MicroFuzz in taint verification
    scenarios, enhancing the overall accuracy of the analysis process.


    ### 7 RELATED WORK


    Fuzzers for Monolithic Software. Representative fuzzers such as AFL [\[49\]](#page-11-1),
    libFuzzer [\[31\]](#page-10-0), and honggfuzz [\[18\]](#page-10-1) provide guidance
    to other fuzzers. The typical fuzzing workflow consists of four phases: seed scheduling,
    seed mutation, seed execution, and seed selection. Various designs have been incorporated
    into these phases. Böhme et al. [\[8\]](#page-10-3) treat fuzzing exploration
    as a Markov process and propose a novel seed scheduling strategy that prioritizes
    seeds exploring lowfrequency paths for further mutations. FairFuzz [\[25\]](#page-10-29)
    introduces new seed mutation operations, such as overwriting, deleting, and


    inserting, to enhance testing. AFLGo [\[7\]](#page-10-2) devises a seed selection
    strategy that favors seeds with execution paths closer to the target locations
    in each fuzzing iteration. Similar ideas are also explored in [\[27\]](#page-10-5).
    Gan et al. [\[16\]](#page-10-4) address path collision issues in AFL by correcting
    path coverage calculations. Peng et al. [\[37\]](#page-10-30) combined directed
    fuzzing with symbolic execution to reproduce 1-day vulnerabilities. In recent
    years, many approaches have incorporated AI techniques into the seed mutation
    phase. For example, Zong et al. [\[57\]](#page-11-13) improve directed fuzzing
    efficiency by filtering out inputs predicted to be unreachable to targets. In
    [\[40\]](#page-11-14), an LSTM model is used to learn the mutable positions of
    inputs. Godefroid et al. [\[17\]](#page-10-31) employ an RNN to learn the grammar
    of program inputs using numerous test cases and use the learned grammar to generate
    new inputs. NEUZZ [\[41\]](#page-11-15) applies the concept of gradient descent
    to smooth the neural network model and significantly enhances program coverage
    by learning program branches. With the recent enormous advances in Large Language
    Models (LLMs), TitanFuzz [\[12\]](#page-10-32) and FuzzGPT [\[13\]](#page-10-33)
    have been proposed to directly leverage LLMs for fuzzing DL libraries.


    Unlike other fuzzing frameworks, MicroFuzz does not aim to improve existing fuzzing
    strategies. Instead, its main objective is to provide support and enable the effective
    implementation of these strategies specifically for Microservice software.


    Parallel Fuzzing. Existing approaches have made advancements in enhancing the
    performance of parallel fuzzing by focusing on improving the fuzzing strategy
    [\[9,](#page-10-34) [28,](#page-10-35) [39,](#page-10-36) [44,](#page-11-16) [56\]](#page-11-17)
    or increasing the fuzzing speed [\[14,](#page-10-37) [47\]](#page-11-18). One
    common approach to enhance the fuzzing strategy is task partitioning. PAFL [\[28\]](#page-10-35)introduces
    an effective method to synchronize guiding information and statically divide fuzzing
    tasks based on branching information to minimize overlap between instances. AFLEdge
    [\[44\]](#page-11-16) utilizes static analysis to dynamically create exclusive
    and evenly weighted fuzzing tasks. Another strategy to improve fuzzing is through
    ensemble fuzzing [\[9\]](#page-10-34) or collaborative fuzzing [\[24\]](#page-10-38),
    where the strengths of different fuzzers are combined. By fuzzing the same target
    with multiple fuzzers and sharing their progress, overall performance can be improved.
    EnFuzz [\[9\]](#page-10-34) designs heuristics to evaluate fuzzer diversity and
    selects the most diverse subset for ensemble fuzzing through efficient seed synchronization.
    Cupid [\[24\]](#page-10-38) proposes a collaborative fuzzing framework that automatically
    discovers the optimal combination of fuzzers for a target. One challenge in parallel
    fuzzing is the operating system bottleneck. Xu et al. [\[47\]](#page-11-18) address
    this by introducing new operating primitives that enhance scalability and performance
    in parallel fuzzing, mitigating file system contention and scalability issues.


    A recent endeavor in parallelizing fuzzing involved the redesign of parallel fuzzing
    using a microservice architecture, as demonstrated in µFUZZ [\[10\]](#page-10-10).
    It aimed to use the CPU power in the distributed cloud for fuzzing monolithic
    software by enhancing I/O operations and eliminating synchronization.


    Nevertheless, our MicroFuzz is uniquely designed to address the specific challenges
    of identifying potential issues in Microservice software. As a result, the challenges
    we encounter differ from those encountered in other fuzzing frameworks.


    MicroFuzz: An Efficient Fuzzing Framework for Microservices ICSE-SEIP ''24, April
    14–20, 2024, Lisbon, Portugal


    ### 8 CONCLUSION


    This paper presents the first comprehensive study on Microservice fuzzing, which
    differs significantly from state-of-the-art fuzzing techniques for monolithic
    software. To facilitate Microservice fuzzing, we propose an efficient fuzzing
    framework named MicroFuzz incorporating innovative approaches such as Mocking-Assisted
    Seed Execution, Distributed Tracing, Seed Refresh, and Pipeline Parallelism to
    enhance fuzzing efficiency. After running on thousands of Apps in AntGroup, MicroFuzz
    identified 5,718 potential quality or security risks, out of which 1,764 are confirmed.
    Furthermore, Micro-Fuzz significantly enhances line coverage by 12.24% and detects
    new paths by 38.42% in the iteration testing.


    ### ACKNOWLEDGMENTS


    This work is supported by Ant Group.


    ### REFERENCES


    - <span id="page-10-28"></span>[1] 2021. Apache RocketMQ.<https://rocketmq.apache.org/>

    - <span id="page-10-22"></span>[2] Alibaba. 2021. OceanBase.<https://dbdb.io/db/oceanbase>

    - <span id="page-10-11"></span>[3] Anastasios Antoniadis, Nikos Filippakis, Paddy
    Krishnan, Raghavendra Ramesh, Nicholas Allen, and Yannis Smaragdakis. 2020. Static
    Analysis of Java Enterprise Applications: Frameworks and Caches, the Elephants
    in the Room. In Proceedings of the 41st ACM SIGPLAN Conference on Programming
    Language Design and Implementation (London, UK) (PLDI 2020). Association for Computing
    Machinery, New York, NY, USA, 794–807.<https://doi.org/10.1145/3385412.3386026>

    - <span id="page-10-17"></span>[4] Steven Arzt, Siegfried Rasthofer, Christian
    Fritz, Eric Bodden, Alexandre Bartel, Jacques Klein, Yves Le Traon, Damien Octeau,
    and Patrick McDaniel. 2014. Flow-Droid: Precise Context, Flow, Field, Object-Sensitive
    and Lifecycle-Aware Taint Analysis for Android Apps. In Proceedings of the 35th
    ACM SIGPLAN Conference on Programming Language Design and Implementation (Edinburgh,
    United Kingdom) (PLDI ''14). Association for Computing Machinery, New York, NY,
    USA, 259–269.<https://doi.org/10.1145/2594291.2594299>

    - <span id="page-10-18"></span>[5] Jonathan Bell and Gail Kaiser. 2014. Phosphor:
    Illuminating Dynamic Data Flow in Commodity Jvms. In Proceedings of the 2014 ACM
    International Conference on Object Oriented Programming Systems Languages & Applications
    (Portland, Oregon, USA) (OOPSLA ''14). Association for Computing Machinery, New
    York, NY, USA, 83–101.<https://doi.org/10.1145/2660193.2660212>

    - <span id="page-10-12"></span>[6] Marcel Böhme. 2018. STADS: Software Testing
    as Species Discovery. ACM Trans. Softw. Eng. Methodol. 27, 2, Article 7 (jun 2018),
    52 pages. [https://doi.org/10.1145/](https://doi.org/10.1145/3210309) [3210309](https://doi.org/10.1145/3210309)

    - <span id="page-10-2"></span>[7] Marcel Böhme, Van-Thuan Pham, Manh-Dung Nguyen,
    and Abhik Roychoudhury. 2017. Directed Greybox Fuzzing. In Proceedings of the
    2017 ACM SIGSAC Conference on Computer and Communications Security (Dallas, Texas,
    USA) (CCS ''17). Association for Computing Machinery, New York, NY, USA, 2329–2344.
    <https://doi.org/10.1145/3133956.3134020>

    - <span id="page-10-3"></span>[8] Marcel Böhme, Van-Thuan Pham, and Abhik Roychoudhury.
    2016. Coverage-Based Greybox Fuzzing as Markov Chain. In Proceedings of the 2016
    ACM SIGSAC Conference on Computer and Communications Security (Vienna, Austria)
    (CCS ''16). Association for Computing Machinery, New York, NY, USA, 1032–1043.
    <https://doi.org/10.1145/2976749.2978428>

    - <span id="page-10-34"></span>[9] Yuanliang Chen, Yu Jiang, Fuchen Ma, Jie Liang,
    Mingzhe Wang, Chijin Zhou, Xun Jiao, and Zhuo Su. 2019. EnFuzz: Ensemble Fuzzing
    with Seed Synchronization among Diverse Fuzzers. In 28th USENIX Security Symposium
    (USENIX Security 19). USENIX Association, Santa Clara, CA, 1967–1983. [https://www.usenix.org/](https://www.usenix.org/conference/usenixsecurity19/presentation/chen-yuanliang)
    [conference/usenixsecurity19/presentation/chen-yuanliang](https://www.usenix.org/conference/usenixsecurity19/presentation/chen-yuanliang)

    - <span id="page-10-10"></span>[10] Yongheng Chen, Rui Zhong, Yupeng Yang, Hong
    Hu, Dinghao Wu, and Wenke Lee. 2023. µFUZZ: Redesign of Parallel Fuzzing using
    Microservice Architecture. In 32nd USENIX Security Symposium (USENIX Security
    23). USENIX Association, Anaheim, CA, 1325–1342. [https://www.usenix.org/conference/usenixsecurity23/](https://www.usenix.org/conference/usenixsecurity23/presentation/chen-yongheng)
    [presentation/chen-yongheng](https://www.usenix.org/conference/usenixsecurity23/presentation/chen-yongheng)

    - <span id="page-10-19"></span>[11] James Clause, Wanchun Li, and Alessandro Orso.
    2007. Dytan: A Generic Dynamic Taint Analysis Framework. In Proceedings of the
    2007 International Symposium on Software Testing and Analysis (London, United
    Kingdom) (IS-STA ''07). Association for Computing Machinery, New York, NY, USA,
    196–206. <https://doi.org/10.1145/1273463.1273490>

    - <span id="page-10-32"></span>[12] Yinlin Deng, Chunqiu Steven Xia, Haoran Peng,
    Chenyuan Yang, and Lingming Zhang. 2023. Large Language Models are Zero-Shot Fuzzers:
    Fuzzing Deep-Learning Libraries via Large Language Models. arXiv[:2212.14834](https://arxiv.org/abs/2212.14834)
    [cs.SE]

    - <span id="page-10-33"></span>[13] Yinlin Deng, Chunqiu Steven Xia, Chenyuan
    Yang, Shizhuo Dylan Zhang, Shujing Yang, and Lingming Zhang. 2023. Large Language
    Models are Edge-Case Fuzzers: Testing Deep Learning Libraries via FuzzGPT. arXiv[:2304.02014](https://arxiv.org/abs/2304.02014)
    [cs.SE]

    - <span id="page-10-37"></span>[14] Andrea Fioraldi, Dominik Maier, Heiko Eißfeldt,
    and Marc Heuse. 2020. AFL++: Combining Incremental Steps of Fuzzing Research.
    In 14th USENIX Workshop on Offensive Technologies (WOOT 20). USENIX Association.

    - <span id="page-10-26"></span>[15] Zhisong Fu, Zhengwei Wu, Houyi Li, Yize Li,
    Min Wu, Xiaojie Chen, Xiaomeng Ye, Benquan Yu, and Xi Hu. 2017. GeaBase: A High-Performance
    Distributed Graph Database for Industry-Scale Applications. In 2017 Fifth International
    Conference on Advanced Cloud and Big Data (CBD). 170–175. [https://doi.org/10.1109/CBD.](https://doi.org/10.1109/CBD.2017.37)
    [2017.37](https://doi.org/10.1109/CBD.2017.37)

    - <span id="page-10-4"></span>[16] Shuitao Gan, Chao Zhang, Xiaojun Qin, Xuwen
    Tu, Kang Li, Zhongyu Pei, and Zuoning Chen. 2018. CollAFL: Path Sensitive Fuzzing.
    In 2018 IEEE Symposium on Security and Privacy (SP). 679–696.<https://doi.org/10.1109/SP.2018.00040>

    - <span id="page-10-31"></span>[17] Patrice Godefroid, Hila Peleg, and Rishabh
    Singh. 2017. Learn&Fuzz: Machine Learning for Input Fuzzing. CoRR abs/1701.07232
    (2017). arXiv[:1701.07232](https://arxiv.org/abs/1701.07232) <http://arxiv.org/abs/1701.07232>

    - <span id="page-10-1"></span>[18] Google. 2018. honggfuzz.<hhttps://github.com/google/honggfuzz>

    - <span id="page-10-8"></span>[19] Google. 2022. ClusterFuzz Trophies.<https://google.github.io/clusterfuzz#trophies>

    - <span id="page-10-25"></span>[20] Ant Group. 2020. Introduction to SOFAStack
    Microservices).

    - <span id="page-10-24"></span>[21] Ant Group. 2021. AntScheduler.<https://github.com/mcalus3/AntScheduler>

    - <span id="page-10-27"></span>[22] Ant Group. 2021. SOFAMQ.<https://github.com/sofastack-guides/sofamq-demo>

    - <span id="page-10-38"></span><span id="page-10-20"></span>[23] Ant Group. 2021.
    SOFASTACK.<https://github.com/sofastack> [24] Emre Güler, Philipp Görz, Elia Geretto,
    Andrea Jemmett, Sebastian Österlund, Herbert Bos, Cristiano Giuffrida, and Thorsten
    Holz. 2020. Cupid: Automatic Fuzzer

    - Selection for Collaborative Fuzzing. In Annual Computer Security Applications
    Conference (Austin, USA) (ACSAC ''20). Association for Computing Machinery, New
    York, NY, USA, 360–372.<https://doi.org/10.1145/3427228.3427266>

    - <span id="page-10-29"></span>[25] Caroline Lemieux and Koushik Sen. 2018. FairFuzz:
    A Targeted Mutation Strategy for Increasing Greybox Fuzz Testing Coverage. In
    2018 33rd IEEE/ACM International Conference on Automated Software Engineering
    (ASE). 475–485. <https://doi.org/10.1145/3238147.3238176>

    - <span id="page-10-15"></span>[26] Hareton K. N. Leung and Lee J. White. 1989.
    Insights into regression testing (software testing). Proceedings. Conference on
    Software Maintenance - 1989 (1989), 60–69.

    - <span id="page-10-5"></span>[27] Yuekang Li, Bihuan Chen, Mahinthan Chandramohan,
    Shang-Wei Lin, Yang Liu, and Alwen Tiu. 2017. Steelix: Program-State Based Binary
    Fuzzing. In Proceedings of the 2017 11th Joint Meeting on Foundations of Software
    Engineering (Paderborn, Germany) (ESEC/FSE 2017). Association for Computing Machinery,
    New York, NY, USA, 627–637.<https://doi.org/10.1145/3106237.3106295>

    - <span id="page-10-35"></span>[28] Jie Liang, Yu Jiang, Yuanliang Chen, Mingzhe
    Wang, Chijin Zhou, and Jiaguang Sun. 2018. PAFL: Extend Fuzzing Optimizations
    of Single Mode to Industrial Parallel Mode. In Proceedings of the 2018 26th ACM
    Joint Meeting on European Software Engineering Conference and Symposium on the
    Foundations of Software Engineering (Lake Buena Vista, FL, USA) (ESEC/FSE 2018).
    Association for Computing Machinery, New York, NY, USA, 809–814.<https://doi.org/10.1145/3236024.3275525>

    - <span id="page-10-13"></span>[29] Jiangchao Liu, Jierui Liu, Peng Di, Alex X.
    Liu, and Zexin Zhong. 2022. Record and Replay of Online Traffic for Microservices
    with Automatic Mocking Point Identification. In Proceedings of the 44th International
    Conference on Software Engineering: Software Engineering in Practice (Pittsburgh,
    Pennsylvania) (ICSE-SEIP ''22). Association for Computing Machinery, New York,
    NY, USA, 221–230. <https://doi.org/10.1145/3510457.3513029>

    - <span id="page-10-6"></span>[30] Zixi Liu, Yang Feng, Yining Yin, Jingyu Sun,
    Zhenyu Chen, and Baowen Xu. 2023. QATest: A Uniform Fuzzing Framework for Question
    Answering Systems. In Proceedings of the 37th IEEE/ACM International Conference
    on Automated Software Engineering (Rochester, MI, USA) (ASE ''22). Association
    for Computing Machinery, New York, NY, USA, Article 81, 12 pages.<https://doi.org/10.1145/3551349.3556929>

    - <span id="page-10-16"></span><span id="page-10-0"></span>[31] LLVM. 2018. libFuzzer.<https://llvm.org/docs/LibFuzzer.html>
    [32] Zhenyue Long, Zeliu Ao, Guoquan Wu, Wei Chen, and Jun Wei. 2020. WebRTS:
    A Dynamic Regression Test Selection Tool for Java Web Applications. In 2020 IEEE
    International Conference on Software Maintenance and Evolution (ICSME).

    - 822–825.<https://doi.org/10.1109/ICSME46990.2020.00102>

    - <span id="page-10-23"></span>[33] Redis Ltd. [n. d.]. Redis.<https://redis.io/>

    - <span id="page-10-21"></span>[34] Microsoft. 2022. Cache-Aside pattern. [https://learn.microsoft.com/en-us/azure/](https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside)
    [architecture/patterns/cache-aside](https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside)

    - <span id="page-10-9"></span>[35] Sam Newman. 2021. Building microservices. "
    O''Reilly Media, Inc.".

    - <span id="page-10-14"></span>[36] OpenTracing. [n. d.]. .<https://opentracing.io/>

    - <span id="page-10-30"></span>[37] Jiaqi Peng, Feng Li, Bingchang Liu, Lili Xu,
    Binghong Liu, Kai Chen, and Wei Huo. 2019. 1dvul: Discovering 1-day vulnerabilities
    through binary patches. In 2019 49th Annual IEEE/IFIP International Conference
    on Dependable Systems and Networks (DSN). IEEE, 605–616.

    - <span id="page-10-7"></span>[38] Theofilos Petsios, Adrian Tang, Salvatore Stolfo,
    Angelos D. Keromytis, and Suman Jana. 2017. NEZHA: Efficient Domain-Independent
    Differential Testing. In 2017 IEEE Symposium on Security and Privacy (SP). 615–632.
    [https://doi.org/](https://doi.org/10.1109/SP.2017.27) [10.1109/SP.2017.27](https://doi.org/10.1109/SP.2017.27)

    - <span id="page-10-36"></span>[39] Van-Thuan Pham, Manh-Dung Nguyen, Quang-Trung
    Ta, Toby Murray, and Benjamin I.P. Rubinstein. 2021. Towards Systematic and Dynamic
    Task Allocation for Collaborative Parallel Fuzzing. In 2021 36th IEEE/ACM International
    Conference on Automated Software Engineering (ASE). 1337–1341. [https://doi.org/10.1109/](https://doi.org/10.1109/ASE51524.2021.9678810)
    [ASE51524.2021.9678810](https://doi.org/10.1109/ASE51524.2021.9678810)


    <span id="page-11-0"></span>ICSE-SEIP ''24, April 14–20, 2024, Lisbon, Portugal
    Peng Di, Bingchang Liu, and Yiyi Gao


    - <span id="page-11-14"></span>[40] Mohit Rajpal, William Blum, and Rishabh Singh.
    2017. Not all bytes are equal: Neural byte sieve for fuzzing. CoRR abs/1711.04596
    (2017). arXiv[:1711.04596](https://arxiv.org/abs/1711.04596) <http://arxiv.org/abs/1711.04596>

    - <span id="page-11-15"></span>[41] Dongdong She, Kexin Pei, Dave Epstein, Junfeng
    Yang, Baishakhi Ray, and Suman Jana. 2019. NEUZZ: Efficient Fuzzing with Neural
    Program Smoothing. In 2019 IEEE Symposium on Security and Privacy (SP). 803–817.
    [https://doi.org/10.1109/](https://doi.org/10.1109/SP.2019.00052) [SP.2019.00052](https://doi.org/10.1109/SP.2019.00052)

    - <span id="page-11-12"></span>[42] Manu Sridharan, Shay Artzi, Marco Pistoia,
    Salvatore Guarnieri, Omer Tripp, and Ryan Berg. 2011. F4F: Taint Analysis of Framework-Based
    Web Applications. In Proceedings of the 2011 ACM International Conference on Object
    Oriented Programming Systems Languages and Applications (Portland, Oregon, USA)
    (OOPSLA ''11). Association for Computing Machinery, New York, NY, USA, 1053–1068.
    <https://doi.org/10.1145/2048066.2048145>

    - <span id="page-11-3"></span>[43] W. Wang, A. Benea, and F. Ivancic. 2023. Zero-Config
    Fuzzing for Microservices. In 2023 38th IEEE/ACM International Conference on Automated
    Software Engineering (ASE). IEEE Computer Society, Los Alamitos, CA, USA, 1840–1845.
    [https://doi.](https://doi.org/10.1109/ASE56229.2023.00036) [org/10.1109/ASE56229.2023.00036](https://doi.org/10.1109/ASE56229.2023.00036)

    - <span id="page-11-16"></span>[44] Yifan Wang, Yuchen Zhang, Chenbin Pang, Peng
    Li, Nikolaos Triandopoulos, and Jun Xu. 2021. Facilitating Parallel Fuzzing with
    Mutually-Exclusive Task Distribution. In Secur. Priv. Commun. Networks, Joaquin
    Garcia-Alfaro, Shujun Li, Radha Poovendran, Hervé Debar, and Moti Yung (Eds.).
    Springer International Publishing, Cham, 185–206.

    - <span id="page-11-11"></span>[45] Wiki. [n. d.]. Dijkstra''s Algorithm. [https://en.wikipedia.org/wiki/Dijkstra%27s\\_](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm)
    [algorithm](https://en.wikipedia.org/wiki/Dijkstra%27s_algorithm)

    - <span id="page-11-2"></span>[46] Wikipedia. [n. d.]. Microservices. Retrieved
    Feb 14, 2023 from [https://en.wikipedia.](https://en.wikipedia.org/wiki/Microservices)
    [org/wiki/Microservices](https://en.wikipedia.org/wiki/Microservices)

    - <span id="page-11-18"></span>[47] Wen Xu, Sanidhya Kashyap, Changwoo Min, and
    Taesoo Kim. 2017. Designing New Operating Primitives to Improve Fuzzing Performance.
    In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications
    Security (Dallas, Texas, USA) (CCS ''17). Association for Computing Machinery,
    New York, NY, USA, 2313–2328.<https://doi.org/10.1145/3133956.3134046>

    - <span id="page-11-7"></span>[48] S. Yoo and M. Harman. 2012. Regression Testing
    Minimization, Selection and Prioritization: A Survey. Softw. Test. Verif. Reliab.
    22, 2 (mar 2012), 67–120. [https:](https://doi.org/10.1002/stv.430) [//doi.org/10.1002/stv.430](https://doi.org/10.1002/stv.430)

    - <span id="page-11-1"></span>[49] Michal Zalewski. 2014. American Fuzzing Loop.<https://lcamtuf.coredump.cx/afl/>

    - <span id="page-11-8"></span>[50] Lingming Zhang. 2018. Hybrid Regression Test
    Selection. In Proceedings of the 40th International Conference on Software Engineering
    (Gothenburg, Sweden) (ICSE ''18). Association for Computing Machinery, New York,
    NY, USA, 199–209. <https://doi.org/10.1145/3180155.3180198>

    - <span id="page-11-4"></span>[51] Man Zhang, Andrea Arcuri, Yonggang Li, Yang
    Liu, and Kaiming Xue. 2023. White-Box Fuzzing RPC-Based APIs with EvoMaster: An
    Industrial Case Study. ACM Trans. Softw. Eng. Methodol. 32, 5, Article 122 (jul
    2023), 38 pages. [https:](https://doi.org/10.1145/3585009) [//doi.org/10.1145/3585009](https://doi.org/10.1145/3585009)

    - <span id="page-11-5"></span>[52] Man Zhang, Andrea Arcuri, Yonggang Li, Kaiming
    Xue, Zhao Wang, Jian Huo, and Weiwei Huang. 2022. Fuzzing Microservices In Industry:
    Experience of Applying EvoMaster at Meituan. arXiv[:2208.03988](https://arxiv.org/abs/2208.03988)
    [cs.SE]

    - <span id="page-11-10"></span>[53] Zelin Zhao, Xizao Wang, Zhaogui Xu, Zhenhao
    Tang, Yongchao Li, and Peng Di. 2023. Incremental Call Graph Construction in Industrial
    Practice. In 2023 IEEE/ACM 45th International Conference on Software Engineering:
    Software Engineering in Practice (ICSE-SEIP). IEEE, 471–482.

    - <span id="page-11-9"></span>[54] Hua Zhong, Lingming Zhang, and Sarfraz Khurshid.
    2019. TestSage: Regression Test Selection for Large-Scale Web Service Testing.
    In 2019 12th IEEE Conference on Software Testing, Validation and Verification
    (ICST). 430–440. [https://doi.org/](https://doi.org/10.1109/ICST.2019.00052) [10.1109/ICST.2019.00052](https://doi.org/10.1109/ICST.2019.00052)

    - <span id="page-11-6"></span>[55] Zexin Zhong, Jiangchao Liu, Diyu Wu, Peng Di,
    Yulei Sui, Alex X. Liu, and John C. S. Lui. 2023. Scalable Compositional Static
    Taint Analysis for Sensitive Data Tracing on Industrial Micro-Services. In 2023
    IEEE/ACM 45th International Conference on Software Engineering: Software Engineering
    in Practice (ICSE-SEIP). 110–121.<https://doi.org/10.1109/ICSE-SEIP58684.2023.00015>

    - <span id="page-11-17"></span>[56] Xu Zhou, Pengfei Wang, Chenyifan Liu, Tai
    Yue, Yingying Liu, Congxi Song, Kai Lu, and Qidi Yin. 2020. UniFuzz: Optimizing
    Distributed Fuzzing via Dynamic Centralized Task Scheduling. ArXiv abs/2009.06124
    (2020). [https:](https://api.semanticscholar.org/CorpusID:221655823) [//api.semanticscholar.org/CorpusID:221655823](https://api.semanticscholar.org/CorpusID:221655823)

    - <span id="page-11-13"></span>[57] Peiyuan Zong, Tao Lv, Dawei Wang, Zizhuang
    Deng, Ruigang Liang, and Kai Chen. 2020. FuzzGuard: Filtering out Unreachable
    Inputs in Directed Grey-box Fuzzing through Deep Learning. In 29th USENIX Security
    Symposium (USENIX Security 20). USENIX Association, 2255–2269. [https://www.usenix.org/conference/](https://www.usenix.org/conference/usenixsecurity20/presentation/zong)
    [usenixsecurity20/presentation/zong](https://www.usenix.org/conference/usenixsecurity20/presentation/zong)'
- title: Optimistic Prediction of Synchronization-Reversal Data Races
  abstract: "Dynamic data race detection has emerged as a key technique for ensuring\n\
    reliability of concurrent software in practice. However, dynamic approaches can\n\
    often miss data races owing to nondeterminism in the thread scheduler.\nPredictive\
    \ race detection techniques cater to this shortcoming by inferring\nalternate\
    \ executions that may expose data races without re-executing the\nunderlying program.\
    \ More formally, the dynamic data race prediction problem\nasks, given a trace\
    \ \\sigma of an execution of a concurrent program, can \\sigma\nbe correctly reordered\
    \ to expose a data race? Existing state-of-the art\ntechniques for data race prediction\
    \ either do not scale to executions arising\nfrom real world concurrent software,\
    \ or only expose a limited class of data\nraces, such as those that can be exposed\
    \ without reversing the order of\nsynchronization operations.\n  In general, exposing\
    \ data races by reasoning about synchronization reversals\nis an intractable problem.\
    \ In this work, we identify a class of data races,\ncalled Optimistic Sync(hronization)-Reversal\
    \ races that can be detected in a\ntractable manner and often include non-trivial\
    \ data races that cannot be\nexposed by prior tractable techniques. We also propose\
    \ a sound algorithm OSR\nfor detecting all optimistic sync-reversal data races\
    \ in overall quadratic\ntime, and show that the algorithm is optimal by establishing\
    \ a matching lower\nbound. Our experiments demonstrate the effectiveness of OSR\
    \ on our extensive\nsuite of benchmarks, OSR reports the largest number of data\
    \ races, and scales\nwell to large execution traces."
  url: http://arxiv.org/abs/2401.05642v1
  keywords: ''
  document: "# Optimistic Prediction of Synchronization-Reversal Data Races\n\n[Zheng\
    \ Shi](https://orcid.org/0000-0001-5021-7134) National University of Singapore\
    \ Singapore, Singapore shizheng@u.nus.edu\n\n[Umang Mathur](https://orcid.org/0000-0002-7610-0660)\
    \ National University of Singapore Singapore, Singapore umathur@comp.nus.edu.sg\n\
    \n[Andreas Pavlogiannis](https://orcid.org/0000-0002-8943-0722) Aarhus University\
    \ Aarhus, Denmark pavlogiannis@cs.au.dk\n\n# ABSTRACT\n\nDynamic data race detection\
    \ has emerged as a key technique for ensuring reliability of concurrent software\
    \ in practice. However, dynamic approaches can often miss data races owing to\
    \ nondeterminism in the thread scheduler. Predictive race detection techniques\
    \ cater to this shortcoming by inferring alternate executions that may expose\
    \ data races without re-executing the underlying program. More formally, the dynamic\
    \ data race prediction problem asks, given a trace of an execution of a concurrent\
    \ program, can be correctly reordered to expose a data race? Existing state-of-the\
    \ art techniques for data race prediction either do not scale to executions arising\
    \ from real world concurrent software, or only expose a limited class of data\
    \ races, such as those that can be exposed without reversing the order of synchronization\
    \ operations.\n\nIn general, exposing data races by reasoning about synchronization\
    \ reversals is an intractable problem. In this work, we identify a class of data\
    \ races, called Optimistic Sync(hronization)-Reversal races that can be detected\
    \ in a tractable manner and often include non-trivial data races that cannot be\
    \ exposed by prior tractable techniques. We also propose a sound algorithm OSR\
    \ for detecting all optimistic sync-reversal data races in overall quadratic time,\
    \ and show that the algorithm is optimal by establishing a matching lower bound.\
    \ Our experiments demonstrate the effectiveness of OSR— on our extensive suite\
    \ of benchmarks, OSR reports the largest number of data races, and scales well\
    \ to large execution traces.\n\n#### ACM Reference Format:\n\nZheng Shi, Umang\
    \ Mathur, and Andreas Pavlogiannis. 2024. Optimistic Prediction of Synchronization-Reversal\
    \ Data Races. In Proceedings of International Conference on Software Engineering\
    \ (ICSE '24). ACM, New York, NY, USA, [28](#page-27-0) pages.<https://doi.org/10.1145/nnnnnnn.nnnnnnn>\n\
    \n#### <span id=\"page-0-1\"></span>1 INTRODUCTION\n\nConcurrency bugs such as\
    \ data races and deadlocks often escape in-house testing and manifest only in\
    \ production [\\[19,](#page-11-0) [59\\]](#page-12-0), making the development\
    \ of reliable concurrent software a challenging task. Automated data race detection\
    \ has emerged as a first line of defense against undesired behaviors caused by\
    \ data races, has been actively studied over multiple decades, and is also the\
    \ subject of this paper. In particular, our focus is on dynamic analyses, which,\
    \ unlike static\n\nICSE '24, April 12–21, 2024, Lisbon, Portugal\n\n© 2024 Association\
    \ for Computing Machinery.\n\nACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . \\$15.00\n\
    \n<https://doi.org/10.1145/nnnnnnn.nnnnnnn>\n\n<span id=\"page-0-0\"></span>![](_page_0_Figure_16.jpeg)\n\
    \nFigure 1: The two conflicting events <sup>1</sup> = ⟨1, w()⟩ and <sup>12</sup>\
    \ = ⟨4, w()⟩ is a predictable data race of <sup>1</sup> which is also an optimistic\
    \ sync-reversal race, witnessed by the correct reordering <sup>1</sup> that reverses\
    \ critical sections.\n\ntechniques, are the preferred class of techniques for\
    \ detecting data races for industrial scale software applications [\\[59\\]](#page-12-0).\n\
    \nA dynamic data race detector observes an execution of a concurrent program and\
    \ infers the presence of a data race by analysing the trace of the observed execution.\
    \ A key challenge in the design of such a technique is sensitivity to non-deterministic\
    \ thread schedules — even for a fixed program input, a data race may be observed\
    \ under a very specific thread schedule, but not under other thread schedules.\
    \ This means that a simplistic race detector that, say, only checks for two conflicting\
    \ events appearing simultaneously in the execution trace, is likely going to miss\
    \ many bugs. This is where predictive analysis techniques shine — instead of looking\
    \ for bugs only in the execution that was observed, they additionally also detect\
    \ bugs in executions that, while not explicitly observed during testing, can nevertheless\
    \ be inferred from the observed execution, without rerunning the underlying program\
    \ [\\[31,](#page-11-1) [34,](#page-11-2) [45,](#page-11-3) [57,](#page-12-1) [60,](#page-12-2)\
    \ [65\\]](#page-12-3). Predictive techniques identify the space of executions\
    \ or reorderings that can provably be inferred from a given observed execution\
    \ , and then look for a reordering in this space, that can serve as a witness\
    \ to a bug such as a data race. Consider the execution 1 in Figure [1a](#page-0-0)\
    \ consisting of events 1, 2, . . . , <sup>12</sup> where denotes the th event\
    \ from the top. The two write events on variable , 1 and 12, are far apart and\
    \ not witnessed as a data race in 1. However, the correct reordering 1 of 1, in\
    \ which the two write events appear consecutively, shows that it is nevertheless,\
    \ a predictable data race of 1. Indeed any program that generates <sup>1</sup>\
    \ will also generate 1 albeit with a different thread interleaving.\n\nIn general,\
    \ sound (no false positives) and complete (no false negatives) data race prediction\
    \ is known to be an intractable problem [\\[44\\]](#page-11-4). Soundness is a\
    \ key desired property, since false positives need to be otherwise vetted manually,\
    \ a task which is particularly challenging in the case of concurrent programs.\
    \ Consequently,\n\nPermission to make digital or hard copies of all or part of\
    \ this work for personal or classroom use is granted without fee provided that\
    \ copies are not made or distributed for profit or commercial advantage and that\
    \ copies bear this notice and the full citation on the first page. Copyrights\
    \ for components of this work owned by others than ACM must be honored. Abstracting\
    \ with credit is permitted. To copy otherwise, or republish, to post on servers\
    \ or to redistribute to lists, requires prior specific permission and/or a fee.\
    \ Request permissions from permissions@acm.org.\n\nmany recent works counter the\
    \ intractability by proposing incomplete (but nevertheless sound) predictive race\
    \ detection algorithms that work in polynomial time and have high precision in\
    \ practice. The main contribution of this paper is a new race prediction algorithm\
    \ OSR that is sound, has higher prediction power than prior algorithms and achieves\
    \ high scalability in practice.\n\nThe design of our algorithm OSR stems from\
    \ the observation that often, data races can be exposed only by inverting the\
    \ relative order of (some pairs of) critical sections, or synchronizations. The\
    \ data race (1, 12) in Figure [1a,](#page-0-0) for instance, can in fact only\
    \ be observed in correct reorderings that invert the order of the two critical\
    \ sections on lock ℓ. However, reversing synchronization (lock/unlock) operations\
    \ in the reordering can further force a reversal in the order in which memory\
    \ access events must appear in the reordering, and can be intractable to reason\
    \ about [\\[44,](#page-11-4) [45\\]](#page-11-3). This strong tradeoff between\
    \ precision (obtained by virtue of reversing the order of many synchronization\
    \ operations) and performance has materialized on both the extremes. Algorithms\
    \ such as those based on the happens-before partial order [\\[42,](#page-11-5)\
    \ [55\\]](#page-12-4) or the recently proposed SyncP [\\[45\\]](#page-11-3) run\
    \ in linear time but fail to expose races that mandate reasoning about synchronization\
    \ reversals. On the other extreme, methods that exhaustively search for reversals,\
    \ either resort to expensive constraint solving [\\[31,](#page-11-1) [60\\]](#page-12-2)\
    \ or saturation style reasoning [\\[18,](#page-11-6) [54\\]](#page-12-5), and\
    \ do not scale to long execution traces observed in real world concurrent applications.\
    \ Our proposed algorithm OSR aims to strike a balance — it is designed to optimistically\
    \ reason about synchronization reversals, and identifies those reversals that\
    \ do not lead to the reversal of memory operations. The pair (1, 12) in Figure\
    \ [1](#page-0-0) is an example of a race that OSR reports.\n\nOSR reports all\
    \ optimistic synchronization-reversal races in overall time e(N<sup>2</sup> ),\
    \ spending e(N ) time for processing each event in the given execution trace .\
    \ Here, N is the number of events in and <sup>e</sup> hides polynomial multiplicative\
    \ factors due to number of locks and threads which are typically considered constants.\
    \ In order to check for the absence of memory reversals, OSR constructs a graph\
    \ (optimistic reordering graph) of events and checks if it is acyclic. Naively,\
    \ such an acyclicity check would take e(N ) time for every pair of conflicting\
    \ events, resulting in a total cubic running time. A key technical contribution\
    \ of our work is to perform this check in amortized constant time by constructing\
    \ a succinct representation of this graph, called abstract optimistic reordering\
    \ graph, of constant size. We show that this abstract graph preserves acyclicity,\
    \ and can be constructed in an incremental manner in amortized constant time,\
    \ allowing us to perform race prediction for the entire input execution in overall\
    \ quadratic (instead of cubic) time. Finally, we show that the problem of checking\
    \ the existence of an optimistic sync-reversal race also admits a matching quadratic\
    \ time lower bound, thereby implying that our algorithm is optimal.\n\nWe implemented\
    \ OSR and evaluate its performance thoroughly. Our evaluation demonstrates the\
    \ effectiveness of our algorithm on a comprehensive suite of 153 Java and C/C++\
    \ benchmarks derived from real-world programs. Our results show OSR has comparable\
    \ scalability as linear time algorithms SyncP and WCP, while it reports significantly\
    \ more races than the second most predictive one on many benchmarks, confirming\
    \ our hypothesis that going beyond the principle of synchronisation preservation\
    \ allows us\n\nto discover significantly more races and with better performance.\
    \ OSR, thus, advances the state-of-the-art in sound predictive race detection.\n\
    \nThe rest of the paper is organized as follows. In Section [2,](#page-1-0) we\
    \ discuss relevant background. In Section [3,](#page-3-0) we formally define the\
    \ notion of optimistic sync-reversal races, and present our algorithm OSR for\
    \ detecting all optimistic sync-reversal races in Section [4.](#page-4-0) Our\
    \ evaluation of OSR and its comparison with other race prediction algorithms is\
    \ presented in Section [5.](#page-7-0) In Section [6](#page-8-0) we discuss related\
    \ work and conclude in Section [7.](#page-10-0)\n\n#### <span id=\"page-1-0\"\
    ></span>2 PRELIMINARIES\n\nIn this section, we discuss preliminary notation and\
    \ the formal definition of the problem of dynamic data race prediction. Next,\
    \ we briefly recall the notion of sync-preserving data races [\\[45\\]](#page-11-3)\
    \ and discuss some of the limitations of this notion, paving the way to our algorithm\
    \ OSR.\n\nTrace and events. An execution trace (or simply trace) of a concurrent\
    \ program is a sequence of events = 1<sup>2</sup> . . . N. An event is a tuple\
    \ = ⟨, , ⟩, where is a unique identifier for , is the thread that performs and\
    \ is the operation corresponding to ; often the identifier will be clear from\
    \ context and we will drop it. We use th() and op() to denote the thread and operation\
    \ of . Operations are r(), w() (read or write access of memory location or variable\
    \ ) or acq(ℓ), rel(ℓ) (acquire or release of lock ℓ); fork and join operations\
    \ are omitted from presentation but not from our implementation. For a trace ,\
    \ we will use Events(), Threads(), Vars(), Locks() to denote respectively the\
    \ set of all events, threads, variables and locks appearing in .\n\nWell-formedness.\
    \ We assume that traces are well-formed, in that they do not violate lock semantics.\
    \ In particular, for a well formed trace , we require that for each lock ℓ ∈ Locks(),\
    \ the sequence of operations on ℓ alternate between acquires and releases, where\
    \ each release event is preceded by a matching acquire event of the same thread.\
    \ For an acquire (resp. release) event , we use the notation match () to denote\
    \ the matching release (resp. acquire) event of in if one exists; otherwise we\
    \ say match () = ⊥.\n\nTrace order, thread order and reads-from. The trace order\
    \ ≤ tr of a trace is the total order induced by the sequence of events in , i.e.,\
    \ <sup>1</sup> ≤ tr <sup>2</sup> iff either <sup>1</sup> <sup>=</sup> <sup>2</sup>\
    \ or <sup>1</sup> appears earlier than <sup>2</sup> in . The thread order ≤ TO\
    \ is a partial order on Events() such that for any two events 1, 2, we have <sup>1</sup>\
    \ ≤ TO <sup>2</sup> iff th(1) <sup>=</sup> th(2) and <sup>1</sup> ≤ tr 2. When\
    \ looking for predictable data races, we often look for reorderings of a given\
    \ trace that preserve its control flow, and determine this using the reads-from\
    \ function. For a read event ∈ Events() with op() = r() for some variable , the\
    \ writer of , denoted = rf () is the last write event on before , i.e., op() =\
    \ w(), ≤ tr and ¬(∃ ′ ≠ , op( ′ ) = w() ∧ ≤ tr ′ ≤ tr ). Without loss of generality,\
    \ we will assume that rf () is always defined for each read event . Given a set\
    \ ⊆ Events(), we say that is (≤ TO,rf )-closed if (a) for all events 1, <sup>2</sup>\
    \ ∈ Events() if (<sup>1</sup> ≤ TO 2∧<sup>2</sup> <sup>∈</sup> ), then <sup>1</sup>\
    \ <sup>∈</sup> , and (b) for all events ∀1, <sup>2</sup> ∈ Events(), if (<sup>1</sup>\
    \ = rf (2) ∧ <sup>2</sup> ∈ ), then <sup>1</sup> ∈ . We use TRClosure(S) to denote\
    \ the smallest set ′ such that ⊆ ′ and ′ is (≤ TO,rf )-closed.\n\n<span id=\"\
    page-2-0\"></span>![](_page_2_Figure_1.jpeg)\n\n2 Figure 2: The two write events\
    \ <sup>1</sup> = ⟨1, w()⟩ and <sup>5</sup> = ⟨2, w()⟩ in <sup>2</sup> are conflicting.\
    \ (1, 5) is not a data race but a predictable data race of 2, witnessed by correct\
    \ reorderings <sup>2</sup> and ′ 2 .\n\nCorrect reordering. Predictive race detection,\
    \ given a trace , asks if an alternate execution trace witnesses a data race,\
    \ and more importantly, can be inferred from . The notion of correct reorderings\
    \ precisely formalizes this. Given well-formed traces and , with Events() ⊆ Events(),\
    \ we say that is a correct reordering of if respects the thread order and reads-from\
    \ relations of . This means that (1) Events() is (≤ TO,rf )-closed, (2) for any\
    \ two events 1, <sup>2</sup> ∈ Events(), if <sup>1</sup> ≤ TO 2, then <sup>1</sup>\
    \ <sup>≤</sup> TO 2, and (3) for any two events 1, <sup>2</sup> ∈ Events(), if\
    \ <sup>1</sup> = rf (2), then <sup>1</sup> = rf (2).\n\nData races and predictable\
    \ data races. A pair of events (, ′ ) in is said to be a conflicting pair, denoted\
    \ ⊲⊳ ′ , if both are access events to the same variable, and at least one of them\
    \ is a write event, i.e., (op(), op( ′ )) ∈ {(w(), w()), (w(), r()), (r(), w())}\
    \ for some ∈ Vars(). For a trace with Events() ⊆ Events(), we say that event is\
    \ -enabled in if ∉ Events() but all threadpredecessors of are in , i.e., { ′ ∈\
    \ Events() | ′ ≠ , ′ ≤ TO } ⊆ Events(). A conflicting pair (, ′ ) is said to be\
    \ a data race of if there is a prefix of such that both and ′ are -enabled in\
    \ . Finally, a conflicting pair (, ′ ) is a predictable data race of if there\
    \ is a correct reordering of such that both and ′ are -enabled in some prefix\
    \ of . In this case, we say that witnesses the data race (, ′ ).\n\n<span id=\"\
    page-2-1\"></span>Example 1. Consider trace <sup>2</sup> in Figure [2a](#page-2-0)\
    \ containing 6 events performed by two threads <sup>1</sup> and 2. As before,\
    \ we use to denote the th event of 2. The two events <sup>1</sup> <sup>=</sup>\
    \ ⟨1, w()⟩ and <sup>5</sup> <sup>=</sup> ⟨2, w()⟩ are conflicting (i.e., <sup>1</sup>\
    \ ⊲⊳ 5). The pair (1, 5) is not a data race in 2 as no prefix of 2 has both these\
    \ events simultaneously enabled. Consider the trace <sup>2</sup> in Figure [2b;](#page-2-0)\
    \ it is a correct reordering of <sup>2</sup> because it preserves both the thread\
    \ order and reads-from relation of 2. For the same reason, ′ 2 is a correct reordering\
    \ of 2 (and also of 2). Now, observe that (1, 5) is a data race in <sup>2</sup>\
    \ (and also in ′ 2 ) because in the prefix = ⟨2, acq(ℓ)⟩, both <sup>1</sup> and\
    \ <sup>5</sup> are 2-enabled (resp. ′ 2 -enabled) and thus 2-enabled. Thus, while\
    \ (1, 5) is not a data race in 2, it is a predictable data race of 2.\n\nThe problem\
    \ of predicting data races — given an execution trace , determine if there is\
    \ a predictable data race of — has been studied before [\\[31,](#page-11-1) [34,](#page-11-2)\
    \ [54,](#page-12-5) [57,](#page-12-1) [60,](#page-12-2) [65\\]](#page-12-3) and\
    \ is known to be an intractable problem [\\[44\\]](#page-11-4). This means that\
    \ any sound and complete algorithm for predicting data races is unlikely to scale\
    \ to real world software applications whose execution traces can have billions\
    \ of events. To cater to this, practical data race predictors resort to incomplete\
    \ but\n\nsound algorithms that run in polynomial time. In the next section, we\
    \ discuss the recently proposed SyncP algorithm that employs the principle of\
    \ synchronization preservation for predicting data races whose theoretical complexity\
    \ is linear.\n\n#### 2.1 Sync-Preserving Data Races\n\nOur work is closer in spirit\
    \ to the work of [\\[45\\]](#page-11-3) which presents the SyncP algorithm that\
    \ works in linear time and is the current state-of-the-art race prediction algorithm.\
    \ The principle employed by SyncP is to focus on a special class of reorderings\
    \ and the data races witnessed by such reorderings; we discuss these next.\n\n\
    Sync-preserving reorderings and data races. A correct reordering of a trace is\
    \ said to be sync(hronization)-preserving if for any two critical sections of\
    \ (on the same lock) that are both present in , their relative order is the same,\
    \ That is, for every lock ℓ ∈ Locks() and for any two acquire events 1, <sup>2</sup>\
    \ ∈ Events() such that op(1) = op(2) = acq(ℓ), if 1, <sup>2</sup> ∈ Events(),\
    \ then we have: <sup>1</sup> ≤ tr <sup>2</sup> iff <sup>1</sup> <sup>≤</sup> tr\
    \ 2. A pair of conflicting events (, ′ ) in Events() is said to be a sync-preserving\
    \ data race of if there is a sync-preserving correct reordering of that witnesses\
    \ this race.\n\nExample 2. Consider again, the trace <sup>2</sup> and recall from\
    \ Example [1](#page-2-1) that the pair (1, 5) is not a data race of <sup>2</sup>\
    \ but a predictable race witnessed by the correct reordering 2. Observe however\
    \ that 2 is not a sync-preserving reordering of 2 because it flips the order of\
    \ the two critical sections on lock ℓ. Nevertheless, (1, 5) is a syncpreserving\
    \ race of 2. This is because the reordering ′ 2 is, in fact, a sync-preserving\
    \ reordering of <sup>2</sup> (even though it is a prefix of the non-sync-preserving\
    \ reordering 2); there is only one critical section in ′ 2 and thus vacuously,\
    \ the relative order on critical sections is the same as in 2.\n\nLimited predictive\
    \ power of SyncP. While the SyncP algorithm runs in overall linear time, it can\
    \ miss data races which are not synchronization-preserving. These are precisely\
    \ those conflicting pairs (, ′ ) such that any correct reordering that witnesses\
    \ a race on and ′ necessarily reverses the relative order of two critical sections\
    \ on a common lock. We illustrate this next, and remark that, in general, reasoning\
    \ about even a single reversal is intractable [\\[45\\]](#page-11-3).\n\n<span\
    \ id=\"page-2-2\"></span>Example 3. Let us again consider the trace in Figure\
    \ [1a](#page-0-0) (Section [1\\)](#page-0-1). The two conflicting events <sup>1</sup>\
    \ = ⟨1, w()⟩ and <sup>12</sup> = ⟨4, w()⟩, are a predictable data race of <sup>1</sup>\
    \ as witnessed by the correct reordering 1 in Figure [1b,](#page-0-0) which is\
    \ not a sync-preserving correct reordering of 1. In fact, consider any correct\
    \ reordering of <sup>1</sup> that witnesses the race (1, 12). Then must include\
    \ the events 10 and 11, and thus the corresponding write events 4 and 8, together\
    \ with the thread predecessors <sup>3</sup> = ⟨2, acq(ℓ)⟩ and <sup>7</sup> = ⟨3,\
    \ acq(ℓ)⟩. Next, for well-formedness, at least one of the matching releases <sup>6</sup>\
    \ = ⟨2,rel(ℓ)⟩ as well as <sup>9</sup> = ⟨3,rel(ℓ)⟩ must also be present in .\
    \ However, including <sup>6</sup> in would enforce that <sup>5</sup> = ⟨2,r()⟩,\
    \ and its write event <sup>2</sup> = ⟨1, w()⟩ are present in , and then, the event\
    \ <sup>1</sup> must also be present in the reordering making it no longer enabled\
    \ in . This, therefore, means that <sup>6</sup> ∉ Events(), and thus, the only\
    \ other available release event <sup>9</sup> must be present in (for well-formedness).\
    \ Further, to ensure well-formedness, 3 must appear after 9 in . Thus, any reordering\n\
    \n witnessing the race between 1and 12 must reverse the order of the critical\
    \ sections.\n\n#### <span id=\"page-3-0\"></span>3 OPTIMISTIC REASONING FOR REVERSALS\n\
    \nGiven that reasoning about synchronization reversals is computationally hard,\
    \ how do we identify such races efficiently? At a high level, the intractability\
    \ in data race prediction arises because a search for a correct reordering entails\
    \ (1) a search for an appropriate set of events (amongst exponentially many sets)\
    \ and further, (2) given an appropriate set of events, a search for a linear order\
    \ (amongst exponentially many linear orders) on this set which is well-formed,\
    \ is a correct reordering and witnesses the race. We propose (1) a new notion\
    \ of data races called optimistic sync(hronization) reversal races which can be\
    \ predicted by opting for an optimistic approach to resolve both these steps,\
    \ and (2) an algorithm OSR to detect all such data races in e(N<sup>2</sup> )\
    \ time. In this section, we discuss this notion of data races and discuss our\
    \ algorithm in Section [4.](#page-4-0)\n\n#### 3.1 Optimistic Sync-Reversal Races\n\
    \nA crucial aspect of choosing the correct set of events is to ensure that multiple\
    \ acquire events on the same lock do not stay unmatched; otherwise, the set cannot\
    \ be linearized to a well-formed trace. In general, adding a matching release\
    \ event may lead to recursive addition of further events. Some choices may (recursively)\
    \ at times lead to the addition of one of the two focal events , ′ (candidate\
    \ data race), leading to them being no longer enabled. We define a simple and\
    \ tractable notion of optimistic lock-closure, which, instead of considering all\
    \ choices, simply includes all matching release events as long as the two focal\
    \ events are not included. In the following, we fix a trace .\n\nOptimistic lock-closure.\
    \ Let 1, <sup>2</sup> ∈ Events(). We say that a set ⊆ Events() is optimistically\
    \ lock-closed with respect to (1, 2) if (a) 1, <sup>2</sup> ∉ and prev (1), prev\
    \ (2) ∈ , (b) is (≤ TO,rf )-closed, and (c) for every acquire event <sup>∈</sup>\
    \ , if 1, <sup>2</sup> <sup>∉</sup> TRClosure(match (a)), then match () ∈ . We\
    \ denote the smallest set that contains and is optimistically lock-closed set,\
    \ as OLClosure(S, e1, e2)\n\n<span id=\"page-3-2\"></span>Example 4. Let us recall\
    \ trace <sup>1</sup> from Figure [1](#page-0-0) and consider the set <sup>1</sup>\
    \ = {3, 4, 7, 8, 9, 10, 11}. Observe that <sup>1</sup> is optimistically lock-closed\
    \ with respect to (1, 12), because (1) <sup>1</sup> doesn't include either of\
    \ 1, 12, (2) <sup>1</sup> is (≤ TO,rf )-closed, and finally, (3) 1, <sup>12</sup>\
    \ ∉ TRClosure(e9). Note that <sup>1</sup> ∈ TRClosure(e6) but <sup>6</sup> ∉ 1.\n\
    \nEven though the notion of optimistically lock-closed set is simple, in general,\
    \ checking if such a set can be linearized into a correct reordering that witnesses\
    \ a data race, is an intractable problem, as we show next (Theorem [3.1\\)](#page-3-1).\n\
    \n<span id=\"page-3-1\"></span>Theorem 3.1. Let be a trace, let 1, <sup>2</sup>\
    \ be conflicting events and let ⊆ Events() be an optimistically lock-closed set\
    \ with respect to (1, 2). The problem of determining whether there is a correct\
    \ reordering such that Events() = is NP-hard.\n\nThe proof of Theorem [3.1](#page-3-1)\
    \ is presented in appendix [A.1.](#page-13-0) Given the above result, we also\
    \ define the following more tractable notion of optimistic reordering that ensures\
    \ that there are no memory reversals, and moreover, critical sections are reversed\
    \ only when absolutely required, i.e., that unmatched critical sections appear\
    \ later than matched ones.\n\nOptimistic correct reordering. A trace is said to\
    \ be an optimistic correct reordering of if (a) is a correct reordering of , (b)\
    \ for all pairs of conflicting memory access events <sup>1</sup> ⊲⊳ <sup>2</sup>\
    \ in Events(), 1 ≤ tr <sup>2</sup> iff <sup>1</sup> <sup>≤</sup> tr 2, and (c)\
    \ for any lock <sup>ℓ</sup> and for any two acquire events <sup>1</sup> ≠ <sup>2</sup>\
    \ (with op(1) = op(2) = acq(ℓ)), if <sup>1</sup> and <sup>2</sup> are both matched\
    \ in (i.e., match () ∈ Events() for both ∈ {1, 2}), then we must have <sup>1</sup>\
    \ ≤ tr <sup>2</sup> iff <sup>1</sup> <sup>≤</sup> tr 2.\n\nWe now formalize optimistic\
    \ sync-reversal data races.\n\n<span id=\"page-3-4\"></span>Definition 1 (Optimistic\
    \ Sync-Reversal Race). Let be a trace and let (1, 2) be a pair of conflicting\
    \ events in . We say that (1, 2) is an optimistic sync-reversal data race if there\
    \ is an optimistic correct reordering of such that Events() is optimistically\
    \ lock-closed with respect to (1, 2) and both <sup>1</sup> and <sup>2</sup> are\
    \ -enabled in .\n\n<span id=\"page-3-3\"></span>Example 5. In Figure [1,](#page-0-0)\
    \ the pair (1, 12) is an optimistic syncreversal race, because the prefix ′ <sup>1</sup>\
    \ with first 7 events of <sup>1</sup> is an optimistic reordering of the optimistically\
    \ lock closed set 1, outlined in Example [4,](#page-3-2) (in which 1 and 12 are\
    \ 1-enabled). This is because, all conflicting accesses of ′ 1 have the same relative\
    \ order as in 1, and further, the unmatched acquire event is positioned after\
    \ all closed critical sections. Similarly, for the trace 2 of Figure [2,](#page-2-0)\
    \ the linearization ′ 2 = ⟨2, acq(ℓ)⟩ of the set <sup>2</sup> (outlined in Example\
    \ [4\\)](#page-3-2) is trivially an optimistic correct reordering.\n\n#### 3.2\
    \ Comparison with other techniques\n\nHere, we qualitatively compare our proposed\
    \ class of races with those reported by other sound predictive race detection\
    \ techniques proposed in the literature, namely SyncP [\\[45\\]](#page-11-3) and\
    \ M2 [\\[54\\]](#page-12-5) and illustrate how the set of races reported by OSR\
    \ is neither a strict subset, nor a strict super set of those detected by each.\n\
    \nExample 6. Recall again the execution trace <sup>1</sup> in Figure [1.](#page-0-0)\
    \ In Example [5](#page-3-3) we established that the pair (1, 12) is an optimistic\
    \ sync-reversal race, while in Example [3,](#page-2-2) we showed that it is not\
    \ a sync-preserving data race. When determining if (1, 12) can be declared a predictive\
    \ data race, the M2 algorithm computes the set = {1, 2, 3, 4, 5, 6, 7, 8, 10,\
    \ 11} to be the candidate set that witnesses the race. Observe however, this set\
    \ contains the event 1 and thus cannot witness the race (1, 12) since one of these\
    \ events is not enabled in . Thus, some optimistic sync-reversal races are neither\
    \ sync-preserving races, nor can be detected by M2.\n\nExample 7. Consider the\
    \ trace in Figure [3a.](#page-4-1) The pair (1, 21) is a sync-preserving data\
    \ race as witnessed by the correct reordering shown in Figure [3b.](#page-4-1)\
    \ This pair, however is not an optimistic syncreversal data race since the smallest\
    \ optimistically lock-closed set capable of witnessing the race is the set OSR\
    \ = {[3,9] , [12,14] , 17,20}, where , is shorthand for , +1, . . . , −1, . Observe\
    \ that OSRcontains two unmatched acquire events of lock ℓ2, and adding either\
    \ matching release will bring 1 in the set. Likewise, M2 computes the set containing\
    \ all events but 21, and thus contains 1. Thus, there are sync-preserving races\
    \ which are neither optimistic sync-reversal races, nor can be detected by M2.\n\
    \nExample 8. Finally, consider the trace in Figure [3c,](#page-4-1) derived from\
    \ [\\[54\\]](#page-12-5). Here, the pair (10, 19) is a data race that M2 can predict\n\
    \n<span id=\"page-4-1\"></span>![](_page_4_Figure_2.jpeg)\n\nFigure 3: Two traces\
    \ containing two predictable races. One of them (a) can be detected by SyncP,\
    \ but not M2 nor OSR. (b) is the witness of race in (a). The other one (c) can\
    \ be detected by M2, but not SyncP nor OSR. Trace in (c) is directly cited from\
    \ M2 paper [\\[54\\]](#page-12-5) without modification. (d) is the witness of\
    \ race in (c).\n\n(also see Figure [3d](#page-4-1) for the witnessing execution).\
    \ We remark that any correct reordering witnessing this race must reverse the\
    \ order of the two acquire events <sup>8</sup> and 13, as well as the order of\
    \ conflicting memory access events 9 and 14. Consequently, this is an example\
    \ of a race reported by M2 that is neither a sync-preserving race, nor an optimistic\
    \ sync-reversal race.\n\n### <span id=\"page-4-0\"></span>4 THE OSR ALGORITHM\n\
    \nWe now describe our algorithm OSR that detects optimistic syncreversal data\
    \ races. For ease of presentation, we will first discuss how to check if a given\
    \ pair (1, 2) of conflicting events is an optimistic sync-reversal data race (Section\
    \ [4.1\\)](#page-4-2), ine(N ) time, where N is the number of events in the given\
    \ trace. Naively, it can be used to report all optimistic sync-reversal data races\
    \ in e(N<sup>3</sup> ) time, by enumerating all (N<sup>2</sup> ) pairs of conflicting\
    \ events and checking each of them in e(N ) time. Instead, OSR runs in overall\
    \ e(N<sup>2</sup> ) time and is based on interesting insights that enable it to\
    \ perform incremental computation over the entire trace (Section [4.2\\)](#page-5-0).\
    \ We present our overall algorithm and its optimality in Section [4.3.](#page-7-1)\n\
    \n#### <span id=\"page-4-2\"></span>4.1 Checking Race On A Given Pair Of Events\n\
    \nBased on Definition [1,](#page-3-4) the task of checking if a given pair (1,\
    \ 2) of conflicting events is an optimistic sync-reversal data race entails examining\
    \ all optimistic lock-closed sets and checking if any of these can be linearized.\n\
    \nConstructing optimistically lock-closed set. Our algorithm, however, exploits\
    \ the following observation (Lemma [4.1\\)](#page-4-3), and focuses on only a\
    \ single set, namely the smallest such set. In the following, we will abuse the\
    \ notation and use OLClosure(e1, e2) to denote the set OLClosure(Se1,e<sup>2</sup>\
    \ , e1, e2), where 1,<sup>2</sup> = {prev (1)} ∪ {prev (2)}. Here, prev () is\
    \ the last event such that ≤ TO ; if no such event exists, we say prev () = ⊥,\
    \ in which case {prev ()} = ∅.\n\n<span id=\"page-4-3\"></span>Lemma 4.1. Let\
    \ 1, <sup>2</sup> be conflicting events in trace . If (1, 2) is an optimistic\
    \ sync-reversal race, then it can be witnessed in an optimistic correct reordering\
    \ such that Events() = OLClosure(e1, e2).\n\n<span id=\"page-4-4\"></span>\n\n\
    | Algorithm 1: Computing optimistic lock closure |                           \
    \                                  |  |  |  |  |\n|------------------------------------------------|-------------------------------------------------------------|--|--|--|--|\n\
    | 1 procedure ComputeOLClosure(\U0001D4460,<br>\U0001D4521,\U0001D4522)     |\
    \                                                             |  |  |  |  |\n\
    | 2                                              | \U0001D446<br>← \U0001D446\
    0∪TRClosure(prev\U0001D70E<br>(e1))∪TRClosure(prev\U0001D70E<br>(e2)) |  |  |\
    \  |  |\n| 3                                              | while \U0001D446<br>changes\
    \ do                                       |  |  |  |  |\n| 4                \
    \                              | ∃\U0001D44E<br>∈ Acqs(S),<br>(\U0001D44E)<br>∉\
    \ \U0001D446<br>if<br>∧<br>match\U0001D70E         |  |  |  |  |\n|          \
    \                                      | \U0001D4521, \U0001D4522<br>∉ TRClosure(match\U0001D70E\
    <br>(a))<br>then                |  |  |  |  |\n| 5                           \
    \                   | \U0001D446<br>← \U0001D446<br>∪ TRClosure(match\U0001D70E\
    <br>(a))                      |  |  |  |  |\n| 6                             \
    \                 | return \U0001D446                                        \
    \            |  |  |  |  |\n\nIn Algorithm [1,](#page-4-4) we outline our algorithm\
    \ to compute the smallest set that we identified in Lemma [4.1.](#page-4-3) It\
    \ takes 3 arguments — the two events 1, <sup>2</sup> and a set 0; for computing\
    \ OLClosure(e1, e2), we must set <sup>0</sup> = ∅; later in Section [4.2](#page-5-0)\
    \ this set will be used to enable incremental computation. This algorithm performs\
    \ a fixpoint computation starting from the set <sup>0</sup> ∪ TRClosure(prev (e1))\
    \ ∪ TRClosure(prev (e2)), and identifies an unmatched acquire event and checks\
    \ if its matching release can be added without adding <sup>1</sup> or 2; if so,\
    \ is added; Acqs(S) denotes the set of acquire events in the set . The algorithm\
    \ ensures that the set is (≤ TO,rf )-closed at each step, and runs in (T2N ) <sup>=</sup>\
    \ e(N ) time.\n\nChecking optimistic reordering. First, we check if the set constructed\
    \ by Algorithm [1](#page-4-4) islock-feasible, i.e., the set of unmatched acquires\
    \ OAcqs(S, ℓ) = { ∈ Acqs(S) | match () ∉ } for each lock ℓ is either singleton\
    \ or empty:\n\nlockFeasible() ≡ ∀ℓ ∈ Locks(), |OAcqs(S, ℓ)| ≤ 1\n\n<span id=\"\
    page-5-1\"></span>![](_page_5_Figure_1.jpeg)\n\n(a) Opt. reord. graph of <sup>1</sup>\
    \ (b) Abst. opt. reord. graph of <sup>1</sup> Figure 4: Optimistic and abstract\
    \ optimistic reordering graphs of <sup>1</sup> from Figure [1a](#page-0-0) are\
    \ acyclic\n\nObserve that if lockFeasible() does not hold, then every linearization\
    \ of will have more than one critical sections (on some lock) that overlap, making\
    \ it a non-well-formed trace. Next, inspired from the notion of optimistic reordering,\
    \ we construct the optimisticreordering-graph Opt = ( Opt , Opt ), where Opt =\
    \ , and Opt = Opt ,≤ TO ∪ Opt ,⊲⊳ ∪ Opt ,match∪ Opt ,unmatch. Here, Opt ,≤ TO\
    \ is the set of edges (, ′ ), where = prev ( ′ ). The set Opt ,⊲⊳ consists of\
    \ all immediate conflict edges, i.e., all pairs (, ′ ) in such that ⊲⊳ ′ , ≤ tr\
    \ ′ and there is no intermediate event in that conflicts with both. The set Opt\
    \ ,match consists of all pairs (, ′ ) such that ≤ tr ′ and there is a common lock\
    \ ℓ for which op() = rel(ℓ), op( ′ ) = acq(ℓ), both and ′ are matched in , and\
    \ there is no intermediate critical section on ℓ. Finally, the remaining set of\
    \ edges order matched critical sections before unmatched ones, i.e., Opt ,unmatch\
    \ <sup>=</sup> {(, ′ ) | ∃ℓ, op() = rel(ℓ), op( ′ ) = acq(ℓ), match ( ′ ) ∉ }.\
    \ Since optimistic reorderings forbid reversal in the order of conflicting memory\
    \ accesses, as well as in the order of same-lock critical sections that are completely\
    \ matched, it suffices to check the acycliclity of Opt, so that the existence\
    \ of witness is guaranteed.\n\n<span id=\"page-5-2\"></span>Lemma 4.2. Let be\
    \ a trace and let ⊆ Events() such that is (≤ TO,rf )-closed and also lock-feasible.\
    \ Then, there is an optimistic reordering of on the set iff the graph Opt is acyclic.\n\
    \nExample 9. For trace <sup>1</sup> in Figure [1a,](#page-0-0) we have OLClosure(e1,\
    \ e12) = {3, 4, 7, 8, 9, 10, 11}. The optimisticreordering-graph over <sup>1</sup>\
    \ = OLClosure(e1, e12) is shown in Figure [4a;](#page-5-1) Observe that there\
    \ is no cycle. Indeed, as guaranteed by Lemma [4.2,](#page-5-2) there is an optimistic\
    \ reordering, namely the 7 length prefix of <sup>1</sup> from Figure [1b](#page-0-0)\
    \ that witnesses the race (1, 12). Let us now consider 3, Figure [5a.](#page-6-0)\
    \ The optimistic lock-closure with respect to (4, 9) is <sup>3</sup> = OLClosure(e4,\
    \ e9) = {1, 2, 3, 6, 7, 8}. The optimistic reordering graph over 3, shown in Figure\
    \ [5b,](#page-6-0) contains a cycle. Indeed, (4, 9) is not a predictable race.\n\
    \nWe remark that Opt can be constructed and checked for cycles in time (T N )\
    \ <sup>=</sup> e(N ). Thus the overall algorithm for checking if given (1, 2)\
    \ is an optimistic sync-reversal race is — first compute OLClosure(e1, <sup>e</sup>2)\
    \ in e(N ) time, check lock-feasibility in\n\n(LT ) <sup>=</sup> e(1) time and\
    \ perform graph construction and cycle detection in e(N ) time. We thus have the\
    \ following theorem.\n\n<span id=\"page-5-4\"></span>Theorem 4.1. Let be a trace\
    \ and let 1, <sup>2</sup> be conflicting events in . The problem of determining\
    \ if (1, 2) is an optimistic syncreversal race can be solved in time T (T N +\
    \ L) <sup>=</sup> e(N ) time.\n\n#### <span id=\"page-5-0\"></span>4.2 Incremental\
    \ Race Detection\n\nOverview. Recall that there are (N<sup>2</sup> ) pairs of\
    \ conflicting events, and instead of naively examining each of them, we develop\
    \ an incremental algorithm that determines the existence of an optimistic sync-reversal\
    \ race in totale(N<sup>2</sup> ) time. We achieve this by spending e(N ) time\
    \ per (read/write) event <sup>∈</sup> Events(), and determine in overall e(N )\
    \ time if there is some event ′ such that ( ′ , ) is a race, by scanning the trace\
    \ from earliest to latest events. To do so, our algorithm exploits several novel\
    \ insights. Let us fix one of the events . First, we show that the optimistic\
    \ lock closure can be computed incrementally from previously computed sets, instead\
    \ of computing it from scratch for each ′ . Even though the closure sets can be\
    \ computed incrementally, the optimistic-reordering-graph Opt (Section [4.1\\\
    )](#page-4-2) cannot be computed in an incremental fashion, because the edges\
    \ in this graph depend upon precisely which events are present in the set. In\
    \ particular, a previously unmatched acquire event may become matched in a larger\
    \ set, and thus, we may have fewer edges in the larger graph. Our second insight\
    \ caters to this — we represent the graph succinctly as an abstract optimisticreordering-graph\
    \ which has e(1) (instead of e(N )) nodes, and moreover, can be computed by pre-populating\
    \ an appropriate data structure and performing range minima queries over it, to\
    \ determine reachability information in the abstract graph in e(1) time.\n\nIncrementally\
    \ constructing optimistic lock closure. The incremental closure computation relies\
    \ on the observation that the closure is monotonic with respect to thread-order\
    \ (Lemma [4.3\\)](#page-5-3). Thus, if we fix a thread , and scan the events of\
    \ from earliest to latest events, then we can reuse prior computations. In fact,\
    \ Algorithm [1](#page-4-4) already works in this fashion — it builds on top of\
    \ the given input set . Lemma [4.3](#page-5-3) establishes the correctness and\
    \ time complexity of closure computation.\n\n<span id=\"page-5-3\"></span>Lemma\
    \ 4.3. Let 1, 2, ′ 2 ∈ Events() be events in trace with <sup>2</sup> ≤ TO ′ 2\
    \ . Let = OLClosure(e1, e2) and let ′ = OLClosure(e1, e ′ 2 ). We have the following:\
    \ (1) ⊆ ′ . (2) = ComputeOLClosure(1, 2, ∅), and further this call (in Algorithm\
    \ [1\\)](#page-4-4) takes e(| |) time. (3) ′ = ComputeOLClosure(1, ′ 2 , ), and\
    \ further this call (in Algorithm [1\\)](#page-4-4) takes e(| ′ | − | |) time.\n\
    \nAbstract optimistic-reordering-graph. For a set ⊆ Events(), the abstract optimistic-reordering-graph\
    \ is a tuple Abs = ( Abs , Abs ), where the vertices and edges are defined as\
    \ follows. (1) Abs = Ð ℓ ∈Locks() {lastRel(S, ℓ)} ∪ OAcqs(S, ℓ), where lastRel(S,\
    \ ℓ) is the last release event on lock ℓ (according to ≤ tr) which is present\
    \ in . (2) (, ′ ) ∈ Abs if there is a path from to ′ in the graph Opt . In other\
    \ words, Abs only contains (L) vertices, corresponding to the last release events,\
    \ and acquire events that are unmatched in , and preserves the reachability information\n\
    \n<span id=\"page-6-4\"></span><span id=\"page-6-0\"></span>![](_page_6_Figure_1.jpeg)\n\
    \n(a) Trace <sup>3</sup> (b) Reordering graph (c) Abstract graph Figure 5: In\
    \ 3, (4, 9) is not a predictable race. The optimistic reordering graph and the\
    \ abstract optimistic reordering graph are cyclic.\n\nbetween these events. Lemma\
    \ [4.4](#page-6-1) formalizes the intuition behind this graph — it preserves the\
    \ cyclicity information of the larger graph Opt , because any cycle in Opt must\
    \ involve a 'backward' edge from a matched release and an unmatched acquire event.\
    \ Abs can thus be used to check for the existence of an optimistic reordering\
    \ using an e(1) check instead of an e(N ) check based on Lemma [4.2.](#page-5-2)\n\
    \n<span id=\"page-6-1\"></span>Lemma 4.4. Let be a trace and let ⊆ Events() be\
    \ a (≤ TO,rf ) closed set. Opt has a cycle iff Abs has a cycle.\n\nExample 10.\
    \ Figure [4b](#page-5-1) shows the abstract optimistic reordering graph for trace\
    \ <sup>1</sup> in Figure [1a,](#page-0-0) corresponding to the set <sup>1</sup>\
    \ = OLClosure(e1, e12), and contains the last release of lock ℓ in <sup>1</sup>\
    \ as well as the only open acquire in 1. This graph, like the graph in Figure\
    \ [4a](#page-5-1) is acyclic. In Figure [5,](#page-6-0) the abstract graph (Figure\
    \ [5c\\)](#page-6-0) captures the path <sup>2</sup> → <sup>3</sup> → <sup>7</sup>\
    \ → <sup>8</sup> of Figure [5b](#page-6-0) with a direct edge <sup>2</sup> → 8,\
    \ thereby preserving the cycle.\n\nConstructing vertices and backward edges of\
    \ Abs . Recall that is a (≤ TO,rf )-closed subset of Events(). The set of vertices\
    \ of this graph can be determined in (L) time by maintaining the last event of\
    \ every thread present in . This information can be inductively maintained as\
    \ is being computed incrementally. The 'backward' edges — namely those pairs (,\
    \ ) where ∈ is an unmatched acquire on some lock ℓ, and = lastRel(S, ℓ) but ≤\
    \ tr — can be computed in (L) time.\n\nPre-computing earliest immediate successor.\
    \ For constructing forward edges, we first pre-compute a map (for each pair of\
    \ threads 1, 2), EIS1,<sup>2</sup> such that, for every <sup>1</sup> ∈ Events()|<sup>1</sup>\
    \ = { ∈ Events() | th() = }, the event EIS1,<sup>2</sup> (1) is the earliest immediate\
    \ successor of 1 in thread 2, in the full graph Opt Events() ; observe the subscript\
    \ Events() instead of an arbitrary set . EIS1,<sup>2</sup> can be computed as\
    \ a pre-processing step in (T N ) <sup>=</sup> e(N ) time and stored as an array,\
    \ indexed by the events of thread 1.\n\nDetermining forward edges of Abs . The\
    \ forward edges of Abs summarize paths in Opt and are computed as follows. Recall\
    \ that we are given a (≤ TO,rf )-closed subset of Events(), and the path between\
    \ two events must only be contained with the events of , thus the arrays {EIS1,<sup>2</sup>\
    \ }1,2∈Threads() cannot be used as is\n\n<span id=\"page-6-2\"></span>\n\n| Algorithm\
    \ 2: Earliest successors of event<br>\U0001D452<br>within set<br>\U0001D446  \
    \              |  |  |  |  |  |  |\n|----------------------------------------------------------------------------------|--|--|--|--|--|--|\n\
    | 1 procedure getSuccessors(\U0001D452,<br>\U0001D446)                       \
    \                        |  |  |  |  |  |  |\n| = th(\U0001D452),<br>let \U0001D461\
    \U0001D452<br>visitedThr ← ∅                                             |  |\
    \  |  |  |  |  |\n| let last\U0001D446<br>be the last event by<br>\U0001D461<br>in\
    \ S, for<br>\U0001D461<br>∈ Threads(\U0001D70E)<br>\U0001D461    |  |  |  |  |\
    \  |  |\n| for \U0001D461<br>∈ Threads(\U0001D70E)<br>do                     \
    \                                 |  |  |  |  |  |  |\n| succ\U0001D446<br>last\U0001D446\
    <br>,\U0001D461) [\U0001D452,<br>\U0001D452,\U0001D461 ← rangeMin(EIS\U0001D461\
    \U0001D452<br>]<br>5<br>\U0001D461\U0001D452                |  |  |  |  |  | \
    \ |\n| while visitedThr ≠ Threads(\U0001D70E)<br>do<br>6                     \
    \                    |  |  |  |  |  |  |\n| succ\U0001D446<br>let \U0001D4611<br>be\
    \ s.t.<br>\U0001D4611<br>∉ visitedThr and<br>is the<br>7<br>\U0001D452,\U0001D461\
    1      |  |  |  |  |  |  |\n| \U0001D70E<br>{succ\U0001D446<br>earliest in<br>tr\
    \ from<br>≤<br>\U0001D452,\U0001D461 }\U0001D461∉visitedThr                  |\
    \  |  |  |  |  |  |\n| for \U0001D4612<br>∈ Threads(\U0001D70E)<br>do<br>8   \
    \                                             |  |  |  |  |  |  |\n| ) [succ\U0001D446\
    <br>last\U0001D446<br>\U0001D45B\U0001D452\U0001D464\U0001D446\U0001D462\U0001D450\
    \U0001D450<br>,<br>← rangeMin(EIS\U0001D4611,\U0001D4612<br>]<br>9<br>\U0001D452\
    ,\U0001D4611<br>\U0001D4611 |  |  |  |  |  |  |\n| TO succ\U0001D446<br>\U0001D70E\
    <br>if \U0001D45B\U0001D452\U0001D464\U0001D446\U0001D462\U0001D450\U0001D450\
    <br>≤<br>then<br>10<br>\U0001D452,\U0001D4612                           |  | \
    \ |  |  |  |  |\n| succ\U0001D446<br>← \U0001D45B\U0001D452\U0001D464\U0001D446\
    \U0001D462\U0001D450\U0001D450<br>11<br>\U0001D452,\U0001D4612               \
    \                                  |  |  |  |  |  |  |\n| visitedThr ← visitedThr\
    \ ∪ {\U0001D4611}<br>12                                             |  |  |  |\
    \  |  |  |\n| return {succ\U0001D446<br>\U0001D452,\U0001D461 }\U0001D461<br>∈Threads(\U0001D70E\
    )<br>13                                     |  |  |  |  |  |  |\n\n| Algorithm\
    \ 3: Detecting races between<br>\U0001D452<br>and thread |\n|---------------------------------------------------------|\n\
    |---------------------------------------------------------|\n\n<span id=\"page-6-3\"\
    ></span>\n\n| 1 procedure incrementalRaceDetection(\U0001D452,<br>\U0001D461)\
    \ |                                                                          \
    \                |  |  |  |  |  |  |  |\n|-----------------------------------------------|------------------------------------------------------------------------------------------|--|--|--|--|--|--|--|\n\
    | 2                                             | \U0001D446<br>← ∅          \
    \                                                                       |  | \
    \ |  |  |  |  |  |\n| 3                                             | \U0001D70E\
    <br>′ ∈<br>′ and<br>′ ≤<br>for \U0001D452<br>Events(\U0001D70E) \U0001D461<br>s.t.\
    \ \U0001D452<br>⊲⊳<br>\U0001D452<br>\U0001D452<br>tr \U0001D452<br>do |  |  |\
    \  |  |  |  |  |\n| 4                                             | \U0001D446\
    <br>← ComputeOLClosure(e, e', S)                                             \
    \           |  |  |  |  |  |  |  |\n| 5                                      \
    \       | if lockFeasible(\U0001D446)<br>and \U0001D43A<br>Abs<br>is acyclic then<br>\U0001D446\
    \                               |  |  |  |  |  |  |  |\n| 6                  \
    \                           | ′<br>declare (\U0001D452<br>,<br>\U0001D452) as\
    \ race.                                                      |  |  |  |  |  |\
    \  |  |\n\nto efficiently determine paths. However, a combination of range minima\
    \ queries [\\[7\\]](#page-11-7) and shortest path computation can nevertheless\
    \ still be used to determine path information efficiently. Let us use succ , to\
    \ denote the earliest event in thread that has a path from event , using only\
    \ forward edges of Opt . The event succ , can be computed using a Bellman-Ford-Moore\
    \ [\\[12,](#page-11-8) [27,](#page-11-9) [48\\]](#page-11-10) style shortest path\
    \ computation, as shown in Algorithm [2.](#page-6-2) This algorithm performsrangeMin()\
    \ [, ] queries which return the earliest event (according to ≤ TO) in the segment\
    \ of the array starting at index and ending at index . With e(N ) time and space\
    \ pre-processing, each range minimum query takes (1) time [\\[7,](#page-11-7)\
    \ [28\\]](#page-11-11), Thus, the task of determining {succ , } <sup>∈</sup>Threads()\
    \ takes (T<sup>2</sup> ) time. Now, in the graph Abs , we add an edge from to\
    \ ′ if succ ,th( ′ ) ≤ TO ′ . Thus, we add all forward edges of the graph in overall\
    \ (T2L) time.\n\nChecking if a given event is in race with some event. We now\
    \ have all the ingredients to describe our overall incremental algorithm to check\
    \ if event is in optimistic-sync-reversal race with some event of a given thread\
    \ (Algorithm [3\\)](#page-6-3). For this, we first initialize all the arrays {EIS1,<sup>2</sup>\
    \ }1,2∈Threads() using a linear scan of the trace , and also do pre-processing\
    \ for fast performing range minima queries, spending overall time (T N ). Then,\
    \ we iterate over each event ′ of thread that conflict with , starting from the\
    \ earliest to the latest. For each event, we incrementally update the optimistic\
    \ lock-closure set and check if it is lock-feasible. If so, we construct the abstract\
    \ optimistic-reordering-graph Abs and check if it is acyclic, and report a race\
    \ if so.\n\n<span id=\"page-7-2\"></span>\n\n| Algorithm 4: Detecting optimistic\
    \ sync-reversal races in<br>\U0001D70E |                                     \
    \                          |  |                                 |  |  |  |  |\n\
    |---------------------------------------------------------------|---------------------------------------------------------------|--|---------------------------------|--|--|--|--|\n\
    | 1 procedure OSR(\U0001D70E)                                            |   \
    \                                                            |  |            \
    \                     |  |  |  |  |\n| 2                                     \
    \                        | for \U0001D452<br>∈ Events(\U0001D70E)<br>s.t. \U0001D452\
    <br>is a memory access event do |  |                                 |  |  | \
    \ |  |\n| 3                                                             | ′ ∈<br>for\
    \ \U0001D461<br>Threads(\U0001D70E)<br>do                              |  |  \
    \                               |  |  |  |  |\n| 4                           \
    \                                  |                                         \
    \                      |  | incrementalRaceDetection(e, t') |  |  |  |  |\n\n\
    Theorem 4.2. Let be an execution, ∈ Events() be a read or write event and let\
    \ ∈ Threads(). The problem of checking if there is an event ′ with th( ′ ) = such\
    \ that (, ′ ) is an optimisticsync-reversal race, can be solved in time (T<sup>2</sup>\
    \ + L)LN .\n\n# <span id=\"page-7-1\"></span>4.3 Detecting All Optimistic Sync-Reversal\
    \ Races\n\nGiven a trace , all the optimistic sync-reversal races in can now be\
    \ detected by enumerating all events and threads and checking if incrementalRaceDetection(,\
    \ ) reports a race. Our resulting algorithm OSR (Algorithm [4\\)](#page-7-2) runs\
    \ in time T L (T<sup>2</sup> + L)N<sup>2</sup> .\n\n<span id=\"page-7-4\"></span>Theorem\
    \ 4.3. Given a trace , the problem of checking if has an optimistic sync-reversal\
    \ data race, can be solved in time T L (T<sup>2</sup> + L)N<sup>2</sup> <sup>=</sup>\
    \ e(N<sup>2</sup> ) time.\n\nHardness of detecting optimistic sync-reversal races.\
    \ We have, thus far, established that the problem of checking the existence of\
    \ optimistic sync-reversal data races can be solved in quadratic time. In the\
    \ following, we also show a matching quadratic time lower bound, thus establishing\
    \ that our algorithm OSR is indeed optimal. The lower bound is conditioned on\
    \ the Strong Exponential Time Hypothesis (SETH), which is a widely believed conjecture.\
    \ We use fine-grained reductions to establish a reduction from the orthogonal\
    \ vectors problem which holds true under SETH [\\[70\\]](#page-12-6). The full\
    \ proof of the following result is presented in Appendix [B.8.](#page-16-0)\n\n\
    <span id=\"page-7-5\"></span>Theorem 4.4. Assume SETH holds. Given an arbitrary\
    \ trace , the problem of determining if has an OSR race cannot be solved in time\
    \ (N2− ) (where N = |Events()|) for every > 0.\n\n#### <span id=\"page-7-0\"></span>5\
    \ EVALUATION\n\nWe implemented our algorithm OSR in Java, using the Rapid dynamic\
    \ analysis framework [\\[4\\]](#page-11-12). We evaluate the performance and precision\
    \ of OSR, on 153 benchmarks and compare it with prior state-of-the-art sound predictive\
    \ race detection algorithms. We discuss our experimental set up in Section [5.1](#page-7-3)\
    \ and our evaluation results in Section [5.2,](#page-8-1) Section [5.3](#page-8-2)\
    \ and Section [5.4.](#page-8-3)\n\n#### <span id=\"page-7-3\"></span>5.1 Experimental\
    \ Setup\n\nBenchmarks. Our evaluation subjects are both Java (Category-1) as well\
    \ as C/C++/OpenMP (Category-2) benchmarks. Category-1, derived from [\\[45\\]](#page-11-3),\
    \ contains 30 Java programs from the IBM Contest benchmark suite [\\[24\\]](#page-11-13),\
    \ the Java Grande forum benchmark suite [\\[63\\]](#page-12-7), DaCapo [\\[13\\\
    ]](#page-11-14), SIR [\\[22\\]](#page-11-15) and other standalone benchmarks.\
    \ Category-2 contains 123 benchmarks from OmpSCR [\\[23\\]](#page-11-16), DataRaceBench\
    \ [\\[39\\]](#page-11-17) DataRaceOnAccelerator [\\[62\\]](#page-12-8), NAS parallel\
    \ benchmarks [\\[11\\]](#page-11-18), CORAL [\\[5,](#page-11-19) [6\\]](#page-11-20),\
    \ ECP proxy applications [\\[1\\]](#page-11-21) and the Mantevo project [\\[2\\\
    ]](#page-11-22). For an apples-to-apples comparison, we\n\nevaluate all compared\
    \ techniques on the same execution trace to remove bias due to thread-scheduler.\
    \ For this, we generate traces out of these programs using ThreadSanitizer [\\\
    [64\\]](#page-12-9) (for Category-2) and using RVPredict [\\[47\\]](#page-11-23)\
    \ (for Category-1). For Java programs, we generate one trace per program and for\
    \ C/C++ programs, we generate multiple traces of the same program with different\
    \ thread number and input parameters. All compared methods then evaluate each\
    \ generated trace 3 times. We did not exclude any traces from the benchmarks,\
    \ except one corrupted trace.\n\nAs part of our evaluation, we also explored synthetically\
    \ created benchmark traces from RaceInjector [\\[3,](#page-11-24) [69\\]](#page-12-10),\
    \ that uses SMT solving to inject data races into existing traces. However, the\
    \ traces in [\\[3\\]](#page-11-24) are short, could not be used to distinguish\
    \ most compared methods and were not useful for a conclusive evaluation. Our evaluation\
    \ on these traces is deferred to Appendix [C](#page-17-0) (Table [4\\)](#page-19-0).\
    \ As observed in prior works [\\[18,](#page-11-6) [26,](#page-11-25) [45,](#page-11-3)\
    \ [54\\]](#page-12-5), a large fraction of events in traces are thread-local,\
    \ and do not affect the precision or soundness of race detection algorithms, but\
    \ can significantly slow down race detection. Therefore, we filter out these thread-local\
    \ events, as with prior work [\\[34,](#page-11-2) [45,](#page-11-3) [54\\]](#page-12-5).\n\
    \nCompared methods. We compare OSR with state-of-the-art sound predictive algorithms:\
    \ WCP [\\[34\\]](#page-11-2), SHB [\\[42\\]](#page-11-5), M2 [\\[54\\]](#page-12-5)\
    \ and SyncP [\\[45\\]](#page-11-3). Amongst these, SHB and WCP are partial order\
    \ based methods and run in linear time. M2 and SyncP are closer in spirit to ours\
    \ — they first identify a set of events and then a linearization of this set that\
    \ can witness a data race. SyncP works in linear time while M2 has higher polynomial\
    \ complexity of e(N<sup>4</sup> log(N )) [\\[54\\]](#page-12-5). For all these\
    \ algorithms, we use the publicly available source codes [\\[34,](#page-11-2)\
    \ [42,](#page-11-5) [45,](#page-11-3) [54\\]](#page-12-5). To achieve fair comparison,\
    \ we modify each of them, so that (1) each algorithm reports on the same criteria\
    \ (events v/s memory locations v/s program locations) (2) any redundant operations\
    \ not relevant to the reporting criteria are removed. A comparison with recent\
    \ work SeqC [\\[18\\]](#page-11-6) was not possible because the implementation\
    \ of SeqC is neither publicly available nor could be obtained even after contacting\
    \ the authors. Our evaluation didn't include comparison with solver-aided race\
    \ predictors, such as RVPredict [\\[31\\]](#page-11-1). Based on prior work [\\\
    [34\\]](#page-11-2), such predictors are known to not scale, have unpredictable\
    \ race reports and typically have lower predictive power than the simplest of\
    \ race prediction algorithms, thanks to the windowing strategy they implement.\n\
    \nMachine configuration and evaluation settings. The experiments are conducted\
    \ on a 2.0GHz 64-bit Linux machine. For Category-1 (Java) benchmarks, we set the\
    \ heap size of JVM to be 60GB and timeout to be 2 hours; this set up is similar\
    \ to previous works [\\[34,](#page-11-2) [45\\]](#page-11-3), except for the larger\
    \ heap space, mandated by the larger memory requirement of M2. For Category-2\
    \ (C/C++) benchmarks, we set the heap size to be 400GB and timeout to be 3 hours,\
    \ since these are much more challenging — the number of events, locks and variables\
    \ in these are typically 10 − 100× more than traces in Category-1. All experiments\
    \ are repeated 3 times and the times reported are averaged over these 3 runs.\n\
    \nReported metrics. Our evaluation aims to understand the prediction power (precision)\
    \ as well as the scalability of OSR and assess how it compares against existing\
    \ state-of-the-art race prediction techniques. For each execution trace , we report\
    \ key characteristics\n\n(number of events, threads, locks, read events, write\
    \ events, acquire events and release events) to estimate how challenging each\
    \ benchmark is. Next, we measure and report the following :\n\n- Running time.\
    \ For each algorithm, we report the average running time (over 3 trials) for processing\
    \ the entire execution. This is aimed to understand if the worst case quadratic\
    \ complexity of OSR affects its performance in practice, or it is on par with\
    \ other linear time methods such as WCP, SHB and SyncP.\n- Race reports in Category-1.\
    \ For benchmarks in Category-1, we report the number of racy events reported;\
    \ an event <sup>2</sup> is racy if there is a conflicting event 1 earlier in the\
    \ trace, such that (1, 2) is a race. We also report the number of distinct source\
    \ code lines for these racy events. We note here one racy source code line could\
    \ correspond to many racy events.\n- Race reports in Category-2. For benchmarks\
    \ in Category-2, we report the number of variables (memory locations) that are\
    \ racy. A variable is racy if there is a racy event that accesses . The number\
    \ of racy events in the C/C++ benchmarks is typically very large, and reporting\
    \ each racy event throttles nearly all algorithms. If a compared method times\
    \ out, we report the number of racy variables found before timing out. This enables\
    \ us to better evaluate their ability to find races in a more reasonable setting.\
    \ Besides, most algorithms report many races before they timeout.\n- Scaling behavior\
    \ of OSR. OSR runs in worst case quadratic time. We empirically evaluate how OSR\
    \ scales with trace length, for a small set of benchmarks to gauge its in-practice\
    \ behavior.\n\n#### <span id=\"page-8-1\"></span>5.2 Evaluation Results For Java\
    \ Benchmarks\n\nTable [1](#page-9-0) summarizes the results for Category-1.\n\n\
    Prediction power. OSR reports the largest number of races on each trace; it reports\
    \ about 200 more racy events and 3 extra racy locations over the second most predictive\
    \ method (SyncP); we remark that any extra data race can be an insidious bug [\\\
    [15\\]](#page-11-26) and deserves rigorous attention by developers. Although WCP\
    \ can detect syncreversal races in principle, and reports much fewer races than\
    \ OSR (and also misses races reported by SyncP). M2 takes much more memory and\
    \ time than OSR, and times out on two benchmarks (linkedlist and lufact), while\
    \ runs out of memory on the benchmark tsp. On other benchmarks, OSR demonstrates\
    \ the same prediction power as M2. Overall M2 detects 29.2k less races. In terms\
    \ of racy source code locations, OSR also reports 24, 47, 3, 13 more than SHB,\
    \ WCP, SyncP and M2, respectively. We remark that this class of benchmarks does\
    \ not bring out the full potential of OSR— even if OSR reports the highest number\
    \ of races individually for each benchmark, at least one other method also reports\
    \ this number of races. Category-2 though does better justice to OSR.\n\nRunning\
    \ time. SHB and WCP are lightweight partial order-based linear time algorithms\
    \ and finish fastest. On the other hand, M2 performs an expensive computation,\
    \ times out on some large traces and takes more than 6 hours to finish. SyncP\
    \ runs in linear time, but our algorithm OSR outperforms it by about 1.5×. We\
    \ note that the linkedlist benchmark is especially challenging, with large number\
    \ of variables, as a result of which SyncP allocates a large memory to account\
    \ for its heavy data structure usage.\n\nThus, for Category-1 benchmarks, OSR\
    \ demonstrates highest race coverage, and runs faster than the state-of-the-art\
    \ SyncP.\n\n### <span id=\"page-8-2\"></span>5.3 Evaluation Results For C/C++\
    \ Benchmarks\n\nTable [2](#page-10-1) summarizes our evaluation over Category-2\
    \ (C/C++) benchmarks. In Appendix [C,](#page-17-0) we present detailed statistics\
    \ of these benchmarks (see Table [6](#page-25-0) and Table [5\\)](#page-22-0).\n\
    \nPrediction power. OSR displays high race coverage on this set of traces. Overall,\
    \ OSR reports 2.5× more races than the second most predictive method (SHB). On\
    \ all, except 5, of the 118 benchmarks, OSR reports the highest number of racy\
    \ variables. Each of the remaining 5 benchmark traces have a large number of events,\
    \ and only the lightweight algorithms (SHB and WCP) finish within the 3 hour time\
    \ limit. In terms of total races found, OSR reports 2.5× and 2.7× more races than\
    \ SHB (2 nd highest) and WCP (3 rd highest). SyncP and M2 time out on most benchmarks.\
    \ We speculate that this is because both these methods have high memory requirement\
    \ and result in large time spent in garbage collection. OSR, therefore, has the\
    \ highest race coverage even for the C/C++ benchmarks.\n\nWe remark that the number\
    \ of racy variables in this class of benchmarks is very high. We speculate this\
    \ is because our instrumentation using ThreadSanitizer does not explicitly tag\
    \ atomic operations. Further many benchmarks perform matrix operations, giving\
    \ rise to many distinct memory locations. Nevertheless, we choose to report all\
    \ races because data races can render these programs potentially non-robust, and\
    \ under weak memory consistency, data races can lead to undefined semantics.\n\
    \nRunning time. Overall, SHB runs the fastest. SyncP and M2, on the other hand,\
    \ frequently time out. The difference in the performance between SyncP, M2 and\
    \ OSR gets exacerbated on the C/C++ benchmarks because these contain much larger\
    \ execution traces than Java benchmarks. The performance of OSR (total running\
    \ time of 42 hours) is close to WCP (30 hours). OSR, therefore, achieves an optimal\
    \ balance between predictive power and scalability — OSR has the highest predictive\
    \ power and outperforms SHB, WCP, SyncP, M2, and often runs faster than more exhaustive\
    \ techniques.\n\n#### <span id=\"page-8-3\"></span>5.4 Scalability\n\nIn this\
    \ section, we take a closer look at the run-time behavior of OSR to understand\
    \ its unexpected high scalability on some benchmarks. We select the most challenging\
    \ benchmarks from each of the following groups: HPCBench, CoMD, DataRaceBench,\
    \ OMPRacer in Category-2. For these benchmarks, we measure the time to process\
    \ every million events and report it in Figure [6.](#page-10-2) We observe that\
    \ on these four benchmarks, OSR scales linearly for a large prefix, while gradually\
    \ slows down on two of them. The nearlinear behavior of OSR is likely an artefact\
    \ of the fact that, many of these benchmarks traces have large number of data\
    \ races, thus the race check for a single event succeeds quickly instead of the\
    \ worst case linear time requirement. Therefore, instead of spending overall quadratic\
    \ time, OSR spends linear time on average.\n\n#### <span id=\"page-8-0\"></span>6\
    \ RELATED WORK\n\nDynamic predictive analysis. Happens-before (HB) [\\[37\\]](#page-11-27)\
    \ based race detection [\\[26,](#page-11-25) [55\\]](#page-12-4) has been adopted\
    \ by mature tools [\\[49,](#page-12-11) [64\\]](#page-12-9),\n\n<span id=\"page-9-0\"\
    ></span>Table 1: Evaluation on **Category-1** (Java benchmarks). Columns 1-3 denote\
    \ the name, number of events and number of threads for each benchmark. Columns\
    \ 4-13 are the number of racy events (and racy program locations) reported and\
    \ average running time of each algorithm.\n\n| 1            | 2      | 3 | 4 \
    \              | 5              | 6                | 7              | 8      \
    \          | 9              | 10             | 11             | 12           \
    \    | 13       |\n|--------------|--------|---|-----------------|----------------|------------------|----------------|------------------|----------------|----------------|----------------|------------------|----------|\n\
    | Benchmarks N |        | T | SHB             |                | WCP         \
    \     |                | SyncP            |                | M2             |\
    \                | OSR              |          |\n|              |        |  \
    \ | Races           | Time (s) Races |                  | Time (s) Races |   \
    \               | Time (s) Races |                | Time (s) Races |         \
    \         | Time (s) |\n| array        | 11     | 3 | 0(0)            | 0.05 \
    \          | 0(0)             | 0.08           | 0(0)             | 0.06     \
    \      | 0(0)           | 0.03           | 0(0)             | 0.09     |\n| critical\
    \     | 11     | 4 | 3(3)            | 0.04           | 1(1)             | 0.05\
    \           | 3(3)             | 0.07           | 3(3)           | 0.02      \
    \     | 3(3)             | 0.07     |\n| account      | 15     | 4 | 3(1)    \
    \        | 0.04           | 3(1)             | 0.06           | 3(1)         \
    \    | 0.06           | 3(1)           | 0.02           | 3(1)             | 0.08\
    \     |\n| airtickets   | 18     | 5 | 8(3)            | 0.05           | 5(2)\
    \             | 0.08           | 8(3)             | 0.06           | 8(3)    \
    \       | 0.03           | 8(3)             | 0.08     |\n| pingpong     | 24\
    \     | 7 | 8(3)            | 0.04           | 8(3)             | 0.07       \
    \    | 8(3)             | 0.06           | 8(3)           | 0.03           | 8(3)\
    \             | 0.08     |\n| twostage     | 83     |   | 12 4(1)         | 0.06\
    \           | 4(1)             | 0.10           | 4(1)             | 0.14    \
    \       | 8(2)           | 0.05           | 8(2)             | 0.10     |\n| wronglock\
    \    | 122    |   | 22 12(2)        | 0.07           | 3(2)             | 0.11\
    \           | 25(2)            | 0.22           | 25(2)          | 0.18      \
    \     | 25(2)            | 0.13     |\n| bbuffer      | 9      | 3 | 3(1)    \
    \        | 0.05           | 1(1)             | 0.06           | 3(1)         \
    \    | 0.05           | 3(1)           | 0.02           | 3(1)             | 0.10\
    \     |\n| prodcons     | 246    | 8 | 1(1)            | 0.07           | 1(1)\
    \             | 0.13           | 1(1)             | 0.16           | 1(1)    \
    \       | 0.06           | 1(1)             | 0.12     |\n| clean        | 867\
    \    | 8 | 59(4)           | 0.11           | 82(4)            | 0.23        \
    \   | 60(4)            | 0.26           | 110(4)         | 0.65           | 110(4)\
    \           | 0.20     |\n| mergesort    | 167    | 5 | 1(1)            | 0.89\
    \           | 1(1)             | 0.13           | 3(1)             | 0.10    \
    \       | 5(2)           | 0.04           | 5(2)             | 0.12     |\n| bubblesort\
    \   | 1.7K   |   | 13 269(5)       | 0.15           | 100(5)           | 0.30\
    \           | 269(5)           | 2.29           | 374(5)         | 8.40      \
    \     | 374(5)           | 0.28     |\n| lang         | 1.8K   | 7 | 400(1)  \
    \        | 0.17           | 400(1)           | 0.26           | 400(1)       \
    \    | 0.33           | 400(1)         | 0.54           | 400(1)           | 0.22\
    \     |\n| readwrite    | 9.8K   | 5 | 92(4)           | 0.27           | 92(4)\
    \            | 0.63           | 199(4)           | 0.81           | 228(4)   \
    \      | 9.00           | 228(4)           | 0.69     |\n| raytracer    | 526\
    \    | 3 | 8(4)            | 0.10           | 8(4)             | 0.17        \
    \   | 8(4)             | 0.15           | 8(4)           | 0.09           | 8(4)\
    \             | 0.15     |\n| bufwriter    | 10K    | 6 | 8(4)            | 0.29\
    \           | 8(4)             | 0.77           | 8(4)             | 0.75    \
    \       | 8(4)           | 0.52           | 8(4)             | 0.49     |\n| ftpserver\
    \    | 17K    |   | 11 69(21)       | 1.18           | 70(21)           | 0.99\
    \           | 85(21)           | 6.01           | 85(21)         | 2.43      \
    \     | 85(21)           | 0.79     |\n| moldyn       | 21K    | 3 | 103(3)  \
    \        | 1.03           | 103(3)           | 0.73           | 103(3)       \
    \    | 0.79           | 103(3)         | 31.43          | 103(3)           | 0.46\
    \     |\n| linkedlist   |        |   | 910K 12 6.0K(4) | 3.77           | 6.0K(3)\
    \          | 6.80           | 7.1K(4)          | 378.25         | 0(0)       \
    \    | 7200           | 7.1K(4)          | 6.56     |\n| derby        | 75K  \
    \  | 4 | 29(10)          | 0.94           | 28(10)           | 2.30          \
    \ | 29(10)           | 19.08          | 30(11)         | 5.66           | 30(11)\
    \           | 3.67     |\n| jigsaw       | 3.2K   | 8 | 4(4)            | 0.17\
    \           | 4(4)             | 0.39           | 6(6)             | 2.90    \
    \       | 6(6)           | 0.23           | 6(6)             | 0.35     |\n| sunflow\
    \      | 3.3K   |   | 17 84(6)        | 0.17           | 69(6)            | 0.39\
    \           | 119(7)           | 2.53           | 130(7)         | 1.10      \
    \     | 130(7)           | 0.35     |\n| cryptorsa    | 1.3M   | 7 | 11(5)   \
    \        | 5.95           | 11(5)            | 10.87          | 35(7)        \
    \    | 156.19         | 35(7)          | 20.39          | 35(7)            | 173.74\
    \   |\n| xalan        | 672K 7 |   | 31(10)          | 3.22           | 21(7)\
    \            | 12.07          | 37(12)           | 160.62         | 37(12)   \
    \      | 6.56           | 37(12)           | 230.03   |\n| lufact       | 892K\
    \ 5 |   | 22.0K(3)        | 3.39           | 22.0K(3)         | 7.16         \
    \  | 22.0K(3)         | 62.10          | 0(0)           | 7200           | 22.0K(3)\
    \         | 4.15     |\n| batik        | 131    | 7 | 10(2)           | 0.09 \
    \          | 10(2)            | 0.11           | 10(2)            | 0.12     \
    \      | 10(2)          | 0.04           | 10(2)            | 0.12     |\n| lusearch\
    \     | 751K 8 |   | 232(44)         | 2.86           | 119(27)          | 7.94\
    \           | 232(44)          | 9.26           | 232(44)        | 50.4      \
    \     | 232(44)          | 3.65     |\n| tsp          | 15M    |   | 10 143(6)\
    \       | 33.63          | 140(6)           | 66.07          | 143(6)        \
    \   | 146.24         | 0(0)           | 7200           | 143(6)           | 160.39\
    \   |\n| luindex      | 16K    | 3 | 1(1)            | 0.38           | 2(2) \
    \            | 0.68           | 15(15)           | 0.71           | 15(15)   \
    \      | 0.53           | 15(15)           | 0.49     |\n| sor          | 1.9M\
    \   | 5 | 0(0)            | 4.79           | 0(0)             | 9.92         \
    \  | 0(0)             | 13.16          | 0(0)           | 10.61          | 0(0)\
    \             | 38.0     |\n| Sum          |        |   | 29.5K(157) 64.0 |  \
    \              | 29.2K(134) 129.7 |                | 30.9K(178) 961.9 |      \
    \          | 1.9K(168) 6.0h |                | 31.1K(181) 625.7 |          |\n\
    \nand has subsequently been strengthened to SHB [\\[42\\]](#page-11-5) so that\
    \ all races reported are sound. Causal Precedence (CP) [\\[65\\]](#page-12-3)\
    \ and Weak Causal Precedence (WCP) [\\[34\\]](#page-11-2) weaken HB in favor of\
    \ predictive power, and run in polynomial and linear time, respectively. Other\
    \ works such as DC [\\[56,](#page-12-12) [58\\]](#page-12-13) and SDP [\\[29\\\
    ]](#page-11-28) are also partial order based methods that are either sound by\
    \ design or perform graph-based analysis to regain soundness. SyncP [\\[45\\]](#page-11-3),\
    \ M2 [\\[54\\]](#page-12-5), SeqCheck [\\[18\\]](#page-11-6) work similar to OSR,\
    \ by constructing an appropriate set of events and appropriate linearization over\
    \ this set. SMT solver backed approaches [\\[31,](#page-11-1) [60\\]](#page-12-2)\
    \ aim for sound and complete race prediction but do not scale to moderately large\
    \ execution traces. The complexity of data race prediction was extensively studied\
    \ in [\\[44\\]](#page-11-4) and was shown to be NP-hard and also W[1]-hard, implying\
    \ that an FPT algorithm (parameterized by the number of threads) for race prediction\
    \ is unlikely. The fine-grained complexity of HB and SyncP\n\nwas studied in [\\\
    [36\\]](#page-11-29); in practice, HB can be sped up using the tree clock data\
    \ structure [\\[43\\]](#page-11-30). Predictive analyses have also been developed\
    \ for deadlocks [\\[33,](#page-11-31) [68\\]](#page-12-14), atomicity violations\
    \ [\\[46,](#page-11-32) [66\\]](#page-12-15), for more general temporal specifications\
    \ [\\[10\\]](#page-11-33) and more recently has been investigated from the lens\
    \ of generalizing trace equivalence [\\[25\\]](#page-11-34).\n\nOther concurrency\
    \ testing approaches. Static analysis techniques employ forms of lockset style\
    \ reasoning [\\[61\\]](#page-12-16) to detect data races [\\[14,](#page-11-35)\
    \ [38,](#page-11-36) [51,](#page-12-17) [73\\]](#page-12-18) to report data races,\
    \ but are known to report false positives. Model checking techniques for concurrent\
    \ software [\\[8,](#page-11-37) [35,](#page-11-38) [52\\]](#page-12-19) have been\
    \ employed to detect concurrency bugs [\\[30,](#page-11-39) [53\\]](#page-12-20).\
    \ Another class of systematic exploration techniques include controlled concurrency\
    \ testing [\\[9,](#page-11-40) [21\\]](#page-11-41), including those that employ\
    \ randomization [\\[17,](#page-11-42) [40,](#page-11-43) [72\\]](#page-12-21)\
    \ and state-based learning [\\[50\\]](#page-12-22). More recently, feedback driven\
    \ randomized techniques have been\n\n<span id=\"page-10-1\"></span>Table 2: Evaluation\
    \ summary on **Category-2** (C/C++ benchmarks). Benchmarks are grouped based on\
    \ their source, and each row corresponds to one group. Column 1 denotes the source\
    \ and size of each group. Columns 2 and 3 respectively denote the range and the\
    \ total number of events in each group. Column 4 denotes the range of number of\
    \ threads in the benchmarks. Column 5-14 denote the total number of racy memory\
    \ locations, and average running time (in minutes) reported by each algorithm.\n\
    \n| 1               | 2            | 3     | 4        | 5     | 6     | 7    \
    \ | 8     | 9     | 10     | 11    | 12     | 13    | 14    |\n|-----------------|--------------|-------|----------|-------|-------|-------|-------|-------|--------|-------|--------|-------|-------|\n\
    | Benchmark Group | N            |       | T        |       | SHB   |       |\
    \ WCP   |       | SyncP  |       | M2     |       | OSR   |\n|               \
    \  | Range        | Total |          | Races | Time  | Races | Time  | Races |\
    \ Time   | Races | Time   | Races | Time  |\n| CoMD (8)        | [2.5M, 117M]\
    \ | 707M  | [16, 56] | 41.6k | 29.1  | 247k  | 72.3  | 32    | 1440   | 672  \
    \ | 1440   | 441k  | 32.4  |\n| SimpleMOC (1)   | [19M, 19M]   | 19M   | [16,\
    \ 16] | 380   | 0.1   | 388   | 23.8  | 32    | 180    | 32    | 180    | 32 \
    \   | 180   |\n| OMPRacer (15)   | [0.7M, 157M] | 625M  | [16, 58] | 1.2M  | 17.4\
    \  | 0.7M  | 84.1  | 3.3k  | 2.4k   | 1.9k  | 2.1k   | 1.3M  | 35.8  |\n| DRACC\
    \ (13)      | [0.5k, 104M] | 694M  | [16, 16] | 2247  | 8.4   | 2247  | 105.7\
    \ | 2442  | 1440.5 | 361   | 990.1  | 2450  | 66.6  |\n| DRB (33)        | [0.5k,\
    \ 900M] | 5.7B  | [16, 56] | 50.4k | 169.5 | 54.5k | 0.6k  | 1.5k  | 5.4k   |\
    \ 0.9k  | 4.9k   | 47.4k | 1.4k  |\n| HPC (46)        | [1k, 335M]   | 3.8B  |\
    \ [16, 56] | 6.5M  | 174.2 | 6.4M  | 775.4 | 102k  | 7.7k   | 3305  | 6.8k   |\
    \ 18.3M | 574.8 |\n| misc (7)        | [1k, 29M]    | 49M   | [4, 219] | 8548\
    \  | 0.9   | 8481  | 182.2 | 479   | 900.9  | 895   | 444.6  | 4289  | 183.4 |\n\
    | Total (123)     |              | 11.6B |          | 7.9M  | 6.7h  | 7.4M  |\
    \ 30.3h | 109k  | 324.4h | 8.1k  | 280.5h | 20.1M | 41.2h |\n\n<span id=\"page-10-2\"\
    ></span>![](_page_10_Figure_4.jpeg)\n\nemployed for testing concurrent programs\
    \ [\\[32,](#page-11-44) [71\\]](#page-12-23) Randomization has also been shown\
    \ to reduce time overhead of dynamic data race detection [\\[16,](#page-11-45)\
    \ [41,](#page-11-46) [67\\]](#page-12-24).\n\n#### <span id=\"page-10-0\"></span>7\
    \ CONCLUSIONS AND FUTURE WORK\n\nWe propose OSR, a sound polynomial time race\
    \ prediction algorithm that identifies data races that can be witnessed by optimistically\
    \ reversing synchronization operations. OSR significantly advances the state-of-the-art\
    \ in sound dynamic data race prediction. OSR-style reasoning can be helpful for\
    \ exposing other concurrency bugs such as deadlocks [\\[33,](#page-11-31) [68\\\
    ]](#page-12-14) and atomicity violations.\n\n### ACKNOWLEDGMENTS\n\nThis work\
    \ is partially supported by the National Research Foundation, Singapore, and Cyber\
    \ Security Agency of Singapore under its National Cybersecurity R&D Programme\
    \ (Fuzz Testing <NRF-NCR25-Fuzz-0001>) and by a research grant (VIL42117) from\
    \ VIL-LUM FONDEN. Any opinions, findings and conclusions, or recommendations expressed\
    \ in this material are those of the author(s) and do not reflect the views of\
    \ National Research Foundation, Singapore, and Cyber Security Agency of Singapore.\n\
    \nICSE '24, April 12–21, 2024, Lisbon, Portugal Zheng Shi, Umang Mathur, and Andreas\
    \ Pavlogiannis\n\n#### REFERENCES\n\n- <span id=\"page-11-21\"></span>[1] [n.\
    \ d.]. ECP Proxy Applications. [https://proxyapps.exascaleproject.org/.](https://proxyapps.exascaleproject.org/)\
    \ Accessed: 2021-08-01.\n- <span id=\"page-11-22\"></span>[2] [n. d.]. Mantevo\
    \ Project. [https://mantevo.org/.](https://mantevo.org/) Accessed: 2021-08-01.\n\
    - <span id=\"page-11-24\"></span>[3] [n. d.]. RaceInjector traces. [https://github.com/ALFA-group/RaceInjector](https://github.com/ALFA-group/RaceInjector-counterexamples/tree/main)[counterexamples/tree/main.](https://github.com/ALFA-group/RaceInjector-counterexamples/tree/main)\
    \ Accessed: 2023-07-14.\n- <span id=\"page-11-12\"></span>[4] [n. d.]. RAPID.\
    \ [https://github.com/umangm/rapid.](https://github.com/umangm/rapid) Accessed:\
    \ 2023-07-06.\n- <span id=\"page-11-19\"></span>[5] 2014. CORAL Benchmarks. Accessed:\
    \ 2021-08-01.\n- <span id=\"page-11-20\"></span>[6] 2014. CORAL2 Benchmarks. Accessed:\
    \ 2021-08-01.\n- <span id=\"page-11-7\"></span>[7] 2023. Range Minima Query Solutions.\
    \ [https://en.wikipedia.org/wiki/Range\\\\_](https://en.wikipedia.org/wiki/Range_minimum_query)\
    \ [minimum\\\\_query.](https://en.wikipedia.org/wiki/Range_minimum_query) Accessed:\
    \ 2023-07-18.\n- <span id=\"page-11-37\"></span>[8] Parosh Abdulla, Stavros Aronis,\
    \ Bengt Jonsson, and Konstantinos Sagonas. 2014. Optimal Dynamic Partial Order\
    \ Reduction. In Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles\
    \ of Programming Languages (San Diego, California, USA) (POPL '14). Association\
    \ for Computing Machinery, New York, NY, USA, 373–384.<https://doi.org/10.1145/2535838.2535845>\n\
    - <span id=\"page-11-40\"></span>[9] Udit Agarwal, Pantazis Deligiannis, Cheng\
    \ Huang, Kumseok Jung, Akash Lal, Immad Naseer, Matthew Parkinson, Arun Thangamani,\
    \ Jyothi Vedurada, and Yunpeng Xiao. 2021. Nekara: Generalized Concurrency Testing.\
    \ In 2021 36th IEEE/ACM International Conference on Automated Software Engineering\
    \ (ASE). 679–691.<https://doi.org/10.1109/ASE51524.2021.9678838>\n- <span id=\"\
    page-11-33\"></span>[10] Zhendong Ang and Umang Mathur. 2024. Predictive Monitoring\
    \ against Pattern Regular Languages. Proc. ACM Program. Lang. 8, POPL, Article\
    \ 73 (jan 2024). <https://doi.org/10.1145/3632915>\n- <span id=\"page-11-18\"\
    ></span>[11] David H Bailey, Eric Barszcz, John T Barton, David S Browning, Robert\
    \ L Carter, Leonardo Dagum, Rod A Fatoohi, Paul O Frederickson, Thomas A Lasinski,\
    \ Rob S Schreiber, et al. 1991. The NAS parallel benchmarks—summary and preliminary\
    \ results. In Proceedings of the 1991 ACM/IEEE Conference on Supercomputing. 158–\
    \ 165.\n- <span id=\"page-11-8\"></span>[12] RICHARD BELLMAN. 1958. ON A ROUTING\
    \ PROBLEM. Quart. Appl. Math. 16, 1 (1958), 87–90.<http://www.jstor.org/stable/43634538>\n\
    - <span id=\"page-11-14\"></span>[13] Stephen M Blackburn, Robin Garner, Chris\
    \ Hoffmann, Asjad M Khang, Kathryn S McKinley, Rotem Bentzur, Amer Diwan, Daniel\
    \ Feinberg, Daniel Frampton, Samuel Z Guyer, et al. 2006. The DaCapo benchmarks:\
    \ Java benchmarking development and analysis. In Proceedings of the 21st annual\
    \ ACM SIGPLAN conference on Object-oriented programming systems, languages, and\
    \ applications. 169–190.\n- <span id=\"page-11-35\"></span>[14] Sam Blackshear,\
    \ Nikos Gorogiannis, Peter W O'Hearn, and Ilya Sergey. 2018. RacerD: compositional\
    \ static race detection. Proceedings of the ACM on Programming Languages 2, OOPSLA\
    \ (2018), 1–28.\n- <span id=\"page-11-26\"></span>[15] Hans-J Boehm. 2012. Position\
    \ paper: Nondeterminism is unavoidable, but data races are pure evil. In Proceedings\
    \ of the 2012 ACM workshop on Relaxing synchronization for multicore and manycore\
    \ scalability. 9–14.\n- <span id=\"page-11-45\"></span>[16] Michael D. Bond, Katherine\
    \ E. Coons, and Kathryn S. McKinley. 2010. PACER: Proportional Detection of Data\
    \ Races. In Proceedings of the 31st ACM SIGPLAN Conference on Programming Language\
    \ Design and Implementation (Toronto, Ontario, Canada) (PLDI '10). Association\
    \ for Computing Machinery, New York, NY, USA, 255–268.<https://doi.org/10.1145/1806596.1806626>\n\
    - <span id=\"page-11-42\"></span>[17] Sebastian Burckhardt, Pravesh Kothari, Madanlal\
    \ Musuvathi, and Santosh Nagarakatte. 2010. A randomized scheduler with probabilistic\
    \ guarantees of finding bugs. ACM SIGARCH Computer Architecture News 38, 1 (2010),\
    \ 167–178.\n- <span id=\"page-11-6\"></span>[18] Yan Cai, Hao Yun, Jinqiu Wang,\
    \ Lei Qiao, and Jens Palsberg. 2021. Sound and efficient concurrency bug prediction.\
    \ In Proceedings of the 29th ACM Joint Meeting on European Software Engineering\
    \ Conference and Symposium on the Foundations of Software Engineering. 255–267.\n\
    - <span id=\"page-11-0\"></span>[19] Milind Chabbi and Murali Krishna Ramanathan.\
    \ 2022. A Study of Real-World Data Races in Golang. In Proceedings of the 43rd\
    \ ACM SIGPLAN International Conference on Programming Language Design and Implementation\
    \ (San Diego, CA, USA) (PLDI 2022). Association for Computing Machinery, New York,\
    \ NY, USA, 474–489.<https://doi.org/10.1145/3519939.3523720>\n- <span id=\"page-11-47\"\
    ></span>[20] Lijie Chen and Ryan Williams. 2019. An equivalence class for orthogonal\
    \ vectors. In Proceedings of the Thirtieth Annual ACM-SIAM Symposium on Discrete\
    \ Algorithms. SIAM, 21–40.\n- <span id=\"page-11-41\"></span>[21] Pantazis Deligiannis,\
    \ Aditya Senthilnathan, Fahad Nayyar, Chris Lovett, and Akash Lal. 2023. Industrial-Strength\
    \ Controlled Concurrency Testing for C# Programs with COYOTE. In International\
    \ Conference on Tools and Algorithms for the Construction and Analysis of Systems.\
    \ Springer, 433–452.\n- <span id=\"page-11-15\"></span>[22] Hyunsook Do, Sebastian\
    \ Elbaum, and Gregg Rothermel. 2005. Supporting controlled experimentation with\
    \ testing techniques: An infrastructure and its potential impact. Empirical Software\
    \ Engineering 10 (2005), 405–435.\n- <span id=\"page-11-16\"></span>[23] Antonio\
    \ J Dorta, Casiano Rodriguez, and Francisco de Sande. 2005. The OpenMP source\
    \ code repository. In 13th Euromicro Conference on Parallel, Distributed and Network-Based\
    \ Processing. IEEE, 244–250.\n- <span id=\"page-11-13\"></span>[24] Eitan Farchi,\
    \ Yarden Nir, and Shmuel Ur. 2003. Concurrent bug patterns and how to test them.\
    \ In Proceedings international parallel and distributed processing symposium.\
    \ IEEE, 7–pp.\n- <span id=\"page-11-34\"></span>[25] Azadeh Farzan and Umang Mathur.\
    \ 2024. Coarser Equivalences for Causal Concurrency. Proc. ACM Program. Lang.\
    \ 8, POPL, Article 31 (jan 2024). [https:](https://doi.org/10.1145/3632873)\n\n\
    [//doi.org/10.1145/3632873](https://doi.org/10.1145/3632873)\n\n- <span id=\"\
    page-11-25\"></span>[26] Cormac Flanagan and Stephen N. Freund. 2009. FastTrack:\
    \ Efficient and Precise Dynamic Race Detection. In Proceedings of the 30th ACM\
    \ SIGPLAN Conference on Programming Language Design and Implementation (Dublin,\
    \ Ireland) (PLDI '09). Association for Computing Machinery, New York, NY, USA,\
    \ 121–133. [https:](https://doi.org/10.1145/1542476.1542490) [//doi.org/10.1145/1542476.1542490](https://doi.org/10.1145/1542476.1542490)\n\
    - <span id=\"page-11-9\"></span>[27] Lester Randolph Ford. 1956. Network flow\
    \ theory. (1956).\n- <span id=\"page-11-11\"></span>[28] Harold N Gabow, Jon Louis\
    \ Bentley, and Robert E Tarjan. 1984. Scaling and related techniques for geometry\
    \ problems. In Proceedings of the sixteenth annual ACM symposium on Theory of\
    \ computing. 135–143.\n- <span id=\"page-11-28\"></span>[29] Kaan Genç, Jake Roemer,\
    \ Yufan Xu, and Michael D Bond. 2019. Dependenceaware, unbounded sound predictive\
    \ race detection. Proceedings of the ACM on Programming Languages 3, OOPSLA (2019),\
    \ 1–30.\n- <span id=\"page-11-39\"></span>[30] Patrice Godefroid. 2005. Software\
    \ model checking: The VeriSoft approach. Formal Methods in System Design 26 (2005),\
    \ 77–101.\n- <span id=\"page-11-1\"></span>[31] Jeff Huang, Patrick O'Neil Meredith,\
    \ and Grigore Rosu. 2014. Maximal sound predictive race detection with control\
    \ flow abstraction. In Proceedings of the 35th ACM SIGPLAN conference on programming\
    \ language design and implementation. 337–348.\n- <span id=\"page-11-44\"></span>[32]\
    \ Dae R Jeong, Kyungtae Kim, Basavesh Shivakumar, Byoungyoung Lee, and Insik Shin.\
    \ 2019. Razzer: Finding kernel race bugs through fuzzing. In 2019 IEEE Symposium\
    \ on Security and Privacy (SP). IEEE, 754–768.\n- <span id=\"page-11-31\"></span>[33]\
    \ Christian Gram Kalhauge and Jens Palsberg. 2018. Sound Deadlock Prediction.\
    \ Proc. ACM Program. Lang. 2, OOPSLA, Article 146 (oct 2018), 29 pages. [https:](https://doi.org/10.1145/3276516)\
    \ [//doi.org/10.1145/3276516](https://doi.org/10.1145/3276516)\n- <span id=\"\
    page-11-2\"></span>[34] Dileep Kini, Umang Mathur, and Mahesh Viswanathan. 2017.\
    \ Dynamic Race Prediction in Linear Time. In Proceedings of the 38th ACM SIGPLAN\
    \ Conference on Programming Language Design and Implementation (Barcelona, Spain)\
    \ (PLDI 2017). Association for Computing Machinery, New York, NY, USA, 157–170.\
    \ <https://doi.org/10.1145/3062341.3062374>\n- <span id=\"page-11-38\"></span>[35]\
    \ Michalis Kokologiannakis and Viktor Vafeiadis. 2021. GenMC: A model checker\
    \ for weak memory models. In International Conference on Computer Aided Verification.\
    \ Springer, 427–440.\n- <span id=\"page-11-29\"></span>[36] Rucha Kulkarni, Umang\
    \ Mathur, and Andreas Pavlogiannis. 2021. Dynamic Data-Race Detection Through\
    \ the Fine-Grained Lens. In 32nd International Conference on Concurrency Theory.\n\
    - <span id=\"page-11-27\"></span>[37] Leslie Lamport. 1978. Time, Clocks, and\
    \ the Ordering of Events in a Distributed System. Commun. ACM 21, 7 (jul 1978),\
    \ 558–565. [https://doi.org/10.1145/359545.](https://doi.org/10.1145/359545.359563)\
    \ [359563](https://doi.org/10.1145/359545.359563)\n- <span id=\"page-11-36\"></span>[38]\
    \ Yanze Li, Bozhen Liu, and Jeff Huang. 2019. Sword: A scalable whole program\
    \ race detector for java. In 2019 IEEE/ACM 41st International Conference on Software\
    \ Engineering: Companion Proceedings (ICSE-Companion). IEEE, 75–78.\n- <span id=\"\
    page-11-17\"></span>[39] Chunhua Liao, Pei-Hung Lin, Joshua Asplund, Markus Schordan,\
    \ and Ian Karlin. 2017. DataRaceBench: a benchmark suite for systematic evaluation\
    \ of data race detection tools. In Proceedings of the International Conference\
    \ for High Performance Computing, Networking, Storage and Analysis. 1–14.\n- <span\
    \ id=\"page-11-43\"></span>[40] Weiyu Luo and Brian Demsky. 2021. C11Tester: a\
    \ race detector for C/C++ atomics. In Proceedings of the 26th ACM International\
    \ Conference on Architectural Support for Programming Languages and Operating\
    \ Systems. 630–646.\n- <span id=\"page-11-46\"></span>[41] Daniel Marino, Madanlal\
    \ Musuvathi, and Satish Narayanasamy. 2009. LiteRace: Effective sampling for lightweight\
    \ data-race detection. In Proceedings of the 30th ACM SIGPLAN Conference on Programming\
    \ Language Design and Implementation. 134–143.\n- <span id=\"page-11-5\"></span>[42]\
    \ Umang Mathur, Dileep Kini, and Mahesh Viswanathan. 2018. What happens-after\
    \ the first race? enhancing the predictive power of happens-before based dynamic\
    \ race detection. Proceedings of the ACM on Programming Languages 2, OOPSLA (2018),\
    \ 1–29.\n- <span id=\"page-11-30\"></span>[43] Umang Mathur, Andreas Pavlogiannis,\
    \ Hünkar Can Tunç, and Mahesh Viswanathan. 2022. A Tree Clock Data Structure for\
    \ Causal Orderings in Concurrent Executions. In Proceedings of the 27th ACM International\
    \ Conference on Architectural Support for Programming Languages and Operating\
    \ Systems. ACM, Lausanne Switzerland, 710–725.<https://doi.org/10.1145/3503222.3507734>\n\
    - <span id=\"page-11-4\"></span>[44] Umang Mathur, Andreas Pavlogiannis, and Mahesh\
    \ Viswanathan. 2020. The complexity of dynamic data race prediction. In Proceedings\
    \ of the 35th Annual ACM/IEEE Symposium on Logic in Computer Science. 713–727.\n\
    - <span id=\"page-11-3\"></span>[45] Umang Mathur, Andreas Pavlogiannis, and Mahesh\
    \ Viswanathan. 2021. Optimal prediction of synchronization-preserving races. Proceedings\
    \ of the ACM on Programming Languages 5, POPL (2021), 1–29.\n- <span id=\"page-11-32\"\
    ></span>[46] Umang Mathur and Mahesh Viswanathan. 2020. Atomicity Checking in\
    \ Linear Time Using Vector Clocks. In Proceedings of the Twenty-Fifth International\
    \ Conference on Architectural Support for Programming Languages and Operating\
    \ Systems (Lausanne, Switzerland) (ASPLOS '20). Association for Computing Machinery,\
    \ New York, NY, USA, 183–199.<https://doi.org/10.1145/3373376.3378475>\n- <span\
    \ id=\"page-11-23\"></span>[47] Patrick Meredith and Grigore Roşu. 2010. Runtime\
    \ verification with the RV system. In International Conference on Runtime Verification.\
    \ Springer, 136–152.\n- <span id=\"page-11-10\"></span>[48] Edward F. Moore. 1959.\
    \ The shortest path through a maze. In Proc. Internat. Sympos. Switching Theory\
    \ 1957, Part II. Harvard Univ. Press, Cambridge, Mass., 285–292.\n\n- <span id=\"\
    page-12-11\"></span>[49] Arndt Müehlenfeld and Franz Wotawa. 2007. Fault Detection\
    \ in Multi-threaded C++ Server Applications. In Proceedings of the 12th ACM SIGPLAN\
    \ Symposium on Principles and Practice of Parallel Programming (San Jose, California,\
    \ USA) (PPoPP '07). ACM, New York, NY, USA, 142–143.<https://doi.org/10.1145/1229428.1229457>\n\
    - <span id=\"page-12-22\"></span>[50] Suvam Mukherjee, Pantazis Deligiannis, Arpita\
    \ Biswas, and Akash Lal. 2020. Learning-based controlled concurrency testing.\
    \ Proceedings of the ACM on Programming Languages 4, OOPSLA (2020), 1–31.\n- <span\
    \ id=\"page-12-17\"></span>[51] Mayur Naik, Alex Aiken, and John Whaley. 2006.\
    \ Effective static race detection for Java. In Proceedings of the 27th ACM SIGPLAN\
    \ Conference on Programming Language Design and Implementation. 308–319.\n- <span\
    \ id=\"page-12-19\"></span>[52] Brian Norris and Brian Demsky. 2013. CDSchecker:\
    \ Checking Concurrent Data Structures Written with C/C++ Atomics. In Proceedings\
    \ of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming\
    \ Systems Languages & Applications (Indianapolis, Indiana, USA) (OOPSLA '13).\
    \ Association for Computing Machinery, New York, NY, USA, 131–150. [https://doi.org/10.1145/2509136.](https://doi.org/10.1145/2509136.2509514)\
    \ [2509514](https://doi.org/10.1145/2509136.2509514)\n- <span id=\"page-12-20\"\
    ></span>[53] Jonas Oberhauser, Rafael Lourenco de Lima Chehab, Diogo Behrens,\
    \ Ming Fu, Antonio Paolillo, Lilith Oberhauser, Koustubha Bhat, Yuzhong Wen, Haibo\
    \ Chen, Jaeho Kim, et al. 2021. VSync: push-button verification and optimization\
    \ for synchronization primitives on weak memory models. In Proceedings of the\
    \ 26th ACM International Conference on Architectural Support for Programming Languages\
    \ and Operating Systems. 530–545.\n- <span id=\"page-12-5\"></span>[54] Andreas\
    \ Pavlogiannis. 2019. Fast, sound, and effectively complete dynamic race prediction.\
    \ Proceedings of the ACM on Programming Languages 4, POPL (2019), 1–29.\n- <span\
    \ id=\"page-12-4\"></span>[55] Eli Pozniansky and Assaf Schuster. 2003. Efficient\
    \ on-the-fly data race detection in multithreaded C++ programs. In Proceedings\
    \ of the ninth ACM SIGPLAN symposium on Principles and practice of parallel programming.\
    \ 179–190.\n- <span id=\"page-12-12\"></span>[56] Jake Roemer, Kaan Genç, and\
    \ Michael D Bond. 2020. SmartTrack: efficient predictive race detection. In Proceedings\
    \ of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation.\
    \ 747–762.\n- <span id=\"page-12-1\"></span>[57] Jake Roemer, Kaan Genç, and Michael\
    \ D. Bond. 2018. High-Coverage, Unbounded Sound Predictive Race Detection. In\
    \ Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design\
    \ and Implementation (Philadelphia, PA, USA) (PLDI 2018). Association for Computing\
    \ Machinery, New York, NY, USA, 374–389.<https://doi.org/10.1145/3192366.3192385>\n\
    - <span id=\"page-12-13\"></span>[58] Jake Roemer, Kaan Genç, and Michael D. Bond.\
    \ 2018. High-Coverage, Unbounded Sound Predictive Race Detection. In Proceedings\
    \ of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation\
    \ (Philadelphia, PA, USA) (PLDI 2018). Association for Computing Machinery, New\
    \ York, NY, USA, 374–389.<https://doi.org/10.1145/3192366.3192385>\n- <span id=\"\
    page-12-0\"></span>[59] Caitlin Sadowski and Jaeheon Yi. 2014. How Developers\
    \ Use Data Race Detection Tools. In Proceedings of the 5th Workshop on Evaluation\
    \ and Usability of Programming Languages and Tools (Portland, Oregon, USA) (PLATEAU\
    \ '14). Association for Computing Machinery, New York, NY, USA, 43–51. [https:](https://doi.org/10.1145/2688204.2688205)\
    \ [//doi.org/10.1145/2688204.2688205](https://doi.org/10.1145/2688204.2688205)\n\
    - <span id=\"page-12-2\"></span>[60] Mahmoud Said, Chao Wang, Zijiang Yang, and\
    \ Karem Sakallah. 2011. Generating data race witnesses by an SMT-based analysis.\
    \ In NASA Formal Methods Symposium. Springer, 313–327.\n- <span id=\"page-12-16\"\
    ></span>[61] Stefan Savage, Michael Burrows, Greg Nelson, Patrick Sobalvarro,\
    \ and Thomas Anderson. 1997. Eraser: A dynamic data race detector for multithreaded\
    \ programs. ACM Transactions on Computer Systems (TOCS) 15, 4 (1997), 391–411.\n\
    - <span id=\"page-12-8\"></span>[62] Adrian Schmitz, Joachim Protze, Lechen Yu,\
    \ Simon Schwitanski, and Matthias S Müller. 2019. DataRaceOnAccelerator–a micro-benchmark\
    \ suite for evaluating correctness tools targeting accelerators. In European Conference\
    \ on Parallel Processing. Springer, 245–257.\n- <span id=\"page-12-7\"></span>[63]\
    \ Koushik Sen, Grigore Roşu, and Gul Agha. 2005. Detecting errors in multithreaded\
    \ programs by generalized predictive analysis of executions. In Formal Methods\
    \ for Open Object-Based Distributed Systems: 7th IFIP WG 6.1 International Conference,\
    \ FMOODS 2005, Athens, Greece, June 15-17, 2005. Proceedings 7. Springer, 211–226.\n\
    - <span id=\"page-12-9\"></span>[64] Konstantin Serebryany and Timur Iskhodzhanov.\
    \ 2009. ThreadSanitizer: data race detection in practice. In Proceedings of the\
    \ workshop on binary instrumentation and applications. 62–71.\n- <span id=\"page-12-3\"\
    ></span>[65] Yannis Smaragdakis, Jacob Evans, Caitlin Sadowski, Jaeheon Yi, and\
    \ Cormac Flanagan. 2012. Sound Predictive Race Detection in Polynomial Time. In\
    \ Proceedings of the 39th Annual ACM SIGPLAN-SIGACT Symposium on Principles of\
    \ Programming Languages (Philadelphia, PA, USA) (POPL '12). Association for Computing\
    \ Machinery, New York, NY, USA, 387–400. [https://doi.org/10.1145/](https://doi.org/10.1145/2103656.2103702)\
    \ [2103656.2103702](https://doi.org/10.1145/2103656.2103702)\n- <span id=\"page-12-15\"\
    ></span>[66] Francesco Sorrentino, Azadeh Farzan, and P. Madhusudan. 2010. PENELOPE:\
    \ Weaving Threads to Expose Atomicity Violations. In Proceedings of the Eighteenth\
    \ ACM SIGSOFT International Symposium on Foundations of Software Engineering (Santa\
    \ Fe, New Mexico, USA) (FSE '10). Association for Computing Machinery, New York,\
    \ NY, USA, 37–46.<https://doi.org/10.1145/1882291.1882300>\n- <span id=\"page-12-24\"\
    ></span>[67] Mosaad Al Thokair, Minjian Zhang, Umang Mathur, and Mahesh Viswanathan.\
    \ 2023. Dynamic Race Detection with O (1) Samples. Proceedings of the ACM on Programming\
    \ Languages 7, POPL (2023), 1308–1337.\n- <span id=\"page-12-14\"></span>[68]\
    \ Hünkar Can Tunç, Umang Mathur, Andreas Pavlogiannis, and Mahesh Viswanathan.\
    \ 2023. Sound Dynamic Deadlock Prediction in Linear Time. Proc. ACM Program. Lang.\
    \ 7, PLDI, Article 177 (jun 2023), 26 pages. [https:](https://doi.org/10.1145/3591291)\
    \ [//doi.org/10.1145/3591291](https://doi.org/10.1145/3591291)\n- <span id=\"\
    page-12-10\"></span>[69] Michael Wang, Shashank Srikant, Malavika Samak, and Una-May\
    \ O'Reilly. 2023. RaceInjector: Injecting Races to Evaluate and Learn Dynamic\
    \ Race Detection Algorithms. In Proceedings of the 12th ACM SIGPLAN International\
    \ Workshop on the State Of the Art in Program Analysis. 63–70.\n- <span id=\"\
    page-12-6\"></span>[70] Ryan Williams. 2005. A new algorithm for optimal 2-constraint\
    \ satisfaction and its implications. Theoretical Computer Science 348, 2 (2005),\
    \ 357–365. [https://doi.org/](https://doi.org/10.1016/j.tcs.2005.09.023) [10.1016/j.tcs.2005.09.023](https://doi.org/10.1016/j.tcs.2005.09.023)\
    \ Automata, Languages and Programming: Algorithms and Complexity (ICALP-A 2004).\n\
    - <span id=\"page-12-23\"></span>[71] Meng Xu, Sanidhya Kashyap, Hanqing Zhao,\
    \ and Taesoo Kim. 2020. Krace: Data race fuzzing for kernel file systems. In 2020\
    \ IEEE Symposium on Security and Privacy (SP). IEEE, 1643–1660.\n- <span id=\"\
    page-12-21\"></span>[72] Xinhao Yuan, Junfeng Yang, and Ronghui Gu. 2018. Partial\
    \ order aware concurrency sampling. In Computer Aided Verification: 30th International\
    \ Conference, CAV 2018, Held as Part of the Federated Logic Conference, FloC 2018,\
    \ Oxford, UK, July 14-17, 2018, Proceedings, Part II 30. Springer, 317–335.\n\
    - <span id=\"page-12-18\"></span>[73] Sheng Zhan and Jeff Huang. 2016. ECHO: instantaneous\
    \ in situ race detection in the IDE. In Proceedings of the 2016 24th ACM SIGSOFT\
    \ International Symposium on Foundations of Software Engineering. 775–786.\n\n\
    #### A PROOFS FROM SECTION 3\n\n#### <span id=\"page-13-0\"></span>A.1 Proof of\
    \ Theorem [3.1](#page-3-1)\n\nTheorem [3.1.](#page-3-1) Let be a trace, let 1,\
    \ <sup>2</sup> be conflicting events and let ⊆ Events() be an optimistically lock-closed\
    \ set. The problem of determining whether there is a correct reordering such that\
    \ Events() = and both <sup>1</sup> and <sup>2</sup> are -enabled in is NP-hard.\n\
    \nWe prove this theorem by instead establishing the following stronger Theorem\
    \ [A.1;](#page-13-1) it claims that, the problem of determining if the smallest\
    \ optimistically lock-closed set can be linearized, is NP-hard problem.\n\n<span\
    \ id=\"page-13-1\"></span>Theorem A.1. Let be a trace, let 1, <sup>2</sup> be\
    \ conflicting events, and let = OLClosure(e1, e2). The problem of determining\
    \ whether there is a correct reordering s.t. Events() = is NP-hard.\n\nThe high\
    \ level idea behind our proof of is inspired from [\\[44\\]](#page-11-4), which\
    \ shows that the problem of checking if a given pair of conflicting events is\
    \ a predictable data race, is NP-hard. In [\\[44\\]](#page-11-4), the proof proceeds\
    \ by first showing that an intermediate problem, namely RF-poset realizability,\
    \ is NP-hard. An instance of this problem is a triple P = (, , ), where is some\
    \ set of read, write, acquire and release events, ⊆ × is a partial order on and\
    \ is a function that maps every read event ∈ to a unique write event ∈ on the\
    \ same memory location. P is a positive intance of RF-poset-realixability if there\
    \ is a linearization of that respects ∪ {(, ) | = ()} and also ensures that between\
    \ any read (resp. release) event and its corresponding write (resp. matching acquire)\
    \ event = (), there is no other write event of the same memory location (resp.\
    \ lock) as . In [\\[44\\]](#page-11-4), the NP-hardness of RF-poset realizability\
    \ is established via a reduction from INDEPENDENT-SET(c), which is the problem\
    \ of checking if for an input graph , there is an independent set of of size at\
    \ least . Following this, [\\[44\\]](#page-11-4) establishes a reduction from\
    \ RF-poset realizability to the race prediction problem.\n\nOur proof is inspired\
    \ from this, but is a direct reduction from INDEPENDENT-SET(c) to our problem\
    \ — given a trace and a pair (1, 2), determine if there is a correct reordering\
    \ containing exactly the events OLClosure(e1, e2). Given an input graph (instance\
    \ of RF-poset realizability problem), we construct trace with two events 1 and\
    \ 2 in as follows. We first construct an intermediate RF-poset instace P by slightly\
    \ modifying the RF-poset instance constructed by [\\[44\\]](#page-11-4), ensuring\
    \ that P is realizable iff the graph has an independent set of size ≥ . Starting\
    \ with P, we can then construct a trace with two specific events 1, <sup>2</sup>\
    \ such that P can be realized iff there is a correct reordering of for which OLClosure(e1,\
    \ e2) can be linearized.\n\nProof. Given an INDEPENDENT-SET(c) problem on graph\
    \ , we encode a RF-poset realizability instance P as following. The set of events\
    \ belong to 2 + 2 threads 1, <sup>2</sup> . . . 2+2, and we describe the total\
    \ order of events in each thread next.\n\n$$\\begin{array}{l} \\text{(1) For }\
    \ i = 2 \\cdot c + 1, \\,\\tau\\_{\\bar{t}} = \\mathbf{w}(q), \\mathbf{w}(v\\\
    _{2c+1}) \\\\ \\text{(2) For } i = 2 \\cdot c + 2, \\,\\tau\\_{\\bar{t}} = \\\
    tau\\_{\\bar{t}}^1 \\circ \\tau\\_{\\bar{t}}^2, \\text{ where } \\bar{t} \\end{array}$$\n\
    \n$$\\tau\\_{\\mathfrak{t}}^{1} = \\mathbf{r}(\\mathsf{s}\\_{1}), \\dots, \\mathbf{r}(\\\
    mathsf{s}\\_{\\mathcal{C}}), \\mathbf{acq}(\\ell\\_{\\mathfrak{l}}), \\dots, \\\
    mathbf{acq}(\\ell\\_{\\mathfrak{c}}), \\mathbf{r}(q), \\mathbf{w}\\_{\\mathfrak{l}}(\\\
    mathbf{x}), \\mathbf{rel}(\\ell\\_{\\mathfrak{c}}), \\dots, \\mathbf{rel}(\\ell\\\
    _{\\mathfrak{l}}).$$\n\n$$\\text{Let } C\\_{\\mathfrak{l}} = \\mathbf{r}(v\\_{\\\
    mathfrak{l} + \\mathbf{c}}) \\cdot \\mathbf{r}(v\\_{\\mathfrak{l}}) \\text{ and\
    \ } \\tau\\_{\\mathfrak{l}}^{2} = \\mathbf{r}(v\\_{2\\mathfrak{c} + \\mathbf{1}})\
    \ \\diamond C\\_{\\mathfrak{c}} \\diamond \\cdots \\diamond C\\_{\\mathfrak{l}}.$$\n\
    \n(3) For each integer 1 ≤ ≤ , = 1 ◦ 2 ◦. . . ◦w(). For 2 ≤ ≤ − 1, we have = acq\
    \ (ℓ,<sup>1</sup> ), . . . , acq (ℓ, ), w( ), r( ),rel(ℓ, ), . . . ,rel(ℓ,<sup>1</sup>\
    \ ), where 1, . . . , denotes the neighbors of node in graph . Let 1 = acq (ℓ1,<sup>1</sup>\
    \ ), . . . , acq (ℓ1, ), w(),r( 1 ) rel(ℓ1, ), . . . ,rel(ℓ1,<sup>1</sup> ), and\
    \ = acq (ℓ,<sup>1</sup> ), . . . , acq (ℓ, ), w( ),r(),rel(ℓ, ), . . . rel(ℓ,<sup>1</sup>\
    \ ). 1 2\n\n(4) For each integer + 1 ≤ ≤ 2, = ◦ ◦ . . . ◦ w(), where = acq (ℓ−\
    \ ), w( − ),r( +1 − ),rel (ℓ− ).\n\nSee an example of the reduction outlined above\
    \ in Figure [7.](#page-14-0) Each variable in P is written once, so the read-from\
    \ relation is clear. The partial order is the thread order induced by the threads\
    \ 1, . . . 2+2.\n\nWe remark that the poset P is almost identical to the one in\
    \ [\\[44\\]](#page-11-4) (let's call it P ′ ), except for the extra read and write\
    \ events on variables {1, . . . , 2+1} at the end of each thread in P. We will\
    \ use P′ to denote the subset of events that belong to P ′ .\n\nLet us first argue\
    \ that P is realizable iff P ′ is realizable. If P ′ is realizable, then there\
    \ is a linearization ′ of P′ that preserves thread order and the reads-from of\
    \ events in P′ . Consider the the trace = ′ , w(1) . . . w(2 ),r(1) . . . r(2\
    \ ), where we omit the obvious thread identifiers of events on {1, . . . , 2+1}.\
    \ Clearly, ′ witnesses the realizability of P. Now, if P ′ is realizable using\
    \ a linearization , it is easy to argue that the linearization ′ obtained by removing\
    \ events of memory locations {1, . . . , 2+1} witnesses the realizability of P\
    \ ′ . It thus also follows that is a positive instance of INDEPENDENT-SET(c) iff\
    \ P is realizable.\n\nLet us now construct the trace and complete our reduction.\
    \ The set of events of trace will be Events() = ⊎ {w<sup>1</sup> (), w<sup>2</sup>\
    \ ()}, where is a fresh memory location and w<sup>1</sup> () writes to as the\
    \ new last event of 2+1, while w<sup>2</sup> () writes to as the new last event\
    \ of 2+2. Observe that in P, every write event in thread is read by events in\
    \ + for 1 ≤ ≤ . We let be an arbitrary interleaving of and + that respects the\
    \ thread order and read-from relation. We construct the trace to be the following.\n\
    \n$$\\sigma = \\tau\\_{2c+1} \\circ \\text{w}\\_1(a) \\circ \\mathfrak{t}\\_1\
    \ \\circ \\cdots \\circ \\mathfrak{t}\\_c \\circ \\tau\\_{2c+2} \\circ \\text{w}\\\
    _2(a)$$\n\nFirst, it is clear that OLClosure(w<sup>1</sup> (a), w<sup>2</sup>\
    \ (a)) = . Thus, OLClosure(w<sup>1</sup> (a), w<sup>2</sup> (a)) can be linearized\
    \ iff P can be realized. Consequently, the input graph has an independent set\
    \ of size ≥ iff (w<sup>1</sup> (), w<sup>2</sup> ()) is witnessed as a race of\
    \ using OLClosure(w<sup>1</sup> (a), w<sup>2</sup> (a)). Finally, it is clear\
    \ that the construction takes polynomial time in the size of the graph . Thus,\
    \ it follows that the problem of checking if, for a given trace and a pair of\
    \ conflicting events (1, 2) in , whether there is a correct reordering of with\
    \ Events() = OLClosure(e1, e2), is also NP-hard. □\n\n#### B PROOFS FROM SECTION\
    \ 4\n\n#### B.1 Proof of Lemma [4.1](#page-4-3)\n\nLemma [4.1.](#page-4-3) Let\
    \ (1, 2) be a conflicting pair of events in trace . If (1, 2) is an optimistic\
    \ sync-reversal race, then it can be witnessed in an optimistic correct reordering\
    \ with Events() = OLClosure(e1, e2).\n\nProof Sketch. Given and two conflicting\
    \ events e1, e2, let = OLClosure(e1, e2) and be an arbitrary optimistically lock-closed\n\
    \n<span id=\"page-14-0\"></span>![](_page_14_Figure_2.jpeg)\n\nFigure 7: Given\
    \ a graph and independent set size of 2, our construction to show NP-Hardness\
    \ of linearizing OLClosure(e1, e2)\n\nevent set. By definition, is the smallest\
    \ optimistically lock-closed set and thus ⊆ . Let Opt ,Opt be the optimistic-reorderinggraph\
    \ of and , respectively, We now show if there is a cycle in Opt , then Opt also\
    \ has a cycle.\n\nFirst we consider the nodes in Opt and we have for any node\
    \ in Opt , must be in Opt , because is a superset over . Second we show for all\
    \ forward edges → in Opt , this edge also exists in Opt . This is because , are\
    \ also nodes in , and the edge → exists, if both , are in .\n\nNext, we show that\
    \ for each backward edges (, ) in Opt , there is a path from to in Opt ; here,\
    \ by backward edge we mean that ≤ tr . Notice that since (, ) is a backward edge,\
    \ it must be that = last(rel(ℓ)) be the last release of lock ℓ and = acqO(ℓ) is\
    \ an unmatched acquire in , for some ℓ. We first establish that indeed must also\
    \ be unmatched in . Since is optimistically lock closed, it must be that {1, 2}\
    \ ∩ TRClosure(match (a)) ≠ ∅. If, on the contrary, match () ∈ , the fact that\
    \ is (≤ TO,rf )-closed, we must have {1, 2} ∩ ≠ ∅. Clearly this would contradicts\
    \ the fact that is optimistically lock-closed. Thus, is unmatched even in\n\n\
    . Further, from the definition of Opt , it follows that ( ′ , ) is an edge of\
    \ Opt .\n\nNow let ′ = last(rel(ℓ)) We have ≤ tr ′ , because ⊆ . This means that\
    \ there is a path in Opt of the form → ′ → in Opt . In other words, all paths\
    \ of Opt are preserved in Opt and thus, so are the cycles of Opt .\n\nBy definition,\
    \ if (e1, e2) is an optimistic sync-reversal race, there is a optimistic correct\
    \ reordering , s.t. the optimistic-reorderinggraph of Events() has no cycle. Then\
    \ we can conclude Opt also has no cycle, thus the linearization of Opt can also\
    \ witness this race (thanks to Lemma [4.2\\)](#page-5-2). □\n\n#### B.2 Proof\
    \ of Lemma [4.2](#page-5-2)\n\nLemma [4.2.](#page-5-2) Let be a trace and let\
    \ ⊆ Events() such that is (≤ TO,rf )-closed and also lock-feasible. Then, there\
    \ is an optimistic reordering of on the set iff the graph Opt is acyclic.\n\n\
    Proof Sketch. Let us first assume that Opt is acyclic. Consider a linearization\
    \ of Opt . We argue that is an optimistic reordering of . First, is (≤ TO,rf )-closed\
    \ and Opt orders all events of the same thread as in . Hence respects ≤ TO. Second,\
    \ for every read event, its corresponding writerrf () is in , and further is ordered\
    \ before in the graph Opt , and every other conflicting write ′ is either after\
    \ or before in and thus in Opt and thus in . Finally, lock semantics are preserved\
    \ since is lock-feasible, the matched critical sections are totally ordered and\
    \ further the unmatched acquire is ordered after every other release of the same\
    \ lock. Finally, is an optimistic reordering because the order of matched critical\
    \ sections and the order of conflicting events is preserved because they are explicit\
    \ edges in Opt .\n\nNow assume that there is an optimistic reordering of with\
    \ Events() = . We will argue that for every edge (1, 2) of Opt , we have <sup>1</sup>\
    \ ≤ tr 2. This would imply that Opt is acyclic, since is acylic. First, consider\
    \ the case when (1, 2) is such that <sup>1</sup> ≤ TO 2. Since is a correct reordering\
    \ of , we must also have <sup>1</sup> ≤ TO 2. Second, consider the case when <sup>1</sup>\
    \ = rel(ℓ) and <sup>2</sup> = acq(ℓ). If <sup>2</sup> is matched in , then we\
    \ have <sup>1</sup> ≤ tr <sup>2</sup> since is an optimistic reordering. Otherwise,\
    \ <sup>2</sup> is an unmatched acquire and must be placed last in anyway. Finally,\
    \ if <sup>1</sup> ⊲⊳ 2, then the fact that 1 ≤ tr <sup>2</sup> and that orders\
    \ conflicting events the same way as implies that <sup>1</sup> ≤ tr 2. □\n\n####\
    \ B.3 Proof of Lemma [4.3](#page-5-3)\n\nLemma [4.3.](#page-5-3) Let 1, 2, ′ 2\
    \ ∈ Events() be events in trace with <sup>2</sup> ≤ TO ′ 2 . Let = OLClosure(e1,\
    \ e2) and let ′ = OLClosure(e1, e ′ 2 ). We have the following: (1) ⊆ ′ . (2)\
    \ = ComputeOLClosure(1, 2, ∅), and further this call (in Algorithm [1\\)](#page-4-4)\
    \ takes e(| |) time. (3) ′ = ComputeOLClosure(1, ′ 2 , ), and further this call\
    \ (in Algorithm [1\\)](#page-4-4) takes e(| ′ | − | |) time.\n\nProof Sketch.\
    \ We first show ComputeOLClosure(1, 2, ∅) = . For convenience, we denote as after\
    \ i-th iteration in Algorithm [1.](#page-4-4) Now we prove ComputeOLClosure(1,\
    \ 2, ∅) ⊆ by induction.\n\n- Firstly, the initial set <sup>0</sup> ⊆\n- Assuming\
    \ after iterations, ⊆ , we show +<sup>1</sup> ⊆ . By definition of ComputeOLClosure,\
    \ +<sup>1</sup> = ∪TRClosure(rel), where match (rel) ∈ and {1, 2} ∩ TRClosure(rel)\
    \ = ∅. Since ⊆ , by definition of OLClosure(e1, e2), we have rel ∈ and therefore\
    \ +<sup>1</sup> ⊆\n\nSo far we proved ComputeOLClosure(1, 2, ∅) ⊆ . Further we\
    \ claim ComputeOLClosure(1, 2, ∅) is optimistic lock-closed. Otherwise, the while\
    \ loop in Algorithm [1](#page-4-4) will not terminate. This proves = ComputeOLClosure(1,\
    \ 2, ∅).\n\nNow we prove ⊆ ′ . We consider an arbitrary run of Algorithm [1](#page-4-4)\
    \ on computing = ComputeOLClosure(1, 2, ∅), and construct another valid run of\
    \ Algorithm [1](#page-4-4) on computing ′ = ComputeOLClosure(1, ′ 2 , ∅). During\
    \ this process, we prove after iterations, ⊆ ′ for all .\n\n(1) We observe <sup>0</sup>\
    \ ⊆ ′ 0 , as prev (2) ∈ TRClosure(prev (e ′ 2 )).\n\n(2) Assuming ⊆ ′ , we prove\
    \ +<sup>1</sup> ⊆ ′ +1 .\n\nFor all release event rel(ℓ), if rel(ℓ) ∉ and {1,\
    \ 2} ∩ TRClosure(rel(ℓ)) = ∅, we have {1, ′ 2 } ∩ TRClosure(rel(ℓ)) = ∅, because\
    \ <sup>2</sup> ≤ TO ′ 2 . Then there are two possibilities. The first being that\
    \ rel(ℓ) ∈ ′ , which means ′ is already a superset of +1, so that +<sup>1</sup>\
    \ ⊆ ′ ⊆ ′ +1 . Alternatively, if rel(ℓ) ∉ ′ , for any update we do for , we can\
    \ also do the same update for ′ . Therefore, after one more iteration, the observation\
    \ of +<sup>1</sup> ⊆ ′ +1 still holds.\n\nThe observation above proves ComputeOLClosure(1,\
    \ 2, ∅) ⊆ ComputeOLClosure(1, ′ 2 , ∅). Since ComputeOLClosure(1, 2, ∅) = and\
    \ ComputeOLClosure(1, ′ 2 , ∅) = ′ , we have ⊆ ′ .\n\nNow we show can be computed\
    \ by ComputeOLClosure in ˜ (| |) time. In each iteration of ComputeOLClosure,\
    \ we need (T L) time to check if any updates can be done, and there are at most\
    \ | | iterations. Therefore, each event is visited at most ˜ (T L) times.\n\n\
    For the third conclusion, we can take as a start point and call ComputeOLClosure(1,\
    \ ′ 2 , ) to compute ′ , as ⊆ ′ . Following the proof of the second conclusion,\
    \ this takes ˜ (| ′ | − | |) time. It remains to show ComputeOLClosure(1, ′ 2\
    \ , ) returns ′ . We show this by induction. We denote ′ as ′ after iterations\
    \ in Algorithm [1.](#page-4-4)\n\n- It's obvious that ′ 0 ⊆ ′\n- Assuming ′ ⊆\
    \ ′ , we show ′ +1 ⊆ ′ . By definition of ComputeOLClosure, ′ +1 = ′ ∪ TRClosure(rel),\
    \ where match (rel) ∈ ′ and {1, ′ 2 } ∩ TRClosure(rel) = ∅. Since ′ ⊆ ′ , by definition\
    \ of OLClosure(e1, e ′ 2 ), we have rel ∈ ′ and therefore ′ +1 ⊆ ′\n\nThis proves\
    \ ComputeOLClosure(1, ′ 2 , ) indeed returns ′ .\n\n□\n\n#### B.4 Proof of Theorem\
    \ [4.1](#page-5-4)\n\nTheorem [4.1.](#page-5-4) Let be a trace and let 1, <sup>2</sup>\
    \ be conflicting events in . The problem of determining if (1, 2) is an optimistic\
    \ syncreversal race can be solved in time T (T N + L) <sup>=</sup> e(N ) time.\n\
    \nProof. For given 1, 2, to determine if they are OSR race, we firstly compute\
    \ their optimistic lock closure, check for lockfeasibility and then build the\
    \ abstract graph to check for cycles. We have shown in Section [4.1](#page-4-2)\
    \ that for any given 1, 2, OLClosure(e1, <sup>e</sup>2) can be computed in (T2N\
    \ ). Lock-feasibility can be checked in (T L) time.\n\nTo build the graph, we\
    \ firstly add all vertices and backward edges. Later, we compute earliest successors\
    \ for each vertex in the graph and add forward edges correspondingly. The abstract\
    \ graph contains at most 2L nodes by definition. Also in Section [4.2,](#page-5-0)\
    \ we have shown that it takes (L) time to add all backward edges and (T2L) time\
    \ to add all forward edges. Checking cycles in the graph takes (L + L<sup>2</sup>\
    \ ) time, as there are at most (L) vertices and (L<sup>2</sup> ) edges. Therefore,\
    \ building the graph and checking for cycle take (L + L + T2L + L<sup>2</sup>\
    \ ), i.e. (L (T<sup>2</sup> + L)) in total.\n\nTo do race detection on given 1,\
    \ 2, it takes (NT<sup>2</sup> + LT + L (T<sup>2</sup> + L)), i.e. (T2N + L<sup>2</sup>\
    \ ) □\n\n#### B.5 Proof of Theorem [4.2](#page-6-4)\n\nTheorem [4.2.](#page-6-4)\
    \ Let be an execution, ∈ Events() be a read or write event and let ∈ Threads().\
    \ The problem of checking if there is an event ′ with th( ′ ) = such that (, ′\
    \ ) is an optimisticsync-reversal race, can be solved in time (T<sup>2</sup> +\
    \ L)LN .\n\nProof. Following Algorithm [3,](#page-6-3) the computation ComputeOLClosure\
    \ for each (, ′ ), s.t. th( ′ ) = is equivalent to compute the ComputeOLClosure\
    \ for and the last ′ in thread , which can be done in (T2N ) time.\n\nWe also\
    \ need to check lock-feasibility, build graph and check cycles for each ′ in .\
    \ There are at most N such ′ . The total time complexity to do so is (N (LT +\
    \ L (T<sup>2</sup> + L))), i.e. (NL (T<sup>2</sup> + L)).\n\nIn total, we need\
    \ (T2N + NL (T<sup>2</sup> + L)), i.e. (T<sup>2</sup> + L)LN time to check for\
    \ all races between (, ′ ), s.t. th( ′ ) = □\n\n#### B.6 Proof of Theorem [4.3](#page-7-4)\n\
    \nTheorem [4.3.](#page-7-4) Given a trace , the problem of checking if has an\
    \ optimistic sync-reversal data race, can be solved in time T L (T<sup>2</sup>\
    \ + L)N<sup>2</sup> <sup>=</sup> e(N<sup>2</sup> ) time.\n\nProof. Following Algorithm\
    \ [4,](#page-7-2) we iterate over all events and for a fixed event , we iterate\
    \ over all threads. Therefore, Algorithm [3](#page-6-3) is called at most(T N\
    \ ) times. Then the total complexity to check for races is bound by (T N · (T<sup>2</sup>\
    \ + L)LN ), i.e. (T L (T<sup>2</sup> + L)N<sup>2</sup> time. □\n\n#### B.7 Proof\
    \ of Lemma [4.4](#page-6-1)\n\nLemma [4.4.](#page-6-1) Let be a trace and let\
    \ ⊆ Events() be a (≤ TO,rf ) closed set. Opt has a cycle iff Abs has a cycle.\n\
    \nProof Sketch. Firstly, we show if there is a cycle in Abs , then there is a\
    \ cycle ′ in Opt . For every edge → in , if it is a forward edge, then we replace\
    \ it with the corresponding forward path from to . If → is a backward edge, then\
    \ we keep as it is. After this substitution, we get the replaced as a cycle ′\
    \ in Opt .\n\nIf there is a cycle ′ in Opt , then there is a cycle in Abs . Considering\
    \ the edges in ′ , must contain backward edges, otherwise ′ cannot be a cycle.\
    \ Let be the set of backward edges in and be the set of nodes in . We observe\
    \ that is a subset of the vertices in Opt , because the vertex set of Opt is a\
    \ super set over Abs .\n\nTherefore, can be constructed as following. First we\
    \ keep all last release and open acquire event as nodes in ′ . Second we add all\
    \ backward edges in to ′ . Lastly, we replace all forward paths (paths don't contain\
    \ backward edges) in with a direct edge and add them into ′ . We now have successfully\
    \ constructed cycle ′ in Abs . □\n\n#### <span id=\"page-16-0\"></span>B.8 Proof\
    \ of Theorem [4.4](#page-7-5)\n\nTheorem [4.4.](#page-7-5) Assume SETH holds.\
    \ Given an arbitrary trace , the problem of determining if has an OSR race cannot\
    \ be solved in time (N2− ) (where N = |Events()|) for every > 0.\n\nOrthogonal\
    \ Vector Hypothesis (OV). The Orthogonal Vectors problem is defined as following.\
    \ Given two sets, each containing <sup>N</sup> -dimensional 0-1 vectors, where\
    \ <sup>=</sup> e((N )), determine if there exists two vectors <sup>1</sup> ∈ ,\
    \ <sup>2</sup> ∈ , s.t. (1, 2) has an inner product of zero. OV Hypothesis is\
    \ a well-known conjecture and it has been widely accepted that it's not likely\
    \ to give a sub-quadratic\n\n<span id=\"page-16-1\"></span>![](_page_16_Figure_16.jpeg)\n\
    \nFigure 8: Given two sets , of vectors of length 2, our construction to show\
    \ quadratic hardness of OSR race detection\n\nalgorithm to solve the Orthogonal\
    \ Vector problem [\\[20,](#page-11-47) [36\\]](#page-11-29), i.e. OV Hypothesis\
    \ states OV Problem has a lower bound of e(N )<sup>2</sup> .\n\nWe now reduce\
    \ the existence problem of OSR race to the OV problem and show that the problem\
    \ of determining if there is a OSR race in also has a lower bound of e(N )<sup>2</sup>\
    \ , unless OV Hypothesis fails.\n\nProof. Given two sets , of N -dimensional 0-1\
    \ vectors, we construct a trace as following (shown in Figure [8\\)](#page-16-1).\
    \ contains two threads , . As , are finite sets, we enumerate elements from ,\
    \ as 1, 2, . . . , 1, 2, .... For an arbitrary vector = (1, ..., ), assuming it\
    \ contains non-zero bits, we use a list (1, ..., ) to denote the index of non-zero\
    \ elements in . For example, vector (0, 1, 0, 1) has non-zero bits [2, 4], as\
    \ its 2nd and 4th bits are 1. We define an event clause associated with vector\
    \ as = acq(ℓ<sup>1</sup> ) ◦ · · ·◦acq(ℓ ) ◦w() ◦rel(ℓ ) ◦· · ·◦rel(ℓ<sup>1</sup>\
    \ ). Let = <sup>1</sup> ◦<sup>2</sup> ◦· · ·◦ <sup>N</sup> and = <sup>1</sup>\
    \ ◦<sup>2</sup> ◦ · · · ◦<sup>N</sup> . And we require ∀ ∈ , ′ ∈ , ≤ tr ′ . Then\
    \ we observe a total order ≤ tr on .\n\nNow we show there is a pair of orthogonal\
    \ vectors in , , iff there is a OSR race in . If there is a OSR race (), () in\
    \ , they must correspond to vector ∈ , ∈ . Since ( (), ()) is a data race, they\
    \ must be from different threads and their lock set must be disjoint. Therefore\
    \ ∀ 1 ≤ ≤ , either [] = 0 or [] = 0, thus , are orthogonal.\n\nIf there is a pair\
    \ of orthogonal vector , , then we consider their clause, . Let (), () be the\
    \ two write operations in , and now we show , is a OSR race. For convenience,\
    \ let = OLClosure(w<sup>a</sup> (x), w<sup>b</sup> (x)). The following observations\
    \ hold.\n\n- (1) () ∈ Events(tA) and () ∈ Events(tB), so that ∈ and ∈ .\n- (2)\
    \ = { | ≤ TO prev ( ())} ∪ { | ≤ TO prev ( ())} and ∀ lock ℓ ∈ Locks(S), there\
    \ is at most one open acquire on ℓ, because , are orthogonal, so the\n\nclause\
    \ , don't hold the same lock. This proves is potentially feasible\n\n(3) We guarantee\
    \ has no cycles, as no direct edge is from an acquire event to other events except\
    \ thread order.\n\nFollowing the definition, it's obvious to see () and () is\
    \ a OSR race, and thus we have proved there is a pair of orthogonal vectors in\
    \ , , iff there is a OSR race in . If OV Hypothesis holds, then the problem of\
    \ checking existence of OSR race has a lower bound of e(N )<sup>2</sup> .\n\n\
    □\n\n#### <span id=\"page-17-0\"></span>C EXTRA TABLES FOR SECTION 5\n\nTable\
    \ 3: Statistics of the Java benchmarks. N, T, V, L, Reads, Writes, Acq are the\
    \ number of events, threads, variables, locks, read events, write events and acquire\
    \ events after filtering, respectively.\n\n| Benchmark  | N    | T  | V   | L\
    \   | Reads | Writes | Acq  | Benchmark   | N    | T  | V   | L   | Reads | Writes\
    \ | Acq  |\n|------------|------|----|-----|-----|-------|--------|------|-------------|------|----|-----|-----|-------|--------|------|\n\
    | array      | 11   | 3  | 2   | 1   | 1     | 4      | 2    | critical    | 11\
    \   | 4  | 1   | 0   | 2     | 4      | 0    |\n| account    | 15   | 4  | 1 \
    \  | 0   | 6     | 5      | 0    | airtickets  | 18   | 5  | 1   | 0   | 9   \
    \  | 5      | 0    |\n| pingpong   | 24   | 7  | 2   | 0   | 10    | 8      |\
    \ 0    | twostage    | 83   | 12 | 2   | 2   | 20    | 12     | 20   |\n| wronglock\
    \  | 122  | 22 | 1   | 2   | 40    | 21     | 20   | bbuffer     | 9    | 3  |\
    \ 1   | 0   | 2     | 5      | 0    |\n| prodcons   | 246  | 8  | 3   | 1   |\
    \ 125   | 41     | 34   | clean       | 867  | 8  | 2   | 2   | 286   | 96   \
    \  | 239  |\n| mergesort  | 167  | 5  | 1   | 1   | 55    | 7      | 49   | bubblesort\
    \  | 1.6K | 13 | 25  | 1   | 1.1K  | 263    | 119  |\n| lang       | 1.8K | 7\
    \  | 100 | 0   | 1.3K  | 500    | 0    | readswrites | 10K  | 5  | 6   | 1   |\
    \ 4.2K  | 2.2K   | 1.7K |\n| raytracer  | 526  | 3  | 3   | 0   | 514   | 9  \
    \    | 0    | bufwriter   | 10K  | 6  | 6   | 1   | 5.3K  | 2.2K   | 1.4K |\n\
    | ftpserver  | 17K  | 11 | 135 | 143 | 7.9K  | 0.8K   | 4.2K | moldyn      | 21K\
    \  | 3  | 2   | 0   | 21K   | 68     | 0    |\n| linkedlist | 0.9M | 12 | 932\
    \ | 1   | 0.9M  | 1.9K   | 1.0K | derby       | 75K  | 4  | 190 | 133 | 19K  \
    \ | 12K    | 22K  |\n| jigsaw     | 3.2K | 8  | 51  | 45  | 551   | 498    | 1.1K\
    \ | sunflow     | 3.3K | 17 | 20  | 7   | 2.0K  | 125    | 585  |\n| cryptorsa\
    \  | 1.3M | 7  | 18  | 27  | 709K  | 287K   | 156K | xalan       | 671K | 7  |\
    \ 72  | 138 | 205K  | 99K    | 184K |\n| lufact     | 891K | 5  | 6   | 1   |\
    \ 5.3K  | 2.2K   | 1.4K | batik       | 131  | 7  | 5   | 0   | 115   | 10   \
    \  | 0    |\n| lusearch   | 751K | 8  | 77  | 4   | 751K  | 172    | 53   | tsp\
    \         | 15M  | 10 | 189 | 2   | 15M   | 30K    | 91   |\n| luindex    | 16K\
    \  | 3  | 9   | 4   | 2.6K  | 66     | 6.6K | sor         | 1.9M | 5  | 4   |\
    \ 1   | 633K  | 804    | 633K |\n\n| Table 4: Summarized races and running time\
    \ (in seconds) for RaceInjector traces |  |  |  |  |\n|---------------------------------------------------------------------------------|--|--|--|--|\n\
    |---------------------------------------------------------------------------------|--|--|--|--|\n\
    \n<span id=\"page-19-0\"></span>\n\n| 1                         | 2     | 3  \
    \   | 4     | 5    | 6     | 7    | 8     | 9    | 10    | 11    | 12    | 13\
    \   |\n|---------------------------|-------|-------|-------|------|-------|------|-------|------|-------|-------|-------|------|\n\
    | Benchmark                 | Trace | N     | SHB   |      | WCP   |      | SyncP\
    \ |      | M2    |       | OSR   |      |\n|                           |     \
    \  |       | Races | Time | Races | Time | Races | Time | Races | Time  | Races\
    \ | Time |\n|                           | 43    | 494   | 37    | 0.12 | 28  \
    \  | 0.18 | 37    | 0.21 | 37    | 0.36  | 37    | 0.16 |\n|                 \
    \          | 45    | 494   | 37    | 0.11 | 28    | 0.16 | 37    | 0.22 | 37 \
    \   | 0.34  | 37    | 0.17 |\n|                           | 47    | 494   | 37\
    \    | 0.12 | 28    | 0.18 | 37    | 0.21 | 37    | 0.33  | 37    | 0.15 |\n|\
    \                           | 49    | 494   | 37    | 0.12 | 28    | 0.17 | 37\
    \    | 0.22 | 37    | 0.35  | 37    | 0.16 |\n|                           | 51\
    \    | 494   | 37    | 0.11 | 28    | 0.17 | 37    | 0.19 | 37    | 0.34  | 37\
    \    | 0.16 |\n|                           | 54    | 494   | 37    | 0.12 | 28\
    \    | 0.17 | 37    | 0.2  | 37    | 0.36  | 37    | 0.17 |\n|               \
    \            | 66    | 494   | 37    | 0.12 | 28    | 0.21 | 37    | 0.2  | 37\
    \    | 0.37  | 37    | 0.16 |\n| SHB-missed/ArrayList-27th | 91    | 494   | 37\
    \    | 0.11 | 28    | 0.16 | 37    | 0.21 | 37    | 0.37  | 37    | 0.17 |\n|\
    \                           | 108   | 494   | 44    | 0.11 | 39    | 0.17 | 44\
    \    | 0.21 | 44    | 0.36  | 44    | 0.16 |\n|                           | 109\
    \   | 494   | 44    | 0.11 | 40    | 0.19 | 44    | 0.2  | 44    | 0.36  | 44\
    \    | 0.16 |\n|                           | 115   | 494   | 44    | 0.1  | 40\
    \    | 0.17 | 44    | 0.18 | 44    | 0.36  | 44    | 0.15 |\n|               \
    \            | 118   | 494   | 44    | 0.1  | 40    | 0.16 | 44    | 0.2  | 44\
    \    | 0.36  | 44    | 0.15 |\n|                           | 120   | 494   | 44\
    \    | 0.11 | 40    | 0.18 | 44    | 0.21 | 44    | 0.36  | 44    | 0.15 |\n|\
    \                           | 122   | 494   | 44    | 0.1  | 40    | 0.18 | 44\
    \    | 0.18 | 44    | 0.35  | 44    | 0.15 |\n|                           | 124\
    \   | 494   | 37    | 0.12 | 28    | 0.17 | 37    | 0.21 | 37    | 0.34  | 37\
    \    | 0.16 |\n|                           | 158   | 494   | 37    | 0.11 | 28\
    \    | 0.17 | 37    | 0.22 | 37    | 0.37  | 37    | 0.15 |\n|               \
    \            | 184   | 42461 | 1129  | 0.79 | 739   | 1.09 | 1129  | 1.54 | 1129\
    \  | 50.47 | 1129  | 1.29 |\n|                           | 319   | 42461 | 1129\
    \  | 0.83 | 739   | 1.05 | 1129  | 1.59 | 1129  | 45.16 | 1129  | 1.21 |\n| SHB-missed/Jigsaw-35th\
    \    | 414   | 42461 | 1129  | 0.87 | 739   | 1.08 | 1129  | 1.52 | 1129  | 49.41\
    \ | 1129  | 1.22 |\n|                           | 468   | 42461 | 1129  | 0.8\
    \  | 739   | 1.05 | 1129  | 1.53 | 1129  | 48.49 | 1129  | 1.2  |\n|         \
    \                  | 475   | 42461 | 1129  | 0.87 | 739   | 1.07 | 1129  | 1.57\
    \ | 1129  | 48.01 | 1129  | 1.2  |\n|                           | 484   | 42461\
    \ | 1129  | 0.85 | 739   | 1.05 | 1129  | 1.6  | 1129  | 47.91 | 1129  | 1.23\
    \ |\n|                           | 97    | 635   | 42    | 0.11 | 35    | 0.17\
    \ | 42    | 0.19 | 42    | 0.3   | 42    | 0.14 |\n|                         \
    \  | 98    | 635   | 42    | 0.12 | 34    | 0.17 | 42    | 0.19 | 42    | 0.31\
    \  | 42    | 0.14 |\n|                           | 99    | 635   | 42    | 0.12\
    \ | 35    | 0.16 | 42    | 0.19 | 42    | 0.33  | 42    | 0.14 |\n|          \
    \                 | 100   | 635   | 42    | 0.13 | 34    | 0.17 | 42    | 0.21\
    \ | 42    | 0.33  | 42    | 0.14 |\n|                           | 101   | 635\
    \   | 42    | 0.12 | 35    | 0.17 | 42    | 0.22 | 42    | 0.32  | 42    | 0.14\
    \ |\n|                           | 102   | 635   | 42    | 0.12 | 34    | 0.18\
    \ | 42    | 0.2  | 42    | 0.31  | 42    | 0.14 |\n|                         \
    \  | 105   | 635   | 42    | 0.11 | 33    | 0.17 | 42    | 0.21 | 42    | 0.31\
    \  | 42    | 0.14 |\n|                           | 107   | 635   | 42    | 0.12\
    \ | 33    | 0.18 | 42    | 0.2  | 42    | 0.32  | 42    | 0.15 |\n|          \
    \                 | 109   | 635   | 42    | 0.12 | 33    | 0.18 | 42    | 0.19\
    \ | 42    | 0.33  | 42    | 0.14 |\n|                           | 111   | 635\
    \   | 42    | 0.12 | 34    | 0.17 | 42    | 0.19 | 42    | 0.31  | 42    | 0.14\
    \ |\n|                           | 113   | 635   | 42    | 0.12 | 34    | 0.18\
    \ | 42    | 0.21 | 42    | 0.31  | 42    | 0.14 |\n|                         \
    \  | 115   | 635   | 42    | 0.12 | 34    | 0.19 | 42    | 0.2  | 42    | 0.31\
    \  | 42    | 0.19 |\n|                           | 117   | 635   | 42    | 0.11\
    \ | 34    | 0.18 | 42    | 0.18 | 42    | 0.37  | 42    | 0.15 |\n|          \
    \                 | 119   | 635   | 42    | 0.12 | 34    | 0.17 | 42    | 0.21\
    \ | 42    | 0.36  | 42    | 0.14 |\n|                           | 120   | 635\
    \   | 42    | 0.12 | 35    | 0.17 | 42    | 0.19 | 42    | 0.31  | 42    | 0.14\
    \ |\n|                           | 121   | 635   | 42    | 0.11 | 34    | 0.18\
    \ | 42    | 0.21 | 42    | 0.31  | 42    | 0.14 |\n|                         \
    \  | 122   | 635   | 42    | 0.11 | 35    | 0.16 | 42    | 0.2  | 42    | 0.32\
    \  | 42    | 0.14 |\n|                           | 123   | 635   | 42    | 0.11\
    \ | 35    | 0.18 | 42    | 0.2  | 42    | 0.3   | 42    | 0.15 |\n|          \
    \                 | 126   | 635   | 42    | 0.12 | 35    | 0.17 | 42    | 0.2\
    \  | 42    | 0.31  | 42    | 0.14 |\n|                           | 127   | 635\
    \   | 42    | 0.11 | 34    | 0.17 | 42    | 0.18 | 42    | 0.32  | 42    | 0.14\
    \ |\n| SHB-missed/TreeSet-22th   | 128   | 635   | 42    | 0.12 | 35    | 0.18\
    \ | 42    | 0.2  | 42    | 0.32  | 42    | 0.15 |\n|                         \
    \  | 129   | 635   | 42    | 0.13 | 34    | 0.17 | 42    | 0.2  | 42    | 0.32\
    \  | 42    | 0.14 |\n|                           | 130   | 635   | 42    | 0.12\
    \ | 35    | 0.18 | 42    | 0.21 | 42    | 0.3   | 42    | 0.15 |\n|          \
    \                 | 131   | 635   | 42    | 0.12 | 34    | 0.18 | 42    | 0.19\
    \ | 42    | 0.32  | 42    | 0.14 |\n|                           | 132   | 635\
    \   | 42    | 0.13 | 35    | 0.17 | 42    | 0.2  | 42    | 0.31  | 42    | 0.14\
    \ |\n\n| 1                           | 2     | 3     | 4     | 5    | 6     |\
    \ 7    | 8     | 9    | 10    | 11    | 12    | 13   |\n|-----------------------------|-------|-------|-------|------|-------|------|-------|------|-------|-------|-------|------|\n\
    | Benchmark                   | Trace | N     | SHB   |      | WCP   |      |\
    \ SyncP |      | M2    |       | OSR   |      |\n|                           \
    \  |       |       | Races | Time | Races | Time | Races | Time | Races | Time\
    \  | Races | Time |\n|                             | 133   | 635   | 42    | 0.13\
    \ | 35    | 0.17 | 42    | 0.2  | 42    | 0.32  | 42    | 0.14 |\n|          \
    \                   | 134   | 635   | 42    | 0.12 | 35    | 0.18 | 42    | 0.21\
    \ | 42    | 0.31  | 42    | 0.15 |\n|                             | 135   | 635\
    \   | 42    | 0.11 | 35    | 0.18 | 42    | 0.19 | 42    | 0.32  | 42    | 0.15\
    \ |\n|                             | 136   | 635   | 42    | 0.12 | 35    | 0.19\
    \ | 42    | 0.2  | 42    | 0.33  | 42    | 0.14 |\n|                         \
    \    | 137   | 635   | 42    | 0.11 | 35    | 0.17 | 42    | 0.19 | 42    | 0.33\
    \  | 42    | 0.14 |\n|                             | 138   | 635   | 42    | 0.12\
    \ | 35    | 0.17 | 42    | 0.21 | 42    | 0.31  | 42    | 0.15 |\n|          \
    \                   | 139   | 635   | 42    | 0.12 | 35    | 0.18 | 42    | 0.17\
    \ | 42    | 0.3   | 42    | 0.15 |\n|                             | 140   | 635\
    \   | 42    | 0.12 | 35    | 0.19 | 42    | 0.2  | 42    | 0.32  | 42    | 0.14\
    \ |\n|                             | 141   | 635   | 42    | 0.13 | 35    | 0.19\
    \ | 42    | 0.19 | 42    | 0.3   | 42    | 0.14 |\n|                         \
    \    | 142   | 635   | 42    | 0.12 | 35    | 0.18 | 42    | 0.19 | 42    | 0.32\
    \  | 42    | 0.15 |\n|                             | 143   | 635   | 42    | 0.12\
    \ | 35    | 0.17 | 42    | 0.19 | 42    | 0.32  | 42    | 0.15 |\n|          \
    \                   | 144   | 635   | 42    | 0.11 | 35    | 0.16 | 42    | 0.2\
    \  | 42    | 0.31  | 42    | 0.14 |\n|                             | 145   | 635\
    \   | 42    | 0.12 | 35    | 0.17 | 42    | 0.21 | 42    | 0.32  | 42    | 0.15\
    \ |\n|                             | 149   | 635   | 42    | 0.11 | 35    | 0.17\
    \ | 42    | 0.19 | 42    | 0.32  | 42    | 0.15 |\n|                         \
    \    | 150   | 635   | 42    | 0.12 | 34    | 0.17 | 42    | 0.22 | 42    | 0.31\
    \  | 42    | 0.14 |\n|                             | 151   | 635   | 42    | 0.13\
    \ | 35    | 0.2  | 42    | 0.19 | 42    | 0.32  | 42    | 0.14 |\n|          \
    \                   | 98    | 635   | 42    | 0.12 | 34    | 0.17 | 42    | 0.19\
    \ | 42    | 0.33  | 42    | 0.16 |\n|                             | 100   | 635\
    \   | 42    | 0.12 | 34    | 0.17 | 42    | 0.2  | 42    | 0.31  | 42    | 0.16\
    \ |\n|                             | 102   | 635   | 42    | 0.12 | 34    | 0.17\
    \ | 42    | 0.2  | 42    | 0.32  | 42    | 0.15 |\n|                         \
    \    | 109   | 635   | 42    | 0.11 | 33    | 0.18 | 42    | 0.19 | 42    | 0.33\
    \  | 42    | 0.16 |\n|                             | 111   | 635   | 42    | 0.12\
    \ | 34    | 0.18 | 42    | 0.2  | 42    | 0.3   | 42    | 0.16 |\n|          \
    \                   | 113   | 635   | 42    | 0.12 | 34    | 0.17 | 42    | 0.2\
    \  | 42    | 0.32  | 42    | 0.16 |\n|                             | 115   | 635\
    \   | 42    | 0.12 | 34    | 0.17 | 42    | 0.2  | 42    | 0.32  | 42    | 0.16\
    \ |\n|                             | 117   | 635   | 42    | 0.12 | 34    | 0.17\
    \ | 42    | 0.2  | 42    | 0.34  | 42    | 0.16 |\n|                         \
    \    | 119   | 635   | 42    | 0.12 | 34    | 0.16 | 42    | 0.19 | 42    | 0.33\
    \  | 42    | 0.16 |\n|                             | 121   | 635   | 42    | 0.12\
    \ | 34    | 0.17 | 42    | 0.19 | 42    | 0.32  | 42    | 0.16 |\n| WCP-missed/TreeSet-22th\
    \     | 123   | 635   | 42    | 0.11 | 35    | 0.18 | 42    | 0.2  | 42    | 0.31\
    \  | 42    | 0.16 |\n|                             | 127   | 635   | 42    | 0.12\
    \ | 34    | 0.18 | 42    | 0.21 | 42    | 0.32  | 42    | 0.16 |\n|          \
    \                   | 129   | 635   | 42    | 0.11 | 34    | 0.17 | 42    | 0.2\
    \  | 42    | 0.32  | 42    | 0.15 |\n|                             | 131   | 635\
    \   | 42    | 0.12 | 34    | 0.18 | 42    | 0.18 | 42    | 0.34  | 42    | 0.15\
    \ |\n|                             | 133   | 635   | 42    | 0.12 | 35    | 0.17\
    \ | 42    | 0.2  | 42    | 0.33  | 42    | 0.16 |\n|                         \
    \    | 135   | 635   | 42    | 0.12 | 35    | 0.18 | 42    | 0.19 | 42    | 0.31\
    \  | 42    | 0.17 |\n|                             | 137   | 635   | 42    | 0.12\
    \ | 35    | 0.16 | 42    | 0.2  | 42    | 0.32  | 42    | 0.16 |\n|          \
    \                   | 139   | 635   | 42    | 0.11 | 35    | 0.19 | 42    | 0.19\
    \ | 42    | 0.3   | 42    | 0.15 |\n|                             | 141   | 635\
    \   | 42    | 0.11 | 35    | 0.2  | 42    | 0.21 | 42    | 0.31  | 42    | 0.15\
    \ |\n|                             | 143   | 635   | 42    | 0.12 | 35    | 0.19\
    \ | 42    | 0.18 | 42    | 0.31  | 42    | 0.15 |\n|                         \
    \    | 145   | 635   | 42    | 0.12 | 35    | 0.17 | 42    | 0.19 | 42    | 0.33\
    \  | 42    | 0.16 |\n|                             | 109   | 494   | 44    | 0.11\
    \ | 40    | 0.16 | 44    | 0.2  | 44    | 0.39  | 44    | 0.16 |\n|          \
    \                   | 118   | 494   | 44    | 0.11 | 40    | 0.16 | 44    | 0.19\
    \ | 44    | 0.37  | 44    | 0.16 |\n| SyncP-missed/ArrayList-27th | 120   | 494\
    \   | 44    | 0.1  | 40    | 0.16 | 44    | 0.2  | 44    | 1.21  | 44    | 0.14\
    \ |\n|                             | 122   | 494   | 44    | 0.12 | 40    | 0.17\
    \ | 44    | 0.19 | 44    | 0.38  | 44    | 0.14 |\n|                         \
    \    | 219   | 42461 | 1129  | 0.85 | 739   | 1.08 | 1129  | 1.47 | 1129  | 48.19\
    \ | 1129  | 1.51 |\n| SyncP-missed/Jigsaw-35th    | 475   | 42461 | 1129  | 0.81\
    \ | 739   | 1.07 | 1129  | 1.57 | 1129  | 48.48 | 1129  | 1.44 |\n|          \
    \                   |       |       |       |      |       |      |       |  \
    \    |       |       |       |      |\n|                             | 484   |\
    \ 42461 | 1129  | 0.8  | 739   | 1.06 | 1129  | 1.41 | 1129  | 47.2  | 1129  |\
    \ 1.43 |\n|                             | 97    | 635   | 42    | 0.12 | 35  \
    \  | 0.17 | 42    | 0.2  | 42    | 0.36  | 42    | 0.15 |\n|                 \
    \            | 99    | 635   | 42    | 0.11 | 35    | 0.16 | 42    | 0.19 | 42\
    \    | 0.36  | 42    | 0.15 |\n|                             | 101   | 635   |\
    \ 42    | 0.12 | 35    | 0.18 | 42    | 0.2  | 42    | 0.36  | 42    | 0.16 |\n\
    |                             | 120   | 635   | 42    | 0.11 | 35    | 0.17 |\
    \ 42    | 0.19 | 42    | 0.36  | 42    | 0.17 |\n\nICSE '24, April 12–21, 2024,\
    \ Lisbon, Portugal Zheng Shi, Umang Mathur, and Andreas Pavlogiannis\n\n| 1  \
    \       | 2     | 3   | 4     | 5    | 6     | 7    | 8     | 9    | 10    | 11\
    \   | 12    | 13   |\n|-----------|-------|-----|-------|------|-------|------|-------|------|-------|------|-------|------|\n\
    | Benchmark | Trace | N   | SHB   |      | WCP   |      | SyncP |      | M2  \
    \  |      | OSR   |      |\n|           |       |     | Races | Time | Races |\
    \ Time | Races | Time | Races | Time | Races | Time |\n|           | 122   | 635\
    \ | 42    | 0.12 | 35    | 0.17 | 42    | 0.2  | 42    | 0.35 | 42    | 0.14 |\n\
    |           | 126   | 635 | 42    | 0.13 | 35    | 0.17 | 42    | 0.2  | 42  \
    \  | 0.37 | 42    | 0.16 |\n|           | 128   | 635 | 42    | 0.13 | 35    |\
    \ 0.19 | 42    | 0.2  | 42    | 0.37 | 42    | 0.16 |\n|           | 130   | 635\
    \ | 42    | 0.13 | 35    | 0.18 | 42    | 0.18 | 42    | 0.38 | 42    | 0.15 |\n\
    |           | 132   | 635 | 42    | 0.12 | 35    | 0.19 | 42    | 0.2  | 42  \
    \  | 0.37 | 42    | 0.15 |\n|           | 134   | 635 | 42    | 0.11 | 35    |\
    \ 0.17 | 42    | 0.2  | 42    | 0.36 | 42    | 0.14 |\n|           | 136   | 635\
    \ | 42    | 0.12 | 35    | 0.17 | 42    | 0.19 | 42    | 0.38 | 42    | 0.16 |\n\
    |           | 138   | 635 | 42    | 0.11 | 35    | 0.16 | 42    | 0.2  | 42  \
    \  | 0.36 | 42    | 0.14 |\n|           | 140   | 635 | 42    | 0.11 | 35    |\
    \ 0.17 | 42    | 0.21 | 42    | 0.36 | 42    | 0.15 |\n|           | 142   | 635\
    \ | 42    | 0.12 | 35    | 0.16 | 42    | 0.19 | 42    | 0.35 | 42    | 0.16 |\n\
    |           | 144   | 635 | 42    | 0.11 | 35    | 0.18 | 42    | 0.19 | 42  \
    \  | 0.35 | 42    | 0.14 |\n\n<span id=\"page-22-0\"></span>Table 5: Details on\
    \ reported races and running time (in minute) by each algorithm on C/C++ benchmarks.\
    \ Column 1-3 states the source of these benchmarks, trace name with number of\
    \ threads and events number after filtering. Columns 4-13 are reported races and\
    \ average running time by each algorithm.\n\n| 1             | 2             \
    \   | 3      | 4      | 5    | 6      | 7    | 8     | 9     | 10    | 11    |\
    \ 12     | 13    |\n|---------------|------------------|--------|--------|------|--------|------|-------|-------|-------|-------|--------|-------|\n\
    |               | Benchmark        | N      | SHB    |      | WCP    |      |\
    \ SyncP |       | M2    |       | OSR    |       |\n| Benchmark Set |        \
    \          |        | Races  | Time | Races  | Time | Races | Time  | Races |\
    \ Time  | Races  | Time  |\n|               | task-16th        | 117M   | 6267\
    \   | 5.5  | 5669   | 14.6 | 1     | 180.0 | 0     | 180.0 | 11757  | 6.5   |\n\
    |               | task-56th        | 117M   | 6267   | 6.1  | 5669   | 14.5 |\
    \ 1     | 180.0 | 0     | 180.0 | 11757  | 5.9   |\n|               | taskdeps-16th\
    \    | 115M   | 5627   | 2.2  | 5190   | 6.5  | 14    | 180.0 | 13    | 180.0\
    \ | 10915  | 3.4   |\n| CoMD          | taskdeps-56th    | 117M   | 6267   | 5.0\
    \  | 5669   | 13.9 | 1     | 180.0 | 0     | 180.0 | 11757  | 5.5   |\n|     \
    \          | taskloop-16th    | 2M     | 257    | 0.1  | 168766 | 0.1  | 0   \
    \  | 180.0 | 474   | 180.0 | 177566 | 0.1   |\n|               | taskloop-56th\
    \    | 4M     | 4982   | 0.1  | 44977  | 0.2  | 0     | 180.0 | 186   | 180.0\
    \ | 194160 | 1.0   |\n|               | openmp-16th      | 115M   | 5627   | 3.3\
    \  | 5190   | 6.8  | 14    | 180.0 | 13    | 180.0 | 10915  | 3.2   |\n|     \
    \          | openmp-56th      | 117M   | 6267   | 5.6  | 5669   | 14.3 | 1   \
    \  | 180.0 | 0     | 180.0 | 11757  | 6.9   |\n| SimpleMOC     | trace-16th  \
    \     | 19M    | 380    | 0.2  | 388    | 23.1 | 32    | 180.0 | 32    | 180.0\
    \ | 32     | 180.0 |\n|               | Amg2013-18th     | 39M    | 140541 | 0.4\
    \  | 107793 | 3.0  | 103   | 180.0 | 102   | 180.0 | 145485 | 0.7   |\n|     \
    \          | Amg2013-58th     | 52M    | 181018 | 1.9  | 133280 | 7.4  | 70  \
    \  | 180.0 | 0     | 180.0 | 190994 | 4.4   |\n|               | Kripke-16th \
    \     | 20M    | 14162  | 0.1  | 44     | 1.4  | 46    | 180.0 | 259   | 180.0\
    \ | 22481  | 0.3   |\n|               | Kripke-56th      | 34M    | 20824  | 1.2\
    \  | 128    | 5.5  | 39    | 180.0 | 12    | 180.0 | 34,155 | 9.8   |\n|     \
    \          | Lulesh-16th      | 10M    | 51621  | 0.3  | 27472  | 0.4  | 1312\
    \  | 180.0 | 620   | 180.0 | 52940  | 0.1   |\n|               | Lulesh-16th \
    \     | 130M   | 158081 | 3.0  | 103306 | 8.8  | 5     | 180.0 | 13    | 180.0\
    \ | 167595 | 4.5   |\n|               | Lulesh-56th      | 14M    | 71676  | 0.3\
    \  | 40322  | 2.7  | 1     | 180.0 | 70    | 180.0 | 73432  | 0.1   |\n| OMPRacer\
    \      | Lulesh-56th      | 156M   | 250954 | 7.8  | 157756 | 27.6 | 1     | 180.0\
    \ | 0     | 180.0 | 261857 | 10.7  |\n|               | miniFE-18th      | 44M\
    \    | 148645 | 0.6  | 51478  | 2.5  | 121   | 180.0 | 77    | 180.0 | 159052\
    \ | 0.3   |\n|               | miniFE-58th      | 63M    | 171460 | 2.7  | 74252\
    \  | 10.6 | 77    | 180.0 | 0     | 180.0 | 191862 | 4.0   |\n|              \
    \ | QuickSilver-56th | 1M     | 20753  | 0.1  | 7288   | 0.1  | 8     | 180.0\
    \ | 610   | 180.0 | 21132  | 0.2   |\n|               | XSBench-16th     | 693.9K\
    \ | 27     | 0.1  | 30     | 0.1  | 221   | 0.9   | 222   | 3.6   | 225    | 0.1\
    \   |\n|               | XSBench-56th     | 710.9K | 89     | 0.1  | 117    |\
    \ 0.1  | 15    | 180.0 | 361   | 17.6  | 370    | 0.1   |\n|               | RSBench-16th\
    \     | 27M    | 22     | 0.3  | 35     | 0.6  | 1271  | 43.7  | 199   | 180.0\
    \ | 1278   | 0.2   |\n|               | RSBench-56th     | 27M    | 95     | 0.1\
    \  | 114    | 1.8  | 0     | 180.0 | 30    | 180.0 | 1405   | 0.3   |\n|     \
    \          | DRACC-009        | 70M    | 16     | 0.2  | 16     | 4.1  | 31  \
    \  | 180.0 | 31    | 142.1 | 32     | 3.3   |\n|               | DRACC-010   \
    \     | 70M    | 16     | 0.4  | 16     | 4.0  | 31    | 180.0 | 31    | 144.4\
    \ | 32     | 2.7   |\n|               | DRACC-011        | 0.5K   | 15     | 0.1\
    \  | 15     | 0.1  | 30    | 0.1   | 30    | 0.1   | 30     | 0.1   |\n|     \
    \          | DRACC-012        | 103M   | 527    | 1.7  | 527    | 16.0 | 542 \
    \  | 180.0 | 22    | 180.0 | 543    | 13.5  |\n|               | DRACC-013   \
    \     | 103M   | 527    | 1.7  | 527    | 22.7 | 542   | 180.0 | 22    | 180.0\
    \ | 543    | 13.7  |\n|               | DRACC-014        | 0.5K   | 15     | 0.1\
    \  | 15     | 0.1  | 30    | 0.1   | 30    | 0.1   | 30     | 0.1   |\n|     \
    \          | DRACC-015        | 70M    | 16     | 0.6  | 16     | 3.7  | 31  \
    \  | 180.0 | 31    | 145.3 | 32     | 3.8   |\n| DRACC-16th    | DRACC-016   \
    \     | 70M    | 16     | 0.7  | 16     | 4.5  | 31    | 180.0 | 31    | 144.9\
    \ | 32     | 4.2   |\n|               | DRACC-017        | 0.5K   | 15     | 0.1\
    \  | 15     | 0.1  | 30    | 0.1   | 30    | 0.1   | 30     | 0.1   |\n|     \
    \          |                  | 0.5K   | 15     | 0.1  | 15     | 0.1  | 30  \
    \  | 0.1   | 30    | 0.1   | 30     | 0.1   |\n|               | DRACC-018   \
    \     | 103M   | 527    | 1.5  | 527    | 19.3 | 542   | 180.0 | 21    | 180.0\
    \ | 543    | 12.4  |\n|               | DRACC-019        | 103M   | 527    | 1.4\
    \  | 527    | 15.8 | 542   | 180.0 | 22    | 180.0 | 543    | 12.5  |\n|     \
    \          | DRACC-020        | 0.5K   | 15     | 0.1  | 15     | 0.1  | 30  \
    \  | 0.1   | 30    | 0.1   | 30     | 0.1   |\n|               | DRB-062     \
    \     | 70M    | 31     | 0.8  | 31     | 4.4  | 46    | 4.7   | 45    | 180.0\
    \ | 46     | 1.4   |\n|               | DRB-105          | 44M    | 866    | 0.4\
    \  | 874    | 2.6  | 46    | 180.0 | 101   | 180.0 | 889    | 7.0   |\n|     \
    \          | DRB-106          | 70M    | 709    | 0.7  | 732    | 4.9  | 46  \
    \  | 180.0 | 46    | 180.0 | 789    | 6.8   |\n|               | DRB-110     \
    \     | 35M    | 15     | 0.3  | 16     | 1.1  | 32    | 180.0 | 32    | 47.8\
    \  | 32     | 6.9   |\n|               | DRB-122          | 0.5K   | 15     |\
    \ 0.1  | 15     | 0.1  | 30    | 0.1   | 30    | 0.1   | 30     | 0.1   |\n| \
    \              | DRB-123          | 77M    | 227    | 0.5  | 713    | 4.8  | 231\
    \   | 180.0 | 46    | 180.0 | 243    | 3.7   |\n|               | DRB-144    \
    \      | 70M    | 16     | 0.7  | 16     | 4.1  | 30    | 180.0 | 30    | 180.0\
    \ | 30     | 180.0 |\n|               | DRB-148          | 70M    | 16     | 0.4\
    \  | 16     | 5.9  | 31    | 180.0 | 31    | 125.9 | 32     | 3.7   |\n\n| 1 \
    \            | 2                                    | 3            | 4       \
    \  | 5           | 6         | 7           | 8         | 9              | 10 \
    \     | 11             | 12              | 13          |\n|---------------|--------------------------------------|--------------|-----------|-------------|-----------|-------------|-----------|----------------|---------|----------------|-----------------|-------------|\n\
    |               | Benchmark<br>N                       |              | SHB  \
    \     |             | WCP       |             | SyncP     |                | M2\
    \      |                | OSR             |             |\n| Benchmark Set | \
    \                                     |              | Races     | Time      \
    \  | Races     | Time        | Races     | Time           | Races   | Time   \
    \        | Races           | Time        |\n|               | DRB-150        \
    \                      | 56M          | 16        | 0.4         | 16        |\
    \ 2.8         | 31        | 180.0          | 31      | 104.4          | 32   \
    \           | 3.3         |\n|               | DRB-152                       \
    \       | 56M          | 16        | 0.3         | 16        | 4.3         | 31\
    \        | 180.0          | 31      | 105.5          | 32              | 3.1 \
    \        |\n|               | DRB-154                              | 0.5K    \
    \     | 15        | 0.1         | 15        | 0.1         | 30        | 0.1  \
    \          | 30      | 0.1            | 30              | 0.1         |\n|   \
    \            | DRB-155                              | 12M          | 17      \
    \  | 0.1         | 18        | 0.6         | 32        | 132.1          | 36 \
    \     | 13.6           | 36              | 0.1         |\n|               | DRB-176\
    \                              | 47M          | 1697      | 0.5         | 1899\
    \      | 2.1         | 51        | 180.0          | 77      | 180.0          |\
    \ 2079            | 7.0         |\n|               | DRB-176                 \
    \             | 272M         | 1835      | 7.2         | 2005      | 20.7    \
    \    | 51        | 180.0          | 0       | 180.0          | 2209          \
    \  | 61.8        |\n|               | DRB-176                              | 782M\
    \         | 2154      | 19.7        | 2385      | 61.9        | 51        | 180.0\
    \          | 0       | 180.0          | 2611            | 175.4       |\n|   \
    \            | DRB-177                              | 45M          | 1204    \
    \  | 0.5         | 1238      | 2.6         | 54        | 180.0          | 78 \
    \     | 180.0          | 1315            | 6.0         |\n|               | DRB-177\
    \                              | 191M         | 1395      | 4.5         | 1424\
    \      | 18.5        | 55        | 180.0          | 0       | 180.0          |\
    \ 1522            | 30.3        |\n|               | DRB-177                 \
    \             | 106M         | 982       | 1.9         | 999       | 7.4     \
    \    | 53        | 180.0          | 13      | 180.0          | 1080          \
    \  | 13.5        |\n|               | DRB-177                              | 519M\
    \         | 1634      | 13.6        | 1685      | 42.0        | 54        | 180.0\
    \          | 0       | 180.0          | 1799            | 80.5        |\n|   \
    \            | DRB-177                              | 333M         | 1704    \
    \  | 8.4         | 1771      | 26.4        | 54        | 180.0          | 0  \
    \     | 180.0          | 1881            | 52.9        |\n|               | DRB-177\
    \                              | 836M         | 1791      | 22.8        | 1857\
    \      | 71.7        | 53        | 180.0          | 0       | 180.0          |\
    \ 1963            | 160.9       |\n|               | DRB-062                 \
    \             | 72M          | 111       | 3.0         | 111       | 10.8    \
    \    | 42        | 180.0          | 0       | 180.0          | 166           \
    \  | 1.8         |\n|               | DRB-105                              | 46M\
    \          | 2778      | 1.4         | 2793      | 6.0         | 42        | 180.0\
    \          | 0       | 180.0          | 2849            | 19.2        |\n|   \
    \            | DRB-106                              | 68M          | 2042    \
    \  | 2.2         | 2086      | 9.4         | 42        | 180.0          | 0  \
    \     | 180.0          | 2284            | 11.7        |\n|               | DRB-110\
    \                              | 35M          | 55        | 0.5         | 56 \
    \       | 5.4         | 42        | 180.0          | 15      | 180.0         \
    \ | 112             | 1.3         |\n|               | DRB-122               \
    \               | 1.8K         | 55        | 0.1         | 55        | 0.1   \
    \      | 43        | 180.0          | 110     | 0.1            | 110         \
    \    | 0.1         |\n| DRB-56th      | DRB-123                              |\
    \ 77M          | 712       | 2.5         | 228       | 10.4        | 42      \
    \  | 180.0          | 0       | 180.0          | 778             | 9.5       \
    \  |\n|               | DRB-155                              | 12M          |\
    \ 58        | 0.2         | 59        | 0.7         | 38        | 180.0      \
    \    | 94      | 180.0          | 126             | 1.1         |\n|         \
    \      | DRB-176                              | 49M          | 5216      | 1.6\
    \         | 5989      | 7.6         | 25        | 180.0          | 0       | 180.0\
    \          | 6802            | 15.1        |\n|               | DRB-176      \
    \                        | 348M         | 6911      | 16.4        | 7985     \
    \ | 70.3        | 24        | 180.0          | 0       | 180.0          | 8174\
    \            | 180.0       |\n|               | DRB-176                      \
    \        | 900M         | 7854      | 43.2        | 9110      | 169.8       |\
    \ 25        | 180.0          | 0       | 180.0          | 5026            | 180.0\
    \       |\n|               | DRB-177                              | 43M      \
    \    | 3138      | 1.2         | 3115      | 5.9         | 4         | 180.0 \
    \         | 0       | 180.0          | 3421            | 13.3        |\n|    \
    \           | DRB-177                              | 326M         | 5131     \
    \ | 15.0        | 5197      | 57.3        | 3         | 180.0          | 0   \
    \    | 180.0          | 5541            | 166.8       |\n|               | graph500-16th\
    \                        | 81M          | 23732     | 1.1         | 14764    \
    \ | 4.5         | 40        | 180.0          | 30      | 180.0          | 113732\
    \          | 3.2         |\n|               | graph500-56th                  \
    \      | 82M          | 38416     | 3.5         | 17050     | 12.0        | 38\
    \        | 180.0          | 0       | 180.0          | 119601          | 7.8 \
    \        |\n|               | HPCCG-16th                           | 55M     \
    \     | 9531      | 0.9         | 4480      | 3.7         | 34        | 180.0\
    \          | 60      | 180.0          | 9547            | 2.2         |\n|   \
    \            | HPCCG-56th                           | 79M          | 15027   \
    \  | 3.4         | 228       | 11.9        | 40        | 180.0          | 0  \
    \     | 180.0          | 15083           | 3.5         |\n|               | DC.S-16th\
    \                            | 1.0K         | 78        | 0.1         | 34   \
    \     | 0.1         | 97        | 0.2            | 98      | 0.1            |\
    \ 99              | 0.1         |\n|               | DC.S-56th               \
    \             | 19.8K        | 570       | 0.1         | 153       | 0.1     \
    \    | 60        | 180.0          | 629     | 0.2            | 629           \
    \  | 0.1         |\n|               | IS.W-16th                            | 48M\
    \          | 64155     | 0.8         | 30642     | 2.3         | 31        | 180.0\
    \          | 75      | 180.0          | 64597           | 2.3         |\n|   \
    \            | IS.W-56th                            | 140M         | 193236  \
    \  | 9.4         | 128441    | 28.8        | 38        | 180.0          | 0  \
    \     | 180.0          | 202142          | 23.7        |\n|               | loopA.bad-16th\
    \                       | 93M          | 30        | 2.0         | 30        |\
    \ 7.5         | 1         | 180.0          | 28      | 180.0          | 150033\
    \          | 2.4         |\n|               | loopA.bad-56th                 \
    \      | 334M         | 118       | 26.4        | 119       | 87.1        | 0\
    \         | 180.0          | 0       | 180.0          | 550125          | 21.0\
    \        |\n|               | loopA.solu1-16th                     | 93M     \
    \     | 31        | 1.9         | 31        | 7.5         | 1         | 180.0\
    \          | 28      | 180.0          | 150049          | 2.0         |\n|   \
    \            | loopA.solu1-56th                     | 334M         | 116     \
    \  | 23.5        | 117       | 94.5        | 0         | 180.0          | 40 \
    \     | 180.0          | 550181          | 23.0        |\n|               | loopA.solu2-16th\
    \                     | 51M          | 31        | 0.4         | 31        | 2.2\
    \         | 15        | 180.0          | 0       | 180.0          | 10049    \
    \       | 0.6         |\n|               | loopA.solu2-56th                  \
    \   | 171M         | 118       | 7.9         | 117       | 27.9        | 1   \
    \      | 180.0          | 0       | 180.0          | 10180           | 10.3  \
    \      |\n|               | loopA.solu3-16th                     | 51M       \
    \   | 31        | 1.0         | 30        | 3.0         | 16        | 180.0  \
    \        | 80      | 180.0          | 10048           | 0.6         |\n|     \
    \          | loopA.solu3-56th<br>loopB.solu1-16th | 171M<br>93M  | 116<br>30 |\
    \ 8.7<br>1.9  | 114<br>30 | 24.6<br>7.1 | 1<br>1    | 180.0<br>180.0 | 0<br>28\
    \ | 180.0<br>180.0 | 10177<br>150037 | 8.8<br>2.1  |\n|               |      \
    \                                |              |           |             |  \
    \         |             |           |                |         |             \
    \   |                 |             |\n|               | loopB.solu1-56th<br>Mandelbrot-16th\
    \  | 334M<br>112M | 113<br>26 | 21.8<br>2.0 | 113<br>33 | 91.8<br>5.9 | 0<br>1968\
    \ | 180.0<br>180.0 | 0<br>13 | 180.0<br>180.0 | 550127<br>1973  | 21.5<br>2.5\
    \ |\n|               | Mandelbrot-56th                      | 114M         | 87\
    \        | 4.6         | 113       | 18.0        | 2         | 180.0         \
    \ | 0       | 180.0          | 2196            | 4.6         |\n|            \
    \   | Pi-16th                              | 96M          | 27        | 1.4  \
    \       | 35        | 5.3         | 48        | 7.5            | 28      | 180.0\
    \          | 53              | 2.5         |\n|               | Pi-56th      \
    \                        | 99M          | 91        | 4.2         | 115      \
    \ | 14.9        | 37        | 180.0          | 0       | 180.0          | 184\
    \             | 6.1         |\n|               | QuickSort-16th              \
    \         | 41M          | 31752     | 0.4         | 31758     | 1.5         |\
    \ 2         | 180.0          | 115     | 180.0          | 91092           | 2.4\
    \         |\n| HPCBench      |                                      |        \
    \      |           |             |           |             |           |     \
    \           |         |                |                 |             |\n\n|\
    \ 1             | 2                | 3      | 4       | 5    | 6       | 7   \
    \  | 8     | 9     | 10    | 11    | 12       | 13    |\n|---------------|------------------|--------|---------|------|---------|-------|-------|-------|-------|-------|----------|-------|\n\
    |               | Benchmark        |        | SHB     |      | WCP     |     \
    \  | SyncP |       | M2    |       | OSR      |       |\n| Benchmark Set |   \
    \               | N      | Races   | Time | Races   | Time  | Races | Time  |\
    \ Races | Time  | Races    | Time  |\n|               | QuickSort-56th   | 41M\
    \    | 31792   | 1.0  | 31798   | 6.8   | 0     | 180.0 | 2     | 180.0 | 91172\
    \    | 3.7   |\n|               | fft6-16th        | 0.9K   | 30      | 0.1  |\
    \ 31      | 0.1   | 78    | 0.2   | 81    | 0.1   | 81       | 0.1   |\n|    \
    \           | fft6-56th        | 2.4K   | 74      | 0.1  | 74      | 0.1   | 27\
    \    | 180.0 | 172   | 0.1   | 172      | 0.1   |\n|               | LUReduction-16th\
    \ | 45M    | 89100   | 0.9  | 32      | 2.1   | 2     | 180.0 | 32    | 180.0\
    \ | 89116    | 3.5   |\n|               | LUReduction-56th | 45M    | 88766  \
    \ | 1.5  | 112     | 7.9   | 0     | 180.0 | 0     | 180.0 | 89209    | 11.2 \
    \ |\n|               | MD-16th          | 118M   | 1499    | 2.9  | 59      |\
    \ 7.9   | 1512  | 180.0 | 13    | 180.0 | 1515     | 4.5   |\n|              \
    \ | MD-56th          | 120M   | 1683    | 5.9  | 178     | 15.5  | 3     | 180.0\
    \ | 0     | 180.0 | 1747     | 8.2   |\n|               | testPath-16th    | 7M\
    \     | 16      | 0.1  | 16      | 0.2   | 124   | 180.0 | 154   | 81.7  | 154\
    \      | 49.0  |\n|               | testPath-56th    | 10M    | 57      | 0.2\
    \  | 57      | 0.3   | 1     | 180.0 | 44    | 180.0 | 544      | 180.0 |\n| \
    \              | fft-16th         | 78M    | 983086  | 2.0  | 983086  | 5.7  \
    \ | 98599 | 180.0 | 30    | 180.0 | 2424886  | 4.1   |\n|               | fft-56th\
    \         | 83M    | 1030016 | 4.5  | 1030016 | 14.3  | 37    | 180.0 | 0    \
    \ | 180.0 | 2565429  | 13.7  |\n|               | fft-56th         | 363M   |\
    \ 3894868 | 24.2 | 4119572 | 91.0  | 37    | 180.0 | 0     | 180.0 | 10261235\
    \ | 98.5  |\n|               | qsomp1-16th      | 674.6K | 16      | 0.1  | 16\
    \      | 0.1   | 282   | 180.0 | 282   | 37.7  | 282      | 0.1   |\n|       \
    \        | qsomp1-56th      | 540.1K | 56      | 0.1  | 56      | 0.1   | 27 \
    \   | 180.0 | 156   | 79.5  | 156      | 0.3   |\n|               | qsomp2-16th\
    \      | 870.5K | 16      | 0.1  | 16      | 0.1   | 375   | 74.1  | 375   | 41.9\
    \  | 375      | 0.2   |\n|               | qsomp2-56th      | 629.6K | 56    \
    \  | 0.1  | 56      | 0.1   | 15    | 180.0 | 208   | 180.0 | 253      | 0.5 \
    \  |\n|               | qsomp3-16th      | 15M    | 16      | 0.1  | 17      |\
    \ 0.4   | 32    | 123.4 | 32    | 15.3  | 32       | 0.3   |\n|              \
    \ | qsomp3-56th      | 4M     | 56      | 0.1  | 57      | 0.3   | 40    | 180.0\
    \ | 112   | 46.4  | 112      | 0.1   |\n|               | qsomp4-16th      | 19M\
    \    | 17      | 0.1  | 17      | 4.3   | 37    | 160.0 | 33    | 180.0 | 37 \
    \      | 0.5   |\n|               | qsomp4-56th      | 6M     | 5269    | 0.1\
    \  | 5044    | 0.2   | 0     | 180.0 | 113   | 180.0 | 5349     | 19.7  |\n| \
    \              | qsomp6-56th      | 507.2K | 56      | 0.1  | 56      | 0.1  \
    \ | 8     | 180.0 | 139   | 180.0 | 536      | 1.8   |\n|               | qsomp7-16th\
    \      | 44M    | 8016    | 0.6  | 8001    | 2.7   | 6787  | 180.0 | 96    | 180.0\
    \ | 8035     | 0.9   |\n|               | qsomp7-56th      | 147M   | 6053   \
    \ | 6.4  | 6052    | 22.1  | 0     | 180.0 | 0     | 180.0 | 6119     | 20.5 \
    \ |\n|               | biojava-4th      | 0.9K   | 2       | 0.1  | 3       |\
    \ 0.1   | 6     | 0.1   | 6     | 0.1   | 6        | 0.1   |\n|              \
    \ | cassandra-132th  | 28M    | 5053    | 0.2  | 5026    | 180.0 | 0     | 180.0\
    \ | 0     | 180.0 | 514      | 180.0 |\n|               | graphchi-20th    | 206.3K\
    \ | 21      | 0.1  | 21      | 0.1   | 137   | 0.1   | 138   | 0.1   | 138   \
    \   | 0.1   |\n| misc          | hsqldb-44th      | 647.5K | 5       | 0.1  |\
    \ 5       | 0.1   | 3     | 180.0 | 5     | 0.1   | 5        | 2.4   |\n|    \
    \           | tradebeans-222th | 218.9K | 170     | 0.1  | 157     | 0.1   | 0\
    \     | 180.0 | 203   | 40.9  | 205      | 0.1   |\n|               | tradesoap-221th\
    \  | 218.6K | 169     | 0.1  | 155     | 0.1   | 0     | 180.0 | 203   | 44.0\
    \  | 205      | 0.4   |\n|               | zxing-15th       | 18M    | 3128  \
    \  | 0.1  | 3114    | 0.9   | 333   | 180.0 | 340   | 180.0 | 3216     | 0.2 \
    \  |\n\n<span id=\"page-25-0\"></span>Table 6: Details of C/C++ benchmarks. Columns\
    \ 1-2 states the source of these benchmarks and trace name with number of threads.\
    \ Columns 3-6 are number of events before filtering, number of events after filtering,\
    \ number of variables, number of locks. Columns 7-10 are number of read, write,\
    \ acquire and release events after filtering.\n\n| 1             | 2         \
    \       | 3    | 4      | 5       | 6     | 7                     | 8        \
    \   | 9             | 10         |\n|---------------|------------------|------|--------|---------|-------|-----------------------|-------------|---------------|------------|\n\
    | Benchmark Set | Benchmark        | N′   | N      | V       | L     | Reads \
    \                | Writes      | Acq           | Rel        |\n|             \
    \  | task-16th        | 174M | 117M   | 11,757  | 56    | 107,864,829        \
    \   | 9,345,091   | 31,555        | 31,555     |\n|               | task-56th\
    \        | 175M | 117M   | 11,757  | 56    | 107,864,829           | 9,345,091\
    \   | 31,555        | 31,555     |\n|               | taskdeps-16th    | 174M\
    \ | 115M   | 10,915  | 16    | 107,576,209           | 7,749,193   | 7,065   \
    \      | 7,065      |\n| CoMD          | taskdeps-56th    | 175M | 117M   | 11,757\
    \  | 56    | 107,864,889           | 9,345,091   | 31,585        | 31,585    \
    \ |\n|               | taskloop-16th    | 251M | 2M     | 177,566 | 16    | 1,132,063\
    \             | 1,364,476   | 1,241         | 1,241      |\n|               |\
    \ taskloop-56th    | 251M | 4M     | 194,160 | 56    | 3,058,872             |\
    \ 1,930,831   | 4,044         | 4,044      |\n|               | openmp-16th  \
    \    | 174M | 115M   | 10,915  | 16    | 107,576,257           | 7,749,193   |\
    \ 7,089         | 7,089      |\n|               | openmp-56th      | 175M | 117M\
    \   | 11,757  | 56    | 107,864,811           | 9,345,091   | 31,546        |\
    \ 31,546     |\n| SimpleMOC     | trace-16th       | 170M | 19M    | 60,029  |\
    \ 5,017 | 7,833,334             | 7,641,040   | 1,771,680     | 1,771,680  |\n\
    |               | Amg2013-18th     | 170M | 39M    | 145,485 | 36    | 3,332,723\
    \             | 36,405,204  | 1,657         | 1,657      |\n|               |\
    \ Amg2013-58th     | 190M | 52M    | 190,994 | 76    | 4,306,355             |\
    \ 48,531,303  | 14,039        | 14,039     |\n|               | Kripke-16th  \
    \    | 117M | 20M    | 22,482  | 17    | 12,509,801            | 8,366,557   |\
    \ 9,447         | 9,447      |\n|               | Kripke-56th      | 119M | 34M\
    \    | 34,156  | 58    | 18,994,381            | 15,904,315  | 44,773        |\
    \ 44,773     |\n|               | Lulesh-16th      | 35M  | 10M    | 52,940  |\
    \ 15    | 8,987,707             | 1,431,554   | 72            | 72         |\n\
    |               | Lulesh-16th      | 543M | 130M   | 167,595 | 16    | 123,136,205\
    \           | 7,407,451   | 2,230         | 2,230      |\n|               | Lulesh-56th\
    \      | 52M  | 14M    | 73,432  | 56    | 12,065,387            | 1,999,030 \
    \  | 1,707         | 1,707      |\n| OMPRacer      | Lulesh-56th      | 569M |\
    \ 156M   | 261,857 | 56    | 143,236,930           | 13,541,685  | 32,046    \
    \    | 32,046     |\n|               | miniFE-18th      | 208M | 44M    | 159,052\
    \ | 36    | 6,323,648             | 37,932,412  | 1,379         | 1,379      |\n\
    |               | miniFE-58th      | 207M | 63M    | 191,862 | 76    | 55,826,793\
    \            | 7,658,888   | 8,823         | 8,823      |\n|               | QuickSilver-56th\
    \ | 133M | 1M     | 21,132  | 56    | 890,633               | 650,042     | 17,387<br>114\
    \ | 17,387     |\n|               | XSBench-16th     | 97M  | 693.9K | 225   \
    \  | 15    | 691,187               | 2,467       |               | 114       \
    \ |\n|               | XSBench-56th     | 97M  | 710.9K | 370     | 56    | 707,006\
    \               | 2,948       | 442           | 442        |\n|              \
    \ | RSBench-16th     | 1.2B | 27M    | 1,278   | 16    | 27,005,898<br>109,606\
    \ |             | 123           | 123        |\n|               | RSBench-56th\
    \     | 1.2B | 27M    | 1,405   | 56    | 27,006,574            | 121,858    \
    \ | 421           | 421        |\n|               | DRACC-009        | 135M |\
    \ 70M    | 32      | 18    | 122                   | 10,000,063  | 30,000,060\
    \    | 30,000,060 |\n|               | DRACC-010        | 135M | 70M    | 32 \
    \     | 18    | 122                   | 10,000,063  | 30,000,060    | 30,000,060\
    \ |\n|               | DRACC-011        | 135M | 0.5K   | 30      | 15    | 204\
    \                   | 60          | 102           | 102        |\n|          \
    \     | DRACC-012        | 105M | 103M   | 543     | 18    | 632             \
    \      | 102,400,575 | 600,060       | 600,060    |\n|               | DRACC-013\
    \        | 105M | 103M   | 543     | 18    | 632                   | 102,400,575\
    \ | 600,060       | 600,060    |\n|               | DRACC-014        | 105M |\
    \ 0.5K   | 30      | 15    | 204                   | 60          | 102       \
    \    | 102        |\n| DRACC-16th    | DRACC-015        | 135M | 70M    | 32 \
    \     | 18    | 121                   | 10,000,063  | 30,000,060    | 30,000,060\
    \ |\n|               | DRACC-016        | 135M | 70M    | 32      | 18    | 121\
    \                   | 10,000,063  | 30,000,060    | 30,000,060 |\n|          \
    \     | DRACC-017        | 27M  | 0.5K   | 30      | 15    | 204             \
    \      | 60          | 102           | 102        |\n|               |       \
    \           | 135M | 0.5K   | 30      | 15    | 204                   | 60   \
    \       | 102           | 102        |\n|               | DRACC-018        | 105M\
    \ | 103M   | 543     | 18    | 632                   | 102,400,575 | 600,060 \
    \      | 600,060    |\n|               | DRACC-019        | 105M | 103M   | 543\
    \     | 18    | 632                   | 102,400,575 | 600,060       | 600,060\
    \    |\n|               | DRACC-020        | 105M | 0.5K   | 30      | 15    |\
    \ 204                   | 60          | 102           | 102        |\n|      \
    \         | DRB-062          | 184M | 70M    | 46      | 15    | 36,102,121  \
    \          | 33,912,061  | 60            | 60         |\n|               | DRB-105\
    \          | 134M | 44M    | 889     | 31    | 8,339,388             | 8,339,291\
    \   | 14,098,397    | 14,098,397 |\n|               | DRB-106          | 134M\
    \ | 70M    | 789     | 31    | 35,341,444            | 7,144,665   | 14,098,428\
    \    | 14,098,428 |\n|               | DRB-110          | 120M | 35M    | 32 \
    \     | 18    | 207                   | 5,000,047   | 15,000,103    | 15,000,103\
    \ |\n|               | DRB-122          | 112M | 0.5K   | 30      | 15    | 210\
    \                   | 60          | 105           | 105        |\n|          \
    \     | DRB-123          | 112M | 77M    | 243     | 16    | 35,000,220      \
    \      | 14,000,062  | 14,000,109    | 14,000,109 |\n|               | DRB-144\
    \          | 140M | 70M    | 32      | 17    | 121                   | 10,000,063\
    \  | 30,000,060    | 30,000,060 |\n|               | DRB-148          | 135M |\
    \ 70M    | 32      | 18    | 121                   | 10,000,063  | 30,000,060\
    \    | 30,000,060 |\n|               | DRB-150          | 112M | 56M    | 32 \
    \     | 17    | 121                   | 8,000,064   | 24,000,060    | 24,000,060\
    \ |\n\n| 1             | 2                | 3    | 4     | 5       | 6   | 7 \
    \          | 8           | 9           | 10          |\n|---------------|------------------|------|-------|---------|-----|-------------|-------------|-------------|-------------|\n\
    | Benchmark Set | Benchmark        | N    | N     | L       | V   | Reads    \
    \   | Writes      | Acq         | Rel         |\n|               | DRB-152   \
    \       | 112M | 56M   | 32      | 17  | 121         | 8,000,064   | 24,000,060\
    \  | 24,000,060  |\n|               | DRB-154          | 112M | 0.5K  | 30   \
    \   | 15  | 204         | 60          | 102         | 102         |\n|       \
    \        | DRB-155          | 50M  | 12M   | 51      | 18  | 344         | 87\
    \          | 6,000,141   | 6,000,141   |\n|               | DRB-176          |\
    \ 90M  | 47M   | 2079    | 31  | 20,649,583  | 10,224,212  | 8,077,747   | 8,077,747\
    \   |\n|               | DRB-176          | 341M | 272M  | 2209    | 31  | 109,382,709\
    \ | 52,675,980  | 55,364,923  | 55,364,923  |\n|               | DRB-176     \
    \     | 1.6B | 782M  | 2611    | 31  | 337,612,032 | 155,172,752 | 144,947,035\
    \ | 144,947,035 |\n|               | DRB-177          | 90M  | 45M   | 1315  \
    \  | 31  | 20,300,303  | 9,112,538   | 8,077,747   | 8,077,747   |\n|        \
    \       | DRB-177          | 211M | 191M  | 1522    | 31  | 82,046,982  | 40,599,487\
    \  | 34,217,455  | 34,217,455  |\n|               | DRB-177          | 382M |\
    \ 106M  | 1080    | 31  | 47,124,525  | 16,760,905  | 21,147,601  | 21,147,601\
    \  |\n|               | DRB-177          | 552M | 519M  | 1799    | 31  | 220,163,418\
    \ | 119,866,791 | 89,582,245  | 89,582,245  |\n|               | DRB-177     \
    \     | 618M | 333M  | 1881    | 31  | 142,820,683 | 80,362,747  | 55,364,923\
    \  | 55,364,923  |\n|               | DRB-177          | 1.6B | 836M  | 1963 \
    \   | 31  | 347,911,303 | 198,868,896 | 144,947,035 | 144,947,035 |\n|       \
    \        | DRB-062          | 193M | 72M   | 166     | 55  | 36,343,511  | 35,982,221\
    \  | 755         | 755         |\n|               | DRB-105          | 134M |\
    \ 46M   | 2,849   | 111 | 9,375,994   | 9,375,741   | 14,098,575  | 14,098,575\
    \  |\n|               | DRB-106          | 134M | 68M   | 2,284   | 111 | 34,064,016\
    \  | 6,297,656   | 14,098,676  | 14,098,676  |\n|               | DRB-110    \
    \      | 120M | 35M   | 112     | 58  | 765         | 5,000,167   | 15,000,382\
    \  | 15,000,382  |\n|               | DRB-122          | 112M | 1.8K  | 110  \
    \   | 55  | 770         | 220         | 385         | 385         |\n| DRB-56th\
    \      | DRB-123          | 112M | 77M   | 778     | 56  | 35,000,781  | 14,000,276\
    \  | 14,000,389  | 14,000,389  |\n|               | DRB-155          | 50M  |\
    \ 12M   | 181     | 58  | 1296        | 307         | 6,000,538   | 6,000,538\
    \   |\n|               | DRB-176          | 90M  | 49M   | 6802    | 111 | 22,550,856\
    \  | 10,755,451  | 8,078,107   | 8,078,107   |\n|               | DRB-176    \
    \      | 341M | 348M  | 8946    | 111 | 160,758,955 | 76,630,057  | 55,365,283\
    \  | 55,365,283  |\n|               | DRB-176          | 1.6B | 900M  | 10164\
    \   | 111 | 406,628,634 | 204,003,136 | 144,947,395 | 144,947,395 |\n|       \
    \        | DRB-177          | 90M  | 43M   | 3421    | 111 | 19,743,274  | 7,490,436\
    \   | 8,078,107   | 8,078,107   |\n|               | DRB-177          | 618M |\
    \ 326M  | 5541    | 111 | 139,688,872 | 75,806,547  | 55,365,283  | 55,365,283\
    \  |\n|               | graph500-16th    | 171M | 81M   | 113,732 | 16  | 76,413,805\
    \  | 4,799,533   | 2,526       | 2,526       |\n|               | graph500-56th\
    \    | 172M | 82M   | 119,601 | 56  | 77,444,355  | 5,086,862   | 26,472     \
    \ | 26,472      |\n|               | HPCCG-16th       | 228M | 55M   | 9,547 \
    \  | 16  | 50,028,952  | 5,798,966   | 2,199       | 2,199       |\n|        \
    \       | HPCCG-56th       | 230M | 79M   | 15,083  | 56  | 72,511,642  | 6,836,516\
    \   | 17,722      | 17,722      |\n|               | DC.S-16th        | 12M  |\
    \ 1.0K  | 102     | 18  | 338         | 409         | 132         | 132      \
    \   |\n|               | DC.S-56th        | 12M  | 19.8K | 633     | 57  | 13,917\
    \      | 4,731       | 524         | 524         |\n|               | IS.W-16th\
    \        | 153M | 48M   | 64,597  | 16  | 31,324,449  | 17,038,722  | 384    \
    \     | 384         |\n|               | IS.W-56th        | 300M | 140M  | 202,142\
    \ | 56  | 119,664,913 | 20,347,145  | 4,400       | 4,400       |\n|         \
    \      | loopA.bad-16th   | 113M | 93M   | 150,033 | 16  | 78,322,852  | 15,149,966\
    \  | 825         | 825         |\n|               | loopA.bad-56th   | 394M |\
    \ 334M  | 550,125 | 56  | 279,145,300 | 55,550,150  | 9,436       | 9,436    \
    \   |\n|               | loopA.solu1-16th | 193M | 93M   | 150,049 | 16  | 78,327,081\
    \  | 15,151,468  | 1,325       | 1,325       |\n|               | loopA.solu1-56th\
    \ | 674M | 334M  | 550,181 | 56  | 279,184,949 | 55,555,652  | 22,485      | 22,485\
    \      |\n|               | loopA.solu2-16th | 96M  | 51M   | 10,049  | 16  |\
    \ 50,165,397  | 1,011,384   | 618         | 618         |\n|               | loopA.solu2-56th\
    \ | 337M | 171M  | 10,180  | 56  | 170,601,797 | 1,015,606   | 11,858      | 11,858\
    \      |\n|               | loopA.solu3-16th | 96M  | 51M   | 10,048  | 16  |\
    \ 50,167,481  | 1,011,381   | 882         | 882         |\n|               | loopA.solu3-56th\
    \ | 337M | 171M  | 10,177  | 56  | 170,604,653 | 1,015,599   | 10,840      | 10,840\
    \      |\n|               | loopB.solu1-16th | 113M | 93M   | 150,037 | 16  |\
    \ 78,322,094  | 15,150,074  | 433         | 433         |\n|               | loopB.solu1-56th\
    \ | 394M | 334M  | 550,127 | 56  | 279,149,802 | 55,550,254  | 11,324      | 11,324\
    \      |\n|               | Mandelbrot-16th  | 116M | 112M  | 1,973   | 16  |\
    \ 112,231,695 | 2,708       | 117         | 117         |\n|               | Mandelbrot-56th\
    \  | 116M | 114M  | 2,196   | 56  | 114,434,245 | 3,096       | 448         |\
    \ 448         |\n|               | Pi-16th          | 150M | 96M   | 53      |\
    \ 16  | 50,000,252  | 46,875,100  | 99          | 99          |\n|           \
    \    | Pi-56th          | 150M | 99M   | 184     | 56  | 50,001,048  | 49,107,502\
    \  | 420         | 420         |\n| HPCBench      | QuickSort-16th   | 134M |\
    \ 41M   | 91,092  | 16  | 32,609,684  | 8,417,535   | 522         | 522      \
    \   |\n|               | QuickSort-56th   | 134M | 41M   | 91,172  | 56  | 32,612,404\
    \  | 8,417,695   | 1,882       | 1,882       |\n|               | fft6-16th  \
    \      | 146M | 0.9K  | 81      | 16  | 561         | 145         | 108      \
    \   | 108         |\n\n<span id=\"page-27-0\"></span>ICSE '24, April 12–21, 2024,\
    \ Lisbon, Portugal Zheng Shi, Umang Mathur, and Andreas Pavlogiannis\n\n| 1  \
    \           | 2                | 3    | 4      | 5          | 6      | 7     \
    \      | 8           | 9          | 10         |\n|---------------|------------------|------|--------|------------|--------|-------------|-------------|------------|------------|\n\
    | Benchmark Set | Benchmark        | N    | N      | L          | V      | Reads\
    \       | Writes      | Acq        | Rel        |\n|               | fft6-56th\
    \        | 146M | 2.4K   | 172        | 55     | 1,234       | 323         | 394\
    \        | 394        |\n|               | LUReduction-16th | 136M | 45M    |\
    \ 89,116     | 16     | 35,960,758  | 9,044,179   | 480        | 480        |\n\
    |               | LUReduction-56th | 137M | 45M    | 89,209     | 56     | 36,002,402\
    \  | 9,044,365   | 15,309     | 15,309     |\n|               | MD-16th      \
    \    | 204M | 118M   | 1,515      | 16     | 113,558,997 | 5,224,843   | 522 \
    \       | 522        |\n|               | MD-56th          | 204M | 120M   | 1,747\
    \      | 56     | 115,223,309 | 5,466,221   | 3,629      | 3,629      |\n|   \
    \            | testPath-16th    | 30M  | 7M     | 25,048     | 17     | 2,647,876\
    \   | 3,556,911   | 631,221    | 631,221    |\n|               | testPath-56th\
    \    | 37M  | 10M    | 69,308     | 57     | 4,219,733   | 3,671,124   | 1,303,636\
    \  | 1,303,636  |\n|               | fft-16th         | 496M | 78M    | 2,424,886\
    \  | 17     | 53,084,901  | 25,690,379  | 159        | 159        |\n|       \
    \        | fft-56th         | 496M | 83M    | 2,565,429  | 56     | 55,988,645\
    \  | 27,188,775  | 589        | 589        |\n|               | fft-56th     \
    \    | 2.1B | 363M   | 10,261,235 | 56     | 244,470,405 | 119,014,191 | 586 \
    \       | 586        |\n|               | qsomp1-16th      | 107M | 674.6K | 283\
    \        | 17     | 203,340     | 26,123      | 222,546    | 222,546    |\n| \
    \              | qsomp1-56th      | 107M | 540.1K | 157        | 57     | 143,062\
    \     | 6,387       | 195,286    | 195,286    |\n|               | qsomp2-16th\
    \      | 108M | 870.5K | 376        | 17     | 261,250     | 32,622      | 288,285\
    \    | 288,285    |\n|               | qsomp2-56th      | 107M | 629.6K | 254\
    \        | 57     | 177,428     | 14,801      | 218,671    | 218,671    |\n| \
    \              | qsomp3-16th      | 142M | 15M    | 33         | 17     | 3,929,700\
    \   | 51          | 5,894,435  | 5,894,434  |\n|               | qsomp3-56th \
    \     | 115M | 4M     | 113        | 57     | 1,009,842   | 171         | 1,514,348\
    \  | 1,514,347  |\n|               | qsomp4-16th      | 164M | 19M    | 37   \
    \      | 17     | 4,782,343   | 14,827      | 7,137,390  | 7,137,390  |\n|   \
    \            | qsomp4-56th      | 114M | 6M     | 5,350      | 57     | 2,707,676\
    \   | 518,055     | 1,863,535  | 1,863,535  |\n|               | qsomp6-56th \
    \     | 107M | 507.2K | 537        | 57     | 186,521     | 44,137      | 138,229\
    \    | 138,229    |\n|               | qsomp7-16th      | 89M  | 44M    | 8,035\
    \      | 16     | 44,130,252  | 304,813     | 123        | 123        |\n|   \
    \            | qsomp7-56th      | 296M | 147M   | 6,119      | 56     | 146,867,929\
    \ | 619,075     | 439        | 439        |\n|               | biojava-4th   \
    \   | 221M | 0.9K   | 9          | 12     | 59          | 24          | 383  \
    \      | 383        |\n|               | cassandra-132th  | 259M | 28M    | 9,839\
    \      | 12,211 | 2,686,843   | 1,672,488   | 12,246,313 | 12,246,313 |\n|   \
    \            | graphchi-20th    | 216M | 206.3K | 144        | 15     | 204,879\
    \     | 719         | 344        | 344        |\n| misc          | hsqldb-44th\
    \      | 19M  | 647.5K | 318        | 51     | 260,630     | 52,096      | 167,362\
    \    | 167,362    |\n|               | tradebeans-222th | 39M  | 218.9K | 778\
    \        | 674    | 71,344      | 30,605      | 58,338     | 58,338     |\n| \
    \              | tradesoap-221th  | 39M  | 218.6K | 775        | 672    | 71,264\
    \      | 30,541      | 58,266     | 58,266     |\n|               | zxing-15th\
    \       | 547M | 18M    | 3,310      | 359    | 18,389,530  | 9,748       | 3,624\
    \      | 3,624      |"
- title: "Challenges, Adaptations, and Fringe Benefits of Conducting Software\n  Engineering\
    \ Research with Human Participants during the COVID-19 Pandemic"
  abstract: 'The COVID-19 pandemic changed the way we live, work and the way we conduct

    research. With the restrictions of lockdowns and social distancing, various

    impacts were experienced by many software engineering researchers, especially

    whose studies depend on human participants. We conducted a mixed methods study

    to understand the extent of this impact. Through a detailed survey with 89

    software engineering researchers working with human participants around the

    world and a further nine follow-up interviews, we identified the key challenges

    faced, the adaptations made, and the surprising fringe benefits of conducting

    research involving human participants during the pandemic. Our findings also

    revealed that in retrospect, many researchers did not wish to revert to the old

    ways of conducting human-oriented research. Based on our analysis and insights,

    we share recommendations on how to conduct remote studies with human

    participants effectively in an increasingly hybrid world when face-to-face

    engagement is not possible or where remote participation is preferred.'
  url: http://arxiv.org/abs/2401.05668v1
  keywords: ''
  document: "# Challenges, Adaptations, and Fringe Benefits of Conducting Software\
    \ Engineering Research with Human Participants during the COVID-19 Pandemic\n\n\
    Anuradha Madugalla · Tanjila Kanij · Rashina Hoda · Dulaji Hidellaarachchi · Aastha\
    \ Pant · Samia Ferdousi · John Grundy\n\nReceived: date / Accepted: date\n\nAbstract\
    \ The COVID-19 pandemic changed the way we live, work and the way we conduct research.\
    \ With the restrictions of lockdowns and social distancing, various impacts were\
    \ experienced by many software engineering researchers, especially whose studies\
    \ depend on human participants. We conducted a mixed methods study to understand\
    \ the extent of this impact. Through a detailed survey with 89 software engineering\
    \ researchers working with human participants around the world and a further nine\
    \ follow-up interviews, we identified the key challenges faced, the adaptations\
    \ made, and the surprising fringe benefits of conducting research involving human\
    \ participants during\n\n#### T. Kanij\n\n#### R.Hoda\n\nDept. of Software Systems\
    \ and Cybersecurity, Monash University, Melbourne, Australia E-mail: rashina.hoda@monash.edu\n\
    \n#### D. Hidellaarachchi\n\nDept. of Software Systems and Cybersecurity, Monash\
    \ University, Melbourne, Australia E-mail: dulaji.hidellaarachchi@monash.edu\n\
    \n#### A. Pant\n\nDept. of Software Systems and Cybersecurity, Monash University,\
    \ Melbourne, Australia E-mail: aastha.pant@monash.edu\n\n#### S. Ferdousi\n\n\
    Dept. of Software Systems and Cybersecurity, Monash University, Melbourne, Australia\
    \ E-mail: samia.ferdousi@monash.edu\n\n#### J. Grundy\n\nDept. of Software Systems\
    \ and Cybersecurity, Monash University, Melbourne, Australia E-mail: john.grundy@monash.edu\n\
    \nA. Madugalla\n\nDept. of Software Systems and Cybersecurity, Monash University,\
    \ Melbourne, Australia E-mail: anu.madugalla@monash.edu\n\nDept. of Software Systems\
    \ and Cybersecurity, Monash University, Melbourne, Australia E-mail: tanjila.kanij@monash.edu\n\
    \nthe pandemic. Our findings also revealed that in retrospect, many researchers\
    \ did not wish to revert to the old ways of conducting human-oriented research.\
    \ Based on our analysis and insights, we share recommendations on how to conduct\
    \ remote studies with human participants effectively in an increasingly hybrid\
    \ world when face-to-face engagement is not possible or where remote participation\
    \ is preferred.\n\nKeywords Software Engineering · COVID-19 · Pandemic · Research\n\
    \n#### 1 Introduction\n\nWorking through a global pandemic brought many challenges\
    \ for professionals around the world. Among them, the COVID-19 pandemic has had\
    \ a profound impact on many research studies in diverse research domains [\\[35\\\
    ]](#page-27-0). Necessary measures such as lockdowns, social distancing, and travel\
    \ restrictions led to various disruptions in research activities [\\[22\\]](#page-27-1)\
    \ [\\[31\\]](#page-27-2). Challenges in recruitment, retention of participants,\
    \ data collection, and access to research sites and facilities have been reported\
    \ across biomedical, pharmaceutical, data science, clinical, behavioural, social\
    \ science and other domains. Clinical research was seen to be among the most impacted\
    \ during the pandemic [\\[48\\]](#page-28-0). Several ongoing clinical research\
    \ studies were abandoned or delayed due to the pandemic, leading to significant\
    \ disruption in the advancement of medical research [\\[40\\]](#page-28-1). Further,\
    \ it was stated that the progress of the studies in areas such as cancer, mental\
    \ health, and chronic disease were impacted due to the shifting of research funding\
    \ priorities toward COVID-19 related research [\\[46\\]](#page-28-2) [\\[48\\\
    ]](#page-28-0).\n\nAs in other research domains, software engineering (SE) practitioners\
    \ were also seen to be affected by the pandemic. Many research studies have been\
    \ conducted on the impact of the COVID-19 pandemic on software practitioners,\
    \ referring to their well-being [\\[21\\]](#page-27-3) [\\[37\\]](#page-27-4),\
    \ team behaviour [\\[26\\]](#page-27-5), work-from-home situation [\\[30\\]](#page-27-6)\
    \ [\\[41\\]](#page-28-3), and productivity [\\[4\\]](#page-26-0). However, the\
    \ majority of the studies focused on the impact of the pandemic on SE practitioners,\
    \ while the impact of the pandemic on SE researchers has not received similar\
    \ attention. SE researchers were not immune to the challenges presented by the\
    \ pandemic. While SE researchers in areas such as program analysis, testing, and\
    \ formal methods would have experienced many professional challenges which should\
    \ be studied, we were particularly interested in empirical SE researchers' experiences.\
    \ Much of their research relies on human participation, and one would expect this\
    \ to be majorly impacted in the face of restrictions, such as lockdowns and social\
    \ distancing, brought on by the pandemic. To understand their experiences, we\
    \ drafted three overarching research questions:\n\nRQ1: What challenges did empirical\
    \ SE researchers face during the pandemic? RQ2: How did empirical SE researchers\
    \ adapt to the challenges?\n\nRQ3: Were there any fringe benefits of doing empirical\
    \ SE research during the pandemic?\n\nTo answer these questions, we designed a\
    \ mixed-methods study composed of a survey followed by in-depth interviews with\
    \ those of the respondents willing to discuss their experiences in further detail.\
    \ We systematically reached out to 2,190 SE researchers who had collectively published\
    \ 587 papers in four high-quality research venues for empirical software engineering\
    \ studies, namely, IEEE Transactions on Software Engineering (TSE), Empirical\
    \ Software Engineering (EMSE), IEEE International Conference on Software Engineering\
    \ (ICSE) and Empirical Software Engineering and Measurement (ESEM), with approvals\
    \ from our Ethics committee and the editors and program co-chairs of these journals\
    \ and conferences. We were interested in SE studies involving human participants\
    \ and received 89 responses from relevant SE researchers. We then conducted a\
    \ further nine in-depth interviews from those willing to share details of their\
    \ experiences. The mix of primarily qualitative and some quantitative data collected\
    \ from the survey and interviews was analysed using socio-technical grounded theory\
    \ for data analysis (STGT4DA) [\\[19\\]](#page-26-1) and descriptive statistical\
    \ analysis respectively. Further details can be found in the Methodology section.\n\
    \nBased on our analysis, we identified key challenges and adaptations across research\
    \ design, recruitment, and data collection. For example, challenges with study\
    \ environment setup, invitation medium, reduced response rates, handling sensitive\
    \ data online, and technical challenges were reported. Adaptations included changes\
    \ to study duration (extending, reducing), leveraging online events, and use of\
    \ online tools, among others. Fringe benefits included improved diversity in recruitment,\
    \ reduced time and costs, increased flexibility, worldwide research collaborations,\
    \ and more, presented in the Findings section.\n\n#### 2 Related Work\n\n### 2.1\
    \ Impact of the Pandemic on Research\n\nThe COVID-19 pandemic produced a significant\
    \ impact globally for each and every individual, as well as a wide range of domains.\
    \ In the study [\\[35\\]](#page-27-0), Omary et al. discussed the impact of the\
    \ COVID-19 pandemic on research in two ways – the impact on research institutions\
    \ and the impact on researchers. They highlighted that COVID-19 causes new institutional\
    \ responsibilities and challenges, such as continuing ongoing research, increasing\
    \ COVID-19-related research, and ensuring safety measurements of the employees\
    \ and students, whereas researchers faced the challenge of maintaining critical\
    \ research activities, coping with multiple research approaches, engaging in research\
    \ remotely, continuously planning and writing research grants, initiating new\
    \ collaborations and many more.\n\nVarious studies have indicated that clinical\
    \ research has been the most impacted research due to COVID-19, as observations\
    \ following patient encounters were hindered due to pandemic restrictions [\\\
    [22\\]](#page-27-1) [\\[31\\]](#page-27-2) [\\[48\\]](#page-28-0). The studies\
    \ further highlighted that major health research areas that are unrelated to COVID-19\
    \ have also been significantly put on hold or suspended entirely due to a variety\
    \ of pandemic-related reasons, such as COVID-19-related legal restrictions, logistics,\
    \ recruitment of vulnerable participants, quality of the collected data and operational\
    \ concerns [\\[46\\]](#page-28-2) [\\[49\\]](#page-28-4).\n\nHowever, these studies\
    \ also indicated that due to COVID-19, innovative methods and strategies were\
    \ introduced that have advanced the overall conduct of clinical research. For\
    \ example, new approaches were developed to recruit participants and conduct the\
    \ studies, such as remote visits via telehealth, the use of home-based monitoring\
    \ technologies, and courier pick-up/ delivery of investigational products to keep\
    \ the studies going throughout the pandemic. Additionally, risk mitigation has\
    \ become central to the planning of health research during the pandemic to mitigate\
    \ the risks faced by healthcare workers and patients due to COVID-19. New policies,\
    \ safety measurements, ethical considerations and many more in the health research\
    \ field have been introduced, making clinical research approaches more flexible\
    \ while maintaining research integrity [\\[46\\]](#page-28-2) [\\[48\\]](#page-28-0).\n\
    \nThe pandemic impacted other research areas, such as social science, economics,\
    \ education, technology, management etc. and the use of different research methods\
    \ in these areas. A study conducted by [\\[42\\]](#page-28-5) highlighted the\
    \ challenges faced by social science researchers during the COVID-19 pandemic,\
    \ specifically referring to the research methods that have been used prior to\
    \ the pandemic and the need for alternative research strategies. In their study\
    \ [\\[13\\]](#page-26-2), George et al. discussed the impact of the COVID-19 pandemic\
    \ on technology and innovation management research and how novel research investigations\
    \ emerged. They pointed out that the pandemic declines the interest in large physical\
    \ infrastructure to make scientific breakthroughs, and virtualization of collaboration\
    \ has become the key to innovation research. A study conducted by Idnani et al.\
    \ [\\[20\\]](#page-27-7) highlighted the COVID-19 pandemic impact on education,\
    \ specifically focusing on tuition-dependent institutes in developing countries\
    \ where online education/ e-learning advancements need to be focused on facing\
    \ unforeseen situations like COVID-19.\n\nFurther, the COVID-19 pandemic majorly\
    \ impacted on utilising several research methods when conducting research studies.\
    \ Various studies discussed the challenges and opportunities of participatory\
    \ research approaches during the COVID-19 pandemic [\\[29\\]](#page-27-8) [\\\
    [16\\]](#page-26-3). They reflect on their experience of conducting remote user\
    \ studies and highlight the key considerations for successful remote research.\
    \ In this study, the main focus was ethnographic research practices and pointed\
    \ out that although the use of a variety of tools was helpful in connecting to\
    \ the participants, it remained less effective compared to traditional user research.\
    \ Gruber et al. [\\[15\\]](#page-26-4) pointed out the importance of adapting\
    \ research methods to the changing environment due to the COVID-19 pandemic and\
    \ emphasized the need for researchers to be flexible and creative in addressing\
    \ the challenges of conducting research with vulnerable populations.\n\nFocusing\
    \ on qualitative research projects during the COVID-19 pandemic, Rahman et al.\
    \ [\\[36\\]](#page-27-9) and Adom et al. [\\[2\\]](#page-26-5) discussed the ad-hoc\
    \ adaptations of qualitative research during the pandemic referring to various\
    \ qualitative research methods and challenges encountered when digitalizing them.\
    \ Some of the core qualitative data collection methods, namely, interviews, observations,\
    \ workshops/action research, were considered, and numerous challenges such as\
    \ distractions from home life, poor internet connections, last minute rescheduling\
    \ were discussed. A study conducted by [\\[44\\]](#page-28-6) discusses the use\
    \ of Zoom as a tool for conducting remote focus groups in the era of social distancing.\
    \ The study highlighted the advantages and disadvantages of using Zoom for conducting\
    \ focus groups and provides practical strategies for conducting successful remote\
    \ focus groups. Irrespective of the challenges faced in adapting a variety of\
    \ traditional research methods to remote research, the studies such as [\\[38\\\
    ]](#page-28-7) complement remote data collection during the COVID-19 pandemic\
    \ as it increased the accessibility and equity in participant contributions and\
    \ lower costs.\n\n#### 2.2 Impact of the Pandemic on Software Engineering Research\n\
    \nStudies have been carried out to explore the impact of the COVID-19 pandemic\
    \ on individuals in various fields, including software engineering[\\[21\\]](#page-27-3)\
    \ [\\[41\\]](#page-28-3). The majority of these studies have focused on the well-being\
    \ of software engineers [\\[21\\]](#page-27-3) [\\[37\\]](#page-27-4) [\\[32\\\
    ]](#page-27-10), software team behaviour [\\[26\\]](#page-27-5), the impact of\
    \ work from home situation [\\[30\\]](#page-27-6) [\\[41\\]](#page-28-3) [\\[34\\\
    ]](#page-27-11) [\\[7\\]](#page-26-6), and productivity of software development\
    \ teams [\\[4\\]](#page-26-0) [\\[47\\]](#page-28-8) during the COVID-19 pandemic.\n\
    \nFor example, in the study [\\[21\\]](#page-27-3), the developers' well-being\
    \ during the pandemic was focused as emotions and identified that the majority\
    \ of the participants expressed to have positive emotions such as happiness, serenity,\
    \ optimism and etc. In contrast, a study [\\[37\\]](#page-27-4) conducted on the\
    \ effect of the pandemic on developers' well-being and productivity indicated\
    \ that the pandemic has had a negative effect on developers' well-being and productivity.\
    \ It highlighted the need for greater flexibility and resilience in software development\
    \ processes. Further, various studies focused on identifying challenges faced\
    \ by software development teams during the pandemic, including challenges in working\
    \ from home, how it impacted communication, collaboration and productivity of\
    \ the team [\\[34\\]](#page-27-11) [\\[7\\]](#page-26-6), and the challenges of\
    \ remote on-boarding of developers ensuring their successful integration to the\
    \ teams and the organization [\\[41\\]](#page-28-3).\n\nHowever, the majority\
    \ of these studies have focused on identifying the COVID-19 impact on the software\
    \ engineering industry and have not discussed their experience in conducting these\
    \ studies during the pandemic. For example, studies such as [\\[25\\]](#page-27-12)\
    \ discussed the limitations of conducting user evaluations during the pandemic\
    \ and the alternative approaches they used to overcome the challenges. In their\
    \ study, Mendon¸ca et al. [\\[28\\]](#page-27-13) discussed the COVID-19 impact\
    \ on the R & D projects where the study mainly focused on development practices\
    \ than the research aspect.\n\nAlthough the researchers had to face numerous challenges\
    \ in continuing their research, some of the adaptations they used are not new\
    \ to the research. For example, conducting online surveys and online interviews\
    \ were there even before the COVID-19 pandemic as new opportunities for the conduct\
    \ of research with the advances in tools and technologies. In their study [\\\
    [3\\]](#page-26-7), Archibald et al. discussed the satisfactory level of using\
    \ Zoom as a data collection method over other interviewing mediums such as face-to-face\
    \ or telephones. In another study [\\[50\\]](#page-28-9), participants' views\
    \ on telephone interviews were considered where their overall experience was positive.\
    \ This shows that some of the adaptations were not new, rather became more common\
    \ during the pandemic.\n\n#### 3 Methodology\n\n#### 3.1 Research Design\n\nOur\
    \ study was designed as a mixed methods study using a mix of different types of\
    \ data (primarily qualitative with some quantitative data), and different data\
    \ collection methods (survey and interviews), using a sequential approach to expand\
    \ on the findings of the survey with in-depth interviews of willing respondents.\
    \ Figure. [1](#page-5-0) summarises the steps followed when designing and carrying\
    \ out this study.\n\nThe questionnaire for the survey was piloted with two initial\
    \ respondents leading to minor refinements to improve the clarity of the questions\
    \ and answer choices. Similarly, the semi-structured questions for the interviews\
    \ were piloted with the first interviewee leading to some refinements in the structure\
    \ and flow of questions for the remaining eight interviews. We had sought and\
    \ gained\n\n<span id=\"page-5-0\"></span>![](_page_5_Figure_6.jpeg)\n\nFig. 1:\
    \ Mixed methods research using socio-technical grounded theory for data analysis\
    \ (STGT4DA) of qualitative data [\\[19\\]](#page-26-1) and statistical analysis\
    \ of quantitative data.\n\napproval from the Human Ethics Committee at Monash\
    \ University (Reference number: 30921).\n\n#### 3.2 Recruitment\n\nIn order to\
    \ collect quality data from credible sources, we applied a purposive sampling\
    \ approach to reach out to authors who had papers published in premier Software\
    \ Engineering conferences and journals, with a special focus on empirical software\
    \ engineering venues which were likely to publish empirical works involving human\
    \ participants. We sought approval from the journal editors of the IEEE Transactions\
    \ on Software Engineering (TSE) and Empirical Software Engineering (EMSE) journals\
    \ and emailed authors who had their papers published in these journals in the\
    \ years 2020 and 2021. We also emailed authors who had papers published in the\
    \ IEEE International Conference on Software Engineering (ICSE) and Empirical Software\
    \ Engineering and Measurement (ESEM) in the years 2020 and 2021. The aim of this\
    \ exercise was to find a significant number of relevant authors to survey. Since\
    \ the impact of the pandemic was different at different times around the world,\
    \ it was assumed that researchers who had a paper published in 2020 and 2021 likely\
    \ had experience of conducting research studies involving human participants before\
    \ the pandemic and had continued doing so during the pandemic, which was validated\
    \ through the responses of those who agreed to participate.\n\nWhether a study\
    \ was conducted with human participants was not always directly discernible from\
    \ the abstracts. We decided to approach all authors who had papers published in\
    \ these venues in those two years. We emailed a total of 2,190 researchers who\
    \ had co-authored 587 papers in the four venues with an invitation to participate\
    \ in a survey. We explained the purpose of the study in the email and that we\
    \ were interested in hearing experiences of researchers whose research involved\
    \ human participants. Participation was anonymous and voluntary.\n\nWe received\
    \ a total of 89 valid responses from all over the world, representing a 4.1% response\
    \ rate. We included all those responses in our analysis. Since the participants\
    \ were researchers themselves and participated voluntarily without any external\
    \ incentives, those who were genuinely interested participated, which is reflected\
    \ in their thorough and meaningful responses. There were no instances of random\
    \ or less-than-candid responses. Many researchers did not fill out the survey\
    \ or respond to our email invitation. Some responded informing us that their study\
    \ did not involve any human participants. We did not include them in the sample.\
    \ We only included those who responded with a willingness to share experiences\
    \ from studies involving human participants. Those studies could be either published\
    \ in that venue (from which we sourced the author) or not yet published or published\
    \ elsewhere. With this recruitment approach, we were able to reach out to many\
    \ authors who had relevant experiences to share. In the situation where multiple\
    \ authors of the same paper wanted to share their experience, we did not filter\
    \ out any of them as our unit of analysis was individual researchers and their\
    \ experiences, not individual papers. Multiple people from the same study could\
    \ have different experiences and perspectives to share, and we wanted to capture\
    \ these.\n\n#### 3.3 Data Collection\n\nOur invitation email contained a direct\
    \ link to the survey[1](#page-7-0) . The survey was available as a Google Form\
    \ that took approximately 15-20 minutes to complete. It was structured into four\
    \ main sections:\n\n- Section-A: Four questions on general demographic information.\
    \ For example, age, gender, years of experience in conducting human-based research\
    \ in SE and the discipline;\n- Section-B: Four questions on research experiences\
    \ from before the pandemic. For example, the country where the researchers conducted\
    \ their studies, the number of human-based research studies and the techniques\
    \ used in data collection prior to the pandemic;\n- Section-C: Four questions\
    \ on research experiences during the pandemic. For example, the country where\
    \ the researchers conducted their studies, the number of human-based research\
    \ studies and the techniques used in data collection during the pandemic;\n- Section-D:\
    \ Seventeen questions on a specific research study (or multiple studies) selected\
    \ by the respondents that were conducted during the pandemic. For example, the\
    \ purpose of the study, the participants of the study, and the data collection\
    \ techniques used for the methods they used such as interviews, surveys, focus\
    \ groups etc.\n\nWhile the survey was anonymous, there was an option for respondents\
    \ to share their contact details if they wanted to participate in a follow-up\
    \ interview. Based on initial interest registered and later availability, nine\
    \ researchers proceeded to participate in follow-up semi-structured interviews.\
    \ None of these nine researchers were co-authors of the same paper. The interviews\
    \ were conducted over Zoom at a time convenient for the participants and lasted\
    \ between 30 to 60 minutes. The interview questions focused on one or two specific\
    \ studies that the researchers had selected to answer Section-D of the survey\
    \ as well as on the overall experience of conducting SE research with people during\
    \ the pandemic. In doing so, they identified the specific papers they were referring\
    \ to and answered questions about the underlying studies, including in-depth examples\
    \ of challenges encountered, adaptations made and rationales for making those\
    \ adaptations, as well as any possible benefits of conducting these studies during\
    \ a pandemic.\n\n<span id=\"page-7-0\"></span><sup>1</sup> <https://forms.gle/itWS6pzHTmkE3n4r5>\n\
    \n<span id=\"page-8-0\"></span>![](_page_8_Figure_1.jpeg)\n\nFig. 2: Example of\
    \ applying STGT for data analysis.\n\n<span id=\"page-8-1\"></span>☛ ✡ Memo on\
    \ \"Extending participation time of the research study\": The researchers had\
    \ to extend the participation time for various reasons...According to P59, extending\
    \ the participation time benefited the study. They considered online participation\
    \ (via Zoom) as a benefit as it is easier to schedule a meeting time and enabled\
    \ longer participation times... P76 extended the time to explain their experiment\
    \ online... On the other hand, P79 mentioned how extending time can negatively\
    \ impact their research study as participants may quit due to long waiting times.\n\
    \nFig. 3: Example of a memo written as part of the STGT for the data analysis\
    \ process.\n\n#### 3.4 Data Analysis\n\nOur survey contained 20 closed-ended questions\
    \ while the remaining 10 questions were open-ended, where respondents could provide\
    \ free text responses. As a result, the survey gave rise to both quantitative\
    \ and qualitative data. The interviews on the other hand gave rise to only qualitative\
    \ data. The quantitative data was analysed using descriptive statistics and its\
    \ findings are reported at pertinent points in the Findings section below.\n\n\
    The qualitative data, from both the open-ended survey questions and the semi-structured\
    \ interviews, were analysed using socio-technical grounded theory for data analysis\
    \ (STGT4DA) [\\[19\\]](#page-26-1) which involved socio-technical open coding,\
    \ constant comparison, and memoing procedures. Given the socio-technical nature\
    \ of the phenomenon under study in the socio-technical domain of SE and the qualitative\
    \ data from the surveys and interviews that needed analysing, we found STGT4DA\
    \ to be well suited to our purpose. Figure [2](#page-8-0) presents examples\n\n\
    ✟\n\n✠\n\nof the open coding and constant comparison while Figure [3](#page-8-1)\
    \ shows one of the memos written during the analysis. The fourth and fifth authors\
    \ performed the open coding, while the first, second, and third authors reviewed\
    \ and provided inputs on codes, concepts, and categories and helped refine the\
    \ findings through critical questioning and feedback. Through discussions, consensus\
    \ was reached on the most prominent codes, concepts, and categories. Having multiple\
    \ researchers involved in this way helped improve the richness and strength of\
    \ the data analysis.\n\nThe length of open-ended responses in the survey varied\
    \ among respondents. Some provided brief responses to the open-ended questions,\
    \ whereas others elaborated on their experiences. The nine interviews were all\
    \ in-depth and provided rich examples of challenges, adaptations, and perceived\
    \ benefits. Using open coding, a variety of codes were generated from both the\
    \ survey responses and the interviews. All the survey data, from 89 respondents,\
    \ was analysed together. Since the interviews could be linked to specific publications\
    \ and were customised accordingly, they were analysed separately from the survey\
    \ data. The data arising from the nine interviews were also compared to the answers\
    \ provided in the survey filled by the interviewees ahead of the interview. These\
    \ findings are reported in the Findings section. The insights gained from the\
    \ memoing in particular are reported in the Discussion section.\n\n#### 4 Findings\n\
    \nIn this section, we present the findings of our study, drawn from both the survey\
    \ responses and the interviews. The first sub-section provides some general information\
    \ about our researchers and the type of research they conducted, second sub-section\
    \ presents our findings in response to the three research questions.\n\n#### 4.1\
    \ General Findings\n\n#### 4.1.1 Demographics\n\nMost of the researchers who participated\
    \ in our study were 31-40 years of age, had between one to six years of experience\
    \ in conducting software engineering research, and were male. Table [1](#page-10-0)\
    \ shows the distribution of the survey respondents in terms of gender, age, and\
    \ experience in conducting software engineering research. While the low number\
    \ of women may be representative of the wider known gender imbalance across the\
    \ SE research community, it may also be an indication of the lower number of women\
    \ publishing during the pandemic. However, we are unable to confirm this from\
    \ our study. In terms of their geographical distribution, most of our participants\
    \ were located in Sweden, USA, Brazil while a few represented Oceania and Asia.\n\
    \nWe invited survey respondents to a follow-up interview, we received 9 responses.\
    \ Table [2](#page-10-1) summarises all the demographic information of the interview\
    \ participants.\n\n| Gender                                                  \
    \                          |                          | Experience           \
    \                                           |                    |\n|-----------------------------------------------------------------------------------|--------------------------|-----------------------------------------------------------------|--------------------|\n\
    | Men<br>Women<br>Others                                                     \
    \       | 70<br>18<br>1            | Less than 1 year<br>1 to 3 years<br>4 to\
    \ 6 years                | 4<br>22<br>21      |\n| Age                       \
    \                                                        |                   \
    \       | 7 to 9 years                                                    | 10\
    \                 |\n| 20 to 30 years<br>31 to 40 years<br>41 to 50 years<br>51\
    \ to 60 years<br>60+ years | 17<br>42<br>20<br>7<br>3 | 10 to 12 years<br>13 to\
    \ 15 years<br>16 to 20 years<br>21+ years | 11<br>11<br>6<br>4 |\n\n<span id=\"\
    page-10-0\"></span>Table 1: Demographics of Survey Respondents\n\nTable 2: Demographics\
    \ of the Interview Participants\n\n<span id=\"page-10-1\"></span>\n\n| ID    |\
    \ Age   | Gender | Country     | Job Title            | Yrs of ex. | Team | Stdy.\
    \ Dur   |\n|-------|-------|--------|-------------|----------------------|------------|------|-------------|\n\
    | INT01 | 36-40 | Male   | USA         | Assoc. Professor     | 4-6        | 5\
    \    | Approx. 1   |\n| INT02 | 31-35 | Male   | Italy       | Principal researcher\
    \ | 4-6        | 3    | 1+          |\n| INT03 | 26-30 | Female | USA        \
    \ | Principal researcher | 4-6        | 3    | Approx. 0.6 |\n| INT04 | 31-35\
    \ | Male   | Brazil      | PhD candidate        | 1-3        | 5    | 3+     \
    \     |\n| INT05 | 41-45 | Male   | Netherlands | Principal researcher | 1-3 \
    \       | 8    | 1+          |\n| INT06 | 31-35 | Male   | Iceland     | Principal\
    \ researcher | 7-9        | 3    | 1+          |\n| INT07 | 41-45 | Male   | USA\
    \         | Principal researcher | 10-12      | 7    | 0.3         |\n| INT08\
    \ | 36-40 | Male   | Thailand    | SE researcher        | 4-6        | 10   |\
    \ Approx. 1   |\n| INT09 | 36-40 | Male   | Spain       | SE researcher      \
    \  | 4-6        | 5    | Approx. 4   |\n\n### 4.1.2 Number of Studies\n\nWhen\
    \ asked about the number of studies conducted per year, we saw a slight reduction\
    \ in studies during the pandemic , with more researchers opting to conduct less\
    \ than three studies. Resulting in a 10% reduction of high achievers who used\
    \ to conduct more than four studies per year. This is understandable, as they\
    \ had to face many challenges (Section 4.4). It was interesting to find that there\
    \ was no significant difference in the number of studies distribution between\
    \ male and female researchers. Additionally, one might assume that researchers\
    \ living in countries with less COVID-19 restrictions would have had a lesser\
    \ impact as against researchers living in other regions. However, we did not find\
    \ a co-relation between the geographical location of the researcher and the number\
    \ of studies and this just goes on to show the widespread impact of the pandemic.\n\
    \n### 4.1.3 Data collection methods and participant groups\n\nWe asked about use\
    \ of six common data collection methods with our researchers : Interviews, Surveys,\
    \ Focus groups, Observations, Workshops and User evaluations. Our findings show\
    \ that each of these methods were adopted to a lesser extent during the pandemic,\
    \ as shown in Table [3.](#page-11-0) Out of these six methods, observations were\
    \ the most impacted. This is supported by our findings in Section 4.4, where observations\
    \ are identified as the most challenging data collection method during the pandemic.\
    \ In all these methods, during the pandemic online techniques were adopted most\
    \ as can be expected. Surveys were mostly conducted via online survey platforms\
    \ while few used email based questionnaires as well. The other five methods: interviews,\
    \ focus groups, observations, and workshops, all had a significant uptake in the\
    \ use of video conferencing. Additionally, few used emails and texting app to\
    \ conduct interviews, few focus groups were conducted via text based social media\
    \ groups i.e Whatsapp, Messenger and few observations were conducted offline via\
    \ diary/note taking. Furthermore, both observations and workshops had few adoptions\
    \ of collaborative tools as well.\n\n#### <span id=\"page-11-0\"></span>Table\
    \ 3: Reported data collection methods and participant groups\n\n| Method     \
    \  |          | Group                           |          |\n|--------------|----------|---------------------------------|----------|\n\
    | Interview    | 62<br>54 | Sw Developers<br>Sw Managers    | 63<br>28 |\n| Surveys\
    \      | 67<br>60 | Sw Designers<br>Sw Testers      | 26<br>24 |\n| Focus Grps\
    \   | 29<br>17 | Users<br>Academics              | 19<br>14 |\n| Observations\
    \ | 36<br>12 | Others                          | 20       |\n| Workshops    |\
    \ 22<br>11 |                                 |          |\n| User Evals   | 30<br>20\
    \ | Pre-Pandemic<br>During-Pandemic |          |\n\nWhen queried about the participant\
    \ groups they worked with during the pandemic, we found that most have focused\
    \ on software industry professionals such as software developers, managers, designers,\
    \ testers and only a few had worked with software users, academics and other groups.\
    \ The distribution of number of studies conducted with each of these groups is\
    \ shown in Table [3.](#page-11-0) In terms of the data collection methods, we\
    \ found that with academics, observations were used slightly more than other methods\
    \ whereas with other groups all methods were adopted equally. This can be due\
    \ the fact that as observations take a significant amount of time, academics were\
    \ happy to allocate those large chunks of time for research as against other groups.\n\
    \n### 4.2 Challenges, Adaptations, and Fringe Benefits\n\nIn this section, for\
    \ ease of reading, we present the challenges, adaptations, and fringe benefits\
    \ under three main research steps that were most commonly covered by the respondents:\
    \ research design, recruitment, and data collection.\n\n### 4.2.1 RQ1: What challenges\
    \ did SE researchers face during the pandemic?\n\nIn response to the first research\
    \ question, we identified a number of challenges that SE researchers had faced\
    \ in working on research that involved human participants during the pandemic.\
    \ These were spread across the research steps of research design, recruitment,\
    \ and data collection.\n\n# x Challenges with Research Design\n\nExtra effort\
    \ to re-design: A number of researchers stated they had to put extra effort into\
    \ the design for online data collection. This work included ensuring the security\
    \ of sensitive data (collected online), difficulties with the ethics application\
    \ process and other challenges with the design. Researchers said they were often\
    \ exhausted by the extra effort they had to contribute. According to INT07 -\"\
    I was like, this is crazy, we should simplify.\". This is also reflected in discussions\
    \ of related work where researchers had to re-design studies by adding an additional\
    \ step to build rapport with interviewees [\\[3\\]](#page-26-7) or to prepare\
    \ interviewees to ensure their home backgrounds are not captured [\\[16\\]](#page-26-3).\
    \ They also had to plan for possible distractions in working from home and address\
    \ aspects such as interviewees not being used to seeing themselves on screen while\
    \ keeping them engaged in eliciting in-depth answers [\\[36\\]](#page-27-9).\n\
    \nChallenges in the environmental setup: Along with adjustments to the design,\
    \ researchers also faced difficulties with setting up the actual data collection\
    \ environment. The following quote by INT07 is a reflection of this: \"I think\
    \ the bigger challenge is just getting it set up and going through, I mean, you\
    \ typically have to install drivers, you have to calibrate, you have to attach\
    \ it to your monitor.\". On a few occasions, it was not possible to set the online\
    \ environment at all, as P33 mentioned \"... we wanted to do an eye-tracking study,\
    \ but that requires them coming to our lab or us coming to their office to install\
    \ an eye tracker, and we couldn't do that since we aren't in person\".\n\n# Challenges\
    \ with Recruitment\n\nChallenges with invitation medium: Researchers indicated\
    \ different challenges related to the particular channels they used for sending\
    \ invitations. According to researchers [INT09, P27], there were fewer replies\
    \ to email invitations. According to some [INT09, P27], recruitment through online\
    \ conferences was difficult since people tend to multitask during online conference\
    \ attendance and it becomes difficult to attract their attention. As one said\
    \ \"People are not 100% focused into the conference...\". Another challenge with\
    \ recruitment medium was the loss of some traditional recruitment channels due\
    \ to the pandemic. A consequence of this loss was reported as getting participants\
    \ with diverse demographics compared to pre-pandemic. P48 mentioned that \"Usually\
    \ able to recruit at meetups, but these were not running, so recruiting was mostly\
    \ online and involved a lot of students rather than professionals.\"\n\nReduced\
    \ response rate: While this is a common challenge generally faced by all researchers\
    \ working with participants, it was potentially aggregated with the pandemic.\
    \ Researchers indicated that the pandemic led to a reduction in their response\
    \ rate during data collection. There were also uncertainties as to whether participants\
    \ will join online data collection or not. The following comment by P24 is reflective\
    \ of this: \"...there was no guarantee participants join on Zoom\". INT09 also\
    \ reported that in the absence of inperson invitations, emails were sent via different\
    \ media which also reduced the response rate, \"During pandemic, you send email\
    \ to manager and manager send the emails to them, but you get 60-70 % responses\"\
    . Some related work also highlights how some interviewees perceived video interviews\
    \ as easier to reschedule (particularly last minute), and how this seem to have\
    \ affected participants' commitment to attend on time or show up at all [\\[36\\\
    ]](#page-27-9)\n\n# 0 Challenges with Data Collection\n\nHandling of sensitive\
    \ data online: Researchers indicated that handling sensitive data during virtual\
    \ data collection was a real challenge and extra effort was needed. According\
    \ to INT07 \"We had to build a website that had our tool and pull data from our\
    \ source code repositories, which is sensitive, and we had to record the responses\
    \ of the people not anonymised, which was also sensitive.\"\n\nReduced human cues\
    \ online: In the absence of in-person data collection, researchers were deprived\
    \ of the obvious benefits such as observing participants' emotions and body language.\
    \ INT08 shared - \"...even we don't evaluate their body languages, it's going\
    \ to be somewhat difficult see how they feel or whether they struggle with the\
    \ tool\". This is supported by literature where researchers find having only the\
    \ neck-up video left out all hand gestures, leg tapping, etc. that may have provided\
    \ some useful insights [\\[29\\]](#page-27-8). Additionally, in some of our other\
    \ work, we also found that groups such as elderly expressed technical concerns\
    \ in using online methods and instead preferred in-person interviews. Interacting\
    \ online also made it harder for some to understand the participants. INT04 said\
    \ \"Maybe the biggest problem is when I talk in English, it is harder to understand\
    \ the accent, it is harder online, and without the camera, it is even harder\"\
    . But from an EDI perspective some may feel comfortable in switching off their\
    \ video and responding via typing. This is supported by literature where people\
    \ with communicative and cognitive disabilities find communication via typing\
    \ gave them time to think and respond as well as resulting in less anxiety [\\\
    [6\\]](#page-26-8)\n\nChallenges with diverse data collection methods: Researchers\
    \ stated that challenges in data collection depended on the method used:\n\n-\
    \ Survey: P63 mentioned that they had to run their surveys for a longer period\
    \ of time during the pandemic, compared to before.\n- Focus groups: P3 mentioned\
    \ that finding a common time slot for conducting focus groups was more challenging.\
    \ They said, \"Most research guidelines suggest face-to-face interviews and focus\
    \ groups over virtual and text-based ones. However, finding a time slot with our\
    \ study participants -especially a common one for the focus groups- became way\
    \ too difficult when the COVID crisis hit the country.\"\n- Observations: P54\
    \ reported that online observation of study participants was challenging compared\
    \ to face-to-face observation. P12 said, \"We wanted to collect observational\
    \ data of how novices and experts browse stack overflow. Pre-pandemic, we would\
    \ have brought people into the lab to use an instrumented computer. However, this\
    \ was not possible, so we screen-recorded remote interactions and used manual\
    \ annotation which was definitely a bit of a pain.\"\n- Experiments: P76 said\
    \ online experiments were less productive than faceto-face ones: \"Entire experiments\
    \ are restricted to online only. In-person would have been more productive in\
    \ explaining the experiment process, even though the experiment can be done online.\"\
    \n- Interviews, Focus groups: INT07 mentioned that the quality of the data transcriptions\
    \ was less than the paid transcriptions they used to have before the pandemic.\
    \ Likewise, a participant [P75] said that building trust with participants during\
    \ online interviews was challenging: \"Sometimes it is harder to establish the\
    \ trust when doing online interviews.\" -P75\n- User evaluations: INT07 stated\
    \ that it was difficult to evaluate models in practice. However, they did not\
    \ explain the reason for it. Sending equipment to users to evaluate models was\
    \ challenging as the users did not want to keep the equipment, according to INT07.\
    \ Likewise, INT09 discussed that it was difficult to grab the attention of users\
    \ for evaluation during the pandemic. INT08 discussed that there could be a difference\
    \ in the user evaluation settings during the pandemic, which was challenging.\n\
    \nTechnical challenges: Data collection was frequently interrupted due to technical\
    \ difficulties related to internet connectivity or the facilitation of online\
    \ sessions. INT08 reported experiencing technical difficulties in facilitating\
    \ the users to play around with the tool to know about their experience and see\
    \ the effectiveness of visualisations. Making changes to the technical setup of\
    \ a tool was also difficult.\n\nWhen analysing these challenges based on SE researchers'\
    \ experience, we found that junior researchers (those with less than 6 years of\
    \ experience) struggled more in data collection and study advertisement. This\
    \ may be due to their lack of experience and lack of pre-established connections\
    \ for advertising venues. Data also showed that senior researchers (more than\
    \ 6 years) found recruitment and data analysis more difficult than their juniors.\
    \ This can possibly be attributed to the limited familiarity of senior researchers\
    \ in using online methods such as social media for recruitment.\n\n#### 4.2.2\
    \ RQ2: How did SE researchers adapt to the challenges?\n\nIn response to the second\
    \ research question, we identified the resilience of SE researchers in continuing\
    \ with their human-oriented research despite the aforementioned challenges. Respondents\
    \ share a variety of adaptations they had made to their research design, recruitment\
    \ techniques, and data collection procedures in the face of the challenges. However,\
    \ a considerable number of participants mentioned that they did not use any adaptations\
    \ in any of the stages of their studies (e.g., recruitment, data collection, etc)\
    \ as they were using similar approaches even before the pandemic. However, they\
    \ pointed out that they experienced more participants' availability during the\
    \ pandemic than before. \"We did not make adaptations, but the participants were\
    \ more available to participate in video calls than to participate in face-to-face\
    \ discussions\" - P20.\n\n# @ Adaptations to Research Design\n\nExtended study\
    \ duration: Researchers acknowledged they conducted longer studies and at times\
    \ it depended on the type of tasks e.g: \"It depends on the task, but during the\
    \ pandemic it takes more time (less efficient) to finish a task\" - P72. They\
    \ extended the participation time and even disregarded task completion time or\
    \ let the participant complete the study without any time limitation, at their\
    \ own convenience during the pandemic. The study duration was extended,\n\n- To\
    \ explain the study: The researchers had to extend the time of the study as it\
    \ requires more time to explain the study when conducted in online environment.\
    \ For example, it was mentioned that when explaining an experiment online takes\
    \ more time than conducting it face-to-face. \"Longer, the longer time need of\
    \ explaining the experiment online\" -P76.\n- To address technical challenges:\
    \ \"During the pandemic, an extra time is necessary to prepare for possible technical\
    \ errors in video conferencing\" - P28. For example, extra time was needed to\
    \ prepare virtual setups, to deal with online connection problems, and blurriness\
    \ in the video/audio setups. However, it was also mentioned that sometimes solving\
    \ technical challenges was beyond researchers. \"Internet connectivity was not\
    \ stable for most of the participants, and we could not help in any way\" - P64.\n\
    \nReduced study duration: In contrast to the earlier point, some researchers had\
    \ sought to reduce their study duration. Reasons given included:\n\n• To keep\
    \ participants focused: It was mentioned that some researchers were concerned\
    \ that it maybe difficult to keep participants focused during online interviews/evaluations\
    \ as most were working remotely and had many work commitments. To make help them\
    \ stay focused, the study time was reduced in the pandemic. \"We tried to keep\
    \ participation time shorter in the online setting because it is more difficult\
    \ to keep people focused during interviews or evaluations\" - P14.\n\n• To recruit\
    \ more participants: Reducing duration of online studies such as interviews, surveys\
    \ were identified as beneficial in recruiting more participants during pandemic.\
    \ \"We tried to keep participation time around 15 minutes, helpful in getting\
    \ more participants\" - P22.\n\ni Adaptations to Recruitment\n\nIncreased use\
    \ of social media: Researchers who used to adopt various forms of physical advertisement\
    \ had to completely move onto online recruitment, especially using social media.\
    \ \"Before the pandemic, we used many times face-to-face events to advertise our\
    \ study and get participants, but now we are more limited to online events, social\
    \ media (e.g., LinkedIn)\" -INT09/P54. Similarly, another participant also mentioned\
    \ that they used social media like LinkedIn to connect with people and recruit\
    \ them: \"I usually use LinkedIn, use connection invitations to connect with them.\"\
    \ - INT04/P45 The advertising for recruitment was conducted predominantly via\
    \ social media such as LinkedIn, and Twitter. They used methods such as posting\
    \ advertisements on these social media, sharing recruitment information via social\
    \ media groups (e.g. LinkedIn groups), and sending private messages to potential\
    \ participants (via LinkedIn). For example, an associate professor mentioned that\
    \ using social media was very effective during the pandemic. \"Because of the\
    \ pandemic, many have started relying more on social media to connect. Therefore,\
    \ advertising there has become more effective\" - INT01/P35.\n\nUse of personalized\
    \ emails: It was pointed out that sending general emails to a wider interested\
    \ population did not work when recruiting participants for many research studies\
    \ during the pandemic. Hence, researchers used personalized emails to potentially\
    \ interested participants and as a result the response ratio was high. To do this,\
    \ first, the researchers identified potential participants via their personal\
    \ networks and then reached out to them using personalized emails rather than\
    \ sending a general email invitation. INT07, a principal researcher, mentioned\
    \ that having a unique pitch for each participant is important when recruiting\
    \ participants via email. \"There is a template that we follow, but we let them\
    \ know we looked at the change you made last week, we want to ask you about it,\
    \ making it personalized\" - INT07/P33.\n\nLeveraging online events: During the\
    \ pandemic, events such as workshops, talks, conferences, and meetups were conducted\
    \ fully online. Researchers used these various events to recruit participants\
    \ for their studies. Online advertisements (posters), online surveys, and Google\
    \ forms were shared in these events inviting participants. For example, during\
    \ online talks, interested participants were collected by sharing a survey/Google\
    \ form. \"Typically we would have a paper sign-up sheet somewhere on campus, but\
    \ we collected interested participants through a Google Form instead\" -P38. However,\
    \ recruiting participants from these online events was somewhat challenging as\
    \ the researchers might not get the target participant groups they want. For example\
    \ \"usually able to recruit at meetups, but these were not running so recruiting\
    \ was mostly online and involved a lot of students rather than professionals\"\
    \ - P48.\n\nOther approaches for recruitment: Researchers said that they used\
    \ a few other recruitment methods:\n\n- Snowballing: Asking participants to introduce\
    \ someone, providing incentives to the participants. This helped to build trust,\
    \ which was quite important in pandemic-led online interactions [\\[51\\]](#page-28-10)\n\
    - Providing attractive incentives to the participants to appreciate the participants'\
    \ time commitment. This has always been helpful for recruitment in general. During\
    \ the pandemic, the researchers who worked with developing countries where most\
    \ had lost their jobs, found this especially helpful [\\[16\\]](#page-26-3).\n\
    - Personal connections: Some chose to meet participants even after the study which\
    \ helped in reaching out to them for other studies later and was helpful in having\
    \ contacts of the participants ahead of time. \"We identified projects and also\
    \ where we knew we had contacts ahead of time because we have talked to them earlier\"\
    \ -INT07/P33. Other research has also found the personal touch introduced by referrals\
    \ and community outreach helpful in recruitment [\\[23\\]](#page-27-14). Some\
    \ even opted to conduct pre-interview rapport building by having introductory\
    \ conversations with interviewees before interviews [\\[36\\]](#page-27-9)\n-\
    \ Involving gatekeepers: Based on related work, some researchers found it hard\
    \ to build a rapport with participants due to lack of actions such as handshaking\
    \ and food/drink sharing. To overcome this, some recruitment was conducted via\
    \ 'gatekeepers' who facilitated an introduction or even secured the interview\
    \ [\\[36\\]](#page-27-9)\n- Convenience sampling: This was adapted for the studies\
    \ with limited time. In the pandemic led recruitment it was difficult to build\
    \ rapport with new entities. Therefore for some studies, convenience sampling\
    \ was the only way forward [\\[10\\]](#page-26-9)\n\n# 5 Adaptations to Data Collection\n\
    \nShift to online methods: All six data collection methods we talked to researchers\
    \ about (surveys, interviews, focus groups, observations, workshops and user evaluations)\
    \ were transformed to online approaches. \"interview scripts were revised and\
    \ minor alterations were introduced to the version used in online interviews.\"\
    \ - P2. As a result, these involved audio/video recordings, screen-recording/screen\
    \ capturing, web-based Q & A. \"We usually collect only audio recording during\
    \ and moderator notes, but we adapted those by adding video recording and notes\
    \ writing on collaborative tools.\" - P21. Participants moved to online approaches\
    \ to conduct surveys. P32 said, \"We moved to Google Forms to conduct surveys.\"\
    \ - P32. This shift resulted in benefits for some e.g.: it helped to conduct more\
    \ interviews within the same day, while it led difficulties to for some e.g.:\
    \ it was difficult to conduct observations and user evaluation online.\n\nBetter\
    \ leveraging online tools: When using various adaptations to data collection methods,\
    \ the use of online tools played an important role. Whether it was for interactions\
    \ with participants, observing/capturing participant tasks or as an alternative\
    \ way for data collection, the researchers used a variety of online tools during\
    \ the pandemic such as,\n\n- Video conferencing tools: Zoom, Skype, and Google\
    \ Meet were mentioned as the key video conferencing tools that were used to interact\
    \ with participants in interviews, observations, focus groups and user evaluation\
    \ studies. \"Before the pandemic, interviews were conducted in-person only for\
    \ participants residing in the city. During the pandemic, they were given the\
    \ option of using Zoom as per their convenience\" -P85. P45 mentioned that they\
    \ had to use Google Meet to conduct the interview online during the pandemic whereas\
    \ P47 used MS Teams.\n- Screen capturing/recording/transcribing: Most video conferencing\
    \ tools themselves provided facilities for screen capturing, recording and even\
    \ transcribing (e.g. Zoom). Screen capturing/recording was used in observations\
    \ and user evaluations to capture participants' tasks/behaviours during the studies\
    \ and mentioned that they would use it in future studies as it was very successful.\
    \ \"It was wonderful, I would only do user studies this way going forward\" -\
    \ INT07/P33. Similarly, another participant [P59] said, \"I found it easier for\
    \ subjects to agree to record audio sessions or interviews on video.\" -P59\n\
    - New data sources: Some researchers shifted to using alternative ways for data\
    \ collection, such as using GitHub repository data, or running several iterations\
    \ with an internal team when they needed to evaluate a tool that they had developed.\
    \ They also highlighted the importance of finding new approaches to conduct the\
    \ studies and having a contingency plan to continue the studies. \"I think the\
    \ COVID situation draws us to find new solutions that we thought we could never\
    \ use before\" -INT08/P47.\n\n## 4.2.3 RQ3: Were there any fringe benefits doing\
    \ research during the pandemic?\n\nFinally, in posing the third question, we were\
    \ not expecting to find many benefits to be shared. However, we were pleasantly\
    \ surprised as respondents shared several fringe benefits of the adaptations they\
    \ had made to their research practices during the pandemic. These are discussed\
    \ below.\n\nEasier recruitment: The majority of the researchers mentioned that\
    \ recruiting participants for their research studies was easier during the pandemic,\
    \ as there were fewer geographic constraints in recruitment [INT07, INT02, P33].\
    \ INT07 mentioned, \"In this case, we're like, well, we can talk to people anywhere.\
    \ It doesn't really matter as long as we can find a time\". P29 said, \"During\
    \ the pandemic, all interviews were conducted using video conferences. However,\
    \ it allowed performing interviews with participants overseas.\". A researcher\
    \ in the survey [P78] supported this by stating that it was easier to find participants\
    \ as the participation was online. P78 said,\"It was easier to find participants\
    \ from several companies, as everyone participated online.\"\n\nExpanded participant\
    \ cohort: A researcher [INT01] assumed that there might be high chances of getting\
    \ participants during the recruitment in the pandemic. Another researcher in the\
    \ survey [P20] reported that the online recruitment process was better than in-person\
    \ recruitment as it increased the participant number. P20 said, \"We did not make\
    \ adaptations, but the participants were more \"available\" to participate in\
    \ video calls than to participate in \"in vivo\" discussions.\" However, it is\
    \ also mentioned that, during the pandemic, getting more companies together was\
    \ easier, however, harder to get the commitment sometimes.\n\nIncreased participant\
    \ diversity: A researcher [INT01] highlighted that the diversity of their study\
    \ participants increased as they were recruited from around the globe. \"The diversity\
    \ increased because we could have people from different geographic locations in\
    \ the data collection, in particular, creating diverse focus groups participation\"\
    \ -[P02]. Another participant [P07] quoted: \"There was a flexibility and possibility\
    \ to reach a larger pool.\" -P07\n\nSaving time and budget: With the shift to\
    \ an online mode of conducting studies, both researchers and participants could\
    \ travel less for studies. Some researchers [INT09, INT02] specifically identified\
    \ less travel time for data collection. INT09 reported, \"Before the pandemic,\
    \ we have to go to the office and meet\". Another aspect of time-saving has happened\
    \ from the perspective of transcription. Researchers in the interview [INT01]\
    \ and survey [P33, P59] reported that it was easier to transcribe the data and\
    \ analyse it during the pandemic. A researcher [INT05] mentioned that email-based\
    \ interviews during the pandemic saved much of their data transcription time.\
    \ Another researcher [P58] mentioned \"Since data is already digital, ... data\
    \ analysis is easier since there is less ambiguity and more structure in the data\"\
    . Overall, a considerable amount of researchers participating in the survey indicated\
    \ that conducting research during the pandemic saved their time in data collection,\
    \ which eventually saved their research budget and increased individuals' willingness\
    \ to participate in their studies. \"Reduced travel times for participants or\
    \ researchers makes planning easier and might increase willingness to participate\"\
    \ -[P58].\n\nEasier data collection: Some researchers reported that it was easier\
    \ to collect data during the pandemic [INT01, INT02, INT07, INT09]. Likewise,\
    \ researchers in the survey [P29] mentioned that they could easily collect the\
    \ data internationally during the pandemic. Some researchers identified even more\
    \ benefits to data collection but these were related to specific data collection\
    \ methods.\n\n• Interviews: A researcher [INT09] mentioned that conducting interviews\
    \ during the pandemic was easier as recording the interview is much easier. The\
    \ researcher said, \"In that case, data collection is easier in the pandemic,\
    \ we can record like what you are doing.\" P33 mentioned the following, \"Since\
    \ we did interviews and tool evaluation over video conference, it was easy to\
    \ record and transcribe the sessions\". A researcher [INT05] also mentioned that\
    \ email-based interviews during the pandemic provided some time for them to analyse\
    \ the responses of the participants. INT05 said, \"Emailbased interviews provided\
    \ enough time for us (research team) to process through the responses of the participants.\"\
    \n\n- Focus groups: Conducting focus groups online has helped to keep participants\
    \ on track with discussion topics, compared to conducting them in person. \"In\
    \ in-person focus group, many participants in the same room would tend to go off-topic.\
    \ However, it was really easy in an online session to keep the discussions on-topic\"\
    \ - [P30].\n- Observations: One of the researchers [INT07] mentioned that virtual\
    \ observation was easy and asking questions to the participants was also easier\
    \ during the pandemic. INT07 said, \"If someone turns off the camera, turns off\
    \ the microphone, they are pretty much invisible, no one sees them. But they can\
    \ be observed.\"\n\nAccelerated completion time: INT07 mentioned that it was easier\
    \ to complete their studies quickly during the pandemic. INT07 said, \"You can\
    \ get off and hop on another one immediately, so that's you'd call it like a positive\
    \ adaptation.\"\n\nIncreased flexibility in data collection: INT01 mentioned that\
    \ the pandemic allowed more flexibility in data collection e.g. it allowed more\
    \ time for assignments and Zoom meetings. According to a researcher [INT04], conducting\
    \ the study during the pandemic was easier as there was no negotiation for the\
    \ interview duration.\n\nEnhanced study flexibility: Another benefit discussed\
    \ by a researcher [INT07] was that it was easier to revisit their collected data,\
    \ know the drawbacks of the data collection method and identify blind spots via\
    \ users in the studies with human participants during the pandemic. Going back\
    \ and making changes to the answers of the collected data was also easy, according\
    \ to some researchers [INT01, INT08]. INT01 mentioned, \"Participants can go back\
    \ to the software to answer the survey, which was very beneficial.\"\n\nWorldwide\
    \ research collaborations: The researchers also discussed getting more opportunities\
    \ for worldwide research collaborations as a benefit. It was mentioned that it\
    \ was easier for them to approach and collaborate with geographically spread groups\
    \ with the help of online collaboration technologies. P59 said, \"I believe that\
    \ the approach of society to online collaboration technologies allows me to collaborate\
    \ more with subjects with whom I carried out the research. In addition, it seems\
    \ to me that since there is less socialization, they also accept more initiatives\
    \ for meetings to discuss professional issues with me\".\n\n![](_page_21_Figure_1.jpeg)\n\
    \n<span id=\"page-21-0\"></span>Conducting Software Engineering Research with\
    \ Human Participants during Covid-19 Pandemic\n\nFig. 4: Key findings of the study\n\
    \n### 5 Discussion\n\n### 5.1 Key Findings\n\nIn analysing the data we collected\
    \ from the survey and follow-up interviews, we identified a list of challenges\
    \ SE researchers faced when conducting research with human participants, the adaptations\
    \ they used as well as several benefits obtained due to the pandemic.Figur[e4](#page-21-0)\
    \ summarises these key findings across challenges, adaptation and benefits SE\
    \ researchers reported in our study.\n\n#### 5.2 Reflections\n\nAs we discussed\
    \ in our related works section, all research with human participants was impacted\
    \ by the pandemic. In the field of Medicine, clinical trials were one of the first\
    \ casualties along with the closing down of laboratory facilities and halt on\
    \ funding [\\[9\\]](#page-26-10). There was also a risk of 'Covidisation' of academic\
    \ research, with research grants and output diverted to COVID-19 research in 2020\
    \ [\\[39\\]](#page-28-11). Sciences such as chemical and biology faced similar\
    \ challenges, with scientists getting banned from accessing laboratories, shortages\
    \ of research equipment (e.g. plastic-ware, personal protective equipment), delays\
    \ in research involving living animals, or requiring human samples [\\[17,](#page-26-11)[5\\\
    ]](#page-26-12). The most impacted group of scientists were the 'Bench' scientists\
    \ who relied more on wet labs [\\[12\\]](#page-26-13). Their adaptations included\
    \ allocating the work-from-home time to plan future experiments and do more reading,\
    \ which led to more review papers [\\[52\\]](#page-28-12). Design researchers\
    \ were another group who were impacted by the pandemic as they needed \"real grass\
    \ root people and faces\" to be the centre of their design practice [\\[1\\]](#page-26-14).\
    \ Similar to SE researchers, they shifted to online interviews and observations.\
    \ However, as they relied more on paying attention to what people do instead of\
    \ listening to people, online data collection was more challenging to them [\\\
    [29\\]](#page-27-8). They adapted their methods to address these challenges by\
    \ trying to get beyond the question-answer dynamic during interviews. They used\
    \ \"think-aloud method' and requested proactive commitment from participants by\
    \ sharing insights with video, pictures, short texts, and audio snippets before\
    \ the interviews to see more than a bobbing head or a shared screen in a conference\
    \ call [\\[14\\]](#page-26-15), [\\[1\\]](#page-26-14). As a field of computer\
    \ science, HCI researchers faced challenges similar to SE researchers with reduced\
    \ participant engagement in online studies, higher risk of privacy, higher noshow\
    \ rates and data loss due to technical issues and requiring an extra level of\
    \ preparation of instructions to send it to participants in advance [\\[45\\]](#page-28-13).\
    \ They also felt recruiting via digital media reduced participant motivation as\
    \ it narrowed down the persuasive abilities of the research team. Their adaptations\
    \ included adopting mixed recruitment strategies, balancing simplicity and complexity\
    \ in studies for better engagement, minding participants' privacy and proficiency\
    \ with the adopted tools, and taking advantage of flexible scheduling to increase\
    \ participant numbers [\\[27,](#page-27-15)[33\\]](#page-27-16).\n\nIt can be\
    \ argued that working remotely had actually started a long time before the pandemic\
    \ started. During the times of the industrial revolution, most people worked from\
    \ the office. However, since the 1980s, with the advances in technology, the concept\
    \ of remote work started emerging, especially with concepts such as \"Global software\
    \ development\" along with \"offshoring\" and \"freelancing\" [\\[43\\]](#page-28-14).\
    \ Some of the challenges in these remote work were social isolation, missing on\
    \ training opportunities, work-life balance issues and lack of awareness in teams\
    \ created by differences in time zones, language and culture [\\[18,](#page-26-16)[24\\\
    ]](#page-27-17), [\\[8\\]](#page-26-17). All these challenges applied to participants\
    \ SE researchers were interacting with as well. However, in traditional remote\
    \ work, the decision to work remotely was a choice; it involved a detailed level\
    \ of planning, training and preparation. But with the pandemic, none of these\
    \ were true, and it led to most of the technical challenges that we discussed\
    \ earlier for SE researchers. Additionally, the physical and mental status of\
    \ the participants were not similar to remote work teams. For example, during\
    \ the pandemic, people were not working from remote offices but from bedrooms,\
    \ kitchen tables and sofas; they had to participate in studies in the middle of\
    \ distractions from children, partners, siblings and roommates. could have COVID\
    \ or maybe taking care of ill family members [\\[11\\]](#page-26-18), [\\[37\\\
    ]](#page-27-4). Therefore, while some of the challenges were similar to traditional\
    \ remote work, there were a lot of differences led by the enforced nature of pandemic\
    \ led remote work and lack of preparation.\n\nWhile we studied SE researchers\
    \ conducting research with human participants during a pandemic, the irony of\
    \ our team being one of them is not lost on us. Indeed, the team faced some challenges\
    \ of our own. These included the usage of terminology, for example \"pre/during\"\
    \ pandemic, due to the pandemic starting at a different time in different countries.\
    \ We collected information on which country the researchers were conducting their\
    \ research in; however, that didn't lead to any interesting findings or correlations.\
    \ Like our respondents we found ourselves adapting our regular practices by providing\
    \ definitions to terminology such as \"pre/during\".\n\nFinally, some fringe benefits\
    \ we experienced include coming up with the recruitment strategy of finding SE\
    \ researchers from the list of publications in reputed venues. In a pre-pandemic\
    \ world, we would prefer to contact researchers at conferences. However, all editors\
    \ were welcoming and supportive of our efforts, by and large, most authors were\
    \ supportive, too. On one occasion an author expressed disturbance due to receiving\
    \ multiple invitations resulting from multiple papers at different venues. Another\
    \ observation is that our mixed method approach (survey followed by an interview)\
    \ enabled us to ask more relevant and customized questions. Although participating\
    \ in a Survey followed by an interview required a significant effort from the\
    \ participants, those who participated were very forthcoming in their responses.\n\
    \nIn our survey, we have not included a specific section referring to future of\
    \ hybrid research. However, when we asked about the challenges, adaptations and\
    \ benefits of doing research during the pandemic, several participants highlighted\
    \ that the challenges they faced during the pandemic can make a hindrance in keep\
    \ doing research in a hybrid world in the future. For example, INT02 mentioned\
    \ that having longer interviews and surveys made difficulties in getting participants\
    \ online and as a result they are now planning shorter interviews and surveys\
    \ to use online in future. Further, INT05 highlighted that they would not use\
    \ slack for focus group studies in future. The reason was that they did not find\
    \ it useful for longer discussions as it was challenging to follow threads on\
    \ slack.\n\n#### 5.3 Threats and Limitations\n\nWe used purposive sampling to\
    \ find SE researchers with relevant experiences while ensuring credibility and\
    \ quality. In doing so, we were led by those researchers who had published papers\
    \ in four prominent SE venues, including two general SE and two empirical SE venues.\
    \ While it cannot be claimed to be entirely representative, this sampling strategy\
    \ was successful in providing us with relevant and valuable data and insights\
    \ for the purpose of the study.\n\nAnother potential limitation could be that\
    \ using Google Forms for data collection may skew the geographical inclusiveness\
    \ of the sample towards the locations of researchers where Google Forms is easily\
    \ accessible, and possibly excluding those locations where this is not the case\
    \ (e.g. China).\n\nWhile our participants faced several challenges in conducting\
    \ research during the pandemic, some of these were not limited to pandemic e.g\
    \ ensuring the security of online collected data. As they faced these challenges\
    \ during the pandemic they seem to have identified them as being led by pandemic.\n\
    \nThis study focuses on the challenges that were faced during the pandemic. We\
    \ were not able to gather data on how researchers' experiences changed with post-pandemic\
    \ as the pandemic was still ongoing when we conducted the study. But analysis\
    \ that probes more into the comparison between regular remote and pandemic remote\
    \ work; and the sustainability of the strategies post-pandemic can be explored\
    \ in future studies. Future studies can also focus on coming up with a set of\
    \ guidelines for different types of studies (e.g observations) especially in the\
    \ post-pandemic research.\n\nSince the study focused on the aspects of research\
    \ related to working with human participants, other steps of research, such as\
    \ data analysis and writing, were not discussed. However, this does not mean SE\
    \ researchers may not have had challenges with those research steps. Future studies\
    \ can take a more holistic look at the SE researcher experience, beyond human-oriented\
    \ research and into the full research life cycle.\n\nFinally, our own research\
    \ team faced many of the same challenges reported by participants in conducting\
    \ this study. Additionally, the time taken to complete the study and write up\
    \ the findings was delayed in response to being inclusive of one of the research\
    \ team members being on maternity leave and later on working part-time.\n\n####\
    \ 5.4 Recommendations\n\nBased on the challenges, adaptations, and fringe benefits\
    \ reported by SE researchers, we propose the following set of guidelines for SE\
    \ research with human participants in the post-pandemic world:\n\n Plan ahead\
    \ to minimize technical difficulties. During online data collection, SE researchers\
    \ had less control over the environment and sometimes faced technical difficulties.\
    \ A contingency plan can help reduce the loss in such scenarios. Some technical\
    \ issues such as internet connectivity are difficult to handle, however, researchers\
    \ can make a plan for any such scenario and share/discuss it with the participants\
    \ beforehand, so that the participants know what needs to be done, in case of\
    \ disruptions (e.g. stop the timer etc).\n\n Hybrid participation is the new standard.\
    \ While recruitment through social media and online events used to be a nice-to-add\
    \ mechanism in addition to in-person invitation in a pre-pandemic world, we recommend\
    \ these as standard additions to all recruitment efforts now as it opens up opportunities\
    \ for more participation and is more inclusive of diverse ways of working and\
    \ engagement.\n\n Making the most of recruitment during online events. Due to\
    \ multitasking during online conference attendance, participants often overlook\
    \ messages. We believe short, attractive graphical messages can help attract their\
    \ attention while recruiting from online conferences.\n\n Leverage features of\
    \ online tools. SE researchers discovered features of the online meeting software\
    \ applications (e.g., recording, screen capture, and auto transcription) to be\
    \ very helpful for data collection. Researchers can continue using these helpful\
    \ features.\n\n Don't compleyely abandon traditional approaches. There are still\
    \ many good reasons to continue traditional approaches to human empirical studies,\
    \ including in-person interviews, observations and focus groups. Indeed in several\
    \ of our current studies we are utilising these in preference to online or hybrid\
    \ studies. This has been done depending on target audience and study e.g. face\
    \ to face focus groups with elderly participants for one of our studies was by\
    \ far and away the preferred mode for these participants. In another of our current\
    \ studies, face to face evaluation of a software tool obviated the need for remote\
    \ participant challenges with downloading, configuring etc.\n\n### 6 Conclusion\n\
    \nThe COVID-19 pandemic impacted all professions and domains, Software Engineering\
    \ research being no different. Our mixed methods study into the experiences of\
    \ SE researchers from around the world conducting research studies involving human\
    \ participants during the pandemic revealed several challenges, adaptations, and\
    \ even some fringe benefits. While some adaptations such as extending study duration\
    \ and leveraging online events were mostly painful, some fringe benefits such\
    \ as increased participant diversity and easier data collection were embraced\
    \ in a way that researchers did not wish to revert to old ways of working. In\
    \ the post-pandemic world, SE researchers working with human participants can\
    \ benefit from better study planning and leveraging hybrid modes of participants,\
    \ effective recruitment from online events, and making the most of the features\
    \ available on online tools to better support research.\n\n#### 7 Declarations\n\
    \n7.1 Funding and/or Conflicts of interests/Competing interests:\n\nConflict of\
    \ interest include Paul Ralph, Sebastian Baltes, Gianisa Adisaputri, Richard Torkar,\
    \ Vladimir Kovalenko, Marcos Kalinowski, Nicole Novielli, Shin Yoo, Xavier Devroey,\
    \ Xin Tan, Minghui Zhou, Burak Turhan, Hideaki Hata, Gregorio Robles, Amin Milani\
    \ Fard, Rana Alkadhi.\n\n#### 7.2 Data Availability Statement:\n\nThe data sets\
    \ generated during and/or analysed during the current study are available in a\
    \ data repository.\n\n#### References\n\n- <span id=\"page-26-14\"></span>1. Remote\
    \ user research: 12 tips from experts. [https://www.shopify.com/partners/blog/](https://www.shopify.com/partners/blog/user-research)\
    \ [user-research](https://www.shopify.com/partners/blog/user-research). (Accessed\
    \ on 11/08/2023)\n- <span id=\"page-26-5\"></span>2. Adom, D., Osei, M., Adu-Agyem,\
    \ J.: Covid-19 lockdown: A review of an alternative to the traditional approach\
    \ to research. Research Journal in Advanced Social Sciences 1, 1–9 (2020)\n- <span\
    \ id=\"page-26-7\"></span>3. Archibald, M.M., Ambagtsheer, R.C., Casey, M.G.,\
    \ Lawless, M.: Using zoom videoconferencing for qualitative data collection: perceptions\
    \ and experiences of researchers and participants. International journal of qualitative\
    \ methods 18, 1609406919874596 (2019)\n- <span id=\"page-26-0\"></span>4. Bezerra,\
    \ C.I., de Souza Filho, J.C., Coutinho, E.F., Gama, A., Ferreira, A.L., de Andrade,\
    \ G.L., Feitosa, C.E.: How human and organizational factors influence software\
    \ teams productivity in covid-19 pandemic: A brazilian survey. In: Proceedings\
    \ of the XXXIV Brazilian Symposium on Software Engineering, pp. 606–615 (2020)\n\
    - <span id=\"page-26-12\"></span>5. Bian, S.X., Lin, E.: Competing with a pandemic:\
    \ Trends in research design in a time of covid-19. Plos one 15(9), e0238831 (2020)\n\
    - <span id=\"page-26-8\"></span>6. Buchholz, M., Holmgren, K., Ferm, U.: Remote\
    \ communication for people with disabilities: Support persons' views on benefits,\
    \ challenges, and suggestions for technology development. Technology and Disability\
    \ 32(2), 69–80 (2020)\n- <span id=\"page-26-6\"></span>7. Butler, J., Jaffe, S.:\
    \ Challenges and gratitude: A diary study of software engineers working from home\
    \ during covid-19 pandemic. In: 2021 IEEE/ACM 43rd International Conference on\
    \ Software Engineering: Software Engineering in Practice (ICSE-SEIP), pp. 362–363.\
    \ IEEE (2021)\n- <span id=\"page-26-17\"></span>8. Charalampous, M., Grant, C.A.,\
    \ Tramontano, C., Michailidis, E.: Systematically reviewing remote e-workers'\
    \ well-being at work: A multidimensional approach. European journal of work and\
    \ organizational psychology 28(1), 51–73 (2019)\n- <span id=\"page-26-10\"></span>9.\
    \ Chong, S.A., Capps, B.J., Subramaniam, M., Voo, T.C., Campbell, A.V.: Clinical\
    \ research in times of pandemics. Public Health Ethics 3(1), 35–38 (2010)\n- <span\
    \ id=\"page-26-9\"></span>10. Cooksey, K.E., Mozersky, J., DuBois, J., Kuroki,\
    \ L., Marx, C.M., Politi, M.C.: Challenges and possible solutions to adapting\
    \ to virtual recruitment: Lessons learned from a survey study during the covid-19\
    \ pandemic. Ethics & Human Research 44(6), 23–31 (2022)\n- <span id=\"page-26-18\"\
    ></span>11. Donnelly, N., Proctor-Thomson, S.B.: Disrupted work: home-based teleworking\
    \ (hbtw) in the aftermath of a natural disaster. New Technology, Work and Employment\
    \ 30(1), 47–61 (2015)\n- <span id=\"page-26-13\"></span>12. Gao, J., Yin, Y.,\
    \ Myers, K.R., Lakhani, K.R., Wang, D.: Potentially long-lasting effects of the\
    \ pandemic on scientists. Nature communications 12(1), 6188 (2021)\n- <span id=\"\
    page-26-2\"></span>13. George, G., Lakhani, K., Puranam, P.: What has changed?\
    \ the impact of covid pandemic on the technology and innovation management research\
    \ agenda. Journal of Management Studies (2020)\n- <span id=\"page-26-15\"></span>14.\
    \ Group, P.L.N.N.: Doing field studies remotely (video). [https://www.nngroup.com/](https://www.nngroup.com/videos/remote-field-studies/)\
    \ [videos/remote-field-studies/](https://www.nngroup.com/videos/remote-field-studies/)\
    \ (2020). (Accessed on 11/08/2023)\n- <span id=\"page-26-4\"></span>15. Gruber,\
    \ M., Eberl, J.M., Lind, F., Boomgaarden, H.G., et al.: Qualitative interviews\
    \ with irregular migrants in times of covid-19: Recourse to remote interview techniques\
    \ as a possible methodological adjustment. In: Forum Qualitative Sozialforschung/Forum:\
    \ Qualitative Social Research, vol. 22, p. 7 (2021)\n- <span id=\"page-26-3\"\
    ></span>16. Hall, J., Gaved, M., Sargent, J.: Participatory research approaches\
    \ in times of covid-19: a narrative literature review. International Journal of\
    \ Qualitative Methods 20, 16094069211010087 (2021)\n- <span id=\"page-26-11\"\
    ></span>17. Heo, S., Chan, A.Y., Diaz Peralta, P., Jin, L., Pereira Nunes, C.R.,\
    \ Bell, M.L.: Impacts of the covid-19 pandemic on scientists' productivity in\
    \ science, technology, engineering, mathematics (stem), and medicine fields. Humanities\
    \ and Social Sciences Communications 9(1), 1–11 (2022)\n- <span id=\"page-26-16\"\
    ></span>18. Herbsleb, J.D.: Global software engineering: The future of socio-technical\
    \ coordination. In: future of software engineering (FOSE'07), pp. 188–198. IEEE\
    \ (2007)\n- <span id=\"page-26-1\"></span>19. Hoda, R.: Socio-technical grounded\
    \ theory for software engineering. IEEE Transactions on Software Engineering 48(10),\
    \ 3808–3832 (2021)\n- <span id=\"page-27-7\"></span>20. Idnani, D., Kubadia, A.,\
    \ Jain, Y., Churi, P.P.: Experience of conducting online test during covid-19\
    \ lockdown: A case study of nmims university. Int. J. Eng. Pedagog. 11(1), 49–63\
    \ (2021)\n- <span id=\"page-27-3\"></span>21. Ju´arez-Ram´ırez, R., Navarro, C.X.,\
    \ Tapia-Ibarra, V., Jim´enez, S., Guerra-Garc´ıa, C., Perez-Gonzalez, H.G.: How\
    \ covid-19 pandemic affects software developers' wellbeing: an exploratory study\
    \ in the west border area of mexico-usa. In: 2021 9th International Conference\
    \ in Software Engineering Research and Innovation (CONISOFT), pp. 112– 121. IEEE\
    \ (2021)\n- <span id=\"page-27-1\"></span>22. Khoo, E.J., Lantos, J.D.: Lessons\
    \ learned from the covid-19 pandemic. Acta Paediatrica (Oslo, Norway: 1992) 109(7),\
    \ 1323 (2020)\n- <span id=\"page-27-14\"></span>23. Kim, N.H., Wilson, N., Mashburn,\
    \ T., Reist, L., Westrick, S.C., Look, K., Kennelty, K., Carpenter, D.: Lessons\
    \ learned recruiting a diverse sample of rural study participants during the covid-19\
    \ pandemic. International Journal of Drug Policy 97, 103344 (2021)\n- <span id=\"\
    page-27-17\"></span>24. Leslie, L.M., Manchester, C.F., Park, T.Y., Mehng, S.A.:\
    \ Flexible work practices: a source of career premiums or penalties? Academy of\
    \ Management Journal 55(6), 1407– 1428 (2012)\n- <span id=\"page-27-12\"></span>25.\
    \ Luy, C., Law, J., Ho, L., Matheson, R., Cai, T., Madugalla, A., Grundy, J.:\
    \ A toolkit for building more adaptable user interfaces for vision-impaired users.\
    \ In: 2021 IEEE Symposium on Visual Languages and Human-Centric Computing (VL/HCC),\
    \ pp. 1–5. IEEE (2021)\n- <span id=\"page-27-5\"></span>26. Marinho, M., Amorim,\
    \ L., Camara, R., Oliveira, B.R., Sobral, M., Sampaio, S.: Happier and further\
    \ by going together: The importance of software team behaviour during the covid-19\
    \ pandemic. Technology in society 67, 101799 (2021)\n- <span id=\"page-27-15\"\
    ></span>27. Marques Correa, C., Diniz Junqueira Barbosa, G., Diniz Junqueira Barbosa,\
    \ S., Selbach Silveira, M.: Hci research experiences during the pandemic: Lessons\
    \ learned for the road ahead. Interacting with Computers p. iwac036 (2022)\n-\
    \ <span id=\"page-27-13\"></span>28. de Mendon¸ca, W.L.M., Costa, P.H.T., Can¸cado,\
    \ E.C.R., Lima, F., Canedo, E.D., Bonif´acio, R., Amaral, L.H.V.: From dusk till\
    \ dawn: Reflections on the impact of covid-19 on the development practices of\
    \ a r&d project. In: Proceedings of the XXXIV Brazilian Symposium on Software\
    \ Engineering, pp. 596–605 (2020)\n- <span id=\"page-27-8\"></span>29. Meskanen-Kundu,\
    \ L., et al.: Remote user study: a reflection on remote user research methods\
    \ during the covid-19 pandemic (2021)\n- <span id=\"page-27-6\"></span>30. Miller,\
    \ C., Rodeghero, P., Storey, M.A., Ford, D., Zimmermann, T.: \" how was your weekend?\"\
    \ software development teams working from home during covid-19. In: 2021 IEEE/ACM\
    \ 43rd International Conference on Software Engineering (ICSE), pp. 624– 636.\
    \ IEEE (2021)\n- <span id=\"page-27-2\"></span>31. Mourad, M., Bousleiman, S.,\
    \ Wapner, R., Gyamfi-Bannerman, C.: Conducting research during the covid-19 pandemic.\
    \ In: Seminars in perinatology, vol. 44, p. 151287. Elsevier (2020)\n- <span id=\"\
    page-27-10\"></span>32. Neto, P.A.d.M.S., Mannan, U.A., de Almeida, E.S., Nagappan,\
    \ N., Lo, D., Kochhar, P.S., Gao, C., Ahmed, I.: A deep dive into the impact of\
    \ covid-19 on software development. IEEE Transactions on Software Engineering\
    \ 48(9), 3342–3360 (2021)\n- <span id=\"page-27-16\"></span>33. van Nifterik,\
    \ W., Visser, F.S., van Erp, J.: Remote contextmapping and prototyping during\
    \ lockdown, a study case. Interaction Design and Architecture (s) 50, 7–26 (2021)\n\
    - <span id=\"page-27-11\"></span>34. Nolan, A., White, R., Soomro, M., Dopamu,\
    \ B.C., Yilmaz, M., Solan, D., Clarke, P.: To work from home (wfh) or not to work\
    \ from home? lessons learned by software engineers during the covid-19 pandemic.\
    \ In: Systems, Software and Services Process Improvement: 28th European Conference,\
    \ EuroSPI 2021, Krems, Austria, September 1–3, 2021, Proceedings, pp. 14–33. Springer\
    \ (2021)\n- <span id=\"page-27-0\"></span>35. Omary, M.B., Eswaraka, J., Kimball,\
    \ S.D., Moghe, P.V., Panettieri, R.A., Scotto, K.W., et al.: The covid-19 pandemic\
    \ and research shutdown: staying safe and productive. The Journal of clinical\
    \ investigation 130(6), 2745–2748 (2020)\n- <span id=\"page-27-9\"></span>36.\
    \ Rahman, S.A., Tuckerman, L., Vorley, T., Gherhes, C.: Resilient research in\
    \ the field: Insights and lessons from adapting qualitative research projects\
    \ during the covid-19 pandemic. International Journal of Qualitative Methods 20,\
    \ 16094069211016106 (2021)\n- <span id=\"page-27-4\"></span>37. Ralph, P., Baltes,\
    \ S., Adisaputri, G., Torkar, R., Kovalenko, V., Kalinowski, M., Novielli, N.,\
    \ Yoo, S., Devroey, X., Tan, X., et al.: Pandemic programming: How covid-19 affects\
    \ software developers and how their organizations can help. Empirical software\
    \ engineering 25, 4927–4961 (2020)\n- <span id=\"page-28-7\"></span>38. Re˜nosa,\
    \ M.D.C., Mwamba, C., Meghani, A., West, N.S., Hariyani, S., Ddaaki, W., Sharma,\
    \ A., Beres, L.K., McMahon, S.: Selfie consents, remote rapport, and zoom debriefings:\
    \ collecting qualitative data amid a pandemic in four resource-constrained settings.\
    \ BMJ Global Health 6(1), e004193 (2021)\n- <span id=\"page-28-11\"></span>39.\
    \ Riccaboni, M., Verginer, L.: The impact of the covid-19 pandemic on scientific\
    \ research in the life sciences. PLoS One 17(2), e0263001 (2022)\n- <span id=\"\
    page-28-1\"></span>40. Riera, R., Bagattini, A.M., Pacheco, R.L., Pachito, D.V.,\
    \ Roitberg, F., Ilbawi, A.: Delays ˆ and disruptions in cancer health care due\
    \ to covid-19 pandemic: systematic review. JCO Global Oncology 7(1), 311–323 (2021)\n\
    - <span id=\"page-28-3\"></span>41. Rodeghero, P., Zimmermann, T., Houck, B.,\
    \ Ford, D.: Please turn your cameras on: Remote onboarding of software developers\
    \ during a pandemic. In: 2021 IEEE/ACM 43rd International Conference on Software\
    \ Engineering: Software Engineering in Practice (ICSE-SEIP), pp. 41–50. IEEE (2021)\n\
    - <span id=\"page-28-5\"></span>42. Ruppel, S.: When your lab is the world but\
    \ the world is closed down-social science research in times of covid-19 (2020)\n\
    - <span id=\"page-28-14\"></span>43. Sako, M.: From remote work to working from\
    \ anywhere. Communications of the ACM 64(4), 20–22 (2021)\n- <span id=\"page-28-6\"\
    ></span>44. Santhosh, L., Rojas, J.C., Lyons, P.G.: Zooming into focus groups:\
    \ strategies for qualitative research in the era of social distancing. ATS scholar\
    \ 2(2), 176–184 (2021)\n- <span id=\"page-28-13\"></span>45. Shah, S., Jain, A.:\
    \ Impact of the covid-19 pandemic on user experience (ux) research. In: HCI International\
    \ 2021-Posters: 23rd HCI International Conference, HCII 2021, Virtual Event, July\
    \ 24–29, 2021, Proceedings, Part III 23, pp. 599–607. Springer (2021)\n- <span\
    \ id=\"page-28-2\"></span>46. Singh, J.A., Bandewar, S.V., Bukusi, E.A.: The impact\
    \ of the covid-19 pandemic response on other health research. Bulletin of the\
    \ World Health Organization 98(9), 625 (2020)\n- <span id=\"page-28-8\"></span>47.\
    \ Smite, D., Tkalich, A., Moe, N.B., Papatheocharous, E., Klotins, E., Buvik,\
    \ M.P.: Changes in perceived productivity of software engineers during covid-19\
    \ pandemic: The voice of evidence. Journal of Systems and Software 186, 111197\
    \ (2022)\n- <span id=\"page-28-0\"></span>48. Tuttle, K.R.: Impact of the covid-19\
    \ pandemic on clinical research. Nature Reviews Nephrology 16(10), 562–564 (2020)\n\
    - <span id=\"page-28-4\"></span>49. Villarosa, A.R., Ramjan, L.M., Maneze, D.,\
    \ George, A.: Conducting population health research during the covid-19 pandemic:\
    \ impacts and recommendations. Sustainability 13(6), 3320 (2021)\n- <span id=\"\
    page-28-9\"></span>50. Ward, K., Gott, M., Hoare, K.: Participants' views of telephone\
    \ interviews within a grounded theory study. Journal of advanced nursing 71(12),\
    \ 2775–2785 (2015)\n- <span id=\"page-28-10\"></span>51. Wilson, B., Wright, K.,\
    \ Taylor, R., Higgs, E.: Beyond recruitment: good participatory practice enhances\
    \ the impact of research in a pandemic. Nature Medicine 27(3), 369–371 (2021)\n\
    - <span id=\"page-28-12\"></span>52. Woolston, C.: Scientists carry on through\
    \ the pandemic. Nature 592, 806 (2021)\n\n### A Appendix : Supplementary Material\n\
    \nA. Madugalla, 'Supplementary Material for Paper Titled \"Challenges, Adaptations,\
    \ and Fringe Benefits of Conducting Software Engineering Research with Human Participants\
    \ during the COVID-19 Pandemic\"'. Zenodo, Dec. 14, 2023. doi: 10.5281/zenodo.10376868."
