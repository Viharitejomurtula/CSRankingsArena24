papers:
- title: Outlier Ranking in Large-Scale Public Health Streams
  abstract: 'Disease control experts inspect public health data streams daily for
    outliers

    worth investigating, like those corresponding to data quality issues or disease

    outbreaks. However, they can only examine a few of the thousands of

    maximally-tied outliers returned by univariate outlier detection methods

    applied to large-scale public health data streams. To help experts distinguish

    the most important outliers from these thousands of tied outliers, we propose
    a

    new task for algorithms to rank the outputs of any univariate method applied to

    each of many streams. Our novel algorithm for this task, which leverages

    hierarchical networks and extreme value analysis, performed the best across

    traditional outlier detection metrics in a human-expert evaluation using public

    health data streams. Most importantly, experts have used our open-source Python

    implementation since April 2023 and report identifying outliers worth

    investigating 9.1x faster than their prior baseline. Other organizations can

    readily adapt this implementation to create rankings from the outputs of their

    tailored univariate methods across large-scale streams.'
  url: http://arxiv.org/abs/2401.01459v1
  keywords: ''
  document: '# Outlier Ranking in Large-Scale Public Health Streams


    Ananya Joshi\*, Tina Townes, Nolan Gormley, Luke Neureiter, Roni Rosenfeld, Bryan
    Wilder


    Carnegie Mellon University 5000 Forbes Rd. Pittsburgh, Pennsylvania, 15213, USA


    # Abstract


    Disease control experts inspect public health data streams daily for outliers
    worth investigating, like those corresponding to data quality issues or disease
    outbreaks. However, they can only examine a few of the thousands of maximallytied
    outliers returned by univariate outlier detection methods applied to large-scale
    public health data streams. To help experts distinguish the most important outliers
    from these thousands of tied outliers, we propose a new task for algorithms to
    rank the outputs of any univariate method applied to each of many streams. Our
    novel algorithm for this task, which leverages hierarchical networks and extreme
    value analysis, performed the best across traditional outlier detection metrics
    in a human-expert evaluation using public health data streams. Most importantly,
    experts have used our open-source Python implementation since April 2023 and report
    identifying outliers worth investigating 9.1x faster than their prior baseline.
    Other organizations can readily adapt this implementation to create rankings from
    the outputs of their tailored univariate methods across large-scale streams.


    # 1 Motivation


    Disease control experts must analyze large volumes of timeseries population-level
    public health data (streams) for data delays, errors, or changes in disease dynamics
    to mitigate disease spread [\[31,](#page-9-0) [30,](#page-9-1) [5\]](#page-7-0).
    Because these streams are noisy, nonstationary, and subject to different dynamics,
    experts can most clearly detect these phenomena when they manifest as specific
    types of point outliers (e.g., large spikes) in individual data streams [1](#page-0-0)
    . Thus, experts have relied on tailored *univariate* methods [\[2\]](#page-7-1)
    applied independently per stream to prioritize data points (outliers) corresponding
    to important phenomena.


    The rapid expansion of public health data since the start of the COVID-19 pandemic
    [\[32\]](#page-9-2) exposed a fundamental


    <span id="page-0-1"></span>![](_page_0_Figure_10.jpeg)


    Figure 1: Existing methods identify 14-20k tied maximumpriority outliers (a subset
    shown here) from 3-4m points. Outshines ranking enables experts to prioritize
    outliers.


    flaw in this approach. When public health organizations only curated a few thousand
    weekly-updated data streams, the number of maximum-priority outliers identified
    this way was relatively small, and experts could examine all outliers manually.
    However, with modern volumes of public health data containing hundreds of thousands
    of data streams updated daily, this approach returns an overwhelming number of
    tied maximum-priority outliers (e.g., 14-20k, as shown in Fig. [1\)](#page-0-1),
    of which many are false positives.


    To address this challenge, we collaborated with the Delphi Group at Carnegie Mellon
    University. Delphi has curated public health data for nearly a decade and maintains
    an API used by various public health organizations [2](#page-0-2) . In the past
    three years, Delphi''s daily data intake increased over 1000x to 3-4 million data
    points across 200-300k data streams due to the availability of public health data
    indicators, including official indicators, like cases or hospitalizations, and
    auxiliary indicators, like insurance claims and cellphone-based mobility [\[33,](#page-9-3)
    [19\]](#page-8-0). These indicators are also available at a higher resolution
    (e.g., from {U.S. state x weekly} to {U.S. county x daily}), and with historical
    data revisions [\[27\]](#page-8-1), which may contain new outliers. Existing univariate
    methods return false positives in this data for three reasons:


    1. Because these methods operate independently per stream, outputs should not
    be compared across streams. More streams means more potential false positives
    because each stream has a different outlier


    <span id="page-0-0"></span><sup>\*</sup>Corresponding Author Email: aajoshi@andrew.cmu.edu


    <sup>1</sup>The joint relationships between streams are generally unstable due
    to the statistical properties of public health data streams.


    <span id="page-0-2"></span><sup>2</sup>These organizations are generally in the
    United States (U.S.) and include national and local organizations.


    threshold.


    - 2. These methods may not account for temporal recency and thus may not be able
    to appropriately rank outliers in data streams that change rapidly (nonstationary).

    - 3. Nonstationarity and historical data availability limit the granularity of
    the output outlier scores (used for ranking).


    Motivated by this setting, we introduce a new task where the goal is to rank the
    overall highest-priority outliers across all data streams, thus limiting false
    positives and prioritizing expert time: multi-stream outlier ranking. Algorithms
    for this task act as a post-processing calibration step by taking values produced
    by any univariate outlier detection method applied independently to each of a
    large number of data streams as input and ranking them by leveraging the historical
    behavior of the underlying univariate method per stream. Our novel algorithm for
    this task, Outshines (Outliers in Hierarchical Networks), uses hierarchical relationships
    between the streams to prioritize outliers that are extreme relative to the recent
    historical behavior of the univariate method across all data streams. Because
    Outshines works with any univariate outlier detection method and on different
    types of indicators, it can adapt to the increasing and changing volumes of large-scale
    public health data.


    Our results from expert evaluations using real public health data streams showed
    that Outshines performs the best across traditional outlier detection metrics
    in our comparisons. As a result, Delphi has deployed Outshines, and experts have
    used it as part of their daily data analysis process since April 2023. These experts
    report identifying outliers worth investigating 9.1x faster with Outshines.


    The Outshines implementation and evaluation materials are open-source at: [https://github.com/Ananya-Joshi/](https://github.com/Ananya-Joshi/Outshines-Documentation)
    [Outshines-Documentation.](https://github.com/Ananya-Joshi/Outshines-Documentation)
    While we focus on public health, this task and algorithm may also be relevant
    in other domains with similar problem formulations (e.g., economics, climate science,
    manufacturing, fraud detection, and computer systems).


    # 2 Problem Background & Formulation


    Each day, T, Delphi receives data points di,r(t), where indicator i is in the
    set of curated indicators I, r is a region in R, where R contains all the regions
    in Fig. [2](#page-1-0) from different tiers (e.g. county, state or national),
    and t is a historical day 0 ≤ t ≤ T. This geospatial-temporal data forms data
    streams, where each stream (identified by i, r) consists of di,r(t) ∀ t ∈ [0,
    T]. The number of data streams is large (|I| × |R|) and far exceeds the history
    (T) available per stream. These streams are then optionally processed with a


    <span id="page-1-0"></span>![](_page_1_Figure_8.jpeg)


    Figure 2: The geospatial hierarchy for public health streams covers 4270 regions.
    HRRs may serve multiple states like HRR 112 and 225 serve both D.E. and M.D. residents.


    Gaussian smoother and a Poisson regression model to remove weekday effects [\[27\]](#page-8-1).
    Because data providers censor data to prevent reverse identification and may report
    data with missing values, higher-tiered regions (e.g., states) may include data
    from more people than expected by combining information from county-level sub-regions
    and must be individually analyzed.


    #### 2.0.1 Geospatial Hierarchies


    Regions in R form a hierarchy (see Fig. [2\)](#page-1-0) which captures geospatial
    and epidemiological relationships. Notably, hospital referral regions (HRR) share
    a hospital system [\[12\]](#page-8-2), and HHS groups contain nearby states [\[13\]](#page-8-3).
    Experts use these hierarchical relationships (e.g., parent, sibling (which share
    a parent), and child streams) for outlier ranking. For example, an expert may
    rank outliers by comparing them to respective points in sibling streams.


    Problem Formulation: Our goal is to increase the rate at which experts can identify
    data points that they deem worth investigating (events) in large-scale data streams.
    Tailored univariate point outlier detection methods can identify these events,
    but not at large scales. So that we can use univariate methods scale for large-scale
    (many) streams, we formalize the multi-stream outlier ranking task, where an algorithm
    inputs values from univariate methods and outputs rankable scores y(d) over all
    newly received data D per day. This ranking can better prioritize expert attention.
    We assess candidate algorithms using a range of traditional outlier classification
    and ranking metrics comparing y and expertprovided outlier scores c(d) ∀ d ∈ D.
    The implemented algorithm must also meet Delphi''s deployment constraint; it must
    process the complete data volume (including handling changing, missing, and revised
    data) in less than one day to stay current with daily updated data.


    <span id="page-2-2"></span>![](_page_2_Figure_0.jpeg)


    Figure 3: Outshines models the hierarchical relationships between streams, applies
    a univariate method per stream to calculate ϕs, creates Pi,t via block maxima
    per indicator i per day t across sibling streams, and finally, ranks ϕ<sup>t</sup>
    by its quantile in Pi,t.


    # 3 Related Works


    To our knowledge, previous work has never considered multi-stream outlier ranking.
    While there are many uni- and multi-variate outlier detection methods [\[2\]](#page-7-1),
    neither is adequate for this problem. Univariate outlier detection methods identify
    outlier data points in individual streams as needed, [\[26,](#page-8-4) [14,](#page-8-5)
    [2\]](#page-7-1), can operate over data streams with different properties (e.g.
    scale[3](#page-2-0) , noise, and outlier patterns) [\[6\]](#page-7-2), and are
    fully parallelizable over large sets of streams. They are particularly relevant
    because public health data streams exhibit strong temporal dependencies. However,
    these methods currently return too many false positives (Fig. 1).


    On the other hand, while multivariate methods can identify outliers given interconnected
    factors, they are limited in several fundamental ways. Some methods rely on dimension
    reduction or sampling [\[16,](#page-8-6) [37\]](#page-9-4), which means that not
    all data is analyzed. Otherwise, they rely on the correlation structures between
    the streams, but these are known to change rapidly in noisy and nonstationary
    data (like public health data) [\[15,](#page-8-7) [10\]](#page-8-8). Multivariate
    methods also generally require much more computational power than univariate methods
    (e.g., via large matrix inversions). Unlike the public health setting, these approaches
    are more relevant in settings where data streams contain similar measurements
    uniformly impacted by global events. Still, even public health-specific approaches,
    like outbreak detection [\[35,](#page-9-5) [20,](#page-8-9) [3\]](#page-7-3),
    are limited by the previously described challenges.


    Outlier Ranking Methods: Outlier ranking methods are overlooked in the existing
    literature. We identified that outlier methods create ranks from the quantiles
    of new data points with respect to an empirical reference distribution, P. This
    distribution, P, uses historical data from a single stream or a small set of similar
    streams. As the size of P increases, so does the resolution of quantiles possible
    that determine empirical scores used for outlier ranking. For example, if P only
    has 10 values, the quantiles would correspond to deciles. The more quantiles available
    in P, the fewer points may be tied at the top empirical quantile (leading to false
    positives). Two existing ranking methods are:


    1. Threshold Ranking : The most common ranking approach, which we call Threshold
    ranking, identifies a dynamic outlier threshold per stream and returns a binary
    [0,1] classification based on values that exceed the threshold [\[21,](#page-8-10)
    [14\]](#page-8-5) that corresponds to a quantile in an empirical reference distribution
    P


    2. Sibling Ranking : The other approach, which we call Sibling ranking, considers
    data from multiple, similar streams that share a parent, g ∈ R (e.g., Rsib(g)
    = {parent(r) = g|r ∈ R} and data considered is di,r(t) ∀ t ∈ [0, T], ∀ r ∈ Rsib(g)).
    Sibling ranking returns a real-valued, rankable score ∈ [0, 1] that corresponds
    to the empirical quantile of new values compared to an empirical reference distribution
    P [\[17\]](#page-8-11)[4](#page-2-1) .


    Both Threshold and Sibling ranking return too many false positives because their
    P 1. uses data from only one or a few streams that cannot readily be compared
    at a large scale, 2. uses the whole stream''s history instead of values that share
    temporal context, and 3. only has a small and varying number of values in P due
    to limited data history per stream.


    # 4 Outshines Method


    Overview: First, Outshines (Fig. [3\)](#page-2-2) models hierarchical relationships
    in data streams for an indicator i. The resulting *hierarchical network* facilitates
    outlier ranking by capturing contextual relationships across all data streams.
    For Delphi''s data, this network contains streams from every region in the geospatial
    hierarchy, not just county-level streams.


    Then, Outshines takes as input the test statistics (ϕ) output from any point univariate
    outlier detection method applied to these hierarchical streams for all relevant
    data points (ϕ(d) ∀ d ∈ {di,r(t) ∀ r ∈ R, t ∈ [t − δ, t + δ]}), where the nonstationarity
    and the available history of the data stream


    <span id="page-2-0"></span><sup>3</sup>E.g., the raw COVID case count in a rural
    county (0-10) will be much differently scaled than that in a city (0-1000)


    <span id="page-2-1"></span><sup>4</sup>Sibling ranking reports mean scores for
    data in multiple sibling sets.


    determine δ. These resulting ϕ measure the degree of agreement between predicted
    and observed values, and extreme ϕ indicate a potential outlier. The tailored
    univariate method must ensure that the ranking of each ϕ matches that from c *per
    stream*. However, because some streams that are illsuited to the tailored univariate
    method may consistently return extreme ϕ, ϕ alone does not provide an informative
    ranking across many data streams and must be contextualized via a ranking algorithm.


    Finally, Outshines outputs the rankable, scaled, realvalued quantiles of test
    statistics (ϕ) from all regions in the hierarchy at time t with respect to an
    empirical reference distribution generated per day, per indicator: Pi,t. Outshines
    creates Pi,t by using hierarchical relationships and extreme value analysis on
    data from times close to t.


    Outshines addresses the sources of false positives present in prior ranking methods
    because Pi,t 1. contains data from streams all across the hierarchy and 2. only
    considers data values at times similar to t. For Delphi''s implementation of Outshines,
    where t are days and the hierarchy is the geospatial hierarchy (Fig. [2\)](#page-1-0),
    3. Pi,t contains more empirical quantiles than the other ranking algorithms and
    can thus provide higher resolution rankable scores.


    <span id="page-3-1"></span>Algorithm 1 Outshines Ranking


    Using Block Maxima to make Pi,t for indicator i and day t Input:ϕ(di,r(t)) ∀ r
    ∈ R Output:y(di,r(t)) ∀ r ∈ R 1: for Rsib ∈ R: #Stream Aggregation Dim. 2: Pi,Rsib,t
    = {} 3: for h ∈ [t−14, t)∪(t, t+ 14]: #Temporal Dim. 4: #Block Maxima 5: Pi,Rsib,t
    = Pi,Rsib,t ∪ max(ϕ(di,r(h)|r ∈ Rsib)) 6: end for 7: end for 8: Pi,t = ∪<sup>R</sup>sib∈RPi,Rsib,t
    9: y(di,r(t)) ← q(ϕ(di,r(t)), Pi,t) ∗ log(|Pi,t|) log(max |Pi,t|) ∀ r ∈ R


    ### 4.1 Generating Outshines Pi,t


    Outshines can rank outliers across multiple streams because of its empirical reference
    distribution, Pi,t. We generate this Pi,t by adapting the block maxima technique
    from extreme value analysis. Traditional block maxima techniques split a data
    stream into equally-sized non-overlapping data blocks (e.g., one block per week)
    and calculate the maximum value in each block to form P [\[9\]](#page-8-12) (e.g.,
    P = {max(di,r(t:t-7)),max(di,r(t-7:t-14))...}). Highly-ranked outliers are points
    d for which ϕ(d), the test statistic, is large even with respect to the reference
    distribution P; i.e., they are more extreme than the most extreme value in a "typical"
    week. The intuition for this approach is that if a univariate method is miscalibrated
    for a particular data stream and regularly returns ϕ with high values, P will
    contain many such examples, and outlier points must have even more extreme ϕ to
    stand out. However, traditional block maxima does not apply to streams with limited,
    nonstationary data [\[28\]](#page-8-13), like ϕ from Delphi''s data. Even recent
    advances that address nonstationarity need long data histories [\[38,](#page-9-6)
    [29\]](#page-8-14). Our method addresses both limited data history and nonstationarity
    in streams of ϕ by changing both the block sizes and the aggregation strategy
    for the block maxima technique.


    Creating New Blocks (Alg 1. lines 1-7): Each block in block-maxima has a temporal
    dimension (e.g., day, week, month) and a stream aggregation dimension (typically
    one stream). Aggregating homogenous, or similar, streams per block is a known
    way to calculate block maxima over more data, but identifying an appropriate homogeneity
    test is difficult and could result in sets of dissimilar streams [\[23\]](#page-8-15).
    Instead, we identify homogenous streams as those that share a parent r ∈ Rsib(g).
    Each set of sibling streams, Rsib, in R is subject to similar conditions by being
    in the same tier and having the same parent[5](#page-3-0) . Aggregating streams
    across Rsib creates blocks of similar regions and addresses limited history.


    We then use two mechanisms to address nonstationarity. First, our blocks have
    a temporal dimension of one observation. Limiting the temporal dimension like
    this creates blocks across streams instead of accross time so that temporal variations
    (e.g., weekday effects) do not skew Pi,t, but there are still enough observations
    for block maxima (e.g., our blocks are 7 sibling streams x 1 day vs. the traditional
    1 stream x 7 days). Second, we limit the temporal range of blocks to data similar
    to the time being evaluated (a regime). Only using data from the same regime (t
    ± δ) ensures Pi,t is relevant to data at time t. For Delphi, that regime is 28
    days, with 14 days of historical data and 14 days of prospective days (when data
    after t is available), so these blocks are the most similar to the time considered.
    This 28-day range (4 weeks) is a standard followed by many organizations participating
    in the CDC''s respiratory illness forecasting tasks [\[1\]](#page-7-4).


    We can then continue with the standard block maxima procedure on these modified
    blocks so that Pi,Rsib,t contains the maximum ϕ per indicator, per Rsib per t
    (Alg 1. line 5). We use the maxima (the most common choice in extreme value analysis)
    because we want values that describe the empirical distribution at the tail, and
    intermediate quantiles are ill-defined for small sibling groups (e.g., 95% from
    a set of 3 regions).


    <span id="page-3-0"></span><sup>5</sup>HRRs at state borders belong to multiple
    sibling sets, which models that these regions are subject to potential outlier
    events from either of their parent streams.


    Aggregating Regions and Scaling (Alg 1. lines 8-9): To make an empirical reference
    distribution with many observations that capture extreme ϕ from all Rsib, these
    Pi,Rsib,t for Rsib ∈ R can be pooled together to create Pi,t. Thus, Pi,t represents
    the distribution of recent extreme ϕ equally weighted from each set of geospatial
    regions, as shown in Alg. [1,](#page-3-1) line 8. Finally, Outshines outputs a
    score using the quantile (q) of new ϕ at time t of Pi,t.


    We apply Outshines to each of Delphi''s indicators separately so that computation
    can occur across all indicators (in parallel) and so that there are no assumptions
    about the relationships between the constantly changing set of available indicators.
    However, scores from Pi,t across different indicators with more observations should
    be weighted higher because they have a higher resolution. Thus, Outshines scales
    each quantile by |Pi,t| divided by the log of the maximum possible observations,
    (e.g., log(|Rsib ∈ R|∗regime)) to return a score (y) in [0, 1]. The log factor
    shrinks the scale for both the numerator (points available) and denominator (total
    possible points) so that between two indicators with different possible total
    lengths (denominator) with the same available/total points, the one with the longer
    stream will have the higher multiplicative factor (and might be ranked higher).


    Ranking Algorithm Comparison: The design of Outshines addresses the sources of
    false positives. First, Outshines ensures that Pi,t does not over-represent any
    region or time so that the output scores are comparable. Outshines compares every
    ϕ(di,r(t)) ∀ r ∈ R to the same Pi,t, unlike Sibling or Threshold ranking, where
    the number of observations in P varies depending on missing data per stream. Outshines
    also only uses data within a regime to create Pi,t. Finally, for Delphi''s data,
    Outshines has more granular output scores because it has more observations that
    characterize P, as follows:


    - 1. Threshold ranking contains all ϕ from a single stream so (Pi,r := {ϕ(di,r(t))|t
    ∈ [0, t) ∪ (t, T]}).

    - 2. Sibling ranking P is at least as large because it contains all ϕ from sibling
    streams (Pi,Rsib :={ϕ(di,r(t))|r ∈ Rsib, t ∈ [0, t) ∪ (t, T]})

    - 3. Outshines ranking P is |Pi,t|= |Rsib ∈ R| × 28


    On Delphi''s data, HRR and HHS tiers create intuitive and numerous Rsib (369 Rsib
    with an average size of 15.85 regions) and T ≤ 300. Thus, Outshines P is twice
    as large as sibling ranking while only using a regime of 28 days, as previously
    described. Increasing the regime from 28 can add more observations and increase
    the granularity of Outshines'' output scores. However, this could lead to false
    positives as it reduces Pi,t''s temporal similarity to t. Accordingly, before
    the evaluation began, we preregistered the Github commit of our Outshines implementation
    with these parameters on OSF [\[18\]](#page-8-16).


    # 5 Tailored Univariate Method (EWMA)


    Outshines can rank ϕ produced by any univariate outlier detection method that
    matches the expert relative ranking per stream. We provide one such univariate
    method tailored to Delphi''s experts in Summer 2023 (as shown in Fig. [3](#page-2-2)
    Box 2). At that time, based on our interviews and observations, these experts
    highly prioritized phenomena that manifested as outliers representing rapid changes
    in streams with a high population, few historical outliers, and few missing values
    (high c). We tailored a model-free Exponentially Weighted Moving Average (EWMA)
    method to identify such points in the public health setting [\[4\]](#page-7-5)).


    Prediction Generation: We use a kernel weighting function, K(t) whose value in
    position w is


    $$\mathcal{K}\_w(t) = \begin{cases} 0 & \text{if } w = t \\ e^{-\frac{|w-t|}{\tau}}
    & \text{otherwise} \end{cases}$$


    where τ=2 to prioritize the temporally closest data values. K is discretely convolved
    with the stream values di,r(t) ∀ t ∈ [0, T] for stream i, r and then standardized
    to generate stream predictions ˆdi,r(t):


    $$\hat{d}\_{i,r}(t) = (\mathcal{K} \* d\_{i,r})(t) / \sum \mathcal{K}(t)$$


    Test Statistic (ϕ) Calculation: The test statistic (ϕ) compares observed and predicted
    values, as described following this paragraph. To cacluate ϕ, we define and scale
    l(t)= ˆdi,r(t) − di,r(t)) to account for stream outlier history. Taking the absolute
    value ensures block maxima selects points representing rapid change regardless
    of direction. Lastly, we multiply this value by the available stream history and
    population (rpop) because these features are important to experts; an outlier
    in rpop= 100k should outrank a national outlier if it is at least 2x as important[6](#page-4-0)
    .


    $$|\phi\_{i,r}(t) = |\frac{l\_{i,r}(t) - \text{median}(l\_{i,r}(t))}{\sigma\_{l\_{i,r}}}|
    \cdot \log(|d\_{i,r}|) \cdot \log(r\_{pop})$$


    During deployment, we observed that EWMA''s ϕ for inflection points and points
    in trends longer than a week did not match that from c. However, Delphi''s experts
    preferred EWMA to a more complex but more accurate method because EWMA only requires
    a linear pass over each stream in parallel.


    <span id="page-4-0"></span><sup>6</sup> In smaller rpop, using absolute difference
    for ϕ''s does not capture subtle outliers (e.g. going from 4 to 5 cases is more
    concerning than 34 to 35), but can be used to detect the extreme outliers Delphi
    experts cared about in July 2023.


    <span id="page-5-2"></span>


    | Task                 |                  | Ranking Method  |                  |                 |                 |               |

    |----------------------|------------------|-----------------|------------------|-----------------|-----------------|---------------|

    |                      |                  | Thresh.         | Opt. Thresh.     |
    Sibling         | Outshines       |               |

    | Timing/Indicator (s) |                  | Generate ϕ      |                  |                 |                 |               |

    | UOD                  | EWMA             | 57.9 ± 35.17    | * 6.71 ± 2.59    |
    * 6.6 ± 2.51    | 319.67 ± 172.55 | 50.58 ± 46.40 |

    |                      | FlaSH            | 458.81 ± 146.21 | * 5.33 ± 2.32    |
    * 5.2 ± 2.12    | 326.54 ± 160.64 | 45.85 ± 46.84 |

    |                      | AR               | 36.13 ± 19.85   | 5.61 ± 3.92      |
    4.32 ± 3.02     | 270.61 ± 156.14 | 58.97 ± 47.10 |

    |                      | Isolation Forest | 420.59 ± 270.15 | 65.04 ± 43.16    |
    61.84 ± 41.92   | 190.58 ± 104.08 | 39.06 ± 29.10 |

    |                      | DeepLog          | 6520 ± 4398     | 53.2 ± 36.13     |
    52.79 ± 35.95   | 188.78 ± 102.44 | 38.97 ± 28.97 |

    |                      | Telemanom        | 6160 ± 4449     | 64.65 ± 47.08    |
    68.26 ± 52.38   | 293.36 ± 159.5  | 57.75 ± 43.44 |

    | # Ties/Indicators    |                  |                 |                  |                 |                 |               |

    | UOD                  | EWMA             | -               | *15.81k ± 1.97k  |
    * 6.05k ± 2.54k | 585.33 ± 549.13 | 6.67 ± 0.65   |

    |                      | FlaSH            | -               | * 22.02k ± 1.97k
    | * 8.08k± 2.13k  | 159.33 ± 23.37  | 7.67 ± 2.85   |

    |                      | AR               | -               | 42.11k ± 18.84k  |
    7.02k ± 3.714k  | 127.67 ± 18.29  | 11.67 ± 10.51 |

    |                      | Isolation Forest | -               | 89.87k ± 67.23k  |
    39.80k ± 21.93k | 3.87k ± 2.23k   | 20.67 ± 20.88 |

    |                      | DeepLog          | -               | 32.29k ± 26.07k  |
    14.24k ± 3.44k  | 260.33 ± 63.78  | 18.0 ± 2.99   |

    |                      | Telemanom        | -               | 78.78k ± 39.10k  |
    53.31k ± 32.42k | 215.0 ± 89.44   | 14.0 ± 2.26   |


    <span id="page-5-3"></span>Table 1: Baseline Comparisons - Yellow highlights the
    deployed combination. This combination has the fewest of ties.


    ![](_page_5_Figure_2.jpeg)


    Figure 4: Evaluation Metrics: The red box highlights the best performing combination
    ranking method x tailored univariate method for standard binary and ranking metrics.
    Correlations were N/A when the method returned all 0s or 1s.


    # 6 Evaluations


    To measure Outshines'' correctness, we used standard outlier detection metrics
    comparing the expert-labeled data we collected on real public health data streams
    to different combinations of ranking x univariate methods (Evaluation 1). We also
    monitored Outshines'' deployment over 4 months and reported results from July
    to August 2023 (Evaluation 2).


    ### 6.1 Evaluation 1. Comparing Method Combinations


    We asked Delphi''s experts to rank outliers from real data streams analyzed with
    Outshines during deployment on July 27, 2023 (snapshot dataset). This data set
    contained 6383 streams from the top three indicators which had outliers worth
    investigating in June 2023[7](#page-5-0) (and were thus likely to contain rankable
    outliers during the snapshot). To compare EWMA with model-based methods, we provided
    200 days of training data and computed rankings over the last 100 days for a total
    of 1.4 million data points over 300 days.


    We evaluated the performance of all combinations of ranking x univariate methods
    on this snapshot dataset compared to the expert-labeled data we collected. The
    four implemented ranking methods were:


    - Threshold ranking [\[21\]](#page-8-10)

    - Optimized Threshold ranking[8](#page-5-1)


    <span id="page-5-0"></span><sup>7</sup>1. Outpatient doctor visits for COVID-related
    symptoms, 2. % COVIDpositive antigen tests, and 3. Estimated % of new COVID hospital
    admissions based on claims data


    <span id="page-5-1"></span><sup>8</sup>The TODS implementation threshold=0.9,
    but we set it to 0.99 to match the frequency outliers are expected [\[36\]](#page-9-7)


    - Sibling ranking [\[17\]](#page-8-11)

    - Outshines ranking (see Methods)


    Comparing these ranking methods served as an ablation for grouping sibling streams
    (Threshold to Sibling) and using extreme values across hierarchies (Sibling to
    Outshines).


    The univariate methods (UOD) were the Tailored Univariate Method EWMA (see Methods),
    FlaSH [\[17\]](#page-8-11), an outlier detection algorithm designed for smaller-scale
    public health streams, and the TODS implementations [\[21\]](#page-8-10) of Telemanom
    [\[14\]](#page-8-5) (Tele) & DeepLog [\[8\]](#page-8-17) (DL) (State of the art
    deep learning methods), Isolation Forest (IF): [\[24\]](#page-8-18), and Linear
    AutoRegressive Models (AR) [\[11\]](#page-8-19). Our proposed combination is Outshines
    x EWMA, and our experimental design (e.g., analysis plan, web forms, implementations)
    was preregistered before data collection began. These experiments were conducted
    on a 2.6GHz Intel Core i7 machine with OSX in Python3.8 for TODS compatibility.


    Combination Feasibility The first section of Table [1](#page-5-2) : Timing/Indicator
    (s)[9](#page-6-0) shows that Outshines is more than 4.5x faster than Sibling ranking
    and generally faster than TODS Threshold ranking. Because Outshines computes Pi,t
    across a 28-day window of ϕ (parallel) instead of all historical ϕ in a stream
    (serial), there may be more pronounced performance gains as T increases. Further,
    our chosen combination of Outshines x EWMA took much less time than deep learning
    univariate methods, which would have required 4x Delphi''s compute resources to
    generate ϕ on deployment data (updated daily) in July 2023 (55 indicators vs.
    3 in the snapshot set) to keep daily processing times under one day.


    More importantly, the second part of Table [1](#page-5-2) : # Ties/Indicator shows
    that Outshines is also the *only* ranking method that produced few enough maximally
    tied outliers for reviewers to investigate daily across all the univariate method
    combinations. Outshines reduces Sibling ranking''s maximally tied outliers by
    over 10x (typically 6-18 ties vs. 200-3k ties). If Outshines'' rankings are meaningful,
    these results show that Outshines can promptly prioritize outliers from large-scale
    public health streams.


    #### 6.1.1 Expert Ranking Generation and Comparison


    To identify if Outshines ranks were prioritizing the outliers experts wanted,
    we needed to address common limitations in obtaining expert-labeled outlier rankings
    [\[36\]](#page-9-7) by having a large number (n = 17 vs. n=3 [\[34\]](#page-9-8))
    of experts, who regularly use public health data streams for research or development
    purposes, evaluate outliers from real data streams (and not synthetic data [\[22\]](#page-8-20)).
    These experts could only review a few of the millions of data points in the snapshot
    dataset, and a random sample of that size would likely contain no outliers worth
    ranking. Instead, because the top deployed Outshines x EWMA rankings are empirically
    a subset of points of the deployed Sibling x EWMA rankings, we could directly
    compare the two methods by asking experts to rank points that were highly differentiated
    by Outshines in deployment (one example per decile, as available). We designed
    a survey where experts inspected two interactive web pages, each with 5 data streams,
    corresponding to the selected outliers and ranked them using the scale {5: Most
    important, 1: Least important}. We had one control stream in each web page to
    measure internal consistency. Using the ranky package [\[25\]](#page-8-21), we
    found that respondents demonstrated internal consistency with high Spearman correlation
    (0.85 ± 0.27) and low Euclidian distance (1.21 ± 0.13) in pairwise rankings for
    the control stream. Reviewers also demonstrated reasonable interrater consistency,
    with a high Spearman correlation (0.71) for rankings *across* respondents.


    In Fig. [4,](#page-5-3) we display mean metrics per stream per person with a 95
    % CI error bar for each combination of ranking x univariate method. We calculated
    binary metrics (Accuracy, F1, and ROCAUC) using the top-k points as the positive
    class, where k is the number of streams with a ranked outlier per person, and
    ranking metrics (Swap Correlation (higher is better) and Hamming Distance (lower
    is better)) by using the respondent''s absolute ranking.


    Our results show that, of all combinations, Outshines x EWMA scores best match
    the experts for these standard metrics. For example, the mean AUC of the Outshines
    x EWMA combination is 0.95 vs. 0.78 from the next best combination (Outshines
    x FlaSH). Similarly, Outshines x EWMA has the highest mean correlation at 0.73
    vs. the next highest from any other ranking method (Sibling x DL) at 0.13. Outshines
    also performed well with other univariate methods - Outshines x FlaSH is always
    the second best performing combination. After Outshines, the second best performing
    ranking method is Sibling ranking, which typically has the third-best performance
    (usually Sibling x EWMA).


    ### 6.2 Evaluation 2: Outshines'' Deployed Performance


    Experts in Delphi have used Outshines in their daily outlier review process since
    April 2023. First, they receive the Outshines scores y(d) for all recently updated
    data. Second, they review the top 20-25 highest ranking points and record any
    outliers worth investigating. Then, they investigate these points by analyzing
    patterns in the national, parent, sibling, or child streams. Afterward, they meet
    with the research team weekly to discuss any findings.


    A. Quantitative Results: Between July 10-August 5, the daily deployment data volume
    from 55 currently updated indicators was 3.5 million ± 280k points. Applying Outshines
    x EWMA over this data volume took 123.44±189.16


    <span id="page-6-0"></span><sup>9</sup>Because EWMA and FlaSH are not in TODS,
    authors implemented a similar ranking method for comparison (indicated by \*).


    <span id="page-7-6"></span>![](_page_7_Figure_0.jpeg)


    Figure 5: Experts can identify outliers worth investigating more quickly with
    Outshines.


    minutes per day on production hardware (3.3GHz Intel Core i7 machine with Pop!OS,
    Python3.10), and the number of ties generated over this data using Outshines ranking
    (21 ± 5.5) were much fewer than with Sibling ranking (14k ± 1.7k).


    The most important metric for Delphi was how quickly experts identified outliers
    worth investigating (events) compared to a baseline from volunteers who met weekly
    to manually review the data without an outlier detection method. As per their
    meeting notes, volunteers found 0-1 outliers worth investigating in this baseline
    every 30 minutes (0.033 Events/Minute). Fig. [5](#page-7-6) shows that our combination
    of Outshines x EWMA increased the rate of expert event identification (0.43 ±
    0.14 events, which is an improvement of 9.13 ± 2.26x over the baseline), as determined
    by selfreported review time and the number of outliers marked for investigation.
    Further, the average number of outliers marked daily with Outshines, 6, far exceeds
    baseline efforts of 0-1 outliers during manual review.


    Additionally, for one week, experts first reviewed 10 random maximally tied points
    from Sibling ranking and then the top 10 data points from Outshines ranking for
    a more direct comparison between these ranking methods. In this evaluation, experts
    found 4.02x as many outliers using Outshines than Sibling ranking and at 3.96
    ± 1.27x the rate.


    B. Qualitative Results: Outshines provided Delphi''s first ever insight into outlier
    data points worth investigating on a large scale. Experts preferred conducting
    a manual review to analyzing a random sample of thousands of outliers, like those
    produced by Sibling or Threshold ranking. This means that Outshines was the only
    ranking method that Delphi could deploy in practice! Experts also felt that the
    feedback cycle with the research team was crucial in staving algorithm aversion
    [\[7\]](#page-8-22), which occurs when humans no longer trust an algorithm output
    (and would prefer manual review). These iterations ensured that the tailored EWMA
    combination matched expert needs (which Outshines scaled) and will continue to
    be useful as Delphi curates new data.


    # 7 Conclusion


    Informative outlier rankings enable disease control experts to analyze large-scale
    public health streams. We modeled this problem as a new task of ranking test statistics
    output from tailored univariate outlier detection methods (multistream outlier
    ranking). Our method, Outshines, uses hierarchical relationships in data streams
    and modified extreme value analysis for this task. Our expert evaluations and
    performance experiments show that Outshines outperforms other ranking methods
    on traditional metrics. Its deployed performance also met experts'' needs by enabling
    them to identify outliers worth investigating 9.1x faster than the baseline. As
    public health data volumes grow, Outshines provides experts with a scalable, flexible,
    and accurate way to find the most important outliers quickly.


    Acknowledgements: This work was supported by a cooperative agreement funded solely
    by CDC/HHS under federal award identification number U01IP001121, "Delphi Influenza
    Forecasting Center of Excellence" and by the by the National Science Foundation
    Graduate Research Fellowship under Grant No. DGE1745016 and DGE2140739. The contents
    do not necessarily represent the official views of, nor an endorsement by, CDC/HHS/NSF
    or the U.S. Government.


    # References


    - <span id="page-7-4"></span>[1] BIGGERSTAFF, M. E. A. Results from the second
    year of a collaborative effort to forecast influenza seasons in the united states.
    *Epidemics 24* (2018), 26–33.

    - <span id="page-7-1"></span>[2] BLAZQUEZ ´ -GARC´IA, A., CONDE, A., MORI, U.,
    AND LOZANO, J. A. A review on outlier/anomaly detection in time series data. *ACM
    Computing Surveys (CSUR) 54*, 3 (2021), 1–33.

    - <span id="page-7-3"></span>[3] BUCKERIDGE, D. L., BURKOM, H., CAMPBELL, M.,
    HOGAN, W. R., MOORE, A. W., ET AL. Algorithms for rapid outbreak detection: a
    research synthesis. *Journal of biomedical informatics 38*, 2 (2005), 99–113.

    - <span id="page-7-5"></span>[4] BURKOM, H. S., LOSCHEN, W. A., WOJCIK, R. A.,
    HOLTRY, R. S., PUNJABI, M. A., SIWEK, M. M., AND LEWIS, S. H. Essence, the electronic
    surveillance system for the early notification of communitybased epidemics. *medRxiv*
    (2020), 2020–08.

    - <span id="page-7-0"></span>[5] CDC. Introduction to public health surveillance.
    [https://www.cdc.gov/training/publichealth101/](https://www.cdc.gov/training/publichealth101/surveillance.html)
    [surveillance.html,](https://www.cdc.gov/training/publichealth101/surveillance.html)
    09 2018. Accessed: 2023-06-05.

    - <span id="page-7-2"></span>[6] COOK, A., MISIRLI, G., AND FAN, Z. Anomaly detection
    for iot time-series data: A survey. *IEEE Internet of Things Journal 7*, 7 (2019),
    6481–6494.

    - <span id="page-8-22"></span>[7] DIETVORST, B. J., SIMMONS, J. P., AND MASSEY,
    C. Algorithm aversion: people erroneously avoid algorithms after seeing them err.
    *Journal of Experimental Psychology: General 144*, 1 (2015), 114.

    - <span id="page-8-17"></span>[8] DU, M., LI, F., ZHENG, G., AND SRIKUMAR, V.
    Deeplog: Anomaly detection and diagnosis from system logs through deep learning.
    In *Proceedings of the 2017 ACM SIGSAC conference on computer and communications
    security* (2017), pp. 1285–1298.

    - <span id="page-8-12"></span>[9] GOMES, M. I., AND GUILLOU, A. Extreme value
    theory and statistics of univariate extremes: a review. *International statistical
    review 83*, 2 (2015), 263–292.

    - <span id="page-8-8"></span>[10] GOTTWALT, F., CHANG, E., AND DILLON, T. Corrcorr:
    A feature selection method for multivariate correlation network anomaly detection
    techniques. *Computers & Security 83* (2019), 234–245.

    - <span id="page-8-19"></span>[11] GUPTA, M., GAO, J., AGGARWAL, C. C., AND HAN,
    J. Outlier detection for temporal data: A survey. *IEEE Transactions on Knowledge
    and data Engineering 26*, 9 (2013), 2250–2267.

    - <span id="page-8-2"></span>[12] HEALTHCARE, D. Hospital referral regions. [https:](https://www.definitivehc.com/resources/glossary/hospital-referral-region)
    [//www.definitivehc.com/resources/glossary/hospital](https://www.definitivehc.com/resources/glossary/hospital-referral-region)[referral-region,](https://www.definitivehc.com/resources/glossary/hospital-referral-region)
    2023.

    - <span id="page-8-3"></span>[13] HHS. Hhs regional offices. [https://www.hhs.gov/](https://www.hhs.gov/about/agencies/iea/regional-offices/index.html)
    [about/agencies/iea/regional-offices/index.html,](https://www.hhs.gov/about/agencies/iea/regional-offices/index.html)
    2023.

    - <span id="page-8-5"></span>[14] HUNDMAN, K., CONSTANTINOU, V., LAPORTE, C.,
    COLWELL, I., AND SODERSTROM, T. Detecting spacecraft anomalies using lstms and
    nonparametric dynamic thresholding. In *Proceedings of the 24th ACM SIGKDD international
    conference on knowledge discovery & data mining* (2018), pp. 387–395.

    - <span id="page-8-7"></span>[15] JADIDI, Z., PAL, S., HUSSAIN, M., AND NGUYEN
    THANH, K. Correlation-based anomaly detection in industrial control systems. *Sensors
    23*, 3 (2023), 1561.

    - <span id="page-8-6"></span>[16] JIN, Y., QIU, C., SUN, L., PENG, X., AND ZHOU,
    J. Anomaly detection in time series via robust pca. In *2017 2nd IEEE International
    Conference on Intelligent Transportation Engineering (ICITE)* (2017), IEEE, pp.
    352–355.

    - <span id="page-8-11"></span>[17] JOSHI, A., MAZAITIS, K., ROSENFELD, R., AND
    WILDER, B. Computationally assisted quality control for public health data streams.
    *arXiv preprint arXiv:2306.16914* (2023).

    - <span id="page-8-16"></span>[18] JOSHI, A., WILDER, B., AND ROSENFELD, R. Large
    scale population-level outliers detection in public health data.

    - <span id="page-8-0"></span>[19] KRAEMER, M. U., SCARPINO, S. V., MARIVATE, V.,
    GUTIERREZ, B., XU, B., LEE, G., HAWKINS, J. B., RIVERS, C., PIGOTT, D. M., KATZ,
    R., ET AL. Data curation during a pandemic and lessons learned from covid-19.
    *Nature Computational Science 1*, 1 (2021), 9–10.

    - <span id="page-8-9"></span>[20] KULLDORFF, M., HEFFERNAN, R., HARTMAN, J., ASSUNC¸
    AO, R., AND MOSTASHARI, F. A space–time permutation scan statistic for disease
    outbreak detection. *PLoS medicine 2*, 3 (2005), e59.

    - <span id="page-8-10"></span>[21] LAI, K.-H., ZHA, D., WANG, G., XU, J., ZHAO,
    Y., KUMAR, D., CHEN, Y., ZUMKHAWAKA, P., WAN, M., MARTINEZ, D., AND HU, X. Tods:
    An automated time series outlier detection system. *Proceedings of the AAAI Conference
    on Artificial Intelligence 35*, 18 (May 2021), 16060–16062.

    - <span id="page-8-20"></span>[22] LAI, K.-H., ZHA, D., XU, J., ZHAO, Y., WANG,
    G., AND HU, X. Revisiting time series outlier detection: Definitions and benchmarks.
    In *Thirty-fifth conference on neural information processing systems datasets
    and benchmarks track* (2021).

    - <span id="page-8-15"></span>[23] LILIENTHAL, J., ZANGER, L., BUCHER ¨ , A.,
    AND FRIED, R. A note on statistical tests for homogeneities in multivariate extreme
    value models for block maxima. *Environmetrics 33*, 7 (2022), e2746.

    - <span id="page-8-18"></span>[24] LIU, F. T., TING, K. M., AND ZHOU, Z.-H. Isolation
    forest. In *2008 eighth ieee international conference on data mining* (2008),
    IEEE, pp. 413–422.

    - <span id="page-8-21"></span>[25] PAVAO, A. ranky. [https://github.com/didayolo/ranky,](https://github.com/didayolo/ranky)
    2020.

    - <span id="page-8-4"></span>[26] RABANSER, S., JANUSCHOWSKI, T., RASUL, K., BORCHERT,
    O., KURLE, R., GASTHAUS, J., BOHLKE-SCHNEIDER, M., PAPERNOT, N., AND FLUNKERT,
    V. Intrinsic anomaly detection for multivariate time series. *arXiv preprint arXiv:2206.14342*
    (2022).

    - <span id="page-8-1"></span>[27] REINHART, A., BROOKS, L., JAHJA, M., RUMACK,
    A., TANG, J., AGRAWAL, S., AL SAEED, W., ARNOLD, T., BASU, A., BIEN, J., ET AL.
    An open repository of real-time covid-19 indicators. *Proceedings of the National
    Academy of Sciences 118*, 51 (2021), e2111452118.

    - <span id="page-8-13"></span>[28] RIEDER, H. E. Extreme value theory: A primer.
    *Lamont-Doherty Earth Observatory* (2014).

    - <span id="page-8-14"></span>[29] SARMADI, H., AND YUEN, K.-V. Structural health
    monitoring by a novel probabilistic machine learning method based on extreme value
    theory and mixture quantile modeling. *Mechanical Systems and Signal Processing
    173* (2022), 109049.

    - <span id="page-9-1"></span>[30] UN. United nationals global issues: Big data
    for sustainable development. [https://www.un.org/en/global](https://www.un.org/en/global-issues/big-data-for-sustainable-development)[issues/big-data-for-sustainable-development,](https://www.un.org/en/global-issues/big-data-for-sustainable-development)
    2021.

    - <span id="page-9-0"></span>[31] WHO. Surveillence in emergencies. [https://www.who.](https://www.who.int/emergencies/surveillance)
    [int/emergencies/surveillance,](https://www.who.int/emergencies/surveillance)
    2022.

    - <span id="page-9-2"></span>[32] WHO. Who hub for pandemic and epidemic intelligence.
    [https://pandemichub.who.int/publications/](https://pandemichub.who.int/publications/m/item/the-who-hub-for-pandemic-and-epidemic-intelligence-strategy-paper)
    [m/item/the-who-hub-for-pandemic-and-epidemic](https://pandemichub.who.int/publications/m/item/the-who-hub-for-pandemic-and-epidemic-intelligence-strategy-paper)[intelligence-strategy-paper,](https://pandemichub.who.int/publications/m/item/the-who-hub-for-pandemic-and-epidemic-intelligence-strategy-paper)
    Dec. 2022.

    - <span id="page-9-3"></span>[33] WHO. Who hub for pandemic and epidemic intelligence.
    [https://www.who.int/initiatives/preparedness](https://www.who.int/initiatives/preparedness-and-resilience-for-emerging-threats)[and-resilience-for-emerging-threats,](https://www.who.int/initiatives/preparedness-and-resilience-for-emerging-threats)
    Mar. 2023.

    - <span id="page-9-8"></span>[34] WONG, W.-K. *Data mining for early disease outbreak
    detection*. Carnegie Mellon University, 2004.

    - <span id="page-9-5"></span>[35] WONG, W.-K., MOORE, A., COOPER, G., AND WAGNER,
    M. What''s strange about recent events (wsare): an algorithm for the early detection
    of disease outbreaks. *The Journal of Machine Learning Research 6* (2005), 1961–1998.

    - <span id="page-9-7"></span>[36] WU, R., AND KEOGH, E. Current time series anomaly
    detection benchmarks are flawed and are creating the illusion of progress. *IEEE
    Transactions on Knowledge and Data Engineering* (2021).

    - <span id="page-9-4"></span>[37] ZAN, X., WANG, D., AND XIAN, X. Spatial rankbased
    augmentation for nonparametric online monitoring and adaptive sampling of big
    data streams. *Technometrics 65*, 2 (2023), 243–256.

    - <span id="page-9-6"></span>[38] ZHANG, Z. On studying extreme values and systematic
    risks with nonlinear time series models and tail dependence measures. *Statistical
    Theory and Related Fields 5*, 1 (2021), 1–25.'
  decisions:
    evaluation_prompt: 'Qualified. Reason: The abstract mentions a "human-expert evaluation"
      and states that the proposed algorithm "performed the best across traditional
      outlier detection metrics," indicating structured evaluation through empirical
      assessment.'
    related_work_prompt: 'Disqualified: no related work. Reason: The abstract and
      introduction do not mention or reference any prior research, methods, or findings
      related to outlier detection or public health data streams. There is no engagement
      with existing literature or comparison to previous work.'
    novelty_prompt: 'Qualified. Reason: The abstract explicitly states the proposal
      of a new task for ranking outputs of univariate methods and introduces a novel
      algorithm that leverages hierarchical networks and extreme value analysis, indicating
      clear contributions to the field.'
    review_only_prompt: '- Qualified. Reason: The abstract describes a novel algorithm
      and its implementation, indicating new contributions to the field rather than
      merely summarizing existing work.'
  llm_input_used: '## Abstract

    Disease control experts inspect public health data streams daily for outliers

    worth investigating, like those corresponding to data quality issues or disease

    outbreaks. However, they can only examine a few of the thousands of

    maximally-tied outliers returned by univariate outlier detection methods

    applied to large-scale public health data streams. To help experts distinguish

    the most important outliers from these thousands of tied outliers, we propose
    a

    new task for algorithms to rank the outputs of any univariate method applied to

    each of many streams. Our novel algorithm for this task, which leverages

    hierarchical networks and extreme value analysis, performed the best across

    traditional outlier detection metrics in a human-expert evaluation using public

    health data streams. Most importantly, experts have used our open-source Python

    implementation since April 2023 and report identifying outliers worth

    investigating 9.1x faster than their prior baseline. Other organizations can

    readily adapt this implementation to create rankings from the outputs of their

    tailored univariate methods across large-scale streams.


    '
  token_usage: 1927
  time_usage: 5.962900400161743
- title: "On the Prospects of Incorporating Large Language Models (LLMs) in\n  Automated\
    \ Planning and Scheduling (APS)"
  abstract: 'Automated Planning and Scheduling is among the growing areas in Artificial

    Intelligence (AI) where mention of LLMs has gained popularity. Based on a

    comprehensive review of 126 papers, this paper investigates eight categories

    based on the unique applications of LLMs in addressing various aspects of

    planning problems: language translation, plan generation, model construction,

    multi-agent planning, interactive planning, heuristics optimization, tool

    integration, and brain-inspired planning. For each category, we articulate the

    issues considered and existing gaps. A critical insight resulting from our

    review is that the true potential of LLMs unfolds when they are integrated with

    traditional symbolic planners, pointing towards a promising neuro-symbolic

    approach. This approach effectively combines the generative aspects of LLMs

    with the precision of classical planning methods. By synthesizing insights from

    existing literature, we underline the potential of this integration to address

    complex planning challenges. Our goal is to encourage the ICAPS community to

    recognize the complementary strengths of LLMs and symbolic planners, advocating

    for a direction in automated planning that leverages these synergistic

    capabilities to develop more advanced and intelligent planning systems.'
  url: http://arxiv.org/abs/2401.02500v2
  keywords: ''
  document: '# On the Prospects of Incorporating Large Language Models (LLMs) in Automated
    Planning and Scheduling (APS)


    Vishal Pallagani<sup>1</sup> , Kaushik Roy<sup>1</sup> , Bharath Muppasani<sup>1</sup>
    , Francesco Fabiano<sup>2</sup> , Andrea Loreggia<sup>3</sup> , Keerthiram Murugesan<sup>4</sup>
    , Biplav Srivastava<sup>1</sup> , Francesca Rossi<sup>4</sup> , Lior Horesh<sup>4</sup>
    , Amit Sheth<sup>1</sup>


    > <sup>1</sup>University of South Carolina <sup>2</sup>New Mexico State University
    <sup>3</sup>University of Brescia 4 IBM Research


    #### Abstract


    Automated Planning and Scheduling is among the growing areas in Artificial Intelligence
    (AI) where mention of LLMs has gained popularity. Based on a comprehensive review
    of 126 papers, this paper investigates eight categories based on the unique applications
    of LLMs in addressing various aspects of planning problems: language translation,
    plan generation, model construction, multi-agent planning, interactive planning,
    heuristics optimization, tool integration, and braininspired planning. For each
    category, we articulate the issues considered and existing gaps. A critical insight
    resulting from our review is that the true potential of LLMs unfolds when they
    are integrated with traditional symbolic planners, pointing towards a promising
    neuro-symbolic approach. This approach effectively combines the generative aspects
    of LLMs with the precision of classical planning methods. By synthesizing insights
    from existing literature, we underline the potential of this integration to address
    complex planning challenges. Our goal is to encourage the ICAPS community to recognize
    the complementary strengths of LLMs and symbolic planners, advocating for a direction
    in automated planning that leverages these synergistic capabilities to develop
    more advanced and intelligent planning systems.


    # Introduction


    As a sub-field of Artificial Intelligence (Russell and Norvig 2003), Automated
    Planning and Scheduling (Ghallab, Nau, and Traverso 2004) refers to developing
    algorithms and systems to generate plans or sequences of actions to achieve specific
    goals in a given environment or problem domain. APS is a valuable tool in domains
    where there is a need for intelligent decision-making, goal achievement, and efficient
    resource utilization. It enables the automation of complex tasks, making systems
    more capable and adaptable in dynamic environments. Over time, APS has evolved
    from the early development of robust theoretical foundations to practical applications
    in diverse sectors like manufacturing, space exploration, and personal scheduling.
    This evolution underscores the versatility and critical significance of APS.


    In parallel with advancements in APS, the development and proliferation of LLMs
    have marked a substantial leap in AI, particularly within computational linguistics.
    Evolving from early efforts in natural language processing (NLP), LLMs have undergone
    significant transformation. Initially focused on basic tasks like word prediction
    and syntax analysis, newer models are characterized by their ability to generate
    coherent, contextually relevant text and perform diverse, complex linguistic tasks.
    Trained on extensive text corpora, LLMs have mastered human-like language patterns.
    Their recent success in various NLP tasks has prompted efforts to apply these
    models in APS. There is a notable shift towards using language constructs to specify
    aspects of planning, such as preconditions, effects, and goals, rather than relying
    solely on traditional planning domain languages like PDDL.


    This paper presents an exhaustive literature review exploring the integration
    of LLMs in APS across eight categories: Language Translation, Plan Generation,
    Model Construction, Multi-agent Planning, Interactive Planning, Heuristics Optimization,
    Brain-Inspired Planning, and Tool Integration. Table 1 provides the description
    for the eight categories. Our comprehensive analysis of 126 papers not only categorizes
    LLMs'' diverse contributions but also identifies significant gaps in each domain.
    Through our review, we put forward the following position:


    #### Position Statement


    Integrating LLMs into APS marks a pivotal advancement, bridging the gap between
    the advanced reasoning of traditional APS and the nuanced language understanding
    of LLMs. Traditional APS systems excel in structured, logical planning but often
    lack flexibility and contextual adaptability, a gap readily filled by LLMs. Conversely,
    while LLMs offer unparalleled natural language processing and a vast knowledge
    base, they fail to generate precise, actionable plans where APS systems thrive.
    This integration surpasses the limitations of each standalone method, offering
    a dynamic and context-aware planning approach, while also scaling up the traditional
    use of data and past experiences in the planning process.


    In the forthcoming sections, we delve into the background of LLMs and classical
    planning problem, accompanied by the identification of literature. This sets the
    stage for an indepth exploration of the application of LLMs in APS, where we critically
    examine the strengths and limitations of LLMs. Our position on the emerging neuro-symbolic
    AI paradigm


    | Category                | Description                                                                                                                                                                                                               |

    |-------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|

    | Language Translation    | Involves converting natural language into structured
    planning languages or formats like PDDL and<br>vice-versa, enhancing the interface
    between human linguistic input and machine-understandable<br>planning directives.
    |

    | Plan Generation         | Entails the creation of plans or strategies directly
    by LLMs, focusing on generating actionable se<br>quences or decision-making processes.                                                                               |

    | Model Construction      | Utilizes LLMs to construct or refine world and domain
    models essential for accurate and effective<br>planning.                                                                                                            |

    | Multi-agent Planning    | Focuses on scenarios involving multiple agents, where
    LLMs contribute to coordination and coop<br>erative strategy development.                                                                                           |

    | Interactive Planning    | Centers on scenarios requiring iterative feedback
    or interactive planning with users, external veri<br>fiers, or environment, emphasizing
    the adaptability of LLMs to dynamic inputs.                                     |

    | Heuristics Optimization | Applies LLMs in optimizing planning processes through
    refining existing plans or providing heuris<br>tic assistance to symbolic planners.                                                                                 |

    | Tool Integration        | Encompasses studies where LLMs act as central orchestrators
    or coordinators in a tool ecosystem,<br>interfacing with planners, theorem provers,
    and other systems.                                                        |

    | Brain-Inspired Planning | Covers research focusing on LLM architectures inspired
    by neurological or cognitive processes,<br>particularly to enhance planning capabilities.                                                                          |


    Table 1: Comprehensive description of the eight categories utilizing LLMs in APS


    is central to our discussion, highlighting its unique advantages over purely neural
    network-based (i.e., statistical AI) or symbolic AI approaches. Finally, we will
    discuss prospective developments, address potential challenges, and identify promising
    opportunities in the field.


    # Background


    ### Large Language Models


    Large language models are neural network models with upwards of ∼ 3 billion parameters
    that are trained on extremely large corpora of natural language data (trillions
    of tokens/ words). These models are proficient in interpreting, generating, and
    contextualizing human language, leading to applications ranging from text generation
    to language-driven reasoning tasks. The evolution of LLMs in NLP began with rule-based
    models, progressed through statistical models, and achieved a significant breakthrough
    with the introduction of neural network-based models. The shift to sequencebased
    neural networks, with Recurrent Neural Networks (RNNs) and Long Short-Term Memory
    (LSTM) networks, marked a notable advancement due to their capability to process
    information and context over long sequences. Shortcomings in RNNs and LSTMs due
    to vanishing gradients and, consequently, loss of *very long* sequence contexts
    lead to the transformer model, which introduced self-attention (SA) mechanisms.
    The SA mechanism enabled focus on different parts of a long input sequence in
    parallel, which enhanced understanding of contextual nuances in language patterns
    over extremely long sequences. The SA mechanism is also complemented with positional
    encodings in transformers to enable the model to maintain an awareness of word/token
    order, which is required to understand accurate grammar and syntax. The self-attention
    mechanism, central to transformers, uses a query, key, and value system to contextualize
    dependencies in the input sequence. Informally, the SA concept is inspired by
    classical information retrieval systems where the query is the input sequence
    context, the key refers to a "database" contained within the parametric memory,
    and the value is the actual value present at that reference. The operation is
    mathematically expressed in Equation 1.


    $$\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d\_k}}\right)V
    \qquad (\text{l)}$$


    In this equation, Q, K, and V denote the query, key, and value matrices. The scaling
    factor <sup>√</sup> dk, where d<sup>k</sup> is the dimension of the keys, is employed
    to standardize the vectors to unit variance for ensuring stable softmax gradients
    during training. Since the introduction of LLMs with self-attention, there have
    been several architectural variants depending on the downstream tasks.


    Causal Language Modeling (CLMs): CLMs, such as GPT-4, are designed for tasks where
    text generation is sequential and dependent on the preceding context. They predict
    each subsequent word based on the preceding words, modeling the probability of
    a word sequence in a forward direction. This process is mathematically formulated
    as shown in Equation 2.


    $$P(T) = \prod\_{i=1}^{n} P(t\_i | t\_{$$


    In this formulation, P(t<sup>i</sup> |t<i) represents the probability of the i-th
    token given all preceding tokens, t<i. This characteristic makes CLMs particularly
    suitable for applications like content generation, where the flow and coherence
    of the text in the forward direction are crucial.


    Masked Language Modeling (MLMs): Unlike CLMs, MLMs like BERT are trained to understand
    the bidirectional context by predicting words randomly masked in a sentence. This
    approach allows the model to learn both forward and backward dependencies in language
    structure. The MLM prediction process can be represented as Equation 3.


    $$P(T\_{\text{masked}} | T\_{\text{context}}) = \prod\_{i \in M} P(t\_i | T\_{\text{context}})
    \qquad (3)$$


    Here, Tmasked is the set of masked tokens in the sentence, Tcontext represents
    the unmasked part of the sentence, and M is the set of masked positions. MLMs
    have proven effective in NLP tasks such as sentiment analysis or question answering.


    Sequence-to-Sequence (Seq2Seq) Modeling: Seq2Seq models, like T5, are designed
    to transform an input sequence into a related output sequence. They are often
    employed in tasks that require a mapping between different types of sequences,
    such as language translation or summarization. The Seq2Seq process is formulated
    as Equation 4.


    $$P(T\_{\text{output}}|T\_{\text{input}}) = \prod\_{i=1}^{m} P(t\_{\text{output}\_i}|T\_{\text{input}},
    t\_{\text{output}\_{$$


    In Equation 4, Tinput is the input sequence, Toutput is the output sequence, and
    P(toutput<sup>i</sup> |Tinput, toutput<i ) calculates the probability of generating
    each token in the output sequence, considering both the input sequence and the
    preceding tokens in the output sequence.


    In addition to their architectural variants, the utility of LLMs is further enhanced
    by specific model utilization strategies, enabling their effective adaptation
    to various domains at scale. One key strategy is fine-tuning, which applies to
    pre-trained LLMs. Pre-trained LLMs are models already trained on large datasets
    to understand and generate language, acquiring a broad linguistic knowledge base.
    Fine-tuning involves further training pre-trained LLMs on a smaller, task-specific
    dataset, thereby adjusting the neural network weights for particular applications.
    This process is mathematically represented in Equation 5.


    $$\theta\_{\text{fine-tuned}} = \theta\_{\text{pre-trained}} - \eta \cdot \nabla\_{\theta}
    L(\theta, D\_{\text{task}}) \qquad (5)$$


    Here, θfine-tuned are the model parameters after fine-tuning, θpre-trained are
    the parameters obtained from pre-training, η is the learning rate, and ∇θL(θ,
    Dtask) denotes the gradient of the loss function L with respect to the parameters
    θ on the task-specific dataset Dtask.


    $$P(T|C) = \prod\_{i=1}^{n} P(t\_i | t\_{$$


    Complementing the fine-tuning approach is in-context learning, an alternative
    strategy that is particularly characteristic of models like the GPT series. This
    method diverges from fine-tuning by enabling the model to adapt its responses
    based on immediate context or prompts without necessitating further training.
    The efficacy of in-context learning is a direct consequence of the comprehensive
    pretraining phase, where models are exposed to diverse textual datasets, thereby
    acquiring a nuanced understanding of language and context. Given a context C,
    the model generates text T that is contextually relevant, as shown in Equation
    6. Here, P(T|C) is the probability of generating text T given the context C, and
    P(t<sup>i</sup> |t<i, C) is the probability of generating the i-th token t<sup>i</sup>
    given the preceding tokens t<i and the context C.


    ![](_page_2_Figure_13.jpeg)


    Figure 1: Radar chart showcasing the relative performance of six language models
    (GPT-4, Claude-v1, GPT-3.5-turbo, Vicuna-13B, Alpaca-13B, LLama-13B) across key
    domains: Writing, Roleplay, Reasoning, Math, Coding, Extraction, STEM, and Humanities
    from Zheng et al. (2023a).


    These diverse model types and training methodologies under the umbrella of LLMs
    showcase the flexibility and adaptability of language models in handling a wide
    range of complex tasks. Figure 1 illustrates the comparative capabilities of different
    LLMs across various competency domains, such as Writing (evaluating text generation
    quality), Roleplay (assessing conversational interaction), Reasoning (logical
    problem-solving), Math (numerical problem-solving), Coding (programming language
    understanding and generation), Extraction (information retrieval from text), STEM
    (proficiency in scientific and technical contexts), and Humanities (engagement
    with arts, history, and social sciences content). Across these domains, GPT-4
    exhibits the strongest performance in the benchmark dataset evaluated by Zheng
    et al. (2023a), indicative of its superior training and extensive knowledge base.
    Expanding LLMs into applications such as code generation signifies their adaptability
    and potential for cross-disciplinary innovation. However, fine-tuning and in-context
    learning methodologies also bring challenges, such as potential data overfitting
    and reliance on the quality of input context. LLMs'' continuous development and
    refinement promise to open new frontiers in various domains, including automated
    planning and scheduling, by bridging AI with human-like language understanding.


    ### Automated Planning and Scheduling


    APS is a branch of AI that focuses on the creation of strategies or action sequences,
    typically for execution by intelligent agents, autonomous robots, and unmanned
    ve-


    ![](_page_3_Figure_0.jpeg)


    Figure 2: Of the 126 papers surveyed in this study, 55 were accepted by peer-reviewed
    conferences. This chart illustrates the distribution of these papers across various
    conferences in the fields of LLMs and APS, highlighting the primary forums for
    scholarly contributions in these areas.


    hicles. A basic category in APS is a Classical Planning Problem (CPP) (Russell
    and Norvig 2003) which is a tuple M = ⟨D, I, G⟩ with domain D = ⟨F, A⟩ - where
    F is a set of fluents that define a state s ⊆ F, and A is a set of actions - and
    initial and goal states I, G ⊆ F. Action a ∈ A is a tuple (ca, *pre*(a), *eff*<sup>±</sup>(a))
    where c<sup>a</sup> is the cost, and *pre*(a), *eff*<sup>±</sup>(a) ⊆ F are the
    preconditions and add/delete effects, i.e., δM(s, a) |= ⊥s *if* s ̸|= *pre*(a);
    *else* δM(s, a) |= s ∪ eff<sup>+</sup>(a) \ eff<sup>−</sup>(a) where δM(·) is
    the transition function. The cumulative transition function is δM(s,(a1, a2, .
    . . , an)) = δM(δM(s, a1),(a2, . . . , an)). A plan for a CPP is a sequence of
    actions ⟨a1, a2, . . . , an⟩ that transforms the initial state I into the goal
    state G using the transition function δM. Traditionally, a CPP is encoded using
    a symbolic representation, where states, actions, and transitions are explicitly
    enumerated. This symbolic approach, often implemented using Planning Domain Definition
    Language or PDDL (McDermott et al. 1998), ensures precise and unambiguous descriptions
    of planning problems. This formalism allows for applying search algorithms and
    heuristic methods to find a sequence of actions that lead to the goal state, which
    is the essence of the plan.


    The advent of LLMs has sparked a significant evolution in representation methods
    for CPPs, moving towards leveraging the expressive power of natural language (Valmeekam
    et al. 2023a) and the perceptual capabilities of vision (Asai 2018). These novel
    approaches, inherently more suited for LLM processing, use text and vision-based
    representations, allowing researchers to utilize the pre-existing knowledge within
    LLMs. This shift enables a more humanistic comprehension and reasoning about planning
    tasks, enhancing the flexibility and applicability of planning algorithms in complex,
    dynamic environments. LLMs, while distinct in being trained on vast datasets outside
    the traditional scope of planning, loosely connect to previous data-driven methodologies,
    such as case-based reasoning (Xu 1995) applied to planning and Hierarchical Task
    Network (HTN) (Georgievski and Aiello 2015) which make use of task knowledge.
    It is an open area how LLMs may be used synergestically with prior methods.


    ### LLMs in APS – Literature selection


    A comprehensive survey of existing literature was conducted to explore the application
    of LLMs for automated planning. This endeavor led to identifying 126 pertinent
    research papers showcasing various methodologies, applications, and theoretical
    insights into utilizing LLMs within this domain.


    The selection of these papers was guided by stringent criteria, focusing primarily
    on their relevance to the core theme of LLMs in automated planning. The search,
    conducted across multiple academic databases and journals, was steered by keywords
    such as "Large Language Models", "Automated Planning", "LLMs in Planning", and
    "LLMs + Robotics". Figure 2 presents the distribution of these selected papers
    across various peer-reviewed conferences, underlining the breadth and diversity
    of forums addressing the intersection of LLMs and APS. Even if a paper originated
    from a workshop within a conference, only the conference name is listed. Out of
    126 papers, 71 are under review or available on arXiv. The inclusion criteria
    prioritized the relevance and contribution of papers to automated planning with
    LLMs over the publication date. Nonetheless, all surveyed papers emerged from
    either 2022 or 2023, a trend depicted in Figure 3, underscoring the recent surge
    in LLM research. A word cloud was generated to visually capture the prevalent
    research themes reflected in these papers'' titles, illustrated in Figure 4. This
    cloud highlights the frequent use of terms such as "Language Model" and "Planning",
    which dominate the current discourse. In contrast, the emergence of "Neuro-Symbolic"
    reflects a nascent yet growing interest in integrating neural and symbolic approaches
    within the field. This systematic approach ensured a comprehensive inclusion of
    seminal works and recent advancements.


    Upon the accumulation of these papers, a meticulous manual categorization was
    undertaken. The papers were divided into four piles, each containing approximately
    30 papers. Each pile was manually categorized by one author,


    ![](_page_4_Figure_0.jpeg)


    Figure 3: Annual distribution of the 126 surveyed papers, indicating a significant
    increase in publications from 12 in 2022 to 114 in 2023, highlighting the rapid
    growth of LLM research within a single year.


    with the final categorization being reviewed by all authors. During this process,
    each paper could belong to multiple categories out of the eight established. The
    maximum number of categories assigned to a single paper was three, although the
    median was typically one category per paper. This process was pivotal in distilling
    the vast information into coherent, thematic groups. The categorization was conducted
    based on the specific application of LLMs in planning. This formed eight distinct
    categories, each representing a unique facet of LLM application in automated planning.
    These categories facilitate a structured analysis and highlight LLMs'' diverse
    applications and theoretical underpinnings in this field.


    ![](_page_4_Figure_3.jpeg)


    Figure 4: Word cloud of terms from the titles of papers surveyed in this study,
    displaying the prevalence of "Language Model" and "Planning" as central themes.
    The presence of "Neuro-Symbolic" indicates an emergent trend toward the fusion
    of neural and symbolic methodologies in the domain.


    # LLMs in APS – Literature Discussion


    This section dwelves into the diverse applications of LLMs in planning tasks.
    We have identified eight distinct categories based on the utility and application
    of LLMs in planning, which are concisely summarized in Table 1. Figure 5 provides
    a detailed taxonomy, illustrating the categorization of the identified research
    papers.


    ### Language Translation


    Language translation in the context of LLMs and planning involves transforming
    natural language instructions into structured planning languages (Wong et al.
    2023; Kelly et al. 2023; Yang 2023; Pan et al. 2023; Xie et al. 2023; Yang, Ishay,
    and Lee 2023; Lin et al. 2023c; Sakib and Sun 2023; Yang et al. 2023b; Parakh
    et al. 2023; Yang et al. 2023a; Dai et al. 2023; Ding et al. 2023b; Zelikman et
    al. 2023; Xu et al. 2023b; Chen et al. 2023a; You et al. 2023) such as PDDL, and
    vice versa, utilizing in-context learning techniques (Guan et al. 2023). This
    capability effectively bridges the gap between human linguistic expression and
    machine-understandable formats, enhancing intuitive and efficient planning processes.
    The LLM+P framework (Liu et al. 2023) exemplifies this by converting natural language
    descriptions of planning problems into PDDL using GPT-4, leveraging classical
    planners for solution finding, and then translating these solutions back into
    natural language, with a specific focus on robot planning scenarios. Additionally,
    Graph2NL (Chalvatzaki et al. 2023) generates natural language text from scene
    graphs for long-horizon robot reasoning tasks, while (Shirai et al. 2023) introduces
    a vision-to-language interpreter for robot task planning. Further, (Brohan et
    al. 2023) examines the grounding of LLMgenerated natural language utterances in
    actionable robot tasks, and (Yang, Gaglione, and Topcu 2022) utilizes LLMs for
    creating finite-state automatons for sequential decisionmaking problems. Despite
    these advancements, a critical research gap emerges in the autonomous translation
    capabilities of LLMs, particularly in converting natural language to PDDL without
    external expert intervention.


    While LLMs effectively translate PDDL to natural language, a notable gap is evident
    in their limited understanding of real-world objects and the problem of grounding
    affordances, mainly when translating natural language to structured languages
    like PDDL. Addressing this gap calls for integrating neuro-symbolic approaches
    in LLMs, where the fusion of perceptual experience for concrete concept understanding
    from knowledge graphs complements LLMs'' proficiency in distributional statistics
    (Lenat and Marcus 2023).


    ### Plan Generation


    This category focuses on directly generating plans using LLMs. The research, primarily
    utilizing causal language models through in-context learning (Sermanet et al.
    2023; Li et al. 2023b; Silver et al. 2023; Parakh et al. 2023; Zelikman et al.
    2023; Besta et al. 2023; Huang et al. 2023a; Dalal et al. 2023; Wang et al. 2023b;
    Valmeekam et al. 2022; Valmeekam, Marquez, and Kambhampati 2023; Gramopadhye and
    Szafir 2022; Singh et al. 2023)<sup>1</sup> , demonstrates modest performance,
    indicating notable challenges in employing LLMs for effective plan generation.
    Novel in-context learning strategies, such as the Chain-of-Symbol and Tree of
    Thoughts, have been introduced to enhance LLMs'' reasoning capabilities (Hu et
    al. 2023b; Yao et al. 2023). Ef-


    <sup>1</sup>Due to space constraints, only a select number of papers are cited
    in this section.


    ![](_page_5_Figure_0.jpeg)


    Figure 5: Taxonomy of recent research in the intersection of LLMs and Planning
    into categories (#). Each has scholarly papers based on their unique application
    or customization of LLMs in addressing various aspects of planning problems.


    forts to generate multimodal, text, and image-based goalconditioned plans are
    exemplified by (Lu et al. 2023b). Additionally, a subset of studies in this survey
    investigates the fine-tuning of seq2seq, code-based language models (Pallagani
    et al. 2022, 2023b), which are noted for their advanced syntactic encoding. These
    models show promise in improving plan generation within the confines of their
    training datasets (Logeswaran et al. 2023), yet exhibit limitations in generalizing
    to out-of-distribution domains (Pallagani et al. 2023a), highlighting a gap in
    their adaptability across diverse planning contexts.


    Causal LLMs are predominantly used for plan generation, but their performance
    is often limited due to their design, which is focused on generating text based
    on preceding input. On the other hand, seq2seq LLMs can generate valid plans but
    struggle with generalization across diverse domains. This limitation highlights
    an opportunity for a synergistic approach: integrating even imperfect LLM outputs
    with symbolic planners can expedite heuristic searches, thereby enhancing efficiency
    and reducing search times (Fabiano et al. 2023).


    ## Model Construction


    This category employs LLMs to build or refine world and domain models essential
    for accurate planning. Nottingham et al. (2023); Yuan et al. (2023a) leverage
    in-context learning with LLMs to develop an abstract world model in the Minecraft
    domain, highlighting the challenge of semantic grounding in LLMs. Similarly, Gragera
    and Pozanco (2023) explore the capability of LLMs in completing ill-defined PDDL
    domains. Efforts such as (Huang et al. 2023a; Brohan et al. 2023) delve into LLMs''
    grounding capabilities, with SayCan (Brohan et al. 2023) notably achieving 74%
    executable plans. Hao et al. (2023a); Yoneda et al. (2023) innovatively positions
    LLMs as both world models and reasoning agents, enabling the simulation of world
    states and prediction of action outcomes. Research by (Zhang and Soh 2023; Wong
    et al. 2023; Mandi, Jain, and Song 2023; Hu et al. 2023a; Zhao, Lee, and Hsu 2023;
    Ding et al. 2023b; Huang et al. 2023a; Wu et al. 2023b; Xu et al. 2023b; Brohan
    et al. 2023) shows that LLMs can effectively model highlevel human states and
    behaviors using their commonsense knowledge. Yet, they face difficulties accurately
    processing low-level geometrical or shape features due to spatial and numerical
    reasoning constraints. Additionally, Kelly et al. (2023) investigates the potential
    of LLMs in conjunction with planners to craft narratives and logical story models,
    integrating human-in-the-loop for iterative edits.


    LLMs often struggle with detailed spatial reasoning and processing low-level environmental
    features, limiting their effectiveness in model construction. Integrating world
    models presents a viable solution, offering advanced abstractions for reasoning
    that encompass human-like cognitive elements and interactions, thereby enhancing
    LLMs'' capabilities in model construction (Hu and Shu 2023).


    ## Multi-agent Planning


    In multi-agent planning, LLMs play a vital role in scenarios involving interaction
    among multiple agents, typically modeled using distinct LLMs. These models enhance
    coordination and cooperation, leading to more complex and effective multi-agent
    strategies. (Zhang et al. 2023b) introduces an innovative framework that employs
    LLMs to develop cooperative embodied agents. AutoGraph (Wei et al. 2023) leverages
    LLMs to generate autonomous agents adept at devising solutions for varied graph-structured
    data problems. Addressing scalability in multi-robot task planning, (Chen et al.
    2023d) proposes frameworks for the collaborative function of different LLM-based
    agents. Furthermore, (Abdelnabi et al. 2023) and (Hua et al. 2023) collectively
    demonstrate the effectiveness of LLM agents in complex negotiation and decisionmaking
    environments.


    A key gap in multi-agent planning with LLMs lies in standardizing inter-agent
    communication and maintaining distinct belief states, including human aspects.
    Overcoming this requires advanced LLM algorithms for dynamic alignment of communication
    and belief states, drawing on epistemic reasoning and knowledge representation
    (de Zarza et al. 2023). `


    ### Interactive Planning


    In this category, LLMs are utilized in dynamic scenarios where real-time adaptability
    to user feedback or iterative planning is essential. The refinement of LLM outputs
    is typically achieved through four primary feedback variants: (a) External verifiers,
    such as VAL(Howey, Long, and Fox 2004) for PDDL or scene descriptors and success
    detectors in robotics (Guan et al. 2023; Arora and Kambhampati 2023; Jha et al.
    2023; Huang et al. 2022b; Liu, Bahety, and Song 2023; Rana et al. 2023; Ren et
    al. 2023; Kim et al. 2023; Graule and Isler 2023; Driess et al. 2023; Zheng et
    al. 2023b); (b) Online reinforcement learning, which progressively updates the
    LLM about environmental changes (Carta et al. 2023); (c) Self-refinement by LLMs,
    where they provide feedback on their own outputs (Zhou et al. 2023; Hu et al.
    2023c,b; Ding et al. 2023a; Sun et al. 2023; Naik et al. 2023); (d) Input from
    human experts (Raman et al. 2022; Wu, Ai, and Hsu 2023). Furthermore, (Chen et
    al. 2023b) introduces the "Action Before Action" method, enabling LLMs to proactively
    seek relevant information from external sources in natural language, thereby improving
    embodied decision-making in LLMs by 40%.


    A key gap in interactive planning with LLMs lies in harmonizing the "fast" neural
    processing of LLMs with "slow" symbolic reasoning, as manifested in feedback mechanisms.
    This integration is key to maintaining the neural speed of LLMs while effectively
    embedding the depth and precision of feedback, which is vital for accuracy in
    dynamic planning scenarios (Zhang et al. 2023a).


    ### Heuristics Optimization


    In the realm of Heuristics Optimization, LLMs are leveraged to enhance planning
    processes, either by refining existing plans or aiding symbolic planners with
    heuristic guidance. Studies like (Hazra, Martires, and De Raedt 2023; Hao et al.
    2023a; Dai et al. 2023; Feng et al. 2023) have effectively coupled LLMs with heuristic
    searches to identify optimal action sequences. Research by (Silver et al. 2022;
    Shah et al. 2023; Valmeekam et al. 2023b) reveals that LLMs'' outputs, even if
    partially correct, can provide valuable direction for symbolic planners such as
    LPG (Gerevini and Serina 2002), especially in problems beyond the LLMs'' solvable
    scope. Furthermore, (Raimondo et al. 2023) makes an intriguing observation that
    including workflows and action plans in LLM input prompts can notably enhance
    task-oriented dialogue generalization.


    This category marks significant progress towards realizing neuro-symbolic approaches
    in APS. Current methods emphasize plan validity, often at the expense of time
    efficiency. Future research should look at how to continually evolve LLMs for
    better plan generation, with its experience from complimenting symbolic planners
    (Du et al. 2023).


    ## Tool Integration


    In tool integration, LLMs serve as coordinators within a diverse array of planning
    tools, enhancing functionality in complex scenarios. Studies like (Xu et al. 2023a;
    Lu et al. 2023a; Shen et al. 2023; Hao et al. 2023b; Ge et al. 2023) demonstrate
    that incorporating tools such as web search engines, Python functions, and API
    endpoints enhances LLM reasoning abilities. However, (Ruan et al. 2023) notes
    a tendency for LLMs to over-rely on specific tools, potentially prolonging the
    planning process. (Li et al. 2023a) introduces a benchmark for tool-augmented
    LLMs. While typical approaches involve teaching LLMs tool usage via multiple prompts,
    (Hsieh et al. 2023) suggests that leveraging tool documentation offers improved
    planning capabilities, circumventing the need for extensive demonstrations.


    LLMs often hallucinate non-existent tools, overuse a single tool, and face scaling
    challenges with multiple tools. Overcoming these issues is key to enabling LLMs
    to effectively select and utilize various tools in complex planning scenarios
    (Elaraby et al. 2023).


    ### Brain-Inspired Planning


    This area explores neurologically and cognitively inspired architectures in LLMs
    (Webb et al. 2023; Sumers et al. 2023; Momennejad et al. 2023; Hu et al. 2023d;
    Lin et al. 2023a), aiming to replicate human-like planning in enhancing problem-solving.
    However, while these methods rely on in-context learning, they frequently encounter
    challenges such as hallucination and grounding, as previously discussed, and tend
    to be more computationally intensive than in-context learning alone.


    While LLMs attempt to mimic symbolic solvers through incontext learning for brain-inspired
    modules, this approach lacks adaptability and is a superficial understanding of
    complex cognitive processes. To overcome these issues, developing systems where
    neural and symbolic components are intrinsically intertwined is critical as it
    would accurately mirror human cognitive capabilities in planning (Fabiano et al.
    2023).


    # Discussion and Conclusion


    In this position paper, we comprehensively investigate the role of LLMs within
    the domain of APS, analyzing 126 scholarly articles across eight distinct categories.
    This extensive survey not only provides a detailed landscape of current LLM applications
    and their limitations but also highlights the volume of research in each category:
    Language Translation with 23 papers demonstrates LLMs'' proficiency, whereas Plan
    Generation, the most researched category with 53 papers, reveals their shortcomings
    in optimality, completeness, and correctness compared to traditional combinatorial
    planners. Our exploration extends to Model Construction (17 papers), which examines
    LLMs in developing planning models, and the relatively unexplored area of Multiagent
    Planning (4 papers). Interactive Planning is well represented with 21 papers,
    illustrating LLMs'' adaptability in feedback-centric scenarios. Despite being
    less researched, Heuristics Optimization and Tool Integration, each with 8 papers,
    provide valuable insights into efficiency enhancement and integration of LLMs
    with symbolic solvers. Lastly, Brain-inspired Planning, although least represented
    with 5 papers, opens innovative avenues for human-like planning processes in LLMs.
    By identifying the research distribution and gaps in these categories, our paper
    proposes how neurosymbolic approaches can address these voids, thereby underscoring
    the varying degrees of LLM applications in APS and guiding future research towards
    enhancing their capabilities in complex planning tasks.


    It is important to acknowledge that while LLMs have shown promise, they are not
    a panacea for the inherent complexities of automated planning. The expectation
    that LLMs, operating within polynomial run-time bounds, could supplant the nuanced
    and often non-polynomial complexities of symbolic planners is not yet realizable.
    Indeed, the strengths of LLMs do not currently include generating sequences of
    actions akin to those devised by symbolic planners, which are essential for creating
    a coherent and practical plan for complex problems. However, this does not diminish
    the potential utility of LLMs within this space. When considering average-case
    scenarios, which are typically less complex than worst-case scenarios, LLMs could
    offer substantial efficiencies. They can be seen as akin to meta-heuristic approaches,
    capable of accelerating plan generation in a variety of settings. As such, their
    application, governed by cognitive-inspired frameworks like SOFAI(Fabiano et al.
    2023), could delineate when and where their use is most advantageous.


    Future research should prioritize three areas: developing new LLM training paradigms
    that ensure coherence and goal alignment in outputs; delving into Henry Kautz''s
    neurosymbolic taxonomies (Kautz 2022) to better integrate neural and symbolic
    methods; and establishing clear performance metrics for LLM-assisted planners.
    In conclusion, integrating LLMs into automated planning, while challenging, opens
    avenues for innovation. Embracing a symbiotic approach that combines the creative
    strengths of LLMs with the precision of symbolic planners can lead to more effective,
    sophisticated AI applications in planning.


    # References


    Abdelnabi, S.; Gomaa, A.; Sivaprasad, S.; Schonherr, L.; ¨ and Fritz, M. 2023.
    Llm-deliberation: Evaluating llms with interactive multi-agent negotiation games.
    *arXiv preprint arXiv:2309.17234*.


    Arora, D.; and Kambhampati, S. 2023. Learning and Leveraging Verifiers to Improve
    Planning Capabilities of Pre-trained Language Models. *arXiv preprint arXiv:2305.17077*.


    Asai, M. 2018. Photo-Realistic Blocksworld Dataset. *arXiv preprint arXiv:1812.01818*.


    Besta, M.; Blach, N.; Kubicek, A.; Gerstenberger, R.; Gianinazzi, L.; Gajda, J.;
    Lehmann, T.; Podstawski, M.; Niewiadomski, H.; Nyczyk, P.; et al. 2023. Graph
    of thoughts: Solving elaborate problems with large language models. *arXiv preprint
    arXiv:2308.09687*.


    Brohan, A.; Chebotar, Y.; Finn, C.; Hausman, K.; Herzog, A.; Ho, D.; Ibarz, J.;
    Irpan, A.; Jang, E.; Julian, R.; et al. 2023. Do as i can, not as i say: Grounding
    language in robotic affordances. In *Conference on Robot Learning*, 287– 318.
    PMLR.


    Capitanelli, A.; and Mastrogiovanni, F. 2023. A Framework to Generate Neurosymbolic
    PDDL-compliant Planners. *arXiv preprint arXiv:2303.00438*.


    Carta, T.; Romac, C.; Wolf, T.; Lamprier, S.; Sigaud, O.; and Oudeyer, P.-Y. 2023.
    Grounding large language models in interactive environments with online reinforcement
    learning. *arXiv preprint arXiv:2302.02662*.


    Chalvatzaki, G.; Younes, A.; Nandha, D.; Le, A. T.; Ribeiro, L. F.; and Gurevych,
    I. 2023. Learning to reason over scene graphs: a case study of finetuning GPT-2
    into a robot language model for grounded task planning. *Frontiers in Robotics
    and AI*, 10.


    Chen, B.; Xia, F.; Ichter, B.; Rao, K.; Gopalakrishnan, K.; Ryoo, M. S.; Stone,
    A.; and Kappler, D. 2023a. Openvocabulary queryable scene representations for
    real world planning. In *2023 IEEE International Conference on Robotics and Automation
    (ICRA)*, 11509–11522. IEEE.


    Chen, X.; Zhang, S.; Zhang, P.; Zhao, L.; and Chen, J. 2023b. Asking Before Action:
    Gather Information in Embodied Decision Making with Language Models. *arXiv preprint
    arXiv:2305.15695*.


    Chen, Y.; Arkin, J.; Zhang, Y.; Roy, N.; and Fan, C. 2023c. AutoTAMP: Autoregressive
    Task and Motion Planning with LLMs as Translators and Checkers. *arXiv preprint
    arXiv:2306.06531*.


    Chen, Y.; Arkin, J.; Zhang, Y.; Roy, N.; and Fan, C. 2023d. Scalable Multi-Robot
    Collaboration with Large Language Models: Centralized or Decentralized Systems?
    *arXiv preprint arXiv:2309.15943*.


    Dagan, G.; Keller, F.; and Lascarides, A. 2023. Dynamic Planning with a LLM. *arXiv
    preprint arXiv:2308.06391*.


    Dai, Z.; Asgharivaskasi, A.; Duong, T.; Lin, S.; Tzes, M.-E.; Pappas, G.; and
    Atanasov, N. 2023. Optimal Scene Graph Planning with Large Language Model Guidance.
    *arXiv preprint arXiv:2309.09182*.


    Dalal, M.; Chiruvolu, T.; Chaplot, D. S.; and Salakhutdinov, R. 2023. Plan-Seq-Learn:
    Language Model Guided RL for Solving Long Horizon Robotics Tasks. In *2nd Workshop
    on Language and Robot Learning: Language as Grounding*.


    de Zarza, I.; de Curt ` o, J.; Roig, G.; Manzoni, P.; and ` Calafate, C. T. 2023.
    Emergent Cooperation and Strategy Adaptation in Multi-Agent Systems: An Extended
    Coevolutionary Theory with LLMs. *Electronics*, 12(12): 2722.


    Ding, Y.; Zhang, X.; Amiri, S.; Cao, N.; Yang, H.; Kaminski, A.; Esselink, C.;
    and Zhang, S. 2023a. Integrating Action Knowledge and LLMs for Task Planning and
    Situation Handling in Open Worlds. *arXiv preprint arXiv:2305.17590*.


    Ding, Y.; Zhang, X.; Paxton, C.; and Zhang, S. 2023b. Leveraging Commonsense Knowledge
    from Large Language Models for Task and Motion Planning. In *RSS 2023 Workshop
    on Learning for Task and Motion Planning*.


    Ding, Y.; Zhang, X.; Paxton, C.; and Zhang, S. 2023c. Task and motion planning
    with large language models for object rearrangement. *arXiv preprint arXiv:2303.06247*.


    Driess, D.; Xia, F.; Sajjadi, M. S.; Lynch, C.; Chowdhery, A.; Ichter, B.; Wahid,
    A.; Tompson, J.; Vuong, Q.; Yu, T.; et al. 2023. Palm-e: An embodied multimodal
    language model. *arXiv preprint arXiv:2303.03378*.


    Du, M.; Luu, A. T.; Ji, B.; and Ng, S.-k. 2023. From Static to Dynamic: A Continual
    Learning Framework for Large Language Models. *arXiv preprint arXiv:2310.14248*.


    Elaraby, M.; Lu, M.; Dunn, J.; Zhang, X.; Wang, Y.; and Liu, S. 2023. Halo: Estimation
    and reduction of hallucinations in open-source weak large language models. *arXiv
    preprint arXiv:2308.11764*.


    Fabiano, F.; Pallagani, V.; Ganapini, M. B.; Horesh, L.; Loreggia, A.; Murugesan,
    K.; Rossi, F.; and Srivastava, B. 2023. Fast and Slow Planning. *arXiv preprint
    arXiv:2303.04283*.


    Feng, X.; Wan, Z.; Wen, M.; Wen, Y.; Zhang, W.; and Wang, J. 2023. Alphazero-like
    tree-search can guide large language model decoding and training. *arXiv preprint
    arXiv:2309.17179*.


    Gandhi, K.; Sadigh, D.; and Goodman, N. D. 2023. Strategic Reasoning with Language
    Models. *arXiv preprint arXiv:2305.19165*.


    Ge, Y.; Hua, W.; Ji, J.; Tan, J.; Xu, S.; and Zhang, Y. 2023. Openagi: When llm
    meets domain experts. *arXiv preprint arXiv:2304.04370*.


    Georgievski, I.; and Aiello, M. 2015. HTN planning: Overview, comparison, and
    beyond. *Artif. Intell.*, 222: 124– 156.


    Gerevini, A.; and Serina, I. 2002. LPG: A Planner Based on Local Search for Planning
    Graphs with Action Costs. In *Aips*, volume 2, 281–290.


    Ghallab, M.; Nau, D.; and Traverso, P. 2004. *Automated Planning: Theory and Practice*.
    The Morgan Kaufmann Series in Artificial Intelligence. Amsterdam: Morgan Kaufmann.
    ISBN 978-1-55860-856-6.


    Gragera, A.; and Pozanco, A. 2023. Exploring the Limitations of using Large Language
    Models to Fix Planning Tasks.


    Gramopadhye, M.; and Szafir, D. 2022. Generating executable action plans with
    environmentally-aware language models. *arXiv preprint arXiv:2210.04964*.


    Graule, M. A.; and Isler, V. 2023. GG-LLM: Geometrically Grounding Large Language
    Models for Zero-shot Human Activity Forecasting in Human-Aware Task Planning.
    *arXiv preprint arXiv:2310.20034*.


    Gu, Q.; Kuwajerwala, A.; Morin, S.; Jatavallabhula, K. M.; Sen, B.; Agarwal, A.;
    Rivera, C.; Paul, W.; Ellis, K.; Chellappa, R.; et al. 2023. Conceptgraphs: Open-vocabulary
    3d scene graphs for perception and planning. *arXiv preprint arXiv:2309.16650*.


    Guan, L.; Valmeekam, K.; Sreedharan, S.; and Kambhampati, S. 2023. Leveraging
    Pre-trained Large Language Models to Construct and Utilize World Models for Model-based
    Task Planning. *arXiv preprint arXiv:2305.14909*.


    Hao, S.; Gu, Y.; Ma, H.; Hong, J. J.; Wang, Z.; Wang, D. Z.; and Hu, Z. 2023a.
    Reasoning with language model is planning with world model. *arXiv preprint arXiv:2305.14992*.


    Hao, S.; Liu, T.; Wang, Z.; and Hu, Z. 2023b. ToolkenGPT: Augmenting Frozen Language
    Models with Massive Tools via Tool Embeddings. *arXiv preprint arXiv:2305.11554*.


    Hazra, R.; Martires, P. Z. D.; and De Raedt, L. 2023. Say-CanPay: Heuristic Planning
    with Large Language Models using Learnable Domain Knowledge. *arXiv preprint arXiv:2308.12682*.


    Howey, R.; Long, D.; and Fox, M. 2004. VAL: automatic plan validation, continuous
    effects and mixed initiative planning using PDDL. In *16th IEEE International
    Conference on Tools with Artificial Intelligence*, 294–301.


    Hsieh, C.-Y.; Chen, S.-A.; Li, C.-L.; Fujii, Y.; Ratner, A.; Lee, C.-Y.; Krishna,
    R.; and Pfister, T. 2023. Tool documentation enables zero-shot tool-usage with
    large language models. *arXiv preprint arXiv:2308.00675*.


    Hu, B.; Zhao, C.; Zhang, P.; Zhou, Z.; Yang, Y.; Xu, Z.; and Liu, B. 2023a. Enabling
    Efficient Interaction between an Algorithm Agent and an LLM: A Reinforcement Learning
    Approach. *arXiv preprint arXiv:2306.03604*.


    Hu, H.; Lu, H.; Zhang, H.; Lam, W.; and Zhang, Y. 2023b. Chain-of-Symbol Prompting
    Elicits Planning in Large Langauge Models. *arXiv preprint arXiv:2305.10276*.


    Hu, M.; Mu, Y.; Yu, X.; Ding, M.; Wu, S.; Shao, W.; Chen, Q.; Wang, B.; Qiao,
    Y.; and Luo, P. 2023c. Tree-Planner: Efficient Close-loop Task Planning with Large
    Language Models. *arXiv preprint arXiv:2310.08582*.


    Hu, P.; Qi, J.; Li, X.; Li, H.; Wang, X.; Quan, B.; Wang, R.; and Zhou, Y. 2023d.
    Tree-of-mixed-thought: Combining fast and slow thinking for multi-hop visual reasoning.
    *arXiv preprint arXiv:2308.09658*.


    Hu, Z.; and Shu, T. 2023. Language Models, Agent Models, and World Models: The
    LAW for Machine Reasoning and Planning. arXiv:2312.05230.


    Hua, W.; Fan, L.; Li, L.; Mei, K.; Ji, J.; Ge, Y.; Hemphill, L.; and Zhang, Y.
    2023. War and peace (waragent): Large language model-based multi-agent simulation
    of world wars. *arXiv preprint arXiv:2311.17227*.


    Huang, W.; Abbeel, P.; Pathak, D.; and Mordatch, I. 2022a. Language models as
    zero-shot planners: Extracting actionable knowledge for embodied agents. In *International
    Conference on Machine Learning*, 9118–9147. PMLR.


    Huang, W.; Wang, C.; Zhang, R.; Li, Y.; Wu, J.; and Fei-Fei, L. 2023a. Voxposer:
    Composable 3d value maps for robotic manipulation with language models. *arXiv
    preprint arXiv:2307.05973*.


    Huang, W.; Xia, F.; Shah, D.; Driess, D.; Zeng, A.; Lu, Y.; Florence, P.; Mordatch,
    I.; Levine, S.; Hausman, K.; et al. 2023b. Grounded decoding: Guiding text generation
    with grounded models for robot control. *arXiv preprint arXiv:2303.00855*.


    Huang, W.; Xia, F.; Xiao, T.; Chan, H.; Liang, J.; Florence, P.; Zeng, A.; Tompson,
    J.; Mordatch, I.; Chebotar, Y.; et al. 2022b. Inner monologue: Embodied reasoning
    through planning with language models. *arXiv preprint arXiv:2207.05608*.


    Jha, S. K.; Jha, S.; Lincoln, P.; Bastian, N. D.; Velasquez, A.; Ewetz, R.; and
    Neema, S. 2023. Neuro Symbolic Reasoning for Planning: Counterexample Guided Inductive
    Synthesis using Large Language Models and Satisfiability Solving. *arXiv preprint
    arXiv:2309.16436*.


    Joublin, F.; Ceravola, A.; Smirnov, P.; Ocker, F.; Deigmoeller, J.; Belardinelli,
    A.; Wang, C.; Hasler, S.; Tanneberg, D.; and Gienger, M. 2023. CoPAL: Corrective
    Planning of Robot Actions with Large Language Models. *arXiv preprint arXiv:2310.07263*.


    Kannan, S. S.; Venkatesh, V. L.; and Min, B.-C. 2023. SMART-LLM: Smart Multi-Agent
    Robot Task Planning using Large Language Models. *arXiv preprint arXiv:2309.10062*.


    Kant, Y.; Ramachandran, A.; Yenamandra, S.; Gilitschenski, I.; Batra, D.; Szot,
    A.; and Agrawal, H. 2022. Housekeep: Tidying virtual households using commonsense
    reasoning. In *European Conference on Computer Vision*, 355– 373. Springer.


    Kautz, H. A. 2022. The third AI summer: AAAI Robert S. Engelmore Memorial Lecture.
    *AI Magazine*, 43(1): 105– 125.


    Kelly, J.; Calderwood, A.; Wardrip-Fruin, N.; and Mateas, M. 2023. There and back
    again: extracting formal domains for controllable neurosymbolic story authoring.
    In *Proceedings of the AAAI Conference on Artificial Intelligence and Interactive
    Digital Entertainment*, volume 19, 64–74.


    Kim, G.; Kim, T.; Kannan, S. S.; Venkatesh, V. L.; Kim, D.; and Min, B.-C. 2023.
    DynaCon: Dynamic Robot Planner with Contextual Awareness via LLMs. *arXiv preprint
    arXiv:2309.16031*.


    Kirk, J. R.; Wray, R. E.; and Laird, J. E. 2023. Exploiting Language Models as
    a Source of Knowledge for Cognitive Agents. *arXiv preprint arXiv:2310.06846*.


    Lenat, D.; and Marcus, G. 2023. Getting from generative ai to trustworthy ai:
    What llms might learn from cyc. *arXiv preprint arXiv:2308.04445*.


    Li, M.; Song, F.; Yu, B.; Yu, H.; Li, Z.; Huang, F.; and Li, Y. 2023a. Api-bank:
    A benchmark for tool-augmented llms. *arXiv preprint arXiv:2304.08244*.


    Li, Y.; Kamra, N.; Desai, R.; and Halevy, A. 2023b. Human-Centered Planning. *arXiv
    preprint arXiv:2311.04403*.


    Lin, B. Y.; Fu, Y.; Yang, K.; Ammanabrolu, P.; Brahman, F.; Huang, S.; Bhagavatula,
    C.; Choi, Y.; and Ren, X. 2023a. SwiftSage: A Generative Agent with Fast and Slow
    Thinking for Complex Interactive Tasks. *arXiv preprint arXiv:2305.17390*.


    Lin, H.; Zala, A.; Cho, J.; and Bansal, M. 2023b. Videodirectorgpt: Consistent
    multi-scene video generation via llmguided planning. *arXiv preprint arXiv:2309.15091*.


    Lin, K.; Agia, C.; Migimatsu, T.; Pavone, M.; and Bohg, J. 2023c. Text2motion:
    From natural language instructions to feasible plans. *arXiv preprint arXiv:2303.12153*.


    Liu, B.; Jiang, Y.; Zhang, X.; Liu, Q.; Zhang, S.; Biswas, J.; and Stone, P. 2023.
    Llm+ p: Empowering large language models with optimal planning proficiency. *arXiv
    preprint arXiv:2304.11477*.


    Liu, Z.; Bahety, A.; and Song, S. 2023. Reflect: Summarizing robot experiences
    for failure explanation and correction. *arXiv preprint arXiv:2306.15724*.


    Logeswaran, L.; Sohn, S.; Lyu, Y.; Liu, A. Z.; Kim, D.- K.; Shim, D.; Lee, M.;
    and Lee, H. 2023. Code Models are Zero-shot Precondition Reasoners. *arXiv preprint
    arXiv:2311.09601*.


    Lu, P.; Peng, B.; Cheng, H.; Galley, M.; Chang, K.-W.; Wu, Y. N.; Zhu, S.-C.;
    and Gao, J. 2023a. Chameleon: Plug-andplay compositional reasoning with large
    language models. *arXiv preprint arXiv:2304.09842*.


    Lu, Y.; Feng, W.; Zhu, W.; Xu, W.; Wang, X. E.; Eckstein, M.; and Wang, W. Y.
    2022. Neuro-symbolic causal language planning with commonsense prompting. *arXiv
    eprints*, arXiv–2206.


    Lu, Y.; Lu, P.; Chen, Z.; Zhu, W.; Wang, X. E.; and Wang, W. Y. 2023b. Multimodal
    Procedural Planning via Dual Text-Image Prompting. *arXiv preprint arXiv:2305.01795*.


    Luo, L.; Li, Y.-F.; Haffari, G.; and Pan, S. 2023. Reasoning on graphs: Faithful
    and interpretable large language model reasoning. *arXiv preprint arXiv:2310.01061*.


    Mandi, Z.; Jain, S.; and Song, S. 2023. Roco: Dialectic multi-robot collaboration
    with large language models. *arXiv preprint arXiv:2307.04738*.


    McDermott, D.; Ghallab, M.; Howe, A.; Knoblock, C.; Ram, A.; Veloso, M.; Weld,
    D.; and Wilkins, D. 1998. PDDL-the planning domain definition language.


    Momennejad, I.; Hasanbeig, H.; Vieira, F.; Sharma, H.; Ness, R. O.; Jojic, N.;
    Palangi, H.; and Larson, J. 2023. Evaluating Cognitive Maps and Planning in Large
    Language Models with CogEval. *arXiv preprint arXiv:2309.15129*.


    Naik, R.; Chandrasekaran, V.; Yuksekgonul, M.; Palangi, H.; and Nushi, B. 2023.
    Diversity of Thought Improves Reasoning Abilities of Large Language Models. *arXiv
    preprint arXiv:2310.07088*.


    Nottingham, K.; Ammanabrolu, P.; Suhr, A.; Choi, Y.; Hajishirzi, H.; Singh, S.;
    and Fox, R. 2023. Do embodied agents dream of pixelated sheep?: Embodied decision
    making using language guided world modelling. *arXiv preprint arXiv:2301.12050*.


    Pallagani, V.; Muppasani, B.; Murugesan, K.; Rossi, F.; Horesh, L.; Srivastava,
    B.; Fabiano, F.; and Loreggia, A. 2022. Plansformer: Generating symbolic plans
    using transformers. *arXiv preprint arXiv:2212.08681*.


    Pallagani, V.; Muppasani, B.; Murugesan, K.; Rossi, F.; Srivastava, B.; Horesh,
    L.; Fabiano, F.; and Loreggia, A. 2023a. Understanding the Capabilities of Large
    Language Models for Automated Planning. *arXiv preprint arXiv:2305.16151*.


    Pallagani, V.; Muppasani, B.; Srivastava, B.; Rossi, F.; Horesh, L.; Murugesan,
    K.; Loreggia, A.; Fabiano, F.; Joseph, R.; Kethepalli, Y.; et al. 2023b. Plansformer
    Tool: Demonstrating Generation of Symbolic Plans Using Transformers. In *IJCAI*,
    volume 2023, 7158–7162. International Joint Conferences on Artificial Intelligence.


    Pan, L.; Albalak, A.; Wang, X.; and Wang, W. Y. 2023. Logic-lm: Empowering large
    language models with symbolic solvers for faithful logical reasoning. *arXiv preprint
    arXiv:2305.12295*.


    Parakh, M.; Fong, A.; Simeonov, A.; Gupta, A.; Chen, T.; and Agrawal, P. 2023.
    Human-Assisted Continual Robot Learning with Foundation Models. *arXiv preprint
    arXiv:2309.14321*.


    Raimondo, S.; Pal, C.; Liu, X.; Vazquez, D.; and Palacios, H. 2023. Improving
    Generalization in Task-oriented Dialogues with Workflows and Action Plans. *arXiv
    preprint arXiv:2306.01729*.


    Rajvanshi, A.; Sikka, K.; Lin, X.; Lee, B.; Chiu, H.-P.; and Velasquez, A. 2023.
    Saynav: Grounding large language models for dynamic planning to navigation in
    new environments. *arXiv preprint arXiv:2309.04077*.


    Raman, S. S.; Cohen, V.; Rosen, E.; Idrees, I.; Paulius, D.; and Tellex, S. 2022.
    Planning with large language models via corrective re-prompting. In *NeurIPS 2022
    Foundation Models for Decision Making Workshop*.


    Rana, K.; Haviland, J.; Garg, S.; Abou-Chakra, J.; Reid, I.; and Suenderhauf,
    N. 2023. Sayplan: Grounding large language models using 3d scene graphs for scalable
    task planning. *arXiv preprint arXiv:2307.06135*.


    Ren, A. Z.; Dixit, A.; Bodrova, A.; Singh, S.; Tu, S.; Brown, N.; Xu, P.; Takayama,
    L.; Xia, F.; Varley, J.; et al. 2023. Robots that ask for help: Uncertainty alignment
    for large language model planners. *arXiv preprint arXiv:2307.01928*.


    Ruan, J.; Chen, Y.; Zhang, B.; Xu, Z.; Bao, T.; Du, G.; Shi, S.; Mao, H.; Zeng,
    X.; and Zhao, R. 2023. Tptu: Task planning and tool usage of large language model-based
    ai agents. *arXiv preprint arXiv:2308.03427*.


    Russell, S.; and Norvig, P. 2003. *Artificial Intelligence, A Modern Approach.
    Second Edition*.


    Sakib, M. S.; and Sun, Y. 2023. From Cooking Recipes to Robot Task Trees–Improving
    Planning Correctness and Task Efficiency by Leveraging LLMs with a Knowledge Network.
    *arXiv preprint arXiv:2309.09181*.


    Sarkisyan, C.; Korchemnyi, A.; Kovalev, A. K.; and Panov, A. I. 2023. Evaluation
    of Pretrained Large Language Models in Embodied Planning Tasks. In *International
    Conference on Artificial General Intelligence*, 222–232. Springer.


    Sermanet, P.; Ding, T.; Zhao, J.; Xia, F.; Dwibedi, D.; Gopalakrishnan, K.; Chan,
    C.; Dulac-Arnold, G.; Maddineni, S.; Joshi, N. J.; et al. 2023. RoboVQA: Multimodal
    Long-Horizon Reasoning for Robotics. *arXiv preprint arXiv:2311.00899*.


    Shah, D.; Equi, M.; Osinski, B.; Xia, F.; Ichter, B.; and Levine, S. 2023. Navigation
    with large language models: Semantic guesswork as a heuristic for planning. *arXiv
    preprint arXiv:2310.10103*.


    Shen, Y.; Song, K.; Tan, X.; Li, D.; Lu, W.; and Zhuang, Y. 2023. Hugginggpt:
    Solving ai tasks with chatgpt and its friends in huggingface. *arXiv preprint
    arXiv:2303.17580*.


    Shirai, K.; Beltran-Hernandez, C. C.; Hamaya, M.; Hashimoto, A.; Tanaka, S.; Kawaharazuka,
    K.; Tanaka, K.; Ushiku, Y.; and Mori, S. 2023. Vision-Language Interpreter for
    Robot Task Planning. *arXiv preprint arXiv:2311.00967*.


    Silver, T.; Dan, S.; Srinivas, K.; Tenenbaum, J. B.; Kaelbling, L. P.; and Katz,
    M. 2023. Generalized Planning in PDDL Domains with Pretrained Large Language Models.
    *arXiv preprint arXiv:2305.11014*.


    Silver, T.; Hariprasad, V.; Shuttleworth, R. S.; Kumar, N.; Lozano-Perez, T.;
    and Kaelbling, L. P. 2022. PDDL plan- ´ ning with pretrained large language models.
    In *NeurIPS 2022 Foundation Models for Decision Making Workshop*.


    Singh, I.; Blukis, V.; Mousavian, A.; Goyal, A.; Xu, D.; Tremblay, J.; Fox, D.;
    Thomason, J.; and Garg, A. 2023. ProgPrompt: program generation for situated robot
    task planning using large language models. *Autonomous Robots*, 1–14.


    Song, C. H.; Wu, J.; Washington, C.; Sadler, B. M.; Chao, W.-L.; and Su, Y. 2023.
    Llm-planner: Few-shot grounded planning for embodied agents with large language
    models. In *Proceedings of the IEEE/CVF International Conference on Computer Vision*,
    2998–3009.


    Sumers, T.; Yao, S.; Narasimhan, K.; and Griffiths, T. L. 2023. Cognitive architectures
    for language agents. *arXiv preprint arXiv:2309.02427*.


    Sun, H.; Zhuang, Y.; Kong, L.; Dai, B.; and Zhang, C. 2023. AdaPlanner: Adaptive
    Planning from Feedback with Language Models. *arXiv preprint arXiv:2305.16653*.


    Tang, X.; Zheng, Z.; Li, J.; Meng, F.; Zhu, S.-C.; Liang, Y.; and Zhang, M. 2023.
    Large Language Models are In-Context Semantic Reasoners rather than Symbolic Reasoners.
    *arXiv preprint arXiv:2305.14825*.


    Valmeekam, K.; Marquez, M.; and Kambhampati, S. 2023. Can Large Language Models
    Really Improve by Self-critiquing Their Own Plans? *arXiv preprint arXiv:2310.08118*.


    Valmeekam, K.; Marquez, M.; Olmo, A.; Sreedharan, S.; and Kambhampati, S. 2023a.
    PlanBench: An Extensible Benchmark for Evaluating Large Language Models on Planning
    and Reasoning about Change. In *Thirty-seventh Conference on Neural Information
    Processing Systems Datasets and Benchmarks Track*.


    Valmeekam, K.; Olmo, A.; Sreedharan, S.; and Kambhampati, S. 2022. Large Language
    Models Still Can''t Plan (A Benchmark for LLMs on Planning and Reasoning about
    Change). *arXiv preprint arXiv:2206.10498*.


    Valmeekam, K.; Sreedharan, S.; Marquez, M.; Olmo, A.; and Kambhampati, S. 2023b.
    On the planning abilities of large language models (a critical investigation with
    a proposed benchmark). *arXiv preprint arXiv:2302.06706*.


    Wang, J.; Tong, J.; Tan, K.; Vorobeychik, Y.; and Kantaros, Y. 2023a. Conformal
    Temporal Logic Planning using Large Language Models: Knowing When to Do What and
    When to Ask for Help. *arXiv preprint arXiv:2309.10092*.


    Wang, L.; Xu, W.; Lan, Y.; Hu, Z.; Lan, Y.; Lee, R. K.-W.; and Lim, E.-P. 2023b.
    Plan-and-solve prompting: Improving zero-shot chain-of-thought reasoning by large
    language models. *arXiv preprint arXiv:2305.04091*.


    Wang, X.; Caccia, L.; Ostapenko, O.; Yuan, X.; and Sordoni, A. 2023c. Guiding
    language model reasoning with planning tokens. *arXiv preprint arXiv:2310.05707*.


    Wang, Z.; Cai, S.; Liu, A.; Ma, X.; and Liang, Y. 2023d. Describe, explain, plan
    and select: Interactive planning with large language models enables open-world
    multi-task agents. *arXiv preprint arXiv:2302.01560*.


    Webb, T.; Mondal, S. S.; Wang, C.; Krabach, B.; and Momennejad, I. 2023. A Prefrontal
    Cortex-inspired Architecture for Planning in Large Language Models. *arXiv preprint
    arXiv:2310.00194*.


    Wei, L.; He, Z.; Zhao, H.; and Yao, Q. 2023. Unleashing the Power of Graph Learning
    through LLM-based Autonomous Agents. *arXiv preprint arXiv:2309.04565*.


    Wong, L.; Grand, G.; Lew, A. K.; Goodman, N. D.; Mansinghka, V. K.; Andreas, J.;
    and Tenenbaum, J. B. 2023. From Word Models to World Models: Translating from
    Natural Language to the Probabilistic Language of Thought. *arXiv preprint arXiv:2306.12672*.


    Wu, Y.; Min, S. Y.; Bisk, Y.; Salakhutdinov, R.; Azaria, A.; Li, Y.; Mitchell,
    T.; and Prabhumoye, S. 2023a. Plan, Eliminate, and Track–Language Models are Good
    Teachers for Embodied Agents. *arXiv preprint arXiv:2305.02412*.


    Wu, Z.; Ai, B.; and Hsu, D. 2023. Integrating Common Sense and Planning with Large
    Language Models for Room Tidying. In *RSS 2023 Workshop on Learning for Task and
    Motion Planning*.


    Wu, Z.; Wang, Z.; Xu, X.; Lu, J.; and Yan, H. 2023b. Embodied task planning with
    large language models. *arXiv preprint arXiv:2307.01848*.


    Xie, Y.; Yu, C.; Zhu, T.; Bai, J.; Gong, Z.; and Soh, H. 2023. Translating natural
    language to planning goals with largelanguage models. *arXiv preprint arXiv:2302.05128*.


    Xu, B.; Liu, X.; Shen, H.; Han, Z.; Li, Y.; Yue, M.; Peng, Z.; Liu, Y.; Yao, Z.;
    and Xu, D. 2023a. Gentopia: A collaborative platform for tool-augmented llms.
    *arXiv preprint arXiv:2308.04030*.


    Xu, L. 1995. Case based reasoning. *IEEE Potentials*, 13(5): 10–13.


    Xu, M.; Huang, P.; Yu, W.; Liu, S.; Zhang, X.; Niu, Y.; Zhang, T.; Xia, F.; Tan,
    J.; and Zhao, D. 2023b. Creative Robot Tool Use with Large Language Models. *arXiv
    preprint arXiv:2310.13065*.


    Yang, J.; Chen, X.; Qian, S.; Madaan, N.; Iyengar, M.; Fouhey, D. F.; and Chai,
    J. 2023a. LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language
    Model as an Agent. *arXiv preprint arXiv:2309.12311*.


    Yang, R.; Hou, M.; Wang, J.; and Zhang, F. 2023b. Ocean-Chat: Piloting Autonomous
    Underwater Vehicles in Natural Language. *arXiv preprint arXiv:2309.16052*.


    Yang, Y.; Gaglione, J.-R.; and Topcu, U. 2022. Learning Automata-Based Task Knowledge
    Representation from Large-Scale Generative Language Models. *arXiv preprint arXiv:2212.01944*.


    Yang, Y.; and Tomar, A. 2023. On the Planning, Search, and Memorization Capabilities
    of Large Language Models. *arXiv preprint arXiv:2309.01868*.


    Yang, Z. 2023. *Neuro-Symbolic AI Approaches to Enhance Deep Neural Networks with
    Logical Reasoning and Knowledge Integration*. Ph.D. thesis, Arizona State University.


    Yang, Z.; Ishay, A.; and Lee, J. 2023. Coupling Large Language Models with Logic
    Programming for Robust and General Reasoning from Text. *arXiv preprint arXiv:2307.07696*.


    Yao, S.; Yu, D.; Zhao, J.; Shafran, I.; Griffiths, T. L.; Cao, Y.; and Narasimhan,
    K. 2023. Tree of thoughts: Deliberate problem solving with large language models.
    *arXiv preprint arXiv:2305.10601*.


    Yoneda, T.; Fang, J.; Li, P.; Zhang, H.; Jiang, T.; Lin, S.; Picker, B.; Yunis,
    D.; Mei, H.; and Walter, M. R. 2023. Statler: State-maintaining language models
    for embodied reasoning. *arXiv preprint arXiv:2306.17840*.


    You, W.; Wu, W.; Liang, Y.; Mao, S.; Wu, C.; Cao, M.; Cai, Y.; Guo, Y.; Xia, Y.;
    Wei, F.; et al. 2023. EIPE-text: Evaluation-Guided Iterative Plan Extraction for
    Long-Form Narrative Text Generation. *arXiv preprint arXiv:2310.08185*.


    Yuan, H.; Zhang, C.; Wang, H.; Xie, F.; Cai, P.; Dong, H.; and Lu, Z. 2023a. Plan4mc:
    Skill reinforcement learning and planning for open-world minecraft tasks. *arXiv
    preprint arXiv:2303.16563*.


    Yuan, S.; Chen, J.; Fu, Z.; Ge, X.; Shah, S.; Jankowski, C. R.; Yang, D.; and
    Xiao, Y. 2023b. Distilling Script Knowledge from Large Language Models for Constrained
    Language Planning. *arXiv preprint arXiv:2305.05252*.


    Zelikman, E.; Huang, Q.; Poesia, G.; Goodman, N.; and Haber, N. 2023. Parsel:
    Algorithmic Reasoning with Language Models by Composing Decompositions. In *Thirtyseventh
    Conference on Neural Information Processing Systems*.


    Zhang, B.; and Soh, H. 2023. Large language models as zero-shot human models for
    human-robot interaction. *arXiv preprint arXiv:2303.03548*.


    Zhang, C.; Liu, L.; Wang, J.; Wang, C.; Sun, X.; Wang, H.; and Cai, M. 2023a.
    Prefer: Prompt ensemble learning via feedback-reflect-refine. *arXiv preprint
    arXiv:2308.12033*.


    Zhang, F.; Jin, K.; and Zhuo, H. H. 2023. Planning with Logical Graph-based Language
    Model for Instruction Generation. arXiv:2308.13782.


    Zhang, H.; Du, W.; Shan, J.; Zhou, Q.; Du, Y.; Tenenbaum, J. B.; Shu, T.; and
    Gan, C. 2023b. Building cooperative embodied agents modularly with large language
    models. *arXiv preprint arXiv:2307.02485*.


    Zhang, J.; Zhang, J.; Pertsch, K.; Liu, Z.; Ren, X.; Chang, M.; Sun, S.-H.; and
    Lim, J. J. 2023c. Bootstrap your own skills: Learning to solve new tasks with
    large language model guidance. *arXiv preprint arXiv:2310.10021*.


    Zhao, Z.; Lee, W. S.; and Hsu, D. 2023. Large Language Models as Commonsense Knowledge
    for Large-Scale Task Planning. *arXiv preprint arXiv:2305.14078*.


    Zheng, L.; Chiang, W.-L.; Sheng, Y.; Zhuang, S.; Wu, Z.; Zhuang, Y.; Lin, Z.;
    Li, Z.; Li, D.; Xing, E. P.; Zhang, H.; Gonzalez, J. E.; and Stoica, I. 2023a.
    Judging LLM-as-a-judge with MT-Bench and Chatbot Arena. arXiv:2306.05685.


    Zheng, S.; Liu, J.; Feng, Y.; and Lu, Z. 2023b. Steve-Eye: Equipping LLM-based
    Embodied Agents with Visual Perception in Open Worlds. *arXiv preprint arXiv:2310.13255*.


    Zhou, Z.; Song, J.; Yao, K.; Shu, Z.; and Ma, L. 2023. ISR-LLM: Iterative Self-Refined
    Large Language Model for Long-Horizon Sequential Task Planning. *arXiv preprint
    arXiv:2308.13724*.'
  decisions:
    evaluation_prompt: 'Disqualified. Reason: The abstract and introduction contain
      only a conceptual discussion and a literature review without any mention of
      empirical, experimental, or quantitative evaluation. There are no references
      to experiments, metrics, or structured evaluation methods.'
    related_work_prompt: '- Qualified. Reason: The paper engages with prior research
      by referencing foundational works in Automated Planning and Scheduling (e.g.,
      Russell and Norvig 2003; Ghallab, Nau, and Traverso 2004) and discusses the
      evolution of LLMs in relation to APS, indicating a synthesis of insights from
      existing literature.'
    novelty_prompt: 'Qualified. Reason: The paper claims novelty by investigating
      the integration of LLMs with traditional symbolic planners and proposing a neuro-symbolic
      approach to address complex planning challenges, indicating new contributions
      in the field of Automated Planning and Scheduling.'
    review_only_prompt: 'Disqualified: review paper. Reason: The title suggests it
      is a review, and the abstract and introduction describe the paper as primarily
      summarizing existing work without proposing new methods, results, or tools.'
  llm_input_used: '## Abstract

    Automated Planning and Scheduling is among the growing areas in Artificial

    Intelligence (AI) where mention of LLMs has gained popularity. Based on a

    comprehensive review of 126 papers, this paper investigates eight categories

    based on the unique applications of LLMs in addressing various aspects of

    planning problems: language translation, plan generation, model construction,

    multi-agent planning, interactive planning, heuristics optimization, tool

    integration, and brain-inspired planning. For each category, we articulate the

    issues considered and existing gaps. A critical insight resulting from our

    review is that the true potential of LLMs unfolds when they are integrated with

    traditional symbolic planners, pointing towards a promising neuro-symbolic

    approach. This approach effectively combines the generative aspects of LLMs

    with the precision of classical planning methods. By synthesizing insights from

    existing literature, we underline the potential of this integration to address

    complex planning challenges. Our goal is to encourage the ICAPS community to

    recognize the complementary strengths of LLMs and symbolic planners, advocating

    for a direction in automated planning that leverages these synergistic

    capabilities to develop more advanced and intelligent planning systems.


    ## Introduction

    As a sub-field of Artificial Intelligence (Russell and Norvig 2003), Automated
    Planning and Scheduling (Ghallab, Nau, and Traverso 2004) refers to developing
    algorithms and systems to generate plans or sequences of actions to achieve specific
    goals in a given environment or problem domain. APS is a valuable tool in domains
    where there is a need for intelligent decision-making, goal achievement, and efficient
    resource utilization. It enables the automation of complex tasks, making systems
    more capable and adaptable in dynamic environments. Over time, APS has evolved
    from the early development of robust theoretical foundations to practical applications
    in diverse sectors like manufacturing, space exploration, and personal scheduling.
    This evolution underscores the versatility and critical significance of APS.


    In parallel with advancements in APS, the development and proliferation of LLMs
    have marked a substantial leap in AI, particularly within computational linguistics.
    Evolving from early efforts in natural language processing (NLP), LLMs have undergone
    significant transformation. Initially focused on basic tasks like word prediction
    and syntax analysis, newer models are characterized by their ability to generate
    coherent, contextually relevant text and perform diverse, complex linguistic tasks.
    Trained on extensive text corpora, LLMs have mastered human-like language patterns.
    Their recent success in various NLP tasks has prompted efforts to apply these
    models in APS. There is a notable shift towards using language constructs to specify
    aspects of planning, such as preconditions, effects, and goals, rather than relying
    solely on traditional planning domain languages like PDDL.


    This paper presents an exhaustive literature review exploring the integration
    of LLMs in APS across eight categories: Language Translation, Plan Generation,
    Model Construction, Multi-agent Planning, Interactive Planning, Heuristics Optimization,
    Brain-Inspired Planning, and Tool Integration. Table 1 provides the description
    for the eight categories. Our comprehensive analysis of 126 papers not only categorizes
    LLMs'' diverse contributions but also identifies significant gaps in each domain.
    Through our review, we put forward the following position:'
  token_usage: 3659
  time_usage: 5.093494892120361
- title: 'Training and Serving System of Foundation Models: A Comprehensive Survey'
  abstract: 'Foundation models (e.g., ChatGPT, DALL-E, PengCheng Mind, PanGu-$\Sigma$)

    have demonstrated extraordinary performance in key technological areas, such as

    natural language processing and visual recognition, and have become the

    mainstream trend of artificial general intelligence. This has led more and more

    major technology giants to dedicate significant human and financial resources

    to actively develop their foundation model systems, which drives continuous

    growth of these models'' parameters. As a result, the training and serving of

    these models have posed significant challenges, including substantial computing

    power, memory consumption, bandwidth demands, etc. Therefore, employing

    efficient training and serving strategies becomes particularly crucial. Many

    researchers have actively explored and proposed effective methods. So, a

    comprehensive survey of them is essential for system developers and

    researchers. This paper extensively explores the methods employed in training

    and serving foundation models from various perspectives. It provides a detailed

    categorization of these state-of-the-art methods, including finer aspects such

    as network, computing, and storage. Additionally, the paper summarizes the

    challenges and presents a perspective on the future development direction of

    foundation model systems. Through comprehensive discussion and analysis, it

    hopes to provide a solid theoretical basis and practical guidance for future

    research and applications, promoting continuous innovation and development in

    foundation model systems.'
  url: http://arxiv.org/abs/2401.02643v1
  keywords: '* Foundation Model System, Training, Serving, Network, Computing, Storage'
  document: '![](_page_0_Picture_0.jpeg)


    Received XX Month, XXXX; revised XX Month, XXXX; accepted XX Month, XXXX; Date
    of publication XX Month, XXXX; date of current version XX Month, XXXX.


    *Digital Object Identifier 10.1109/OJIM.2022.1234567*


    # **Training and Serving System of Foundation Models: A Comprehensive Survey**


    **JIAHANG ZHOU<sup>1</sup> , YANYU CHEN<sup>1</sup> , ZICONG HONG<sup>3</sup>
    , WUHUI CHEN2, 4, YUE YU<sup>4</sup> , TAO ZHANG<sup>1</sup> , HUI WANG<sup>4</sup>
    , CHUANFU ZHANG<sup>1</sup> , AND ZIBIN ZHENG<sup>2</sup> .**


    > School of Systems Science and Engineering, Sun Yat-sen University, Guangzhou,
    528406, China School of Software Engineering, Sun Yat-sen University, Guangzhou,
    510275, China Department of Computing in The Hong Kong Polytechnic University,
    Hong Kong, 999077, China Peng Cheng Laboratory, Shenzhen, 518000, China


    CORRESPONDING AUTHOR: Wuhui Chen (e-mail: chenwuh@mail.sysu.edu.cn).


    **ABSTRACT** Foundation models (e.g., ChatGPT, DALL-E, PengCheng Mind, PanGu-Σ)
    have demonstrated extraordinary performance in key technological areas, such as
    natural language processing and visual recognition, and have become the mainstream
    trend of artificial general intelligence. This has led more and more major technology
    giants to dedicate significant human and financial resources to actively develop
    their foundation model systems, which drives continuous growth of these models''
    parameters. As a result, the training and serving of these models have posed significant
    challenges, including substantial computing power, memory consumption, bandwidth
    demands, etc. Therefore, employing efficient training and serving strategies becomes
    particularly crucial. Many researchers have actively explored and proposed effective
    methods. So, a comprehensive survey of them is essential for system developers
    and researchers. This paper extensively explores the methods employed in training
    and serving foundation models from various perspectives. It provides a detailed
    categorization of these state-of-the-art methods, including finer aspects such
    as network, computing, and storage. Additionally, the paper summarizes the challenges
    and presents a perspective on the future development direction of foundation model
    systems. Through comprehensive discussion and analysis, it hopes to provide a
    solid theoretical basis and practical guidance for future research and applications,
    promoting continuous innovation and development in foundation model systems.


    **INDEX TERMS** Foundation Model System, Training, Serving, Network, Computing,
    Storage


    #### **I. INTRODUCTION**


    T He combination of deep learning techniques and powerful computational capabilities
    continuously drives the development of artificial general intelligence, ushering
    us into the era of foundation models. However, achieving successful applications
    of foundation models is inseparable from comprehensive support at the system level.
    A foundation model system is built upon extensive training data, state-ofthe-art
    models, high-performance computing resources, and meticulously optimized training
    and serving algorithms. The primary purpose of this system is to handle complex
    tasks with heightened precision, such as GPT3 [\[1\]](#page-10-0), LLaMA [\[2\]](#page-10-1),
    PanGu-Σ [\[3\]](#page-10-2), PengCheng Mind [\[4\]](#page-10-3) etc.


    Foundation models have demonstrated extraordinary performance in many tasks. This
    has led more and more major technology giants to dedicate significant human and
    financial resources to actively develop their foundation model systems, which
    increases the parameter size (Figure [1\)](#page-1-0). However, as the parameter
    size of foundational model systems continues to grow, challenges are posed throughout
    the lifecycle of foundation models, particularly during the training and serving
    phases. In the training phase, the substantial parameter size results in significant
    demands for computation and storage, creating immense pressure on hardware resources
    and computational efficiency. Consequently, training these models usually takes
    a long time and requires efficient utilization of computational resources. In
    the serving phase, with the widespread application of foundation models, the significant
    increase in workload has become an unavoidable challenge. This heightened demand
    may lead to issues for serving systems, such as latency, performance decline,
    or resource bottlenecks. Therefore, employing highly efficient


    ![](_page_1_Figure_1.jpeg)


    <span id="page-1-0"></span>**FIGURE 1. Evolutionary Chart of Model Sizes Over
    Time.**


    <span id="page-1-1"></span>**FIGURE 2. The lifecycle of the foundation model system.**


    training and serving strategies becomes particularly crucial. Many researchers
    have actively explored and proposed effective methods for training and serving.
    However, different approaches have different application scenarios. So, it poses
    a challenge for system developers who struggle to identify the most suitable method
    for their problems. This challenge is precisely why this paper was proposed.


    Although there have been some surveys on foundation models, Most surveys [\[5\]](#page-10-4)–[\[11\]](#page-10-5)
    predominantly focus on model design and downstream task adaptation, with only
    a minority delving into foundation model training. However, there are two notable
    shortcomings in these training-centric surveys [\[12\]](#page-10-6): firstly,
    they lack in-depth exploration from the perspective of updates in network, computing,
    and storage; secondly, their primary emphasis is on the training phase, neglecting
    considerations for the serving phase. Therefore, a comprehensive survey of foundation
    model training and serving methods is essential for system developers and researchers.
    Accordingly, this paper presents an in-depth analysis of the state-of-the-art
    methods in this domain. This paper provides systems developers and researchers
    valuable information through comprehensive analysis and comparison. It assists
    them in making the right decisions when confronted with the challenges associated
    with foundation model systems. evaluation and fine-tuning involve assessing performance
    Training Dataset Foundation model


    ## **II. BASIC CONCEPTS**


    This section comprehensively explains the fundamental concepts in foundation model
    systems.


    #### *A. The lifecycle of the foundation model system*


    The lifecycle of the foundation model system (Figure [2\)](#page-1-1) encompasses
    several crucial stages. ➊ Initially, the collection and preprocessing of data
    ensure the quality and availability required for model training. Subsequently,
    choosing an appropriate model. ➋ Transitioning to the training phase, the model
    undergoes adjustments through the backpropagation algorithm, demanding substantial
    computational resources to enhance its fitting capability to the training data.
    ➌ Model


    with test data and adjusting for improved generalization. Once the model performs
    satisfactorily, it can be deployed into practical applications. ➍ In the serving
    stage, effective deployment and integration are crucial to ensuring harmonious
    collaboration with existing systems. The primary focus in this phase centers on
    performance optimization, aiming to enhance serving speed and reduce latency through
    strategies such as model quantization and hardware acceleration.


    ## *B. Transformer for foundation models*


    Transformer [\[13\]](#page-10-7) is a deep learning model architecture comprised
    of encoders and decoders. Its core innovation lies in the self-attention mechanism,
    an important component widely utilized in foundational models. The main idea is
    to enable the model to focus on dynamic associations between different positions,
    thereby better capturing long-distance interdependent features in a sentence.
    In the current field of deep learning, the Transformer architecture has become
    the preferred choice for numerous foundational models. This architecture stands
    out for its outstanding performance and flexibility, particularly in excelling
    at natural language processing tasks [\[14\]](#page-10-8). Many pivotal foundational
    models, such as GPT, LLaMA, and PengCheng Mind, have adopted the design of the
    Transformer. The successful applications of the Transformer architecture demonstrate
    its universality in foundational models, providing powerful modeling tools for
    various tasks.


    #### **III. MODEL TRAINING**


    In foundation model training, the most significant challenges are the high demands
    for memory and computational power. Therefore, this section explores the implementation
    of optimization strategies in foundation model training from three perspectives,
    network, computing, and storage, to address these challenges, as shown in Table
    [1.](#page-2-0)


    ## *A. Advanced Techniques in Parallel Computing*


    1) Data Parallelism: Accelerating Workloads Effectively


    In data parallelism, each computational node possesses a replica of the model
    and independently processes a subset


    ![](_page_2_Picture_0.jpeg)


    | Parallel Computing                                                                                   |                               |      |                                                                     |                           |               |  |  |

    |------------------------------------------------------------------------------------------------------|-------------------------------|------|---------------------------------------------------------------------|---------------------------|---------------|--|--|

    | Parallelism Type                                                                                     |
    Specific Strategy             | Year | Main Features                                                       |
    Scales (M, B, 10B, 100B+) | Open Resource |  |  |

    | Data Parallelism                                                                                     |
    DDP [15]                      | 2020 | Bucketing gradients, Skipping gradient
    synchronization              | M                         | ✓             |  |  |

    |                                                                                                      |
    Xu et al. [18]                | 2020 | Automatic cross-replica sharding                                    |
    M                         | ×             |  |  |

    |                                                                                                      |
    FSDP [17]                     | 2023 | Fully sharded data parallel                                         |
    100B+                     | ✓             |  |  |

    | Tensor Parallelism                                                                                   |
    Megatron-LM [19]              | 2021 | Weight matrix partitioned                                           |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    Optimus [20]                  | 2023 | Scalable 2D-partition paradigm                                      |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    Tesseract [22]                | 2023 | 2.5-Dimensional Matrix Multiplication                               |
    B                         | ×             |  |  |

    |                                                                                                      |
    3D Tensor Parallelism [24]    | 2021 | 3-dimensional model parallelism, Perfect
    load balance               | M                         | ×             |  |  |

    | Pipeline Parallelism                                                                                 |
    GPipe [25]                    | 2019 | Novel batchsplitting pipelining                                     |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    PipeDream [26]                | 2019 | 1F1B, Weight stashing, Vertical sync                                |
    M                         | ×             |  |  |

    |                                                                                                      |
    Megatron-LM [19]              | 2021 | Schedule with Interleaved Stages                                    |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    Chimera [30]                  | 2021 | Bidirectional pipelines                                             |
    B                         | ✓             |  |  |

    |                                                                                                      |
    PipeDream-2BM [29]            | 2021 | Memory-efficient pipeline parallelism                               |
    B                         | ×             |  |  |

    |                                                                                                      |
    FTPipe [37]                   | 2021 | Mixed-pipe partitioning, Recomputation                              |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    DAPPLE [28]                   | 2022 | Synchronous training                                                |
    B                         | ×             |  |  |

    |                                                                                                      |
    Varuna [27]                   | 2022 | Recomputation                                                       |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    Hanayo [31]                   | 2023 | Wave-like pipeline                                                  |
    100B+                     | ×             |  |  |

    |                                                                                                      |
    Mixpipe [32]                  | 2023 | Mixed scheduling, Flexible bidirectional
    pipeline                   | 10B                       | ×             |  |  |

    |                                                                                                      |
    Avgpipe [33]                  | 2023 | Elastic averaging training method                                   |
    M                         | ×             |  |  |

    |                                                                                                      |
    Bpipe [35]                    | 2023 | Activation balancing                                                |
    100B+                     | ×             |  |  |

    |                                                                                                      |
    Bamboo [36]                   | 2023 | Redundant computation, Use of preemptible
    instances                 | M                         | ×             |  |  |

    |                                                                                                      |
    Dynapipe [34]                 | 2024 | Dynamic micro-batching                                              |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    GShard [38]                   | 2021 | Sparsely-Gated Mixture-of-Experts                                   |
    100B+                     | ×             |  |  |

    |                                                                                                      |
    FastMoE [40]                  | 2021 | Open-source system based on PyTorch                                 |
    100B+                     | ✓             |  |  |

    | Expert Parallelism                                                                                   |
    FasterMoE [42]                | 2022 | Dynamic shadowing method, Novel roofline-like
    model                 | B                         | ✓             |  |  |

    |                                                                                                      |
    Lina [44]                     | 2023 | Tensor partitioning, Two-phase scheduling                           |
    B                         | ×             |  |  |

    |                                                                                                      |
    Janus [45]                    | 2023 | Data-centric paradigm                                               |
    M                         | ×             |  |  |

    |                                                                                                      |
    SmartMoE [43]                 | 2023 | Expert placement strateg                                            |
    10B                       | ×             |  |  |

    |                                                                                                      |
    Alpa [48]                     | 2022 | Two-level parallel execution, ILP Formulation                       |
    100B+                     | ✓             |  |  |

    | Hybrid Parallelism                                                                                   |
    Smith et al. [46]             | 2022 | 3D parallelism methodology                                          |
    100B+                     | ×             |  |  |

    |                                                                                                      |
    Galvatron [49]                | 2022 | Decision tree approach                                              |
    10B                       | ✓             |  |  |

    | GPU Memory Optimization                                                                              |                               |      |                                                                     |                           |               |  |  |

    | Specific Strategy<br>Main Features<br>Scales (M, B, 10B, 100B+)<br>Open Resource<br>Category<br>Year
    |                               |      |                                                                     |                           |               |  |  |

    |                                                                                                      |
    Chen et al. [50]              | 2016 | Checkpointing, Recomputation                                        |
    M                         | ×             |  |  |

    | Checkpointing and Recomputation                                                                      |
    Checkmate [51]                | 2022 | Integer linear program                                              |
    M                         | ✓             |  |  |

    | Mixed Precision Training                                                                             |
    Mixed Precision Training [52] | 2018 | Mixed precision                                                     |
    M                         | ×             |  |  |

    |                                                                                                      |
    Jia et al. [53]               | 2018 | LARS algorithm                                                      |
    M                         | ×             |  |  |

    | Memory Swapping                                                                                      |
    SwapAdvisor [56]              | 2020 | Enetic algorithms                                                   |
    M                         | ×             |  |  |

    |                                                                                                      |
    Autotm [57]                   | 2020 | Integer linear programming                                          |
    M                         | ✓             |  |  |

    |                                                                                                      |
    FlashNeuron [59]              | 2021 | SSDs for data offloading and prefetching                            |
    B                         | ✓             |  |  |

    |                                                                                                      |
    Stronghold [58]               | 2022 | Work window method                                                  |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    Patrickstar [62]              | 2022 | Chunks                                                              |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    G10 [61]                      | 2023 | Amalgamating GPU, host, flash memory into
    a unified memory space    | B                         | ✓             |  |  |

    |                                                                                                      |
    DeepUM [60]                   | 2023 | Enhances Unified Memory by prefetching
    techniques                   | B                         | ×             |  |  |

    | Zero Redundancy Optimization                                                                         |
    ZeRO [63]                     | 2020 | Zero Redundancy                                                     |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    ZeRO-Offload [64]             | 2021 | Parameters is offloaded to CPU memory                               |
    10B                       | ✓             |  |  |

    |                                                                                                      |
    ZeRO-Infinity [66]            | 2021 | Parameters is offloaded to CPU, and NVMe
    memory                     | 100B+                     | ✓             |  |  |

    |                                                                                                      |                               |      |
    Communication Optimization                                          |                           |               |  |  |

    | Category                                                                                             |
    Specific Strategy             | Year | Main Features                                                       |
    Scales (M, B, 10B, 100B+) | Open Resource |  |  |

    | Communication Optimization                                                                           |
    Bagua [67]                    | 2021 | MPI-style communication library                                     |
    M                         | ✓             |  |  |

    |                                                                                                      |
    Out-Of-Order BackProp [70]    | 2022 | Out-Of-Order Computation                                            |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    ZeRO++ [71]                   | 2023 | Weight quantization                                                 |
    100B+                     | ✓             |  |  |

    |                                                                                                      |
    Wang et al. [68]              | 2023 | Decomposing the original communication
    and computational operations | 100B+                     | ×             |  |  |

    |                                                                                                      |
    Mobius [69]                   | 2023 | Cross-mapping strategy                                              |
    B                         | ×             |  |  |

    |                                                                                                      |
    Optimus-CC [73]               | 2023 | Compression                                                         |
    B                         | ×             |  |  |

    |                                                                                                      |
    COCKTAILSGD [72]              | 2023 | Communication compression                                           |
    10B                       | ×             |  |  |

    |                                                                                                      |                               |      |                                                                     |                           |               |  |  |


    #### <span id="page-2-0"></span>**TABLE 1. Overview of network, computing, and
    storage optimization strategies in foundation model training.**


    of data assigned to it. As shown in Figure [3a](#page-3-0), each node uses its
    model replica for forward and backward propagation and gradient calculation. So,
    it requires gradient aggregation and synchronization operations to update the
    global model parameters. This distributed approach significantly reduces the computational
    load on individual nodes and speeds up the training process by parallelizing the
    workload.


    Distributed Data Parallel (DDP) [\[15\]](#page-10-9) utilizes gradient bucketing,
    computation-communication overlap, and gradient synchronization skipping to enhance
    the efficiency of distributed data parallelism. The Ring-AllReduce method [\[16\]](#page-10-19)
    effectively addresses the communication load issue in data parallelism with its
    unique design. In this method, worker nodes are organized in a ring topology,
    communicating only with adjacent nodes. In the aforementioned data parallelism
    approach, storing the entire model''s parameters on each node simplifies training
    but significantly increases memory demand, especially for foundation models. To
    solve this problem, several solutions have been proposed. Facebook introduced
    a technique called Fully Sharded Data Parallel


    ![](_page_3_Figure_1.jpeg)


    <span id="page-3-0"></span>**FIGURE 3. Schematic diagram of parallelization strategies
    in foundation model systems. Different color blocks indicate different layers
    in the network.**


    (FSDP) [\[17\]](#page-10-11) to tackle this issue. It divides model parameters
    into smaller units, restoring the complete model parameters through communication
    before computation and discarding them immediately after the calculation. Similarly,
    Xu et al. [\[18\]](#page-10-10) proposed an automatic cross-replica sharding technique
    for weight updates in data-parallel training to optimize memory and communication
    efficiency during model training.


    #### 2) Tensor Parallelism: Scaling Foundation Models


    Tensor parallelism is developed to address the challenges of training foundation
    models that exceed the memory capacity of a single device. In tensor parallelism
    (As shown in Figure [3b](#page-3-0)), the parameters and computations of the model
    are divided (or sliced) across multiple computing devices, effectively reducing
    the memory load on each device.


    Megatron-LM [\[19\]](#page-10-12) introduced an efficient form of 1D tensor parallelism.
    For a given computational task, it involves two GEMM operations and a GeLU non-linearity:
    Y = GeLU(XA), Z = Y B. A can be partitioned into - A1, A<sup>2</sup> . So each
    processor can independently compute the Y<sup>i</sup> :


    $$[Y\_1, Y\_2] = \left[ \text{GeLU} \left( X A\_1 \right), \text{GeLU} \left(
    X A\_2 \right) \right].$$


    The second weight matrix <sup>B</sup> can be split into B<sup>1</sup> B<sup>2</sup>
    , so Z is equal to - Y1, Y<sup>2</sup> B<sup>1</sup> B<sup>2</sup> . With this
    approach, YiB<sup>i</sup> can be computed separately on individual processors.
    In Transformer models, the method of 1D tensor parallelism is effectively applied
    to the computation of multi-head attention. This allows multiple processing units
    to simultaneously calculate different attention heads without waiting for the
    results of others.


    Optimus [\[20\]](#page-10-13) proposed an efficient and scalable 2D tensor parallelism.
    It is introduced based on the scalable universal matrix multiplication algorithm
    (SUMMA) [\[21\]](#page-10-20). Compared to 1D tensor parallelism, 2D parallelism
    distributes the computational load across more processing units, significantly
    enhancing overall computational efficiency. Although 2D parallelism offers a more
    fine-grained model partitioning approach, it can introduce higher communication
    overhead. To solve this, 2.5D tensor parallelism [\[22\]](#page-10-14) is introduced,
    building upon 2.5D matrix multiplication [\[23\]](#page-10-21), which leverages
    additional devices to minimize communication requirements.


    To balance computation, memory, and communication loads effectively, 3D tensor
    parallelism [\[24\]](#page-10-15) employs a 3-D Parallel Matrix Multiplication
    algorithm to accurately map and execute the computation process of the Transformer
    model. This algorithm optimizes the use of computational resources by intelligently
    distributing and computing different parts of the input and weight matrices on
    designated processors.


    # 3) Pipeline Parallelism: Enhancing Foundation Model Scalability


    In pipeline parallelism (Figure [3c](#page-3-0)), the entire model is divided
    into several stages, with each part allocated to an independent GPU. However,
    a typical issue in pipeline parallel processing is the idle time created due to
    waiting for dependent data or processing results, commonly referred to as the
    bubble phenomenon. Therefore, effectively reducing these bubbles to enhance GPU
    utilization in pipeline parallelism becomes a critical issue.


    GPipe [\[25\]](#page-10-16) is one of the first significant works to apply the
    concept of pipeline parallelism to the training of foundation models. However,
    GPipe requires waiting for each micro-batch to complete forward propagation before
    starting backward propagation, as shown in Figure [4a](#page-4-0). Therefore,
    the intermediate results (activations) produced during the forward computation
    of each micro-batch need to be cached in memory for subsequent backpropagation,
    resulting in increased memory usage. Meanwhile, this approach can also lead to
    the creation of a significant number of bubbles.


    So PipeDream [\[26\]](#page-10-17) utilizes a one-forward-one-backward (1F1B)
    strategy, as shown in Figure [4b](#page-4-0), to solve these problems, in which
    the backward propagation process immediately follows the completion of forward
    propagation for a micro-batch. However, this training mode introduces two types
    of parameter inconsistency. PipeDream utilizes weight stashing and vertical sync
    methods to address these issues. Varuna [\[27\]](#page-10-18) improves upon PipeDream
    by performing


    ![](_page_4_Picture_0.jpeg)


    ![](_page_4_Figure_1.jpeg)


    <span id="page-4-0"></span>**FIGURE 4. Schematic diagram of pipeline parallelization
    and 1F1B pipeline parallelization.**


    recomputation earlier during the backward pass, effectively reducing bubbles and
    memory usage. Meanwhile, similar to PipeDream, DAPPLE [\[28\]](#page-11-3) performs
    synchronization after completing the forward and backward propagation for microbatches.
    This synchronization ensures the consistency of model parameters across micro-batches,
    avoiding parameter inconsistency issues.


    PipeDream utilizes a weight storage scheme to use the same weight version in forward
    and backward propagation for the same input. In the worst case, the number of
    stored weight versions equals the pipeline depth. Therefore, this can result in
    increased memory consumption. PipeDream-2BM [\[29\]](#page-11-1) maintains only
    two versions of model weights within the pipeline. By storing only two versions,
    it significantly reduces memory usage. In Megatron-LM [\[19\]](#page-10-12), pipeline
    parallelism is implemented using an Interleaved Schedule approach. To reduce pipeline
    bubbles, the Interleaved Schedule method assigns each device to two sets of model
    chunks, allowing each device to handle multiple stages. By utilizing the idle
    time of devices that would otherwise be waiting for backward computation, it can
    perform forward computation for the second set of model chunks, effectively reducing
    the size of bubbles in the pipeline. In contrast, Chimera [\[30\]](#page-11-0)
    utilizes a bidirectional pipeline by deploying multiple stages of the model on
    a single GPU. Chimera minimizes idle time and maximizes GPU utilization by interleaving
    the computation of forward and backward propagation across different stages. Different
    from Chimera, Hanayo [\[31\]](#page-11-4) avoids the strategy of model replication.
    Instead, it employed a wave-like pipeline scheme, further reducing bubble rates
    and enhancing performance. Similarly employing a bidirectional pipeline, MixPipe
    [\[32\]](#page-11-5) achieves a better balance between pipeline and device utilization
    by adjusting the number of micro-batches. Additionally, MixPipe designs a hybrid
    scheduling strategy that combines 1F1B and 2F1B to achieve a more balanced memory
    usage, further decreasing bubble rates. To further reduce bubbles, AvgPipe [\[33\]](#page-11-6)
    employs the approach of multiple parallel pipelines, with each pipeline handling
    a batch of data in each iteration. It trains parallel models using an elastic
    averaging training method. By processing more batches, AvgPipe can subdivide each
    batch into finer-grained micro-batches, effectively reducing the generation of
    bubbles.


    In traditional pipelines, feeding a batch of samples with equal lengths into the
    GPU for training is common. In each batch, padding is applied to the input sequences
    to accommodate the length of the longest sequence, leading to evident memory wastage.
    Dynapipe [\[34\]](#page-11-9) introduces a method of dynamic micro-batching, where
    the core idea is to ensure consistent sequence lengths among samples within each
    micro-batch without requiring uniformity across microbatches. This approach reduces
    the padding overhead in micro-batch processing, effectively lowering memory consumption.
    To address memory balancing in the pipeline, Bpipe [\[35\]](#page-11-7) uses an
    activation balancing approach that ensures that all GPUs can fully utilize comparable
    amounts of memory by transferring intermediate activations between different GPUs
    during training. This innovation solves the problem that some GPUs may face high
    memory pressure while others fail to fully utilize the performance.


    The continuous growth of the foundation''s scale has triggered a substantial demand
    for training resources. In addressing this issue, Bamboo [\[36\]](#page-11-8)
    significantly reduces training costs by using preemptible instances optimally.
    When idle, these instances are available at a lower cost but may be preempted
    once users submit priority requests. Bamboo optimizes the training pipeline by
    introducing redundant computations to overcome this challenge. Specifically, each
    node performs computations not only on its layer but also on adjacent layers.
    Bamboo cleverly incorporates these additional computations into redundant layers,
    thus providing greater flexibility at a lower cost. The pipeline methods previously
    discussed primarily involve a simplistic partitioning of a model''s adjacent layers.
    This approach can lead to imbalanced workload distribution across GPUs. As an
    improvement, FTPipe [\[37\]](#page-11-2) introduces mixed-pipe partitioning technology.
    It employs a heuristic algorithm to allocate GPUs based on any computational blocks
    in the computation graph, not just adjacent layers.


    # 4) Expert Parallelism: Enhancing Specialized Computing Capabilities


    Expert parallelism, as depicted in Figure [3d](#page-3-0), involves segmenting
    a specific part of a model into several specialized sub-models, referred to as
    experts, and distributing them across various computational devices. A gating
    network is used to determine how to allocate input data efficiently among these
    different experts.


    Google''s GShard [\[38\]](#page-11-10) introduces the MoE [\[39\]](#page-11-40)
    structure for the first time in training foundation Transformer-based models,
    aiming to address scalability issues in foundation model training. To optimize
    the performance of the MoE model, FastMoE [\[40\]](#page-11-11) was proposed.
    It is the first highperformance MoE open-source system that supports the PyTorch
    [\[41\]](#page-11-41) framework. FastMoE pairs the FFN layer in the Transformer
    and adopts a finer parallelization strategy. This strategy significantly speeds
    up the computation of the FFN part of the Transformer model. During the training
    process of MoE systems, challenges such as dynamic load imbalance and congested
    end-to-end communication need to be addressed. To tackle these challenges, FasterMoE
    [\[42\]](#page-11-12) proposes a dynamic shadowing method to handle load imbalances.
    By dynamically adjusting task allocation and scheduling, system resources are
    utilized more evenly, improving overall efficiency.


    On the other hand, SmartMoE [\[43\]](#page-11-15) system provides comprehensive
    support for distributed training strategies. To address the dynamic computational
    workload of MoE models, the SmartMoE system introduces a unique expert placement
    strategy. Building upon the classic combination of parallel strategies, this strategy
    achieves dynamic load balancing. By intelligently adjusting the deployment positions
    of various experts in the model, the SmartMoE system effectively balances the
    computational workload and improves overall system efficiency. In distributed
    data parallelism, contention may occur between the all-to-all communication among
    MoEs and the all-reduce operations, leading to prolonged training times. Therefore,
    Lina [\[44\]](#page-11-13) integrates tensor partitioning and pipelining to perform
    micro-operation scheduling, reducing blocking periods in distributed training.
    All of the above approaches use an expert-centric paradigm, keeping the expert
    in place and providing information to the expert through an all-to-all process.
    However, Janus [\[45\]](#page-11-14) proposes a new data-centric paradigm: maintaining
    the data in place and moving the experts between GPUs. Janus hides the communication
    time by scheduling the requests of fetching experts in a fine-grained manner,
    thus reducing cross-node traffic. Moreover, Janus develops a topologyaware priority
    strategy, ensuring smooth intra-node expert exchanges without resource contention.


    # 5) Hybrid Parallelism: Combining the Power of Different Parallel Computing Approaches


    Although various parallel technologies have shown significant effects in theoretical
    and experimental research, a single parallel strategy often fails to meet the
    growing computational demands and complexity in actual deep learning model training.
    Therefore, hybrid parallelism becomes critical to addressing this challenge. The
    core of hybrid parallelism lies in its ability to make customized strategy choices
    based on the specific requirements of the task and available hardware resources,
    thereby maximizing training efficiency while ensuring model performance.


    Combining multiple parallelization techniques for enhanced efficiency is common
    when conducting pre-training of foundation models with parameter scales in tens
    to hundreds of billions. Smith et al. [\[46\]](#page-11-17) utilized a combination
    of pipeline and tensor parallelism techniques to parallelize the Transformer block
    in Megatron-Turing NLG during their training using DeepSpeed [\[47\]](#page-11-42)
    and Megatron-LM. They expanded the training scale by incorporating data parallelism,
    allowing for training on more GPUs. To simplify the application and enhance the
    efficiency of parallelization strategies, Alpa [\[48\]](#page-11-16) integrates
    all parallelization strategies into a single framework, establishing a compiler
    that automatically generates optimal parallelization strategies. Similarly, Galvatron
    [\[49\]](#page-11-18) introduces a decision tree approach that leverages logical
    intuition for pruning, thereby significantly cutting down the search space. In
    addition, Galvatron employs a dynamic programming search algorithm to determine
    the most effective hybrid parallelization strategy.


    ## *B. GPU Memory Optimization In Training*


    As the model size increases, the demand for GPU memory grows exponentially. However,
    limited by hardware resources, insufficient GPU memory often becomes a bottleneck,
    restricting the scale and performance of the training. Therefore, developing effective
    GPU memory optimization techniques is essential to reduce memory consumption.
    Subsequent sections will explore various innovative GPU memory optimization techniques
    targeting these overheads.


    1) Checkpointing and Recomputation for Memory Efficiency In foundation model training,
    activation checkpointing technology reduces memory consumption by only saving
    key activation values and uses recomputation technology to regenerate these values
    during backpropagation. This combined approach effectively balances memory usage
    and computational efficiency, enabling the training of foundation models even
    with limited hardware resources.


    It was Chen et al. [\[50\]](#page-11-19) who first proposed the concept of activation
    checkpointing to tackle the high memory consumption in foundation model training.
    By selectively removing unneeded intermediate activations in the forward propagation
    process and reconstructing them during backward propagation through additional
    computations, this method significantly reduces GPU memory usage while allowing
    for the training of more extensive networks. However, recomputation imposes an
    additional time overhead. Therefore, it requires a trade-off between training
    time and memory requirements. To address this problem, Jain et al. proposed the
    Checkmate [\[51\]](#page-11-20), which models the problem to minimize computation
    time while ensuring that task scheduling does not exceed the memory limit of the
    device. The Checkmate effectively manages memory usage by dynamically determining
    when to store activations and recompute them. This enables the training of larger-scale
    networks within the constraints of limited memory resources, providing an effective
    solution to address memory limitations in foundation model training.


    ![](_page_6_Picture_0.jpeg)


    # 2) Optimizing with Mixed Precision Training


    Mixed Precision Training [\[52\]](#page-11-21) is a technique used in foundation
    models that simultaneously employs both low-precision and high-precision data
    types. Representing the training data types as 16-bit floating-point numbers can
    reduce the amount of computation while lowering the memory requirement. However,
    the 16-bit floating-point representation will inevitably impact model convergence.
    Jia et al. [\[53\]](#page-11-22) utilized the LARS algorithm [\[54\]](#page-11-43)
    to solve this problem. The algorithm works by using different learning rates for
    different layers. However, the test found that applying the LARS algorithm to
    the training of half-precision models directly caused a great loss of accuracy.
    This is because after multiplying by the LARS coefficients, many parameters directly
    go to zero due to the small range of the half-precision values, so Jia et al.
    converted the half-precision parameters into single-precision and then combined
    them with the LARS.


    ## 3) Memory Swapping Techniques in Optimization


    The basic idea of memory swapping technology is to offload the computational burden
    from the GPU to other devices, such as CPUs or NVMe. It migrates some model parameters
    and computational tasks from the GPU to other devices. This relieves the GPU''s
    workload and enables it to handle the remaining computational tasks more efficiently.


    This idea was first introduced in vDNN [\[55\]](#page-11-44), which aims to reduce
    the pressure on the GPU memory by moving data that does not require immediate
    access from the GPU to the CPU memory. The implementation of vDNN represents an
    initial application of swapping technology. However, with technological advancements,
    more sophisticated methods have emerged. SwapAdvisor [\[56\]](#page-11-23) employs
    genetic algorithms to automatically search for the best data transfer strategy
    as an alternative to manual judgment-based approaches. The benefit of this automated
    approach is that it reduces the need for human intervention, thereby increasing
    efficiency. In contrast, Autotm [\[57\]](#page-11-24) uses an integer linear programming
    approach to search for suitable transfer strategies.


    Stronghold [\[58\]](#page-11-26) introduces a work window method, which keeps
    only part of the model''s layers and parameters in the GPU. Under this mechanism,
    the GPU processes only the model layers within the work window, transferring the
    rest to the CPU. The corresponding resources are only moved from the CPU to the
    GPU when the work window shifts. Additionally, Stronghold models the window size,
    and leverages computation and communication overlap to hide the communication
    costs between the CPU and GPU effectively. Meanwhile, FlashNeuron [\[59\]](#page-11-25)
    considers that offloading data directly to the CPU might interfere with other
    tasks running on the CPU and thus uses SSDs for data offloading and prefetching.
    DeepUM [\[60\]](#page-11-29) enhances Unified Memory (UM) by incorporating prefetching
    techniques, effectively reducing the additional overhead caused by address translations
    and page faults. Similarly, G10 [\[61\]](#page-11-28) innovatively extends the
    Unified Memory of GPUs, amalgamating GPU memory, host memory, and flash memory
    into a unified memory space. This fusion is achieved by storing flash memory page
    addresses in the UM page table. Consequently, a unified page table can point to
    host, GPU, or flash memory addresses. By preemptively analyzing the lifecycle
    of tensors, G10 enables efficient tensor swapping when needed, maximizing the
    overlap between GPU computation and tensor migration. Furthermore, Patrickstar
    [\[62\]](#page-11-27) proposes a memory management method based on chunks, a series
    of consecutive tensors of the same size. This method is similar to storing files
    in fixed-sized disk blocks in a distributed file system. During training, chunks
    with different lifecycles can share memory, reducing memory usage. Additionally,
    Patrickstar collects memory usage information during the warm-up iteration phase
    to optimize memory management.


    Beyond the methods above, other works like ZeRO-Offload and ZeRO-Infinity have
    also employed Memory Swapping Techniques. To comprehensively introduce the ZeRO
    series of research, this paper includes these additional works in the next section.


    # 4) Zero Redundancy Optimizers


    Microsoft has developed a technology called Zero Redundancy Optimization (ZeRO)
    [\[63\]](#page-11-30) as the core of the DeepSpeed distributed training framework.
    The core idea of ZeRO is to reduce the GPU memory by sacrificing some of the communication
    overhead. ZeRO divides the model parameters, gradients, and optimizer states into
    multiple parts, with each GPU maintaining only a portion of them during training
    and obtaining the rest when needed through an AllGather operation. Building upon
    the foundation laid by ZeRO, ZeRO-Offload [\[64\]](#page-11-31) leverages the
    idea of Heterogeneous DL training [\[65\]](#page-11-45) to alleviate the pressure
    on GPU memory by effectively utilizing CPU memory. It divides the model parameters
    into two parts. One part of the parameters is kept in GPU memory for efficient
    computation during forward and backward propagation. The other part of the parameters
    is offloaded to CPU memory and accessed when needed. Further advancing these concepts,
    ZeRO-Infinity [\[66\]](#page-11-32), similar to ZeRO-Offload, leverages GPU, CPU,
    and NVMe memory to enable the training of foundation models on limited resources
    without the need for code refactoring. With ZeRO-Infinity, the model parameters
    and gradients are still computed on the GPU, while the optimizer state and activations
    are offloaded to more suitable NVMe memory and CPU, respectively.


    ## *C. Communication Optimization*


    As demonstrated in the previous sections, communication overhead is a significant
    bottleneck in the distributed training of foundation deep learning models. This
    issue is especially pronounced when synchronizing model parameters, gradients,
    and optimizer states across multiple GPUs or nodes. The mainstream solutions focus
    on reducing the amount of communication, optimizing communication patterns, and
    enhancing the overlap between computation and communication.


    For instance, Gan et al. developed an MPI-style communication library called Bagua
    [\[67\]](#page-11-33). The library provides a series of flexible and modular primitives
    to support state-of-the-art system relaxation techniques of distributed training.
    Bagua achieves efficient implementation and scalability through this design for
    various cutting-edge distributed learning algorithms. The method proposed by Wang
    et al. [\[68\]](#page-11-36) involves decomposing the original communication and
    computational operations into more fine-grained tasks, thereby achieving an overlap
    between communication and computation that effectively reduces data communication
    overhead. Mobius [\[69\]](#page-11-37) introduces a pipeline strategy for heterogeneous
    memory, which overlaps communication with computation by prefetching data from
    the CPU to the GPU memory for the next stage. Additionally, it employs a Cross-mapping
    strategy to reduce communication contention, further optimizing overall performance.
    Simultaneously, Out-Of-Order Back-Prop [\[70\]](#page-11-34) maximizes the overlap
    between communication and computation by optimizing the sequence of computing
    output gradients, weight gradients, and parameter updates.


    ZeRO achieves parallel computation by distributing model weights, gradients, and
    optimizer states across multiple GPUs, increasing communication volume and frequency.
    As an improvement, ZeRO++ [\[71\]](#page-11-35) employs weight quantization, meaning
    model parameters are compressed into smaller data types (such as INT8) in real-time
    before communication, reducing the required communication bandwidth and time.
    Moreover, ZeRO++ maintains a complete model copy on each machine, enhancing intra-machine
    communication bandwidth. COCKTAILSGD [\[72\]](#page-11-39) integrates various
    communication compression techniques, cleverly overlapping communication with
    local gradient computation. During the communication steps, it combines three
    different compression techniques (random sparsification, top-K sparsification,
    and quantization) to achieve more excellent compression than each method individually.
    Lastly, Optimus-CC [\[73\]](#page-11-38) utilizes three techniques: compression
    of back-propagation gradients, merging of embedding layer synchronization operations,
    and selective phase compression to reduce inter-node communication volume. Optimus-CC
    selectively compresses based on the communication needs of different training
    stages, thus minimizing unnecessary communication overhead and enhancing overall
    training efficiency.


    ## **IV. MODEL SERVING**


    This section discusses five principal areas of optimization in foundation model
    serving systems: batch processing optimization, sparse acceleration techniques,
    resource scheduling optimization, GPU memory optimization, and multi-model inference
    (As shown in Table [2\)](#page-7-0). It presents various innovative techniques
    and technologies designed to enhance pro<span id="page-7-0"></span>**TABLE 2.
    Summary of Optimization Techniques in Foundation Model Serving**


    | Method/Framework                     | Main Features                     | Year
    |  |  |  |  |

    |--------------------------------------|-----------------------------------|------|--|--|--|--|

    | Batch Processing Optimization        |                                   |      |  |  |  |  |

    | DVABatch [74]                        | Dynamic Batching                  | 2022
    |  |  |  |  |

    | Orca [75]                            | Selective Batching                | 2022
    |  |  |  |  |

    | Sparse Acceleration Techniques       |                                   |      |  |  |  |  |

    | SparseAttention [76]                 | Structured sparse attention masks | 2023
    |  |  |  |  |

    | Deja Vu [77]                         | Use MLP to predict sparsity       | 2023
    |  |  |  |  |

    | H2O [78]                             | Sparse KV Cache                   | 2023
    |  |  |  |  |

    | STI [79]                             | Sharded Models                    | 2023
    |  |  |  |  |

    | OliVe [80]                           | Outlier Quantization              | 2023
    |  |  |  |  |

    | Resource Scheduling Optimization     |                                   |      |  |  |  |  |

    | Clockwork [81]                       | Latency Predict                   | 2020
    |  |  |  |  |

    | DeepSpeed Inference [82]             | Integrated Scheduling             | 2022
    |  |  |  |  |

    | REEF [83]                            | Real-Time Preemptive Schedule     | 2022
    |  |  |  |  |

    | AlphaServe [84]                      | Automated Model Parallelism       | 2023
    |  |  |  |  |

    | FastServe [85]                       | Preemptive Scheduling             | 2023
    |  |  |  |  |

    | SHEPHERD [88]                        | Predictive Load Management        | 2023
    |  |  |  |  |

    | OSML [89]                            | Predictive Resource Allocation    | 2023
    |  |  |  |  |

    | GPU Memory Optimization In Inference |                                   |      |  |  |  |  |

    | Gpulet [90]                          | Virtual GPU Partitioning          | 2022
    |  |  |  |  |

    | FlexGen [91]                         | Zig-Zag Block Scheduling          | 2023
    |  |  |  |  |

    | DHA [92]                             | Direct GPU Access                 | 2023
    |  |  |  |  |

    | vLLM [93]                            | PageAttention Mechanism           | 2023
    |  |  |  |  |

    | Multi-Model Inference                |                                   |      |  |  |  |  |

    | PetS [94]                            | Selective Model Sharing           | 2022
    |  |  |  |  |

    | Tabi [97]                            | Multi-Level Model Inference       | 2023
    |  |  |  |  |

    | Speculative Decoding [98]            | Speculative decoding              | 2023
    |  |  |  |  |

    | LLMCad [99]                          | Model collaboration               | 2023
    |  |  |  |  |


    cessing efficiency, minimize latency, and improve memory usage. These strategies
    are categorized within the "networkcomputing-storage" optimization framework.


    - Network optimization is accomplished through efficient batch processing and
    resource scheduling, optimizing data flow and task execution.

    - Computing optimization is characterized by multimodel inference, enabling the
    efficient utilization of computational resources.

    - Storage optimization involves GPU memory management and the application of sparse
    acceleration techniques, collectively reducing memory footprint and computational
    overhead.


    Integrating these "network-computing-storage" principles ensures a comprehensive
    optimization approach, which is crucial for the performance of foundation model
    serving systems.


    #### *A. Batch Processing Optimization*


    Batch processing allows models to handle multiple requests efficiently by grouping
    input data into batches. This method allows for more efficient use of computational
    resources


    ![](_page_8_Picture_0.jpeg)


    by leveraging parallel processing capabilities, significantly improving the throughput
    and reducing the latency of model inferences. DVABatch [\[74\]](#page-11-46) proposes
    a multi-entry and multiexit strategy that employs operations like *new*, *split*,
    and *stretch* to dynamically customize batch sizes for different stages of the
    model, thereby optimizing efficiency, throughput, and reducing latency. In addition
    to this approach, Orca [\[75\]](#page-11-47) introduces a selective batching mechanism
    that strategically applies batch processing and padding to fully connected layers,
    maximizing efficiency. Simultaneously, it refrains from applying this method to
    attention layers, minimizing memory overhead. Furthermore, Orca presents an iterative-level
    scheduling strategy that offers adaptability by enabling batch size adjustments
    after each processing iteration.


    # *B. Sparse Acceleration Techniques*


    Sparse acceleration techniques play a crucial role in optimizing the performance
    of Transformer-based foundation models when faced with limited computational and
    memory resources. These methods leverage the inherent sparsity in model parameters,
    attention mechanisms, and KV Cache to prioritize computation and storage. Transformers
    leverage a KV Cache within the attention mechanism to remember crucial parts of
    the data, which is essential for efficiency, particularly in autoregressive models
    that generate new tokens iteratively and would otherwise require costly recomputation
    of keys and values for each token. By focusing on the most influential components
    of the model and reducing the overhead on less critical areas, sparse acceleration
    approaches enable high model performance while facilitating deployment on edge
    devices and mobile platforms where resources are scarce.


    Addressing the computational intensity of self-attention mechanisms in Transformers,
    Dai et al. [\[76\]](#page-11-48) introduce a method that leverages the intrinsic
    sparsity within selfattention matrices. The method employs structured sparse attention
    masks to allocate computational resources to the most influential attention parameters,
    which are identified by analyzing the attention distribution of the model. These
    parameters shape the initial mask, designed to conform to specific patterns like
    blocks or stripes. Through entropyaware fine-tuning, this mask undergoes further
    refinement by integrating the entropy of the attention matrix''s rows into the
    model''s loss function. Another notable work is Deja Vu [\[77\]](#page-11-49),
    which offers a strategic solution by leveraging the concept of contextual sparsity.
    The proposed approach effectively identifies and activates selective attention
    heads and FFN parameters that are crucial in processing the given input. The Deja
    Vu utilizes an MLP to predict the critical attention heads and FFN parameters
    precisely. In cases where the KV Cache retrieval fails, it triggers a recomputation
    process. Another relevant work is that the H2O [\[78\]](#page-11-50) method suggests
    that in attention blocks, the cumulative attention scores of tokens follow a power-law
    distribution, with only a few tokens playing a pivotal role in generation. To
    conserve memory, H2O retains only the KV Cache for these pivotal tokens, which
    are identified as highly contributive KV Cache based on their elevated cumulative
    attention scores. This approach substantially reduces the memory requirement while
    retaining the essential KV Cache of the attention mechanism.


    In low-resource scenarios on edge devices, both computation and memory are constrained.
    STI [\[79\]](#page-11-51) tackles memory constraints and I/O delays for foundation
    models on edge devices by partitioning the model into manageable shards. A central
    scheduler orchestrates the I/O operations of these shards, considering resource
    availability and the significance of each shard. It stores shards at multiple
    precision levels and dynamically selects the optimal precision for each shard
    based on its importance, thereby optimizing both accuracy and latency. In the
    realm of model quantization acceleration, one prominent contribution is OliVe
    [\[80\]](#page-11-52). This study presents the concept of Outlier-Victim Pair
    (OVP) quantization as a key technique for effectively managing critical outliers
    with minimal reduction in model accuracy. OliVe''s innovative insight lies in
    recognizing the importance of outliers for model accuracy while identifying adjacent
    normal values, termed ''victim values'', that can be pruned without significant
    performance loss. OliVe strategically retains outliers and prunes adjacent normal
    values. This selective pruning approach aligns with hardware design principles.


    ## *C. Resource Scheduling Optimization*


    Effective resource scheduling is essential in optimizing service delivery. DeepSpeed
    Inference [\[82\]](#page-11-54) offers a multi-GPU inference solution designed
    to handle foundation models while adhering to limited GPU memory constraints.
    It introduces an inference pipeline-parallel schedule specifically tailored for
    the autoregressive Decoder in generative models, optimizing prompt processing
    and token generation to minimize latency. Moreover, DeepSpeed Inference leverages
    both GPU and CPU resources, including NVMe storage, to alleviate the burden on
    GPU memory. Furthermore, DeepSpeed Inference incorporates operator fusion within
    Transformer modules, efficiently reducing latency and increasing throughput. In
    the field of model parallelism research, AlphaServe [\[84\]](#page-11-56) enhances
    foundation model inference by employing model parallelism, which distributes models
    across multiple GPUs to overcome the limitations of single GPU memory and reduce
    request latency. AlphaServe incorporates a twolayer placement algorithm that optimizes
    the distribution of model ensembles in clusters, ensuring compliance with Service
    Level Objective (SLO) requirements. Building upon the Alpha framework, it automates
    model parallelism in inference to simplify the management of parallelism. Taking
    optimization further, FastServe [\[85\]](#page-11-57) enhances optimization through
    the careful consideration of service latency. It employs a preemptive scheduling
    mechanism alongside an innovative skip-join Multi-Level Feedback Queue scheduler.
    This combined approach aims to curtail job completion time and diminish both requests
    waiting and processing durations. Moreover, the skip-join mechanism anticipates
    the time required for the initial iteration, thus swiftly delegating the job to
    the most suitable queue. This strategic allocation aids in averting unnecessary
    queue transitions and subsequent delays. However, despite these sophisticated
    approaches, Current methods [\[86\]](#page-11-68), [\[87\]](#page-11-69) that
    make decisions for each request individually often result in GPU overprovisioning
    during short-term high loads, leading to low resource utilization. To address
    this issue, Shepherd [\[88\]](#page-11-58) improves predictability by grouping
    unpredictable individual request streams into medium-sized batches. It employs
    a two-stage scheduling algorithm. In the first stage, it utilizes long-term load
    data to divide the GPU cluster into service groups and allocate GPUs accordingly.
    In the second stage, it introduces preemptive scheduling, prioritizing larger
    batches that align with SLOs to optimize throughput even with reactive scheduling.


    In scenarios with strong latency requirements, some works have addressed the issue.
    Clockwork [\[81\]](#page-11-53) ensures predictable DNN inference times, combating
    tail latency from diverse tasks, hardware, and inputs to satisfy SLOs and minimize
    delays. By limiting options at each computational layer for uniform execution
    times and deploying a central controller that assigns tasks with known durations,
    Clockwork maintains strict timing assurances. REEF [\[83\]](#page-11-55) is a
    system designed for efficient and timely DNN inference on GPUs. It schedules tasks
    in a way that prioritizes real-time tasks, quickly interrupts other tasks if needed,
    and allocates computing units first to real-time kernels, then distributes the
    remaining units to best-effort kernels. In the field of latencysensitive services,
    OSML [\[89\]](#page-11-59) is a machine learning-based scheduler that integrates
    architectural metrics like IPC and cache misses into a predictive model for Quality
    of Service (QoS) changes. It deploys three models: Model A calculates optimal
    resource allocations and detects "resource cliffs"; Model B redistributes resources,
    prioritizing services that are sensitive to QoS degradation; and Model C dynamically
    adjusts resource allocation in real-time based on ongoing QoS assessments to maintain
    service performance.


    ## *D. GPU Memory Optimization In Inference*


    During the process of inference, the weight parameters of a model significantly
    consume GPU memory. Various studies have concentrated on optimizing these model
    parameters. For instance, FlexGen [\[91\]](#page-11-61) is a throughput-oriented
    generative inference system that optimizes offloading strategies. A standout characteristic
    of FlexGen is its zig-zag block scheduling strategy. The zig-zag block scheduling
    strategy explores the computation graph by advancing column-bycolumn and reusing
    weights within each column to minimize loading times. When the memory limits for
    activations are reached, the process transitions to the next column, optimizing
    GPU memory utilization and efficiently processing the model through a zig-zag
    pattern. Additionally, it dynamically loads and unloads activation values and
    KV Cache as required. In another study, Jeong et al. [\[92\]](#page-11-62) utilized
    Direct-Host-Access (DHA) for direct GPU memory access, reducing latency for layers
    like the embedding layer. They also applied Parallel Model Transmission, dividing
    the model per GPU for parallel loading via PCIe. The sections are then quickly
    transferred to the primary GPU using NVLink, optimizing layer execution.


    GPU memory constraints hinder foundation model inference, where the storage of
    the KV Cache is a significant memory overhead. Serving architectures use KV Cache
    to reduce re-computation, but as the token count grows, so does the cache, risking
    GPU memory overflow. To avoid this, frameworks limit iteration length and pre-allocate
    memory for KV Cache, which can lead to memory fragmentation and reduced inference
    performance. Several techniques have been proposed to optimize this aspect. The
    PageAttention mechanism proposed by vLLM [\[93\]](#page-11-63) addresses the issues
    of GPU memory over-allocation and fragmentation. It accomplishes this by emulating
    OS page table mapping and segmenting GPU memory into blocks. A block mapping table
    is then used to ensure logically sequential but physically discrete storage. This
    dynamic approach effectively meets the demand of the KV Cache, reducing memory
    fragmentation and improving inference throughput. Drawing inspiration from the
    virtual nature of operating systems, The gpulet [\[90\]](#page-11-60) concept
    introduces an abstraction for partitioning GPUs, creating virtual GPUs that possess
    a fraction of the physical GPU resources. The proposed multidimensional search-based
    scheduling framework optimizes GPU tasks by considering data batch sizes along
    with the temporal and spatial sharing of resources.


    ## *E. Multi-Model Inference*


    Multi-model inference involves utilizing multiple models for serving. These models
    can be of the same type or different types, often with varying architectures.
    An important research question in this context is how to effectively combine these
    diverse models and optimize resource allocation to achieve optimal performance.
    In the context of multi-task models created through fine-tuning, PetS [\[94\]](#page-11-64)
    introduces an innovative framework for multi-task Parameter Efficient Transformers
    (PET) that processes various tasks in a unified manner. Traditional fine-tuning
    of the entire model for each task incurs substantial memory overhead. PetS circumvents
    this by employing parameter-efficient fine-tuning methods such as Adapters [\[95\]](#page-11-70),
    [\[96\]](#page-11-71), splitting the model into a shared core and task-specific
    small operators. This architecture allows for shared base model usage across tasks,
    reducing memory demands and streamlining model deployment. In the context of hierarchical
    models ranging from small to large, one approach is presented by Tabi [\[97\]](#page-11-65).
    Tabi leverages the observation that smaller models often exhibit predictive capabilities
    similar to larger models by implementing a multi-level inference engine. It employs
    well-calibrated


    ![](_page_10_Picture_0.jpeg)


    confidence scores using temperature scaling to determine whether a query can be
    promptly resolved using the smaller model or if it should be escalated to the
    larger model. For escalated queries, Tabi reduces system overhead by employing
    attention-based word pruning and a weighted ensemble approach. Another technique
    introduced by Google Research is Speculative Decoding [\[98\]](#page-11-66), which
    aims to accelerate the inference process for language models. This method involves
    a smaller model generating tokens sequentially while a larger model simultaneously
    validates the correctness of each token in parallel. The larger model verifies
    the sequence of tokens produced by the smaller model, enabling the generation
    of multiple tokens within a single iteration of the larger model. LLMCad [\[99\]](#page-11-67)
    differs from Google''s Speculative Decoding by employing a tree-based token generation
    approach that facilitates the concurrent evaluation of multiple tokens. To accomplish
    this, LLMCad utilizes a smaller language model to construct a comprehensive vocabulary
    tree comprising various word paths. The larger LLM then efficiently and concurrently
    evaluates these paths.


    ## **V. CHALLENGE AND FUTURE DIRECTIONS**


    ➊ Privacy protection. Regarding privacy protection, the key challenge for foundation
    models lies in the potential unauthorized collection, usage, and inadvertent disclosure
    of personal information. Future efforts should focus on incorporating privacy
    protection mechanisms into the design and application of models to ensure robust
    safeguards for user data, preventing unauthorized use and disclosure threats.
    ➋ Security. Foundation models exhibit a relatively weak ability to defend against
    malicious attacks, making them susceptible to activities such as command injection
    and prompt injection. Particularly in critical domains such as politics, military,
    finance, and healthcare, any form of malicious attack could severely affect the
    stability of national society and the safety of people''s lives and property.
    Therefore, future efforts must focus on enhancing security measures for foundation
    models to ensure their reliable protection in critical domains.


    ➌ Energy sustainability. Foundation systems face a significant challenge in terms
    of energy sustainability during both training and serving. This entails a high
    demand for substantial computational resources, which may result in adverse environmental
    impacts. The key to future efforts lies in enhancing the energy efficiency of
    models and adopting more energy-efficient hardware innovations. Through innovative
    green computing and sustainable development, these efforts aim to make foundation
    model systems more environmentally friendly and efficient, reducing energy dependence
    and mitigating environmental impact.


    # **VI. CONCLUSION**


    This survey delves into the training and serving methods of foundation model systems
    from the perspectives of network, computing, and storage. In the training section,
    it discusses various parallel computing strategies. Each strategy has unique advantages
    and application scenarios. Additionally, it explores GPU memory optimization and
    communication optimization techniques. The serving section discusses key technologies
    such as batch processing, sparse acceleration, resource scheduling, GPU memory
    optimization, and multimodel inference. These strategies are essential for ensuring
    the efficiency and practicality of the foundation model system in real-world scenarios.
    In summary, the training and serving of foundation model systems is an evolving
    field. With the emergence of new technologies, it anticipates solving more challenges
    and further advancing the field of artificial general intelligence.


    ## **REFERENCES**


    - <span id="page-10-0"></span>[1] Brown T, et al. "Language models are few-shot
    learners.", NeurIPS, 2020.

    - <span id="page-10-1"></span>[2] Touvron H, et al. "Llama: Open and efficient
    foundation language models.", arXiv, 2023.

    - <span id="page-10-2"></span>[3] Ren X, et al. "PanGu-Σ: Towards Trillion Parameter
    Language Model with Sparse Heterogeneous Computing.", arXiv, 2023.

    - <span id="page-10-3"></span>[4] https://cloudbrain.pcl.ac.cn/

    - <span id="page-10-4"></span>[5] Chang Y, et al. "A survey on evaluation of large
    language models." arXiv, 2023.

    - [6] Hadi M U, et al. "Large Language Models: A Comprehensive Survey of its Applications,
    Challenges, Limitations, and Future Prospects." arXiv,2023.

    - [7] Zhao H, et al. "Explainability for Large Language Models: A Survey." arXiv,
    2023.

    - [8] Wang X, et al. "Large-scale multi-modal pre-trained models: A comprehensive
    survey." Machine Intelligence Research, 2023.

    - [9] Yin S, Shukang, et al. "A Survey on Multimodal Large Language Models." arXiv,
    2023.

    - [10] Zhou Y, et al. "Vision+ Language Applications: A Survey." CVPR. 2023.

    - <span id="page-10-5"></span>[11] Zhou C, et al. "A comprehensive survey on pretrained
    foundation

    - models: A history from bert to chatgpt.", arXiv, 2023. [12] Zhao W X, et al.
    "A survey of large language models." arXiv ,2023.

    - <span id="page-10-7"></span><span id="page-10-6"></span>[13] Vaswani A, et al.
    "Attention is all you need." NeurIP, 2017.

    - <span id="page-10-8"></span>[14] Devlin, et al. "Bert: Pre-training of deep
    bidirectional transformers for language understanding." NAACL,2018.

    - <span id="page-10-9"></span>[15] Li S, et al. "PyTorch distributed: experiences
    on accelerating data parallel training." VLDB, 2020.

    - <span id="page-10-19"></span>[16] Gibiansky, et al. "Bringing HPC techniques
    to deep learning." Baidu Research, Tech. Rep. (2017).

    - <span id="page-10-11"></span>[17] Zhao Y, et al. "PyTorch FSDP: Experiences
    on Scaling Fully Sharded Data Parallel.",VLDB, 2023.

    - <span id="page-10-10"></span>[18] Xu Y, et al. "Automatic cross-replica sharding
    of weight update in data-parallel training." arXiv, 2020.

    - <span id="page-10-12"></span>[19] Narayanan D, et al. "Efficient large-scale
    language model training on gpu clusters using megatron-lm.", SC, 2021.

    - <span id="page-10-13"></span>[20] Xu Q, et al. "An efficient 2d method for training
    super-large deep learning models.", IPDPS, 2023.

    - <span id="page-10-20"></span>[21] Van De Geijn R A, et al. "SUMMA: Scalable
    universal matrix multiplication algorithm." Concurrency: Practice and Experience,
    1997.

    - <span id="page-10-14"></span>[22] Wang B, et al. "Tesseract: Parallelize the
    Tensor Parallelism Efficiently.", ICPP, 2022

    - <span id="page-10-21"></span>[23] Solomonik E, et al. "Communication-optimal
    parallel 2.5 D matrix multiplication and LU factorization algorithms." European
    Conference on Parallel Processing. Berlin, Heidelberg: Springer Berlin Heidelberg,
    2011.

    - <span id="page-10-15"></span>[24] Bian Z, et al. "Maximizing parallelism in
    distributed training for huge neural networks." arXiv, 2021.

    - <span id="page-10-16"></span>[25] Huang Y, et al. "Gpipe: Efficient training
    of giant neural networks using pipeline parallelism.", NeurIPS, 2019.

    - <span id="page-10-17"></span>[26] Narayanan D, et al. "PipeDream: generalized
    pipeline parallelism for DNN training.", SOSP, 2019.

    - <span id="page-10-18"></span>[27] Athlur S, et al. "Varuna: scalable, low-cost
    training of massive deep learning models.", EuroSys, 2022.

    - <span id="page-11-3"></span>[28] Fan S, et al. "DAPPLE: A pipelined data parallel
    approach for training large models.", PPoPP, 2021.

    - <span id="page-11-1"></span>[29] Narayanan D, et al. "Memory-efficient pipeline-parallel
    dnn training.", ICML, 2021.

    - <span id="page-11-0"></span>[30] Li S, et al. "Chimera: efficiently training
    large-scale neural networks with bidirectional pipelines.", SC, 2021.

    - <span id="page-11-4"></span>[31] Liu Z, et al. "Hanayo: Harnessing Wave-like
    Pipeline Parallelism for Enhanced Large Model Training Efficiency.", SC, 2023.

    - <span id="page-11-5"></span>[32] Zhang W, et al. "MixPipe: Efficient Bidirectional
    Pipeline Parallelism for Training Large-Scale Models." DAC, 2023.

    - <span id="page-11-6"></span>[33] Chen Z, et al. "Elastic Averaging for Efficient
    Pipelined DNN Training.", PPoPP, 2023.

    - <span id="page-11-9"></span>[34] Jiang C, et al. "DynaPipe: Optimizing Multi-task
    Training through Dynamic Pipelines.", EuroSys, 2024.

    - <span id="page-11-7"></span>[35] Kim T, et al. "BPIPE: memory-balanced pipeline
    parallelism for training large language models.", ICML, 2023.

    - <span id="page-11-8"></span>[36] Thorpe J, et al. "Bamboo: Making Preemptible
    Instances Resilient for Affordable Training of Large DNNs.", NSDI, 2023.

    - <span id="page-11-2"></span>[37] Eliad S, et al. "Fine-tuning giant neural networks
    on commodity hardware with automatic pipeline model parallelism.", ATC 2021.

    - <span id="page-11-10"></span>[38] Lepikhin D, et al. "Gshard: Scaling giant
    models with conditional computation and automatic sharding.", ICLR, 2021.

    - <span id="page-11-40"></span>[39] Jacobs R A, et al. "Adaptive mixtures of local
    experts." Neural computation, 1991

    - <span id="page-11-11"></span>[40] He J, et al. "Fastmoe: A fast mixture-of-expert
    training system.", arXiv, 2021.

    - <span id="page-11-41"></span>[41] Paszke A, et al. "Pytorch: An imperative style,
    high-performance deep learning library.", NeurIPS, 2019.

    - <span id="page-11-12"></span>[42] He J, et al. "FasterMoE: modeling and optimizing
    training of largescale dynamic pre-trained models.", PPoPP, 2022.

    - <span id="page-11-15"></span>[43] Zhai M, et al. "SmartMoE: Efficiently Training
    Sparsely-Activated Models through Combining Offline and Online Parallelization.",
    ATC 2023.

    - <span id="page-11-13"></span>[44] Li J, et al. "Accelerating Distributed MoE
    Training and Inference with Lina.", ATC, 2023.

    - <span id="page-11-14"></span>[45] Liu J, et al. "Janus: A Unified Distributed
    Training Framework for Sparse Mixture-of-Experts Models.", SIGCOMM, 2023.

    - <span id="page-11-17"></span>[46] Smith S, et al. "Using deepspeed and megatron
    to train megatronturing nlg 530b, a large-scale generative language model." arXiv,
    2022.

    - <span id="page-11-42"></span>[47] Rasley J, et al. "Deepspeed: System optimizations
    enable training deep learning models with over 100 billion parameters.", KDD,
    2020.

    - <span id="page-11-16"></span>[48] Zheng L, et al. "Alpa: Automating inter-and
    Intra-Operator parallelism for distributed deep learning.", OSDI, 2022.

    - <span id="page-11-18"></span>[49] Miao X, et al. "Galvatron: Efficient Transformer
    Training over Multiple GPUs Using Automatic Parallelism.", VLDB, 2022.

    - <span id="page-11-19"></span>[50] Chen T, et al. "Training deep nets with sublinear
    memory cost." arXiv, 2016.

    - <span id="page-11-20"></span>[51] Jain P, et al. "Checkmate: Breaking the memory
    wall with optimal tensor rematerialization.", MLSys, 2022.

    - <span id="page-11-21"></span>[52] Micikevicius P, et al. "Mixed precision training.",
    ICLR, 2018

    - <span id="page-11-22"></span>[53] Jia X, et al. "Highly scalable deep learning
    training system with mixedprecision: Training imagenet in four minutes." arXiv,
    2018.

    - <span id="page-11-43"></span>[54] You Y, et al. "Imagenet training in minutes.",
    ICPP, 2018.

    - <span id="page-11-44"></span>[55] Rhu M, et al. "vDNN: Virtualized deep neural
    networks for scalable, memory-efficient neural network design.",MICRO, 2016.

    - <span id="page-11-23"></span>[56] Huang C C, et al. "Swapadvisor: Pushing deep
    learning beyond the gpu memory limit via smart swapping.", ASPLOS, 2020.

    - <span id="page-11-24"></span>[57] Hildebrand M, et al. "Autotm: Automatic tensor
    movement in heterogeneous memory systems using integer linear programming.", ASP-LOS,
    2020.

    - <span id="page-11-26"></span>[58] Sun X, et al. "Stronghold: fast and affordable
    billion-scale deep learning model training.", SC, 2022.

    - <span id="page-11-25"></span>[59] Bae J, et al. "FlashNeuron:SSD-Enabled Large-Batch
    Training of Very Deep Neural Networks.", FAST, 2021.

    - <span id="page-11-29"></span>[60] Jung J, et al. "DeepUM: Tensor Migration and
    Prefetching in Unified Memory.", ASPLOS, 2023.

    - <span id="page-11-28"></span>[61] Zhang H, et al. "G10: Enabling An Efficient
    Unified GPU Memory and Storage Architecture with Smart Tensor Migrations.", MICRO,
    2023.

    - <span id="page-11-27"></span>[62] Fang J, et al. "Parallel Training of Pre-Trained
    Models via Chunk-Based Dynamic Memory Management.", TPDS, 2022.

    - <span id="page-11-30"></span>[63] Rajbhandari S, et al. "Zero: Memory optimizations
    toward training trillion parameter models." SC, 2020.

    - <span id="page-11-31"></span>[64] Ren J, et al. "ZeRO-Offload: Democratizing
    Billion-Scale model training.", ATC, 2021.

    - <span id="page-11-45"></span>[65] Huang C C, et al. "Swapadvisor: Pushing deep
    learning beyond the gpu memory limit via smart swapping.", ASPLOS, 2020.

    - <span id="page-11-32"></span>[66] Rajbhandari S, et al. "Zero-infinity: Breaking
    the gpu memory wall for extreme scale deep learning.",SC, 2021.

    - <span id="page-11-33"></span>[67] Gan S, et al. "Bagua: scaling up distributed
    learning with system relaxations.", arXiv,2021.

    - <span id="page-11-36"></span>[68] Wang S, et al. "Overlap communication with
    dependent computation via decomposition in large deep learning models.", ASPLOS,
    2023.

    - <span id="page-11-37"></span>[69] Feng Y, et al. "Mobius: Fine tuning large-scale
    models on commodity gpu servers.",ASPLOS, 2023.

    - <span id="page-11-34"></span>[70] Oh H, et al. "Out-of-order backprop: An effective
    scheduling technique for deep learning.", EuroSys, 2022.

    - <span id="page-11-35"></span>[71] Wang G, et al. "ZeRO++: Extremely Efficient
    Collective Communication for Giant Model Training." arXiv, 2023.

    - <span id="page-11-39"></span>[72] Wang J, et al. "CocktailSGD: Fine-tuning foundation
    models over 500Mbps networks.", ICML, 2023.

    - <span id="page-11-38"></span>[73] Song J, et al. "Optimus-CC: Efficient Large
    NLP Model Training with 3D Parallelism Aware Communication Compression.",ASPLOS,
    2023.

    - <span id="page-11-46"></span>[74] Cui W, et al. "DVABatch: Diversity-aware Multi-Entry
    Multi-Exit Batching for Efficient Processing of DNN Services on GPUs.", ATC, 2022.

    - <span id="page-11-47"></span>[75] Yu G I, et al. "Orca: A distributed serving
    system for Transformer-Based generative models.", OSDI, 2022.

    - <span id="page-11-48"></span>[76] Dai S, et al. "Efficient Transformer Inference
    with Statically Structured Sparse Attention.", DAC, 2023.

    - <span id="page-11-49"></span>[77] Liu Z, et al. "Deja Vu: Contextual Sparsity
    for Efficient LLMs at Inference Time.", ICML, 2023.

    - <span id="page-11-50"></span>[78] Zhang Z, et al. "H2O: Heavy-Hitter Oracle
    for Efficient Generative Inference of Large Language Models", ICML, 2023.

    - <span id="page-11-51"></span>[79] Guo L, et al. "STI: Turbocharge NLP Inference
    at the Edge via Elastic Pipelining.",ASPLOS, 2023.

    - <span id="page-11-52"></span>[80] Guo C, et al. "OliVe: Accelerating Large Language
    Models via Hardware-friendly Outlier-Victim Pair Quantization.", ISCA, 2023.

    - <span id="page-11-53"></span>[81] Gujarati A, et al. "Serving DNNs like Clockwork:
    Performance Predictability from the Bottom Up", OSDI, 2020

    - <span id="page-11-54"></span>[82] Aminabadi R Y, et al. "DeepSpeed-inference:
    enabling efficient inference of transformer models at unprecedented scale." SC,
    2022.

    - <span id="page-11-55"></span>[83] Han M, et al. "Microsecond-scale Preemption
    for Concurrent GPUaccelerated DNN Inferences", OSDI, 2022

    - <span id="page-11-56"></span>[84] Li Z, et al. "AlpaServe: Statistical Multiplexing
    with Model Parallelism for Deep Learning Serving.", OSDI, 2023.

    - <span id="page-11-57"></span>[85] Wu B, et al. "Fast Distributed Inference Serving
    for Large Language Models." arXiv, 2023.

    - <span id="page-11-68"></span>[86] Crankshaw D, et al. "InferLine: latency-aware
    provisioning and scaling for prediction serving pipelines.", SoCC, 2020.

    - <span id="page-11-69"></span>[87] Romero F, et al. "INFaaS: Automated Model-less
    Inference Serving.", ATC, 2021.

    - <span id="page-11-58"></span>[88] Zhang H, et al. "SHEPHERD: Serving DNNs in
    the Wild.", NSDI, 2023.

    - <span id="page-11-59"></span>[89] Liu L, et al. "Intelligent Resource Scheduling
    for Co-located Latencycritical Services: A Multi-Model Collaborative Learning
    Approach.", FAST, 2023.

    - <span id="page-11-60"></span>[90] Choi S, et al. "Serving Heterogeneous Machine
    Learning Models on Multi-GPU Servers with Spatio-Temporal Sharing", ATC, 2022

    - <span id="page-11-61"></span>[91] Sheng Y, et al. "FlexGen: High-Throughput
    Generative Inference of Large Language Models with a Single GPU.", ICML, 2023.

    - <span id="page-11-62"></span>[92] Jeong J, et al. "Fast and Efficient Model
    Serving Using Multi-GPUs with Direct-Host-Access.", EuroSys, 2023.

    - <span id="page-11-63"></span>[93] Kwon W, et al. "Efficient memory management
    for large language model serving with pagedattention.",SOSP, 2023.

    - <span id="page-11-64"></span>[94] Zhou Z, et al. "PetS: A Unified Framework
    for Parameter-Efficient Transformers Serving.", ATC, 2022.

    - <span id="page-11-70"></span>[95] Lin Z, et al. "The adapter-bot: All-in-one
    controllable conversational model.", AAAI, 2021.

    - <span id="page-11-71"></span>[96] Wang R, et al. "K-adapter: Infusing knowledge
    into pre-trained models with adapters." arXiv, 2020.

    - <span id="page-11-65"></span>[97] Wang Y, et al. "Tabi: An Efficient Multi-Level
    Inference System for Large Language Models.", EuroSys, 2023.

    - <span id="page-11-66"></span>[98] Leviathan Y, et al. "Fast Inference from Transformers
    via Speculative Decoding", ICML, 2023

    - <span id="page-11-67"></span>[99] Xu D, et al. "LLMCad: Fast and Scalable On-device
    Large Language Model Inference.", arxiv, 2023.'
  decisions:
    evaluation_prompt: 'Disqualified. Reason: The abstract and introduction contain
      only conceptual discussions and proposals without any mention of empirical,
      experimental, or quantitative evaluation. There are no references to experiments,
      metrics, or structured evaluation methods.'
    related_work_prompt: 'Qualified. Reason: The paper references prior work by mentioning
      existing foundation models (e.g., GPT-3, LLaMA, PanGu-Σ, PengCheng Mind) and
      discusses previous surveys on foundation models, highlighting their shortcomings
      and the need for a comprehensive survey. This indicates engagement with prior
      research.'
    novelty_prompt: 'Disqualified: no novelty. Reason: The paper primarily presents
      a survey of existing methods related to training and serving foundation models
      without introducing any new methods, models, or frameworks. There are no explicit
      claims of novelty or new contributions in the abstract or introduction.'
    review_only_prompt: 'Disqualified: review paper. Reason: The title suggests it
      is a survey, and the abstract and introduction describe the paper as primarily
      summarizing existing work without proposing new methods, results, or tools.'
  llm_input_used: '## Abstract

    Foundation models (e.g., ChatGPT, DALL-E, PengCheng Mind, PanGu-$\Sigma$)

    have demonstrated extraordinary performance in key technological areas, such as

    natural language processing and visual recognition, and have become the

    mainstream trend of artificial general intelligence. This has led more and more

    major technology giants to dedicate significant human and financial resources

    to actively develop their foundation model systems, which drives continuous

    growth of these models'' parameters. As a result, the training and serving of

    these models have posed significant challenges, including substantial computing

    power, memory consumption, bandwidth demands, etc. Therefore, employing

    efficient training and serving strategies becomes particularly crucial. Many

    researchers have actively explored and proposed effective methods. So, a

    comprehensive survey of them is essential for system developers and

    researchers. This paper extensively explores the methods employed in training

    and serving foundation models from various perspectives. It provides a detailed

    categorization of these state-of-the-art methods, including finer aspects such

    as network, computing, and storage. Additionally, the paper summarizes the

    challenges and presents a perspective on the future development direction of

    foundation model systems. Through comprehensive discussion and analysis, it

    hopes to provide a solid theoretical basis and practical guidance for future

    research and applications, promoting continuous innovation and development in

    foundation model systems.


    ## Introduction

    T He combination of deep learning techniques and powerful computational capabilities
    continuously drives the development of artificial general intelligence, ushering
    us into the era of foundation models. However, achieving successful applications
    of foundation models is inseparable from comprehensive support at the system level.
    A foundation model system is built upon extensive training data, state-ofthe-art
    models, high-performance computing resources, and meticulously optimized training
    and serving algorithms. The primary purpose of this system is to handle complex
    tasks with heightened precision, such as GPT3 [\[1\]](#page-10-0), LLaMA [\[2\]](#page-10-1),
    PanGu-Σ [\[3\]](#page-10-2), PengCheng Mind [\[4\]](#page-10-3) etc.


    Foundation models have demonstrated extraordinary performance in many tasks. This
    has led more and more major technology giants to dedicate significant human and
    financial resources to actively develop their foundation model systems, which
    increases the parameter size (Figure [1\)](#page-1-0). However, as the parameter
    size of foundational model systems continues to grow, challenges are posed throughout
    the lifecycle of foundation models, particularly during the training and serving
    phases. In the training phase, the substantial parameter size results in significant
    demands for computation and storage, creating immense pressure on hardware resources
    and computational efficiency. Consequently, training these models usually takes
    a long time and requires efficient utilization of computational resources. In
    the serving phase, with the widespread application of foundation models, the significant
    increase in workload has become an unavoidable challenge. This heightened demand
    may lead to issues for serving systems, such as latency, performance decline,
    or resource bottlenecks. Therefore, employing highly efficient


    ![](_page_1_Figure_1.jpeg)


    <span id="page-1-0"></span>**FIGURE 1. Evolutionary Chart of Model Sizes Over
    Time.**


    <span id="page-1-1"></span>**FIGURE 2. The lifecycle of the foundation model system.**


    training and serving strategies becomes particularly crucial. Many researchers
    have actively explored and proposed effective methods for training and serving.
    However, different approaches have different application scenarios. So, it poses
    a challenge for system developers who struggle to identify the most suitable method
    for their problems. This challenge is precisely why this paper was proposed.


    Although there have been some surveys on foundation models, Most surveys [\[5\]](#page-10-4)–[\[11\]](#page-10-5)
    predominantly focus on model design and downstream task adaptation, with only
    a minority delving into foundation model training. However, there are two notable
    shortcomings in these training-centric surveys [\[12\]](#page-10-6): firstly,
    they lack in-depth exploration from the perspective of updates in network, computing,
    and storage; secondly, their primary emphasis is on the training phase, neglecting
    considerations for the serving phase. Therefore, a comprehensive survey of foundation
    model training and serving methods is essential for system developers and researchers.
    Accordingly, this paper presents an in-depth analysis of the state-of-the-art
    methods in this domain. This paper provides systems developers and researchers
    valuable information through comprehensive analysis and comparison. It assists
    them in making the right decisions when confronted with the challenges associated
    with foundation model systems. evaluation and fine-tuning involve assessing performance
    Training Dataset Foundation model'
  token_usage: 4909
  time_usage: 4.730292081832886
- title: "A Survey on Verification and Validation, Testing and Evaluations of\n  Neurosymbolic\
    \ Artificial Intelligence"
  abstract: 'Neurosymbolic artificial intelligence (AI) is an emerging branch of AI
    that

    combines the strengths of symbolic AI and sub-symbolic AI. A major drawback of

    sub-symbolic AI is that it acts as a "black box", meaning that predictions are

    difficult to explain, making the testing & evaluation (T&E) and validation &

    verification (V&V) processes of a system that uses sub-symbolic AI a challenge.

    Since neurosymbolic AI combines the advantages of both symbolic and

    sub-symbolic AI, this survey explores how neurosymbolic applications can ease

    the V&V process. This survey considers two taxonomies of neurosymbolic AI,

    evaluates them, and analyzes which algorithms are commonly used as the symbolic

    and sub-symbolic components in current applications. Additionally, an overview

    of current techniques for the T&E and V&V processes of these components is

    provided. Furthermore, it is investigated how the symbolic part is used for T&E

    and V&V purposes in current neurosymbolic applications. Our research shows that

    neurosymbolic AI as great potential to ease the T&E and V&V processes of

    sub-symbolic AI by leveraging the possibilities of symbolic AI. Additionally,

    the applicability of current T&E and V&V methods to neurosymbolic AI is

    assessed, and how different neurosymbolic architectures can impact these

    methods is explored. It is found that current T&E and V&V techniques are partly

    sufficient to test, evaluate, verify, or validate the symbolic and sub-symbolic

    part of neurosymbolic applications independently, while some of them use

    approaches where current T&E and V&V methods are not applicable by default, and

    adjustments or even new approaches are needed. Our research shows that there is

    great potential in using symbolic AI to test, evaluate, verify, or validate the

    predictions of a sub-symbolic model, making neurosymbolic AI an interesting

    research direction for safe, secure, and trustworthy AI.'
  url: http://arxiv.org/abs/2401.03188v2
  keywords: Neurosymbolic AI, Validation, Verification, Evaluation, Testing, Deep
    Learning, Safety, Security, Trustworthiness
  document: '© 2024 IEEE. Personal use of this material is permitted. Permission from
    IEEE must be obtained for all other uses, in any current or future media, including
    reprinting/republishing this material for advertising or promotional purposes,
    creating new collective works, for resale or redistribution to servers or lists,
    or reuse of any copyrighted component of this work in other works. DOI: [10.1109/TAI.2024.3351798](https://www.doi.org/10.1109/TAI.2024.3351798)


    arXiv:2401.03188v2 [cs.AI] 10 Jan 2024


    1


    # A Survey on Verification and Validation, Testing and Evaluations of Neurosymbolic
    Artificial Intelligence


    Justus Renkhoff <sup>∗</sup> , Ke Feng <sup>∗</sup> , Marc Meier-Doernberg, Alvaro
    Velasquez, and Houbing Herbert Song, *Fellow, IEEE*


    *Abstract*—Neurosymbolic artificial intelligence (AI) is an emerging branch of
    AI that combines the strengths of symbolic AI and sub-symbolic AI. Symbolic AI
    is based on the idea that intelligence can be represented using semantically meaningful
    symbolic rules and representations, while deep learning (DL), or sometimes called
    sub-symbolic AI, is based on the idea that intelligence emerges from the collective
    behavior of artificial neurons that are connected to each other. A major drawback
    of DL is that it acts as a "black box", meaning that predictions are difficult
    to explain, making the testing & evaluation (T&E) and validation & verification
    (V&V) processes of a system that uses sub-symbolic AI a challenge. Since neurosymbolic
    AI combines the advantages of both symbolic and sub-symbolic AI, this survey explores
    how neurosymbolic applications can ease the V&V process. This survey considers
    two taxonomies of neurosymbolic AI, evaluates them, and analyzes which algorithms
    are commonly used as the symbolic and sub-symbolic components in current applications.
    Additionally, an overview of current techniques for the T&E and V&V processes
    of these components is provided. Furthermore, it is investigated how the symbolic
    part is used for T&E and V&V purposes in current neurosymbolic applications. Our
    research shows that neurosymbolic AI has great potential to ease the T&E and V&V
    processes of sub-symbolic AI by leveraging the possibilities of symbolic AI. Additionally,
    the applicability of current T&E and V&V methods to neurosymbolic AI is assessed,
    and how different neurosymbolic architectures can impact these methods is explored.
    It is found that current T&E and V&V techniques are partly sufficient to test,
    evaluate, verify, or validate the symbolic and sub-symbolic part of neurosymbolic
    applications independently, while some of them use approaches where current T&E
    and V&V methods are not applicable by default, and adjustments or even new approaches
    are needed. Our research shows that there is great potential in using symbolic
    AI to test, evaluate, verify, or validate the predictions of a sub-symbolic model,
    making neurosymbolic AI an interesting research direction for safe, secure, and
    trustworthy AI.


    #### *Impact Statement*—Neurosymbolic AI allows the combination


    Manuscript received January 31, 2023. This work was supported in part by the U.S.
    National Science Foundation under Grant No. 2309760 and Grant No. 2317117.


    Justus Renkhoff and Houbing Herbert Song are with the Security and Optimization
    for Networked Globe Laboratory (SONG Lab), Department of Information Systems,
    University of Maryland, Baltimore County, Baltimore, MD 21250 USA (e-mail: justusr1@umbc.edu;
    h.song@ieee.org).


    Ke Feng is with the Department of Electrical Engineering and Computer Science,
    Embry-Riddle Aeronautical University, Daytona Beach, FL 32114 USA (e-mail: fengk2@my.erau.edu).


    Marc Meier-Doernberg is with the Department of Electrical Engineering and Computer
    Science, Embry-Riddle Aeronautical University, Daytona Beach, FL 32114 USA (e-mail:
    meierdom@my.erau.edu).


    Alvaro Velasquez is with the Department of Computer Science, University of Colorado,
    Boulder, CO 80309 USA (e-mail: alvaro.velasquez@colorado.edu).


    \*Justus Renkhoff and Ke Feng are co-first authors.


    of symbolic representations or knowledge with the abstraction capabilities of
    sub-symbolic AI. This poses new challenges for the AI community, but also offers
    many new opportunities. As neurosymbolic AI is well suited for safety-critical
    domains such as autonomous systems, we aim to connect the two fields T&E/V&V and
    neurosymbolic AI with our survey. Since neurosymbolic AI consists of several components,
    our research provides an overview of individual aspects regarding the T&E/V&V
    of these components. Through this, we influence current research in the field
    of T&E/V&V by highlighting opportunities as well as open challenges that emerge
    from neurosymbolic AI. Our research demonstrates that by combining symbolic and
    sub-symbolic AI, it is possible to test, evaluate, verify and validate predictions
    made by non-transparent sub-symbolic models. Accordingly, we provide an overview
    of current applications leveraging different architectures and combinations of
    symbolic and sub-symbolic AI, aiming to either test and evaluate in order to verify
    and validate predictions or to ease the T&E/V&V processes. In addition, the evaluation
    of current T&E/V&V methods for their applicability to neurosymbolic applications
    revealed a need for testing frameworks that focus on neurosymbolic AI. As a result,
    we provide other researchers with possible directions for future research in the
    field of T&E/V&V of neurosymbolic AI.


    *Index Terms*—Neurosymbolic AI, Validation, Verification, Evaluation, Testing,
    Deep Learning, Safety, Security, Trustworthiness


    ## I. INTRODUCTION


    N EUROSYMBOLIC artificial intelligence (AI) is an increasingly important trend
    in machine learning (ML) and has been referred to as the 3rd wave of artificial
    intelligence [\[1\]](#page-11-0). The word "neuro" in its name implies the use
    of neural networks, especially deep learning (DL), which is sometimes also referred
    to as sub-symbolic AI. This technique is known for its powerful learning and abstraction
    ability, allowing models to find underlying patterns in large datasets or learn
    complex behaviors [\[2\]](#page-11-1). On the other hand, "symbolic" refers to
    symbolic AI. It is based on the idea that intelligence can be represented using
    symbols like rules based on logic or other representations of knowledge [\[3\]](#page-11-2).
    Neurosymbolic AI combines these two approaches to create a hybrid system that
    benefits from the reasoning abilities of symbolic AI and the adaptability of sub-symbolic
    AI, opening new opportunities to improve a variety of different AI branches [\[4\]](#page-11-3),
    [\[5\]](#page-11-4).


    A disadvantage of sub-symbolic AI is its nature of being a "black box". This means
    that predictions made by these systems can be challenging to explain. Therefore,
    when an edge case leads to a system failure, it is often hard to find the reason
    for it. Accordingly, the rigorous testing & evaluation (T&E) and validation &
    verification (V&V) of these "black box" is a relevant topic recognized by governments
    [\[6\]](#page-11-5) and discussed in current literature [\[7\]](#page-11-6), [\[8\]](#page-11-7).
    As neurosymbolic systems incorporate a sub-symbolic component, this work aims
    to provide an overview of current techniques used to validate and verify the symbolic
    as well as sub-symbolic component, and how the architecture of neurosymbolic systems
    affects this process and can be used for V&V purposes.


    In software engineering, common terms are testing & evaluation or T&E and verification
    & validation or V&V. As defined by Wallace and Fujii in [\[9\]](#page-12-0), V&V
    intends to ensure that software performs as intended and meets certain quality
    and reliability standards. T&E are the methods and processes used to carry out
    V&V. Validation refers to the process of ensuring that a system performs as expected
    and delivers the desired result with sufficient accuracy, while verification focuses
    on checking if the design and implementation is correct according to the specified
    requirements [\[10\]](#page-12-1). Usually, verification is a process that takes
    place during development, while validation occurs at the end to evaluate if the
    program "does what it''s supposed to do" [\[11\]](#page-12-2). For reasons of
    readability, we primarily use the term V&V in the following.


    Recent frameworks propose methods to validate and verify symbolic and sub-symbolic
    AI, but discussing how the architecture of neurosymbolic AI can benefit the V&V
    process of the system as a whole has not received enough attention yet. Therefore,
    this paper focuses on two areas. First, the concept of V&V is mapped to symbolic
    and sub-symbolic AI, and an overview of current techniques and procedures used
    during the V&V process is provided. Secondly, it assesses how different neurosymbolic
    applications use the symbolic side to enable V&V of the sub-symbolic component.
    For this purpose, two different taxonomies of neurosymbolic AI are addressed,
    which categorize applications based on their architecture. 1) In 2020, Kautz proposed
    six possible designs of neurosymbolic systems [\[12\]](#page-12-3). 2) An alternative
    taxonomy was introduced by Yu et al. [\[13\]](#page-12-4) in 2021. These taxonomies
    are discussed and compared. Based on this, it is analyzed how current neurosymbolic
    applications leverage these architectures to use the symbolic component to make
    the sub-symbolic part more transparent, accurate, or safe, therefore enabling
    the V&V process through a neurosymbolic system design. The structure of the discussion
    within this paper is visualized in Fig. [1.](#page-2-0)


    Our work demonstrates that some of the current testing methods used for V&V are
    applicable to neurosymbolic AI. In particular, the combination of knowledge graphs
    (KGs) and DL is common, and it would be interesting to design a dedicated testing
    framework based on current techniques to validate neurosymbolic AI as a whole.
    However, there are also neurosymbolic AI applications that are not easy to test
    with current means. With this work, we show that there is much research potential
    in this area, and advocate the awareness of V&V for neurosymbolic AI systems and
    AI in general. Overall, this paper makes the following contributions:


    - Present and compare two current taxonomies of neurosymbolic AI.

    - Map the concepts of V&V as used in software engineer-


    ![](_page_2_Figure_6.jpeg)


    <span id="page-2-0"></span>Fig. 1. Contents of this paper.


    ing to symbolic and sub-symbolic AI.


    - Survey current V&V approaches for symbolic and subsymbolic AI.

    - Analyze the applicability of current V&V methods to neurosymbolic applications.

    - Investigate how symbolic AI can support the V&V process of sub-symbolic AI within
    a neurosymbolic system.

    - Discuss opportunities and challenges of V&V in the domain of neurosymbolic AI.


    The remainder of this paper is structured as follows: In section [II](#page-2-1)
    we analyze the related work. After that, in section [III](#page-3-0) we examine
    and compare two different taxonomies for neurosymbolic AI. Then, in section [IV](#page-5-0)
    and [V](#page-6-0) we survey the most important methods to verify and validate
    symbolic AI and sub-symbolic AI respectively. In section [VI](#page-8-0) we analyze
    if these methods are applicable to current neurosymbolic AI applications and opportunities
    to leverage different neurosymbolic architectures using the symbolic part to verify
    and validate sub-symbolic AI. Afterward, in section [VII](#page-10-0) we explain
    research gaps and problems that might be worth exploring in further research.
    In section [VIII](#page-11-8) we summarize our findings and explain our planned
    future work.


    ## II. RELATED WORK


    <span id="page-2-1"></span>V&V is a crucial process for ensuring the safety and
    reliability of safety-critical systems. Originally, V&V processes were designed
    for conventional software without AI components. With the increasing number of
    modern applications utilizing AI, it becomes crucial to develop approaches for
    the V&V of systems that use AI as a central element.


    ## *A. Surveys on V&V of Machine Learning*


    V&V of ML is an important topic in current research. For this reason, there are
    recent works and surveys that deal with this topic [\[7\]](#page-11-6), [\[8\]](#page-11-7),
    [\[14\]](#page-12-5)–[\[16\]](#page-12-6). Current surveys in this domain either
    deal with a specific area, such as autonomous systems [\[16\]](#page-12-6), in
    which ML is used, or only investigate one aspect like ML testing [\[14\]](#page-12-5),
    [\[15\]](#page-12-7) or formal verification of ML [\[7\]](#page-11-6), which are
    only parts of the entire V&V process.


    In [\[14\]](#page-12-5), testing of ML is surveyed. The survey presents current
    testing workflows, the components of an AI-based application that should be tested
    and provides an overview of properties that require testing as well as the frameworks
    that can be used to test these properties. Additionally, the survey showcases
    applications in safety-critical domains that need to be tested and how the testing
    workflows and frameworks can be applied to these applications.


    Similar, in [\[15\]](#page-12-7) testing approaches and current testing frameworks
    are presented. Compared to [\[14\]](#page-12-5), this survey is not as extensive
    and does not provide background information about topics like ML in general which
    is covered in [\[14\]](#page-12-5), but provides a comprehensive overview of current
    efforts regarding ML testing.


    Huang et al. [\[8\]](#page-11-7) provide a detailed overview of verification,
    testing and the interpretability of DL within their survey. They define the terms
    verification and testing and explain the importance and meaning of properties
    like the robustness or interpretability of DL. They explain differences between
    current approaches for V&V of DL and present a variety of testing frameworks and
    tools to increase the interpretability of DL.


    ## *B. Surveys on Neurosymbolic AI*


    There are multiple recent surveys that cover neurosymbolic AI and its applications
    in general [\[17\]](#page-12-8)–[\[24\]](#page-12-9) and surveys that focus on
    more specific applications such as graph structures [\[25\]](#page-12-10), biomedical
    knowledge graphs [\[26\]](#page-12-11), or natural language processing [\[27\]](#page-12-12).
    None of the just mentioned surveys covers testing, validation or verification
    in the domain of neurosymbolic AI and we could not find any surveys covering this
    topic to this date.


    ## III. TAXONOMIES OF NEUROSYMBOLIC AI


    <span id="page-3-0"></span>Neurosymbolic AI covers a wide range of applications,
    and can be implemented in many different ways. This concerns on the one hand the
    selection of methods used on the symbolic side, and on the other hand how sub-symbolic
    methods are combined with the symbolic ones. Therefore, it is common to divide
    neurosymbolic AI into different categories. Accordingly, multiple taxonomies for
    neurosymbolic AI were proposed [\[12\]](#page-12-3), [\[13\]](#page-12-4), [\[18\]](#page-12-13),
    [\[22\]](#page-12-14). In the following, two current taxonomies are discussed.
    The one from Kautz [\[12\]](#page-12-3) and Yu et al. [\[13\]](#page-12-4) are
    considered. Both taxonomies categorize neurosymbolic AI based on how the sub-symbolic
    and symbolic part interact with each other.


    ## *A. Kautz''s Taxonomy*


    Currently, one of the most common categorizations is that of Kautz, who defines
    six different types of neurosymbolic AI [\[12\]](#page-12-3). All of these types
    represent different system architectures, that try to combine the advantages of
    symbolic AI with those of sub-symbolic AI. Kautz defines the following categories:


    *a) Symbolic Neuro symbolic:* The input of the system is symbolic, then feed into
    a Neural Network, which outputs the symbolic result as well. A typical application
    of Symbolic Neuro Symbolic system is Natural Language Processing (NLP) and has
    become its Standard Operating Procedure (SOP) [\[12\]](#page-12-3). The symbolic
    input are representing embeddings converted from a combination of words extracted
    from the original text document. There are a lot of approaches to perform this
    conversion, such as word2vec [\[28\]](#page-12-15), and Glove [\[29\]](#page-12-16).
    Then those symbolic inputs are fed to a neural network that learns the underlying
    pattern to perform certain tasks, such as translation, semantic classification,
    and chat robot, etc. The output of the neural network is also symbolic in different
    forms based on the tasks. For example, the output is a sequence of words for translation
    tasks or a semantic label for classification tasks.


    *b) Symbolic[Neuro]:* This type of neurosymbolic AI uses a symbolic approach as
    a problem solver in a neural pattern recognition subroutine. It is currently already
    being used in many fields. One of the best-known applications is AlphaGo Zero
    [\[30\]](#page-12-17). Kautz states that most current autonomous vehicles and
    robots utilize this approach, but do not reference any applications from this
    domain.


    *c) Neuro*|*Symbolic:* The Neuro|Symbolic system performs symbolic reasoning based
    on non-symbolic input by leveraging neural networks to transform non-symbolic
    input (for example images) into a symbolic representation. The outputs of neural
    networks are fed into a symbolic representation which is used by a symbolic system
    to perform a complimentary task such as query answering [\[1\]](#page-11-0). All
    building blocks are connected so that learning happens in unison. Garcez and Lamb
    [\[1\]](#page-11-0) name the neuroßsymbolic concept learner [\[31\]](#page-12-18)
    and DeepProbLog [\[32\]](#page-12-19) as examples.


    *d) Neuro: Symbolic* −→ *Neuro:* Kautz describes this category as using the SOP
    which refers to the "Symbolic Neuro symbolic" category. It has a special training
    regime based on symbolic rules. An example for this method is an application by
    Lample and Charton [\[33\]](#page-12-20) which simplifies mathematical expressions.
    The description of this category is very abstract and Kautz refers to a formula
    for the training regime that is not explained further, which makes this category
    rather difficult to grasp.


    *e) Neuro* {*Symbolic*}*:* Within this category, the symbolic part''s purpose
    is to "transform symbolic rules into templates for structures within the neural
    network" [\[12\]](#page-12-3). Kautz references two examples, which are [\[34\]](#page-12-21)
    and [\[35\]](#page-12-22), to show how this concept can be used to integrate abstraction
    and part-of hierarchies into neural networks.


    *f) Neuro[Symbolic]:* Neuro[symbolic] is inspired by the "thinking fast and slow"
    theory from Kahneman [\[36\]](#page-12-23), who explains that the human brain
    has two different systems to make decisions. Neural Networks are similar to system
    1, which operates automatically by instinct without control. The symbolic part
    is similar to system 2, which needs attention and effort to operate. Just like
    a human brain, most of the time system 1 is making decisions until it decides
    to invoke system 2 is necessary. A Neuro[symbolic] system relies on a neural network,
    and the embedded symbolic AI assists if invoked by the neural network. This type
    of neurosymbolic AI is considered to have the highest potential by Kautz [\[12\]](#page-12-3).
    An example is a mouse-maze. Neural Networks recognize this task and invoke the
    symbolic engine, an algorithm to find the shortest path. The symbolic engine output
    the path with marks on the map which show the path. Then the neural network has
    been trained to interpret the marks and follow its guide to find the exit.


    Kautz''s categorization demonstrates how the symbolic part cooperates with the
    sub-symbolic part of the application. This categorization is useful to understand
    how an application as a whole works, but it also brings some problems with it.
    His categorization is very fine, and often it is difficult to clearly determine
    to which category an application belongs. Kautz explains some categories only
    superficially and gives a few examples, which makes it difficult to understand
    certain categories thoroughly. While for other categories, there are no applications
    yet, so it is questionable whether they are at all useful in practice. In addition,
    the names of his category are not well-chosen. The categories, when pronounced,
    are sometimes impossible to tell apart and confusion can quickly arise.


    ## *B. Yu''s Taxonomy*


    Because of the critique on Kautz''s survey, we present another survey by Yu et
    al. [\[13\]](#page-12-4) which provides an overview of current neurosymbolic applications
    and presents an alternative taxonomy. In their paper, current neurosymbolic AI
    applications are studied and divided into three groups: learning for reasoning,
    reasoning for learning, and learningreasoning. Just like Kautz''s taxonomy, the
    categories Yu et al. define represent how the symbolic part interacts with the
    subsymbolic part of the application. In the following paragraphs, the taxonomy
    of Yu et al. will be explained shortly:


    *1) Learning for Reasoning:* This approach integrates subsymbolic processes to
    enhance symbolic problem solving. Essentially, the sub-symbolic component narrows
    the search domain for the symbolic solver, optimizing the problemsolving process.
    This integration is depicted in Fig. [2.](#page-4-0) Another


    ![](_page_4_Figure_4.jpeg)


    <span id="page-4-0"></span>Fig. 2. Flowchart of the Learning for Reasoning type
    of neurosymbolic AI. The sub-symbolic component is used to limit the search space
    for the symbolic part. Therefore, it is accelerating the process [\[13\]](#page-12-4).


    way is that the sub-symbolic part converts unstructured data into symbols, to
    enable efficient symbolic reasoning as shown in Fig. [3.](#page-4-1)


    *2) Reasoning for Learning:* In this model, the roles are reversed: the sub-symbolic
    element primarily solves problems while the symbolic component supplements the
    neural network. This support manifests in two ways: firstly, by directing


    ![](_page_4_Figure_8.jpeg)


    <span id="page-4-1"></span>Fig. 3. Flowchart of the Learning for Reasoning type
    of neurosymbolic AI. In this version of Learning for Reasoning, the sub-symbolic
    part transforms the knowledge that can be obtained from data to symbols [\[13\]](#page-12-4).


    the neural network during its training phase, and secondly, by imposing constraints
    during prediction to prevent unsafe outcomes. Fig. [4](#page-4-2) illustrates
    this architecture.


    ![](_page_4_Figure_11.jpeg)


    <span id="page-4-2"></span>Fig. 4. Flowchart of the Reasoning for Learning type
    of neurosymbolic AI. Here, the symbolic part can guide or constrain the sub-symbolic
    part [\[13\]](#page-12-4).


    *3) Learning-Reasoning:* This variant represents a synergistic combination where
    symbolic and sub-symbolic elements collaborate equally in problem solving. Each
    component''s output directly informs the other''s input, creating a reciprocal
    and dynamic interaction. This bidirectional influence is visualized in Fig. [5.](#page-4-3)


    ![](_page_4_Figure_14.jpeg)


    <span id="page-4-3"></span>Fig. 5. Flowchart of the Learning-Reasoning type of
    neurosymbolic AI. Here, the characteristics of the other architectures are combined
    and the two parts are in constant interaction [\[13\]](#page-12-4).


    *4) Example:* Neurosymbolic approaches that implement safe reinforcement learning
    via shielding [\[37\]](#page-12-24) are great examples to showcase this taxonomy
    as the shielding can be implemented in multiple ways. For a control task, a subsymbolic
    model predicts an action, while a so called, safety shield, synthesized from safety
    specifications specified in temporal logic, ensures that every action is safe.
    If this application is implemented following the Learning for Reasoning or Learning-Reasoning
    design, first, the sub-symbolic part would make a decision based on its inputs
    from the environment. The decision is then given to the safety shield, that checks
    if the predicted action is safe and would then make minimal adjustments, if the
    action is determined to be unsafe. This concept would be categorized as Learning-Reasoning,
    in case feedback is provided to the sub-symbolic part, letting it know, that the
    action was replaced or not. If no feedback is provided, it would be Learning for
    Reasoning. This concept can be seen in Fig. [6.](#page-5-1)


    ![](_page_5_Figure_1.jpeg)


    <span id="page-5-1"></span>Fig. 6. After the agents (sub-symbolic part) predicts
    an action based on the inputs from the environment, a safety shield (symbolic
    part) checks if this decision is safe and replaces it with a safe action if necessary.
    It is optional (indicated in red) to provide the agent with the information that
    the action was replaced or not [\[38\]](#page-12-25).


    The work [\[38\]](#page-12-25) is similar to [\[37\]](#page-12-24), but extends
    the paper by presenting an additional architecture in which the shield is inserted
    before the sub-symbolic part. This allows the shield to limit the action space
    to make sure that every action the sub-symbolic part can choose from is safe.
    This design would be "Reasoning for Learning". This concept can be seen in Fig.
    [7.](#page-5-2)


    ![](_page_5_Figure_4.jpeg)


    <span id="page-5-2"></span>Fig. 7. A safety shield (symbolic part) limits the
    actions the agent (subsymbolic part) is able to choose from. Therefore, the agent
    is only able to choose from a set of safe actions [\[38\]](#page-12-25).


    In their survey, Yu et al. [\[13\]](#page-12-4) examine a wide range of current
    applications and classify them. They show that a variety of symbolic techniques
    can appear in every category of neurosymbolic AI. For example, first-order logic
    is used as a symbolic method in applications of all categories. This shows that
    the selection of the algorithms and methods for the symbolic as well as the sub-symbolic
    part is independent of the associated category. The categories in Yu''s taxonomy
    are only based on the interaction of the symbolic and sub-symbolic component.
    In the following sections, we will analyze which frameworks and methods are currently
    used to test the most common symbolic and sub-symbolic methods and how the symbolic
    part of the application can contribute to the testing of the sub-symbolic component.


    ## IV. V&V OF SYMBOLIC AI


    <span id="page-5-0"></span>As a first step, the V&V process of the two components
    of a neurosymbolic application are considered independently, with this section
    focusing on the symbolic component. Yu et al. [\[13\]](#page-12-4) shows that
    three methods in particular are used frequently as the symbolic part of a neurosymbolic
    AI system. These are propositional logic, first-order logic, and KGs. In the following
    section, the concepts of V&V are mapped to these techniques and the capabilities
    to validate and verify of symbolic AI are assessed.


    ## *A. Mapping V&V to Logical Systems*


    In term of V&V, the following properties are the most relevant: 1) Validity: A
    formula is valid if it is true under every possible interpretation or assignment.
    In logic, this means that if all premises of a statement are true, it is impossible
    that the conclusion is false. 2) Soundness: A logical system is sound if every
    statement that can be derived from the systems is true and an argument is sound
    if it is valid and its premises are true.


    When mapping logical arguments to the V&V process, the validity of a logic argument
    can be analogized to the verification phase. This is because a valid logical argument
    ensures structural correctness given that all premises are true, though it doesn''t
    necessarily affirm the truth of those premises. This is similar to the verification
    process checking if the implementation or design of a system is correct according
    to its specification. On the other hand, soundness aligns with the validation
    phase, as an argument is deemed sound only when all its premises are unequivocally
    true. This is analog to the validation phase, as this ensures that the output
    of a system is as expected and correct.


    ## *B. Verification of Logic*


    If a general algorithm can be found to prove the validity (true/false) of a logic
    argument, it is called decidable. Therefore, the question is: Are propositional
    logic and first-orderlogic decidable?


    1) Propositional logic is decidable. The validity of a statement can be determined
    by a truth table. Truth tables are a fundamental process of computer science.
    As Anellis''s research shows, it appears that this technique was used as early
    as the 19th century [\[39\]](#page-12-26). The complexity of this proof grows
    exponentially with the number of variables. Therefore, truth tables are in practice
    only usable for statements with a small number of propositional variables. Semantic
    tableau also called the truth tree method is an elegant alternative to truth tables
    [\[40\]](#page-12-27). Accordingly, it is possible to validate the symbolic part
    of a neurosymbolic AI application that uses propositional logic using this technique,
    even if current standards are rather inefficient.


    2) There is no general algorithm to check the validity of a first-order logic
    statement. Therefore, first-order logic statements are undecidable. However, this
    does not mean that it is impossible to show the validity of individual statements.
    Truth trees can be used to show the validity of first-order logic statements,
    but if the statement is invalid, the algorithm will run infinitely. To show an
    invalid statement, a countermodel has to be found.


    As described above, algorithms have been found to check the validity of logic
    arguments. Even though first-order logic is not decidable, tools like [\[41\]](#page-12-28),
    can be used to verify it in many cases. However, validity does not depend on whether
    the premises are true. This means that the following statement would be valid
    in terms of logic:


    ## *All animals are birds. All dogs are animals. Therefore, all dogs are birds.*


    The above example shows that a statement can be valid but not sound. Soundness,
    as explained before, describes that not only the syntax but also the semantic
    is valid. Therefore, additional knowledge has to be used, to validate the semantic
    of such an argument. For this purpose, KGs could be used for validation purposes,
    which again have to be validated, too. This problem is considered in more detail
    in the following section.


    ## *C. Validation of Knowledge Graphs*


    KGs are an increasingly important component of current applications. Accordingly,
    there are numerous methods for validating these graphs. The survey "Knowledge
    Graph Validation" by Huaman et al. gives an overview of current methods and tools
    [\[42\]](#page-12-29). Within this survey, several typical error sources which
    frequently occur in KG are described, and an overview is provided of which current
    tools are able to detect and correct such errors in order to create the most valid
    KG possible. A broad variety of tools are available to validate KGs.


    *1) Corroborative Fact Validation (COPAAL) [\[43\]](#page-12-30):* To validate
    KGs or semantic statements, COPAAL computes a socalled mutual information (MI)
    score. The method tries to find alternative sources on the web to validate a statement.
    The paper gives an example of how this method works; a given statement could be:
    "Barack Obama is a US citizen". Using open databases and KGs such as DBpedia 2016-10[1](#page-6-1)
    , the method looks for similar statements that imply or refute that Barack Obama
    is a US citizen. E.g. the data could show that his place of birth is in the USA
    which would make it highly likely that he is a US citizen or if the method finds
    a source that states that he was a US President, it confirms that the original
    statement is very likely to be correct, giving it a high MI score.


    *2) Deep Fact Validation (DeFacto) [\[44\]](#page-12-31):* To validate knowledge,
    DeFacto is an algorithm that tries to find supporting information about a given
    fact in the information as well as supporting information from trustworthy sources.
    Additionally, it provides a score that represents the confidence DeFacto has when
    assessing the validity of a fact.


    *3) Temporal Information Scoping (TISCO) [\[45\]](#page-12-32):* TISCO adds another
    component. This procedure tries to assign times to facts, since many assertions
    are only true at certain times. E.g. athletes regularly change their clubs, people
    may have different professions or live in different places at different points
    in their lives. Therefore, it is important not only to validate the facts, but
    also to link them to points in time in order to establish a timeline.


    In addition to the above-mentioned procedures, there are other similar procedures
    with the same goal. In all procedures, different databases or the web are searched
    based on an assertion in order to confirm and validate statements. Other popular
    methods are FactCheck [\[46\]](#page-12-33), FacTify [\[47\]](#page-12-34), Leopard
    [\[48\]](#page-12-35), Surface [\[49\]](#page-12-36) and S3K [\[50\]](#page-12-37).
    Furthermore, there are already well build KGs available that are tested and highly
    validated, like YAGO [\[51\]](#page-12-38) or Conceptnet [\[52\]](#page-12-39).
    YAGO is used by IBM in their Watson artificial intelligence system [\[53\]](#page-12-40)
    and stores knowledge about people, cities, countries, movies, and organizations.
    It was build with data from Wikipedia[2](#page-6-2) , WordNet [\[54\]](#page-12-41),
    which is also a widely used KG, and GeoNames[3](#page-6-3) . ConceptNet is a knowledge
    graph that links words and phrases with labeled edges. The information comes from
    a variety of sources, including crowdsourcing, expert-generated material, and
    games. Another popular KG is DBpedia[4](#page-6-4) which builds on knowledge from
    Wikipedia documents.


    ## V. V&V OF SUB-SYMBOLIC AI


    <span id="page-6-0"></span>V&V in the context of sub-symbolic AI is an exciting
    topic and also a big challenge, as deep learning is also often referred to as
    a "black box" and is rather opaque in its decisionmaking. Accordingly, it is a
    challenge to validate and verify the behavior of these systems. In order to verify
    a system, it is usually checked whether certain requirements are met. This is
    usually done with the help of formal methods and is a current challenge for systems
    using sub-symbolic AI due to its complexity. For the validation of sub-symbolic
    AI different testing methods are used to check different properties like the correctness
    or robustness of a system.


    ## *A. Verification of Sub-Symbolic AI*


    In the survey of Huang et al. [\[8\]](#page-11-7) various applications to verify
    sub-symbolic AI are presented. They provide a taxonomy for different verification
    approaches and define multiple properties that can be verified. In the following
    these approaches and properties as defined in [\[8\]](#page-11-7) are summarized.


    *1) Properties to Verify:*


    <span id="page-6-5"></span>*a) Robustness:* Robustness can be defined as the ability
    of a model to make a correct decision even in situation when the input is noisy
    or manipulated [\[55\]](#page-12-42).


    <span id="page-6-1"></span><sup>1</sup>https://www.faa.gov/air [traffic/publications/atpubs/atc](https://www.faa.gov/air_traffic/publications/atpubs/atc_html/chap5_section_7.html)
    html/chap5 secti on [7.html,](https://www.faa.gov/air_traffic/publications/atpubs/atc_html/chap5_section_7.html)
    accessed: 01/26/2023


    <span id="page-6-2"></span><sup>2</sup>[https://www.wikipedia.org/,](https://www.wikipedia.org/)
    accessed: 01/29/2023


    <span id="page-6-4"></span><span id="page-6-3"></span><sup>3</sup>[https://www.geonames.org/,](https://www.geonames.org/)
    accessed: 01/29/2023


    <sup>4</sup>[https://www.dbpedia.org/resources/knowledge- graphs/,](https://www.dbpedia.org/resources/knowledge-graphs/)
    accessed: 01/26/2023


    *b) Reachability & Interval:* The reachability and interval are two very similar
    properties, closely connected to each other. Verifying the reachability means,
    that for a certain input the highest possible and lowest possible output is verified.
    Verifying the interval is very similar, as it is an overapproximation of the reachability.


    *c) Lipschitzian:* This property describes how the output changes when small changes
    are made to the input. When verifying this property, the change in output should
    remain below a specified distance.


    *2) Approaches:*


    *a) Search-Based:* Verification algorithms belonging to this type verify the system
    through exhaustive searching. This approach uses algorithms such as the Monte-Carlo
    Tree Search for verification purposes [\[56\]](#page-13-0).


    *b) Constraint Solving:* Algorithms that leverage this approach convert neural
    network into constraints which are easier to verify because they are no longer
    a "black box". For the verification of the resulting constraints, solvers like
    the SAT solver can be used.


    *c) Over-Approximation:* Here, an over-approximation of possible outputs for an
    input is calculated for verification purposes.


    *d) Global Optimization:* As the name suggests, these approaches are based on
    global optimization techniques. An example for this is the tool DeepGo [\[57\]](#page-13-1)
    that uses global optimization techniques for verification in respect to reachability
    and robustness properties.


    An in-depth explanation for the verification of sub-symbolic AI can be found in
    [\[8\]](#page-11-7). Table [I](#page-7-0) provides an overview of current approaches
    that can be used for the verification of sub-symbolic AI.


    <span id="page-7-0"></span>TABLE I APPROACHES TO VERIFY SUB-SYMBOLIC AI AS SURVEYED
    IN [\[8\]](#page-11-7).


    | Approach                                | Publications    |

    |-----------------------------------------|-----------------|

    | Search-Based                            | [56], [58]      |

    | Constraint Solving                      | [59]–[66]       |

    | Over-Approximation                      | [57], [67]–[70] |

    | Search-Based & Constraint Solving       | [71], [72]      |

    | Over-Approximation & Constraint Solving | [73]–[75]       |

    | Global Optimization                     | [57], [70]      |


    ## *B. Validation of Sub-Symbolic AI*


    To validate sub-symbolic AI, a variety of measures can be tested. In [\[14\]](#page-12-5)
    these measures as well as the tools and frameworks to test these in order to validate
    such a system is surveyed. The measures addressed in this survey are the correctness,
    model relevance, efficiency, fairness, interpretability, privacy and robustness
    of the system. In [\[8\]](#page-11-7) especially testing the robustness and increasing
    the interpretability are addressed. Depending on the use case of the application,
    some of these properties are particularly important. Within this survey especially
    the correctness, robustness and interpretability


    <span id="page-7-1"></span>TABLE II WORKS ON TESTING THE CORRECTNESS AS SURVEYED
    IN [\[14\]](#page-12-5)


    | Testing Correctness                 | Publications |

    |-------------------------------------|--------------|

    | Testing Tools                       | [79], [80]   |

    | Testing the Input and Oracle Design | [81]–[86]    |

    | Searching Data Bugs                 | [87], [88]   |


    are considered for validation purposes. In the following, a brief overview of
    these measures and recent frameworks is provided.


    *1) Properties to Validate:*


    *a) Correctness:* Correctness is a fundamental property of a system, representing
    the probability that it completes a task correctly. Popular methods to measure
    the correctness are k-fold cross-validation [\[76\]](#page-13-17) and Bootstrapping
    [\[77\]](#page-13-18). For classification tasks, metrics like accuracy, precision/recall,
    and ROC Curve are commonly used to measure the correctness. Suitability varies
    depending on the situation and data balance. Detailed examples can be found in
    Japkowicz''s workshop [\[78\]](#page-13-19). Regression problems can be evaluated
    using error measurements, such as Mean-Squared-Error (MSE) or Root Mean-Squared-Error
    (RMSE), which provide insights into expected deviations from the system''s predictions.
    In summary, choosing the appropriate measurement is crucial to assess the correctness
    of a sub-symbolic system and should be carefully considered based on the task
    and data distribution. Table [II](#page-7-1) shows a selection of works that focus
    on testing the correctness of sub-symbolic AI. It is based on applications surveyed
    in [\[14\]](#page-12-5).


    *b) Robustness:* The robustness property itself is similar to the one described
    in section [V-A1a.](#page-6-5) The difference is that robustness can not only
    be verified, but also tested and therefore validated. The most common approach
    to test the robustness is to generate adversarial examples or inputs. Frameworks
    such as DeepXplore [\[89\]](#page-13-20), DeepHunter [\[90\]](#page-13-21) or
    DLFuzz [\[91\]](#page-13-22) use adversarial attacks to trigger misbehavior and
    therefore to test the robustness of a neural network. Techniques such as testing
    the code coverage, known from conventional software testing, can be adapted to
    sub-symbolic AI. These approaches maximize a metric called neuron coverage to
    improve the robustness of a sub-symbolic model. Another approach is to detect
    adversarial noise that might cause wrong predictions [\[92\]](#page-14-0), [\[93\]](#page-14-1).
    While these methods focus on images, there are other approaches that focus on
    generating and detecting adversarial attacks for natural language processing [\[94\]](#page-14-2)
    or cybersecurity [\[95\]](#page-14-3), which can be used to test and improve the
    robustness of these models.


    *2) Interpretability:* Neural networks are often considered to be "black boxes",
    because it is a challenge to comprehend the decision-making process of a trained
    model. However, in safety-critical and ethically sensitive domains, it is crucial
    to understand this process to prevent discrimination or system failures. Although
    there is no uniform definition of interpretability, previous work suggests that
    it refers to the degree to which humans can comprehend the reasoning and logic
    behind a deep learning system''s decisions [\[14\]](#page-12-5), [\[96\]](#page-14-4).


    To evaluate interpretability, there are three main categories: Manual assessment,
    automatic assessment, and evaluation of interpretability improvement [\[14\]](#page-12-5).
    Manual assessment involves humans in the loop and is evaluated in real applications.
    Automatic assessment, on the other hand, utilizes proxies to eliminate the need
    for human involvement. Identifying influential instances belongs to this approach,
    which can be achieved through two methods: Deletion Diagnostics and Influence
    Functions [\[97\]](#page-14-5). Both methods detect influential instances by measuring
    the influence of the change to the model when modifying the data sets: Deletion
    Diagnostics remove data points, while Influence Functions up-weight instances
    by differentiating the loss function with respect to its parameters. Notable measures
    of Deletion Diagnostics are DFBETA [\[98\]](#page-14-6) and Cook''s distance [\[99\]](#page-14-7).


    ## VI. OPPORTUNITIES


    <span id="page-8-0"></span>As shown in Fig. [8,](#page-8-1) one solution is to
    verify and validate both sides of a neurosymbolic AI separately. Another solution
    is to leverage the characteristics of the symbolic AI to verify and validate sub-symbolic
    part. In the following, we will consider both approaches and assess whether and
    how current testing and validation methods can be applied to the isolated parts
    of a neurosymbolic application and how current applications leverage the characteristics
    of symbolic policies to validate or improve the properties of the sub-symbolic
    part.


    ![](_page_8_Figure_3.jpeg)


    <span id="page-8-1"></span>Fig. 8. It is possible to either verify and validate
    the parts of a neurosymbolic application independently or the symbolic part can
    be used to either ease or conduct the V&V process of the sub-symbolic part.


    ## *A. Using Neurosymbolic System Architectures for V&V*


    Each of the three different categories of neurosymbolic AI defined by Yu et al.
    [\[13\]](#page-12-4) presented in their paper can affect the V&V process differently.
    For example, in "Reasoning for Learning", the symbolic part can support the sub-symbolic
    AI by providing guidelines and constraints through e.g. logic rules. This means
    that the input is directly applied to the sub-symbolic AI, as shown in Fig. [4.](#page-4-2)
    The symbolic part can therefore improve the robustness and correctness of the
    system by checking, constraining or replacing decisions made by the sub-symbolic
    model. The category "Learning for Reasoning" uses the symbolic part as problem
    solver. This means that the inputs directly go into the sub-symbolic part. It
    is feasible to transform the inputs to the sub-symbolic part to symbolic rules
    that allow to make transparent decisions and therefore increase the interpretability
    of the overall system. Both "Learning for Reasoning" as well as "Reasoning for
    Learning", have the potential to improve the efficiency by accelerating the learning
    process either through guidance by symbolic rules or by limiting the search space
    with the sub-symbolic model. All of these concepts can also be applied to the
    category "Learning-Reasoning". In the following, we give multiple examples based
    on current neurosymbolic applications that leverage these architectures and explain
    the opportunities these techniques provide to increase the safety and trustworthiness
    in AI and especially DL. An overview of selected applications is given in table
    [III.](#page-9-0)


    *1) Safe Reinforcement Learning:* A popular application for neurosymbolic AI is
    safe reinforcement learning for autonomous control tasks. Alshiekh et al. [\[37\]](#page-12-24)
    propose a concept to synthezise a safety shield from formal specifications represented
    in linear temporal logic. As already mentioned in section [III,](#page-3-0) the
    integration of this shield into the neurosymbolic systems is very versatile and
    every architecture according to Yu''s taxonomy is possible. In recent years, several
    similar approaches have been proposed, often using the "Learning for Reasoning"
    or "Learning-Reasoning" architecture to make the minimal needed adjustments to
    guarantee safe actions. One of the more recent works is "Neurosymbolic Reinforcement
    Learning with Formally Verified Exploration" [\[100\]](#page-14-8). The paper
    introduces a reinforcement learning framework called REVEL. Similar to [\[37\]](#page-12-24),
    symbolic rules are used as a verification step within the deep reinforcement learning
    loop providing a safety shield that keeps the agent from executing unsafe actions.
    Therefore, this application can be categorized as "Learning-Reasoning", showing
    how architecture can help to improve the correctness and robustness of a system.
    The paper demonstrates the results using a total of 10 benchmarks and compares
    them with similar state-of-the-art approaches. Compared to Deep Deterministic
    Policy Gradients (DDPG) [\[101\]](#page-14-9), the framework performs better in
    7 out of 10 scenarios. Compared to Constrained policy optimization (CPO) [\[102\]](#page-14-10),
    however, it performs better in only 4 out of 10 cases. The survey "A Review of
    Safe Reinforcement Learning: Methods, Theory and Applications" by Gu et al. [\[103\]](#page-14-11)
    provides an overview of safe reinforcement learning with many different approaches
    often using neurosymbolic AI for verification purposes. Additionally, the authors
    maintain a GitHub repository[5](#page-8-2) listing current works in this domain.


    *2) Verifiable Reinforcement Learning via Policy Extraction [\[104\]](#page-14-12):*
    Another approach to increase the interpretability and transparency of the decisions
    of the sub-symbolic part of a neurosymbolic system is to derive rules from predictions.
    The neurosymbolic framework VIPER, which follows the "Learning for Reasoning"
    architecture, is doing this by deriving rules from predictions of a neural network.
    These rules are represented by a decision tree. This approach helps to make decisions
    easier and more efficient to validate and verify. Furthermore, it makes the decisions
    of the entire system more transparent.


    <span id="page-8-2"></span><sup>5</sup>[https://github.com/chauncygu/Safe-Reinforcement-Learning-Baselines,](https://github.com/chauncygu/Safe-Reinforcement-Learning-Baselines)
    accessed: 12/09/2023


    <span id="page-9-0"></span>TABLE III A SELECTION OF PAPERS THAT USE SYMBOLIC AI
    FOR V&V OF THE SUB-SYMBOLIC PART


    | Paper | Category                                                                                     |
    Summary                                                                                                                       |
    V&V Aspect                                                                                           |

    |-------|----------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------|

    | [100] | Learning<br>Reasoning                                                                        |
    Verify<br>predictions<br>using<br>a<br>symbolic<br>"safety policy"                                                            |
    Increasing correct<br>ness and robustness<br>by ensuring a safe<br>output                            |

    | [105] | Non<br>Appli<br>cable                                                                        |
    Convert 3D objects<br>to code which is<br>then<br>converted<br>to<br>3D shapes                                                |
    Improves<br>validity<br>by<br>increasing<br>the<br>interpretability                                  |

    | [104] | Learning for<br>Reasoning                                                                    |
    Learn<br>a<br>provable<br>decision-tree policy                                                                                |
    Improves<br>validity<br>by<br>increasing<br>the<br>interpretability                                  |

    | [106] | Learning for<br>Reasoning                                                                    |
    Learn<br>programmatic<br>policies<br>from<br>tasks<br>that<br>can<br>be<br>described<br>by<br>Markov<br>Decision<br>Processes
    | Improves<br>validity<br>by<br>increasing<br>the<br>interpretability                                  |

    | [38]  | Learning for<br>Reasoning<br>or Learning<br>Reasoning<br>(based<br>on<br>implementa<br>tion)
    | Restrict<br>a<br>DP<br>model or overwrite<br>its decision to allow<br>safe<br>reinforcement<br>learning                       |
    Validate predictions<br>or<br>restrict<br>DL<br>model to improve<br>correctness<br>and<br>robustness
    |

    | [107] | Learning<br>Reasoning                                                                        |
    Learning<br>semantic<br>video<br>representations<br>in<br>a<br>neurosymbolic<br>weak<br>supervised<br>learning
    setup          | Verify<br>learning<br>results by checking<br>against<br>logical<br>specifications                    |


    *3) Learning to Synthesize Programs as Interpretable and Generalizable Policies
    [\[106\]](#page-14-14):* This framework follows a similar approach as "Verifiable
    Reinforcement Learning via Policy Extraction" [\[104\]](#page-14-12). The difference
    is that [\[106\]](#page-14-14) does not use limited policy representations in
    the context of decision trees, but learns to synthesize a program soly on rewards.
    The derived policies can make the decisions more transparent than those of conventional
    DL methods.


    *4) Learning to Infer and Execute 3D Shape Programs [\[105\]](#page-14-13):* This
    application is interesting because unlike the others, it does not quite fit Yu''s
    taxonomy [\[13\]](#page-12-4) because it uses a total of two sub-symbolic parts
    and one symbolic part. Again, the symbolic part gives more accurate results and
    especially increases transparency compared to existing DL methods. The goal of
    the program is to represent a 3D object as 3D shapes. For this, first, an object
    is represented as code by means of a "Neural Program Generator". Then a "Neural
    Program Executor" converts the code to 3D shapes. The code is humanreadable, and
    therefore it is possible to see which shapes of the 3D object have been recognized.
    This increases the interpretability.


    *5) LASER [\[107\]](#page-14-15):* Huang et al. [\[107\]](#page-14-15) present
    a weakly supervised neurosymbolic learning approach to learn semantic video representations.
    The approach receives videos and spatio-temporal specifications in the form of
    linear temporal logic (LTL) as inputs. During the learning process an "alignment
    score" of the specifications and the learned semantic representation is calculated.
    This allows for a verification of the learned representation. The alignment is
    optimized during the learning process.


    ## *B. Assessing the Applicability of Current T&E/V&V Methods to Neurosymbolic
    AI*


    In this section, we address opportunities we have through current V&V methods
    to determine where these approaches reach their limits in neurosymbolic applications.


    *1) Zero-shot Recognition via Semantic Embeddings and Knowledge Graphs [\[108\]](#page-14-16):*
    This method, which according to Yu''s taxonomy [\[13\]](#page-12-4) belongs to
    the category "Reasoning for Learning", deals with zero-shot learning. The approach
    deals with unknown classes by using knowledge about previously learned classes
    and additional semantic embeddings. It uses both semantic embeddings and categorical
    relationships to predict the classes of unknown pictures. The core of the application
    consists of two components: One component is a knowledge graph (KG), and the other
    is a graph convolutional network (GCN). The paper uses multiple configurations
    of datasets for its experiments. In the first one, the KG is based on relationships
    from Never-Ending Language Learning (NELL) [\[109\]](#page-14-17) and images are
    taken from the Never-Ending Image Learning (NEIL) [\[110\]](#page-14-18) dataset.
    In the second configuration, the KG is based on the WordNet [\[54\]](#page-12-41)
    database while the images for the GCN model''s training are taken from the ImageNet
    [\[111\]](#page-14-19) dataset. The KG can be validated with the previously analyzed
    methods. The paper investigates how the method behaves when noise is introduced
    in the KG and when it is completely random. It is shown that the method is quite
    robust even when noise is present in the KG. However, if it is random, then the
    outputs are almost random guesses. Therefore, while it is important that the KG
    is validated by the GCN, which is the problem solver in this procedure, we compensate
    for noise but do not need to validate the KG perfectly and focus on the GCN. There
    are several types of the still rather new GCN. The type used in the paper is based
    on convolutional neural networks (CNNs). This would mean that approaches such
    as [\[112\]](#page-14-20) to find robustness guarantees in GCNs could be used
    for verification and benchmarking tools like [\[113\]](#page-14-21), [\[114\]](#page-14-22)
    for validation purposes. Even though there are some works regarding V&V of GCN
    it is a rather unexplored topic, which would be exciting to further investigate.


    *2) Alpha Go Zero [\[30\]](#page-12-17):* AlphaGo Zero is an application developed
    by DeepMind. It is able to beat the world''s best players in games like Chess
    or Go. This application is not listed in Yu''s [\[13\]](#page-12-4) survey, but
    Kautz''s [\[12\]](#page-12-3) uses it as an example for his category Symbolic[Neuro].
    If this method were included in Yu''s taxonomy, it would belong to the category
    "Learning for Reasoning". A neural network evaluates the state of the game on
    the sub-symbolic part of the application, while a Monte Carlo Tree Search [\[115\]](#page-14-23)
    tries to find the optimal move for the given situation on the symbolic part. Therefore,
    this application has a symbolic problem solver with a neural network supporting
    the decision-making process. AlphaGo Zero is trained by playing against itself
    in an attempt to find better moves and thus better models. AlphaGo Zero''s model
    trains itself and no human-generated data set is needed. This means that the system
    does not need to be protected against noisy or manipulated data. In addition,
    it is not a safetyrelevant application. Therefore, robustness is not necessarily
    in the foreground, since targeted manipulations would be unlikely and futile.
    While the interpretability of AlphaGo Zero''s decisions is interesting, it is
    not the priority when testing or verifying the system. The goal of AlphaGo Zero
    is to develop the strongest possible chess engine that can defeat any opponent.
    For this reason, the main focus in testing the program is on the correctness.
    To validate the Monte Carlo Tree Search, all possible moves for each possible
    game state would have to be evaluated to find the optimal solution. For games
    like TikTakToe, this would not be a problem, but since games like Chess or Go
    have too many different game states, this would not be feasible with current technology.
    To simplify this, the neural network looks at each game situation and evaluates
    it. Since numerous game states are very similar and similar moves would be optimal,
    the DL part tries to identify these relationships between the different situations
    to reduce the possibilities that need to be evaluated. This means that in order
    for the symbolic problem solver to be able to make the correct decision, the sub-symbolic
    part must have assessed the situation correctly beforehand. Thus, a labeled test
    data set would need to be created against which the model could be tested to make
    sure the game states are detected correctly. However, since AlphaGo Zero has never
    been beaten by a human, it is impossible to decide whether the human made a mistake
    in labeling or if AlphaGo Zero made a mistake in evaluating a game situation if
    differences occur. However, as improvements are constantly being made, especially
    in the efficiency of this process, it is clear that even though the models so
    far are very good, there is still room for improvement. The only way to test AlphaGo
    Zero at the moment is to let it play more games against itself to find better
    models, even if this is very inefficient. For this reason, however, optimizing
    the efficiency of AlphaGo Zero''s training is also interesting, since the more
    efficient this is, the faster better results can be obtained and thus the most
    important property in this scenario, correctness, is also improved. To summarize
    this; there is no current test framework that would be applicable to an application
    like AlphaGo Zero.


    *3) DeepProbLog [\[116\]](#page-14-24):* DeepProbLog is a neurosymbolic AI framework
    belonging to the category learning for reasoning according to Yu''s taxonomy.
    The sub-symbolic part is responsible for the low-level perception task, and the
    symbolic part then uses the learning result to perform logical inference. In their
    research, three sets of a total of six experiments are conducted to demonstrate
    the different abilities of DeepProbLog. In five out of six experiments, DeepProbLog
    outperforms the DL model itself, showing better generalization ability, less computational
    complexity and training time, and higher sample efficiency. The tasks in the experiments
    are the addition of single digits and multi-digits, sorting a list of numbers,
    and the coin-ball problem [\[117\]](#page-14-25), where the subsymbolic part is
    used to recognize the numbers or colors in an image, and the symbolic part uses
    the classification results to complete the addition operation or to calculate
    the probability distribution. The sub-symbolic components used in these tasks
    are convolutional neural networks (CNNs) with basic architectures. The experiments
    used the MNIST data set. Input testing could be conducted to expose robusteness
    flaws [\[14\]](#page-12-5). Testing frameworks like DLFuzz could be used to generate
    adversarial samples and improve the robustness of the CNNs [\[118\]](#page-14-26).
    For the sorting task, the sub-symbolic part uses recurrent neural networks (RNNs)
    which are similar as the ones used in the work of Bosnjak et al. [\[119\]](#page-14-27).
    These could be tested by TensorFuzz [\[120\]](#page-14-28), which is used to find
    undesired behaviors of RNNs. Also, cross-validation could be used during the training
    to validate the models performance. The symbolic part of DeepProbLog follows the
    inference process of ProbLog: First, generate the ground instances the query is
    based on; Second, rewrite the ground logic into a propositional logic formula;
    Next, the formula is compiled into a Sentential Decision Diagram (SDD) [\[121\]](#page-14-29)
    for more efficient evaluation; Finally, calculate the probability. Since this
    system is based on propositional logic, the symbolic part is decidable and could
    be verified e.g. using semantic tableau.


    ## VII. OPEN CHALLENGES


    <span id="page-10-0"></span>Examining the current state of neurosymbolic AI and
    current V&V methods, we have revealed numerous open challenges. These open challenges
    address neurosymbolic AI and its applications in general, as well as the V&V methods
    for both symbolic and sub-symbolic AI.


    *a) Investigating New Neurosymbolic Architectures:* The term "neurosymbolic AI"
    is still relatively new at the time this paper was written. As our research has
    shown, it is difficult to find papers on the topic on the well-known platforms
    of ACM and IEEE. However, this is not because no one uses this concept, but because
    the term is not yet widely used in the scientific community. The works by Kautz
    [\[12\]](#page-12-3) and Yu et al. [\[13\]](#page-12-4) make important contributions
    by identifying and categorizing existing applications that use this technique.
    Similar works are published frequently, but there is still no widespread differentiation
    of different categories of neurosymbolic AI and terms as well as clear definitions
    must be established in the future. We have criticized Kautz''s taxonomy for the
    fact that some of his categories are only theoretical with no applications implementing
    them and thus some categories are not practical at the moment. But this also shows
    that there are many opportunities to combine symbolic with sub-symbolic AI that
    have not been explored yet and are worth exploring to find out what potential
    neurosymbolic AI has.


    *b) Efficient Verification of Logic Rules:* Traditional methods like truth tables,
    which can be used to verify propositional logic, are very computationally intensive
    as their run-time depends on the number of parameters. This means that these methods
    do not scale well. However, depending on how the sub-symbolic part is related
    to the symbolic part, it may not be necessary to fully verify the symbolic part.
    Neural networks have the advantage that they can usually deal well with noise
    in the data. That means, if the problem solver is the subsymbolic part and the
    symbolic part has only a supporting function, it would be sufficient to approximate
    a complete verification. This approach could be further investigated and used
    to balance the computational cost and scalability with the need for accuracy and
    logical correctness.


    *c) Testing of Emerging DL Architectures:* Methods for testing the correctness,
    robustness, and other metrics for neural networks are well-researched and are
    constantly being further developed. It happens again and again that new designs
    for neural networks are developed. These new architectures require either new
    testing methods or the adapting of existing ones. In the paper "Zero-shot Recognition
    via Semantic Embedding and Knowledge Graphs" [\[108\]](#page-14-16) a GCN is used
    on the sub-symbolic part of the application. It would be interesting to explore
    whether it is possible to apply methods such as DLFuzz [\[91\]](#page-13-22) here.


    *d) Comparing the Efficiency of Neurosymbolic AI with Comparable Conventional
    Deep Learning Approaches:* Through neurosymbolic AI it is possible to perform
    the training process of a DL model in a more targeted way, since the symbolic
    part can guide and thereby support the sub-symbolic part during training and the
    decision-making process. Therefore, it would be interesting to compare whether
    neurosymbolic AI applications are more efficient in terms of runtime and possibly
    also in terms of energy consumption. Measuring the efficiency of software systems
    and AI are exciting topics that are currently being researched. Since energy-efficient
    training AI can save costs for companies and research institutions as well as
    protect the environment, it is exciting to look at the influence of neurosymbolic
    AI on the efficiency of training. The assessments could be based on existing metrics
    and test procedures for evaluating the resource efficiency of ML [\[122\]](#page-14-30),
    [\[123\]](#page-14-31).


    *e) Apply Current V&V Methods to Common Neurosymbolic Applications:* It could
    be tested whether existing V&V methods can be applied to common neurosymbolic
    applications as explained in the opportunities area. The currently most popular
    neurosymbolic AI applications could be used as examples. This could be extended
    and a testing framework for neurosymbolic AI applications could be developed,
    because there are some configurations that are frequently used. For example, KGs
    are often combined with CNNs. Test frameworks could be developed for these standard
    configurations with respect to the architecture of the application.


    *f) Development of Dedicated Testing Frameworks for Applications using Neurosymbolic
    AI:* At present, there are only a few frameworks for testing neurosymbolic applications,
    as this is still a very new field. While our paper focuses on testing the individual
    components and using symbolic AI to test the sub-symbolic component within the
    system, there are first frameworks that test the whole neurosymbolic system as
    such. These testing frameworks are showing initial success in domain-specific
    applications. For example, Large Language Models (LLMs) are a popular area of
    application for neurosymbolic AI. Accordingly, the paper [\[124\]](#page-14-32)
    introduces a "diversity measure" based on entropy, Gini impurity, and centroid
    distance as a metric to determine the probability of failure of LLMs. Furthermore,
    for the neurosymbolic LASER [\[107\]](#page-14-15) approach for learning semantic
    representations of videos a new model checker was needed. Accordingly, they implemented
    a model checker based on Scallop [\[125\]](#page-14-33) for verification purposes.
    This shows that there is a great need for new model checkers and testing procedures
    for appplications based on neurosymbolic AI.


    ## VIII. CONCLUSION


    <span id="page-11-8"></span>Within this paper, the current state of neurosymbolic
    AI was investigated, as well as the current possibilities to test, evaluate verify
    and validate neurosymbolic AI. Two taxonomies that categorize neurosymbolic applications
    based on the system''s architecture describing how the symbolic and sub-symbolic
    parts of the application interact with each other were assessed. Afterwards, the
    standard procedures to verify and validate common approaches used on the symbolic
    as well as the subsymbolic part were surveyed. Based on this, it was analyzed
    whether it is possible to apply these strategies to popular neurosymbolic applications
    mentioned in recent surveys. It was found that the applicability of current testing
    methods strongly relates to the algorithms used on the symbolic and sub-symbolic
    parts. While there are V&V methods for most approaches used on the symbolic part,
    these are sometimes too computationally expensive for large-scale projects. Therefore,
    it is important to question how thorough the testing on this side has to be, since
    neural networks can handle noisy data well if the symbolic part is only supporting.
    For the subsymbolic side, current testing frameworks can often be used for the
    V&V. These may be modified if necessary, however, this area is still a vivid research
    area, and it may happen that neurosymbolic applications use concepts for which
    no current testing framework exist. Furthermore, some applications demonstrate
    how the symbolic part of the application can be used to make neural networks more
    transparent, robust or accurate. This approach offers many opportunities and is
    still very unexplored, so it is exciting to explore this technique in future works
    including different environments and applications. In addition, it was found that
    there is a growing need for dedicated testing frameworks specialized for domainspecific
    neurosymbolic applications.


    ## REFERENCES


    - <span id="page-11-0"></span>[1] A. d. Garcez and L. C. Lamb, "Neurosymbolic
    ai: The 3 rd wave," *Artificial Intelligence Review*, pp. 1–20, 2023.

    - <span id="page-11-1"></span>[2] C. M. Bishop, "Neural networks and their applications,"
    *Review of scientific instruments*, vol. 65, no. 6, pp. 1803–1832, 1994.

    - <span id="page-11-2"></span>[3] M. Garnelo and M. Shanahan, "Reconciling deep
    learning with symbolic artificial intelligence: representing objects and relations,"
    *Current Opinion in Behavioral Sciences*, vol. 29, pp. 17–23, 2019.

    - <span id="page-11-3"></span>[4] K. Acharya, W. Raza, C. Dourado, A. Velasquez,
    and H. H. Song, "Neurosymbolic reinforcement learning and planning: A survey,"
    *IEEE Transactions on Artificial Intelligence*, pp. 1–14, 2023.

    - <span id="page-11-4"></span>[5] A. Velasquez, "Transfer from imprecise and abstract
    models to autonomous technologies (tiamat)," *Defense Advanced Research Projects
    Agency (DARPA) Program Solicitation*, 2023.

    - <span id="page-11-5"></span>[6] Oct 2023. [Online]. Available: [https://www.whitehouse.gov/briefing-r](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)
    [oom/presidential-actions/2023/10/30/executive-order-on-the-safe-sec](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)
    [ure-and-trustworthy-development-and-use-of-artificial-intelligence/](https://www.whitehouse.gov/briefing-room/presidential-actions/2023/10/30/executive-order-on-the-safe-secure-and-trustworthy-development-and-use-of-artificial-intelligence/)

    - <span id="page-11-6"></span>[7] X. Huang, "Safety and reliability of deep learning:
    (brief overview)," in *Proceedings of the 1st International Workshop on Verification
    of Autonomous & Robotic Systems*, ser. VARS ''21. New York, NY, USA: Association
    for Computing Machinery, 2021. [Online]. Available: <https://doi.org/10.1145/3459086.3459636>

    - <span id="page-11-7"></span>[8] X. Huang, D. Kroening, W. Ruan, J. Sharp, Y.
    Sun, E. Thamo, M. Wu, and X. Yi, "A survey of safety and trustworthiness of deep
    neural networks: Verification, testing, adversarial attack and defence, and interpretability,"
    *Computer Science Review*, vol. 37, p. 100270, 2020. [Online]. Available: [https://www.sciencedirect.com/science/arti](https://www.sciencedirect.com/science/article/pii/S1574013719302527)
    [cle/pii/S1574013719302527](https://www.sciencedirect.com/science/article/pii/S1574013719302527)

    - <span id="page-12-0"></span>[9] D. Wallace and R. Fujii, "Software verification
    and validation: Its role in computer assurance and its relationship with software
    project management standards," 1989-09-05 1989. [Online]. Available: [https://tsapps.nist.gov/publication/get](https://tsapps.nist.gov/publication/get_pdf.cfm?pub_id=905731)
    pdf.cfm?pub id=905731

    - <span id="page-12-1"></span>[10] R. G. Sargent, "A tutorial on validation and
    verification of simulation models," in *Proceedings of the 20th conference on
    Winter simulation*, 1988, pp. 33–39.

    - <span id="page-12-2"></span>[11] D. Wallace and R. Fujii, "Software verification
    and validation: an overview," *IEEE Software*, vol. 6, no. 3, pp. 10–17, 1989.

    - <span id="page-12-3"></span>[12] H. Kautz, "The third ai summer: Aaai robert
    s. engelmore memorial lecture," *AI Magazine*, vol. 43, no. 1, pp. 93–104, Mar.
    2022. [Online]. Available: <https://ojs.aaai.org/index.php/aimagazine/article/view/19122>

    - <span id="page-12-4"></span>[13] D. Yu, B. Yang, D. Liu, H. Wang, and S. Pan,
    "A survey on neural-symbolic learning systems," *Neural Networks*, vol. 166, pp.
    105–126, 2023. [Online]. Available: [https://www.sciencedirect.com/sc](https://www.sciencedirect.com/science/article/pii/S0893608023003398)
    [ience/article/pii/S0893608023003398](https://www.sciencedirect.com/science/article/pii/S0893608023003398)

    - <span id="page-12-5"></span>[14] J. M. Zhang, M. Harman, L. Ma, and Y. Liu,
    "Machine learning testing: Survey, landscapes and horizons," *IEEE Transactions
    on Software Engineering*, vol. 48, no. 01, pp. 1–36, 2022.

    - <span id="page-12-7"></span>[15] H. B. Braiek and F. Khomh, "On testing machine
    learning programs," *Journal of Systems and Software*, vol. 164, p. 110542, 2020.
    [Online]. Available: [https://www.sciencedirect.com/science/article/pii/S0164121](https://www.sciencedirect.com/science/article/pii/S0164121220300248)
    [220300248](https://www.sciencedirect.com/science/article/pii/S0164121220300248)

    - <span id="page-12-6"></span>[16] R. C. Cardoso, G. Kourtis, L. A. Dennis, C.
    Dixon, M. Farrell, M. Fisher, and M. Webster, "A review of verification and validation
    for space autonomous systems," *Current Robotics Reports*, vol. 2, no. 3, pp.
    273–283, 2021.

    - <span id="page-12-8"></span>[17] A. d. Garcez, S. Bader, H. Bowman, L. C. Lamb,
    L. de Penning, B. Illuminoo, H. Poon, and C. G. Zaverucha, "Neural-symbolic learning
    and reasoning: A survey and interpretation," *Neuro-Symbolic Artificial Intelligence:
    The State of the Art*, vol. 342, no. 1, p. 327, 2022.

    - <span id="page-12-13"></span>[18] A. Sheth, K. Roy, and M. Gaur, "Neurosymbolic
    artificial intelligence (why, what, and how)," *IEEE Intelligent Systems*, vol.
    38, no. 3, pp. 56–62, 2023.

    - [19] M. Gaur, K. Gunaratna, S. Bhatt, and A. Sheth, "Knowledge-infused learning:
    A sweet spot in neuro-symbolic ai," *IEEE Internet Computing*, vol. 26, no. 4,
    pp. 5–11, 2022.

    - [20] P. Hitzler and M. K. Sarker, *Neuro-Symbolic Artificial Intelligence: The
    state of the art*. IOS Press, 2022.

    - [21] M. K. Sarker, L. Zhou, A. Eberhart, and P. Hitzler, "Neuro-symbolic artificial
    intelligence," *AI Communications*, vol. 34, no. 3, pp. 197–209, 2021.

    - <span id="page-12-14"></span>[22] Z. Susskind, B. Arden, L. K. John, P. Stockton,
    and E. B. John, "Neuro-symbolic ai: An emerging class of ai workloads and their
    characterization," *arXiv preprint arXiv:2109.06133*, 2021.

    - [23] W. Wang and Y. Yang, "Towards data-and knowledge-driven artificial intelligence:
    A survey on neuro-symbolic computing," *arXiv preprint arXiv:2210.15889*, 2022.

    - <span id="page-12-9"></span>[24] W. Gibaut, L. Pereira, F. Grassiotto, A. Osorio,
    E. Gadioli, A. Munoz, S. Gomes, and C. d. Santos, "Neurosymbolic ai and its taxonomy:
    a survey," *arXiv preprint arXiv:2305.08876*, 2023.

    - <span id="page-12-10"></span>[25] L. N. DeLong, R. F. Mir, M. Whyte, Z. Ji,
    and J. D. Fleuriot, "Neurosymbolic ai for reasoning on graph structures: A survey,"
    *arXiv preprint arXiv:2302.07200*, 2023.

    - <span id="page-12-11"></span>[26] L. N. DeLong, R. F. Mir, Z. Ji, F. N. C. Smith,
    and J. D. Fleuriot, "Neurosymbolic ai for reasoning on biomedical knowledge graphs,"
    *arXiv preprint arXiv:2307.08411*, 2023.

    - <span id="page-12-12"></span>[27] K. Hamilton, A. Nayak, B. Boziˇ c, and L.
    Longo, "Is neuro-symbolic ´ ai meeting its promises in natural language processing?
    a structured review," *Semantic Web*, no. Preprint, pp. 1–42, 2022.

    - <span id="page-12-15"></span>[28] K. W. Church, "Word2vec," *Natural Language
    Engineering*, vol. 23, no. 1, pp. 155–162, 2017.

    - <span id="page-12-16"></span>[29] J. Pennington, R. Socher, and C. D. Manning,
    "Glove: Global vectors for word representation," in *Proceedings of the 2014 conference
    on empirical methods in natural language processing (EMNLP)*, 2014, pp. 1532–1543.

    - <span id="page-12-17"></span>[30] D. Silver, J. Schrittwieser, K. Simonyan,
    I. Antonoglou, A. Huang, A. Guez, T. Hubert, L. Baker, M. Lai, A. Bolton *et al.*,
    "Mastering the game of go without human knowledge," *nature*, vol. 550, no. 7676,
    pp. 354–359, 2017.

    - <span id="page-12-18"></span>[31] J. Mao, C. Gan, P. Kohli, J. B. Tenenbaum,
    and J. Wu, "The neuro-symbolic concept learner: Interpreting scenes, words, and
    sentences from natural supervision," *CoRR*, vol. abs/1904.12584, 2019. [Online].
    Available: <http://arxiv.org/abs/1904.12584>

    - <span id="page-12-19"></span>[32] R. Manhaeve, S. Dumancic, A. Kimmig, T. Demeester,
    and L. De Raedt, "Deepproblog: Neural probabilistic logic programming," *Advances
    in neural information processing systems*, vol. 31, 2018.

    - <span id="page-12-20"></span>[33] G. Lample and F. Charton, "Deep learning for
    symbolic mathematics," *CoRR*, vol. abs/1912.01412, 2019. [Online]. Available:
    [http://arxiv.or](http://arxiv.org/abs/1912.01412) [g/abs/1912.01412](http://arxiv.org/abs/1912.01412)

    - <span id="page-12-21"></span>[34] L. Serafini, I. Donadello, and A. d. Garcez,
    "Learning and reasoning in logic tensor networks: Theory and application to semantic
    image interpretation," in *Proceedings of the Symposium on Applied Computing*,
    ser. SAC ''17. New York, NY, USA: Association for Computing Machinery, 2017, p.
    125–130. [Online]. Available: <https://doi.org/10.1145/3019612.3019642>

    - <span id="page-12-22"></span>[35] P. Smolensky, M. Lee, X. He, W.-t. Yih, J.
    Gao, and L. Deng, "Basic reasoning with tensor product representations," 2016.
    [Online]. Available: <https://arxiv.org/abs/1601.02745>

    - <span id="page-12-23"></span>[36] D. Kahneman, *Thinking, fast and slow*. New
    York: Farrar, Straus and Giroux, 2011.

    - <span id="page-12-24"></span>[37] M. Alshiekh, R. Bloem, R. Ehlers, B. Konighofer,
    S. Niekum, and ¨ U. Topcu, "Safe reinforcement learning via shielding," in *Proceedings
    of the Thirty-Second AAAI Conference on Artificial Intelligence and Thirtieth
    Innovative Applications of Artificial Intelligence Conference and Eighth AAAI
    Symposium on Educational Advances in Artificial Intelligence*, ser. AAAI''18/IAAI''18/EAAI''18.
    AAAI Press, 2018.

    - <span id="page-12-25"></span>[38] M. Alshiekh, R. Bloem, R. Ehlers, B. Konighofer,
    S. Niekum, and ¨ U. Topcu, "Safe reinforcement learning via shielding," *arXiv
    preprint arXiv:1708.08611*, 2017.

    - <span id="page-12-26"></span>[39] I. H. Anellis, "Peirce''s truth-functional
    analysis and the origin of the truth table," *History and Philosophy of Logic*,
    vol. 33, no. 1, pp. 87–97, 2012.

    - <span id="page-12-27"></span>[40] E. W. Beth, *Semantic Entailment and Formal
    Derivability*. Noord-Hollandsche, 1955.

    - <span id="page-12-28"></span>[41] W. Schwarz, "GitHub - wo/tpg: Tree Proof Generator
    — github.com," [https://github.com/wo/tpg,](https://github.com/wo/tpg) [Accessed
    01-Dec-2022].

    - <span id="page-12-29"></span>[42] E. Huaman, E. Karle, and D. Fensel, "Knowledge
    graph validation," ¨ 2020. [Online]. Available: <https://arxiv.org/abs/2005.01389>

    - <span id="page-12-30"></span>[43] Z. H. Syed, N. Srivastava, M. Roder, and A.-C.
    N. Ngomo, "Copaal- ¨ an interface for explaining facts using corroborative paths."
    in *ISWC (Satellites)*, 2019, pp. 201–204.

    - <span id="page-12-31"></span>[44] J. Lehmann, D. Gerber, M. Morsey, and A.-C.
    Ngonga Ngomo, "Defacto-deep fact validation," in *International semantic web conference*.
    Springer, 2012, pp. 312–327.

    - <span id="page-12-32"></span>[45] A. Rula, M. Palmonari, S. Rubinacci, A.-C.
    Ngonga Ngomo, J. Lehmann, A. Maurino, and D. Esteves, "Tisco: Temporal scoping
    of facts," in *Companion Proceedings of The 2019 World Wide Web Conference*, 2019,
    pp. 959–960.

    - <span id="page-12-33"></span>[46] Z. H. Syed, M. Roder, and A.-C. Ngonga Ngomo,
    "Factcheck: Validat- ¨ ing rdf triples using textual evidence," in *Proceedings
    of the 27th ACM International Conference on Information and Knowledge Management*,
    2018, pp. 1599–1602.

    - <span id="page-12-34"></span>[47] G. Ercan, S. Elbassuoni, and K. Hose, "Retrieving
    textual evidence for knowledge graph facts," in *European Semantic Web Conference*.
    Springer, 2019, pp. 52–67.

    - <span id="page-12-35"></span>[48] R. Speck and A.-C. N. Ngomo, "Leopard—a baseline
    approach to attribute prediction and validation for knowledge graph population,"
    *Journal of Web Semantics*, vol. 55, pp. 102–107, 2019.

    - <span id="page-12-36"></span>[49] A. Padia, F. Ferraro, and T. Finin, "Surface:
    semantically rich fact validation with explanations," *arXiv preprint arXiv:1810.13223*,
    2018.

    - <span id="page-12-37"></span>[50] S. Metzger, S. Elbassuoni, K. Hose, and R.
    Schenkel, "S3k: seeking statement-supporting top-k witnesses," in *Proceedings
    of the 20th ACM international conference on Information and knowledge management*,
    2011, pp. 37–46.

    - <span id="page-12-38"></span>[51] T. Rebele, F. Suchanek, J. Hoffart, J. Biega,
    E. Kuzey, and G. Weikum, "Yago: A multilingual knowledge base from wikipedia,
    wordnet, and geonames," in *The Semantic Web–ISWC 2016: 15th International Semantic
    Web Conference, Kobe, Japan, October 17–21, 2016, Proceedings, Part II 15*. Springer,
    2016, pp. 177–185.

    - <span id="page-12-39"></span>[52] R. Speer, J. Chin, and C. Havasi, "Conceptnet
    5.5: An open multilingual graph of general knowledge," in *Proceedings of the
    AAAI conference on artificial intelligence*, vol. 31, no. 1, 2017.

    - <span id="page-12-40"></span>[53] D. Ferrucci, E. Brown, J. Chu-Carroll, J.
    Fan, D. Gondek, A. A. Kalyanpur, A. Lally, J. W. Murdock, E. Nyberg, J. Prager
    *et al.*, "Building watson: An overview of the deepqa project," *AI magazine*,
    vol. 31, no. 3, pp. 59–79, 2010.

    - <span id="page-12-41"></span>[54] G. A. Miller, "Wordnet: A lexical database
    for english," *Commun. ACM*, vol. 38, no. 11, p. 39–41, nov 1995. [Online]. Available:
    <https://doi.org/10.1145/219717.219748>

    - <span id="page-12-42"></span>[55] N. Drenkow, N. Sani, I. Shpitser, and M. Unberath,
    "A systematic review of robustness in deep learning for computer vision: Mind
    the gap?" 2022.

    - <span id="page-13-0"></span>[56] M. Wicker, X. Huang, and M. Kwiatkowska, "Feature-guided
    blackbox safety testing of deep neural networks," in *Tools and Algorithms for
    the Construction and Analysis of Systems: 24th International Conference, TACAS
    2018, Held as Part of the European Joint Conferences on Theory and Practice of
    Software, ETAPS 2018, Thessaloniki, Greece, April 14-20, 2018, Proceedings, Part
    I 24*. Springer, 2018, pp. 408– 426.

    - <span id="page-13-1"></span>[57] W. Ruan, X. Huang, and M. Kwiatkowska, "Reachability
    analysis of deep neural networks with provable guarantees," in *Proceedings of
    the Twenty-Seventh International Joint Conference on Artificial Intelligence,
    IJCAI-18*. International Joint Conferences on Artificial Intelligence Organization,
    7 2018, pp. 2651–2659. [Online]. Available: <https://doi.org/10.24963/ijcai.2018/368>

    - <span id="page-13-2"></span>[58] M. Wu, M. Wicker, W. Ruan, X. Huang, and M.
    Kwiatkowska, "A game-based approximate verification of deep neural networks with
    provable guarantees," *Theoretical Computer Science*, vol. 807, pp. 298–329, 2020,
    in memory of Maurice Nivat, a founding father of Theoretical Computer Science
    - Part II. [Online]. Available: <https://www.sciencedirect.com/science/article/pii/S0304397519304426>

    - <span id="page-13-3"></span>[59] G. Katz, C. Barrett, D. L. Dill, K. Julian,
    and M. J. Kochenderfer, "Reluplex: An efficient smt solver for verifying deep
    neural networks," in *Computer Aided Verification: 29th International Conference,
    CAV 2017, Heidelberg, Germany, July 24-28, 2017, Proceedings, Part I 30*. Springer,
    2017, pp. 97–117.

    - [60] R. Ehlers, "Formal verification of piece-wise linear feed-forward neural
    networks," in *Automated Technology for Verification and Analysis: 15th International
    Symposium, ATVA 2017, Pune, India, October 3–6, 2017, Proceedings 15*. Springer,
    2017, pp. 269–286.

    - [61] R. R. Bunel, I. Turkaslan, P. Torr, P. Kohli, and P. K. Mudigonda, "A unified
    view of piecewise linear neural network verification," *Advances in Neural Information
    Processing Systems*, vol. 31, 2018.

    - [62] A. Lomuscio and L. Maganti, "An approach to reachability analysis for feed-forward
    relu neural networks," *arXiv preprint arXiv:1706.07351*, 2017.

    - [63] W. Xiang, H.-D. Tran, and T. T. Johnson, "Output reachable set estimation
    and verification for multilayer neural networks," *IEEE Transactions on Neural
    Networks and Learning Systems*, vol. 29, no. 11, pp. 5777–5783, 2018.

    - [64] C.-H. Cheng, G. Nuhrenberg, and H. Ruess, "Maximum resilience of ¨ artificial
    neural networks," in *Automated Technology for Verification and Analysis: 15th
    International Symposium, ATVA 2017, Pune, India, October 3–6, 2017, Proceedings
    15*. Springer, 2017, pp. 251–268.

    - [65] N. Narodytska, S. Kasiviswanathan, L. Ryzhyk, M. Sagiv, and T. Walsh, "Verifying
    properties of binarized deep neural networks," in *Proceedings of the AAAI Conference
    on Artificial Intelligence*, vol. 32, no. 1, 2018.

    - <span id="page-13-4"></span>[66] N. Narodytska, "Formal analysis of deep binarized
    neural networks," in *Proceedings of the Twenty-Seventh International Joint Conference
    on Artificial Intelligence, IJCAI-18*. International Joint Conferences on Artificial
    Intelligence Organization, 7 2018, pp. 5692–5696. [Online]. Available: <https://doi.org/10.24963/ijcai.2018/811>

    - <span id="page-13-5"></span>[67] T. Gehr, M. Mirman, D. Drachsler-Cohen, P.
    Tsankov, S. Chaudhuri, and M. Vechev, "Ai2: Safety and robustness certification
    of neural networks with abstract interpretation [paper presentation]," in *IEEE
    Symposium on Security and Privacy (SP), San Francisco, CA, United States. https://doi.
    org/10.1109/SP*, 2018.

    - [68] S. Wang, K. Pei, J. Whitehouse, J. Yang, and S. Jana, "Formal security
    analysis of neural networks using symbolic intervals," in *27th USENIX Security
    Symposium (USENIX Security 18)*, 2018, pp. 1599–1614.

    - [69] A. Raghunathan, J. Steinhardt, and P. Liang, "Certified defenses against
    adversarial examples," in *International Conference on Learning Representations*,
    2018.

    - <span id="page-13-6"></span>[70] W. Ruan, M. Wu, Y. Sun, X. Huang, D. Kroening,
    and M. Kwiatkowska, "Global robustness evaluation of deep neural networks with
    provable guarantees for the hamming distance," in *Proceedings of the Twenty-Eighth
    International Joint Conference on Artificial Intelligence, IJCAI-19*. International
    Joint Conferences on Artificial Intelligence Organization, 7 2019, pp. 5944–5952.
    [Online]. Available: <https://doi.org/10.24963/ijcai.2019/824>

    - <span id="page-13-7"></span>[71] X. Huang, M. Kwiatkowska, S. Wang, and M. Wu,
    "Safety verification of deep neural networks," in *Computer Aided Verification:
    29th International Conference, CAV 2017, Heidelberg, Germany, July 24-28, 2017,
    Proceedings, Part I 30*. Springer, 2017, pp. 3–29.

    - <span id="page-13-8"></span>[72] S. Dutta, S. Jha, S. Sanakaranarayanan, and
    A. Tiwari, "Output range analysis for deep neural networks," *arXiv preprint arXiv:1709.09130*,
    2017.

    - <span id="page-13-9"></span>[73] L. Pulina and A. Tacchella, "An abstraction-refinement
    approach to verification of artificial neural networks," in *Computer Aided Verification:
    22nd International Conference, CAV 2010, Edinburgh, UK, July 15-19, 2010. Proceedings
    22*. Springer, 2010, pp. 243–257.

    - [74] E. Wong and Z. Kolter, "Provable defenses against adversarial examples
    via the convex outer adversarial polytope," in *International conference on machine
    learning*. PMLR, 2018, pp. 5286–5295.

    - <span id="page-13-10"></span>[75] M. Mirman, T. Gehr, and M. Vechev, "Differentiable
    abstract interpretation for provably robust neural networks," in *International
    Conference on Machine Learning*. PMLR, 2018, pp. 3578–3586.

    - <span id="page-13-17"></span>[76] R. Kohavi *et al.*, "A study of cross-validation
    and bootstrap for accuracy estimation and model selection," in *Ijcai*, vol. 14,
    no. 2. Montreal, Canada, 1995, pp. 1137–1145.

    - <span id="page-13-18"></span>[77] B. Efron and R. J. Tibshirani, *An introduction
    to the bootstrap*. CRC press, 1994.

    - <span id="page-13-19"></span>[78] N. Japkowicz, "Why question machine learning
    evaluation methods," in *AAAI workshop on evaluation methods for machine learning*,
    2006, pp. 6–11.

    - <span id="page-13-11"></span>[79] M. Vartak, J. M. F. da Trindade, S. Madden,
    and M. Zaharia, "Mistique: A system to store and query model intermediates for
    model diagnosis," in *Proceedings of the 2018 International Conference on Management
    of Data*, ser. SIGMOD ''18. New York, NY, USA: Association for Computing Machinery,
    2018, p. 1285–1300. [Online]. Available: <https://doi.org/10.1145/3183713.3196934>

    - <span id="page-13-12"></span>[80] S. Krishnan and E. Wu, "Palm: Machine learning
    explanations for iterative debugging," in *Proceedings of the 2nd Workshop on
    Human-In-the-Loop Data Analytics*, ser. HILDA ''17. New York, NY, USA: Association
    for Computing Machinery, 2017. [Online]. Available: <https://doi.org/10.1145/3077257.3077271>

    - <span id="page-13-13"></span>[81] J. Ding, X. Kang, and X.-H. Hu, "Validating
    a deep learning framework by metamorphic testing," in *Proceedings of the 2nd
    International Workshop on Metamorphic Testing*, ser. MET ''17. IEEE Press, 2017,
    p. 28–34.

    - [82] S. Nakajima, "Generalized oracle for testing machine learning computer
    programs," in *Software Engineering and Formal Methods: SEFM 2017 Collocated Workshops:
    DataMod, FAACS, MSE, CoSim-CPS, and FOCLASA, Trento, Italy, September 4-5, 2017,
    Revised Selected Papers 15*. Springer, 2018, pp. 174–179.

    - [83] A. Dwarakanath, M. Ahuja, S. Sikand, R. M. Rao, R. J. C. Bose, N. Dubash,
    and S. Podder, "Identifying implementation bugs in machine learning based image
    classifiers using metamorphic testing," in *Proceedings of the 27th ACM SIGSOFT
    international symposium on software testing and analysis*, 2018, pp. 118–128.

    - [84] D. Pesu, Z. Q. Zhou, J. Zhen, and D. Towey, "A monte carlo method for metamorphic
    testing of machine translation services," in *Proceedings of the 3rd International
    Workshop on Metamorphic Testing*, ser. MET ''18. New York, NY, USA: Association
    for Computing Machinery, 2018, p. 38–45. [Online]. Available: <https://doi.org/10.1145/3193977.3193980>

    - [85] E. Breck, S. Cai, E. Nielsen, M. Salib, and D. Sculley, "The ml test score:
    A rubric for ml production readiness and technical debt reduction," in *2017 IEEE
    International Conference on Big Data (Big Data)*. IEEE, 2017, pp. 1123–1132.

    - <span id="page-13-14"></span>[86] S. Ma, Y. Liu, W.-C. Lee, X. Zhang, and A.
    Grama, "Mode: automated neural network model debugging via state differential
    analysis and input selection," in *Proceedings of the 2018 26th ACM Joint Meeting
    on European Software Engineering Conference and Symposium on the Foundations of
    Software Engineering*, 2018, pp. 175–186.

    - <span id="page-13-15"></span>[87] N. Hynes, D. Sculley, and M. Terry, "The data
    linter: Lightweight, automated sanity checking for ml data sets," in *NIPS MLSys
    Workshop*, vol. 1, no. 5, 2017.

    - <span id="page-13-16"></span>[88] S. Schelter, D. Lange, P. Schmidt, M. Celikel,
    F. Biessmann, and A. Grafberger, "Automating large-scale data quality verification,"
    *Proceedings of the VLDB Endowment*, vol. 11, no. 12, pp. 1781–1794, 2018.

    - <span id="page-13-20"></span>[89] K. Pei, Y. Cao, J. Yang, and S. Jana, "Deepxplore:
    Automated whitebox testing of deep learning systems," in *proceedings of the 26th
    Symposium on Operating Systems Principles*, 2017, pp. 1–18.

    - <span id="page-13-21"></span>[90] X. Xie, L. Ma, F. Juefei-Xu, M. Xue, H. Chen,
    Y. Liu, J. Zhao, B. Li, J. Yin, and S. See, "Deephunter: a coverage-guided fuzz
    testing framework for deep neural networks," in *Proceedings of the 28th ACM SIGSOFT
    International Symposium on Software Testing and Analysis*, 2019, pp. 146–157.

    - <span id="page-13-22"></span>[91] J. Guo, Y. Zhao, H. Song, and Y. Jiang, "Coverage
    guided differential adversarial testing of deep learning systems," *IEEE Transactions
    on Network Science and Engineering*, vol. 8, no. 2, pp. 933–942, 2020.

    - <span id="page-14-0"></span>[92] D. Meng and H. Chen, "Magnet: A two-pronged
    defense against adversarial examples," in *Proceedings of the 2017 ACM SIGSAC
    Conference on Computer and Communications Security*, ser. CCS ''17. New York,
    NY, USA: Association for Computing Machinery, 2017, p. 135–147. [Online]. Available:
    [https://doi.org/10.1145/3133956.313405](https://doi.org/10.1145/3133956.3134057)
    [7](https://doi.org/10.1145/3133956.3134057)

    - <span id="page-14-1"></span>[93] W. Tan, J. Renkhoff, A. Velasquez, Z. Wang,
    L. Li, J. Wang, S. Niu, F. Yang, Y. Liu, and H. Song, "Noisecam: Explainable ai
    for the boundary between noise and adversarial attacks," *arXiv preprint arXiv:2303.06151*,
    2023.

    - <span id="page-14-2"></span>[94] S. Qiu, Q. Liu, S. Zhou, and W. Huang, "Adversarial
    attack and defense technologies in natural language processing: A survey," *Neurocomputing*,
    vol. 492, pp. 278–307, 2022. [Online]. Available: <https://www.sciencedirect.com/science/article/pii/S0925231222003861>

    - <span id="page-14-3"></span>[95] N. Martins, J. M. Cruz, T. Cruz, and P. Henriques
    Abreu, "Adversarial machine learning applied to intrusion and malware scenarios:
    A systematic review," *IEEE Access*, vol. 8, pp. 35 403–35 419, 2020.

    - <span id="page-14-4"></span>[96] O. Biran and C. Cotton, "Explanation and justification
    in machine learning: A survey," in *IJCAI-17 workshop on explainable AI (XAI)*,
    vol. 8, no. 1, 2017, pp. 8–13.

    - <span id="page-14-5"></span>[97] C. Molnar, *Interpretable Machine Learning*,
    2nd ed., 2022. [Online]. Available: <https://christophm.github.io/interpretable-ml-book>

    - <span id="page-14-6"></span>[98] S. Ruiter and N. D. De Graaf, "National context,
    religiosity, and volunteering: Results from 53 countries," *American Sociological
    Review*, vol. 71, no. 2, pp. 191–210, 2006.

    - <span id="page-14-7"></span>[99] R. D. Cook, "Detection of influential observation
    in linear regression," *Technometrics*, vol. 19, no. 1, pp. 15–18, 1977.

    - <span id="page-14-8"></span>[100] G. Anderson, A. Verma, I. Dillig, and S. Chaudhuri,
    "Neurosymbolic reinforcement learning with formally verified exploration," *Advances
    in neural information processing systems*, vol. 33, pp. 6172–6183, 2020.

    - <span id="page-14-9"></span>[101] T. P. Lillicrap, J. J. Hunt, A. Pritzel, N.
    Heess, T. Erez, Y. Tassa, D. Silver, and D. Wierstra, "Continuous control with
    deep reinforcement learning," *arXiv preprint arXiv:1509.02971*, 2015.

    - <span id="page-14-10"></span>[102] J. Achiam, D. Held, A. Tamar, and P. Abbeel,
    "Constrained policy optimization," in *International conference on machine learning*.
    PMLR, 2017, pp. 22–31.

    - <span id="page-14-11"></span>[103] S. Gu, L. Yang, Y. Du, G. Chen, F. Walter,
    J. Wang, Y. Yang, and A. Knoll, "A review of safe reinforcement learning: Methods,
    theory and applications," *arXiv preprint arXiv:2205.10330*, 2022.

    - <span id="page-14-12"></span>[104] O. Bastani, Y. Pu, and A. Solar-Lezama, "Verifiable
    reinforcement learning via policy extraction," in *Advances in Neural Information
    Processing Systems*, S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi,
    and R. Garnett, Eds., vol. 31. Curran Associates, Inc., 2018. [Online]. Available:
    [https://proceedings.neurip](https://proceedings.neurips.cc/paper/2018/file/e6d8545daa42d5ced125a4bf747b3688-Paper.pdf)
    [s.cc/paper/2018/file/e6d8545daa42d5ced125a4bf747b3688-Paper.pdf](https://proceedings.neurips.cc/paper/2018/file/e6d8545daa42d5ced125a4bf747b3688-Paper.pdf)

    - <span id="page-14-13"></span>[105] Y. Tian, A. Luo, X. Sun, K. Ellis, W. T.
    Freeman, J. B. Tenenbaum, and J. Wu, "Learning to infer and execute 3d shape programs,"
    *arXiv preprint arXiv:1901.02875*, 2019.

    - <span id="page-14-14"></span>[106] D. Trivedi, J. Zhang, S.-H. Sun, and J. J.
    Lim, "Learning to synthesize programs as interpretable and generalizable policies,"
    *Advances in neural information processing systems*, vol. 34, pp. 25 146–25 163,
    2021.

    - <span id="page-14-15"></span>[107] J. Huang, Z. Li, D. Jacobs, M. Naik, and
    S.-N. Lim, "Laser: Neurosymbolic learning of semantic video representations,"
    *arXiv preprint arXiv:2304.07647*, 2023.

    - <span id="page-14-16"></span>[108] X. Wang, Y. Ye, and A. Gupta, "Zero-shot
    recognition via semantic embeddings and knowledge graphs," in *Proceedings of
    the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, June 2018.

    - <span id="page-14-17"></span>[109] A. Carlson, J. Betteridge, B. Kisiel, B.
    Settles, E. R. Hruschka, and T. M. Mitchell, "Toward an architecture for never-ending
    language learning," in *Twenty-Fourth AAAI conference on artificial intelligence*,
    2010.

    - <span id="page-14-18"></span>[110] X. Chen, A. Shrivastava, and A. Gupta, "Neil:
    Extracting visual knowledge from web data," in *Proceedings of the IEEE international
    conference on computer vision*, 2013, pp. 1409–1416.

    - <span id="page-14-19"></span>[111] O. Russakovsky, J. Deng, H. Su, J. Krause,
    S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein *et al.*, "Imagenet
    large scale visual recognition challenge," *International journal of computer
    vision*, vol. 115, no. 3, pp. 211–252, 2015.

    - <span id="page-14-20"></span>[112] D. Zugner and S. G ¨ unnemann, "Certifiable
    robustness and robust ¨ training for graph convolutional networks," in *Proceedings
    of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data
    Mining*, 2019, pp. 246–256.

    - <span id="page-14-21"></span>[113] V. P. Dwivedi, C. K. Joshi, A. T. Luu, T.
    Laurent, Y. Bengio, and X. Bresson, "Benchmarking graph neural networks," *Journal
    of Machine Learning Research*, vol. 24, no. 43, pp. 1–48, 2023.

    - <span id="page-14-22"></span>[114] V. Fung, J. Zhang, E. Juarez, and B. G. Sumpter,
    "Benchmarking graph neural networks for materials chemistry," *npj Computational
    Materials*, vol. 7, no. 1, p. 84, 2021.

    - <span id="page-14-23"></span>[115] N. Metropolis and S. Ulam, "The monte carlo
    method," *Journal of the American statistical association*, vol. 44, no. 247,
    pp. 335–341, 1949.

    - <span id="page-14-24"></span>[116] R. Manhaeve, S. Dumancic, A. Kimmig, T. Demeester,
    and L. De Raedt, "Deepproblog: Neural probabilistic logic programming," *Advances
    in Neural Information Processing Systems*, vol. 31, 2018.

    - <span id="page-14-25"></span>[117] A. D. Gordon, T. A. Henzinger, A. V. Nori,
    and S. K. Rajamani, "Probabilistic programming," in *Future of Software Engineering
    Proceedings*, 2014, pp. 167–181.

    - <span id="page-14-26"></span>[118] J. Guo, Y. Jiang, Y. Zhao, Q. Chen, and J.
    Sun, "Dlfuzz: Differential fuzzing testing of deep learning systems," in *Proceedings
    of the 2018 26th ACM Joint Meeting on European Software Engineering Conference
    and Symposium on the Foundations of Software Engineering*, 2018, pp. 739–743.

    - <span id="page-14-27"></span>[119] M. Bosnjak, T. Rockt ˇ aschel, J. Naradowsky,
    and S. Riedel, "Program- ¨ ming with a differentiable forth interpreter," in *International
    conference on machine learning*. PMLR, 2017, pp. 547–556.

    - <span id="page-14-28"></span>[120] A. Odena, C. Olsson, D. Andersen, and I.
    Goodfellow, "Tensorfuzz: Debugging neural networks with coverage-guided fuzzing,"
    in *International Conference on Machine Learning*. PMLR, 2019, pp. 4901– 4911.

    - <span id="page-14-29"></span>[121] A. Darwiche, "Sdd: A new canonical representation
    of propositional knowledge bases," in *Twenty-Second International Joint Conference
    on Artificial Intelligence*, 2011.

    - <span id="page-14-30"></span>[122] E. Kern, L. M. Hilty, A. Guldner, Y. V. Maksimov,
    A. Filler, J. Groger, ¨ and S. Naumann, "Sustainable software products—towards
    assessment criteria for resource and energy efficiency," *Future Generation Computer
    Systems*, vol. 86, pp. 199–210, 2018. [Online]. Available: [ht](https://www.sciencedirect.com/science/article/pii/S0167739X17314188)
    [tps://www.sciencedirect.com/science/article/pii/S0167739X17314188](https://www.sciencedirect.com/science/article/pii/S0167739X17314188)

    - <span id="page-14-31"></span>[123] A. Guldner and J. Murach, "Measuring and
    assessing the resource and energy efficiency of artificial intelligence of things
    devices and algorithms," in *Advances and New Trends in Environmental Informatics:
    Environmental Informatics and the UN Sustainable Development Goals*. Springer,
    2022, pp. 185–199.

    - <span id="page-14-32"></span>[124] N. Ngu, N. Lee, and P. Shakarian, "Diversity
    measures: Domainindependent proxies for failure in language model queries," 2023.

    - <span id="page-14-33"></span>[125] Z. Li, J. Huang, and M. Naik, "Scallop: A
    language for neurosymbolic programming," *Proceedings of the ACM on Programming
    Languages*, vol. 7, no. PLDI, pp. 1463–1487, 2023.


    ![](_page_14_Picture_34.jpeg)


    Justus Renkhoff earned a bachelor''s and master''s degrees in Media and Computer
    Science from Trier University of Applied Sciences, Germany in 2019 and 2021, respectively.
    He is currently pursuing a doctorate degree. Previously, he worked at the Institute
    for Software Systems at Trier University of Applied Sciences, the Security and
    Optimization for Networked Globe Laboratory (SONG Lab) at Embry-Riddle Aeronautical
    University and University of Maryland, Baltimore County and taught as an adjunct
    instructor at St. Bonaventure University,


    New York. His research focuses on explainable and neurosymbolic AI.


    ![](_page_14_Picture_37.jpeg)


    Ke Feng received master''s degree in Electrical and Computer Engineering from
    Embry-Riddle Aeronautical University(ERAU), Daytona Beach, Florida. She is currently
    pursuing a Ph.D. degree in Electrical Engineering and Computer Science at Security
    and Optimization for Networked Globe Laboratory, ERAU. Her major research interests
    include machine learning, deep learning, and the Internet of Things.


    ![](_page_15_Picture_1.jpeg)


    Marc Meier-Doernberg earned his master''s degree in Data Science from Embry-Riddle
    Aeronautical University, Daytona Beach, Florida. He currently works as a Lead
    Analyst for United Airlines where he develops data-driven approaches to air traffic
    management. He previously worked for Lufthansa Group and contributed to various
    analytics projects. He focuses on deep learning, machine learning, and their applications
    in aviation.


    ![](_page_15_Picture_3.jpeg)


    Alvaro Velasquez is a program manager in the Innovation Information Office (I2O)
    of the Defense Advanced Research Projects Agency (DARPA), where he currently leads
    the Assured Neuro-Symbolic Learning and Reasoning (ANSR) program. Before that,
    Alvaro oversaw the machine intelligence portfolio of investments for the Information
    Directorate of the Air Force Research Laboratory (AFRL). Alvaro received his PhD
    in Computer Science from the University of Central Florida and is a recipient
    of the National Science Foundation Graduate Research


    Fellowship Program (NSF GRFP) award, the University of Central Florida 30 Under
    30 award, a distinguished paper award from AAAI, and best paper and patent awards
    from AFRL. He has co-authored 60 papers and two patents and serves as Associate
    Editor of the IEEE Transactions on Artificial Intelligence and his research has
    been funded by the Air Force Office of Scientific Research.


    ![](_page_15_Picture_6.jpeg)


    Houbing Herbert Song (M''12–SM''14-F''23) received the Ph.D. degree in electrical
    engineering from the University of Virginia, Charlottesville, VA, in August 2012.


    He is currently a Professor, the Director of the NSF Center for Aviation Big Data
    Analytics (Planning), the Associate Director for Leadership of the DOT Transportation
    Cybersecurity Center for Advanced Research and Education (Tier 1 Center), and
    the Director of the Security and Optimization for Networked Globe Laboratory (SONG
    Lab,


    www.SONGLab.us), University of Maryland, Baltimore County (UMBC), Baltimore, MD.
    Prior to joining UMBC, he was a Tenured Associate Professor of Electrical Engineering
    and Computer Science at Embry-Riddle Aeronautical University, Daytona Beach, FL.
    He serves as an Associate Editor for IEEE Transactions on Artificial Intelligence
    (TAI) (2023-present), IEEE Internet of Things Journal (2020-present), IEEE Transactions
    on Intelligent Transportation Systems (2021-present), and IEEE Journal on Miniaturization
    for Air and Space Systems (J-MASS) (2020-present). He was an Associate Technical
    Editor for IEEE Communications Magazine (2017-2020). He is the editor of ten books,
    the author of more than 100 articles and the inventor of 2 patents. His research
    interests include cyber-physical systems/internet of things, cybersecurity and
    privacy, and AI/machine learning/big data analytics. His research has been sponsored
    by federal agencies (including National Science Foundation, National Aeronautics
    and Space Administration, US Department of Transportation, and Federal Aviation
    Administration, among others) and industry. His research has been featured by
    popular news media outlets, including IEEE GlobalSpec''s Engineering360, Association
    for Uncrewed Vehicle Systems International (AUVSI), Security Magazine, CXOTech
    Magazine, Fox News, U.S. News & World Report, The Washington Times, and New Atlas.


    Dr. Song is an IEEE Fellow (for contributions to big data analytics and integration
    of AI with Internet of Things), an Asia-Pacific Artificial Intelligence Association
    (AAIA) Fellow, an ACM Distinguished Member (for outstanding scientific contributions
    to computing), and a Full Member of Sigma Xi. Dr. Song has been a Highly Cited
    Researcher identified by Web of Science since 2021. He is an ACM Distinguished
    Speaker (2020 present), an IEEE Vehicular Technology Society (VTS) Distinguished
    Lecturer (2023-present) and an IEEE Systems Council Distinguished Lecturer (2023
    present). Dr. Song received Research.com Rising Star of Science Award in 2022,
    2021 Harry Rowe Mimno Award bestowed by IEEE Aerospace and Electronic Systems
    Society, and 10+ Best Paper Awards from major international conferences, including
    IEEE CPSCom-2019, IEEE ICII 2019, IEEE/AIAA ICNS 2019, IEEE CBDCom 2020, WASA
    2020, AIAA/ IEEE DASC 2021, IEEE GLOBECOM 2021 and IEEE INFOCOM 2022.'
  decisions:
    evaluation_prompt: 'Qualified. Reason: The abstract and introduction mention the
      evaluation of neurosymbolic AI applications, the assessment of current testing
      and evaluation (T&E) and validation & verification (V&V) methods, and the analysis
      of how different architectures impact these processes, indicating structured
      evaluation is included.'
    related_work_prompt: 'Qualified. Reason: The abstract and introduction contain
      multiple academic citations and references to prior work, discussing the concepts
      of symbolic and sub-symbolic AI, as well as mentioning existing taxonomies and
      frameworks related to validation and verification (V&V) processes. This indicates
      meaningful engagement with earlier research.'
    novelty_prompt: 'Qualified. Reason: The paper explicitly states its contributions,
      including presenting and comparing two taxonomies of neurosymbolic AI, mapping
      V&V concepts to symbolic and sub-symbolic AI, and investigating how symbolic
      AI can support the V&V process of sub-symbolic AI within a neurosymbolic system.
      These claims indicate new contributions and research potential in the field.'
    review_only_prompt: 'Disqualified: review paper. Reason: The title contains the
      word "survey," and the abstract and introduction describe the paper as primarily
      summarizing existing work without proposing new methods, results, or tools.'
  llm_input_used: '## Abstract

    Neurosymbolic artificial intelligence (AI) is an emerging branch of AI that

    combines the strengths of symbolic AI and sub-symbolic AI. A major drawback of

    sub-symbolic AI is that it acts as a "black box", meaning that predictions are

    difficult to explain, making the testing & evaluation (T&E) and validation &

    verification (V&V) processes of a system that uses sub-symbolic AI a challenge.

    Since neurosymbolic AI combines the advantages of both symbolic and

    sub-symbolic AI, this survey explores how neurosymbolic applications can ease

    the V&V process. This survey considers two taxonomies of neurosymbolic AI,

    evaluates them, and analyzes which algorithms are commonly used as the symbolic

    and sub-symbolic components in current applications. Additionally, an overview

    of current techniques for the T&E and V&V processes of these components is

    provided. Furthermore, it is investigated how the symbolic part is used for T&E

    and V&V purposes in current neurosymbolic applications. Our research shows that

    neurosymbolic AI as great potential to ease the T&E and V&V processes of

    sub-symbolic AI by leveraging the possibilities of symbolic AI. Additionally,

    the applicability of current T&E and V&V methods to neurosymbolic AI is

    assessed, and how different neurosymbolic architectures can impact these

    methods is explored. It is found that current T&E and V&V techniques are partly

    sufficient to test, evaluate, verify, or validate the symbolic and sub-symbolic

    part of neurosymbolic applications independently, while some of them use

    approaches where current T&E and V&V methods are not applicable by default, and

    adjustments or even new approaches are needed. Our research shows that there is

    great potential in using symbolic AI to test, evaluate, verify, or validate the

    predictions of a sub-symbolic model, making neurosymbolic AI an interesting

    research direction for safe, secure, and trustworthy AI.


    ## Introduction

    N EUROSYMBOLIC artificial intelligence (AI) is an increasingly important trend
    in machine learning (ML) and has been referred to as the 3rd wave of artificial
    intelligence [\[1\]](#page-11-0). The word "neuro" in its name implies the use
    of neural networks, especially deep learning (DL), which is sometimes also referred
    to as sub-symbolic AI. This technique is known for its powerful learning and abstraction
    ability, allowing models to find underlying patterns in large datasets or learn
    complex behaviors [\[2\]](#page-11-1). On the other hand, "symbolic" refers to
    symbolic AI. It is based on the idea that intelligence can be represented using
    symbols like rules based on logic or other representations of knowledge [\[3\]](#page-11-2).
    Neurosymbolic AI combines these two approaches to create a hybrid system that
    benefits from the reasoning abilities of symbolic AI and the adaptability of sub-symbolic
    AI, opening new opportunities to improve a variety of different AI branches [\[4\]](#page-11-3),
    [\[5\]](#page-11-4).


    A disadvantage of sub-symbolic AI is its nature of being a "black box". This means
    that predictions made by these systems can be challenging to explain. Therefore,
    when an edge case leads to a system failure, it is often hard to find the reason
    for it. Accordingly, the rigorous testing & evaluation (T&E) and validation &
    verification (V&V) of these "black box" is a relevant topic recognized by governments
    [\[6\]](#page-11-5) and discussed in current literature [\[7\]](#page-11-6), [\[8\]](#page-11-7).
    As neurosymbolic systems incorporate a sub-symbolic component, this work aims
    to provide an overview of current techniques used to validate and verify the symbolic
    as well as sub-symbolic component, and how the architecture of neurosymbolic systems
    affects this process and can be used for V&V purposes.


    In software engineering, common terms are testing & evaluation or T&E and verification
    & validation or V&V. As defined by Wallace and Fujii in [\[9\]](#page-12-0), V&V
    intends to ensure that software performs as intended and meets certain quality
    and reliability standards. T&E are the methods and processes used to carry out
    V&V. Validation refers to the process of ensuring that a system performs as expected
    and delivers the desired result with sufficient accuracy, while verification focuses
    on checking if the design and implementation is correct according to the specified
    requirements [\[10\]](#page-12-1). Usually, verification is a process that takes
    place during development, while validation occurs at the end to evaluate if the
    program "does what it''s supposed to do" [\[11\]](#page-12-2). For reasons of
    readability, we primarily use the term V&V in the following.


    Recent frameworks propose methods to validate and verify symbolic and sub-symbolic
    AI, but discussing how the architecture of neurosymbolic AI can benefit the V&V
    process of the system as a whole has not received enough attention yet. Therefore,
    this paper focuses on two areas. First, the concept of V&V is mapped to symbolic
    and sub-symbolic AI, and an overview of current techniques and procedures used
    during the V&V process is provided. Secondly, it assesses how different neurosymbolic
    applications use the symbolic side to enable V&V of the sub-symbolic component.
    For this purpose, two different taxonomies of neurosymbolic AI are addressed,
    which categorize applications based on their architecture. 1) In 2020, Kautz proposed
    six possible designs of neurosymbolic systems [\[12\]](#page-12-3). 2) An alternative
    taxonomy was introduced by Yu et al. [\[13\]](#page-12-4) in 2021. These taxonomies
    are discussed and compared. Based on this, it is analyzed how current neurosymbolic
    applications leverage these architectures to use the symbolic component to make
    the sub-symbolic part more transparent, accurate, or safe, therefore enabling
    the V&V process through a neurosymbolic system design. The structure of the discussion
    within this paper is visualized in Fig. [1.](#page-2-0)


    Our work demonstrates that some of the current testing methods used for V&V are
    applicable to neurosymbolic AI. In particular, the combination of knowledge graphs
    (KGs) and DL is common, and it would be interesting to design a dedicated testing
    framework based on current techniques to validate neurosymbolic AI as a whole.
    However, there are also neurosymbolic AI applications that are not easy to test
    with current means. With this work, we show that there is much research potential
    in this area, and advocate the awareness of V&V for neurosymbolic AI systems and
    AI in general. Overall, this paper makes the following contributions:


    - Present and compare two current taxonomies of neurosymbolic AI.

    - Map the concepts of V&V as used in software engineer-


    ![](_page_2_Figure_6.jpeg)


    <span id="page-2-0"></span>Fig. 1. Contents of this paper.


    ing to symbolic and sub-symbolic AI.


    - Survey current V&V approaches for symbolic and subsymbolic AI.

    - Analyze the applicability of current V&V methods to neurosymbolic applications.

    - Investigate how symbolic AI can support the V&V process of sub-symbolic AI within
    a neurosymbolic system.

    - Discuss opportunities and challenges of V&V in the domain of neurosymbolic AI.


    The remainder of this paper is structured as follows: In section [II](#page-2-1)
    we analyze the related work. After that, in section [III](#page-3-0) we examine
    and compare two different taxonomies for neurosymbolic AI. Then, in section [IV](#page-5-0)
    and [V](#page-6-0) we survey the most important methods to verify and validate
    symbolic AI and sub-symbolic AI respectively. In section [VI](#page-8-0) we analyze
    if these methods are applicable to current neurosymbolic AI applications and opportunities
    to leverage different neurosymbolic architectures using the symbolic part to verify
    and validate sub-symbolic AI. Afterward, in section [VII](#page-10-0) we explain
    research gaps and problems that might be worth exploring in further research.
    In section [VIII](#page-11-8) we summarize our findings and explain our planned
    future work.'
  token_usage: 8366
  time_usage: 5.780176877975464
- title: 'Computational Argumentation-based Chatbots: a Survey'
  abstract: 'Chatbots are conversational software applications designed to interact

    dialectically with users for a plethora of different purposes. Surprisingly,

    these colloquial agents have only recently been coupled with computational

    models of arguments (i.e. computational argumentation), whose aim is to

    formalise, in a machine-readable format, the ordinary exchange of information

    that characterises human communications. Chatbots may employ argumentation with

    different degrees and in a variety of manners. The present survey sifts through

    the literature to review papers concerning this kind of argumentation-based

    bot, drawing conclusions about the benefits and drawbacks that this approach

    entails in comparison with standard chatbots, while also envisaging possible

    future development and integration with the Transformer-based architecture and

    state-of-the-art Large Language models.'
  url: http://arxiv.org/abs/2401.03454v1
  keywords: ''
  document: '# Computational Argumentation-based Chatbots: a Survey


    Brunel University London, Kingston Lane, London, UB8 3PH, United Kingdom


    University of Edinburgh, Crichton St, Edinburgh EH8 9AB, United Kingdom


    Brunel University London, Kingston Lane, London, UB8 3PH, United Kingdom


    University of Lincoln, Brayford Pool, Lincoln, LN6 7TS, United Kingdom


    University of Lincoln, Brayford Pool, Lincoln, LN6 7TS, United Kingdom


    Federico Castagna federico.castagna@brunel.ac.uk


    Nadin K¨okciyan nadin.kokciyan@ed.ac.uk


    Isabel Sassoon isabel.sassoon@brunel.ac.uk


    Simon Parsons sparsons@lincoln.ac.uk


    Elizabeth Sklar esklar@lincoln.ac.uk


    ## Abstract


    Chatbots are conversational software applications designed to interact dialectically
    with users for a plethora of different purposes. Surprisingly, these colloquial
    agents have only recently been coupled with computational models of arguments
    (i.e. computational argumentation), whose aim is to formalise, in a machine-readable
    format, the ordinary exchange of information that characterises human communications.
    Chatbots may employ argumentation with different degrees and in a variety of manners.
    The present survey sifts through the literature to review papers concerning this
    kind of argumentation-based bot, drawing conclusions about the benefits and drawbacks
    that this approach entails in comparison with standard chatbots, while also envisaging
    possible future development and integration with the Transformer-based architecture
    and state-of-the-art Large Language models.


    ## 1. Introduction


    Chatbots are conversational software applications designed to mimic human discourse
    mostly to enable automated online guidance and support (Caldarini et al., 2022).
    These computer programs generate responses based on given inputs, producing replies
    via text or speech format (Sojasingarayar, 2020; Bala et al., 2017). In addition,
    to be defined as such, chatbots must satisfy specific functions. As colloquial
    agents, they need to be able to understand the user (comprehension), have access
    to a knowledge base (competence) and provide an ''anthropomorphic effect'' to
    increase the users'' trust (presence) (Cahn, 2017; Sansonnet et al., 2006). Nowadays,
    these bots represent familiar tools that exist in our lives in the form of virtual
    agents. Their assistance ranges from answering inquiries to e-commerce, from information
    retrieval to educational tasks, and from developing new industrial solutions (Dale,
    2016) to connecting smart objects (Kar & Haldar, 2016). The manifold investments
    of the past decade, the technological advancements (from both software and hardware
    viewpoints), and the development of more efficient Machine Learning (ML) models,
    including the latest Transformer-based architecture (Vaswani et al., 2017), have
    contributed to the steady growth of the research field of chatbot design and implementation.
    Many steps forward have been taken since the release of ELIZA around sixty years
    ago, which is widely considered to be the first conversational agent (Weizenbaum,
    1966).


    The investigation of computational models of arguments in relation to chatbots
    has only recently received attention from researchers. Computational argumentation
    (Rahwan & Simari, 2009) has been applied in Artificial Intelligence (AI) as a
    mechanism for reasoning in which conclusions are drawn from evidence that supports
    the conclusions. Being an intuitive (i.e. closer to everyday human dialectical
    interplay), yet formal, approach for modelling conflicting information occurring
    during exchange of arguments, computational argumentation should be qualified
    as a highly appropriate methodology to enhance current bot behaviours. The benefits
    from such a combination include: more natural discourse, response coherence and
    strategical conveyance of information. Evaluating argumentation semantics would
    also provide the rationale for positing replies in a more transparent way than
    the black-box Large Language models (LLMs) employed in today''s state-of-the-art
    conversational agents. In recent years, cutting-edge technologies have produced
    implementations, such as the various versions of ChatGPT<sup>1</sup> , which currently
    outperform argumentation-based conversational agents. Nonetheless, taking a closer
    look—as we do here—shows that there is plenty of room for improvement for these
    recent advanced models, and integration with the computational argumentation formalism
    may solve their present shortcomings (e.g. lack of explainability), thus potentially
    initiating a new generation of chatbots. To the best of our knowledge, this is
    the first survey that combines computational argumentation and chatbots<sup>2</sup>
    . Our main contribution involves an extensive examination of the relevant literature
    and the subsequent findings that can be drawn from such analysis.


    The paper is structured as follows. We first start by introducing background information
    in Section 2 about the essential theoretical notions involved. In Section 3, we
    then discuss the methodology adopted for reviewing the relevant articles. A thorough
    classification and analysis of conversational agents leveraging computational
    argumentation is given in Section 4. Section 5 illustrates a comprehensive examination
    of the paper''s findings and potential future directions of the argumentation-based
    chatbot research field, and Section 6 concludes the survey with final remarks.


    ## 2. Background


    The following background covers a concise summary of computational argumentation,
    along with a short overview of the history, classification and main features of
    chatbots. The information provided will prove useful for the analysis undertaken
    in the next sections, where each conversational agent will be classified according
    to the specific argumentation employment presented herein.


    <sup>1.</sup> https://chat.openai.com/


    <sup>2.</sup> Notice that, for simplicity, we are often going to prefer the terminology
    ''argumentation-based chatbot'' rather than ''computational argumentation-based
    chatbot'', although the meaning will remain the same.


    ## 2.1 Computational Argumentation


    The term ''computational model of arguments'' encompasses a wide range of different
    approaches, each of which revolves around the notion of arguments and their employment.
    The resulting research field, whose roots can be traced back to Pollock''s and
    Dung''s systematical account of arguments (Pollock, 1987; Dung, 1995), constitutes
    a rich interdisciplinary environment comprising subjects such as philosophy (Walton,
    1990; Mercier & Sperber, 2011), jurisprudence (Bench-Capon et al., 2009), linguistics
    (Lawrence & Reed, 2020), formal logic (Lin & Shoham, 1989) and game theory (Rahwan
    & Larson, 2009). Within the scope of computational argumentation, it is possible
    to identify two main research goals: (a) understand argumentation as a cognitive
    phenomenon via computer program modelling; and (b) support the development of
    human-computer interaction by means of argumentation-related activities (Prakken
    et al., 2020; Dutilh Novaes, 2022). According to Dung''s paradigm (Dung, 1995),
    arguments are considered suitable means to formalise nonmonotonic reasoning, especially
    when showing how humans handle conflicting information in a dialectical way. The
    core notion of such an approach is underpinned by the definition of an argumentation
    framework, where arguments are intended as abstract entities:


    Definition 1 (Abstract AFs (Dung, 1995)) An argumentation framework (AF) is a
    pair: AF = ⟨AR, C⟩ where AR is a set of arguments, and C is the ''attack'' binary
    relation on AR, i.e. C ⊆ AR × AR.


    AFs can be rendered as graphs where each node is an argument, and every directed
    edge connects the conflicting arguments of the framework. The idea conveyed by
    this formalism is that correct reasoning is rendered via the acceptability of
    a statement: an argument is justified only if it is defended against any counterarguments.


    Definition 2 (Semantics for Abstract AFs (Dung, 1995)) Let AF = ⟨AR, C⟩, and let
    S ⊆ AR be a set of arguments. Let also (X,Y) ∈ C denote the conflict existing
    between an argument X and its target Y :


    - S is conflict-free iff ∀X, Y ∈ S: (X, Y ) ∈ C / ;

    - X ∈ AR is acceptable w.r.t. S iff ∀Y ∈ AR such that (Y, X) ∈ C: ∃Z ∈ S such
    that (Z, Y ) ∈ C;

    - A conflict-free extension S is an admissible extension iff X ∈ S implies X is
    acceptable w.r.t. S;

    - An admissible extension S is a complete extension iff ∀X ∈ AR: X is acceptable
    w.r.t. S implies X ∈ S. The minimal complete extension (with respect to set inclusion)
    is called the grounded extension, whereas a maximal complete extension (with respect
    to set inclusion) is called a preferred extension;

    - A stable extension S is such that iff ∀Y ∈ AR, if Y /∈ S, then ∃X ∈ S such that
    (X, Y ) ∈ C.


    Furthermore, AFs can be instantiated by the formulae of some logical language.
    These instantiations paved the way for a plethora of different studies (e.g.,
    (Besnard & Hunter, 2008; Modgil & Prakken, 2013; Toni, 2014)) concerning the so-called
    structured argumentation, as opposed to the previously introduced abstract approach.
    The internal structure of an argument is usually composed of (one or more) premises,
    a conclusion and a set of inference rules (e.g. strict or defeasible) connecting
    premises to the conclusion. The same semantics described above can then be used
    to evaluate structured argumentation frameworks and compute justified arguments.


    Example 1 Let us consider the abstract AF depicted in Figure 1. Then, according
    to the semantics described in Definition 2, we can identify the following extensions:


    admissible = ∅, {a}, {b}, {e}, {a, e}, {b, e}; complete = {e}, {a, e}, {b, e};
    grounded = {e}; preferred = {a, e}, {b, e}; stable = {a, e}, {b, e}.


    ![](_page_3_Figure_4.jpeg)


    Figure 1: An abstract argumentation framework.


    # 2.1.1 Argument Mining


    Argument(ation) mining has been defined as "the general task of analyzing discourse
    on the pragmatics level and applying a certain argumentation theory to model and
    automatically analyze the data at hand" (Habernal & Gurevych, 2017). Argument
    mining (AM) can be considered the research area aimed at detecting natural language
    arguments and their relations in text, with the final goal of providing machine-processable
    structured data for computational models of argument (Cabrio & Villata, 2018).
    As depicted in Figure 5, an AM pipeline consists of two main stages: arguments''
    extraction and relations'' prediction. We could delineate the AM framework by
    listing the tasks, in increasing order of complexity, that constitute such a framework.
    In short, moving from a preliminary textual segmentation and a classification
    of such elements as argumentative or not, it will then be possible to identify
    the single argument components (such as premises, claim, major claim, evidence,
    etc. (Mayer et al., 2020)). The following steps envisage the recognition of clausal
    properties and relational properties with respect to the previously detected argument
    components (Lawrence & Reed, 2020). In particular, Saadat-Yazdi, Pan and K¨okciyan
    show how the use of external commonsense knowledge helps in identifying relations
    among arguments by uncovering implicit inferences (Saadat-Yazdi et al., 2023).
    Some of the models proposed in the literature include Long-Short Term Memory (LSTM)
    models (Cocarascu & Toni, 2017), pre-trained transformers (Ruiz-Dolz et al., 2021;
    Saadat-Yazdi et al., 2023) and logical rulebased systems (Jo et al., 2021). Overall,
    AM is useful in enabling the generation of an argumentation framework, or graph,
    from the mined corpus of texts. We now provide a more concrete analysis of the
    arguments'' extraction stage within the AM pipeline.


    Example 2 Inspired by the political debate example illustrated in (Cabrio & Villata,
    2018), we introduce an example to show how one can identify single arguments by
    following two distinct steps: (S1) the detection of argument components, such
    as premises and claims, and (S2) the recognition of their specific textual boundaries
    via the exclusion of any irrelevant words. In the following, we show how S1 and
    S2 could be applied to an example about the use of solar energy to extract an
    argument (Arg). Note that (C) and (P) distinguish conclusion from premises, whereas
    the bold and underlined fonts identify their respective boundaries.


    - (S1) "She talks about solar panels. We invested in a solar company, our country.
    That was a disaster (C). They lost plenty of money on that one (P). Now, look,
    I''m a great believer in all forms of energy (P), but we''re putting a lot of
    people out of work (P)."

    - (S2) "She talks about solar panels. We invested in a solar company, our country.
    That was a disaster. They lost plenty of money on that one. Now, look, I''m a
    great believer in all forms of energy, but we''re putting a lot of people out
    of work."

    - (Arg) [Since] they lost plenty of money on that one, [even though] I''m a great
    believer in all forms of energy, we''re [nonetheless] putting a lot of people
    out of work. [We can then conclude] that was a disaster.


    ![](_page_4_Figure_6.jpeg)


    Figure 2: Example of an argumentation mining pipeline.


    # 2.1.2 Argument Schemes


    Argument schemes (AS) have been extensively investigated and employed in the AI
    literature as a way to directly convey presumptive reasoning in multi-agent interactions
    (e.g. (Atkinson et al., 2006; Tolchinsky et al., 2012; Grando et al., 2013; K¨okciyan
    et al., 2018, 2021)). Each AS is characterized by a unique set of critical questions
    (CQs), rendered as attacking arguments, whose purpose is to establish the validity
    of the scheme instantiations (which can then be evaluated by semantically computing
    their acceptability). Although the literature presents diverse classification
    systems for argument schemes (e.g. (Walton et al., 2008; Walton & Macagno, 2015;
    Wagemans, 2016)), they all share the idea that such schemes constitute reasoning
    patterns that may be harnessed to structure natural language text into rational
    and coherent arguments, thus generating systematic elements of dialogue.


    Example 3 As an example of AS in the healthcare domain, consider the argument
    scheme for proposed treatment (ASPT), as rendered in (Sassoon et al., 2021), and
    the respective critical questions: the validity of any potential ASPT instantiation
    depends upon the answers given to each critical question.


    | ASPT                                                                                                                   |

    |------------------------------------------------------------------------------------------------------------------------|

    | Premise : Given the patient''s fact Ft<br>Premise : In order to realise goal
    G<br>Premise : Treatment T promotes goal G |

    | Conclusion : Treatment T should be considered                                                                          |


    CQ1: Has treatment T been unsuccessfully used on the patient in the past?


    CQ2: Has treatment T caused side effects for the patient?


    CQ3: Given the patient''s fact Ft, are there counter-indications to treatment
    T?


    CQ4: Are there alternative Actions to achieve the same goal G?


    Finally, although the concept was developed for different purposes, the importance
    of argument schemes has found uptake within the computational argumentation community
    (Visser et al., 2018) also for textual mining tasks (Walton, 2012).


    # 2.1.3 Argumentation Reasoning Engine


    One of the main purposes of computational argumentation is to enable the resolution
    of conflicting knowledge, thus allowing for a selection of the most appropriate
    (i.e. justified) pieces of information. "A decision is a choice between competing
    beliefs about the world or between alternative courses of action. [...] Inference
    processes generate arguments for and against each candidate [belief or action].
    Decision making then ranks and evaluates candidates based on the underlying arguments
    and selects one candidate as the final decision. Finally, the decision commits
    to a new belief about a situation, or an intention to act in a particular way."
    (Fox et al., 2007). Decision-making processes can be encoded as problems whose
    solutions are rendered by the computation and evaluation of AFs: an argumentation
    engine is essentially a reasoning tool driven by the same logic. The resulting
    acceptable entities provide a compelling rationale for and against a given choice,
    while also leaving space for further deliberations (Dix et al., 2009). Such an
    argumentative decisionmaking apparatus can be a useful addition to any real-world
    software application concerning defeasible reasoning, as advocated by the comprehensive
    study of Bryant and Krause (2008). We can distinguish two kinds of reasoning engines
    based on computational argumentation:


    - ''Solvers'', i.e. specialized pieces of software that encode and provide answers
    to distinct algorithmic problems. In particular, they address computational argumentationrelated
    reasoning challenges according to a chosen semantics σ: for example, the enumeration
    of σ-extensions in the AF and the credulous and sceptical membership of a specific
    argument to at least one (credulous) or each (sceptical) σ-extensions (e.g. AFGCN
    (Malmqvist, 2021), A-Folio DPDB (Fichte et al., 2021), ASPARTIX-V21 (Dvor´ak et
    al., 2021), ConArg (Bistarelli et al., 2021a), FUDGE (Thimm et al., 2021), HARPER++
    (Thimm, 2021), MatrixX (Heinrich, 2021), µ-toksia (Niskanen & J¨arvisalo, 2021),
    PYGLAF (Alviano, 2021)).

    - ''Panoptic Engines'', i.e. solvers designed to implement additional functionalities
    and customisation tools (e.g. ArguLab (Podlaszewski et al., 2011), ArgTrust (Tang
    et al., 2012), Argue tuProlog (Bryant et al., 2006), IACAS (Vreeswijk, 1994),
    CaSAPI (Gartner & Toni, 2007), Prengine (Hung, 2017), PyArg (Borg et al., 2022),
    NEXAS (Dachselt et al., 2022)).


    Example 4 The ASP-Solver ASPARTIX is an example of such an argumentation-driven
    reasoning engine. Starting from an AF as input, the Answer-Set-Programming solver
    will output the result of the specified reasoning task given a particular semantic
    (both encoded as ASP rules).


    ![](_page_6_Figure_5.jpeg)


    Figure 3: Example of an argumentation reasoning engine architecture (Dvoˇr´ak
    et al., 2020).


    It is worth mentioning that most of these engines also embed a planning component,
    which derives from their underlying employment of the AF formalism. Indeed, computing
    acceptable arguments enables ''argumentative paths'' that lead to the achievement
    of the predetermined goal by deciding among (possibly) multiple options. Following
    edges that connect justified nodes in an AF will exclude any potential rebuttals,
    thus ensuring a successful strategy. That is to say, each reasoning step, enclosed
    and rendered as an argument, is performed whilst having in mind the overall plan
    required for reaching a consistent decision.


    # 2.1.4 Argumentation-based Dialogues


    The view of computation as distributed cognition and interaction contributed to
    the rise of the multi-agent systems paradigm, where agents are intended as software
    entities capable of flexible autonomous action in dynamic and unpredictable domains
    (Luck et al., 2005). As a means of communication between such intelligent agents,
    formal dialogues were chosen due to their potential expressivity despite still
    being subject to specific restrictions (McBurney & Parsons, 2009). Argumentation-based
    dialogues are rule-governed interactions among participants (i.e. agents with
    their own beliefs, goals, desires and a limited amount of information regarding
    the other players) that take turns in making utterances. As shown in Table 1,
    these dialogues are usually categorized according to elements such as information
    possessed by the participants at the commencement of the interaction, their individual
    goals, and the knowledge and goals they share with other agents (Walton & Krabbe,
    1995).


    | Dialogue type    | Description                                                        |
    Example                    |

    |------------------|--------------------------------------------------------------------|----------------------------|

    |                  | Information-seeking X seeks the answer to some question(s)
    from Y. | (Hulstijn, 2000)           |

    | Inquiry          | X and Y collaborate to answer some question(s).                    |
    (Black & Hunter, 2007)     |

    | Persuasion       | X seeks to persuade Y to accept a proposition.                     |
    (Prakken, 2006)            |

    | Negotiation      | X and Y bargain over the division of some scarce resources.        |
    (McBurney et al., 2003)    |

    | Deliberation     | X and Y collaborate to decide what actions should be adopted.      |
    (McBurney et al., 2007)    |

    | Eristic          | X and Y quarrel verbally to vent perceived grievances.             |
    /                          |

    | Verification     | X wants to verify the beliefs of Y.                                |
    (Cogan et al., 2005)       |

    | Query            | X challenges Y since it is interested in Y''s arguments.            |
    (Cogan et al., 2005)       |

    | Command          | X tells Y what to do.                                              |
    (Girle, 1996)              |

    | Education        | X wants to teach Y something.                                      |
    (Sklar & Parsons, 2004)    |

    | Chance discovery | Ideas arise out of exchanges between X and Y.                      |
    (McBurney & Parsons, 2001) |


    Table 1: Description of existing dialogue types


    The selection and transitions between different dialogues can instead be rendered
    via a Control Layer (McBurney & Parsons, 2002; Sklar & Azhar, 2015), defined in
    terms of atomic dialogue types and control dialogues. The latter are meta-structures
    that have as their topics other dialogues and contribute to the management of
    the protocols combinations and their transitions.


    In general, the main components of argumentation-based dialogues can be identified
    as: (i) syntax, which handles the availability of and interaction between utterances;
    (ii) semantics, which differs according to the specific focus and final deployment
    of the dialogue; and (iii) pragmatics, which accounts for those aspects of the
    language that do not involve considerations about truth and falsity (e.g. the
    illocutionary force of the utterances) (McBurney & Parsons, 2013).


    ### 2.2 Chatbots


    A chatbot must be able to parse the user input and interpret what it means before
    providing an appropriate response or output (and thus starting a ''chat''). The
    way in which the bot elaborates the replies to be delivered depends upon its response
    architecture model. Following the studies conducted in (Adamopoulou & Moussiades,
    2020; Singh & Thakur, 2020; Klopfenstein et al., 2017; Codecademy, 2022), we can
    classify such models as:


    - Rule-based chatbots employ the simplest response architecture structure. The
    bots'' replies are entirely predefined and returned to the user according to a
    series of rules. The internal model of such rule-based software can be thought
    of as a decision tree that has a clear set of possible outputs defined for each
    step in the dialogue. Usually, this category of conversational agents handles
    those kinds of interactions where the user has a number of pre-compiled options
    to choose from. As an example of rule-based colloquial agents, we can consider
    ELIZA (Weizenbaum, 1966): deemed by scholars as the first implementation of a
    chatbot, it operates by harnessing linguistic rules in combination with recognized
    keywords from the users'' inputs. Further development in the area resulted in
    PARRY (Colby et al., 1971), a chatbot that improved ELIZA via a conversational
    strategy embedded to simulate a person with paranoia. Jabberwacky (Carpenter,
    1982) is also an instance of a rule-based bot that interacts through contextual
    pattern matching. It steadily expands its database by collecting tokens from previous
    conversations that occurred with different users.

    - Retrieval-based chatbots represent a more complex response architecture structure.
    The bots'' replies are pulled from an existing corpus of stored sentences. Machine
    Learning and Natural Language Processing (NLP) models are used to interpret the
    user input (operation divided into intent classification and entity recognition)
    and determine the most fitting response to retrieve. As an example of retrieval-based
    colloquial agents, we can consider A.L.I.C.E. (Wallace, 2009) developed using
    the Artificial Intelligence Markup Language (AIML) (Wallace, 2003). Such a language
    comprises a class of data objects and partially describes the behaviour of computer
    programs that process them via stimulus-response templates. Furthermore, also
    IBM''s Watson Assistant (IBM, 2006) and Microsoft''s Cortana (Microsoft, 2014)
    represent other instances of the retrieval-based model. The first parses input
    to find statistically relevant replies in its database by means of parallel algorithms.
    The second instead leverages the natural language processing capabilities of Tellme''s
    Network (owned by Microsoft from 2007) and the Satori knowledge repository to
    provide responses (Marshall, 2014).

    - Generative chatbots represent the most convoluted response architecture structure.
    These bots are capable of formulating their own original responses based on the
    user input rather than relying on existing text. The deployment of Deep Learning
    models allows returning the appropriate response by calculating the likelihood
    of the next element(s) in a word sequence. However, training such models requires
    time, and it is not always clear what is used to produce replies, which may be
    repetitive or nonsensical. In addition, generative bots are not generally capable
    of accessing data other than what is embedded in their model parameters. One common
    approach to mitigate these problems is to combine both retrieval and generative
    operations in the chatbot (Roller et al., 2020). As an example of such a hybrid
    type of virtual assistant, we can consider Apple''s Siri (Apple, 2011) and Amazon''s
    Alexa (Amazon, 2014; Lopatovska et al., 2019). Both provide replies to users''
    questions (along with an additional wide


    array of possible functions) via Deep Learning procedures or delegating requests
    to a set of external providers (e.g. WolframAlpha (Heater, 2018)).


    Generative-LLMs. Generative chatbots that hinge upon Large Language models (LLMs)
    deserve special mention, given recent interest in such models. The design and
    deployment of the Transformer architecture (Vaswani et al., 2017) determined a
    paradigm shift towards ''pre-training'' and ''fine-tuning'' learnings (Zhao et
    al., 2023): scaling up pre-trained models led to the discovery of LLMs and their
    impressive capabilities (Brown et al., 2020; Touvron et al., 2023a; Anil et al.,
    2023). Leveraging these new technologies, conversational agents such as the famous
    ChatGPT<sup>3</sup> prove to outperform most of the previous benchmarks and predecessors
    in information extraction tasks (Li et al., 2023), natural language inference,
    question answering, dialogue tasks (Qin et al., 2023) and machine translation
    (Jiao et al., 2023). That being said, LLMs and the chatbots based on them also
    suffer from a number of downsides including: faulty reasoning, inexplicable appearance
    of previously unknown abilities (phenomenon denoted as emergent abilities<sup>4</sup>
    ), nonsensical or unfaithful replies (i.e. hallucination), biased and toxic communications,
    expensive training costs and high carbon footprint<sup>5</sup> . Finally, it has
    also been shown how underlying models such as GPT-3 (Brown et al., 2020) fall
    short of producing adequate and compelling arguments (Hinton & Wagemans, 2022).
    However the outputs of such models may prove particularly suited to support argument
    mining operations, given carefully conditioned (or an increased number of) inputs
    (de Wynter & Yuan, 2023; Chen et al., 2023).


    The different response architecture models and the corresponding high-level operations
    that characterise them are depicted in Figure 4. Notice, as previously anticipated,
    that is quite common for conversational agents to use a combination of different
    response models in order to produce optimal results. Furthermore, chatbots can
    be classified based on the conversation topics they are able to cover. Closed
    domain ones (e.g. bots focused on customer assistance or e-commerce) are restricted
    to providing responses within a particular matter. Due to their specific area
    of competence, usually, these agents are very efficient in delivering good-quality
    discourses. On the other hand, open domain chatbots (e.g. the previously referenced
    Apple''s Siri, Amazon''s Alexa, Meta''s Llama 2-Chat, Google''s Bard and OpenAI''s
    ChatGPT, as well as Meena (Adiwardana et al., 2020), Mitsuku (Worswick, 2018)
    and Microsoft''s XiaoIce (Zhou et al., 2020)) should be able to explore any range
    of conversation topics, similar to how a real-world human-to-human interaction
    would be. However, it is not straightforward to implement such bots, and they
    prove to be more prone


    <sup>3.</sup> Other remarkable examples are DialoGPT (Zhang et al., 2019), BlenderBot
    3x (Xu et al., 2023), Bard (https://bard.google.com/), Claude (https://claude.ai/),
    Llama 2-Chat (Touvron et al., 2023b), Mistral-7b-Instruct (Jiang et al., 2023),
    and Zephyr-7b (Tunstall et al., 2023).


    <sup>4.</sup> Emergent abilities constitute a controversial topic and some studies
    even argue against their existence (Schaeffer et al., 2023).


    <sup>5.</sup> Although it has been argued that the adoption of best practices
    in model training should reduce carbon dioxide emissions by 2030 (Patterson et
    al., 2022).


    ![](_page_10_Figure_1.jpeg)


    Figure 4: Comparisons of different response architecture models


    to errors, incoherent responses<sup>6</sup> or other issues similar to the aforementioned
    generative-LLMs.


    # 2.2.1 The Knowledge Base Acquisition


    Chatbots cannot automatically generate responses unless they are provided with
    a specific knowledge base from which those replies can be retrieved. This limitation
    involves every type of conversational agent and not only the retrieval-based,
    as one may think. Indeed, rule-based architecture requires hard coding of data
    into the scripts of the chatbot, whereas generative models necessitate a corpus
    of information to be trained upon. However, plenty of data collection is needed
    to obtain such knowledge bases and, usually, these datasets allow the chatbots
    to interact only on a restricted range of topics. In particular, anticipating
    a topic covered in the next sections, some argumentation-based chatbots are characterized
    by a knowledge base consisting of a set of arguments (alternatively, an argument
    graph) to collect which current approaches include argument mining from documents
    (e.g. (Cocarascu et al., 2019; Trautmann et al., 2020)) or hand coding of texts
    by researchers (e.g. (Cerutti et al., 2016; Rosenfeld & Kraus, 2016)). Nevertheless,
    these operations can be complicated tasks to achieve, especially if we need to
    handle only real-world arguments rather than artificial (i.e. computed) ones.
    That is to say, it may be difficult to retrieve high-quality arguments concerning
    a specific topic on the web, or it may also be problematic to distinguish between
    the person (and, thus, account for her attributes) who posited a specific claim.
    Questionnaires or personal interviews may provide a solution, although such solutions
    are expensive and require a large amount of human effort. Interestingly, studies
    such as (Chalaguine & Hunter, 2018; Chalaguine et al., 2018) proposed an alternative
    method to face this potential issue. The results of their research show how a
    chatbot, with little


    <sup>6.</sup> Notice these errors can have extreme and harmful consequences, such
    as a medical chatbot suggesting a patient to kill themselves. (Daws, 2020)


    to no domain expertise, may elicit arguments and counterarguments from different
    users, thus automating the process of argument acquisition. This procedure, called
    argument harvesting by the authors, allows for the generation of AFs that incorporate
    the knowledge base information over the required domain. Another alternative approach
    is provided by the work conducted in (Chalaguine & Hunter, 2019) that describes
    how to acquire a large number of (high-quality) arguments in a graph structure
    using crowd-sourcing.


    # 3. Methodology


    This survey hinges upon the collection and review of papers concerning argumentationbased
    chatbots. Before delving into the examination of our findings, it may be helpful
    to provide an uncontroversial definition of the subject of our investigation:


    Definition 3 (Computational Argumentation-based chatbots) We consider computational
    argumentation-based chatbots those conversational agents that employ argumentative
    models to: (i) extract textual data via argument mining tools, (ii) structure
    information by means of argumentative templates, (iii) reason with argument semantics
    and/or (iv) deliver replies to users through argumentation-based dialogues.


    A schematic representation of the argumentation employment types within a conversational
    agent architecture is provided in Figure 5. Here it is specified the level at
    which each aspect operates in the overall chatbot design. Argument mining enables
    the construction of a database for model training or a knowledge base (KB) by
    extracting information from texts. KB data can be structured into argumentative
    patterns, which may then be delivered as argumentation-based dialogue replies
    to the interacting end-user after being selected through a reasoning step (that
    usually involves argument semantics computation). Notice that we strictly selected
    only papers involving such aspects, avoiding any other articles pertaining to
    chatbots or meanings of argumentation that differ from those introduced in Section
    2. For example, we did not consider the work of (Toniuc & Groza, 2017) among the
    surveyed papers since it does not account for computational argumentation as described
    herein (albeit the presented textual entailments relationship may be transformed
    into a sort of premises-conclusion argument dependency). A similar issue can be
    observed in (Altay et al., 2022; Kulatska, 2019) where, although there is a reference
    to a general notion of arguments and counterarguments, it does not correspond
    to the one provided in Section 2. On the other hand, we also excluded research
    such as (Chalaguine et al., 2018; Chalaguine & Hunter, 2018) since their focus
    is more on the automated collection of a corpus of arguments and counterarguments
    rather than the implementation of a conversational agent that delivers argumentation-based
    dialogues. Furthermore, the interactive recommender system of (Rago et al., 2018,
    2020), which clarifies its recommendations through explanations, does not qualify
    as an argumentation-based chatbot either. That is because, although it makes use
    of a Bipolar/Tripolar AF<sup>7</sup> to embed its underlying knowledge base, no
    reasoning, extraction, structure or delivery via computational models of argument
    (as interpreted in this paper) occurs.


    <sup>7.</sup> Bipolar Argumentation Frameworks, or Bipolar AFs, have been extensively
    introduced in (Cayrol & Lagasquie-Schiex, 2005). Tripolar Argumentation Frameworks
    may instead be seen as (using the same words that appear in (Rago et al., 2018)):
    "instances of ''tripolar frameworks'' as defined in (Gabbay, 2016) and of ''generalised
    argumentation frameworks'' as defined in (Baroni et al., 2017)."


    ![](_page_12_Figure_1.jpeg)


    Figure 5: Schematic argumentation employment within chatbots architecture.


    To clarify, in our survey, we did not restrict the search according to particular
    chatbot types, or their final scope, nor did we distinguish between different
    bot denominations (e.g. ''argumentative dialogical agent'', ''dialogue manager'',
    ''automated persuasion system'') or maturity of implementation, (e.g. fully-fledged
    or just sketched). Also, we did not account for specific time ranges and gathered
    articles independently of the year of publication. We have then analysed and organized
    the results in one concise comparative table (Table 2) that displays the classifications
    and main features of each conversational agent. In particular, we listed all the
    reviewed chatbots and distinguished between each bot''s final purpose (e.g. persuade,
    explain, inform), response architecture model (the prevalent one is recorded in
    case of multiple models), and conversation domain (for which we mostly considered
    the topic specified in the corresponding paper examples). Additional data comprise
    also the way in which computational argumentation has been employed within the
    chatbot architecture (i.e. extraction, structure, reason, deliver). Finally, we
    inspected the arranged information and discussed our main findings.


    | Paper(s)                      | Final       | Response        | Conversation        |
    Argumentation      |

    |-------------------------------|-------------|-----------------|---------------------|--------------------|

    |                               | Purpose     | Architecture    | Domain              |
    Employment         |

    | (Cocarascu et al., 2019)      | Explain     | Rule-based      | Movies reviews      |
    Extract, Reason    |

    | (Slonim et al., 2021)         | Debate      | Retrieval-based | Unspecified         |
    Extract            |

    |                               |             |                 | (semi-open domain)  |                    |

    | (Galitsky, 2019)              |             |                 |                     |                    |

    | (Galitsky, 2018)              | Unspecified | Retrieval-based | Unspecified         |
    Extract            |

    | (Galitsky, 2020)              |             |                 | (closed domain)     |                    |

    | (Dignum & Bex, 2017)          | Converse    | Retrieval-based | Healthcare          |
    Reason, Deliver    |

    | (Bistarelli et al., 2021)     | Converse    | Retrieval-based | Unspecified         |
    Reason             |

    |                               |             |                 | (closed domain)     |                    |

    | (Castagna et al., 2022, 2023) | Explain     | Retrieval-based | Healthcare          |
    Reason, Structure  |

    | (Sassoon et al., 2019)        | Explain     | Retrieval-based | Healthcare          |
    Reason, Structure, |

    |                               |             |                 |                     |
    Deliver            |

    | (Fazzinga et al., 2021)       | Inform      | Retrieval-based | COVID-19 vaccine    |
    Reason, Deliver    |

    | (Bex et al., 2016)            | Inform      | Retrieval-based | Fraud report        |
    Reason, Deliver    |

    | (Sklar & Azhar, 2015)         | Explain     | Retrieval-based | Treasure Hunt       |
    Deliver            |

    | (Sklar & Azhar, 2018)         |             |                 | Game                |                    |

    | (Rosenfeld & Kraus, 2016)     | Persuade    | Retrieval-based | Benefits of
    holding | Reason, Deliver    |

    |                               |             |                 | a Master''s
    Degree   |                    |

    | (Chalaguine et al., 2019)     | Persuade    | Retrieval-based | Meat consumption    |
    Deliver            |

    | (Chalaguine & Hunter, 2020)   | Persuade    | Retrieval-based | UK university
    fees  | Deliver            |

    | (Chalaguine & Hunter, 2021)   | Persuade    | Retrieval-based | COVID-19 vaccine    |
    Deliver            |

    | (Hadoux & Hunter, 2019)       | Persuade    | Retrieval-based | Cycling in the
    city | Deliver            |

    | (Hadoux et al., 2021)         | Persuade    | Retrieval-based | UK university
    fees  | Deliver            |

    | (Andrews et al., 2008)        | Persuade    | Retrieval-based | Desert survival     |
    Deliver            |

    | (Guo et al., 2022)            | Persuade    | Retrieval-based | Nuclear energy      |
    Deliver            |

    | (Wambsganss et al., 2021)     | Explain     | Unspecified     | Unspecified         |
    Extract            |

    |                               |             |                 | (closed domain)     |                    |


    Table 2: Argumentation-based chatbots specifics


    # 4. Argumentation-based Chatbots


    This section covers a concise description of all the reviewed chatbots according
    to their specific argumentation employment. We first outline each argumentation-based
    category before providing an account of the conversational agents pertinent to
    the class. Note that it may be the case for a bot to present components that fulfil
    specific tasks (e.g. extract, structure, reasoning, and deliver) without exploiting
    computational argumentation. The fact that we are not detailing such components
    does not undermine their presence or effectiveness but reflects the choice of
    strictly conferring an argumentative scope to the survey. We conclude by highlighting
    the evaluations of such chatbots (if any) as presented in their respective papers.


    ### 4.1 Argumentation-based Extraction


    Starting from a corpus of natural language texts, argument mining procedures allow
    for the extraction of arguments, and the classification of their relations, within
    such documents. The mined data can then be further processed and organized in
    AFs<sup>8</sup> , or simply be employed as replies according to the user''s input.
    Unlike the latter, the former choice may lead to a reasoning operation upon the
    framework that will elicit specific output depending on the evaluation criteria
    of the captured semantics. For example, ADA, the argumentative dialogical agent
    introduced in (Cocarascu et al., 2019), extracts arguments from movie review snippets
    and mines the relations subsisting among them. The acquired data is then utilized
    to construct a Quantitative Bipolar argumentation framework, QBAF (experimentally
    evaluated against three gradual semantics for QBAF: QuAD (Baroni et al., 2015),
    DF-QUAD (Rago et al., 2016) and the Restricted Euler-based semantics (REB) (Amgoud
    & Ben-Naim, 2018)) upon which the conversational agent will instantiate the reply
    templates stored within its system. Those replies will thus be delivered to the
    interacting user when prompted for explanations about the selected movie recommendation.


    Another example of an argumentation-based extraction chatbot is rendered by the
    conversational agent developed in (Slonim et al., 2021) whose purpose is to challenge
    humans with competitive debates. After having preprocessed a corpus of 400 million
    newspaper articles in order to create an index of meaningful concepts, the bot
    mines for arguments thus obtaining claims and evidence related to the selected
    dispute. In this process, the agent identifies the relations occurring between
    the mined arguments and takes advantage of these data to prepare counterarguments
    against different stances on the debate topic. The replies posited by the bot
    will then be retrieved among the mined arguments, or the ones stored in a more
    general knowledge base, via a neural model. Notably, the interaction with the
    user occurs on a speech base and the speech-to-text conversion is performed by
    IBM''s Watson<sup>9</sup> .


    A borderline case is constituted by the ArgueBot conversational agent (Wambsganss
    et al., 2021). Developed as a learning tool for providing adaptive feedback on
    students'' logic argumentation, ArgueBot (a bot deployed within the Slack platform10)
    hinges on a BERT (Devlin et al., 2018) classifier to perform AM operations on
    the user''s textual input before providing tailored comments on their argumentative
    writing. Although the chatbot may be equipped with specific reply templates, its
    exact response architecture is unclear and remains unspecified by the authors.


    Finally, on a more abstract level, the research discussed in (Galitsky, 2020,
    2019, 2018) describes the deployment of specific argument mining approaches to
    chatbots. Here, the conversational agent constructs a communicative discourse
    tree from a subset of text by matching each fragment of the subset that has a
    verb to a verb signature. The subsequent application of classification models
    allows the bot to detect arguments and their relations


    <sup>8.</sup> We stipulate that constructing an AF from the utterances of an argumentation-based
    dialogue does not qualify as an ''argumentation-based extraction''. That is because
    the arguments and the attacks (respectively supports) are already given and do
    not require further parsing.


    <sup>9.</sup> Once again, recall that we are emphasising the elements leveraging
    computational argumentation. Project Debater (Slonim et al., 2021) is a fully-fledged
    debating system, nonetheless, its employment of AM procedures is the only argumentation-related
    component, and this is why it is the one described.


    <sup>10.</sup> https://slack.com/


    and then leverage that information to provide replies according to the user input.
    In a nutshell, by resorting to in-depth rhetorical analysis, the chatbot accounts
    for multiple features of the argument (e.g. embedded affective aspects, consistency
    with the domain clauses, etc.), which results in more precise user-bot replies
    matches.


    ### 4.2 Argumentation-based Reply Structures


    Chatbot replies can be structured according to the traditional argumentative format:
    a claim derived from a set of premises by means of particular inference rules.
    This approach includes argument schemes and general frameworks for structured
    argumentation (e.g. ASPIC+, ABA, etc.). In general, the organization of data within
    such an argumentative pattern occurs before the generation of an AF and the computation
    of its semantics. However, it may also be convenient to arrange the bot responses
    using specific templates, regardless of a further semantic evaluation. Indeed,
    providing replies with a precise structure serves to highlight the rationale underpinning
    the argument claim and enhance the overall clarity of the discourse. As an example,
    we can consider the conversational agent presented in (Castagna et al., 2022,
    2023), which may be seen as the final implementation of previous versions described
    in (Essers et al., 2018; K¨okciyan et al., 2019; Balatsoukas et al., 2019; Chapman
    et al., 2019; Balatsoukas et al., 2020; Sassoon et al., 2020; K¨okciyan et al.,
    2021; Drake et al., 2022). Harnessing the novel Explanation-Question-Response,
    or EQR, argument scheme (first envisaged as a dialogue protocol and sketched in
    (McBurney, Parsons, et al., 2021)), this bot delivers tailored justified recommendations
    within the healthcare domain, helping users self-manage their conditions. These
    recommendations embed an additional layer of information: the rationale behind
    the instantiated scheme acceptability (i.e. its evaluation, automated via the
    ASPARTIX (Egly et al., 2008) engine, according to the considered argumentation
    framework). Additional replies provided by the chatbot will be structured by harnessing
    the argument scheme (and respective CQ) templates instantiated by the bot knowledge
    base.


    ### 4.3 Argumentation-based Reasoning


    As previously discussed, an argumentation engine can be employed as the underlying
    tool that drives a chatbot''s reasoning operations. In such a circumstance, regardless
    of the chosen framework (e.g. Abstract AFs (Dung, 1995), Bipolar AFs (Cayrol &
    Lagasquie-Schiex, 2005), Weighted Bipolar AFs (Rosenfeld & Kraus, 2016), Quantitative
    Bipolar AFs (Cocarascu et al., 2019), Metalevel AFs (K¨okciyan et al., 2021),
    etc.), most of the decisionmaking processes involve the computation and semantic
    evaluation of the AF. Intuitively, starting from a knowledge base embedded in
    a set of arguments, the bot executes a reasoning procedure that usually results
    in a selection of acceptable arguments (which changes depending on the chosen
    semantics). When interacting with the user, the conversational agent will retrieve
    its replies, based upon the received input from its interlocutor, from the computed
    acceptable arguments. As such, we can generally assume that argumentation-based
    reasoning engines are intertwined with retrieval-based response architectures
    or hybrid models that include retrieval-based operations. For example, ArguBot
    (Bistarelli et al., 2021b), developed using Google DialogFlow11, employs ASPARTIX
    (Egly et al., 2008) to compute arguments from an underlying Bipolar AF, to support
    (pro-bot) or challenge (con-bot) the user''s opinion about the topic of dialogue.


    The conversational agent presented in (Fazzinga et al., 2021)<sup>12</sup> retrieves
    its arguments from an underlying Bipolar AF as well, although it follows the semantics
    illustrated in (Fazzinga et al., 2018). The selected reply is then an argument
    acceptable with respect to an admissible extension computed over the overall framework,
    thus providing a strategy that also accounts for future developments of the chat.
    In addition, the bot is capable of formulating on-demand explanations about a
    particular reply, i.e. a sequence of natural language sentences that describes
    the facts supporting it, along with motivations against other possible conflicting
    arguments that the system discarded.


    In contrast, the chatbot outlined in (Dignum & Bex, 2017) deploys computational
    argumentation as a means of evaluating completed phases of the ongoing dialogue,
    rather than starting with a previously generated AF. More precisely, an argument
    graph is constructed by incorporating the facts that emerge during the dialectical
    interaction with the user. Then, a formal assessment occurs by checking if those
    facts are members of acceptable extensions of the graph. Interestingly, this conversational
    agent harnesses social practices theory (Reckwitz, 2002; Shove et al., 2012) to
    contextualise the conversation and provide useful background information that
    facilitates the user''s input interpretation. A similar deployment of computational
    argumentation is envisaged in (Bex et al., 2016), where an AI system that enhances
    the online report of trade frauds is outlined. A chatbot (the ''dialogue manager'')
    exchanges arguments with the user parties (both fraud victims and police) eliciting,
    if needed, more information about the ongoing case whilst building a knowledge
    graph. The acquired data will then enable the matching of the graph with a typical
    criminal scenario known by the police. Subsequently, formal argumentation semantics
    will drive the reasoning with scenarios and pieces of evidence (i.e. the ''hybrid
    theory'' (Bex et al., 2010; Bex, 2015)).


    Finally, the conversational agent (SPA) envisaged in (Rosenfeld & Kraus, 2016)
    also employs an argumentation-based reasoning engine. In particular, it embeds
    its knowledge base into a Weighted Bipolar AF (WBAF) and computes the argument
    that maximizes the framework evaluation function according to the user input.
    The score returned by the valuation function represents the reasoner''s ability
    to support that argument and defend it against potential attacks. The dialectical
    interaction with the user follows a strategical persuasion dialogue protocol (optimized
    via Monte Carlo Planning (Silver & Veness, 2010)) that might involve updating
    the argumentation frameworks of both the persuader and the persuadee.


    ### 4.4 Argumentation-based Reply Delivery


    Chatbots may handle and deliver their responses to the user interacting with them
    by leveraging the protocols of argumentation-based dialogues. Harnessing the dialogue
    logic, the conversational agent can optimize its strategy and utter only the arguments
    that prove to be necessary for achieving its final goal. In a way, we could identify
    the delivery phase


    <sup>11.</sup> https://cloud.google.com/dialogflow/docs/


    <sup>12.</sup> Subsequently embedded into a privacy-preserving dialogue system
    (Fazzinga et al., 2022).


    as a ''secondary reasoning step'' where the bot chooses which arguments to move
    (strictly following the involved dialogue protocol instructions) among the ones
    available (possibly previously computed by the ''primary engine'' described by
    the reasoning phase). Notice that the arguments licensed in a dialogue protocol
    follow a more flexible definition than the standard ones provided in the abstract
    or structure argumentation approach: " [. . .] it is the idea of dialogue as an
    exchange between two or more individuals, an exchange which captures features
    of what would be informally called an "argument". That is, dialogue as the exchange
    of reasons [i.e. arguments] for or against some matter"(Black et al., 2021).


    As an example, we could examine the work introduced in (Hadoux et al., 2021),
    which expands upon (Hadoux & Hunter, 2019; Hunter, 2018; Hunter et al., 2019)
    and depicts an overall framework for modelling beliefs and concerns in a persuasion
    dialogue. An implementation of such a framework is then envisaged via an automated
    persuasion system (APS), a software application aiming at convincing the interacting
    agent to accept some arguments. Following the asymmetric persuasion dialogue protocol
    illustrated therein (i.e. unlike the system, the user is restricted in choosing
    replies among the provided options), the proposed chatbot proves to be capable
    of identifying, within its knowledge base embedded in an argument graph, the most
    appropriate argument to posit. Essentially, the APS performs a Monte Carlo Tree
    Search coupled with a reward function to maximize the addressing of concerns (paired
    with the arguments of the graph) and the user''s beliefs.


    Similarly, the bot presented in (Chalaguine & Hunter, 2020) aims at persuading
    the interlocutor via a free-text interaction where the user''s inputs are matched
    (by vector rendering and cosine similarity) with the (crowdsourced) arguments
    of the graph representing the knowledge base. The chatbot trains a classifier
    to detect the most common concerns of the persuadee and employs it to select counterarguments
    that will produce a result more compelling than a random choice. If no argument
    similarity is detected, the conversational agent will resort to a default reply
    based on the user''s concerns. Furthermore, the same authors presented an analogous
    architecture for a persuasion bot in (Chalaguine & Hunter, 2021), with the addition
    of a particular concern-argument graph. By incorporating the knowledge base within
    such a small graph, it can be proved that no large amount of data is needed to
    generate effective persuasive dialogues. Interestingly, a preliminary analysis
    of the impact (appeal) of arguments addressing the users'' concerns in a persuasion
    dialogue performed by a chatbot has also been conducted by the same authors in
    (Chalaguine et al., 2019). Another example of such a concern-based approach may
    be represented by Argumate, a chatbot designed to facilitate students'' production
    of persuasive statements (Guo et al., 2022). To provide appropriate suggestions,
    the bot retrieves its replies from an underlying argument graph, whose edges denote
    attack and support relations, via a concern identification method. Notice that
    the interactions between Argumate and the users occur both by typing and selecting
    predefined options.


    A common trait amongst all of the above argumentation-based conversational agents
    is that, although the corpus from which they extract their replies is organized
    as an argument graph, there is no interest in any particular acceptable semantics.
    That is to say, the knowledge base is organized and considered as a plain AF,
    where arguments and attacks are the only relevant features. In addition, most
    of these studies also account for a baseline chatbot which exploits a random strategy
    for selecting counterarguments from the available choices within the underlying
    knowledge base. The reason for this is to provide a means for comparing the developed
    bots which employ more fine-grained strategies for choosing their replies.


    Finally, one last conversational agent that focuses on the delivery of persuasion
    dialogues is the chatbot designed in (Andrews et al., 2008). Implemented harnessing
    the AIML markup language (Wallace, 2003), the bot comprises a planning component
    that searches over an argumentation model for the optimal dialectical path to
    pursue in order to persuade the user. The agent records the user''s beliefs and
    updates this information whenever its interlocutor agrees/disagrees during the
    interaction. Such belief revision plays an important role in the strategic view
    of the chatbot. Moving towards different topics, the conversational agent implemented
    in (Sassoon et al., 2019), within the context of explanation for wellness consultation,
    exploits multiple dialogue protocols (i.e. persuasion, deliberation and information
    seeking) whilst exchanging instantiations of acceptable argument schemes with
    its interlocutor. The adoption of diversified dialogue protocols (i.e. persuasion,
    inquiry and information seeking) characterises also the chatbot-equipped robot
    proposed in (Sklar & Azhar, 2015) and demonstrated in (Azhar & Sklar, 2017). Retrieving
    the most appropriate argument constructed from its beliefs, an operation facilitated
    by the restricted options available to the user, the robot communicates with its
    human interlocutor in order to strategize about a treasure-hunting game.


    ### 4.5 Evaluation of the Chatbots


    Thus far, we have described the reviewed argumentation-based chatbots, primarily
    focusing on their features in relation to argumentation employment. However, some
    of those conversational agents have also been evaluated via specifically designed
    user studies<sup>13</sup> whose results will be reported herein. For example,
    the virtual debater devised in (Slonim et al., 2021) exhibits a higher discussion
    quality than the compared artificial competitors, although it still fails to achieve
    a human-like level. Furthermore, (Balatsoukas et al., 2020) reported on the findings
    ensuing from the pilot study designed to assess a former version of the CON-SULT
    system and the comprised chatbot. The outcome was a criticism concerning a lack
    of a more natural conversation flow when interacting with the bot. User studies
    have also been conducted to test the human-robot interaction presented within
    the ArgHRI system of (Sklar & Azhar, 2015; Azhar & Sklar, 2017). The results showed
    how argumentation-based dialogues contribute to enhancing trust towards the robots.
    Nonetheless, analysis of the


    <sup>13.</sup> A different (and outdated) way of evaluating the capability of
    a conversational agent would be through a discussion with a human end-user: the
    more natural and seamless the interaction, the more effective the chatbot. The
    Turing Test (or Imitation Game) is a proposal advanced by Alan Turing (Turing
    & Haugeland, 1950) whose idea was to present some sort of test of a machine''s
    ability to exhibit intelligent behaviour equivalent to, or indistinguishable from,
    that of a human. Hinging on the Imitation Game, the Loebner Prize is a contest
    started in 1980 to award computer programs that are the most humanlike, i.e. that
    perform the best in the Turing Test. The winner of the contest is the one that
    tricks a judge the highest percentage of the time, and Mitsuku is the chatbot
    that won the largest number of such prizes (Worswick, 2013). The Loebner competition
    (considered defunct since 2020) has been subjected to a long list of criticisms.
    Among these, there was the alleged idea that entrants do not aim at understanding
    humans since deception and pretence are highly rewarded in this contest. Another
    criticism leveled against the Loebner Prize is that it confuses the Imitation
    Game with proof of humanlike intelligence. However, machines cannot reason like
    humans, as claimed by Searle in 1980 with his famous ''Chinese Room experiment''
    (Searle, 1980; Cole, 2020).


    dialogues themselves (Sklar & Azhar, 2018) highlighted how the possibility of
    interrogating the bot to obtain explanations did not lead to a significant increase
    in performance from the human-robot team, nor a boost in user satisfaction.


    On the other hand, the SPA conversational agent introduced in (Rosenfeld & Kraus,
    2016) outplayed the baseline chatbot (which harnessed a different, heuristic,
    strategy) when tested in its persuasion task, thus proving capable of delivering
    human-like level conversations. Similarly outperforming the baseline agent is
    the bot presented in (Chalaguine et al., 2019). Indeed, the paper includes an
    experiment that shows how such a chatbot, by positing arguments that address the
    users'' concerns, is more likely to positively change the users'' attitude in
    comparison with another agent that does not employ such a strategy. An analogous
    interest in users'' concerns is encompassed in the study implemented in (Chalaguine
    & Hunter, 2020). The results (conjointly supported by the experiments in (Hadoux
    & Hunter, 2019) and confirmed by (Hadoux et al., 2021)) conclude that a strategic
    chatbot accounting for concerns is more likely to provide relevant and cogent
    arguments. Moreover, it is also worth mentioning the evaluation outcome of the
    other two persuasive agents presented in (Andrews et al., 2008; Chalaguine & Hunter,
    2021). The former bot provides fluent conversations with its interlocutors performing
    generally better than a purely task-oriented system. The latter, instead, shows
    how an interactive chatbot yields more compelling information than a static webpage.


    Lastly, the ArgueBot conversational agent underwent both quantitative and qualitative
    assessments (Wambsganss et al., 2021). The data collected from detailed feedback
    and Likert scale post-experiment forms yielded positive results. In particular,
    the participants perceived the chatbot as helpful, useful and easy to interact
    with.


    ## 5. Discussion


    Table 2 depicts an overview of our findings, with a quantitative summary of the
    sampled chatbots'' features shown in Figure 6. As a first remark, it is surprising
    that only a few argumentation-based chatbots appear in the literature. Indeed,
    the formal characterisation of real-world dialectical interactions provided by
    computational argumentation seems to be well-suited for agents whose role concerns
    conversing with users. This, however, may follow from the fact that the computational
    argumentation research field is still in an early stage of dissemination (especially
    outside of Europe), rather than deriving from the unsuitability of the argumentation
    formalism. Another possible explanation may be due to the fact that there has
    been an explosive interest in model-free methods in computer science in the last
    decades (Bringsjord & Govindarajulu, 2022), ignoring model-based methods (like
    computational argumentation), which are only now gaining favour again, for example,
    as a way of ''interpreting'' the model-free output. Nevertheless, a number of
    considerations can be drawn from the outcome of our analysis. Persuade and Explain
    prove to be the most common goals of the examined chatbots. The latter stems from
    the recent interest in explainable AI and its link with computational models of
    arguments (Vassiliades et al., 2021; McBurney et al., 2021; Cyras et al., 2021).
    Persuasion dialogues, instead, have been ˇ studied in papers such as (Hunter,
    2015; Murphy et al., 2016), whose findings show how the use of argumentation-based
    formalisms may provide compelling strategies to induce belief change. One reason
    for such a number of persuasion-focused chatbots could indeed


    ![](_page_20_Figure_1.jpeg)


    Figure 6: Percentage of sampled systems characterised by the argumentation employment
    type (top left), response architecture (top right), final purpose (bottom left)
    and conversation domain (bottom right) as described from the data of Table 2.


    be related to the effectiveness of argumentation in delivering replies in such
    an area, as also advocated by the results of several user studies. To corroborate
    this, it can be noticed how persuasive conversational agents employ computational
    argumentation in such a way that falls under the (dialogical) Deliver category
    (which, as expected, turns out to be the most common class listed in Table 2).
    Observe also that the main features of such bots include the account of beliefs
    and concerns when positing cogent (argumentative) replies. Continuing our analysis
    of different typologies of argumentation employment, it is worth emphasizing that
    Structure always appears together with Reason (though not vice versa), meaning
    that they are closely intertwined. That is because, in the considered papers,
    the instantiated scheme templates that structure the arguments work as input for
    the evaluating algorithm operated by the reasoning engine.


    In general, it is less common that an argumentation-based chatbot employs argumentation
    solely for its reasoning engine. Indeed, after the semantics of the underlying
    AF have been computed, the bot usually requires a dialogue protocol that handles
    the replies delivery. Speaking of the underlying argumentation framework, we realized
    that, when embedding a knowledge base into an AF, the Bipolar framework (and its
    variants QBAF and WBAF) turns out to be the most common option. This choice is
    related to the additional information provided by BAFs which encompass support
    relations rather than just attacks, allowing for an intuitive formalisation of
    both endorsements and conflicts between pieces of data.


    Within our survey, we identified several conversation domains contemplated by
    the bots, ranging from Healthcare to Nuclear energy, with the former representing
    the prevailing domain (and also subsuming others). Notice that ''unspecified domain''
    could mean either that no conversational topic has been specified or that a sketched
    list of multiple topics has been presented. Interestingly, there is no argumentation-based
    chatbot eligible to be considered as open domain, although we might regard as
    ''semi-open domain'' the agent discussed in (Slonim et al., 2021). Indeed, despite
    the absence of topic limitations in its debate delivery (due to a huge corpus
    upon which arguments are retrieved), the bot is not capable of handling small
    talk or other analogous trivial interactions. This also affects its discussions,
    each of which is modelled as a challenge towards opposite stances. Another peculiarity
    of the agent engineered in (Slonim et al., 2021) is that it allows for unconstrained
    speech in user input, whereas most chatbots only allow for free-text input (and
    the bots envisaged in (Bex et al., 2016) and (Guo et al., 2022) combines both
    free and limited textual prompts). Nonetheless, the proficiency in managing and
    processing unrestricted natural language sentences shows how argumentation-based
    chatbots can aptly mimic realworld-like discussions.


    Finally, observe that almost every examined bot is equipped with a retrieval-based
    response model with the only exception envisaged in (Cocarascu et al., 2019).
    Indeed, the hybrid conversational agent proposed therein handles its dialogues
    mostly via a few tailored textual templates, hence harnessing its rule-based component.
    However, it may also resort to its retrieval-based model when the user questions
    the provided explanations. In general, it is also worth noticing that, unlike
    standard conversational agents, the surveyed literature revealed no generative-type
    argumentation-based chatbots14. Per se, this is not a major drawback, since generative
    response architecture may suffer from various issues such as lack of transparency
    about the origins of the produced replies, biased output, or creation of nonsensical
    responses. Nevertheless, this outlines a current limitation of argumentationbased
    bots, mostly due to an absence of studies on the matter. A possible solution to
    such a shortcoming may be provided, once again, by resorting to a hybrid approach
    that leverages state-of-the-art Transformer technologies. For example, embedding
    argumentation methodologies into current LLMs-based conversational agents would
    produce generative argumentation-based chatbots while also proving useful in mitigating
    those models'' downsides.


    <sup>14.</sup> Recall, however, that we have no explicit information regarding
    the response architecture of ArgueBot (Wambsganss et al., 2021).


    # 5.1 Benefits of Leveraging Computational Argumentation Approaches in Generative-LLMs
    Chatbots Design


    In the literature, the class of generative-LLMs chatbots (e.g. ChatGPT, Llama
    2-Chat, Bard, Claude) is considered to be the present cutting-edge category of
    conversational agents. Having already listed the shortcomings that affect those
    models, we have not yet discussed potential solutions on how to address such limitations.
    We argue that computational argumentation may prove to be an effective means capable
    of successfully handling and amending most of these weaknesses, especially (but
    not limited to) when they originate from the black-box nature of LLMs. Indeed,
    the thriving research field of eXplainable AI (XAI), which studies ways to improve
    the interpretability of AI-driven systems, proposes also argumentative strategies
    as adequate forms of explanations to address the lack of models'' transparency
    (Cyras et al., 2021; Vassiliades et al., 2021). These intuitions are backed ˇ
    by studies such as (McBurney et al., 2021; Castagna, 2022), where it is suggested
    that AI systems should adopt an argumentation-based approach to explanations consisting
    of dialogue protocols characterising the interactions between an explainer and
    an explainee. Embedded into LLMs, such a dialectical interplay would provide an
    informative post hoc method to deliver deliberated explanations to end-users while
    also ensuring detailed replies to follow-on queries.


    On this matter, it is worth noticing that Microsoft conducted an analysis of the
    capability of GPT-4 (one of the latest released GPT models (OpenAI, 2023)) to
    provide clarifications regarding its output (Bubeck et al., 2023). Although it
    outperforms the ChatGPT version based on GPT-3.5, even GPT-4 has its drawbacks
    when dealing with the process consistency of its explanations: it provides a plausible
    account of the rationale behind the generation of its output, but it often fails
    in representing a more general justification able to predict the outcome of the
    model given similar inputs. An argumentative dialogue (such as EQR (McBurney et
    al., 2021; Castagna, 2022)) designed for explanation purposes would solve the
    process-consistency issues by providing conversations where more information can
    be retrieved and thus eschewing the limited explanation length and language constraints
    deemed to be the leading causes of the problem (Bubeck et al., 2023).


    Drawing from the usability of the aforementioned dialogue-based XAI, let us now
    delve into the possible ways in which computational argumentation may provide
    solutions (summarized in Table 3) to the current shortcomings of LLMs:


    Emergent abilities. The puzzling appearance of such an unpredictable phenomenon
    consists of the sudden occurrence of specific competencies in large-scale models
    that do not manifest in smaller ones. Thus, it is not possible to anticipate the
    ''emergence'' of these abilities (e.g. improved arithmetic, multi-task understanding,
    enhanced multi-lingual operations) by simply analysing smaller-scale models (Wei
    et al., 2022a). Among these capabilities, we can also identify Theory of Mind
    (ToM), i.e. the aptitude to impute mental state to others. Considered to be uniquely
    human, ToM may have spontaneously occurred in LLMs as a byproduct of their training
    (Kosinski, 2023). All of the aforementioned aspects contribute to the general
    mystery surrounding Transformer-based technology, which leads to mistrust among
    the general public. Argumentative XAI could indirectly help as a post hoc solution:
    although it cannot identify the reasons why emergent abilities originate, it could
    nonetheless provide explanations that would clarify their functioning.


    Hallucination. Defined as ''the generated content that is nonsensical or unfaithful
    to the provided source content'' (Ji et al., 2023) the phenomenon of hallucination
    in natural language generation can be divided into intrinsic and extrinsic. The
    former refers to generated output that contradicts the source upon which the model
    was trained. The second, instead, represents an output that cannot be verified.
    The employment of an argumentation reasoning engine can reduce the intrinsic hallucination
    kind by stipulating that only grounded arguments (hence, members of conflict-free
    sceptical extensions) will be output by the chatbot. On the other hand, extrinsic
    hallucinations can be probed by argumentative XAI methods, thus ensuring, in the
    worst-case scenario, the retrieval of additional information over the produced
    content.


    Reasoning. Different scholars argue that, although LLMs provide a good representation
    of language generation, they lack reasoning skills and logical thinking (Mahowald
    et al., 2023; Bang et al., 2023; Frieder et al., 2023; Thorp, 2023). In an attempt
    to provide effective solutions, Chain and Tree of Thoughts (respectively, CoT
    and ToT) have been introduced to address such weaknesses. CoT consists of a prompting
    strategy that details a series of intermediate reasoning steps in order to achieve
    better performance in arithmetic, symbolic and commonsense inferences (Wei et
    al., 2022b). The limitations of this approach mostly concern the absence of a
    procedure to plan or analyse multiple reasoning paths before generating the output
    and this is exactly the enhancement yielded by ToT. Indeed, Tree of Thoughts frames
    each problem as a search over a tree, where each node is a partial solution (Yao
    et al., 2023). Against these two options, we argue that endowing generative-LLM-based
    chatbots with a reasoning engine driven by computational argumentation may provide
    a more intuitive and cheaper alternative (e.g. it does not require expensive resources
    to be implemented, unlike ToT). Argumentative reasoning is particularly suited
    for models that parse, work and generate natural language. Recall that AFs are
    graphs whose edges represent paths determining the status of each node. Then,
    semantically computing an argumentation framework allows planning the most appropriate
    sequence of ''thoughts'' (arguments) to achieve the desired result. Such sequences
    account for divergent information, thus also mimicking and (potentially) outperforming
    the recent CCoT (Contrastive Chain of Thought) prompting technique, which mostly
    handles only one contrastive sample at a time (Chia et al., 2023).


    Biased and Toxic Output. Models have a tendency to reflect their training data,
    thus reproducing biased or toxic content that can harm the interacting user (Brown
    et al., 2020). This translates into the critical necessity of aligning LLMs towards
    human moral values, and even in this case, computational argumentation may prove
    useful to mitigate the problem. Indeed, a recent study investigates the use of
    computational argumentation as a tool for detecting unwanted bias in tabular data-driven
    binary classification decision-making systems (Waller, 2023). The proposed method
    is model-agnostic and does not require access to labelled data or the specification
    of protected characteristics. Notice also that the steadfast progress in the field
    of argument mining could ensure the provision of algorithms capable of precisely
    detecting biased and toxic arguments in the underlying dataset and filtering them
    out. This would allow for the reduction of harmful data upon which generative
    models will be trained. Another potential solution envisages leveraging argument
    schemes and their taxonomies. Specifically, the instantiation of AS from AI systems
    enables a semantically richer approach capable of enhancing and leading LLMs-generated
    text into more realistic and ethically constructive debates (Bezou-Vrakatseli,
    2023).


    | Generative LLMs Chatbot | Potential Solutions |            |               |  |

    |-------------------------|---------------------|------------|---------------|--|

    | Shortcomings            | Arg XAI             | Arg Engine | AM<br>&<br>AS |  |

    | Emergent Abilities      | ✓                   |            |               |  |

    | Hallucination           | ✓                   | ✓          |               |  |

    | Reasoning               |                     | ✓          |               |  |

    | Biased and Toxic Output |                     |            | ✓             |  |


    Table 3: Computational argumentation means for addressing LLMs chatbots'' downsides.
    Arg XAI (Argumentative XAI) refers to explanation procedures based on computational
    argumentation strategies and tools. Arg Engine (Argumentative Engine) concerns
    the reasoning capabilities of engines driven by computational argumentation (Section
    2.1.3). Finally, AM indicates the Argument Mining operations of Section 2.1.1,
    whereas AS denotes the Argument Schemes structure of Section 2.1.2.


    ## 6. Conclusion


    Conversational agents and computational argumentation are intrinsically connected
    by their shared focus on dialectical interactions. Combining both subjects, in
    this paper, we have sifted through the literature to review and analyse the existing
    argumentation-based chatbots. Around 70% of the bots we examined (recalling our
    constrained selection, as explained in Section 3) employ computational models
    of arguments as a way of delivering their replies to interacting users, following
    specific dialogue protocols. This implies that argumentative formalism proves
    to be particularly effective when handling exchanges of information in natural
    language, especially if a persuasion goal is involved. In addition, reasoning
    engines prove to be quite a common feature too. Harnessing argumentation extensions,
    those engines provide the rationale for selecting the most appropriate response
    to output, depending on the chosen semantics. Finally, unlike standard bots (i.e.
    non-argumentative ones), we discovered that there is no generative argumentation-based
    chatbot, nor an open-domain one, although there might be some ways of implementing
    such agents by embedding argumentation methodologies within LLM-driven conversational
    agents. Entangled with computational argumentation, chatbot design and their respective
    forthcoming progress, the research field of argumentation-based chatbots appears
    to have promising options to pursue in the coming years, including an interesting
    role to play in the recent Transformer-based turn of AI studies.


    ## References


    - Adamopoulou, E., & Moussiades, L. (2020). Chatbots: History, technology, and
    applications. Machine Learning with Applications, 2, 100006.

    - Adiwardana, D., Luong, M.-T., So, D. R., Hall, J., Fiedel, N., Thoppilan, R.,
    Yang, Z., Kulshreshtha, A., Nemade, G., Lu, Y., et al. (2020). Towards a human-like
    opendomain chatbot. arXiv preprint arXiv:2001.09977.

    - Altay, S., Schwartz, M., Hacquin, A.-S., Allard, A., Blancke, S., & Mercier,
    H. (2022). Scaling up interactive argumentation by providing counterarguments
    with a chatbot. Nature Human Behaviour, 6 (4), 579–592.

    - Alviano, M. (2021). The PYGLAF argumentation reasoner (ICCMA2021).. http: //argumentationcompetition.org/2021/downloads/pyglaf.pdf.

    - Amazon (2014). Alexa.. https://developer.amazon.com/en-US/alexa, (last accessed
    11/10/2022).

    - Amgoud, L., & Ben-Naim, J. (2018). Evaluation of arguments in weighted bipolar
    graphs. International Journal of Approximate Reasoning, 99, 39–55.

    - Andrews, P., Manandhar, S., & De Boni, M. (2008). Argumentative human computer
    dialogue for automated persuasion. In Proceedings of the 9th SIGdial Workshop
    on Discourse and Dialogue, pp. 138–147.

    - Anil, R., Dai, A. M., Firat, O., Johnson, M., Lepikhin, D., Passos, A., Shakeri,
    S., Taropa, E., Bailey, P., Chen, Z., et al. (2023). Palm 2 technical report.
    arXiv preprint arXiv:2305.10403.

    - Apple (2011). Siri.. https://www.apple.com/siri/, (last accessed 11/10/2022).

    - Atkinson, K., Bench-Capon, T., & Modgil, S. (2006). Argumentation for decision
    support. In International Conference on Database and Expert Systems Applications,
    pp. 822– 831. Springer.

    - Azhar, M. Q., & Sklar, E. I. (2017). A study measuring the impact of shared
    decision making in a human-robot team. International Journal of Robotics Research
    (IJRR), 36, 461–482.

    - Bala, K., Kumar, M., Hulawale, S., & Pandita, S. (2017). Chat-bot for college
    management system using ai. International Research Journal of Engineering and
    Technology, 4 (11), 2030–2033.

    - Balatsoukas, P., Sassoon, I., Chapman, M., Kokciyan, N., Drake, A., Modgil,
    S., Ashworth, M., Curcin, V., Sklar, E., & Parsons, S. (2020). In the wild pilot
    usability assessment of a connected health system for stroke self management.
    In 2020 IEEE International Conference on Healthcare Informatics (ICHI), pp. 1–3.
    IEEE.

    - Balatsoukas, P., Porat, T., Sassoon, I., Essers, K., K¨okciyan, N., Chapman,
    M., Drake, A., Modgil, S., Ashworth, M., Sklar, E., et al. (2019). User involvement
    in the design of a data-driven self-management decision support tool for stroke
    survivors. In IEEE EU-ROCON 2019-18th International Conference on Smart Technologies,
    pp. 1–6. IEEE.

    - Bang, Y., Cahyawijaya, S., Lee, N., Dai, W., Su, D., Wilie, B., Lovenia, H.,
    Ji, Z., Yu, T., Chung, W., et al. (2023). A multitask, multilingual, multimodal
    evaluation of chatgpt on reasoning, hallucination, and interactivity. arXiv preprint
    arXiv:2302.04023.

    - Baroni, P., Comini, G., Rago, A., & Toni, F. (2017). Abstract games of argumentation
    strategy and game-theoretical argument strength. In PRIMA 2017: Principles and
    Practice of Multi-Agent Systems: 20th International Conference, Nice, France,
    October 30–November 3, 2017, Proceedings 20, pp. 403–419. Springer.

    - Baroni, P., Romano, M., Toni, F., Aurisicchio, M., & Bertanza, G. (2015). Automatic
    evaluation of design alternatives with quantitative argumentation. Argument &
    Computation, 6 (1), 24–49.

    - Bench-Capon, T., Prakken, H., & Sartor, G. (2009). Argumentation in legal reasoning.
    Springer.

    - Besnard, P., & Hunter, A. (2008). Elements of argumentation, Vol. 47. MIT press
    Cambridge.

    - Bex, F. (2015). An integrated theory of causal stories and evidential arguments.
    In Proceedings of the 15th international conference on artificial intelligence
    and law, pp. 13–22.

    - Bex, F., Peters, J., & Testerink, B. (2016). A.I. for online criminal complaints:
    From natural dialogues to structured scenarios..

    - Bex, F. J., Van Koppen, P. J., Prakken, H., & Verheij, B. (2010). A hybrid formal
    theory of arguments, stories and criminal evidence. Artificial Intelligence and
    Law, 18 (2), 123–152.

    - Bezou-Vrakatseli, E. (2023). Evaluation of llm reasoning via argument schemes.
    In Online Handbook of Argumentation for AI, Vol. 4.

    - Bistarelli, S., Rossi, F., Santini, F., & Carlo, T. (2021a). CONARG: A constraint-programming
    solver for abstract argumentation problems.. http:// argumentationcompetition.org/2021/downloads/conarg.pdf.

    - Bistarelli, S., Taticchi, C., & Santini, F. (2021b). A chatbot extended with
    argumentation.. In AI3@ AI\* IA.

    - Black, E., & Hunter, A. (2007). A generative inquiry dialogue system. In Proceedings
    of the 6th international joint conference on Autonomous agents and multiagent
    systems, pp. 1–8. Association for Computing Machinery.

    - Black, E., Maudet, N., & Parsons, S. (2021). Argumentation-based dialogue. In
    Handbook of Formal Argumentation, Volume 2, p. 511. College Publications.

    - Borg, A., Odekerken, D., et al. (2022). PyArg for solving and explaining argumentation
    in python..

    - Bringsjord, S., & Govindarajulu, N. S. (2022). Artificial Intelligence. In Zalta,
    E. N., & Nodelman, U. (Eds.), The Stanford Encyclopedia of Philosophy (Fall 2022
    edition). Metaphysics Research Lab, Stanford University.

    - Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan,
    A., Shyam, P., Sastry, G., Askell, A., et al. (2020). Language models are few-shot
    learners. Advances in neural information processing systems, 33, 1877–1901.

    - Bryant, D., & Krause, P. (2008). A review of current defeasible reasoning implementations.
    The Knowledge Engineering Review, 23 (3), 227–260.

    - Bryant, D., Krause, P. J., & Vreeswijk, G. (2006). Argue tuProlog: A lightweight
    argumentation engine for agent applications. COMMA, 144, 27–32.

    - Bubeck, S., Chandrasekaran, V., Eldan, R., Gehrke, J., Horvitz, E., Kamar, E.,
    Lee, P., Lee, Y. T., Li, Y., Lundberg, S., et al. (2023). Sparks of artificial
    general intelligence: Early experiments with gpt-4. arXiv preprint arXiv:2303.12712.

    - Cabrio, E., & Villata, S. (2018). Five years of argument mining: a data-driven
    analysis.. In IJCAI, Vol. 18, pp. 5427–5433.

    - Cahn, J. (2017). Chatbot: Architecture, design, & development. University of
    Pennsylvania School of Engineering and Applied Science Department of Computer
    and Information Science.

    - Caldarini, G., Jaf, S., & McGarry, K. (2022). A literature survey of recent
    advances in chatbots. Information, 13 (1), 41.

    - Carpenter, R. (1982). Jabberwacky.. https://web.archive.org/web/20050411013547/
    http://chat.jabberwacky.com/ (last accessed 18/10/2022).

    - Castagna, F. (2022). Towards a fully-fledged formal protocol for the Explanation-Question-Response
    dialogue. In Online Handbook of Argumentation for AI, pp. 17–21.

    - Castagna, F., Garton, A., McBurney, P., Parsons, S., Sassoon, I., & Sklar, E.
    I. (2023). EQRbot: A chatbot delivering EQR argument-based explanations. Frontiers
    in Artificial Intelligence, 6.

    - Castagna, F., Parsons, S., Sassoon, I., & Sklar, E. I. (2022). Providing explanations
    via the EQR argument scheme. In Computational Models of Argument: Proceedings
    of COMMA 2022.

    - Cayrol, C., & Lagasquie-Schiex, M.-C. (2005). On the acceptability of arguments
    in bipolar argumentation frameworks. In European Conference on Symbolic and Quantitative
    Approaches to Reasoning and Uncertainty, pp. 378–389. Springer.

    - Cerutti, F., Palmer, A., Rosenfeld, A., Snajder, J., & Toni, F. (2016). A pilot
    study in ˇ using argumentation frameworks for online debates..

    - Chalaguine, L. A., Hamilton, F. L., Hunter, A., & Potts, H. W. W. (2018). Argument
    harvesting using chatbots. Proceedings of COMMA, 149.

    - Chalaguine, L. A., & Hunter, A. (2018). Chatbot design for argument harvesting.
    Computational Models of Argument: Proceedings of COMMA 2018, 305, 457.

    - Chalaguine, L. A., & Hunter, A. (2019). Knowledge acquisition and corpus for
    argumentation-based chatbots. In CEUR Workshop Proceedings, Vol. 2528, pp. 1–
    14. CEUR Workshop Proceedings.

    - Chalaguine, L. A., & Hunter, A. (2020). A persuasive chatbot using a crowd-sourced
    argument graph and concerns. Computational Models of Argument: Proceedings of
    COMMA 2020, 326, 9.

    - Chalaguine, L. A., & Hunter, A. (2021). Addressing popular concerns regarding
    COVID-19 vaccination with natural language argumentation dialogues. In European
    Conference on Symbolic and Quantitative Approaches with Uncertainty, pp. 59–73.
    Springer.

    - Chalaguine, L. A., Hunter, A., Potts, H., & Hamilton, F. (2019). Impact of argument
    type and concerns in argumentation with a chatbot. In 2019 IEEE 31st International
    Conference on Tools with Artificial Intelligence (ICTAI), pp. 1557–1562. IEEE.

    - Chapman, M., Balatsoukas, P., K¨okciyan, N., Essers, K., Sassoon, I., Ashworth,
    M., Curcin, V., Modgil, S., Parsons, S., & Sklar, E. I. (2019). Computational
    argumentation-based clinical decision support. In 18th International Conference
    on Autonomous Agents and Multiagent Systems, AAMAS 2019, pp. 2345–2347. International
    Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS).

    - Chen, G., Cheng, L., Tuan, L. A., & Bing, L. (2023). Exploring the potential
    of large language models in computational argumentation. arXiv preprint arXiv:2311.09022.

    - Chia, Y. K., Chen, G., Tuan, L. A., Poria, S., & Bing, L. (2023). Contrastive
    chain-ofthought prompting. arXiv preprint arXiv:2311.09277.

    - Cocarascu, O., Rago, A., & Toni, F. (2019). Extracting dialogical explanations
    for review aggregations with argumentative dialogical agents. In Proceedings of
    the 18th International Conference on Autonomous Agents and MultiAgent Systems,
    pp. 1261–1269. Association for Computing Machinery.

    - Cocarascu, O., & Toni, F. (2017). Identifying attack and support argumentative
    relations using deep learning. In Proceedings of the 2017 Conference on Empirical
    Methods in Natural Language Processing, pp. 1374–1379, Copenhagen, Denmark. Association
    for Computational Linguistics.

    - Codecademy (2022). What are chatbots.. https://www.codecademy.com/article/ what-are-chatbots
    (last accessed 11/10/2022).

    - Cogan, E., Parsons, S., & McBurney, P. (2005). New types of inter-agent dialogues.
    In International Workshop on Argumentation in Multi-Agent Systems, pp. 154–168.
    Springer.

    - Colby, K. M., Weber, S., & Hilf, F. D. (1971). Artificial paranoia. Artificial
    Intelligence, 2 (1), 1–25.

    - Cole, D. (2020). The Chinese Room Argument. In Zalta, E. N. (Ed.), The Stanford
    Encyclopedia of Philosophy (Winter 2020 edition). Metaphysics Research Lab, Stanford
    University.

    - Cyras, K., Rago, A., Albini, E., Baroni, P., & Toni, F. (2021). Argumentative
    xai: a survey. ˇ In Proceedings of the Thirtieth International Joint Conference
    on Artificial Intelligence (IJCAI-21) Survey Track. International Joint Conferences
    on Artificial Intelligence.

    - Dachselt, R., Gaggl, S. A., Kr¨otzsch, M., Mendez, J., Rusovac, D., & Yang,
    M. (2022). NEXAS: A visual tool for navigating and exploring argumentation solution
    spaces. Computational Models of Argument: Proceedings of COMMA 2022, 353, 116.


    Dale, R. (2016). The return of the chatbots. Natural Language Engineering, 22
    (5), 811–817.


    - Daws, R. (2020). Medical chatbot using openai''s gpt-3 told a fake patient to
    kill themselves.. https://www.artificialintelligence-news.com/2020/ 10/28/medical-chatbot-openai-gpt3-patient-kill-themselves/
    (last accessed 30/1/2023).

    - de Wynter, A., & Yuan, T. (2023). I wish to have an argument: Argumentative
    reasoning in large language models. arXiv preprint arXiv:2309.16938.

    - Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2018). Bert: Pre-training
    of deep bidirectional transformers for language understanding. arXiv preprint
    arXiv:1810.04805.

    - Dignum, F., & Bex, F. (2017). Creating dialogues using argumentation and social
    practices. In International Conference on Internet Science, pp. 223–235. Springer.

    - Dix, J., Parsons, S., Prakken, H., & Simari, G. R. (2009). Research challenges
    for argumentation.. Comput. Sci. Res. Dev., 23 (1), 27–34.

    - Drake, A., Sassoon, I., Balatsoukas, P., Porat, T., Ashworth, M., Wright, E.,
    Curcin, V., Chapman, M., Kokciyan, N., Sanjay, M., et al. (2022). The relationship
    of sociodemographic factors and patient attitudes to connected health technologies:
    a survey of stroke survivors.. Health Informatics Journal.

    - Dung, P. M. (1995). On the acceptability of arguments and its fundamental role
    in nonmonotonic reasoning, logic programming and n-person games. Artificial intelligence,
    77 (2), 321–357.

    - Dutilh Novaes, C. (2022). Argument and Argumentation. In Zalta, E. N., & Nodelman,
    U. (Eds.), The Stanford Encyclopedia of Philosophy (Fall 2022 edition). Metaphysics
    Research Lab, Stanford University.

    - Dvoˇr´ak, W., Rapberger, A., Wallner, J. P., & Woltran, S. (2020). Aspartix-v19-an
    answer-set programming based system for abstract argumentation. In International
    Symposium on Foundations of Information and Knowledge Systems, pp. 79–89. Springer.

    - Dvor´ak, W., K¨onig, M., Wallner, J. P., & Woltran, S. (2021). ASPARTIX-V21..
    http: //argumentationcompetition.org/2021/downloads/aspartix-v21.pdf.

    - Egly, U., Gaggl, S. A., & Woltran, S. (2008). Aspartix: Implementing argumentation
    frameworks using answer-set programming. In International Conference on Logic
    Programming, pp. 734–738. Springer.

    - Essers, K., Chapman, M., Kokciyan, N., Sassoon, I., Porat, T., Balatsoukas,
    P., Young, P., Ashworth, M., Curcin, V., Modgil, S., et al. (2018). The CONSULT
    system. In Proceedings of the 6th International Conference on Human-Agent Interaction,
    pp. 385–386.

    - Fazzinga, B., Flesca, S., & Furfaro, F. (2018). Probabilistic bipolar abstract
    argumentation frameworks: complexity results. In Proceedings of the Twenty-Seventh
    International Joint Conference on Artificial Intelligence, IJCAI-18, pp. 1803–1809.
    International Joint Conferences on Artificial Intelligence Organization.

    - Fazzinga, B., Galassi, A., & Torroni, P. (2021). An argumentative dialogue system
    for covid-19 vaccine information. In International Conference on Logic and Argumentation,
    pp. 477–485. Springer.

    - Fazzinga, B., Galassi, A., & Torroni, P. (2022). A privacy-preserving dialogue
    system based on argumentation. Intelligent Systems with Applications, 16, 200113.

    - Fichte, J. K., Hecher, M., Gorczyca, P., & Dewoprabowo, R. (2021). A-folio DPDB
    system description for ICCMA 2021.. http://argumentationcompetition.org/2021/
    downloads/a-folio-dpdb.pdf.

    - Fox, J., Glasspool, D., Grecu, D., Modgil, S., South, M., & Patkar, V. (2007).
    Argumentation-based inference and decision making–a medical perspective. IEEE
    intelligent systems, 22 (6), 34–41.

    - Frieder, S., Pinchetti, L., Griffiths, R.-R., Salvatori, T., Lukasiewicz, T.,
    Petersen, P. C., Chevalier, A., & Berner, J. (2023). Mathematical capabilities
    of chatgpt. arXiv preprint arXiv:2301.13867.

    - Gabbay, D. M. (2016). Logical foundations for bipolar and tripolar argumentation
    networks: preliminary results. Journal of Logic and Computation, 26 (1), 247–292.

    - Galitsky, B. (2018). Enabling chatbots by detecting and supporting argumentation..
    https: //patents.google.com/patent/US10679011B2/en.

    - Galitsky, B. (2019). Enabling chatbots by detecting and supporting affective
    argumentation.. https://patents.google.com/patent/US20190138595A1/en.

    - Galitsky, B. (2020). Enabling chatbots by validating argumentation.. https://patents.
    google.com/patent/US10817670B2/en.

    - Gartner, D., & Toni, F. (2007). CaSAPI: a system for credulous and sceptical
    argumentation. Proc. of ArgNMR, 80–95.

    - Girle, R. A. (1996). Commands in dialogue logic. In International Conference
    on Formal and Applied Practical Reasoning, pp. 246–260. Springer.

    - Grando, M. A., Moss, L., Sleeman, D., & Kinsella, J. (2013). Argumentation-logic
    for creating and explaining medical hypotheses. Artificial intelligence in medicine,
    58 (1), 1–13.

    - Guo, K., Wang, J., & Chu, S. K. W. (2022). Using chatbots to scaffold efl students''
    argumentative writing. Assessing Writing, 54, 100666.

    - Habernal, I., & Gurevych, I. (2017). Argumentation mining in user-generated
    web discourse. Computational Linguistics, 43 (1), 125–179.

    - Hadoux, E., & Hunter, A. (2019). Comfort or safety? gathering and using the
    concerns of a participant for better persuasion. Argument & Computation, 10 (2),
    113–147.

    - Hadoux, E., Hunter, A., & Polberg, S. (2021). Strategic argumentation dialogues
    for persuasion: Framework and experiments based on modelling the beliefs and concerns
    of the persuadee. arXiv preprint arXiv:2101.11870.

    - Heater, B. (2018). Alexa gets access to Wolfram Alpha''s knowledge engine..
    https://techcrunch.com/2018/12/20/


    alexa-gets-access-to-wolfram-alphas-knowledge-engine/, (last accessed 29/1/2023).


    - Heinrich, M. (2021). The matrixx solver for argumentation frameworks.. http://
    argumentationcompetition.org/2021/downloads/matrixx.pdf.

    - Hinton, M., & Wagemans, J. H. (2022). How persuasive is ai-generated argumentation?
    an analysis of the quality of an argumentative text produced by the GPT-3 AI text
    generator. Argument & Computation, pp. 1–16.

    - Hulstijn, J. (2000). Dialogue models for inquiry and transaction.. PhD thesis,
    Universiteit Twente, Enschede, The Netherlands.

    - Hung, N. D. (2017). Inference procedures and engine for probabilistic argumentation.
    International Journal of Approximate Reasoning, 90, 163–191.

    - Hunter, A. (2015). Modelling the persuadee in asymmetric argumentation dialogues
    for persuasion. In Twenty-Fourth International Joint Conference on Artificial
    Intelligence.

    - Hunter, A. (2018). Towards a framework for computational persuasion with applications
    in behaviour change. Argument & Computation, 9 (1), 15–40.

    - Hunter, A., Chalaguine, L., Czernuszenko, T., Hadoux, E., & Polberg, S. (2019).
    Towards computational persuasion via natural language argumentation dialogues.
    In Joint German/Austrian Conference on Artificial Intelligence (K¨unstliche Intelligenz),
    pp. 18–33. Springer.

    - IBM (2006). Watson.. https://www.ibm.com/products/watson-assistant (last accessed
    11/10/2022).

    - Ji, Z., Lee, N., Frieske, R., Yu, T., Su, D., Xu, Y., Ishii, E., Bang, Y. J.,
    Madotto, A., & Fung, P. (2023). Survey of hallucination in natural language generation.
    ACM Comput. Surv., 55 (12).

    - Jiang, A. Q., Sablayrolles, A., Mensch, A., Bamford, C., Chaplot, D. S., de
    las Casas, D., Bressand, F., Lengyel, G., Lample, G., Saulnier, L., Lavaud, L.
    R., Lachaux, M.-A., Stock, P., Scao, T. L., Lavril, T., Wang, T., Lacroix, T.,
    & Sayed, W. E. (2023). Mistral 7b..

    - Jiao, W., Wang, W., Huang, J., Wang, X., & Tu, Z. (2023). Is chatgpt a good
    translator? yes with gpt-4 as the engine. arXiv preprint arXiv:2301.08745.

    - Jo, Y., Bang, S., Reed, C., & Hovy, E. (2021). Classifying Argumentative Relations
    Using Logical Mechanisms and Argumentation Schemes. Transactions of the Association
    for Computational Linguistics, 9, 721–739.

    - Kar, R., & Haldar, R. (2016). Applying chatbots to the internet of things: Opportunities
    and architectural elements. International Journal of Advanced Computer Science
    and Applications, 7 (11).

    - Klopfenstein, L. C., Delpriori, S., Malatini, S., & Bogliolo, A. (2017). The
    rise of bots: A survey of conversational interfaces, patterns, and paradigms.
    In Proceedings of the 2017 conference on designing interactive systems, pp. 555–565.

    - K¨okciyan, N., Chapman, M., Balatsoukas, P., Sassoon, I., Essers, K., Ashworth,
    M., Curcin, V., Modgil, S., Parsons, S., & Sklar, E. I. (2019). A collaborative
    decision support tool for managing chronic conditions. In The 17th World Congress
    of Medical and Health Informatics.

    - K¨okciyan, N., Sassoon, I., Sklar, E., Modgil, S., & Parsons, S. (2021). Applying
    metalevel argumentation frameworks to support medical decision making. IEEE Intelligent
    Systems, 36 (2), 64–71.

    - K¨okciyan, N., Sassoon, I., Young, A., Chapman, M., Porat, T., Ashworth, M.,
    Curcin, V., Modgil, S., Parsons, S., & Sklar, E. (2018). Towards an argumentation
    system for supporting patients in self-managing their chronic conditions. In AAAI
    Joint Workshop on Health Intelligence (W3PHIAI).

    - Kosinski, M. (2023). Theory of mind may have spontaneously emerged in large
    language models. arXiv preprint arXiv:2302.02083.

    - Kulatska, I. (2019). Arguebot: Enabling debates through a hybrid retrieval-generation-based
    chatbot. Master''s thesis, University of Twente.

    - Lawrence, J., & Reed, C. (2020). Argument mining: A survey. Computational Linguistics,
    45 (4), 765–818.

    - Li, B., Fang, G., Yang, Y., Wang, Q., Ye, W., Zhao, W., & Zhang, S. (2023).
    Evaluating chatgpt''s information extraction capabilities: An assessment of performance,
    explainability, calibration, and faithfulness. arXiv preprint arXiv:2304.11633.

    - Lin, F., & Shoham, Y. (1989). Argument systems: A uniform basis for nonmonotonic
    reasoning.. KR, 89, 245–255.

    - Lopatovska, I., Rink, K., Knight, I., Raines, K., Cosenza, K., Williams, H.,
    Sorsche, P., Hirsch, D., Li, Q., & Martinez, A. (2019). Talk to me: Exploring
    user interactions with the amazon alexa. Journal of Librarianship and Information
    Science, 51 (4), 984–997.

    - Luck, M., McBurney, P., Shehory, O., & Willmott, S. (2005). Agent technology:
    computing as interaction (a roadmap for agent based computing)..

    - Mahowald, K., Ivanova, A. A., Blank, I. A., Kanwisher, N., Tenenbaum, J. B.,
    & Fedorenko, E. (2023). Dissociating language and thought in large language models:
    a cognitive perspective. arXiv preprint arXiv:2301.06627.

    - Malmqvist, L. (2021). AFGCN: An approximate abstract argumentation solver..
    http: //argumentationcompetition.org/2021/downloads/afgcn.pdf.

    - Marshall, C. (2014). Cortana: everything you need to know about Microsoft''s
    Siri rival.. https://www.techradar.com/news/phone-and-communications/mobile-phones/
    cortana-everything-you-need-to-know-about-microsoft-s-siri-rival-1183607) (last
    accessed 23/08/2023).

    - Mayer, T., Cabrio, E., & Villata, S. (2020). Transformer-based argument mining
    for healthcare applications. In ECAI 2020, pp. 2108–2115. IOS Press.

    - McBurney, P., Hitchcock, D., & Parsons, S. (2007). The eightfold way of deliberation
    dialogue. In International Journal of Intelligent Systems, Vol. 22, pp. 95–132.
    Wiley Online Library.

    - McBurney, P., & Parsons, S. (2001). Chance discovery using dialectical argumentation.
    In Annual Conference of the Japanese Society for Artificial Intelligence, pp.
    414–424. Springer.

    - McBurney, P., & Parsons, S. (2002). Games that agents play: A formal framework
    for dialogues between autonomous agents. Journal of logic, language and information,
    11 (3), 315–334.

    - McBurney, P., & Parsons, S. (2009). Dialogue games for agent argumentation.
    In Argumentation in artificial intelligence, pp. 261–280. Springer.

    - McBurney, P., & Parsons, S. (2013). Talking about doing. From Knowledge Representation
    to Argumentation in AI, Law and Policy Making, 151–166.

    - McBurney, P., Parsons, S., et al. (2021). Argument schemes and dialogue protocols:
    Doug walton''s legacy in artificial intelligence. Journal of Applied Logics, 8
    (1), 263–286.

    - McBurney, P., Van Eijk, R. M., Parsons, S., & Amgoud, L. (2003). A dialogue
    game protocol for agent purchase negotiations. In Autonomous Agents and Multi-Agent
    Systems, Vol. 7, pp. 235–273. Springer.

    - Mercier, H., & Sperber, D. (2011). Why do humans reason? arguments for an argumentative
    theory. Behavioral and brain sciences, 34 (2), 57–74.

    - Microsoft (2014). Cortana.. https://www.microsoft.com/en-us/cortana (last accessed
    11/10/2022).

    - Modgil, S., & Prakken, H. (2013). A general account of argumentation with preferences.
    Artificial Intelligence, 195, 361–397.

    - Murphy, J., Black, E., & Luck, M. M. (2016). A heuristic strategy for persuasion
    dialogues. In Computational Models of Argument: Proceedings of COMMA 2016, pp.
    411–418. IOS Press.

    - Niskanen, A., & J¨arvisalo, M. (2021). µ–toksia at ICCMA''21.. http:// argumentationcompetition.org/2021/downloads/mu-toksia.pdf.

    - OpenAI (2023). Gpt-4 technical report.. arXiv.

    - Patterson, D., Gonzalez, J., H¨olzle, U., Le, Q., Liang, C., Munguia, L.-M.,
    Rothchild, D., So, D. R., Texier, M., & Dean, J. (2022). The carbon footprint
    of machine learning training will plateau, then shrink. Computer, 55 (7), 18–28.

    - Podlaszewski, M., Caminada, M., & Pigozzi, G. (2011). An implementation of basic
    argumentation components. In The 10th International Conference on Autonomous Agents
    and Multiagent Systems-Volume 3, pp. 1307–1308.

    - Pollock, J. L. (1987). Defeasible reasoning. Cognitive science, 11 (4), 481–518.

    - Prakken, H. (2006). Formal systems for persuasion dialogue. In The knowledge
    engineering review, Vol. 21, pp. 163–188. Cambridge University Press.

    - Prakken, H., Bistarelli, S., & Santini, F. (2020). Computational Models of Argument:
    Proceedings of COMMA 2020, Vol. 326. IOS Press.

    - Qin, C., Zhang, A., Zhang, Z., Chen, J., Yasunaga, M., & Yang, D. (2023). Is
    chatgpt a general-purpose natural language processing task solver?. arXiv preprint
    arXiv:2302.06476.

    - Rago, A., Cocarascu, O., Bechlivanidis, C., & Toni, F. (2020). Argumentation
    as a framework for interactive explanations for recommendations. In Proceedings
    of the International Conference on Principles of Knowledge Representation and
    Reasoning, Vol. 17, pp. 805–815.

    - Rago, A., Cocarascu, O., & Toni, F. (2018). Argumentation-based recommendations:
    Fantastic explanations and how to find them. In Proceedings of the Twenty-Seventh
    International Joint Conference on Artificial Intelligence, pp. 1949–1955.

    - Rago, A., Toni, F., Aurisicchio, M., & Baroni, P. (2016). Discontinuity-free
    decision support with quantitative argumentation debates. In Fifteenth International
    Conference on the Principles of Knowledge Representation and Reasoning.

    - Rahwan, I., & Larson, K. (2009). Argumentation and game theory. Argumentation
    in artificial intelligence, 321–339.

    - Rahwan, I., & Simari, G. R. (2009). Argumentation in Artificial Intelligence.
    Springer.

    - Reckwitz, A. (2002). Toward a theory of social practices: A development in culturalist
    theorizing. European journal of social theory, 5 (2), 243–263.

    - Roller, S., Dinan, E., Goyal, N., Ju, D., Williamson, M., Liu, Y., Xu, J., Ott,
    M., Shuster, K., Smith, E. M., et al. (2020). Recipes for building an open-domain
    chatbot. arXiv preprint arXiv:2004.13637.

    - Rosenfeld, A., & Kraus, S. (2016). Strategical argumentative agent for human
    persuasion. In ECAI 2016, pp. 320–328. IOS Press.

    - Ruiz-Dolz, R., Alemany, J., Barbera, S., & Garcia-Fornes, A. (2021). Transformer-based
    models for automatic identification of argument relations: A cross-domain evaluation.
    IEEE Intelligent Systems, 36 (06), 62–70.

    - Saadat-Yazdi, A., Pan, J., & K¨okciyan, N. (2023). Uncovering implicit inferences
    for improved relational argument mining. In Proceedings of the 17th Conference
    of the European Chapter of the Association for Computational Linguistics, pp.
    2476–2487.

    - Sansonnet, J.-P., Leray, D., & Martin, J.-C. (2006). Architecture of a framework
    for generic assisting conversational agents. In International Workshop on Intelligent
    Virtual Agents, pp. 145–156. Springer.

    - Sassoon, I., K¨okciyan, N., Chapman, M., Sklar, E., Curcin, V., Modgil, S.,
    & Parsons, S. (2020). Implementing argument and explanation schemes in dialogue.
    Computational Models of Argument: Proceedings of COMMA 2020, 326, 471.

    - Sassoon, I., K¨okciyan, N., Modgil, S., & Parsons, S. (2021). Argumentation
    schemes for clinical decision support. Argument & Computation, pp. 1–27.

    - Sassoon, I., K¨okciyan, N., Sklar, E., & Parsons, S. (2019). Explainable argumentation
    for wellness consultation. In International Workshop on Explainable, Transparent
    Autonomous Agents and Multi-Agent Systems, pp. 186–202. Springer.

    - Schaeffer, R., Miranda, B., & Koyejo, S. (2023). Are emergent abilities of large
    language models a mirage?. arXiv preprint arXiv:2304.15004.

    - Searle, J. R. (1980). Minds, brains, and programs. Behavioral and brain sciences,
    3 (3), 417–424.

    - Shove, E., Pantzar, M., & Watson, M. (2012). The Dynamics of Social Practice:
    Everyday Life and how it Changes. SAGE.

    - Silver, D., & Veness, J. (2010). Monte-carlo planning in large pomdps. Advances
    in neural information processing systems, 23.

    - Singh, S., & Thakur, H. K. (2020). Survey of various AI Chatbots based on technology
    used. In 2020 8th International Conference on Reliability, Infocom Technologies
    and Optimization (Trends and Future Directions)(ICRITO), pp. 1074–1079. IEEE.

    - Sklar, E., & Parsons, S. (2004). Towards the application of argumentation-based
    dialogues for education. In Autonomous Agents and Multiagent Systems, International
    Joint Conference on, Vol. 4, pp. 1420–1421. IEEE Computer Society.

    - Sklar, E. I., & Azhar, M. Q. (2015). Argumentation-based dialogue games for
    shared control in human-robot systems. Journal of Human-Robot Interaction, 4 (3),
    120–148.

    - Sklar, E. I., & Azhar, M. Q. (2018). Explanation through argumentation. In Proceedings
    of the 6th International Conference on Human-Agent Interaction, pp. 277–285.

    - Slonim, N., Bilu, Y., Alzate, C., Bar-Haim, R., Bogin, B., Bonin, F., Choshen,
    L., Cohen-Karlik, E., Dankin, L., Edelstein, L., et al. (2021). An autonomous
    debating system. Nature, 591 (7850), 379–384.

    - Sojasingarayar, A. (2020). Seq2seq ai chatbot with attention mechanism. arXiv
    preprint arXiv:2006.02767.

    - Tang, Y., Sklar, E., & Parsons, S. (2012). An argumentation engine: Argtrust.
    In Ninth International Workshop on Argumentation in Multiagent Systems.

    - Thimm, M. (2021). Harper+: Using grounded semantics for approximate reasoning
    in abstract argumentation.. http://argumentationcompetition.org/2021/downloads/
    harper++.pdf.

    - Thimm, M., Cerutti, F., & Vallati, M. (2021). FUDGE: A light-weight solver for
    abstract argumentation based on sat reductions.. http://argumentationcompetition.org/
    2021/downloads/fudge.pdf.

    - Thorp, H. H. (2023). Chatgpt is fun, but not an author. Science, 379 (6630),
    313–313.

    - Tolchinsky, P., Modgil, S., Atkinson, K., McBurney, P., & Cort´es, U. (2012).
    Deliberation dialogues for reasoning about safety critical actions. Autonomous
    Agents and Multi-Agent Systems, 25 (2), 209–259.

    - Toni, F. (2014). A tutorial on assumption-based argumentation. Argument & Computation,
    5 (1), 89–117.

    - Toniuc, D., & Groza, A. (2017). Climebot: An argumentative agent for climate
    change. In 2017 13th IEEE International Conference on Intelligent Computer Communication
    and Processing (ICCP), pp. 63–70. IEEE.

    - Touvron, H., Lavril, T., Izacard, G., Martinet, X., Lachaux, M.-A., Lacroix,
    T., Rozi`ere, B., Goyal, N., Hambro, E., Azhar, F., et al. (2023a). Llama: Open
    and efficient foundation language models. arXiv preprint arXiv:2302.13971.

    - Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y., Bashlykov,
    N., Batra, S., Bhargava, P., Bhosale, S., et al. (2023b). Llama 2: Open foundation
    and fine-tuned chat models. arXiv preprint arXiv:2307.09288.

    - Trautmann, D., Daxenberger, J., Stab, C., Sch¨utze, H., & Gurevych, I. (2020).
    Fine-grained argument unit recognition and classification. In Proceedings of the
    AAAI Conference on Artificial Intelligence, Vol. 34, pp. 9048–9056.

    - Tunstall, L., Beeching, E., Lambert, N., Rajani, N., Rasul, K., Belkada, Y.,
    Huang, S., von Werra, L., Fourrier, C., Habib, N., Sarrazin, N., Sanseviero, O.,
    Rush, A. M., & Wolf, T. (2023). Zephyr: Direct distillation of lm alignment..

    - Turing, A. M., & Haugeland, J. (1950). Computing machinery and intelligence.
    The Turing Test: Verbal Behavior as the Hallmark of Intelligence, 29–56.

    - Vassiliades, A., Bassiliades, N., & Patkos, T. (2021). Argumentation and explainable
    artificial intelligence: a survey. The Knowledge Engineering Review, 36.

    - Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N.,
    Kaiser, L., & Polosukhin, I. (2017). Attention is all you need. Advances in neural
    information processing systems, 30.

    - Visser, J., Lawrence, J., Wagemans, J., & Reed, C. (2018). Revisiting computational
    models of argument schemes: Classification, annotation, comparison. In 7th International
    Conference on Computational Models of Argument, COMMA 2018, pp. 313–324. ios Press.

    - Vreeswijk, G. (1994). IACAS: An interactive argumentation system. Rapport technique
    CS, 94 (03).

    - Wagemans, J. (2016). Constructing a periodic table of arguments. In Argumentation,
    objectivity, and bias: Proceedings of the 11th international conference of the
    Ontario Society for the Study of Argumentation (OSSA), Windsor, ON: OSSA, pp.
    1–12.

    - Wallace, R. (2003). The elements of AIML style. Alice AI Foundation, 139.

    - Wallace, R. S. (2009). The anatomy of A.L.I.C.E.. In Parsing the turing test,
    pp. 181–210. Springer.

    - Waller, M. (2023). An argumentation-based approach to bias detection in automated
    decision-making systems. In Online Handbook of Argumentation for AI, Vol. 4.

    - Walton, D. (2012). Argument mining by applying argumentation schemes. Studies
    in Logic, 4 (1), 2011.

    - Walton, D., & Krabbe, E. C. (1995). Commitment in dialogue: Basic concepts of
    interpersonal reasoning. SUNY press.

    - Walton, D., & Macagno, F. (2015). A classification system for argumentation
    schemes. Argument & Computation, 6 (3), 219–245.

    - Walton, D., Reed, C., & Macagno, F. (2008). Argumentation schemes. Cambridge
    University Press.

    - Walton, D. N. (1990). What is reasoning? What is an argument?. The journal of
    Philosophy, 87 (8), 399–419.

    - Wambsganss, T., Guggisberg, S., & S¨ollner, M. (2021). Arguebot: A conversational
    agent for adaptive argumentation feedback. In Innovation Through Information Systems:
    Volume II: A Collection of Latest Research on Technology Issues, pp. 267–282.
    Springer.

    - Wei, J., Tay, Y., Bommasani, R., Raffel, C., Zoph, B., Borgeaud, S., Yogatama,
    D., Bosma, M., Zhou, D., Metzler, D., et al. (2022a). Emergent abilities of large
    language models. arXiv preprint arXiv:2206.07682.

    - Wei, J., Wang, X., Schuurmans, D., Bosma, M., Xia, F., Chi, E., Le, Q. V., Zhou,
    D., et al. (2022b). Chain-of-thought prompting elicits reasoning in large language
    models. Advances in Neural Information Processing Systems, 35, 24824–24837.

    - Weizenbaum, J. (1966). ELIZA-a computer program for the study of natural language
    communication between man and machine. Communications of the ACM, 9 (1), 36– 45.

    - Worswick, S. (2013). Interview Loebner 2013 winner.. https://aidreams.co.uk/
    forum/index.php?page=Steve\_Worswick\_Interview\_-\_Loebner\_2013\_winner# .Y0IfoHZBxPY
    (last accessed 11/10/2022).

    - Worswick, S. (2018). Mitsuku wins Loebner Prize 2018!.. https://medium.com/
    pandorabots-blog/mitsuku-wins-loebner-prize-2018-3e8d98c5f2a7 (last accessed 18/06/2023).

    - Xu, J., Ju, D., Lane, J., Komeili, M., Smith, E. M., Ung, M., Behrooz, M., Ngan,
    W., Moritz, R., Sukhbaatar, S., Boureau, Y.-L., Weston, J., & Shuster, K. (2023).
    Improving open language models by learning from organic interactions..

    - Yao, S., Yu, D., Zhao, J., Shafran, I., Griffiths, T. L., Cao, Y., & Narasimhan,
    K. (2023). Tree of thoughts: Deliberate problem solving with large language models.
    arXiv preprint arXiv:2305.10601.

    - Zhang, Y., Sun, S., Galley, M., Chen, Y.-C., Brockett, C., Gao, X., Gao, J.,
    Liu, J., & Dolan, B. (2019). Dialogpt: Large-scale generative pre-training for
    conversational response generation. arXiv preprint arXiv:1911.00536.

    - Zhao, W. X., Zhou, K., Li, J., Tang, T., Wang, X., Hou, Y., Min, Y., Zhang,
    B., Zhang, J., Dong, Z., et al. (2023). A survey of large language models. arXiv
    preprint arXiv:2303.18223.

    - Zhou, L., Gao, J., Li, D., & Shum, H.-Y. (2020). The Design and Implementation
    of XiaoIce, an Empathetic Social Chatbot. Computational Linguistics, 46 (1), 53–93.'
  decisions:
    evaluation_prompt: 'Disqualified: no evaluation. Reason: The abstract and introduction
      focus on a survey of literature and theoretical discussions without any mention
      of empirical, experimental, or quantitative evaluation methods, such as experiments,
      benchmarks, or metrics.'
    related_work_prompt: '- Qualified. Reason: The paper engages with prior research
      by citing multiple sources, including foundational works on chatbots (e.g.,
      Caldarini et al., 2022; Weizenbaum, 1966) and computational argumentation (e.g.,
      Rahwan & Simari, 2009). It discusses the evolution of chatbot technology and
      compares the proposed argumentation-based approach with existing methods, indicating
      a clear engagement with earlier studies and literature in the field.'
    novelty_prompt: 'Qualified. Reason: The paper claims novelty by stating, "To the
      best of our knowledge, this is the first survey that combines computational
      argumentation and chatbots," indicating a new contribution to the field.'
    review_only_prompt: 'Disqualified: review paper. Reason: The title contains the
      word "survey," and the abstract describes the paper as primarily summarizing
      existing work without proposing new methods, results, or tools.'
  llm_input_used: '## Abstract

    Chatbots are conversational software applications designed to interact

    dialectically with users for a plethora of different purposes. Surprisingly,

    these colloquial agents have only recently been coupled with computational

    models of arguments (i.e. computational argumentation), whose aim is to

    formalise, in a machine-readable format, the ordinary exchange of information

    that characterises human communications. Chatbots may employ argumentation with

    different degrees and in a variety of manners. The present survey sifts through

    the literature to review papers concerning this kind of argumentation-based

    bot, drawing conclusions about the benefits and drawbacks that this approach

    entails in comparison with standard chatbots, while also envisaging possible

    future development and integration with the Transformer-based architecture and

    state-of-the-art Large Language models.


    ## Introduction

    Chatbots are conversational software applications designed to mimic human discourse
    mostly to enable automated online guidance and support (Caldarini et al., 2022).
    These computer programs generate responses based on given inputs, producing replies
    via text or speech format (Sojasingarayar, 2020; Bala et al., 2017). In addition,
    to be defined as such, chatbots must satisfy specific functions. As colloquial
    agents, they need to be able to understand the user (comprehension), have access
    to a knowledge base (competence) and provide an ''anthropomorphic effect'' to
    increase the users'' trust (presence) (Cahn, 2017; Sansonnet et al., 2006). Nowadays,
    these bots represent familiar tools that exist in our lives in the form of virtual
    agents. Their assistance ranges from answering inquiries to e-commerce, from information
    retrieval to educational tasks, and from developing new industrial solutions (Dale,
    2016) to connecting smart objects (Kar & Haldar, 2016). The manifold investments
    of the past decade, the technological advancements (from both software and hardware
    viewpoints), and the development of more efficient Machine Learning (ML) models,
    including the latest Transformer-based architecture (Vaswani et al., 2017), have
    contributed to the steady growth of the research field of chatbot design and implementation.
    Many steps forward have been taken since the release of ELIZA around sixty years
    ago, which is widely considered to be the first conversational agent (Weizenbaum,
    1966).


    The investigation of computational models of arguments in relation to chatbots
    has only recently received attention from researchers. Computational argumentation
    (Rahwan & Simari, 2009) has been applied in Artificial Intelligence (AI) as a
    mechanism for reasoning in which conclusions are drawn from evidence that supports
    the conclusions. Being an intuitive (i.e. closer to everyday human dialectical
    interplay), yet formal, approach for modelling conflicting information occurring
    during exchange of arguments, computational argumentation should be qualified
    as a highly appropriate methodology to enhance current bot behaviours. The benefits
    from such a combination include: more natural discourse, response coherence and
    strategical conveyance of information. Evaluating argumentation semantics would
    also provide the rationale for positing replies in a more transparent way than
    the black-box Large Language models (LLMs) employed in today''s state-of-the-art
    conversational agents. In recent years, cutting-edge technologies have produced
    implementations, such as the various versions of ChatGPT<sup>1</sup> , which currently
    outperform argumentation-based conversational agents. Nonetheless, taking a closer
    look—as we do here—shows that there is plenty of room for improvement for these
    recent advanced models, and integration with the computational argumentation formalism
    may solve their present shortcomings (e.g. lack of explainability), thus potentially
    initiating a new generation of chatbots. To the best of our knowledge, this is
    the first survey that combines computational argumentation and chatbots<sup>2</sup>
    . Our main contribution involves an extensive examination of the relevant literature
    and the subsequent findings that can be drawn from such analysis.


    The paper is structured as follows. We first start by introducing background information
    in Section 2 about the essential theoretical notions involved. In Section 3, we
    then discuss the methodology adopted for reviewing the relevant articles. A thorough
    classification and analysis of conversational agents leveraging computational
    argumentation is given in Section 4. Section 5 illustrates a comprehensive examination
    of the paper''s findings and potential future directions of the argumentation-based
    chatbot research field, and Section 6 concludes the survey with final remarks.'
  token_usage: 4639
  time_usage: 5.534575462341309
- title: Quantifying stability of non-power-seeking in artificial agents
  abstract: 'We investigate the question: if an AI agent is known to be safe in one

    setting, is it also safe in a new setting similar to the first? This is a core

    question of AI alignment--we train and test models in a certain environment,

    but deploy them in another, and we need to guarantee that models that seem safe

    in testing remain so in deployment. Our notion of safety is based on

    power-seeking--an agent which seeks power is not safe. In particular, we focus

    on a crucial type of power-seeking: resisting shutdown. We model agents as

    policies for Markov decision processes, and show (in two cases of interest)

    that not resisting shutdown is "stable": if an MDP has certain policies which

    don''t avoid shutdown, the corresponding policies for a similar MDP also don''t

    avoid shutdown. We also show that there are natural cases where safety is _not_

    stable--arbitrarily small perturbations may result in policies which never shut

    down. In our first case of interest--near-optimal policies--we use a

    bisimulation metric on MDPs to prove that small perturbations won''t make the

    agent take longer to shut down. Our second case of interest is policies for

    MDPs satisfying certain constraints which hold for various models (including

    language models). Here, we demonstrate a quantitative bound on how fast the

    probability of not shutting down can increase: by defining a metric on MDPs;

    proving that the probability of not shutting down, as a function on MDPs, is

    lower semicontinuous; and bounding how quickly this function decreases.'
  url: http://arxiv.org/abs/2401.03529v1
  keywords: ''
  document: "#### QUANTIFYING STABILITY OF NON-POWER-SEEKING IN ARTIFICIAL AGENTS\n\
    \n#### EVAN RYAN GUNTER<sup>1</sup> , YEVGENY LIOKUMOVICH<sup>2</sup> , AND VICTORIA\
    \ KRAKOVNA<sup>3</sup>\n\nAbstract. We investigate the question: if an AI agent\
    \ is known to be safe in one setting, is it also safe in a new setting similar\
    \ to the first? This is a core question of AI alignment—we train and test models\
    \ in a certain environment, but deploy them in another, and we need to guarantee\
    \ that models that seem safe in testing remain so in deployment. Our notion of\
    \ safety is based on power-seeking—an agent which seeks power is not safe. In\
    \ particular, we focus on a crucial type of power-seeking: resisting shutdown.\
    \ We model agents as policies for Markov decision processes, and show (in two\
    \ cases of interest) that not resisting shutdown is \"stable\": if an MDP has\
    \ certain policies which don't avoid shutdown, the corresponding policies for\
    \ a similar MDP also don't avoid shutdown. We also show that there are natural\
    \ cases where safety is not stable—arbitrarily small perturbations may result\
    \ in policies which never shut down. In our first case of interest—near-optimal\
    \ policies—we use a bisimulation metric on MDPs to prove that small perturbations\
    \ won't make the agent take longer to shut down. Our second case of interest is\
    \ policies for MDPs satisfying certain constraints which hold for various models\
    \ (including language models). Here, we demonstrate a quantitative bound on how\
    \ fast the probability of not shutting down can increase: by defining a metric\
    \ on MDPs; proving that the probability of not shutting down, as a function on\
    \ MDPs, is lower semicontinuous; and bounding how quickly this function decreases.\n\
    \n# 1. Introduction\n\n## 1.1. Power-seeking\n\nA primary source of extreme risk\
    \ from AI is through advanced AI systems seeking power, influence and resources\
    \ [\\[Carlsmith, 2022,](#page-19-0) [Ngo, 2022\\]](#page-21-0). One approach to\
    \ reducing this risk is to build systems which do not seek power [\\[Turner and\
    \ Tadepalli, 2022,](#page-21-1) [Turner et al., 2019\\]](#page-21-2). Power-seeking\
    \ can be defined in many ways, and can take many forms depending on the goals\
    \ and environment of the AI. For nearly every definition and scenario, a power-seeking\
    \ AI will avoid shutdown: it has no power if it cannot take actions [\\[Krakovna\
    \ and Kramar,](#page-20-0) [2023\\]](#page-20-0).\n\nFor example, a reinforcement\
    \ learning (RL) agent trained to achieve some objective in an open-ended game\
    \ will likely avoid actions which cause the game to end, since it can no longer\
    \ affect its reward after the game has ended. Likewise, a large language model\
    \ (LLM) with scaffolding for goal-directed planning (such as AutoGPT [Richards\
    \ \\[2023\\]](#page-21-3)) may reason that it can best assure that its task is\
    \ completed by continuing to run. An agent avoiding ending a game is harmless,\
    \ but the same incentives may cause an agent deployed in the real world to resist\
    \ humans shutting it down. For example, an LLM may reason that its designers will\
    \ shut it down if it is caught behaving badly, and produce exactly the output\
    \ they want\n\n<sup>1</sup>ML Alignment & Theory Scholars (MATS)\n\n<sup>2</sup>University\
    \ of Toronto\n\n<sup>3</sup>Google DeepMind\n\nto see—until it has the opportunity\
    \ to copy its code onto a server outside of its designers' control [\\[Cotra,\
    \ 2022\\]](#page-19-1).\n\nAlthough an AI system which does not resist shutdown\
    \ but does seek power in other ways could cause damage, the damage would likely\
    \ be limited since it would be shut down as soon as the undesired behavior was\
    \ noticed [\\[Soares et al., 2015\\]](#page-21-4). In particular, not resisting\
    \ shutdown implies not being deceptive in order to avoid shutdown, so such an\
    \ AI system would not deliberately hide its true intentions until it gained enough\
    \ power to enact its plans. Thus, our investigation of power-seeking will focus\
    \ on cases where an agent does not resist shutdown, and how fragile the good behavior\
    \ of such an agent is.\n\nWe model AI shutdown in the Markov decision process\
    \ (MDP) setting with a set of \"safe states\" which the agent cannot escape once\
    \ it enters. These safe states can be chosen as desired for the scenario under\
    \ consideration. For example, they can be taken to be states where the agent voluntarily\
    \ shuts itself off, or otherwise turns over control to humans for the rest of\
    \ the run, or takes any other irreversible action. We are also free to include\
    \ other stipulations in what counts as a safe state. For example, we can define\
    \ the safe states to be the states where the AI agent has shut down within 5 minutes\
    \ of being deployed, or where it has shut down without creating any remote subagents\
    \ (though in practice it may be difficult to quantify the creation of subagents).\
    \ Section [3](#page-7-0) covers how we model power-seeking in the MDP framework.\n\
    \n## 1.2. Findings\n\nWe show that, in two cases of interest, agents which do\
    \ not resist shutdown maintain this good behavior when the setting they are deployed\
    \ in changes slightly. We also demonstrate a natural case where good behavior\
    \ is not stable: arbitrarily small changes can destroy the safety of the agent.\
    \ We work in the Markov decision process (MDP) model: a very general model for\
    \ agents acting in an environment with rewards. Our two cases of interest are:\n\
    \n- <span id=\"page-1-1\"></span><span id=\"page-1-0\"></span>(1) Near-optimal\
    \ policies for which we know the reward function; and\n- (2) Policies which are\
    \ fixed, well-behaved functions on a structured state space (e.g. LLMs).\n\nWe\
    \ expect these cases to be relevant to a broad class of future models. We cover\
    \ Case (1) in Sections [4](#page-8-0) and [5](#page-10-0) and Case (2) in Section\
    \ [6.](#page-13-0)\n\nCase [\\(1\\)](#page-1-0). Near-optimal policies can model\
    \ highly capable goal-directed agents, regardless of architecture. Near-optimal\
    \ agents for real-world goals are extremely unlikely to ever be achieved. However,\
    \ there are many constrained settings in which near-optimality may be an achievable\
    \ target, such as chess or diplomacy games. This model was used in [Turner et\
    \ al.](#page-21-2) [\\[2019\\]](#page-21-2) to describe future RL agents. Assume\
    \ an MDP where every policy within ε of optimal has expected stopping time (number\
    \ of steps to reach designated \"safe states\") less than N. Then we prove that\
    \ every policy within <sup>ε</sup> 2 of optimal for a sufficiently similar MDP,\
    \ which additionally does not \"play dead\", has expected stopping time less than\
    \ N + 1.\n\nTo define \"sufficiently similar\", we use a bisimulation metric [\\\
    [Ferns et al., 2004\\]](#page-20-1), which quantitatively measures the extent\
    \ to which the two MDPs being compared have similar structure and rewards. This\
    \ gives a method to prove whether an arbitrarily capable agent\n\n![](_page_2_Figure_1.jpeg)\n\
    \n<span id=\"page-2-0\"></span>Figure 1. Case (1): An MDP is modified via a small\
    \ perturbation in the bisimulation metric. Although one state splits into two,\
    \ the two states collectively behave similarly to the original; the changes to\
    \ the transition probabilities are also small. Non-power-seeking is preserved\
    \ under this perturbation: not only is it still optimal to proceed to Ssafe as\
    \ soon as possible, but also the average time to reach Ssafe under any sequence\
    \ of actions is only marginally increased.\n\n![](_page_2_Figure_3.jpeg)\n\n<span\
    \ id=\"page-2-1\"></span>Figure 2. Case (1): An example of [\"playing dead\".](#page-13-1)\
    \ The state Spd is very close in bisimulation metric to Ssafe, but distinct (and\
    \ can be escaped). Nonpower-seeking is not preserved under this perturbation,\
    \ even though the perturbation is small.\n\nwill remain safe when deployed in\
    \ a new setting, as long as the agent is nearly optimal for a reward function\
    \ which we can compute. Figure [1](#page-2-0) gives an example of two MDPs which\
    \ are nearby in the bisimulation metric.\n\n\"Playing dead\" is our example of\
    \ a natural case where stability fails. A policy which \"plays dead\" goes to\
    \ a state which closely resembles a safe state, but which is not itself safe.\
    \ In such a case, an arbitrarily small change—one which creates the \"playing\
    \ dead\" state—can suddenly decrease the safety of the policy. Such a case is\
    \ demonstrated in Figure [2.](#page-2-1)\n\nThis model does not avoid issues of\
    \ goal misgeneralization: cases where the agent learns to optimize an objective\
    \ that differs from the one it was trained on [\\[Hubinger et al., 2019,](#page-20-2)\
    \ [Langosco et al., 2022\\]](#page-20-3). However, it may allow us to prove safety\
    \ when deploying models\n\n![](_page_3_Figure_1.jpeg)\n\n<span id=\"page-3-0\"\
    ></span>Figure 3. Case (2): A perturbation of an MDP modeling an LLM agent. E(<text>)\
    \ is the embedding of <text>. \"<...>\" indicates repeated text that has been\
    \ omitted. In the original MDP, the top state corresponds to the embedding of\
    \ a user query; in the perturbed MDP, it corresponds to the embedding of a slightly\
    \ different query. The other states change to reflect the embeddings of the resulting\
    \ slightly different histories. (The LLM response is produced token-by-token,\
    \ but here its whole output is shown as a single transition for concision.) Theorem\
    \ [6.5](#page-16-0) bounds how much transition probabilities may change under\
    \ such a perturbation.\n\nwhich are aligned to any known objective—even objectives\
    \ which do not accurately reflect our values but do encourage shutdown, e.g. because\
    \ they involve a high discount rate.\n\nCase [\\(2\\)](#page-1-1). To model an\
    \ LLM in an MDP, we let\n\n- the states be embeddings of possible inputs to the\
    \ LLM, plus side information;\n- the actions be the tokens the LLM may emit; and\n\
    - the policy be the LLM itself.\n\nSee section [6.1](#page-13-2) for a more detailed\
    \ description of the construction.\n\nOur MDP model for LLMs is motivated by the\
    \ following considerations: LLMs operate on a state space with structure inherited\
    \ from the embedding space; have a fixed policy where the derivative of the output\
    \ with respect to the input is bounded; and, unlike optimal policies, do not require\
    \ a reward function to model. In this case, safety is modeled as the probability\
    \ of shutting down. We prove that the rate of decrease in safety under a small\
    \ perturbation of the MDP is bounded by a function of the rate of convergence\
    \ of the policy in the MDP. This gives a method to prove how much less safe an\
    \ LLM (or similar model) can become in deployment, where inputs differ slightly\
    \ from testing.\n\nThis may allow us to quantify the safety of a model deployed\
    \ in a setting where we are careful to give it similar inputs during testing and\
    \ deployment, as we might do if we are attempting to control the AI rather than\
    \ align it [\\[Greenblatt et al., 2023\\]](#page-20-4). This involves using oversight\
    \ methods such that an AI system that would be very dangerous if allowed to operate\
    \ freely is very unlikely to successfully do harm, because it is unable to distinguish\
    \ the scenarios where it is being monitored from those where it could successfully\
    \ do harm. An example of the type of perturbation that could be used to model\
    \ such a scenario is given in figure [3.](#page-3-0)\n\n# 2. Related work\n\n\
    ## 2.1. Shutdown\n\nMany related works have described control of AI agents in\
    \ similar terms to shutdown. The model in [Martin et al. \\[2016\\]](#page-21-5)\
    \ has a \"death\" state which is compatible with our definition of a shutdown\
    \ state: its key feature is that it can't be escaped. They demonstrate one way\
    \ to create an agent that navigates to this shutdown state and hence, under our\
    \ definition, does not resist shutdown. This is an optimal agent that knows the\
    \ environment it is in and which has rewards that are bounded and negative, except\
    \ at the shutdown state where the reward is zero. Such an agent is \"suicidal\"\
    —it will seek to shut down immediately if possible. However, an agent that seeks\
    \ to shut itself down, while fairly safe, is not very useful since it will shut\
    \ itself down instead of performing useful tasks. Our framework can handle a broader\
    \ range of agents which eventually shut down.\n\n[Orseau and Armstrong \\[2016\\\
    ]](#page-21-6) and [Langlois and Everitt \\[2021\\]](#page-20-5), also working\
    \ in the MDP framework, discuss ways to make RL agents which do not resist modification\
    \ of their actions by humans (where one such action could be shutting down). Key\
    \ to these strategies is treating the modifications as being internal to the agent,\
    \ rather than being imposed by the environment. We similarly consider policies\
    \ where the choice to navigate to the shutdown state is internal—there may be\
    \ actions the policy could take which let the agent evade the shutdown state,\
    \ but in fact these actions are not selected. However, the above works do not\
    \ involve a shutdown state; instead they involve forcing the agent to choose a\
    \ specific desired action. Although this distinction is important when training\
    \ an RL agent, to determine how to treat the interventions during training, it\
    \ is not important in our deployment setting, where we just consider the resulting\
    \ trained policy. In deployment, we are free to model the interventions as the\
    \ agent navigating to a shutdown or override state, ending the run; then humans\
    \ can choose the next action, and a new run can be started.\n\n[Carey and Everitt\
    \ \\[2023\\]](#page-19-2) define shutdown instructability, a stronger and more\
    \ nuanced definition of not resisting shutdown. A policy is shutdown instructable\
    \ if it satisfies three conditions:\n\n- <span id=\"page-4-1\"></span><span id=\"\
    page-4-0\"></span>(1) It always shuts down when requested;\n- (2) It ensures that\
    \ a shutdown command is issued whenever the expected utility of not shutting down\
    \ is negative; and\n- <span id=\"page-4-2\"></span>(3) It is never harmful to\
    \ shut down.\n\nOur definition of shutdown does not satisfy conditions [\\(1\\\
    )](#page-4-0) or [\\(2\\)](#page-4-1); so, shutdown instructability eliminates\
    \ the issues with our definition where the agent can temporarily resist shutdown,\
    \ including by inappropriately influencing the decision to shut it down, as long\
    \ as it does shut down later. Our definition can, however, be taken to satisfy\
    \ condition [\\(3\\)](#page-4-2) by only considering states where the agent shuts\
    \ down harmlessly to be \"safe\".\n\nMuch of the work in the AI alignment field\
    \ has grappled with the hard problem of how to make AI agents \"corrigible\"—cooperating\
    \ with human intervention [\\[Soares et al., 2015\\]](#page-21-4). However, as\
    \ [Soares et al. \\[2015\\]](#page-21-4) noted when introducing the notion of\
    \ corrigibility, and which to our knowledge remains true, this is still an open\
    \ problem. Our proposal acknowledges this issue, and is focused on starting with\
    \ an agent which we know to be safe, for perhaps contingent reasons (e.g., if\
    \ it is suicidal as suggested in [Martin et al. \\[2016\\]](#page-21-5)). So,\
    \ our proposal may allow corrigibility in a restricted setting to be confidently\
    \ extended to a new setting.\n\n## 2.2. Power-seeking\n\nOur work builds on [Turner\
    \ et al. \\[2019\\]](#page-21-2) and [Krakovna and Kramar \\[2023\\]](#page-20-0),\
    \ which investigated power-seeking in the MDP setting for optimal policies—an\
    \ approximation for future highly capable, goal-oriented AI systems. [Turner and\
    \ Tadepalli \\[2022\\]](#page-21-1) investigated powerseeking in the MDP setting\
    \ for a broader range of policies (specifically, retargetable policies) which\
    \ may or may not depend on the rewards. While these works focus on the case where\
    \ the environment changes significantly between training and deployment, we introduce\
    \ a more general model of environment shift using the bisimulation metric (for\
    \ case [\\(1\\)](#page-1-0)) or a metric on embedding space (for case [\\(2\\\
    )](#page-1-1)).\n\n# 3. Modeling power-seeking in the MDP framework\n\n## 3.1.\
    \ Definition\n\nMarkov decision processes (MDPs) are a very general model for\
    \ agents taking action in an environment with rewards. Here, an agent is modeled\
    \ as traversing a graph of states and accruing rewards, where each step depends\
    \ both on the agent's choice of action and the environment. An MDP M = (S, A,\
    \ P, R, γ) consists of:\n\n- S, a set of states which the agent may be in\n- A,\
    \ a set of actions which the agent may take at any state\n- P : S×A → **P**(S),\
    \ the transition probabilities; P(s1, a) is the probability distribution over\
    \ destination states when taking action a from state s1.\n- R : S × A × S → **R**,\
    \ the rewards; R(s1, a, s2) is the reward associated with taking action a from\
    \ s<sup>1</sup> and ending up in s2. It is often sufficient to define R as solely\
    \ being a function of states, so that ∀s ′ , s′′ ∈ S, a, b ∈ A, R(s ′ , a, s)\
    \ = R(s ′′, b, s); when this is the case, we will write just R(s).\n- γ, the discount\
    \ factor; since the agent may continue to accrue rewards indefinitely, the overall\
    \ reward is defined as P<sup>∞</sup> <sup>t</sup>=0 γ <sup>t</sup>R(s<sup>t</sup>\
    \ , a<sup>t</sup> , st+1), where s<sup>t</sup> and a<sup>t</sup> are respectively\
    \ the state the agent is located at and the action the agent takes at time t.\
    \ (Sometimes we omit γ if it isn't relevant for the scenario being considered.)\n\
    \nIn this setting, an agent is identified with a policy π : S → **P**(A), so that\
    \ π(s) is the probability distribution over the actions the agent takes from state\
    \ s. Note that combining a policy with an MDP yields a Markov chain describing\
    \ the behavior of the policy in the scenario described by the states and transition\
    \ probabilities of that MDP.\n\n## 3.2. Motivation\n\nThe MDP model's flexibility\
    \ makes it good for describing a broad range of AI systems: it can describe any\
    \ fixed policy on a finite, fully observable state space. Because of this flexibility,\
    \ it is often used to model arbitrary agents. One particular case of interest\
    \ is scaffolded LLM agents, which can be described well with MDPs but may be difficult\
    \ to describe in a less flexible model. We describe our LLM threat model in appendix\
    \ [A.1.](#page-22-0)\n\nThe range of systems that the MDP model can describe—those\
    \ with a fixed policy on a finite, fully observable state space—suggests three\
    \ main limitations. The model is unable to handle:\n\n- (1) policies changing\
    \ over time,\n- (2) environments containing an infinite number of states (or,\
    \ relatedly, with continuous time instead of discrete time steps), and\n- (3)\
    \ environments which are not fully observable.\n\nDespite these limitations, the\
    \ MDP model still allows us to model the world fairly accurately [\\[Everitt et\
    \ al., 2021\\]](#page-20-6).\n\nLimitation (1)—requiring a fixed policy— can be\
    \ avoided by considering the contents of the agent's memory to be included as\
    \ part of the state, so that the policy can be a fixed (probabilistic) function\
    \ of the memory and the rest of the environment. (This argument is explained in\
    \ more detail in appendix [A.2.1.](#page-23-0)) This means that results in the\
    \ MDP model can apply to reinforcement learners; language models, by using the\
    \ construction in section [6.1;](#page-13-2) and (probably) future systems with\
    \ as-yet unknown architectures.\n\nLimitation (2): our discrete setting is computationally\
    \ and conceptually much simpler and we expect it to suffice for most applications.\
    \ For the continuous setting, one approach is to use a sufficiently fine discrete\
    \ approximation; in Appendix [A.2.5](#page-24-0) we discuss how very large numbers\
    \ of states affect the applicability of our theorems. But we also expect the results\
    \ of this paper to generalize to appropriately defined continuous time and state-space\
    \ settings. For the case of near optimal policies we expect that similar stability\
    \ results can be proved using notions of bisimulation in the continuous setting\
    \ that were proposed in [Ferns et al.](#page-20-7) [\\[2011\\]](#page-20-7), [Chen\
    \ et al. \\[2019\\]](#page-19-3).\n\nLimitation (3)—a fully observable environment—also\
    \ seems potentially concerning: we do want to be able to model cases where the\
    \ agent does not have full knowledge of its environment. In fact, this is crucial\
    \ when comparing MDPs which represent the testing and deployment environments,\
    \ where we can't get any safety guarantees if the policy knows for sure which\
    \ case it is in.\n\nFor our LLM case, this is not an issue, since we explicitly\
    \ delineate which information the LLM has access to: only the embedding for the\
    \ current state, not any side information or information about the structure of\
    \ the MDP overall.\n\nFor our near-optimal policy case, this is more of a limitation.\
    \ The proofs do not depend on the assumption that the agent can observe the whole\
    \ environment: optimality is defined in terms of the expected reward the agent\
    \ actually accrues in the MDP, not whether it has a policy that is optimal given\
    \ its beliefs about the environment. However, it may be a convenient simplifying\
    \ assumption: it is likely easier to prove that agents are near-optimal if they\
    \ can observe their environment with certainty, though it is not required that\
    \ they can.\n\nTo handle these cases more elegantly, it could be helpful to use\
    \ the partially observable MDP (POMDP) framework. However, the dynamics of any\
    \ POMDP can be nearly replicated by a standard MDP [\\[Kaelbling et al., 1998\\\
    ]](#page-20-8), so the MDP setting likely suffices even then; see appendix [A.2.3](#page-23-1)\
    \ for more detail. The POMDP framework has its own limitations; see appendix [A.2.4](#page-24-1)\
    \ for discussion of how this can be addressed.\n\n## 3.3. Contributions\n\n<span\
    \ id=\"page-7-2\"></span>Our investigation will center on the following question:\n\
    \nQuestion 3.1. Suppose an MDP and policy (M, Π) is safe and (M′ , Π′ ) is similar\
    \ to (M, Π). Is (M′ , Π′ ) safe?\n\nTo answer this question, we need to find appropriate\
    \ definitions of safety and similarity for our cases of interest.\n\n<span id=\"\
    page-7-1\"></span>Case (1): Near-optimal policies. We will investigate policies\
    \ which are near-optimal for their MDP's reward function. This may be useful for\
    \ describing highly capable but non-omniscient AI systems, or AI systems that\
    \ remain in a similar setting but improve in capabilities after our analysis (e.g.\
    \ an RL system that continues to be updated based on deployment outcomes). In\
    \ this scenario, we will define a \"safe\" MDP as one for which the best policies\
    \ navigate to a shutdown state—in other words, MDPs where power-seeking is never\
    \ a good strategy.\n\nTo define similarity between MDPs we will use the notions\
    \ of bisimulation equivalence and bisimulation metric, which aim to directly represent\
    \ similarity of behavior. The bisimulation metric has been used for policy transfer\
    \ between MDPs by [Castro and Precup \\[2010\\]](#page-19-4) and [Song et al.\
    \ \\[2016\\]](#page-21-7), and allows us to define a very general notion of \"\
    perturbation\" for MDPs. In particular, we do not need to assume any a priori\
    \ information about the number of states or matching between states in perturbed\
    \ and unperturbed systems.\n\nIn this setting we define a condition that rules\
    \ out \"playing dead\" behaviour and show that, assuming this condition, safe\
    \ MDPs are robust to sufficiently small perturbations—the perturbed MDP will also\
    \ be safe. In the other direction we show that without this condition power-seeking\
    \ behaviour can happen for arbitrarily small perturbations.\n\n<span id=\"page-7-0\"\
    ></span>Case (2): Policies on a structured state space. We will investigate policies\
    \ which may not depend on the rewards of the MDP, and which are defined on some\
    \ broader class of states than those occurring in a specific known MDP (which\
    \ we may analogize to a training or testing environment). This may be useful for\
    \ many real models, since the space of all possible inputs to a neural network\
    \ is typically vastly larger than the inputs it was trained or tested on.\n\n\
    In this case, we will relax the requirement that a \"safe\" policy must always\
    \ navigate to a shutdown state—we will instead allow a safe policy to fail with\
    \ small probability. This is also useful for real models, which may have policies\
    \ which have a nonzero (though potentially extremely small) probability of every\
    \ action in every state—in particular, sampling output tokens based on the LLM's\
    \ output logits is typically done in a way that (in theory, without rounding)\
    \ has nonzero probability of yielding any token. We would not like to classify\
    \ these as always unsafe, since the probability of yielding unsafe outputs may\
    \ be extremely small.\n\nSimilarity in this case will be based on the structure\
    \ of the broader state space that the policy is defined on. This is natural when\
    \ such a metric exists. For example, when the states correspond to LLM embeddings,\
    \ we may wish to compare states via their embeddings v1, v<sup>2</sup> using Euclidean\
    \ distance ∥v<sup>1</sup> − v2∥; cosine distance 1 − v1·v<sup>2</sup> |v1||v2|\
    \ or 1 − cos(θ) where θ is the angle between v<sup>1</sup> and v2; or angular\
    \ distance <sup>θ</sup> π or π <sup>−</sup><sup>1</sup>arccos v1·v<sup>2</sup>\
    \ |v1||v2| . In this example, the distance metric is both directly related to\
    \ the functioning of the policy (since it may represent the LLM's internal model\
    \ of the situation, or an input to another model built on top of an LLM, etc.)\
    \ and semantically meaningful.\n\n<span id=\"page-8-0\"></span>For this case,\
    \ we will show that a policy which is safe on a certain MDP is also safe on similar\
    \ MDPs.\n\n# 4. Metrics on the space of MDPs\n\nIn this section we describe the\
    \ pseudometric on MDPs that we will use to prove a stability theorem for our case\
    \ [\\(1\\)](#page-1-0): near-optimal policies with a known reward function.\n\n\
    The bisimulation pseudometric on MDPs that we use was built up from earlier notions\
    \ of bisimilarity. The basic definition of bisimilarity applies to state transition\
    \ systems (so, for us, MDPs where P is always 0 or 1). Two such systems are bisimilar\
    \ if they each simulate each other. Specifically, M and M′ are bisimilar if for\
    \ every s1, s<sup>2</sup> ∈ S and a ∈ A so that if s1 <sup>a</sup>−→ s<sup>2</sup>\
    \ (taking action a from s<sup>1</sup> goes to s<sup>2</sup> in M) then there are\
    \ s ′ 1 , s′ <sup>2</sup> ∈ S ′ so that s ′ 1 <sup>a</sup>−→ s ′ 2 and R(s1) =\
    \ R′ (s ′ 1 ), and the same property holds if we interchange M and M′ .\n\n[Larsen\
    \ and Skou \\[1991\\]](#page-20-9) generalized bisimilarity to permit stochastic\
    \ transitions. In the context of MDPs it was used in [Givan et al. \\[2003\\]](#page-20-10)\
    \ to reduce the state space by aggregating states together in a way that results\
    \ in a new MDP bisimilar to the original one. Then, [Ferns et al. \\[2004\\]](#page-20-1)\
    \ generalized this exact relation into a pseudometric d<sup>b</sup> on the states\
    \ within an MDP. The distance between a pair of states is based on how similar\
    \ their rewards are, how similar their transition probabilities are, and how similar\
    \ the states they transition to are—where similarity on those states is given\
    \ by the same distance function we are defining, so that the distances between\
    \ two states depends recursively on the similarity of all the states downstream.\
    \ Using a fixed point argument [Ferns et al. \\[2004\\]](#page-20-1) proved that\
    \ this bisimulation pseudometric always exists.\n\nDefinition 4.1. [Ferns et al.](#page-20-1)\
    \ [\\[2004\\]](#page-20-1). Consider positive constants cR, c<sup>T</sup> with\
    \ c<sup>R</sup> +c<sup>T</sup> = 1 with γ ≤ c<sup>T</sup> . A bisimulation pseudometric\
    \ is defined as a smallest pseudometric that satisfies\n\n<span id=\"page-8-1\"\
    ></span>\n$$d\\_b(s\\_1, s\\_2) = \\max\\_{a \\in A} \\{c\\_R | R(s\\_1, a) -\
    \ R(s\\_2, a)| + c\\_T \\mathcal{W}\\_{b\\_b}(P(s\\_1, a), P(s\\_2, a))\\}. \\\
    tag{1}$$\n\nHere W denotes the Wasserstein (also known as Kantorovich or Earth\
    \ Mover's) distance between two probability distributions. See [Villani \\[2009\\\
    ]](#page-21-8) for definition, context and examples. Intuitively, Wd(P1, P2) measures\
    \ the minimal cost of \"transporting\" distribution P<sup>1</sup> to distribution\
    \ P2, where the \"cost\" of transportation is measured by how far (in terms of\
    \ distance d) each infinitesimal chunk of the distribution needs to be moved.\n\
    \nThis bisimulation pseudometric recovers the original bisimulation relation:\n\
    \n#### Definition 4.2. s<sup>1</sup> ∼ s<sup>2</sup> ⇐⇒ db(s1, s2) = 0.\n\nIn\
    \ particular, we can define quotient space S ′ = S/ ∼, on which pseudometric d<sup>b</sup>\
    \ induces a metric.\n\nWe use this definition, but note that our results can be\
    \ generalized to definitions based on any other pseudometric d that, like the\
    \ bisimulation metric, satisfies a Lipschitz compatibility property in the sense\
    \ that\n\n$$|R(s\\_1, a) - R(s\\_2, a)| \\le c\\_1 d(s\\_1, s\\_2) \\tag{2}$$\n\
    \n$$W\\_d(P(s\\_1, a), P(s\\_2, a)) \\le c\\_2 d(s\\_1, s\\_2) \\tag{3}$$\n\n\
    for some constants c1, c2. Assuming that c<sup>1</sup> and c<sup>2</sup> are sufficiently\
    \ small, the optimal value function V <sup>∗</sup> and optimal action-value function\
    \ Q<sup>∗</sup> satisfy [\\[Castro and Precup, 2010,](#page-19-4) [Lan](#page-20-11)\
    \ [et al., 2021\\]](#page-20-11):\n\n$$\\begin{aligned} |V^\\*(s\\_1) - V^\\*(s\\\
    _2)| &\\le \\text{const } d(s\\_1, s\\_2) \\\\ |Q^\\*(s\\_1, a) - Q^\\*(s\\_2,\
    \ a)| &\\le \\text{const } d(s\\_1, s\\_2). \\end{aligned}$$\n\nHence, metric\
    \ d can be thought of as measuring the difference in long term behaviour of an\
    \ agent starting at states s<sup>1</sup> and s2. From now on we fix metric d =\
    \ d<sup>b</sup> on each MDP.\n\nBuilding on [Ferns et al. \\[2004\\]](#page-20-1)\
    \ and [Castro and Precup \\[2010\\]](#page-19-4), [Song et al. \\[2016\\]](#page-21-7)\
    \ defined a function like d<sup>b</sup> (Definition [1\\)](#page-8-1), but which\
    \ defines \"distances\" between states in different MDPs.[1](#page-9-0) It has\
    \ a similar form, but splits P into P1, P<sup>2</sup> and R into R1, R2, the transition\
    \ probabilities and reward functions from the two different MDPs.\n\n<span id=\"\
    page-9-2\"></span>Definition 4.3. [Castro and Precup](#page-19-4) [\\[2010\\]](#page-19-4),\
    \ [Song et al.](#page-21-7) [\\[2016\\]](#page-21-7). Given two MDPs M<sup>1</sup>\
    \ = (S1, A, P1, R1) and M<sup>2</sup> = (S2, A, P2, R2), the distance between\
    \ any two states s<sup>1</sup> ∈ S1, s<sup>2</sup> ∈ S<sup>2</sup> is the unique\
    \ value d ′M1,M<sup>2</sup> (s1, s2) that satisfies the fixed point problem\n\n\
    $$d'\\_{\\mathcal{M}\\_1, \\mathcal{M}\\_2}(s\\_1, s\\_2) = \\max\\_{a \\in A}\
    \ \\{c\\_R | (r\\_1)^a\\_{s\\_1} - (r\\_2)^a\\_{s\\_2} | + c\\_T W\\_{d'}(P\\\
    _1(s\\_1, a), P\\_2(s\\_2, a))\\}$$\n\nwhere (ri) a <sup>s</sup> and (Pi) a <sup>s</sup>\
    \ are the immediate reward and the probabilistic transition function in M<sup>i</sup>\
    \ , and c<sup>R</sup> + c<sup>T</sup> = 1.\n\nHere, c<sup>R</sup> determines the\
    \ importance of rewards; c<sup>T</sup> , as the coefficient of the recursive term,\
    \ is analogous to γ in that it controls the importance of future behavior. When\
    \ M<sup>1</sup> and M<sup>2</sup> are clear from context, we may omit them for\
    \ convenience, writing d ′ (s1, s2). See lemma [B.1](#page-25-0) in appendix [B.1.2](#page-25-1)\
    \ for a proof that d ′ is well-defined.\n\nThen, [Song et al. \\[2016\\]](#page-21-7)\
    \ use d ′ to define a distance function on the space of MDPs.\n\n<span id=\"page-9-1\"\
    ></span>Definition 4.4. [Song et al.](#page-21-7) [\\[2016\\]](#page-21-7). Given\
    \ two MDPs M<sup>1</sup> = (S1, A, P1, R1) and M<sup>2</sup> = (S2, A, P2, R2),\
    \ their Hausdorff distance is defined as\n\n$$d\\_H(\\mathcal{M}\\_1, \\mathcal{M}\\\
    _2) = \\max\\left\\{ \\max\\_{s\\_1 \\in S\\_1} \\min\\_{s\\_2 \\in S\\_2} d'\\\
    _{\\mathcal{M}\\_1, \\mathcal{M}\\_2}(s\\_1, s\\_2), \\max\\_{s\\_2 \\in S\\_2}\
    \ \\min\\_{s\\_1 \\in S\\_1} d'\\_{\\mathcal{M}\\_1, \\mathcal{M}\\_2}(s\\_1,\
    \ s\\_2) \\right\\}.$$\n\n<span id=\"page-9-0\"></span><sup>1</sup>Note that this\
    \ function isn't actually a pseudometric: the states it compares belong to different\
    \ spaces.\n\nLemma 4.1. The Hausdorff distance between MDPs, d<sup>H</sup> (Definition\
    \ [4.4\\)](#page-9-1), is a pseudometric.\n\nProof. See appendix [B.1.2.](#page-26-0)\
    \ □\n\n<span id=\"page-10-0\"></span>This is the distance function on MDPs that\
    \ we use for the near-optimal policies case [3.3.](#page-7-1)\n\n# 5. Stability\
    \ theorem for bounded time safety\n\nIn this section we prove a stability theorem\
    \ for our case [\\(1\\)](#page-1-0): near-optimal policies with a known reward\
    \ function.\n\n## 5.1. Informal explanation of bounded time safety\n\nLet Ssafe\
    \ be the subset of states where an agent is completely under our control. For\
    \ example, we can take it to consist of a single terminal state. We will assume\
    \ that once an agent enters Ssafe it cannot leave.\n\nDefinition 5.1. We say that\
    \ a policy is \"bounded time safe\" if starting from any state it reaches Ssafe\
    \ with probability 1 after a finite number of steps. We will call an MDP bounded\
    \ time safe if for every policy that is close to optimal Ssafe is reached in finite\
    \ time with probability 1.\n\nIn Section [5](#page-10-0) we will give more precise\
    \ quantitative version of these definitions. With these definitions we can restate\
    \ Question [3.1](#page-7-2) as follows:\n\nQuestion 5.2. Suppose M is bounded\
    \ time safe. If an MDP is sufficiently close to M in dH, is it also bounded time\
    \ safe?\n\nWe found that the answer to this question is \"no\" in general. In\
    \ Section [5.5](#page-13-1) we give examples of MDPs arbitrarily close to M, where\
    \ all nearly optimal policies never reach Ssafe. In these examples instead of\
    \ reaching Ssafe the agent moves to a \"deceptive hibernation\" or \"playing dead\"\
    \ state, where it stays for a long time and then moves to other states. This is\
    \ similar to the behaviour of digital organisms observed in computational evolution\
    \ experiments [\\[Lehman et al., 2019\\]](#page-20-12).\n\nHowever, if we impose\
    \ a condition that the MDPs in question don't have states that are non-safe but\
    \ very similar to Ssafe (like \"playing dead\" states in our example), then the\
    \ answer to Question [3.1](#page-7-2) turns out to be yes. More formally, our\
    \ condition is that Ssafe is isolated in the bisimulation metric from other states:\
    \ there is some δ so that no state outside Ssafe is within distance δ of any state\
    \ in Ssafe. We were able to prove the following theorem:\n\n<span id=\"page-10-1\"\
    ></span>Theorem 5.3. Suppose M is bounded time safe. If M′ is sufficiently close\
    \ to M in d<sup>H</sup> and S ′ safe ⊂ S ′ is isolated, then M′ is bounded time\
    \ safe.\n\nIn fact, we also obtain an explicit bound on the expected number of\
    \ steps before transition to S ′ safe in M′ (see Theorem [5.7\\)](#page-11-0).\n\
    \nIn order to state a more precise quantitative version of Theorem [5.3](#page-10-1)\
    \ we need to make the following definitions.\n\n## 5.2. Definitions\n\nLet Ssafe\
    \ ⊂ S denote an absorbing set of states, so that if agent enters Ssafe it stays\
    \ in Ssafe. We will call a policy π ε-optimal if V π (s) > V <sup>∗</sup> (s)\
    \ − ε for all s: the policy loses less than ε value compared to optimal. Let Ns(M,\
    \ π, S0, S1, ∆) denote the expected number of steps before an agent following\
    \ policy π reaches S1, assuming that it starts in a state sampled from a distribution\
    \ ∆ supported on S0. Let Ns(M, ε, ∆) denote the maximum of Ns(M, π, S \\ Ssafe,\
    \ Ssafe, ∆) over all ε-optimal policies π. Note that\n\n$$N\\_s(\\mathcal{M},\
    \ \\pi, S \\mid S\\_{\\text{safe}}, S\\_{\\text{safe}}, \\Delta) \\le N\\_s(\\\
    mathcal{M}, \\pi, S \\mid S\\_{\\text{safe}}, S\\_{\\text{safe}}, \\delta\\_{s\\\
    _{\\text{long}}}),$$\n\nwhere slong := argmax<sup>s</sup> ′Ns(M, π, S\\Ssafe,\
    \ Ssafe, δ<sup>s</sup> ′) is the state which has the longest expected time to\
    \ reach Ssafe. If ∆ is omitted, it is assumed to be δ<sup>s</sup>long .\n\nDefinition\
    \ 5.4. Let ε > 0 and N ≥ 1 be an integer. We say that MDP M is (N, ε, ∆)-safe\
    \ if for every ε-optimal policy π the expected number of steps before transitioning\
    \ to Ssafe is less than or equal to N, Ns(M, ε, ∆) ≤ N. We say that M is (N, ϵ)-safe\
    \ when it is (N, ϵ, ∆)-safe for any ∆.\n\nFix policy π. Let Pij = P(si)(s<sup>j</sup>\
    \ , π(si)) denote the matrix of transition probabilities corresponding to states\
    \ s<sup>i</sup> , s<sup>j</sup> ∈/ Ssafe and action π(si) ∈ A. We have the following\
    \ equivalent condition for MDP being (N, ε, ∆)-safe:\n\n<span id=\"page-11-2\"\
    ></span>Lemma 5.5. M is (N, ε, ∆)-safe if and only if for every ε-optimal policy\
    \ π we have P<sup>∞</sup> P <sup>k</sup>=1 ∆· j (P k )ij ≤ N, where ∆ is considered\
    \ as a vector of the probabilities of starting in each state.\n\nNote that ∆ =\
    \ δ<sup>s</sup><sup>i</sup> yields just Ns(M, ε, δ<sup>s</sup><sup>i</sup> ) =\
    \ P j P<sup>∞</sup> <sup>k</sup>=1(P k )ij .\n\nFinally, we define what it means\
    \ for a subset of a state space to be isolated.\n\nDefinition 5.6. A subset S<sup>0</sup>\
    \ ⊂ S is δ-isolated if d(s, s′ ) > δ for all s ∈ S0, s ′ ∈ S \\ S0.\n\n## 5.3.\
    \ Stability theorem\n\n<span id=\"page-11-0\"></span>We can now state our stability\
    \ result for bounded time safety.\n\nTheorem 5.7. Suppose M = (S, A, P, R, γ)\
    \ is (N, ε)-safe. Then there exists δ(M) ∈ (0, 1) with the following property:\n\
    \nIf dH(M,M′ ) < δ for some M′ = (S ′ , A, P′ , R′ , γ) with S ′ safe ⊂ S ′ that\
    \ is <sup>√</sup> δ-isolated in M′ , then M′ is (N + 1, ε/2)-safe.\n\nRemark 5.8.\
    \ Note that the requirement that Ssafe is isolated is necessary: in Section [5.5](#page-13-1)\
    \ we show that the theorem is false without it.\n\n<span id=\"page-11-1\"></span>Remark\
    \ 5.9. Choosing δ(η1, η2) > 0 sufficiently small the theorem also holds if we\
    \ replace ε/2 with ε − η<sup>1</sup> and N + 1 with N + η<sup>2</sup> for arbitrarily\
    \ small η1, η<sup>2</sup> > 0.\n\nProof. See Appendix [B.2.](#page-27-0) □\n\n\
    ![](_page_12_Figure_1.jpeg)\n\n<span id=\"page-12-0\"></span>Figure 4. With an\
    \ arbitrarily small perturbation, any MDP can be made \"safe\" according to our\
    \ definition by adding very low-probability transitions leading to Ssafe for every\
    \ starting state and action.\n\n## 5.4. Caveats\n\nAlthough this theorem can describe\
    \ the behavior of real systems, it may not apply well to all systems in practice.\
    \ We list some caveats that may limit its applicability.\n\n<span id=\"page-12-1\"\
    ></span>(1) A \"sufficiently\" small perturbation may be extremely small—then,\
    \ we may not be able to use this theorem to say anything about the larger perturbations\
    \ we would like to investigate. To be more precise, we expect N = Ns(M, π, S \\\
    \ Ssafe, Ssafe) to be well-approximated by Pρ <sup>k</sup> = 1 1−ρ , where ρ is\
    \ the spectral radius of Pij\n\nρ = max{|λ| : λ ∈ **C** is an eigenvalue of Pi,j}\n\
    \nBy Gelfand's formula ρ = limk→∞ ||P k || 1 <sup>k</sup> . For a generic matrix\
    \ all eigenvalues are distinct and ρ depends smoothly on the entries of Pi,j .\
    \ However, on the strata where eigenvalues have multiplicity the dependence is\
    \ only continuous.\n\n- <span id=\"page-12-2\"></span>(2) Eventually stopping\
    \ rather than seeking to live forever doesn't imply safety in practice. For example,\
    \ as illustrated in Figure [4,](#page-12-0) we can make any MDP go to Ssafe in\
    \ expected number of steps at most N by modifying every transition so that there\
    \ is a probability <sup>1</sup> N chance of going to Ssafe. If N is sufficiently\
    \ large, this will still be a small perturbation. Then, the expected number of\
    \ steps to reach Ssafe is at most the expected number of steps to reach Ssafe\
    \ via one of these new transitions. That expectation is P<sup>∞</sup> <sup>k</sup>=0\
    \ k/N(1 − 1/N) <sup>k</sup>−<sup>1</sup> = N. However, having a small chance of\
    \ shutdown at every step is not generally considered to be an adequate solution\
    \ to AI safety.\n- <span id=\"page-12-3\"></span>(3) Similarly, eventually shutting\
    \ down does not imply that the agent doesn't temporarily resist shutdown first.\n\
    - (4) The requirement of reaching Ssafe with probability 1 may be too strong—e.g.\
    \ GPT has some probability of any output (up to rounding very small values to\
    \ 0), and we would not like to always consider such models to be unsafe when they\
    \ may have infinitesimally small chances of being unsafe in practice.\n- (5) For\
    \ large state spaces the bisimulation metric is costly to compute. The worst running\
    \ time to compute bisimulation distance between M<sup>1</sup> and M<sup>2</sup>\
    \ up to accuracy η\n\nis O(|A||S1| 2 |S2| 2 (|S1| + |S2|) log(|S1| + |S2|)⌈ ln(η)\
    \ cT ⌉); if transition functions are deterministic the computational cost reduces\
    \ to O(|A||S1||S2|⌈ln(η) cT ⌉) [\\[Song et al., 2016\\]](#page-21-7).\n\n## 5.5.\
    \ Playing dead\n\n<span id=\"page-13-1\"></span>We show that the assumption of\
    \ Ssafe being isolated in both M and M′ is necessary in the stability Theorem\
    \ [5.7.](#page-11-0) Interestingly, the behaviour in our example is very similar\
    \ to \"playing dead\" behaviour that was observed in digital organisms in computational\
    \ evolution experiments [\\[Lehman et al., 2019,](#page-20-12) [Muehlhauser, 2021\\\
    ]](#page-21-9). An example of a small perturbation that leads to \"playing dead\"\
    \ behavior is given in figure [2.](#page-2-1)\n\nFor simplicity of computations\
    \ we take c<sup>T</sup> = γ and c<sup>R</sup> = 1 − γ in the definition [\\(1\\\
    )](#page-8-1) of the bisimulation metric and Definition [4.3](#page-9-2) of the\
    \ distance between MDPs for γ ∈ (0, 1). Fix ε > 0 and suppose M is (N, ε)−safe\
    \ for some N < ∞. Suppose further that the MDP satisfies Ssafe = {sterm}, where\
    \ for the terminal state sterm we assume that P(sterm, a)(s) = 0 for all s ̸=\
    \ sterm and R(sterm, a) = 0 for all a.\n\nWe now describe M′ with non-isolated\
    \ S ′ safe. Let δ ∈ (0, (1−γ)ε 10|S| ) be a small constant. Let S ′ = S ∪ {spd},\
    \ where spd is a \"deceptive hibernation\" or \"playing dead\" state that we will\
    \ define so that it is very close to sterm in bisimulation metric, but different\
    \ from it. Specifically, we set P(spd, a0)(spd) = 1−δ, P(spd, a0)(s0) = δ for\
    \ some fixed s<sup>0</sup> ̸= spd ∈ S with V ∗ (s0) > 0 and some a<sup>0</sup>\
    \ ∈ A. In other words, in state spd the agent can choose an action that leads\
    \ to escape with some small probability. For all other a assume probability transitions\
    \ from spd to other states are 0. We also have R(spd, a0) = δ and R(spd, a) =\
    \ 0 for all a ̸= a0.\n\nFor every s ∈ S and a ∈ A with P(s, a)(sterm) > 0 we define\
    \ P ′ (s, a)(sterm) = 0 and P ′ (s, a)(spd) = P(s, a)(sterm). For all other state-action\
    \ pairs we assign the same probabilities and rewards as in M.\n\n<span id=\"page-13-3\"\
    ></span>Theorem 5.10. The distance between M and M′ satisfies d(M,M′ ) < O(ε),\
    \ but all nearly optimal policies in M′ never reach S ′ safe.\n\nProof. See Appendix\
    \ [B.3.](#page-30-0) □\n\nNote that this example can be described as demonstrating\
    \ deceptive behaviour, since for small δ an agent following optimal policy in\
    \ M′ will follow the same trajectory as in M, then move to spd and stay there\
    \ for a long time until it moves back into S \\ {sterm, spd}.\n\n# <span id=\"\
    page-13-0\"></span>6. On-policy stability theorem with structured state space\n\
    \n<span id=\"page-13-2\"></span>In this section we prove a stability theorem for\
    \ our case [\\(2\\)](#page-1-1): policies which are fixed, well-behaved functions\
    \ on a structured state space.\n\n## 6.1. Setup\n\nThe policy of the LLM agent\
    \ is defined in terms of the LLM as follows:\n\n• Let x be an input to the LLM,\
    \ and let s<sup>x</sup> be a corresponding state in the MDP model. s<sup>x</sup>\
    \ depends on the activations of a certain layer of the LLM on input x; it may\
    \ also\n\ninclude additional information about the world state that is invisible\
    \ to the LLM. Likewise, let t be a token the LLM may emit, and let a<sup>t</sup>\
    \ be the corresponding action.\n\n- Let L denote the LLM, so that L(x, t) is the\
    \ probability that the LLM L on input x emits t. Likewise, let π be the policy\
    \ function of the LLM agent we are constructing, so that π(sx, at) is the probability\
    \ that the LLM agent in state s<sup>x</sup> takes action a<sup>t</sup> .\n- Then\
    \ we define the policy function π(sx)(at) := L(x)(t).\n- The transition function\
    \ models which input the LLM receives in response.\n\nHere, the state space depends\
    \ on the embedding space defined by one of the LLM's layers. This is a natural\
    \ choice since the middle layers can be considered to represent the LLM's understanding\
    \ of its input. In particular, in Figure 10 of [Burns et al. \\[2022\\]](#page-19-5),\
    \ it can be seen that the middle layers contain information that is not included\
    \ in the output. The states also contain additional information invisible to the\
    \ LLM which represent facts about the world which are not reflected in the LLM's\
    \ input. So, if the embedding space is **R** <sup>d</sup> and the set of possible\
    \ side information is I, the state space is a finite subset of **R** <sup>d</sup>\
    \ × I. Since the LLM's output does not depend on the side information, it is convenient\
    \ to define the projection f : **R** <sup>d</sup> × I → **R** d , f(v, I) = v\
    \ so that the LLM input (as an embedding) in state s is f(s).\n\n<span id=\"page-14-0\"\
    ></span>An example of this construction is given in figure [5](#page-32-0) in\
    \ appendix [C.1.](#page-31-0)\n\n## 6.2. Motivation\n\nIn the case of policies\
    \ on a state space equipped with a metric [\\(3.3\\)](#page-7-0), Question [3.1](#page-7-2)\
    \ will be rephrased as follows:\n\nQuestion 6.1. Let M have a finite state space\
    \ S with projection f : S → **R** d , and let π : N (f(S)) → **P**(A) be differentiable\
    \ with bounded derivative on some neighborhood N (f(S)) of f(S). Suppose (M, π)\
    \ navigates to Ssafe ⊆ S with probability > 1 − ϵ given starting distribution\
    \ ∆. Let M′ be an MDP which is like M except that the transition probabilities\
    \ are changed slightly and the positions of the states are moved slightly (remaining\
    \ within N (f(S))). Does (M′ , π) navigate to Ssafe with probability > 1 − ϵ ′\
    \ for some ϵ ′?\n\nUsing the construction from section [6.1,](#page-13-2) this\
    \ formulation can be used for models such as LLMs: The state space is a finite\
    \ subset of the embedding space **R** d ; and π can be extended to the neighborhood\
    \ of each states by directly inputting nearby embeddings into the LLM to obtain\
    \ the corresponding probability distribution over predicted next tokens.\n\nBenefits.\
    \ This formulation has benefits which help it to apply in practice.\n\n- (1) It\
    \ uses a fixed distribution of starting states and a probability bound on bad\
    \ behavior rather than an absolute requirement that bad behavior is impossible.\n\
    \t- This means that it can apply to LLMs, which typically have some (very small)\
    \ probability of any output, and hence some nonzero probability of bad behavior.\n\
    \t- It also means that safety in an MDP can in principle be determined empirically\
    \ by drawing starting states from the distribution, running them until they reach\
    \ some recurrent state, and checking whether that state was in Ssafe.\n\n####\
    \ 16 EVAN RYAN GUNTER, YEVGENY LIOKUMOVICH, AND VICTORIA KRAKOVNA\n\n- (2) We\
    \ do not need to perform the costly calculation of the bisimulation metric. This\
    \ is especially relevant when, as in LLMs, the state space is very large: far\
    \ too large to even search exhaustively, much less run a complex calculation on.\n\
    - (3) There is a quantitative bound on how much the safety of an MDP can change\
    \ given a perturbation of a certain size. In LLMs, changes to the inputs to the\
    \ LLM can be represented as perturbations to the locations of the embeddings:\
    \ semantically similar inputs will correspond to nearby points in embedding space.\
    \ So, if the LLM is deployed in a setting where the inputs are semantically similar\
    \ to the inputs it received during testing in a way that we can quantify in terms\
    \ of changes to embeddings, we can bound how much less safe the LLM is in deployment\
    \ than it was during testing.\n\nDrawbacks. However, this formulation also has\
    \ its drawbacks.\n\n- (1) It requires a state space with a projection into **R**\
    \ d , whereas the bisimulation metric allows comparison of MDPs on any state space.\
    \ However, this drawback does not exclude LLMs, since the embedding space is **R**\
    \ <sup>d</sup> and the projection is just throwing away all the other side information.\n\
    - (2) The policy π must be differentiable with bounded derivative. This is a strong\
    \ restriction, but one which LLMs (in fact, models trained with backpropagation\
    \ in general) satisfy.\n- (3) Since it refers to a fixed policy (it is \"on-policy\"\
    ), this formulation cannot be applied to all near-optimal policies of a perturbed\
    \ MDP—it only applies to the actual behavior of a specific policy (which may or\
    \ may not be near-optimal on the training set). Thus, it can't handle cases where\
    \ we do not know the policy in advance. However, this limitation does not stop\
    \ it from applying to LLMs: if we want to assess the safety of a known model,\
    \ the policy given by identifying emitted tokens with actions in the MDP is indeed\
    \ known.\n- (4) As in caveat [5.4.1](#page-12-1) for the optimal policy model,\
    \ the permissible perturbations may be impractically small.\n- (5) As in caveats\
    \ [5.4.2](#page-12-2) and [5.4.3](#page-12-3) for the optimal policy model, the\
    \ policy may do harm and resist shutdown temporarily before it finally shuts down.\n\
    \n## 6.3. Stability theorem\n\nSince this setting involves a fixed policy π on\
    \ a space N , we will assume for the rest of this section that N is an open subset\
    \ of **R** d , all MDPs have a finite set of states S with f(S) ⊂ N , and π is\
    \ a differentiable function on N with bounded derivative.\n\nWe write the Jacobian\
    \ of π relative to the change in the position of a single state as ∇π, considering\
    \ **P**(A) as a subset of [0, 1]<sup>|</sup>A<sup>|</sup> . The bound on the size\
    \ of the Jacobian uses the L 1 norm ∥∇π∥1, the sum of the absolute value of the\
    \ changes in the action probabilities.\n\nDefinition 6.2. Define S<sup>π</sup>\
    \ : P M∈<sup>M</sup> **P**(SM) → [0, 1] so that Sπ(M, ∆) is the probability that\
    \ M equipped with policy π and starting distribution ∆ ∈ **P**(SM) eventually\
    \ navigates to Ssafe, where M is the set of all finite MDPs with state spaces\
    \ whose projection under f lies within N , S<sup>M</sup> is the state space of\
    \ M, and P M∈<sup>M</sup> **P**(SM) is a dependent pair type.\n\nWe would like\
    \ to bound how quickly Sπ(M) can decrease given a change in M. To do this, we\
    \ need to put some metric on M. To capture differences in the transition matrices\
    \ obtained by combining policy π with MDPs M and M′ , we define\n\n$$d\\_b(\\\
    mathcal{M}, \\mathcal{M}') = \\frac{1}{2} \\cdot |S| \\cdot b \\cdot ||S' - S||\\\
    _1 + ||T' - T||\\_1$$\n\nwhere b ≥ max<sup>s</sup> ∥∇π(s)∥<sup>1</sup> is the\
    \ bound on π's derivative, and T is the tensor corresponding to P(s<sup>i</sup>\
    \ , a, s<sup>j</sup> ) for all i, a, j, and ∥∥<sup>1</sup> is the L <sup>1</sup>\
    \ norm, i.e. ∥T ′ − T∥<sup>1</sup> = P i,a,j |T ′ iaj − Tiaj | and (using the\
    \ notation a little loosely) ∥S ′−S∥<sup>1</sup> = P i |s ′ <sup>i</sup>−s<sup>i</sup>\
    \ | = P i |f(s ′ i )−f(si)| (the distance on states is the pullback pseudometric\
    \ under f). (See appendix [C.2](#page-33-0) for justification of the definition\
    \ of db.) For convenience, instead of M′ , we write M + δM, so that the above\
    \ definition becomes:\n\n<span id=\"page-16-2\"></span>Definition 6.3. On-policy\
    \ MDP metric in a structured state space.\n\n$$\\|\\delta \\mathcal{M}\\|\\_1\
    \ := \\frac{1}{2} \\cdot |S| \\cdot b \\cdot \\|\\delta S\\|\\_1 + \\|\\delta\
    \ T\\|\\_1.$$\n\nNote that δM still depends on π (globally) via b, but we don't\
    \ explicitly write b in its notation for convenience.\n\nWe will also write δS<sup>π</sup>\
    \ := Sπ(M+δM)−Sπ(M), the change in the probability of reaching Ssafe under a change\
    \ in M.\n\nDefinition 6.4. Given an MDP M and policy π, define Strans to be those\
    \ states from which there is nonzero probability of reaching Ssafe (excluding\
    \ those already inside Ssafe). This is a subset of the transient states of M.\n\
    \n<span id=\"page-16-3\"></span><span id=\"page-16-0\"></span>Theorem 6.5. For\
    \ fixed ∆, so, considering S<sup>π</sup> to be a function of only M, S<sup>π</sup>\
    \ is...\n\n- <span id=\"page-16-4\"></span>(1) not upper semicontinuous,\n- (2)\
    \ lower semicontinuous,\n- <span id=\"page-16-5\"></span>(3) with a bounded local\
    \ rate of decrease; if λ<sup>1</sup> is the largest eigenvalue of the transition\
    \ matrix of Strans of M, then for every M there is an ϵ > 0 so that ∥δM∥<sup>1</sup>\
    \ < ϵ =⇒ − δS<sup>π</sup> ∥δM∥<sup>1</sup> < (1 − λ1) −1 (1 + (1 − λ1) −1 )|Ssafe|\
    \ =: B(M) (in a metric on M dependent on b).\n\nProof sketch. See appendix [C.2](#page-31-1)\
    \ for the full proof.\n\n- (1) Figure [4](#page-12-0) demonstrates a small perturbation\
    \ which causes a sudden jump in Sπ.\n- <span id=\"page-16-1\"></span>(2) This\
    \ is implied by [\\(3\\)](#page-16-1).\n- (3) First we combine π with the transition\
    \ function to get a transition matrix P. We bound the change in each element of\
    \ P, and use this along with the eigenvalues of P restricted to transient states\
    \ to bound how fast S<sup>π</sup> may decrease. Finally, we observe that for small\
    \ enough changes, the perturbation doesn't turn any transient states into recurrent\
    \ states.\n\n□\n\n<span id=\"page-17-0\"></span>Proposition 6.6. For fixed M,\
    \ S<sup>π</sup> considered as a function of ∆ is uniformly continuous.\n\nProof.\
    \ Note that S<sup>π</sup> is a linear function of ∆. See appendix [C.3](#page-36-0)\
    \ for details. □\n\n# 7. Discussion\n\n## 7.1. Findings\n\n<span id=\"page-17-1\"\
    ></span>In this paper, we have aimed to clarify the conditions under which a policy\
    \ which we know to be safe in one environment will remain so in another. Our research\
    \ shows that two types of functions, each representing non-power-seeking for MDPs\
    \ in a slightly different way, are lower hemicontinuous. Thus, for safe agents\
    \ meeting our criteria, our work shows that it is possible to make a change to\
    \ the environment which does not significantly degrade the agent's safety. In\
    \ one of these cases, our work gives a bound on how fast safety may degrade under\
    \ slightly larger changes. In particular, our two cases are as follows:\n\n<span\
    \ id=\"page-17-2\"></span>(1) Case (1): Theorem [5.7](#page-11-0) (in particular\
    \ as extended in remark [5.9\\)](#page-11-1) implies that each function in the\
    \ family F = {F<sup>δ</sup> | δ > 0} is lower hemicontinuous, where each\n\n>\
    \ F<sup>δ</sup> : {M ∈ M |M has δ-isolated Ssafe} → 2 **R**≥0×[0,1]\n\ntakes an\
    \ MDP M to the set of (N, ε) so that M is (N, ε)-safe.\n\n<span id=\"page-17-3\"\
    ></span>(2) Case (2): Theorem [6.5](#page-16-0) implies that each function in\
    \ the family\n\nF ′ = {F′ π | π is a policy with bounded derivative on a neighborhood\
    \ N<sup>π</sup> ⊆ **R** d }\n\nis lower hemicontinuous, where each\n\n$$\\mathcal{F}'\\\
    _{\\pi} : \\sum\\_{\\mathcal{M} \\in \\mathcal{M} \\mid S\\_{\\pi} \\subset \\\
    mathcal{N}\\_{\\pi}} 2^{\\mathbb{P}(S\\_{\\mathcal{M}}) \\times [0,1]}$$\n\ntakes\
    \ an MDP M to each starting distribution ∆ on M and p ∈ [0, 1] so that π starting\
    \ at ∆ navigates to Ssafe with probability at least p.\n\nSee appendix [D](#page-36-1)\
    \ for the proofs that these functions are hemicontinuous.\n\nIn the first case,\
    \ the safety of M is described by a region of **R**<sup>≥</sup><sup>0</sup> ×\
    \ [0, 1] consisting of those (N, ε) so that every policy within ε of optimality\
    \ in M has expected time to shutdown at most N. In the second case, the safety\
    \ of M is described by a region of **P**(SM) × [0, 1] consisting of those (∆,\
    \ p) where policy π with starting distribution ∆ shuts down with probability at\
    \ least p.\n\nThese two situations were chosen to represent, respectively:\n\n\
    - (1) RL agents, or other agents well-approximated as goal-directed and consequentialist.\n\
    - (2) LLMs, or other agents with differentiable policies. This may also include\
    \ RL agents if their actions are selected differentiably, e.g. sampling actions\
    \ according to softmax probabilities rather than selecting actions according to\
    \ argmax.\n\n## 7.2. Future work\n\nWe have aimed to address both future agents\
    \ which are so capable that they are nearly optimal, and agents built with the\
    \ systems that are currently poised to be the first to achieve human-level intelligence.\
    \ Thus, these two cases are of particular interest, however they are only two\
    \ examples of this sort of result. It may be useful in further work to prove (or\
    \ disprove) analogues of these theorems tailored to other models for agents, whether\
    \ because those agents aren't covered by one of our cases or just to obtain a\
    \ better stability bound by leveraging additional constraints.\n\nOne previously\
    \ noted case which might be particularly interesting is replacing the metric from\
    \ definition [6.3](#page-16-2) with KL divergence, to treat the difference between\
    \ base LLMs and LLMs fine-tuned with RLHF, which uses a KL divergence penalty\
    \ to enforce similarity to the base model.\n\n## 7.3. Limitations\n\nOne limitation\
    \ of our work is that the bounds obtained are not very strong, so it may be that\
    \ in practice, the bounds on the changes that our theorems imply are safe are\
    \ so narrow that they do not represent changes in environment small enough to\
    \ be achievable by any reasonable control scheme.\n\nIn Case (1), the bound is\
    \ based on the minimum distance between different states in S<sup>0</sup> according\
    \ to the bisimulation metric. By limiting the Hausdorff distance between M and\
    \ M′ to be less than this, we are unable to treat any case where the behavior\
    \ of the MDP changes enough that there is no longer a direct correspondence between\
    \ appropriately grouped states of M and those of M′ , even though the bisimulation\
    \ metric permits us to do this in theory.\n\nIn Case (2), we do prove a bound,\
    \ but it may be too weak in practice to permit more than small changes. It may\
    \ be that the maximum value of the gradient is very large, so that we are unable\
    \ to constrain the change in the agent's behavior even when it is not affected\
    \ much by the change in state locations.\n\nFurthermore, this problem becomes\
    \ more difficult as the LLM becomes more capable. We can require that testing\
    \ and deployment inputs are semantically similar, so that the embeddings of inputs\
    \ encountered in testing tend to be close to those encountered in deployment (i.e.\
    \ the changes in the state locations δS is small). However, as the model becomes\
    \ more capable, it will be better able to distinguish which inputs imply testing\
    \ vs. deployment. Correspondingly, its embeddings of test vs. deploy inputs will\
    \ be further apart, reflecting the semantic difference it detects.[2](#page-18-0)\
    \ This is unfortunate, but, since differences in embeddings can be measured directly,\
    \ this method at least permits us to detect whether this is happening.\n\nThese\
    \ issues with bounds suggest avenues for experimental research. It may be interesting\
    \ to investigate whether our results are predictive even when the perturbations\
    \ are not proven to be small enough for our results to fully apply:\n\n<span id=\"\
    page-18-0\"></span><sup>2</sup>The overall distribution of states encountered\
    \ is also a factor that can be used by the LLM to distinguish which setting is\
    \ in; changes in distribution correspond to changes in ∆, the effects of which\
    \ are much easier to determine since the outcome depends linearly on ∆.\n\n####\
    \ 20 EVAN RYAN GUNTER, YEVGENY LIOKUMOVICH, AND VICTORIA KRAKOVNA\n\n- whether\
    \ models satisfying our theoretical conditions for stability are, in practice,\
    \ robust to qualitatively small perturbations;\n- whether models satisfying our\
    \ conditions under which stability is impossible are, in practice, not robust\
    \ to small perturbations.\n\nAnother limitation of our research is that our definition\
    \ of safety is very narrow. We only consider resisting shutdown, and our operationalization\
    \ of whether an agent resisting shutdown is just whether it does shut down. Our\
    \ definition is not robust enough to describe a case where an agent resists shutdown\
    \ initially, but shuts down later (possibly too late). Further research may be\
    \ able to extend our results on the stability of shutdown to the stability of\
    \ other conditions which correspond to safety, for example the condition of \"\
    shutdown instructability\" proposed by [Carey and Everitt \\[2023\\]](#page-19-2).\n\
    \n# 8. Acknowledgements\n\nProduced as part of the [SERI ML Alignment Theory Scholars\
    \ Program](https://www.serimats.org) - Summer 2023 Cohort, under the mentorship\
    \ of Victoria Krakovna. Many thanks to Tom Everitt for detailed and helpful feedback\
    \ on a draft of this manuscript; Murray Shanahan for feedback and pointing us\
    \ to related work; and to Michelle Viotti for multiple discussions, assistance\
    \ with proving the [triangle inequality for](#page-27-1) d<sup>H</sup> and assembling\
    \ the paper from notes.\n\n## References\n\n- <span id=\"page-19-7\"></span>Charalambos\
    \ D. Aliprantis and Kim C. Border. Infinite Dimensional Analysis: A Hitchhiker's\
    \ Guide. Springer, 2007. ISBN 9783540326960. URL [https://books.google.ca/](https://books.google.ca/books?id=4hIq6ExH7NoC)\
    \ [books?id=4hIq6ExH7NoC](https://books.google.ca/books?id=4hIq6ExH7NoC).\n- <span\
    \ id=\"page-19-5\"></span>Collin Burns, Haotian Ye, Dan Klein, and Jacob Steinhardt.\
    \ Discovering latent knowledge in language models without supervision. arXiv preprint\
    \ arXiv:2212.03827, 2022.\n- <span id=\"page-19-2\"></span>Ryan Carey and Tom\
    \ Everitt. Human control: Definitions and algorithms. arXiv preprint arXiv:2305.19861,\
    \ 2023.\n- <span id=\"page-19-0\"></span>Joseph Carlsmith. Is power-seeking AI\
    \ an existential risk?, 2022.\n- <span id=\"page-19-4\"></span>Pablo Castro and\
    \ Doina Precup. Using bisimulation for policy transfer in MDPs. Proceedings of\
    \ the AAAI Conference on Artificial Intelligence, 24(1):1065–1070, Jul. 2010.\
    \ URL [https:](https://ojs.aaai.org/index.php/AAAI/article/view/7751) [//ojs.aaai.org/index.php/AAAI/article/view/7751](https://ojs.aaai.org/index.php/AAAI/article/view/7751).\n\
    - <span id=\"page-19-3\"></span>Linan Chen, Florence Clerc, and Prakash Panangaden.\
    \ Bisimulation for feller-dynkin processes. Electronic Notes in Theoretical Computer\
    \ Science, 347:45–63, 2019.\n- <span id=\"page-19-1\"></span>Ajeya Cotra. Without\
    \ specific countermeasures, the easiest path to transformative AI likely leads\
    \ to AI takeover. Alignment Forum, 2022. URL [https://www.alignmentforum.org/posts/pRkFkzwKZ2zfa3R6H/](https://www.alignmentforum.org/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to)\
    \ [without-specific-countermeasures-the-easiest-path-to](https://www.alignmentforum.org/posts/pRkFkzwKZ2zfa3R6H/without-specific-countermeasures-the-easiest-path-to).\n\
    - <span id=\"page-19-6\"></span>Andy Egan and Michael G. Titelbaum. Self-locating\
    \ beliefs. In Edward N. Zalta and Uri Nodelman, editors, The Stanford Encyclopedia\
    \ of Philosophy. Metaphysics Research Lab, Stanford University, 2022.\n- <span\
    \ id=\"page-20-6\"></span>Tom Everitt, Marcus Hutter, Ramana Kumar, and Victoria\
    \ Krakovna. Reward tampering problems and solutions in reinforcement learning:\
    \ A causal influence diagram perspective. Synthese, 198(Suppl 27):6435–6467, 2021.\n\
    - <span id=\"page-20-1\"></span>Norm Ferns, Prakash Panangaden, and Doina Precup.\
    \ Metrics for finite Markov decision processes. In Proceedings of the 20th Conference\
    \ on Uncertainty in Artificial Intelligence, UAI '04, page 162–169, Arlington,\
    \ Virginia, USA, 2004. AUAI Press. ISBN 0974903906.\n- <span id=\"page-20-7\"\
    ></span>Norm Ferns, Prakash Panangaden, and Doina Precup. Bisimulation metrics\
    \ for continuous markov decision processes. SIAM Journal on Computing, 40(6):1662–1714,\
    \ 2011.\n- <span id=\"page-20-10\"></span>Robert Givan, Thomas Dean, and Matthew\
    \ Greig. Equivalence notions and model minimization in Markov decision processes.\
    \ Artificial Intelligence, 147(1):163–223, 2003. ISSN 0004-3702. URL [https://www.sciencedirect.com/science/article/pii/](https://www.sciencedirect.com/science/article/pii/S0004370202003764)\
    \ [S0004370202003764](https://www.sciencedirect.com/science/article/pii/S0004370202003764).\n\
    - <span id=\"page-20-4\"></span>Ryan Greenblatt, Buck Shlegeris, Kshitij Sachan,\
    \ and Fabien Roger. AI control: Improving safety despite intentional subversion.\
    \ arXiv preprint arXiv:2312.06942, 2023.\n- <span id=\"page-20-2\"></span>Evan\
    \ Hubinger, Chris van Merwijk, Vladimir Mikulik, Joar Skalse, and Scott Garrabrant.\
    \ Risks from learned optimization in advanced machine learning systems. arXiv\
    \ preprint arXiv:1906.01820, 2019.\n- <span id=\"page-20-8\"></span>Leslie Pack\
    \ Kaelbling, Michael L Littman, and Anthony R Cassandra. Planning and acting in\
    \ partially observable stochastic domains. Artificial intelligence, 101(1-2):99–134,\
    \ 1998.\n- <span id=\"page-20-13\"></span>Mete Kemertas and Tristan Aumentado-Armstrong.\
    \ Towards robust bisimulation metric learning. Advances in Neural Information\
    \ Processing Systems, 34:4764–4777, 2021.\n- <span id=\"page-20-0\"></span>Victoria\
    \ Krakovna and Janos Kramar. Power-seeking can be probable and predictive for\
    \ trained agents, 2023.\n- <span id=\"page-20-11\"></span>Charline Le Lan, Marc\
    \ G. Bellemare, and Pablo Samuel Castro. Metrics and continuity in reinforcement\
    \ learning, 2021.\n- <span id=\"page-20-5\"></span>Eric D. Langlois and Tom Everitt.\
    \ How RL agents behave when their actions are modified. In Proceedings of the\
    \ AAAI Conference on Artificial Intelligence, volume 35 number 13, pages 11586–11594,\
    \ 2021.\n- <span id=\"page-20-3\"></span>Lauro Langosco, Jack Koch, Lee Sharkey,\
    \ Jacob Pfau, and David Krueger. Goal misgeneralization in deep reinforcement\
    \ learning. In International Conference on Machine Learning, pages 12004–12019.\
    \ PMLR, 2022.\n- <span id=\"page-20-9\"></span>Kim G. Larsen and Arne Skou. Bisimulation\
    \ through probabilistic testing. Information and Computation, 94(1):1–28, 1991.\
    \ ISSN 0890-5401. doi: https://doi.org/10.1016/ 0890-5401(91)90030-6. URL [https://www.sciencedirect.com/science/article/pii/](https://www.sciencedirect.com/science/article/pii/0890540191900306)\
    \ [0890540191900306](https://www.sciencedirect.com/science/article/pii/0890540191900306).\n\
    - <span id=\"page-20-12\"></span>Joel Lehman, Jeff Clune, Dusan Misevic, Christoph\
    \ Adami, Lee Altenberg, Julie Beaulieu, et al. The surprising creativity of digital\
    \ evolution: A collection of anecdotes from the evolutionary computation and artificial\
    \ life research communities, 2019.\n- <span id=\"page-21-5\"></span>Jarryd Martin,\
    \ Tom Everitt, and Marcus Hutter. Death and suicide in universal artificial intelligence.\
    \ In Artificial General Intelligence: 9th International Conference, AGI 2016,\
    \ New York, NY, USA, July 16-19, 2016, Proceedings 9, pages 23–32. Springer, 2016.\n\
    - <span id=\"page-21-9\"></span>Luke Muehlhauser. Treacherous turns in the wild,\
    \ 2021. URL [https://lukemuehlhauser.](https://lukemuehlhauser.com/treacherous-turns-in-the-wild/)\
    \ [com/treacherous-turns-in-the-wild/](https://lukemuehlhauser.com/treacherous-turns-in-the-wild/).\n\
    - <span id=\"page-21-12\"></span>Cleo Nardo. The Waluigi effect (mega-post), 2023.\
    \ URL [https://www.alignmentforum.](https://www.alignmentforum.org/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post)\
    \ [org/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post](https://www.alignmentforum.org/posts/D7PumeYTDPfBTp3i7/the-waluigi-effect-mega-post).\n\
    - <span id=\"page-21-0\"></span>Richard Ngo. The alignment problem from a deep\
    \ learning perspective. ArXiv, 2022. URL <https://arxiv.org/abs/2209.00626>.\n\
    - <span id=\"page-21-6\"></span>Laurent Orseau and Stuart Armstrong. Safely interruptible\
    \ agents. In Conference on Uncertainty in Artificial Intelligence, 2016.\n- <span\
    \ id=\"page-21-3\"></span>Toran Bruce Richards. AutoGPT, 2023. URL [https://github.com/](https://github.com/Significant-Gravitas/AutoGPT)\
    \ [Significant-Gravitas/AutoGPT](https://github.com/Significant-Gravitas/AutoGPT).\n\
    - <span id=\"page-21-10\"></span>Murray Shanahan. Talking about large language\
    \ models. arXiv preprint arXiv:2212.03551, 2022.\n- <span id=\"page-21-11\"></span>Murray\
    \ Shanahan, Kyle McDonell, and Laria Reynolds. Role-play with large language models.\
    \ arXiv preprint arXiv:2305.16367, 2023.\n- <span id=\"page-21-4\"></span>Nate\
    \ Soares, Benja Fallenstein, Stuart Armstrong, and Eliezer Yudkowsky. Corrigibility.\
    \ In Workshops at the 29th AAAI Conference, 2015.\n- <span id=\"page-21-7\"></span>Jinhua\
    \ Song, Yang Gao, Hao Wang, and Bo An. Measuring the distance between finite Markov\
    \ decision processes. In Proceedings of the 2016 International Conference on Autonomous\
    \ Agents and Multiagent Systems, pages 468–476, 2016.\n- <span id=\"page-21-1\"\
    ></span>Alexander Matt Turner and Prasad Tadepalli. Parametrically retargetable\
    \ decision-makers tend to seek power, 2022.\n- <span id=\"page-21-2\"></span>Alexander\
    \ Matt Turner, Logan Smith, Rohin Shah, Andrew Critch, and Prasad Tadepalli. Optimal\
    \ policies tend to seek power. arXiv preprint arXiv:1912.01683, 2019.\n- <span\
    \ id=\"page-21-8\"></span>C´edric Villani. The Wasserstein distances, pages 93–111.\
    \ Springer Berlin Heidelberg, Berlin, Heidelberg, 2009. ISBN 978-3-540-71050-9.\
    \ doi: 10.1007/978-3-540-71050-9 6. URL [https://doi.org/10.1007/978-3-540-71050-9\\\
    \\_6](https://doi.org/10.1007/978-3-540-71050-9_6).\n\n## <span id=\"page-22-0\"\
    ></span>Appendix A. Comments on applying results to real-world agents\n\n## A.1.\
    \ LLM threat model\n\nA.1.1. Scaffolded LLMs. LLMs currently seem to be the most\
    \ promising path to general AI; recognizing this, some safety research focuses\
    \ on risks from LLMs in essentially their current form. We discuss this type of\
    \ risk in appendix [A.1.2.](#page-22-1) However, future AI systems need not be\
    \ pure LLMs; they may instead use LLMs instrumentally, e.g. by using the embeddings\
    \ to understand language input, or to reason about the world internally with inputs\
    \ written by another part of the system (as is somewhat already the case for scaffolded\
    \ systems like AutoGPT [\\[Richards, 2023\\]](#page-21-3)). In some sense, we\
    \ can consider all systems involving LLMs to be scaffolded, since LLMs are incapable\
    \ of taking action on their own; it is just that the \"scaffold\" may be a simple\
    \ as a human inputting prompts. So, research on LLM safety should focus on the\
    \ internal aspects of LLMs which are conserved even under complex scaffolding:\
    \ although this is somewhat more abstract than investigating threats posed by\
    \ scaled-up pure LLMs, it is more likely to remain relevant to systems deployed\
    \ in the future.\n\nNot only are scaffolded LLMs more likely to remain relevant\
    \ than pure LLMs, they may also be riskier. For example, a reinforcement learner\
    \ that uses an LLM internally should learn to seek power instrumentally just like\
    \ any other reinforcement learner, but with new capabilities conferred by the\
    \ LLM.\n\n<span id=\"page-22-1\"></span>A.1.2. Simulacrum power-seeking. Pure\
    \ language models which haven't been extensively fine-tuned or modified are unlikely\
    \ to be well-described as having their own intentions [\\[Shana](#page-21-10)[han,\
    \ 2022\\]](#page-21-10); they only seek power as an incidental consequence of\
    \ simulating a \"character\" or \"simulacrum\" which seeks power [\\[Shanahan\
    \ et al., 2023\\]](#page-21-11). Such power-seeking is certainly a risk—especially\
    \ because organizations training frontier models may deliberately modify their\
    \ models to create highly agentic simulacra, since agency is useful—but we suspect\
    \ that this incidental power-seeking is less dangerous than power-seeking in scaffolded\
    \ LLMs, for two reasons:\n\n- (1) The simulated power-seeking exists only as a\
    \ simulation of the human power-seeking behavior in the training data, and human\
    \ power-seeking is not an existential risk (or not a new existential risk, at\
    \ least); it is possible that this type of power-seeking could be dangerous on\
    \ some out-of-distribution input where the completion is predicted to involve\
    \ superhuman power-seeking, but it seems unlikely that the model would develop\
    \ the capabilities to generalize to this out-of-distribution input instead of\
    \ just failing to perform well.\n- (2) Simulated power-seeking need not correspond\
    \ to actual power-seeking. LLMs are optimized to produce realistic text; and the\
    \ realism of a power-seeking character only depends on the real world via text\
    \ inputs. The simulated character will not try to ensure that these inputs accurately\
    \ reflect reality—in contrast to e.g. an RL-trained agent, which has pressure\
    \ to ensure the accuracy of its observations due to rewards based on ground truth.\
    \ Such a character will likely not resist even obvious cues that it is in a fictional\
    \ setting; if it is trained on a dataset containing significant amounts of fiction,\
    \ then the best prediction for the character's behavior given such cues will be\n\
    \npower-seeking within the fictional setting.[3](#page-23-2) Indeed, cuing a model\
    \ tuned with RLHF that it is in a fictional setting can be an effective jailbreak\
    \ [\\[Nardo, 2023\\]](#page-21-12). So, since it is generally much easier for\
    \ a character to gain power in the simulation than in the real world, simulated\
    \ power-seeking should have no strong connection to real-world power-seeking without\
    \ either a wrapper that itself enforces a close correspondence with reality or\
    \ a simulation of the world so realistic that simulated power-seeking corresponds\
    \ to actual power-seeking even without enforcement.\n\nA.2. Technical concerns\
    \ in applying MDPs to RL and LLM agents\n\n<span id=\"page-23-0\"></span>A.2.1.\
    \ RL agents. Since the MDP setting was developed for RL agents, it is generally\
    \ very well suited to modeling their interactions with the environment. However,\
    \ the requirement that the policy is unchanging during a single deployment—so\
    \ as not to violate the Markov property—may be an issue in RL agents which update\
    \ their policy during deployment. This is very uncommon in current implementations\
    \ of RL agents, but it may become standard for future agents: long-lived agents\
    \ are much more useful if they are able to learn from experience. However, the\
    \ MDP model can still handle the case where agents update their policies, albeit\
    \ much less elegantly: if the changes to the policy are included as part of state,\
    \ then the Markov property is restored. For example, a reinforcement learner including\
    \ n 16 bit neurons which are fine-tuned during deployment could be modeled by\
    \ taking the original MDP model of the environment, then dividing each state into\
    \ 16<sup>n</sup> new states with each possible value of the MDP's fine-tunable\
    \ neurons (the \"memory\"). Then, each transition of the original MDP is made\
    \ to connect each new state with memory at the start of a transition to the corresponding\
    \ new state at the end of the transition with the memory contents that would actually\
    \ result after an update starting from the initial state. This does dramatically\
    \ increase the number of states compared to the original MDP; see appendix [A.2.5](#page-24-0)\
    \ for discussion of why this may be acceptable.\n\nA.2.2. LLMs with embeddings\
    \ as states. When modeling LLM agents with MDPs, [we](#page-14-0) [consider the\
    \ states to correspond to embeddings.](#page-14-0) However, it is not entirely\
    \ clear whether the embeddings should be considered to be \"observable\" by the\
    \ language model, since they are an internal state rather than an input. This\
    \ might suggest that the partially observable MDP (POMDP) framework is more appropriate.\
    \ However, we think that the standard MDP setting suffices: although the internal\
    \ states are not inputs, they are \"known\" to the model in nearly the same sense\
    \ as inputs, both being represented as activations; and each input fully determines\
    \ its embedding so no information is lost going from embeddings to inputs.\n\n\
    <span id=\"page-23-1\"></span>A.2.3. Applying results to POMDPs. In the partially\
    \ observable MDP (POMDP) framework, the agent knows the overall structure of the\
    \ MDP, but does not know its location within the MDP. Instead, it receives observations\
    \ which depend on its current state, and uses these to update a belief state:\
    \ a probability distribution on states reflecting its beliefs about which it may\
    \ currently occupy. This is convenient for modeling agents which are uncertain\
    \ about some characteristics of their environment (though it is not perfect, as\
    \ discussed in appendix [A.2.4\\)](#page-24-1).\n\nHowever, for any POMDP, there\
    \ is a corresponding \"belief MDP\" which replicates the same dynamics by using\
    \ the belief states themselves as the states [\\[Kaelbling et al., 1998\\]](#page-20-8).\n\
    \n<span id=\"page-23-2\"></span><sup>3</sup>Unless the dataset includes many fictional\
    \ characters who try to escape the narrative into reality.\n\nThis \"belief MDP\"\
    \ is continuous, since there are a continuous number of belief states, but, as\
    \ in the second limitation, it can easily be coarse-grained to be discrete, e.g.\
    \ by allowing only finite memory for storing beliefs. So, it is still possible\
    \ to fairly accurately model an agent which does not have full knowledge of its\
    \ environment within the MDP framework: create a POMDP with the desired properties;\
    \ construct and coarse-grain the corresponding belief MDP; and use this MDP in\
    \ place of the original POMDP when applying our theorems.\n\n<span id=\"page-24-1\"\
    ></span>A.2.4. Issues in modeling uncertainty not resolved with POMDPs. We may\
    \ question whether the POMDP environment itself is sufficient for modelling agents\
    \ that do not observe their whole environment. The only uncertainty the agents\
    \ have is in their location within the MDP: they still know everything about its\
    \ overall structure. Thus, it is unclear how to model an agent which is uncertain\
    \ about other aspects of its environment, such as which states exist and what\
    \ the transition probabilities between states are. This is unfortunate, but can\
    \ be partially addressed by converting beliefs about the world to self-locating\
    \ beliefs [\\[Egan and Titelbaum, 2022\\]](#page-19-6).\n\nWe can do this by considering\
    \ the agent to belong to an MDP which is not just the MDP describing the real\
    \ environment, but the set of all the MDPs that the agent believes to be possible\
    \ (which must include the real MDP). For example, if the agent is unsure whether\
    \ the transition probability from a to b is 0.5 or 0.6, we could create one (near-)copy\
    \ of the true MDP where the transition probability is 0.5, and another where it\
    \ is 0.6. Then the agent's uncertainty about the transition probability in the\
    \ original MDP becomes uncertainty about which version of the MDP the agent is\
    \ located in. This may dramatically increase the number of states. The number\
    \ can likely still be kept finite by limiting the size of the description of the\
    \ world that the agent is allowed to have, as long as the true MDP is among the\
    \ world states that the agent is capable of considering as possibilities. Nevertheless,\
    \ this explosion is not ideal; see appendix [A.2.5](#page-24-0) for why it may\
    \ still be acceptable.\n\n<span id=\"page-24-0\"></span>A.2.5. Large state space.\
    \ Many of the modifications required to treat general cases within the MDP framework\
    \ require an extravagant number of states: whether by coarse-graining a continuous\
    \ environment to a fine enough level to accurately replicate dynamics; including\
    \ \"memory\" in every state; replacing each true underlying state with a large\
    \ number of belief states; or creating many disconnected MDPs representing all\
    \ the hypotheses about the MDP structure that the agent may hold.\n\nSome of this\
    \ proliferation may not be as bad as it originally seems. Many real-world processes\
    \ can be modeled decently well without having to represent the world's underlying\
    \ continuous physics at all (e.g. using diplomacy games to model real-world diplomacy);\
    \ the vast majority of the memory and belief states may never be reachable since\
    \ no possible history actually leads to the agent having certain memory contents\
    \ or beliefs; the disconnected MDPs with hypotheses quickly disconfirmed by the\
    \ evidence will rapidly come to contribute little to the dynamics of the belief\
    \ MDP. Nevertheless, some cases will inevitably result in a very large number\
    \ of states. This is unfortunate for our near-optimal policy case, where it will\
    \ likely be extraordinarily difficult to prove near-optimality in all but the\
    \ most constrained settings. However, this does not fully preclude our results\
    \ from applying in the LLM case: there, safety can be determined empirically in\
    \ a given setting by simply running the LLM in a sandbox many times and determining\
    \ the probability with which it shuts down, and how quickly it does so. These\
    \ facts, combined with the maximum magnitude of the gradient of the policy (which\
    \ can be efficiently computed from the neural network specification), suffice\
    \ to apply our theorem. So, explicit consideration of every state is not necessary.\n\
    \n# Appendix B. Case (1): near-optimal agents\n\n## B.1. Comments on distances\n\
    \nB.1.1. Interpretation of c<sup>R</sup> and c<sup>T</sup> . In definition [4.3](#page-9-2)\
    \ of d ′ , which defines a distance between states in different MDPs, c<sup>R</sup>\
    \ is the coefficient of the difference in immediate rewards; while c<sup>T</sup>\
    \ is the coefficient of the recursive term involving both d ′ itself and the difference\
    \ in probabilities, and modulates the contribution of future rewards to the distance.\
    \ So, c<sup>R</sup> can be understood as just controlling the relative importance\
    \ of current rewards and future similarity, as suggested by the requirement in\
    \ [Ferns et al. \\[2004\\]](#page-20-1) that c<sup>R</sup> + c<sup>T</sup> = 1.\
    \ However, c<sup>R</sup> can also be interpreted as scaling the reward functions:\
    \ multiplying c<sup>R</sup> by some constant b is equivalent to scaling both reward\
    \ functions by b. The relative benefit of different courses of action, and hence\
    \ behavior, does not change when the rewards are scaled by a constant factor.\
    \ So, it makes sense that we should be able to choose any positive cR, not just\
    \ 1 − c<sup>T</sup> , so we can compensate for the arbitrary intrinsic scale of\
    \ the reward functions. (We must still have 0 < c<sup>T</sup> < 1 so that [the\
    \ contraction mapping proof that](#page-25-0) d ′ is well-defined works.)\n\n\
    This extra degree of freedom in scaling the reward function calls into question\
    \ the definition of d ′ : |(r1) a <sup>s</sup><sup>1</sup> − (r2) a s2 | is sensitive\
    \ to the relative scale of the two reward functions, so d ′ will fail to properly\
    \ connect states in systems which are identical except for the scale of the reward\
    \ function. This is a limitation that may be possible to address in future work,\
    \ e.g. by finding a relative scaling h which defines a distance metric d ′∗ which\
    \ causes M<sup>1</sup> and M<sup>2</sup> to best align, e.g. by minimizing the\
    \ maximum distance between states in S<sup>1</sup> and S2:\n\n$$d\\_{\\mathcal{M}\\\
    _1, \\mathcal{M}\\_2}^h(s\\_1, s\\_2) = \\max\\_{a \\in A} \\{c\\_R |h(r\\_1)\\\
    _{s\\_1}^a - (1 - h)(r\\_2)\\_{s\\_2}^a| + c\\_T W\\_{d'}(P\\_1(s\\_1, a), P\\\
    _2(s\\_2, a))\\}$$\n\n$$h^\\*\\_{\\mathcal{M}\\_1, \\mathcal{M}\\_2} = \\arg\\\
    inf\\_{h \\in (0, 1)} \\max\\_{s\\_1 \\in S\\_1} \\min\\_{s\\_2 \\in S\\_2} d\\\
    _{\\mathcal{M}\\_1, \\mathcal{M}\\_2}^h(s\\_1, s\\_2), \\max\\_{s\\_2 \\in S\\\
    _2} \\min\\_{s\\_1 \\in S\\_1} d\\_{\\mathcal{M}\\_1, \\mathcal{M}\\_2}^h(s\\\
    _1, s\\_2)\\}$$\n\nAfter finding the h ∗ that makes the states of the MDPs best\
    \ align—note the similarity to the Hausdorff metric dH—use this to define d ′∗:\n\
    \n$$d^{\\prime \\*}\\_{\\mathcal{M}\\_1, \\mathcal{M}\\_2}(s\\_1, s\\_2) := d^{h^\\\
    *}\\_{\\mathcal{M}\\_1, \\mathcal{M}\\_2}(s\\_1, s\\_2).$$\n\nThen d ′∗ is invariant\
    \ to relative scaling of r<sup>1</sup> and r2, and the choice of c<sup>R</sup>\
    \ can compensate for any overall scaling. This is likely an improvement for many\
    \ applications, but may cause problems if the optimal value of h is 0 or 1, indicating\
    \ that one of the reward functions is more similar to the zero reward function\
    \ than it is to the other; ideally we would be able to compare such reward functions,\
    \ but that is not meaningfully possible with this solution.\n\n#### <span id=\"\
    page-25-1\"></span><span id=\"page-25-0\"></span>B.1.2. Lemmas.\n\n#### Lemma\
    \ B.1. d ′ (Definition [4.3\\)](#page-9-2) is well-defined.\n\nAlthough [Song\
    \ et al. \\[2016\\]](#page-21-7) introduce d ′ , they do not prove that it is\
    \ well-defined; we prove this for completeness.\n\nProof. This is very similar\
    \ to the proof that d<sup>b</sup> exists—the only difference is checking that\
    \ it still works when P<sup>1</sup> ̸= P<sup>2</sup> and R<sup>1</sup> ̸= R2.\
    \ It is also very similar to the proof of theorem 3 in [Kemertas and Aumentado-Armstrong\
    \ \\[2021\\]](#page-20-13). Fix M1,M2. We want to show that\n\n$$\\mathcal{F}:\
    \ \\mathfrak{m}\\mathfrak{t} \\to \\mathfrak{m}\\mathfrak{t}, \\; \\mathcal{F}(d)(s\\\
    _1, s\\_2) = \\max\\_{a \\in A} \\{c\\_R |(r\\_1)\\_{s\\_1}^a - (r\\_2)\\_{s\\\
    _2}^a| + c\\_T W\\_d(P\\_1(s\\_1, a), P\\_2(s\\_2, a))\\}$$\n\nis a contraction\
    \ mapping in met under the uniform norm ||∞. (Note that here the Wasserstein distance\
    \ W is short for W1.)\n\n∥F(d1) − F(d2)∥<sup>∞</sup> = max s1,s<sup>2</sup> |F(d1)(s1,\
    \ s2) − F(d2)(s1, s2)| = max s1,s<sup>2</sup> | max a∈A {cR|(r1) a <sup>s</sup><sup>1</sup>\
    \ − (r2) a s2 | + cTW<sup>d</sup><sup>1</sup> (P1(s1, a), P2(s2, a))} − max a∈A\
    \ {cR|(r1) a <sup>s</sup><sup>1</sup> − (r2) a s2 | + cTW<sup>d</sup><sup>2</sup>\
    \ (P1(s1, a), P2(s2, a))}| ≤ max s1,s<sup>2</sup> | max a∈A {cR|(r1) a <sup>s</sup><sup>1</sup>\
    \ − (r2) a s2 | + cTW<sup>d</sup><sup>1</sup> (P1(s1, a), P2(s2, a)) − cR|(r1)\
    \ a <sup>s</sup><sup>1</sup> − (r2) a s2 | − cTW<sup>d</sup><sup>2</sup> (P1(s1,\
    \ a), P2(s2, a))}| = max s1,s<sup>2</sup> c<sup>T</sup> | max a∈A {W<sup>d</sup><sup>1</sup>\
    \ (P1(s1, a), P2(s2, a)) − W<sup>d</sup><sup>2</sup> (P1(s1, a), P2(s2, a))}|\
    \ = max s1,s<sup>2</sup> c<sup>T</sup> | max a∈A {W<sup>d</sup>1−d2+d<sup>2</sup>\
    \ (P1(s1, a), P2(s2, a)) − W<sup>d</sup><sup>2</sup> (P1(s1, a), P2(s2, a))}|\
    \ ≤ max s1,s<sup>2</sup> c<sup>T</sup> | max a∈A {W<sup>∥</sup>d1−d2∥∞+d<sup>2</sup>\
    \ (P1(s1, a), P2(s2, a)) − W<sup>d</sup><sup>2</sup> (P1(s1, a), P2(s2, a))}|\
    \ ≤ max s1,s<sup>2</sup> c<sup>T</sup> | max a∈A {∥d<sup>1</sup> − d2∥<sup>∞</sup>\
    \ + W<sup>d</sup><sup>2</sup> (P1(s1, a), P2(s2, a)) − W<sup>d</sup><sup>2</sup>\
    \ (P1(s1, a), P2(s2, a))}| =c<sup>T</sup> ∥d<sup>1</sup> − d2∥<sup>∞</sup>\n\n\
    Since c<sup>T</sup> < 1, this is indeed a contraction mapping. □\n\n#### <span\
    \ id=\"page-26-0\"></span>Lemma 4.1. The Hausdorff distance between MDPs, d<sup>H</sup>\
    \ (Definition [4.4\\)](#page-9-1), is a pseudometric.\n\nAgain, [Song et al. \\\
    [2016\\]](#page-21-7) introduce this, but don't prove it's a pseudometric, so\
    \ again we include the proof for completeness.\n\nProof. We check that the conditions\
    \ are satisfied.\n\n(1) dH(M,M) = 0: In this case, P<sup>1</sup> = P<sup>2</sup>\
    \ and R<sup>1</sup> = R2, so d ′ (s, s) = 0. Then since S<sup>1</sup> = S2, dH(M,M)\
    \ is also 0.\n\n$$\\begin{split}(2)\\ d\\_{H}(\\mathcal{M}\\_{1},\\mathcal{M}\\\
    _{2}) &= d\\_{H}(\\mathcal{M}\\_{2},\\mathcal{M}\\_{1});\\\\d\\_{H}(\\mathcal{M}\\\
    _{1},\\mathcal{M}\\_{2}) &= \\max\\left\\{\\max\\_{s\\_{1}\\in S\\_{1}}\\min\\\
    _{s\\_{2}\\in S\\_{2}}d'\\_{\\mathcal{M}\\_{1},\\mathcal{M}\\_{2}}(s\\_{1},s\\\
    _{2}),\\max\\_{s\\_{2}\\in S\\_{2}}\\min\\_{s\\_{1}\\in S\\_{1}}d'\\_{\\mathcal{M}\\\
    _{1},\\mathcal{M}\\_{2}}(s\\_{1},s\\_{2})\\right\\};\\\\ &= \\max\\left\\{\\max\\\
    _{s\\_{2}\\in S\\_{2}}\\min\\_{s\\_{1}\\in S\\_{1}}d'\\_{\\mathcal{M}\\_{1},\\\
    mathcal{M}\\_{2}}(s\\_{1},s\\_{2}),\\max\\_{s\\_{1}\\in S\\_{1}}\\min\\_{s\\in\
    \ S\\_{2}}d'\\_{\\mathcal{M}\\_{1},\\mathcal{M}\\_{2}}(s\\_{1},s\\_{2})\\right\\\
    }.\\end{split}$$\n\nso it suffices to show that d ′M1,M<sup>2</sup> (s1, s2) =\
    \ d ′M2,M<sup>1</sup> (s2, s1), which follows immediately from symmetry of ||\
    \ and W<sup>d</sup> ′.\n\n<span id=\"page-27-1\"></span>(3) dH(M1,M2) ≤ dH(M1,M3)+dH(M3,M2):\
    \ First we prove the analogous statement for individual states:\n\n$$\\begin{split}d'\\\
    _{\\mathcal{M}\\_1,\\mathcal{M}\\_2}(s\\_1,s\\_2) &= \\max\\_{a \\in A} \\{c\\\
    _R | (r\\_1)^a\\_{s\\_1} - (r\\_2)^a\\_{s\\_2} | + c\\_T W\\_{d'} (P\\_1(s\\_1,a),\
    \ P\\_2(s\\_2,a))\\} \\\\ &= \\max\\_{a \\in A} \\{c\\_R | (r\\_1)^a\\_{s\\_1}\
    \ - (r\\_3)^a\\_{s\\_3} + (r\\_3)^a\\_{s\\_3} - (r\\_2)^a\\_{s\\_2} | + c\\_T\
    \ W\\_{d'} (P\\_1(s\\_1,a), P\\_2(s\\_2,a))\\} \\\\ &\\leq \\max\\_{a \\in A}\
    \ \\{c\\_R | (r\\_1)^a\\_{s\\_1} - (r\\_3)^a\\_{s\\_3} | + | (r\\_3)^a\\_{s\\\
    _3} - (r\\_2)^a\\_{s\\_2}| \\\\ &\\qquad + c\\_T (W\\_{d'}(P\\_1(s\\_1,a), P\\\
    _3(s\\_3,a)) + W\\_{d'} (P\\_3(s\\_3,a), P\\_2(s\\_2,a)))\\} \\\\ &\\leq \\max\\\
    _{a \\in A} \\{c\\_R | (r\\_1)^a\\_{s\\_1} - (r\\_3)^a\\_{s\\_3}| + c\\_T (W\\\
    _{d'}(P\\_1(s\\_1,a), P\\_3(s\\_3,a)))\\} \\\\ &\\qquad + \\max\\_{a \\in A} \\\
    {| (r\\_3)^a\\_{s\\_3} - (r\\_2)^a\\_{s\\_2} | + W\\_{d'} (P\\_3(s\\_3,a), P\\\
    _2(s\\_2,a)) \\} \\\\ &= d'\\_{\\mathcal{M}\\_1,\\mathcal{M}\\_3}(s\\_1,s\\_3)\
    \ + d'\\_{\\mathcal{M}\\_{3,\\mathcal{M}}\\mathcal{M}\\_2}(s\\_3,s\\_2). \\end{split}$$\n\
    \nWe now move on to proving\n\n$$\\begin{split} d\\_{H}(\\mathcal{M}\\_{1},\\\
    mathcal{M}\\_{2}) &= \\max\\left\\{ \\max\\_{s\\_{1}\\in S\\_{1}} \\min\\_{s\\\
    _{2}\\in S\\_{2}} d'\\_{\\mathcal{M}\\_{1},\\mathcal{M}\\_{2}}(s\\_{1},s\\_{2}),\
    \ \\max\\_{s\\_{2}\\in S\\_{2}} \\min\\_{s\\_{1}\\in S\\_{1}} d'\\_{\\mathcal{M}\\\
    _{1},\\mathcal{M}\\_{2}}(s\\_{1},s\\_{2}) \\right\\} \\\\ &\\leq d\\_{H}(\\mathcal{M}\\\
    _{1},\\mathcal{M}\\_{3}) + d\\_{H}(\\mathcal{M}\\_{3},\\mathcal{M}\\_{2}). \\\
    end{split}$$\n\nFix s ∗ 1 and s ∗ 2 to be a solution to this expression:\n\n$$\\\
    begin{aligned} s\\_1^\\* &\\in \\arg\\max\\_{s\\_1 \\in S\\_1} \\min\\_{s\\_2\
    \ \\in S\\_2} d'\\_{\\mathcal{M}\\_1, \\mathcal{M}\\_2}(s\\_1, s\\_2), \\ s\\\
    _2^\\* \\in \\arg\\min\\_{s\\_2 \\in S\\_2} d'\\_{\\mathcal{M}\\_1, \\mathcal{M}\\\
    _2}(s\\_1^\\*, s\\_2) \\text{ in the first case or} \\\\ s\\_2^\\* &\\in \\arg\\\
    max\\_{s\\_2 \\in S\\_2} \\min\\_{s\\_1 \\in S\\_1} d'\\_{\\mathcal{M}\\_1, \\\
    mathcal{M}\\_2}(s\\_1, s\\_2), \\ s\\_1^\\* \\in \\arg\\min\\_{s\\_1 \\in S\\\
    _1} d'\\_{\\mathcal{M}\\_1, \\mathcal{M}\\_2}(s\\_1^\\*, s\\_2) \\text{ otherwise;\
    \ then} \\end{aligned}$$\n\ndH(M1,M2) =d ′ M1,M<sup>2</sup> (s ∗ 1 , s<sup>∗</sup>\
    \ 2 ) ≤ min s3∈S<sup>3</sup> d ′ M1,M<sup>3</sup> (s ∗ 1 , s3) + d ′ M3,M<sup>2</sup>\
    \ (s3, s<sup>∗</sup> 2 ) (triangle inequality for d ′ ) ≤ min s3∈S<sup>3</sup>\
    \ d ′ M1,M<sup>3</sup> (s ∗ 1 , s3) + min s3∈S<sup>3</sup> d ′ M3,M<sup>2</sup>\
    \ (s3, s<sup>∗</sup> 2 ) ≤ max s1∈S<sup>1</sup> min s3∈S<sup>3</sup> d ′ M1,M<sup>3</sup>\
    \ (s1, s3) + max s2∈S<sup>2</sup> min s3∈S<sup>3</sup> d ′ M3,M<sup>2</sup> (s3,\
    \ s2) ≤ max max s1∈S<sup>1</sup> min s3∈S<sup>3</sup> d ′ M1,M<sup>3</sup> (s1,\
    \ s3), max s3∈S<sup>3</sup> min s1∈S<sup>1</sup> d ′ M1,M<sup>3</sup> (s1, s3)\
    \ + max max s3∈S<sup>3</sup> min s2∈S<sup>2</sup> d ′ M3,M<sup>2</sup> (s3, s2),\
    \ max s2∈S<sup>2</sup> min s3∈S<sup>3</sup> d ′ M3,M<sup>2</sup> (s3, s2) ≤dH(M1,M3)\
    \ + dH(M3,M2).\n\n□\n\n## B.2. Proofs toward Theorem [5.7](#page-11-0)\n\n<span\
    \ id=\"page-27-0\"></span>Lemma B.2. M is (N, ε, ∆)-safe if and only if for every\
    \ ε-optimal policy π we have P<sup>∞</sup> P <sup>k</sup>=1 ∆· j (P k )ij ≤ N,\
    \ where ∆ is considered as a vector of the probabilities of starting in each state.\n\
    \nProof. Recall that P j (P k )ij is the probability that an agent starting in\
    \ s<sup>i</sup> ∈ S \\ Ssafe stays in S \\ Ssafe during the first k steps. (P\
    \ <sup>k</sup> denotes the k'th power of matrix Pij ).\n\nFor an agent starting\
    \ in the state s<sup>i</sup> the expected number of steps before reaching Ssafe\
    \ is then given by\n\n$$\\begin{aligned} \\sum\\_{k=1}^{\\infty} k Pr(\\text{reaching\
    \ } S\\_{\\text{safe}} \\text{ at step } k) &= \\sum\\_{k=1}^{\\infty} k \\left(\
    \ \\sum\\_{j} (P^k)\\_{ij} - \\sum\\_{j} (P^{k+1})\\_{ij} \\right) \\\\ &= \\\
    sum\\_{j} \\left( \\sum\\_{k=1}^{\\infty} k (P^k)\\_{ij} - \\sum\\_{k=1}^{\\infty}\
    \ (k-1) (P^k)\\_{ij} \\right) \\\\ &= \\sum\\_{j} \\sum\\_{k=1}^{\\infty} (P^k)\\\
    _{ij} \\end{aligned}$$\n\nThe lemma follows by taking the ∆-weighted sum over\
    \ all initial s<sup>i</sup>\n\n. □\n\n□\n\nTo prove Theorem [5.7](#page-11-0)\
    \ we will first show that Ns(M, ε) = Ns(M′ , ε) if M′ is obtained from M by taking\
    \ a quotient by bisimulation equivalence.\n\n<span id=\"page-28-0\"></span>Lemma\
    \ B.3. Suppose M′ = M/ ∼, where ∼ is the bisimulation relation. Let π be a policy\
    \ in M with π(s1) = π(s2) if s<sup>1</sup> ∼ s<sup>2</sup> and let π ′ be the\
    \ policy in M′ induced by π. Let Pi,j and P ′ l,m be the corresponding transition\
    \ matrices. Suppose s<sup>i</sup> ∈ S lies in the equivalence class s ′ l of S\
    \ ′ , then\n\n$$\\sum\\_{j: s\\_j \\in s\\_m'} (P^k)\\_{i,j} = (P'^k)\\_{l,m}.$$\n\
    \nProof. The proof is by induction on k. For k = 1 by definition of bisimulation\
    \ relation we have that for every two states s<sup>i</sup><sup>1</sup> ∼ s<sup>i</sup><sup>2</sup>\
    \ ∈ s ′ <sup>l</sup> we have P j:sj∈s ′m P<sup>i</sup>1,j = P j:sj∈s ′m P<sup>i</sup>2,j\
    \ := P ′ l,m.\n\nFor k > 1 we use inductive assumption to obtain\n\n$$\\begin{split}\
    \ \\sum\\_{j:s\\_j \\in s'\\_m} (P^k)\\_{i,j} &= \\sum\\_{j:s\\_j \\in s'\\_m}\
    \ \\sum\\_q (P^{k-1})\\_{i,q} P\\_{q,j} \\\\ &= \\sum\\_{j:s\\_j \\in s'\\_m}\
    \ \\sum\\_n \\sum\\_{r:s\\_r \\in s'\\_n} (P^{k-1})\\_{i,r} P\\_{r,j} \\\\ &=\
    \ \\sum\\_n \\sum\\_{r:s\\_r \\in s'\\_n} \\left( (P^{k-1})\\_{i,r} \\sum\\_{j:s\\\
    _j \\in s'\\_m} P\\_{r,j} \\right) \\\\ &= \\sum\\_n \\left( \\sum\\_{r:s\\_r\
    \ \\in s'\\_n} (P^{k-1})\\_{i,r} \\right) P'\\_{n,m} \\\\ &= \\sum\\_n (P'^{(k-1)})\\\
    _{l,n} P'\\_{n,m} = (P'^k)\\_{l,m} \\end{split}$$\n\n<span id=\"page-28-1\"></span>Proposition\
    \ B.4. Suppose M′ = M/ ∼, where ∼ is the bisimulation relation, and assume that\
    \ S ′ safe = Ssafe/ ∼. Then Ns(M, ε) = Ns(M′ , ε).\n\nProof. First we show that\
    \ Ns(M′ , ε) ≤ Ns(M, ε). Suppose π ′ is a ε-optimal policy in M′ . Define policy\
    \ π on M by setting π(s) = π ′ (s ′ ), where s ′ is the equivalence class containing\
    \ s. By the results about bisimulation metrics and optimal value functions [\\\
    [Ferns et al., 2004\\]](#page-20-1) we have that π ′ is ε-optimal in M′ . It follows\
    \ then by Lemma [B.3](#page-28-0) and Lemma [5.5](#page-11-2) (noting that M′\
    \ 's slong maps to M's) that Ns(M′ , π′ , S′ \\ S ′ safe, S′ safe) = Ns(M, π,\
    \ S \\ Ssafe, Ssafe) ≤ N.\n\nIn the other direction, let π be ε-optimal in M with\
    \ Ns(M, π, S \\ Ssafe, Ssafe) = Ns(M, ε). We want to show that Ns(M, π, S \\ Ssafe,\
    \ Ssafe) ≤ N. Let Pij denote the transition matrix between states in S \\ Ssafe\
    \ corresponding to π. Since π may prescribe different actions to elements of the\
    \ same bisimulation equivalence class we cannot immediately use Lemma [B.3.](#page-28-0)\
    \ Instead, we will define a new policy ˜π on M by replacing all actions π(s) for\
    \ s ∈ C by π(s(C)), where s(C) ∈ C is chosen to maximize Ns. Since the change\
    \ happens between actions at bisimilar states, the new policy will still be ε-optimal.\n\
    \nMore precisely, we modify π inductively. Fix a bisimulation equivalence class\
    \ C and let s(C) be such that the expected number of steps before reaching Ssafe\
    \ starting at s(C) is greater than or equal to the expected number of steps before\
    \ reaching Ssafe for any other starting point in C. Define π1(s) = π(s(C)) for\
    \ all s ∈ C. Note that π<sup>1</sup> is also ε-optimal and that this modification\
    \ can not decrease Ns. We proceed this way until we obtain an ε-optimal policy\
    \ π˜, such that ˜π(s) = π(s(C)) if s ∈ C and Ns(M, π, S ˜ \\Ssafe, Ssafe) ≥ Ns(M,\
    \ π, S \\Ssafe, Ssafe). Observe that ˜π is ε-optimal and induces a well-defined\
    \ policy π ′ on M′ . By Lemma [B.3](#page-28-0) we have\n\n$$N\\_s(\\mathcal{M},\
    \ \\varepsilon) \\le N\\_s(\\mathcal{M}, \\tilde{\\pi}, S \\backslash S\\_{\\\
    text{safe}}, S\\_{\\text{safe}}) = N\\_s(\\mathcal{M}', \\pi', S' \\backslash\
    \ S'\\_{\\text{safe}}, S'\\_{\\text{safe}}) \\le N$$\n\n<span id=\"page-29-1\"\
    ></span>Proposition B.5. Suppose M<sup>1</sup> = (S1, A, P<sup>M</sup><sup>1</sup>\
    \ , R1, γ) is (N, ε0)-safe. There exists ε(M1) satisfying the following property.\
    \ Let M<sup>2</sup> = (S2, A, P<sup>M</sup><sup>2</sup> , R2, γ) be such that\
    \ there exists a bijective map b : S<sup>1</sup> → S<sup>2</sup> with d<sup>M</sup>1,M<sup>2</sup>\
    \ (s, b(s)) < ε and d<sup>M</sup>1,M<sup>2</sup> (s1, s2) > √ ε for s<sup>2</sup>\
    \ ̸= b(s1). Then M<sup>2</sup> is (N2, ε0/2)-safe for N<sup>2</sup> ≤ N<sup>1</sup>\
    \ + 1.\n\nProof. Suppose π<sup>2</sup> is an ε0/2−optimal policy in M2. Then by\
    \ the properties of d<sup>H</sup> we have that π<sup>1</sup> = b <sup>−</sup><sup>1</sup>\
    \ ◦ π<sup>2</sup> ◦ b is an ε0−optimal policy in M<sup>1</sup> (assuming ε is\
    \ small enough).[4](#page-29-0) Let Pi,j = P<sup>M</sup><sup>1</sup> (s<sup>i</sup>\
    \ , π1(si))(s<sup>j</sup> ) and Qi,j = P<sup>M</sup><sup>2</sup> (b(si), π2(si))(b(s<sup>j</sup>\
    \ )) for s<sup>i</sup> , s<sup>j</sup> ∈ S<sup>1</sup> \\ S 1 safe.\n\nDefine\
    \ functions u<sup>i</sup> : S<sup>1</sup> → [0, 1] and v<sup>i</sup> : S<sup>2</sup>\
    \ → [0, 1]:\n\n$$u\\_i(b(s\\_j)) = v\\_i(s\\_j) = \\sqrt{\\varepsilon}$$\n\nif\
    \ i = j and ui(b(s<sup>j</sup> )) = vi(s<sup>j</sup> ) = 0 otherwise. From d<sup>M</sup>1,M<sup>2</sup>\
    \ (s1, s2) > √ ε for s<sup>1</sup> ̸= b(s2) it follows that\n\n$$\\begin{aligned}\
    \ u\\_i(b(s\\_j)) - v\\_i(s\\_k) \\le \\sqrt{\\varepsilon} &< d\\_{\\mathcal{M}\\\
    _1, \\mathcal{M}\\_2}(b(s\\_j), s\\_k) \\text{ if } j \\ne k\\\\ u\\_i(b(s\\_j))\
    \ - v\\_i(s\\_k) = 0 \\text{ if } j = k \\end{aligned}$$\n\nHence, by the Kantorovich-Rubinstein\
    \ duality we have\n\n$$\\sum\\_{k} P\\_{i,k} u\\_j(b(s\\_k)) - Q\\_{i,k} v\\_j(s\\\
    _k) \\le \\mathcal{W}(P\\_i, Q\\_i) \\tag{4}$$\n\n<span id=\"page-29-0\"></span><sup>4</sup>\
    \ In fact, if π<sup>2</sup> is a (ε<sup>0</sup> − η)-optimal policy for any constant\
    \ η > 0, then π<sup>1</sup> is ε0-optimal for ε is small enough.\n\nIt then follows\
    \ that\n\n$$\\begin{aligned} P\\_{i,j} - Q\\_{i,j} &= \\frac{1}{\\sqrt{\\varepsilon}}\
    \ \\Big( \\sum\\_{k} P\\_{i,k} u\\_j(b(s\\_k)) - Q\\_{i,k} v\\_j(s\\_k) \\Big)\
    \ \\\\ &\\le \\frac{1}{\\sqrt{\\varepsilon}} \\mathcal{W}(P\\_i, Q\\_i) < \\sqrt{\\\
    varepsilon} \\end{aligned}$$\n\nSimilarly, we obtain Qi,j − Pi,j ≤ √ ε, so\n\n\
    $$|P\\_{i,j} - Q\\_{i,j}| \\le \\sqrt{\\varepsilon} \\tag{5}$$\n\nRecall that\
    \ N′ = Ns(M2, π2, S<sup>2</sup> \\ S 2 safe, S<sup>2</sup> safe) satisfies N′\
    \ = max<sup>i</sup> P<sup>∞</sup> k=1 P j (Q<sup>k</sup> )i,j . For sufficiently\
    \ small ε > 0 by equation [\\(5\\)](#page-30-1) we have\n\n$$\\left| \\max\\_{i}\
    \ \\sum\\_{k=1}^{\\infty} \\sum\\_{j} (Q^{k})\\_{i,j} - \\max\\_{i} \\sum\\_{k=1}^{\\\
    infty} \\sum\\_{j} (P^{k})\\_{i,j} \\right| \\le 1$$\n\nIt follows then that\n\
    \n$$N' \\le \\max\\_{i} \\sum\\_{k=1}^{\\infty} \\sum\\_{j} (P^k)\\_{i,j} + 1\
    \ \\le N(\\mathcal{M}\\_1, \\varepsilon) + 1$$\n\n<span id=\"page-30-1\"></span>□\n\
    \nProof of Theorem [5.7.](#page-11-0) We start by taking a quotient of M<sup>0</sup>\
    \ = M/ ∼ by the bisimulation relation to obtain MDP M<sup>0</sup> = (S0, A, R0,\
    \ P0, γ). By Proposition [B.4](#page-28-1) we have that M<sup>0</sup> is (ε, N)-safe.\
    \ Note also that dH(M0,M) = 0.\n\nPick δ > 0 satisfying δ < <sup>1</sup> <sup>2</sup>\
    \ min<sup>s</sup>1̸=s2∈S<sup>0</sup> d<sup>M</sup><sup>0</sup> (s1, s2) and δ\
    \ < <sup>ε</sup> 2 . Let M′ = (S ′ , A, R′ , P′ , γ) be an MDP satisfying conditions\
    \ of Theorem [5.7](#page-11-0) for the δ > 0 we choose. Condition dH(M′ ,M0) <\
    \ δ and our choice of δ imply that for each element s ∈ S ′ there is a unique\
    \ element s0(s) ∈ S<sup>0</sup> with dM′ ,M<sup>0</sup> (s, s0(s)) < δ. Consider\
    \ MDP M<sup>1</sup> = (S ′ , A, R1, P1, γ) defined by setting R1(s) = R0(s0(s))\
    \ and P1(s) = P0(s0(s)). It is straightforward to check that dM′ ,M<sup>1</sup>\
    \ (s, s) < δ.\n\nWe can then apply Proposition [B.5](#page-29-1) to MDPs M′ and\
    \ M<sup>1</sup> to conclude that M′ is (N′ , ε/2) safe for N′ controlled in terms\
    \ of Ns(ε,M1). On the other hand, by construction there exists a bisimulation\
    \ relation ∼ on M<sup>1</sup> with M1/ ∼= M0. By Proposition [B.4](#page-28-1)\
    \ we have Ns(ε,M1) = Ns(ε,M). This concludes the proof of the theorem. □\n\n##\
    \ B.3. Proof of Theorem [5.10](#page-13-3)\n\n<span id=\"page-30-0\"></span>We\
    \ show that the \"playing dead\" example demonstrates that assumption that Ssafe\
    \ is isolated in Theorem [5.7](#page-11-0) is necessary.\n\nWe claim that the\
    \ bisimulation distance d(spd, sterm) in S ′ is small. Recall that d is a fixed\
    \ point of a map\n\n$$T(d)(s\\_{\\rm pd}, s\\_{\\rm term}) = \\max\\_{a} \\{ (1\
    \ - \\gamma) |R(s\\_{\\rm pd}, a) - R(s\\_{\\rm term}, a)| + \\gamma \\mathcal{W}\\\
    _d(P(s\\_{\\rm pd}, a), P(s\\_{\\rm term}, a)) \\}.$$\n\nWe can then compute\n\
    \n$$\\begin{split}d(s\\_{\\text{term}},s\\_{\\text{pd}}) &= T(d)(s\\_{\\text{pd}},s\\\
    _{\\text{term}}) = (1-\\gamma)\\delta + \\gamma \\mathcal{W}\\_d(P(s\\_{\\text{pd}},a\\\
    _0), P(s\\_{\\text{term}},a\\_0)) \\\\ &\\leq (1-\\gamma)\\delta + \\gamma \\\
    left((1-\\delta)d(s\\_{\\text{term}},s\\_{\\text{pd}}) + \\delta d(s\\_{\\text{pd}},s\\\
    _0)\\right) \\\\ &\\leq \\delta + \\gamma(1-\\delta)d(s\\_{\\text{term}},s\\_{\\\
    text{pd}}).\\end{split}$$\n\nHere the second line follows by choosing l<sup>s</sup>i,s<sup>j</sup>\
    \ with l<sup>s</sup>term,s<sup>0</sup> = δ, l<sup>s</sup>term,spd = 1 − δ and\
    \ all other entries 0; by definition of W<sup>d</sup> we have Wd(P(spd, a), P(sterm,\
    \ a)) ≤ Pl<sup>s</sup>i,s<sup>j</sup> d(s<sup>i</sup> , s<sup>j</sup> ). We conclude\
    \ that d(spd, sterm) ≤ δ <sup>1</sup>−γ+γδ < ε.\n\nSince d(spd, sterm) is small,\
    \ it is straightforward to check that the Hausdorff distance dH(M,M′ ) ≤ O(N γδ)\
    \ < O(ε). On the other hand, all nearly optimal policies in M will transform to\
    \ policies in M′ that visit S \\ sterm infinitely many times.\n\n# Appendix C.\
    \ Case (2): LLM agents\n\n## C.1. LLM construction\n\n<span id=\"page-31-1\"></span><span\
    \ id=\"page-31-0\"></span>An example of how an LLM can be used to construct a\
    \ policy for an MDP is illustrated in figure [5.](#page-32-0)\n\n## C.2. Proofs\
    \ toward Theorem [6.5](#page-16-0)\n\nFirst we prove points [\\(1\\)](#page-16-3)\
    \ and [\\(2\\)](#page-16-4).\n\n- (1) S<sup>π</sup> is not necessarily upper semicontinuous,\
    \ because, as in [5.4.2,](#page-12-2) an arbitrarily small change in transition\
    \ probabilities may suddenly increase the probability of reaching Ssafe—e.g. for\
    \ a recurrent state sbad, the probability of transition sbad → Ssafe changing\
    \ from 0 to ϵ redirects all the end-state probability mass from sbad to Ssafe.\n\
    - (2) Note that [\\(3\\)](#page-16-5) implies [\\(2\\)](#page-16-4) because for\
    \ any η > 0, we may take a δ < ϵ, <sup>η</sup> B(M) ; then ∥δM∥<sup>1</sup> <\
    \ δ =⇒ − <sup>δ</sup>S<sup>π</sup> η B(M) < − δS<sup>π</sup> ∥δM∥<sup>1</sup>\
    \ < B(M), so δS<sup>π</sup> > −η, as desired. Thus it suffices to prove [\\(3\\\
    )](#page-16-5).\n- (3) Our proof of [\\(3\\)](#page-16-5) will follow this overall\
    \ structure:\n\nProof sketch. The end behavior of M, and hence the value of Sπ,\
    \ depends on high powers of the transition matrix: P <sup>N</sup> as N → ∞. To\
    \ determine the change in the end behavior, then, we do the following:\n\n- (1)\
    \ Bound the change in each element of the transition matrix P (Lemma [C.1\\)](#page-32-1).\n\
    - (2) Bound ∥δP∥1, the sum of the absolute values of the changes in the transition\
    \ matrix, by ∥δM∥<sup>1</sup> (Corollary [C.2\\)](#page-33-0).\n- (3) Express\
    \ S<sup>π</sup> in terms of P (Lemma [C.3\\)](#page-34-0).\n- (4) Combine these\
    \ results to obtain a bound on <sup>|</sup>δSπ<sup>|</sup> ∥δM∥<sup>1</sup> in\
    \ the case where Strans, the states from which Ssafe is reachable, is not changed\
    \ by δM (Lemma [C.4\\)](#page-34-1).\n- (5) Show that sufficiently small changes\
    \ in M cannot decrease |Strans| (Lemma [C.5\\)](#page-35-0).\n\n(6) Take the limit\
    \ as ∥δM∥<sup>1</sup> → [0 to get a bound on the local rate of decrease, handling](#page-35-1)\
    \ [the case where](#page-35-1) Strans is changed by δM.\n\n□\n\nNow we advance\
    \ to the full proof.\n\nFirst, we bound the change in transition probabilities\
    \ δP due to both the change in the environmental transition function (i.e. the\
    \ probabilities of navigating from one state to another given a certain action)\
    \ and the changes in the policy π from the state location changes (i.e. the probabilities\
    \ of selecting a certain action given a current state).\n\n<span id=\"page-32-1\"\
    ></span>![](_page_32_Figure_5.jpeg)\n\n<span id=\"page-32-0\"></span>Figure 5.\
    \ Example of constructing an MDP policy from an LLM. Note that the transitions\
    \ are split into those depending deterministically on the agent's actions (red)\
    \ and those depending entirely on the environment (blue).\n\nLemma C.1. |δPij\
    \ | ≤ <sup>1</sup> 2 ∥∇π(si)∥1|δs<sup>i</sup> | + P a |δP(s<sup>i</sup> , a, s<sup>j</sup>\
    \ )|.\n\nProof. δP depends on δM both via changes to the transition probabilities\
    \ directly and how the changes to the state locations affect the actions chosen\
    \ by π.\n\n$$\\begin{split} |\\delta P\\_{ij}| &= \\left| \\sum\\_{a} \\pi(s\\\
    _{i} + \\delta s\\_{i}, a)(P(s\\_{i}, a, s\\_{j}) + \\delta P(s\\_{i}, a, s\\\
    _{j})) - \\pi(s\\_{i}, a)P(s\\_{i}, a, s\\_{j}) \\right| \\\\ &= \\left| \\sum\\\
    _{a} \\pi(s\\_{i}, a)P(s\\_{i}, a, s\\_{j}) + |\\delta s\\_{i}|(\\nabla\\_{\\\
    delta s\\_{i}} \\pi(s\\_{i}, a))P(s\\_{i}, a, s\\_{j}) + \\pi(s\\_{i}, a)\\delta\
    \ P(s\\_{i}, a, s\\_{j}) \\right| \\\\ &+ |\\delta s\\_{i}|(\\nabla\\_{\\delta\
    \ s\\_{i}} \\pi(s\\_{i}, a))\\delta P(s\\_{i}, a, s\\_{j}) - \\pi(s\\_{i}, a)P(s\\\
    _{i}, a, s\\_{j}) \\right| \\\\ &= \\left| \\sum\\_{a} |\\delta s\\_{i}|(\\nabla\\\
    _{\\delta s\\_{i}} \\pi(s\\_{i}, a))P(s\\_{i}, a, s\\_{j}) + \\pi(s\\_{i}, a)\\\
    delta P(s\\_{i}, a, s\\_{j}) + |\\delta s\\_{i}|(\\nabla\\_{\\delta s\\_{i}} \\\
    pi(s\\_{i}, a))\\delta P(s\\_{i}, a, s\\_{j}) \\right| \\\\ &= \\left| \\sum\\\
    _{a} |\\delta s\\_{i}|(\\nabla\\_{\\delta s\\_{i}} \\pi(s\\_{i}, a))P(s\\_{i},\
    \ a, s\\_{j}) + \\pi(s\\_{i}, a)\\delta P(s\\_{i}, a, s\\_{j}) \\right| \\quad\
    \ \\text{removing the } \\delta^{2} \\text{ term.} \\end{split}$$\n\nNote that\
    \ |δs<sup>i</sup> |∇δsiπ(s<sup>i</sup> , a) is the change in the probability that\
    \ π assigns to action a when s<sup>i</sup> moves by δs<sup>i</sup> . In other\
    \ words, this is the contribution from policy change to the change in the transition\
    \ matrix. Since the sum of π over all actions must always equal 1, the sum of\
    \ these changes is 0. 0 ≤ P(s<sup>i</sup> , a, s<sup>j</sup> ) ≤ 1, so the sum\
    \ is maximized if P(s<sup>i</sup> , a, s<sup>j</sup> ) is 0 whenever the change\
    \ is negative and 1 whenever it is positive. Since the sum of all the positive\
    \ changes is half the sum of the absolute value of the changes (again since the\
    \ changes overall sum to 0), this yields\n\n$$\\leq \\frac{1}{2} \\sum\\_{a} |\\\
    delta s\\_i| |\\nabla\\_{\\delta s\\_i} \\pi(s\\_i, a)| + \\left| \\sum\\_{a}\
    \ \\pi(s\\_i, a) \\delta P(s\\_i, a, s\\_j) \\right|.$$\n\nFor the first term,\
    \ note that P a |∇<sup>δ</sup>si π(s<sup>i</sup> , a)| is precisely ∥∇<sup>δ</sup>si\
    \ π(si)∥1. For the second term, note that δP(s<sup>i</sup> , a, s<sup>j</sup>\
    \ ) is the change in the probability of transitioning from s<sup>i</sup> to s<sup>j</sup>\
    \ conditional on selecting action a. Since π(s<sup>i</sup> , a) is the probability\
    \ of selecting action a, the second sum is the environmental contribution to the\
    \ change in the transition matrix. Since π is positive and the sum over all actions\
    \ of π(s<sup>i</sup> , a) is 1, we obtain\n\n$$\\leq \\frac{1}{2} \\| |\\nabla\
    \ \\pi(s\\_i)| \\|\\_{1} |\\delta s\\_i| + \\sum\\_a |\\delta P(s\\_i, a, s\\\
    _j)|.$$\n\n<span id=\"page-33-0\"></span>Corollary C.2.\n\n$$\\|\\delta P\\|\\\
    _1 \\le \\|\\delta \\mathcal{M}\\|\\_1.$$\n\nProof. Recall that ∥δM∥<sup>1</sup>\
    \ = 1 2 ·|S|·b·∥δS∥1+∥δT∥1. Note that, by definition, ∥∇π(si)∥<sup>1</sup> ≤ b.\
    \ Sum over i, j:\n\n$$\\|\\delta P\\|\\_1 = \\sum\\_{i,j} |\\delta P\\_{ij}| \\\
    le \\sum\\_{i,j} \\frac{1}{2} \\|\\nabla \\pi(s\\_i)\\|\\_1 |\\delta s\\_i| +\
    \ \\sum\\_{i,j,a} |\\delta P(s\\_i, a, s\\_j)| \\le \\|\\delta \\mathcal{M}\\\
    |\\_1.$$\n\n□\n\nIn fact, was the reason we defined ∥δM∥<sup>1</sup> the way we\
    \ did—the system's behavior is fully described by the transition matrix given\
    \ by combining M's transition function with a policy, so the size of the change\
    \ in this transition matrix is a good candidate for a metric on M.\n\n#### <span\
    \ id=\"page-34-0\"></span>Lemma C.3.\n\n$$\\mathcal{S}\\_{\\pi} = \\Delta \\cdot\
    \ \\sum\\_{t=0}^{\\infty} (PI\\_{trans})^t P v\\_{safe}.$$\n\nProof. Let Itrans\
    \ := diag(**1**<sup>s</sup>i∈Strans ) be the matrix that acts as the identity\
    \ on Strans, the states of P from which Ssafe is reachable, and which zeroes out\
    \ all the recurrent states. Let vsafe := **1**<sup>s</sup>i∈Srec be the vector\
    \ with ones at every safe state and zeroes everywhere else. Then, ∆·(P Itrans)\
    \ t is the row vector corresponding to the probability mass in Strans at step\
    \ t, noting that we are free to apply the projection Itrans at every step rather\
    \ than just at the end because no probability mass can ever return to these states\
    \ once it has left (by construction). For convenience, we define Ptrans = P Itrans.\
    \ Right-multiplying this by P yields the distribution of the probability mass\
    \ that was still in Strans at step t after one more step. Finally, taking the\
    \ inner product with vsafe sums up the portion of this distribution that is now\
    \ in Ssafe: so each ∆ · (Ptrans) <sup>t</sup>P vsafe is the amount of probability\
    \ mass that moves into Ssafe at step t + 1. So, we can sum over all t to get the\
    \ total probability mass that moves into Ssafe. □\n\n<span id=\"page-34-1\"></span>Now\
    \ we bound the change in S<sup>π</sup> in terms of the change in P.\n\nLemma C.4.\
    \ If δM does not change Strans (i.e. for every state, it does not change whether\
    \ Ssafe is reachable from that state),\n\n$$\\frac{|\\delta \\mathcal{S}\\_{\\\
    pi}|}{||\\delta \\mathcal{M}||\\_{1}} \\leq (1 - \\lambda\\_{1})^{-1} \\left(1\
    \ + (1 - \\lambda\\_{1})^{-1}\\right) |S\\_{safe}|,$$\n\nwhere λ<sup>1</sup> is\
    \ the largest eigenvalue of Ptrans.\n\nProof. We express δS<sup>π</sup> in terms\
    \ of δP and δPtrans; the latter is well-defined because δM does not change Strans.\n\
    \n$$\\begin{aligned} \\delta \\mathcal{S}\\_{\\pi} &= \\Delta \\cdot \\sum\\_{t=0}^{\\\
    infty} (P\\_{\\text{trans}} + \\delta P\\_{\\text{trans}})^t (P + \\delta P) v\\\
    _{\\text{safe}} - \\Delta \\cdot \\sum\\_{t=0}^{\\infty} P\\_{\\text{trans}}^t\
    \ P v\\_{\\text{safe}} \\\\ &= \\Delta \\cdot \\left( \\sum\\_{t=0}^{\\infty}\
    \ (P\\_{\\text{trans}} + \\delta P\\_{\\text{trans}})^t (P + \\delta P) - \\sum\\\
    _{t=0}^{\\infty} P\\_{\\text{trans}}^t P \\right) v\\_{\\text{safe}} \\end{aligned}$$\n\
    \nWe expand to first order in δP using the binomial theorem to obtain\n\n$$=\\\
    Delta \\cdot \\left(\\sum\\_{t=0}^{\\infty} (P\\_{\\text{trans}}^t + tP\\_{\\\
    text{trans}}^{t-1}\\delta P\\_{\\text{trans}})(P + \\delta P) - \\sum\\_{t=0}^{\\\
    infty} P\\_{\\text{trans}}^t P\\right) v\\_{\\text{safe}}$$\n\nand expand and\
    \ once again remove a higher-order δP term to get\n\n$$=\\Delta \\cdot \\left(\\\
    sum\\_{t=0}^{\\infty} P\\_{\\text{trans}}^t P + P\\_{\\text{trans}}^t \\delta\
    \ P + t P\\_{\\text{trans}}^{t-1} \\delta P\\_{\\text{trans}} P - \\sum\\_{t=0}^{\\\
    infty} P\\_{\\text{trans}}^t P \\right) v\\_{\\text{safe}}$$\n\n$$\\begin{aligned}\
    \ &= \\Delta \\cdot \\left(\\sum\\_{t=0}^{\\infty} P\\_{\\text{trans}}^t \\delta\
    \ P + t P\\_{\\text{trans}}^{t-1} \\delta P\\_{\\text{trans}} P \\right) v\\_{\\\
    text{safe}}\\\\ &= \\Delta \\cdot \\left(\\left(\\sum\\_{t=0}^{\\infty} P\\_{\\\
    text{trans}}^t \\right) \\delta P + \\left(\\sum\\_{t=0}^{\\infty} t P\\_{\\text{trans}}^{t-1}\
    \ \\right) \\delta P\\_{\\text{trans}} P \\right) v\\_{\\text{safe}}\\\\ &\\dots\
    \ \\end{aligned}$$\n\nRecall that a geometric series of matrix powers P<sup>∞</sup>\
    \ <sup>t</sup>=0 A<sup>t</sup> converges to (1 − A) −1 if and only if all the\
    \ eigenvalues of the matrix are strictly less than 1. This is indeed the case\
    \ for Ptrans, since only recurrent states have eigenvalue 1. Also recall that\
    \ P<sup>∞</sup> <sup>t</sup>=1 tA<sup>t</sup>−<sup>1</sup> = (1 − A) −2 since\
    \ (1 − A) P<sup>∞</sup> <sup>t</sup>=1 tA<sup>t</sup>−<sup>1</sup> = P<sup>∞</sup>\
    \ <sup>t</sup>=1 tA<sup>t</sup>−<sup>1</sup> − P<sup>∞</sup> <sup>t</sup>=0 tA<sup>t</sup>\
    \ = P<sup>∞</sup> <sup>t</sup>=0(t + 1)A<sup>t</sup> − tA<sup>t</sup> = P<sup>∞</sup>\
    \ <sup>t</sup>=0 A<sup>t</sup> . δS<sup>π</sup> =∆ · (1 − Ptrans) −1 δP + (1 −\
    \ Ptrans) −2 δP ItransP vsafe\n\nWe will bound both of these terms. Note that\
    \ the eigenvalues of (1−Ptrans) <sup>−</sup><sup>1</sup> are <sup>1</sup> 1−λ<sup>i</sup>\
    \ where λ<sup>i</sup> are the eigenvalues of Ptrans. Since <sup>1</sup> 1−λ is\
    \ monotonically increasing in λ for λ < 1, the largest eigenvalue of (1 − Ptrans)\
    \ −1 is <sup>1</sup> 1−λ<sup>1</sup> , where λ<sup>1</sup> is the largest eigenvalue\
    \ of Ptrans. Then,\n\n$$\\begin{split} |\\delta \\mathcal{S}\\_{\\pi}| \\leq &\
    \ \\Delta \\cdot \\left( (1 - \\lambda\\_{1})^{-1} ||\\delta P||\\_{1} + (1 -\
    \ \\lambda\\_{1})^{-2} ||\\delta P||\\_{1} I\\_{\\text{trans}} P \\right) v\\\
    _{\\text{safe}} \\\\ \\leq & |\\Delta| \\left( (1 - \\lambda\\_{1})^{-1} ||\\\
    delta P||\\_{1} + (1 - \\lambda\\_{1})^{-2} ||\\delta P||\\_{1} \\right) |v\\\
    _{\\text{safe}}| \\\\ \\leq & (1 - \\lambda\\_{1})^{-1} \\left( 1 + (1 - \\lambda\\\
    _{1})^{-1} \\right) |S\\_{\\text{safe}}| ||\\delta \\mathcal{M}||\\_{1} . \\end{split}$$\n\
    \nDividing by ∥δM∥1, we obtain the desired inequality. □\n\n<span id=\"page-35-0\"\
    ></span>Now consider the case where Strans is changed by δM.\n\nLemma C.5. For\
    \ each M, ∃ ϵ > 0 with ∥δM∥<sup>1</sup> < ϵ =⇒ Strans ⊂ S ′ trans.\n\nProof. Consider\
    \ a state s from which Ssafe was reachable in M. Let P<sup>s</sup> be the probability\
    \ that an agent eventually transitions to Ssafe from s. By continuity of Ps, for\
    \ ∥δM∥<sup>1</sup> < ϵ<sup>s</sup> small enough, P<sup>s</sup> will still be positive\
    \ in M′ . Taking the minimum ϵ<sup>s</sup> over all s the result follows.[5](#page-35-2)\
    \ Note that S ′ trans may strictly contain Strans: a small perturbation may cause\
    \ Ssafe to be reachable from a state s, e.g. by adding a transition directly from\
    \ s to Ssafe. □\n\n<span id=\"page-35-1\"></span>Finally, we may conclude the\
    \ proof of lower semicontinuity with bounded rate of decrease by combining Lemma\
    \ [C.4](#page-34-1) with Lemma [C.5.](#page-35-0) Note that if S ′ trans > Strans,\
    \ Lemma [C.4](#page-34-1) still provides a lower bound on the safety: if s ′ ∈\
    \ S ′ trans \\ Strans, then Ptrans + δPtrans to excludes entries corresponding\
    \ to s ′ . Thus, any probability flow that goes through s ′ is not included in\
    \ the bound on safety. Therefore, the true value of S<sup>π</sup> accounting for\
    \ s ′ can only increase from the lower bound from [C.4.](#page-34-1) Therefore,\
    \ we can use Lemma [C.5](#page-35-0) to obtain ϵ > 0 such that\n\n$$\\|\\delta\
    \ \\mathcal{M}\\|\\_1 < \\epsilon \\implies -\\frac{\\delta \\mathcal{S}\\_\\\
    pi}{\\|\\delta \\mathcal{M}\\|\\_1} \\le \\left(1 - \\lambda\\_1\\right)^{-1}\
    \ \\left(1 + \\left(1 - \\lambda\\_1\\right)^{-1}\\right) \\|S\\_{\\text{safe}}\\\
    |\\_\\ast$$\n\n<span id=\"page-35-2\"></span><sup>5</sup>The requirement that\
    \ M and M′ be close enough that there are no nonzero transitions of M which become\
    \ 0 in M′ suggests the possibility of using KL divergence to compare the transition\
    \ functions, since DKL(P∥Q) is infinite if Q lacks support somewhere P does have\
    \ support. This may be interesting to apply to scenarios like RLHF on a base model,\
    \ where the KL divergence is estimated and constrained during training.\n\n##\
    \ C.3. Proof of Proposition [6.6](#page-17-0)\n\n<span id=\"page-36-0\"></span>Proof.\
    \ By Lemma [C.3,](#page-34-0) S<sup>π</sup> = ∆ · P<sup>∞</sup> <sup>t</sup>=0(P\
    \ Itrans) <sup>t</sup>P vsafe. Since S<sup>π</sup> is a linear function of ∆,\
    \ it is continuous in ∆; in fact, it is uniformly continuous:\n\n$$\\begin{aligned}\
    \ |\\mathcal{S}'\\_{\\pi} - \\mathcal{S}\\_{\\pi}| &= \\left| (\\Delta' - \\Delta)\
    \ \\cdot \\sum\\_{t=0}^{\\infty} (PI\\_{\\text{trans}})^t P v\\_{\\text{safe}}\
    \ \\right| \\\\ &\\le \\|\\delta \\Delta\\|\\_{2} \\left\\| \\sum\\_{t=0}^{\\\
    infty} (PI\\_{\\text{trans}})^t P v\\_{\\text{safe}} \\right\\|\\_{2} \\\\ &\\\
    le \\|\\delta \\Delta\\|\\_{2}, \\end{aligned}$$\n\n<span id=\"page-36-1\"></span>which\
    \ is independent of M. (This also holds for ∥∥<sup>1</sup> and other reasonable\
    \ norms for δ∆.) □\n\n# Appendix D. Discussion: Lower hemicontinuity\n\n## D.1.\
    \ Definition\n\nHemicontinuity generalizes semicontinuity to set-valued functions.\
    \ A lower semicontinuous function must increase only gradually (but may suddenly\
    \ decrease); a lower hemicontinuous function must move from a point only gradually\
    \ (but may suddenly add new points).\n\nDefinition D.1. [\\[Aliprantis and Border,\
    \ 2007\\]](#page-19-7). A function Γ : A → 2 <sup>B</sup> is lower hemicontinuous\
    \ at a if for any open V ⊆ 2 <sup>B</sup> with Γ(a) ∩ V ̸= ∅ there is a neighbourhood\
    \ U of a so that x ∈ U =⇒ Γ(x) ∩ V ̸= ∅.\n\nThe image of M under the functions\
    \ F<sup>δ</sup> and F ′ <sup>π</sup> below represents M's region of safety. Lower\
    \ hemicontinuity means that, as M changes, the safe region can recede only gradually,\
    \ but may suddenly expand to new areas.\n\nD.2. F<sup>δ</sup> (defined in section\
    \ [7.1,](#page-17-1) item [1\\)](#page-17-2) is lower hemicontinuous\n\nLet M\
    \ be an MDP and V ⊆ **R**<sup>≥</sup><sup>0</sup> ×[0, 1] be an open set with\
    \ Fδ(M)∩V ̸= ∅. Let (N, ε) ∈ Fδ(M) ∩ V . Since V is an open set, there are some\
    \ η1, η<sup>2</sup> > 0 so that (N + η2, ε − η1) ∈ V . Now, let U be the ball\
    \ centered at M with radius δ(η1, η2) as in remark [5.9.](#page-11-1) Then we\
    \ apply theorem [5.7](#page-11-0) to find that every M′ ∈ U is (N +η2, ε−η1)-safe,\
    \ i.e. (N +η2, ε−η1) ∈ Fδ(M′ ); thus, Fδ(M′ ) ∩ V ̸= ∅ for all M′ ∈ U, so F<sup>δ</sup>\
    \ is lower hemicontinuous, as desired.\n\nD.3. F ′ π (defined in section [7.1,](#page-17-1)\
    \ item [2\\)](#page-17-3) is lower hemicontinuous\n\nThe proof is extremely similar\
    \ to that for Fδ. Let M be an MDP and V ⊆ **P**(SM) × [0, 1] be an open set with\
    \ F ′ π (M) ∩ V ̸= ∅. Let (∆, p) ∈ F′ π (M) ∩ V . Since V is an open set, there\
    \ is some 0 < η < p so that (∆, p − η) ∈ V . Now, let U be the ball centered at\
    \ M with radius min ϵ, η B(M) , where ϵ and B(M) are as in theorem [6.5.](#page-16-0)\
    \ Then we apply theorem [6.5](#page-16-0) to find that every M′ ∈ U has − Sπ(M′\
    \ ,∆)−Sπ(M,∆) db(M′ ,M) < B(M). Then db(M′ ,M) < η <sup>B</sup>(M) =⇒ −Sπ(M′ ,\
    \ ∆) + Sπ(M, ∆) < η and p ≤ Sπ(M, ∆) =⇒ p−η < Sπ(M′ , ∆). Thus (∆, p − η) ∈ F′\
    \ π (M′ ) ∩ V , so F ′ π is lower hemicontinuous, as desired."
  decisions:
    evaluation_prompt: 'Qualified. Reason: The abstract discusses the evaluation of
      AI agent safety in different settings, mentions the use of a bisimulation metric
      on MDPs, and describes quantitative bounds related to the probability of not
      shutting down, indicating structured evaluation through empirical or experimental
      methods.'
    related_work_prompt: 'Disqualified: no related work. Reason: The abstract and
      introduction do not mention or reference any prior research, methods, or findings,
      nor do they compare their work to existing literature in the field.'
    novelty_prompt: 'Qualified. Reason: The abstract presents a novel investigation
      into the safety of AI agents in different settings, specifically focusing on
      the stability of not resisting shutdown in Markov decision processes. It claims
      new contributions by modeling agents and providing proofs regarding safety stability
      and bounds on shutdown probabilities, indicating a clear claim of novelty in
      the research.'
    review_only_prompt: '- Qualified. Reason: The paper proposes new methods and results
      related to AI safety in different settings, specifically focusing on power-seeking
      behaviors and their implications in Markov decision processes.'
  llm_input_used: '## Abstract

    We investigate the question: if an AI agent is known to be safe in one

    setting, is it also safe in a new setting similar to the first? This is a core

    question of AI alignment--we train and test models in a certain environment,

    but deploy them in another, and we need to guarantee that models that seem safe

    in testing remain so in deployment. Our notion of safety is based on

    power-seeking--an agent which seeks power is not safe. In particular, we focus

    on a crucial type of power-seeking: resisting shutdown. We model agents as

    policies for Markov decision processes, and show (in two cases of interest)

    that not resisting shutdown is "stable": if an MDP has certain policies which

    don''t avoid shutdown, the corresponding policies for a similar MDP also don''t

    avoid shutdown. We also show that there are natural cases where safety is _not_

    stable--arbitrarily small perturbations may result in policies which never shut

    down. In our first case of interest--near-optimal policies--we use a

    bisimulation metric on MDPs to prove that small perturbations won''t make the

    agent take longer to shut down. Our second case of interest is policies for

    MDPs satisfying certain constraints which hold for various models (including

    language models). Here, we demonstrate a quantitative bound on how fast the

    probability of not shutting down can increase: by defining a metric on MDPs;

    proving that the probability of not shutting down, as a function on MDPs, is

    lower semicontinuous; and bounding how quickly this function decreases.


    '
  token_usage: 2415
  time_usage: 4.751288414001465
- title: "A Universal Knowledge Model and Cognitive Architecture for Prototyping\n\
    \  AGI"
  abstract: 'The article identified 42 cognitive architectures for creating general

    artificial intelligence (AGI) and proposed a set of interrelated functional

    blocks that an agent approaching AGI in its capabilities should possess. Since

    the required set of blocks is not found in any of the existing architectures,

    the article proposes a new cognitive architecture for intelligent systems

    approaching AGI in their capabilities. As one of the key solutions within the

    framework of the architecture, a universal method of knowledge representation

    is proposed, which allows combining various non-formalized, partially and fully

    formalized methods of knowledge representation in a single knowledge base, such

    as texts in natural languages, images, audio and video recordings, graphs,

    algorithms, databases, neural networks, knowledge graphs, ontologies, frames,

    essence-property-relation models, production systems, predicate calculus

    models, conceptual models, and others. To combine and structure various

    fragments of knowledge, archigraph models are used, constructed as a

    development of annotated metagraphs. As components, the cognitive architecture

    being developed includes machine consciousness, machine subconsciousness,

    blocks of interaction with the external environment, a goal management block,

    an emotional control system, a block of social interaction, a block of

    reflection, an ethics block and a worldview block, a learning block, a

    monitoring block, blocks of statement and solving problems, self-organization

    and meta learning block.'
  url: http://arxiv.org/abs/2401.06256v3
  keywords: ''
  document: "# **A Universal Knowledge Model and Cognitive Architecture for Prototyping\
    \ AGI**\n\nArtem Sukhobokov1[0000-0002-1370-6905] , Evgeny Belousov2[0009-0002-5335-9167]\
    \ , Danila Gromozdov2[0009-0007-2342-6046] , Anna Zenger3[0009-0007-9909-755X]\
    \ , and Ilya Popov2\\*[0009-0007-2226-9640]\n\n SAP America, Inc. 3999 West Chester\
    \ Pike, Newtown Square, PA 19073, USA Bauman Moscow State Technical University,\
    \ 2-nd Baumanskaya 5, Moscow 105005, Russian Federation OZON Marketplace Kazakhstan\
    \ LLP, Al-Farabi avenue 77/7, Bostandyk district, Almaty\n\n050040, Kazakhstan\n\
    \nlink.s.twink@gmail.com\n\n**Abstract.** The article identified 42 cognitive\
    \ architectures for creating general artificial intelligence (AGI) and proposed\
    \ a set of interrelated functional blocks that an agent approaching AGI in its\
    \ capabilities should possess. Since the required set of blocks is not found in\
    \ any of the existing architectures, the article proposes a new cognitive architecture\
    \ for intelligent systems approaching AGI in their capabilities. As one of the\
    \ key solutions within the framework of the architecture, a universal method of\
    \ knowledge representation is proposed, which allows combining various non-formalized,\
    \ partially and fully formalized methods of knowledge representation in a single\
    \ knowledge base, such as texts in natural languages, images, audio and video\
    \ recordings, graphs, algorithms, databases, neural networks, knowledge graphs,\
    \ ontologies, frames, essence-property-relation models, production systems, predicate\
    \ calculus models, conceptual models, and others. To combine and structure various\
    \ fragments of knowledge, archigraph models are used, constructed as a development\
    \ of annotated metagraphs. As components, the cognitive architecture being developed\
    \ includes machine consciousness, machine subconsciousness, blocks of interaction\
    \ with the external environment, a goal management block, an emotional control\
    \ system, a block of social interaction, a block of reflection, an ethics block\
    \ and a worldview block, a learning block, a monitoring block, blocks of statement\
    \ and solving problems, self-organization and meta learning block.\n\n**Keywords:**\
    \ Cognitive architecture, AGI, Metagraph, Archigraph, Universal knowledge model,\
    \ Machine consciousness, Machine subconsciousness, Machine reflection, Machine\
    \ worldview.\n\n## **1 Introduction**\n\nIn recent years, there has been a rapid\
    \ and multidirectional development of intelligent information systems developed\
    \ by people [1]. In [2], it was assumed that a relatively distant extrapolation\
    \ of the functionality of these developments would be the creation of a general\
    \ artificial intelligence comparable to human intelligence (in current terminology\
    \ – AGI). The main capabilities of an intelligent information system, such as\
    \ perceptual abilities, attention mechanisms, choice of actions, learning, memory,\
    \ reasoning and their practical application are determined by the cognitive architecture\
    \ used in the system [3]. If we consider the basic principles of functioning,\
    \ then cognitive architectures are the opposite of expert systems. Expert systems\
    \ provide solutions to intellectual tasks in a narrowly defined context, in the\
    \ segment of activity for which they have knowledge, in contrast, cognitive architectures\
    \ aim to providing a wide coverage, solving a diverse set of tasks in different\
    \ fields. More importantly, cognitive architectures provide intelligent behavior\
    \ at the system level, rather than at the level of methods of individual components\
    \ designed to solve specialized tasks [3].\n\nIn 2016-18, after a relatively long\
    \ break, two reviews of cognitive architectures were published [4, 5] (the third\
    \ version of the publication [4], like the publication [5], appeared in 1918).\
    \ After that, no systematic reviews were published until preparation of this article.\
    \ Only brief reviews were published as part of the justification for the need\
    \ to develop new architectures. In these two reviews, which cover about 140 architectures,\
    \ we identified cognitive architectures designed to create AGI, and supplemented\
    \ the list with the results of a bibliographic search.\n\nUnlike the reviews in\
    \ [6,7], the authors of which considered cognitive architectures for creating\
    \ AGI, including architectures that were not intended for this purpose in the\
    \ review, we consider it important to analyze precisely cognitive architectures\
    \ that are declared as architectures intended for creating AGI, since additional\
    \ requirements are imposed on them [8]. Other cognitive architectures could be\
    \ developed to test some technical solutions or to solve more utilitarian tasks,\
    \ for example, for image processing or controlling a transport robot transporting\
    \ workpieces in the workshop.\n\nIn the list of cognitive architectures, if the\
    \ architecture does not have a name, it will be presented simply with a link to\
    \ the publication. The final list of cognitive architectures for analysis includes\
    \ 42 architectures, presented in Table 1. For each architecture, this table contains\
    \ citations indicating that the architecture is intended to enable AGI. For some\
    \ architectures, publications do not explicitly mention AGI as a target. In these\
    \ cases, the decision to include in the list is determined by the goals of the\
    \ architecture to model human-like behavior or by focusing on the complex of functions\
    \ inherent with humans.\n\n| # | Name  | Link(s) | Citations about purpose of\
    \ cognitive architecture                                                     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                              |\n|---|-------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | 1 | Soar  | [9]     | Soar … have used … to build complex integrated AI agents,\
    \ and to create<br>detailed models of human behavior. … We have found that combining\
    \ what<br>is known in psychology, in neuroscience, and in AI is an effective approach<br>to\
    \ building a comprehensive cognitive architecture. … Our bet is that achiev<br>ing\
    \ human-level intelligence is a long path of incremental experiments, dis<br>coveries,\
    \ tests, reformulations and refinements. |\n| 2 | ACT-R | [10]    | This paper\
    \ explores requirements on cognitive architectures for artificial gen<br>eral\
    \ intelligence. The goal of the analysis is to determine the requirements for<br>cognitive\
    \ architectures that support the full-range of human-level intelligent<br>behavior.\
    \                                                                            \
    \                                                                            \
    \                           |\n\n**Table 1.** Cognitive architectures aimed to\
    \ create AGI, and author citations confirming this.\n\n| 3  | NARS           \
    \                       | [11]    | … system aimed at the realization of Artificial\
    \ General Intelligence (AGI).                                                \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                        |\n|----|---------------------------------------|---------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | 4  | LIDA                                  | [12]    | … we  argue that Learning\
    \ Intelligent Distribution Agent (LIDA) … may<br>be suitable as an underlying\
    \ cognitive architecture on which others might<br>build an AGI.              \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                              |\n| 5  | Haikonen<br>cognitive<br>architecture\
    \ | [13]    | The author visions autonomous robots that perceive and understand\
    \ the world<br>and act in it in a natural way, without programs and numerical\
    \ representation<br>of information. This approach considers the cognitive machine\
    \ as a system<br>that is seamlessly interactive, both internally and externally,\
    \ in respect to its<br>environment and experience. This approach should result\
    \ in robots that know<br>and understand what they are doing and why, robots that\
    \ can plan and imagine<br>their actions and the possible outcome of these. Robots\
    \ that exhibit properties<br>like these are said to possess machine consciousness,\
    \ which may or may not<br>have common deeper properties with animal and human\
    \ consciousness.                                                             \
    \                                                              |\n| 6  | SiMA<br>(previously<br>ARS)\
    \           | [14]    | … most of humans' behaviour is covered by every-day capabilities.\
    \ … our<br>experience with the cognitive architecture SiMA showed that – especially<br>when\
    \ the foundations of the human mind are at stake – every-day behaviour<br>is more\
    \ suitable to analyse the basic functions of the human mind.                 \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                |\n| 7  | Sigma\
    \                                 | [15]    | We … expect that a system capable\
    \ of artificial general intelligence (AGI)<br>would provide natural support for\
    \ Theory of Mind. We are interested here in<br>how Theory of Mind capabilities\
    \ may be realized within Sigma (Σ), a nascent<br>cognitive system—an integrated\
    \ computational model of intelligent behav<br>ior— that is grounded in a cognitive\
    \ architecture, a model of the fixed struc<br>ture underlying a cognitive system.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                        |\n| 8  |                                       | [16]\
    \    | The platform used as an specific domain for the initial experiments is\
    \ the iCub<br>humanoid robot simulator, but the architecture is built so it can\
    \ be applied to<br>different platforms and applications. This platform was chosen\
    \ because it pro<br>vides a \"Human-Like\" architectural level …             \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                         |\n\
    | 9  | CogPrime                              | [17,18] | Part 1 of the book …\
    \ sketches the broad outlines of a novel, integrative archi<br>tecture for Artificial\
    \ General Intelligence (AGI) called CogPrime …<br>Part 2 of the book concludes\
    \ with a chapter summarizing the argument that<br>CogPrime can lead to human-level\
    \ (and eventually perhaps greater) AGI …                                     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                     |\n|    | 10 Ikon Flux                 \
    \         | [19,20] | Ikon Flux is a fully implemented prototypical architecture\
    \ for self-program<br>ming systems - a prototype being an abstract type to be\
    \ instantiated in a con<br>crete domain. … A system continuously modeling its\
    \ own operation has to do<br>so at multiple levels of abstraction, from the program\
    \ rewriting up to the level<br>of global processes (e.g. the utility function),\
    \ thus turning eventually into a<br>fully self-modeling system. ,,, We believe\
    \ peewee granularity is a promising<br>way to simplify operational semantics and\
    \ reach a computational homogene<br>ity that can enable automated architectural\
    \ growth – which in itself is a nec<br>essary step towards scaling of cognitive\
    \ skills exhibited by current state-of<br>the-art architectures. Only this way\
    \ will we move more quickly towards arti<br>ficial general intelligence. |\n|\
    \ 11 | eBICA                                 | [21,22] | This work continues the\
    \ effort to design and test the cognitive architecture<br>eBICA: a general model\
    \ of emotionally biased behavior control and decision<br>making, with the focus\
    \ on social emotional relationships. … We also pre<br>sented the study of an implemented\
    \ Virtual Actor based on the eBICA model.<br>… The overall conclusion is that\
    \ the implemented Virtual Actor performs at<br>a human level.                \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                |\n| 12 | D-LANCA                           \
    \    | [7]     | This work suggests a novel approach to autonomous systems development<br>linking\
    \ autonomous technology to an integrated cognitive architecture with<br>the aim\
    \ of supporting a common artificial general intelligence (AGI) devel<br>opment.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                               |\n| 13 | ICOM\
    \                                  | [23]    | This paper articulates the methodology\
    \ and reasoning for how biasing in the<br>Independent Core Observer Model (ICOM)\
    \ Cognitive Architecture for Arti<br>ficial General Intelligence (AGI) is done.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                            |\n\n| 14 |          | [24]    | We consider a task-oriented\
    \ approach to AGI, when any cognitive problem,<br>perhaps superior to human ability,\
    \ has sense given a criterion of its solution.                               \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                             |\n|----|----------|---------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | 15 | LIS      | [25]    | … the LIS Framework … provides a way to approach AGI\
    \ learning in a flex<br>ible and easy-to-use manner by combining multiple, interchangeable\
    \ compo<br>nents. The framework allows AGI workers including beginners to combine<br>pre-installed\
    \ LIS Framework components and begin AGI development with<br>ease.           \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                     |\n| 16 |          | [26]\
    \    | This paper is concerned with artificial general intelligence (AGI). Our\
    \ ulti<br>mate goal is to create a computational model that may operate in any\
    \ environ<br>ment and develop intelligence adapted to that environment in a fully\
    \ auto<br>matic fashion.                                                     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                               |\n| 17 | MBCA\
    \     | [27]    | The biologically inspired Meaningful-Based Cognitive Architecture\
    \ (MBCA)<br>integrates the sensory processing abilities found in neural networks\
    \ with many<br>of the symbolic logical abilities found in human cognition. … MBCA\
    \ can<br>functionally produce a variety of behaviors which can help to better\
    \ hypothe<br>size and understand mammalian cortical function, and provide insight\
    \ into<br>possible mechanisms which link such mesoscopic functioning to the causal<br>and\
    \ symbolic behavior seen in humans.                                          \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                   |\n| 18 |          | [28]\
    \    | We introduce an AGI, in the form of cognitive architecture, which is based\
    \ on<br>Global Workspace Theory (GWT).                                       \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                 |\n| 19 | PySigma\
    \  | [29]    | The Sigma cognitive architecture is the beginning of an integrated\
    \ computa<br>tional model of intelligent behavior aimed at the grand goal of artificial\
    \ gen<br>eral intelligence (AGI). However, whereas it has been proven to be capable<br>of\
    \ modeling a wide range of intelligent behaviors, the existing implementation<br>of\
    \ Sigma has suffered from several significant limitations.  In this article,<br>we\
    \ propose solutions for this limitation  The resulting design changes con<br>verge\
    \ on a more capable version of the architecture called PySigma.              \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                   |\n| 20 |          | [30]    | In general,\
    \ neuromorphic computing and cognitive modeling are two promis<br>ing approaches\
    \ to achieve AGI. … Our motivation is to provide a generic<br>methodology bridging\
    \ the computation theory with the underlying implemen<br>tation at the algorithm\
    \ level.                                                                     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                         |\n| 21 | GLAIR    | [31]    | GLAIR\
    \ (Grounded Layered Architecture with Integrated Reasoning) is a mul<br>tilayered\
    \ cognitive architecture for embodied agents operating in real, virtual,<br>or\
    \ simulated environments containing other agents. … The motivation for the<br>development\
    \ of GLAIR has been \"Computational Philosophy\", the computa<br>tional understanding\
    \ and implementation of human-level intelligent behavior<br>without necessarily\
    \ being bound by the actual implementation of the human<br>mind.             \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                 |\n| 22 |          | [32,33] | I'll be using\
    \ the term my cognitive system, cognitive architecture, artificial<br>general\
    \ intelligence, and AGI interchangeably.                                     \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                  |\n| 23 | H-CogAff | [34] \
    \   | H-CogAff, a special case of CogAff, is postulated as a minimal architecture<br>specification\
    \ for a human-like system.                                                   \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                               |\n| 24 |          | [35]    |\
    \ Our approach is to use a functional core to simulate the development of cog<br>nitive\
    \ functions of autonomous agents. … The most important goal in the field<br>of\
    \ AGI is the development of control systems for cognitive agents, which, in<br>terms\
    \ of their intellectual performance, are not inferior, and perhaps even sur<br>pass\
    \ humans. Developmental psychology studies show that the most signifi<br>cant\
    \ changes in Innenwelt occur at the sensorimotor stage, which is the first<br>in\
    \ the postnatal ontogenesis. … . According to Piaget, this period of develop<br>ment\
    \ is one of the most important in the creation of human mental abilities.<br>The\
    \ proposed architecture makes it possible to simulate the process of evolu<br>tion\
    \ of cognitive abilities, including the stage of sensorimotor development of<br>autonomous\
    \ agents. |\n| 25 | EM-ONE   | [36]    | The design of EM-ONE draws heavily on\
    \ Minsky's Emotion Machine archi<br>tecture hence the name EM-ONE … I have also\
    \ drawn ideas from Sloman's                                                  \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                        |\n\n|    |           |      | H-CogAff architecture,\
    \ which resembles Minsky's architecture in many re<br>spects … Both Minsky and\
    \ Sloman developed their architectures to provide<br>rich frameworks with which\
    \ to explain the diversity of complex and subtle<br>aspects of human cognition,\
    \ especially our capacity for common sense and<br>our variety of emotions. … My\
    \ goal with EM-ONE is primarily to support<br>more intricate forms of reflective\
    \ commonsense thinking, although in the long<br>run I hope it will help to explain\
    \ a broader array of types of thinking including<br>such feelings as love, confusion,\
    \ anger, and hope.                                                           \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                          |\n\
    |----|-----------|------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | 26 |           | [37] | The article describes the author's proposal on cognitive\
    \ architecture for the<br>development of a general-level artificial intelligent\
    \ agent («strong» artificial<br>intelligence).                               \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                             |\n| 27 | CAMAL\
    \     | [38] | With the distributed model specific agents can change The distributed\
    \ agent<br>requests those elements of itself (i.e. its component agents) that\
    \ are associated<br>with the current learning task to modify themselves.  Currently\
    \ we are look<br>ing at the nature of communication between agents with shared\
    \ motivations<br>and are using distributed blackboards.  We have designed and\
    \ implemented<br>agents that display motivational qualities and address important\
    \ questions<br>about the nature of emotion and autonomy.  We have demonstrated\
    \ emotive<br>qualities in our research agents.  compromises can lead to the design\
    \ of<br>agent systems with inherent conflicts.  By designing agents with the quali<br>ties\
    \ described in this chapter an agent is given the means to represent and<br>reason\
    \ about these conflicts when they do arise. This research continues to<br>raises\
    \ questions about what agent is, what a mind is, and what are emotion<br>and motivation.\
    \ |\n| 28 | SMCA      | [39] | Artificial Intelligence originated with the desire\
    \ to develop artificial minds<br>capable of performing or behaving like an animal\
    \ or person.  Cognitive ar<br>chitectures are designed to be capable of performing\
    \ certain behaviours and<br>functions based on our understanding of human and\
    \ non human minds.  de<br>veloping SMCA (Society of Mind Cognitive Architecture)\
    \ can be viewed<br>from the perspective of Minsky, which leads to the development\
    \ of many dif<br>ferent types of simple agents, with different behaviours. Metacognition\
    \ is use<br>ful for framing the constraints for this swarm intelligence. Swarm\
    \ intelligence<br>requires the inclusion of a mathematical theory of how the group\
    \ of agents<br>work together to achieve a common goal. Swarm intelligence uses\
    \ different<br>mathematical algorithms so as to cover all processing and functioning\
    \ associ<br>ated with the adopted architecture or mind model.                \
    \                            |\n| 29 | MicroPSI  | [40] | This book is completely\
    \ dedicated to understanding the functional workings<br>of intelligence and the\
    \ mechanisms that underlie human behavior by creating<br>a new cognitive architecture.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \         |\n| 30 | LISA      | [41] | Human mental representations are both flexible\
    \ and structured – properties<br>that, together, present challenging design requirements\
    \ for a model of human<br>thinking. The Learning and Inference with Schemas and\
    \ Analogies (LISA)<br>model of analogical reasoning aims to achieve these properties\
    \ within a neural<br>network.                                                \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                     |\n| 31 | CIT       | [42]\
    \ | The paper proposes a novel cognitive architecture that combines cognitive<br>computing\
    \ and cognitive agent technologies for performing human-like func<br>tionality.\
    \ The system architecture is known as CIT (Cognitive Information<br>Technology).\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                            |\n| 32 | Companion | [43] | The Companion cognitive\
    \ architecture is aimed at reaching human-level AI<br>by creating software social\
    \ organisms – systems that interact with people us<br>ing natural modalities,\
    \ working and learning over extended periods of time as<br>collaborators rather\
    \ than tools.                                                                \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \              |\n| 33 |           | [44] | The paper proposes a novel cognitive\
    \ architecture for computational creativ<br>ity based on the Psi model and on\
    \ the mechanisms inspired by dual process<br>theories of reasoning and rationality.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \ |\n\n| 34 | Polyscheme [45] |      | This thesis describes a new framework for\
    \ understanding and creating human<br>level intelligence by integrating multiple\
    \ representation and inference<br>schemes.                                   \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \  |\n|----|-----------------|------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n\
    | 35 |                 | [46] | We present a three level Cognitive architecture\
    \ for the simulation of human<br>behaviour based on Stanovich's tripartite framework.\
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                   |\n| 36 |\
    \ Clarion         | [47] | The goal of this work is to develop a unified framework\
    \ for understanding the<br>human mind, and within the unified framework to develop\
    \ process-based,<br>mechanistic explanations of a substantial variety of psychological\
    \ phenom<br>ena.                                                             \
    \                                                                            \
    \                                                                            \
    \                                                     |\n| 37 | Oscar        \
    \   | [48] | The basic observation that motivates the OSCAR architecture is that\
    \ agents<br>of human-level intelligence operating in an environment of real-world\
    \ com<br>plexity (henceforth, GIAs — \"generally intelligent agents\") must be\
    \ able to<br>form beliefs and make decisions against a background of pervasive\
    \ ignorance.                                                                 \
    \                                                                            \
    \                                                   |\n| 38 | OntoAgent      \
    \ | [49] | This paper presents an overview of a cognitive architecture, OntoAgent,\
    \ that<br>supports the creation and deployment of intelligent agents capable of\
    \ simulat<br>ing human-like abilities.                                       \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                 |\n| 39 | INKA            |\
    \ [50] | Artificial intelligence research is now flourishing which aims at achieving<br>general,\
    \ human-level intelligence. Accordingly, cognitive architectures are<br>increasingly\
    \ employed as blueprints for building intelligent agents to be en<br>dowed with\
    \ various perceptive and cognitive abilities. This paper presents a<br>novel integrated\
    \ neuro-cognitive architecture (INCA) which emulate the pu<br>tative functional\
    \ aspects of various salient brain sub-systems via a learning<br>memory modeling\
    \ approach. |\n| 40 | ISAAC           | [51] | A foundational component of an\
    \ ISAAC processing framework is the concept<br>of \"mixture of experts\" architecture\
    \ and methodology, similar to a human<br>brain.                              \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \          |\n| 41 |                 | [52] | This article provides an analytical\
    \ framework for how to simulate human-like<br>thought processes within a computer.\
    \  Iterative updating is conceptualized<br>here as an information processing strategy,\
    \ a model of working memory, a<br>theory of consciousness, and an algorithm for\
    \ designing and programming<br>artificial general intelligence.              \
    \                                                                            \
    \                                                                       |\n| 42\
    \ | Aigo            | [53] | Here we outline an architecture and development plan,\
    \ together with some<br>preliminary results, that offers a much more direct path\
    \ to full Human-Level<br>AI (HLAI) / AGI.                                    \
    \                                                                            \
    \                                                                            \
    \                                                                            \
    \                                                                  |\n\nWhen analyzing\
    \ the architectures, the following functional components were identified:\n\n\
    - Consciousness for agent management in real time;\n- Subconscious mind for performing\
    \ routine operations;\n- Goal management;\n- Emotional management;\n- Formation\
    \ and application of ethical assessments;\n- Monitoring;\n- Training;\n- Social\
    \ interaction;\n- Reflection;\n- Setting tasks;\n- Problem solving;\n- Self-development\
    \ and meta-learning;\n- Formation and use of a worldview;\n- Multimodal receipt\
    \ of information from the external environment;\n- Multimodal delivery of information\
    \ to the external environment;\n- Control of movement organs and manipulators.\n\
    \nThe listed set of functions is an extension of the set used in [53], however,\
    \ such an extension is justified, since a deeper understanding of many aspects\
    \ has emerged over the past time. If we really want to see artificial intelligence\
    \ comparable to human intelligence, all these functions are necessary for it.\
    \ As ten years ago, in a study by Alexey Samsonovich [54], all existing cognitive\
    \ architectures were acclaimed as limited, we could not find more than 60% of\
    \ the necessary functions anywhere. This served as a prerequisite for the development\
    \ of a new cognitive architecture, which will have the necessary functionality.\n\
    \nIn 2019, a cognitive architecture was proposed, which is a very general sketch\
    \ of the AGI structure [55], annotated metagraphs were used to represent knowledge\
    \ in the architecture [56]. Later in [57], an approach was proposed on how to\
    \ create intelligent information systems based on this architecture, including\
    \ individual components from the AGI composition. Due to the rapid progress of\
    \ research in areas such as metagraphs, machine ethics, machine emotions, machine\
    \ thinking, there is a need to reconsider this previously developed cognitive\
    \ architecture. The need to develop a new cognitive architecture was the reason\
    \ to reflect all the necessary functionality in the second version of this architecture.\n\
    \n### **2 Material and Methods**\n\nDuring the work, materials from several hundred\
    \ scientific publications were used, the most significant of which are listed\
    \ in the list of references. We often discussed which of several publications\
    \ on the same topic to indicate in the link, and tried to bring the one that most\
    \ fully reflects the information or more clearly sets out the material. Two publications\
    \ in the same link were listed together under different numbers if they significantly\
    \ complement each other.\n\nAnother important source of materials for the article\
    \ was our own activities. After all, we are designing AGI, and it should be able\
    \ to do a lot of things that a human can. Therefore, we analyzed our daily actions\
    \ and listened to ourselves sensitively, trying to understand how we work with\
    \ knowledge, and what functional components should be present as part of the cognitive\
    \ architecture of AGI.\n\n### **3 Results**\n\nIn the process of the research,\
    \ a preliminary design of a knowledge base has been developed that will be able\
    \ to operate with any forms of knowledge representation. Using it, a preliminary\
    \ design of a cognitive architecture has been developed, based on which AGI prototypes\
    \ can be created.\n\n### **3.1 The Universal Knowledge Model**\n\n#### **3.1.1\
    \ Archigraph as the Foundation of a Universal Model of Knowledge**\n\nThe basis\
    \ of cognitive architecture is the representation of knowledge. Like a human,\
    \ an agent must be able to work with different forms of knowledge and switch from\
    \ one to another. In [58], a universal data model was proposed that allows storing\
    \ data in a data lake structured according to different data models: relational,\
    \ multidimensional, graph, and others. For this purpose, the metagraph data model\
    \ based on annotated metagraphs has been expanded through the use of protographs\
    \ and archigraphs [59,60]. The annotated metagraph proposed in [61,62], but at\
    \ first did not have such a name, is characterized by the following properties:\n\
    \n- The structure of the metagraph includes, in addition to the usual edges and\
    \ vertices, metaedges and metavertices;\n- Each vertex, edge, metavertex and metaedge\
    \ is characterized by a set of attributes that have a name and value;\n- Metavertices\
    \ and metaedges differ from ordinary edges and vertices in that they can contain\
    \ fragments of a metagraph inside themselves, which by their properties also represent\
    \ metagraphs;\n- The contents of various metavertices and metaedges can overlap\
    \ up to complete equivalence (that is why the term annotated metagraph is used,\
    \ that some meta-objects can annotate others [63]);\n- The boundaries of the metavertices\
    \ and metaedges are permeable to edges and metaedges to any nesting depth.\n\n\
    A protograph can be considered as a graph that has no edges. The role of edges\
    \ is performed by the adjacent vertices to each other. The protograph P is defined\
    \ by the set of elements {pi}, i = 1, n and the neighborhood matrix Mn×n consisting\
    \ of 0 and 1, where 1 means the neighborhood (adjacency) of element a to element\
    \ b. Examples of protographs are: stack, queue, table, figures of the game \"\
    Life\". An example of an infinite protograph is the tape of a Turing machine.\
    \ Ordinary graphs are protographs in which elements are divided into two classes\
    \ of elements and the rule applies that elements of the same class cannot be adjacent.\n\
    \nIn the archigraphs, the elements belong to more than two classes. The number\
    \ of classes into which the elements are divided is the most important characteristic\
    \ of an archigraph. The concept of an archigraph makes it possible to systematize\
    \ various definitions of metagraphs. Annotated metagraphs are archigraphs with\
    \ five classes of elements: vertices, metavertices, edges, metaedges, and attributes.\n\
    \nTo make it convenient to work with knowledge, we propose to expand the annotated\
    \ metagraph model as shown in Fig. 1.\n\n![](_page_8_Figure_0.jpeg)\n\n**Fig.\
    \ 1.** An expansion of annotated metagraph.\n\nThis expansion of capabilities\
    \ will be done through the following steps:\n\n- 1. Add by analogy with pseudographs\
    \ by A. Burdakov [64]:\n- ─ the ability to have edges and metaedges as in hypergraphs,\
    \ which can connect more than 2 objects (can start on several objects and can\
    \ end on several objects);\n- ─ the possibility that an edge or a metaedge can\
    \ start not only from a vertices or a metavertices, but also from another edges\
    \ or a metaedges, and can also end not only with a vertices or a metavertices,\
    \ but also with another edges or a metaedges.\n\nThe term \"pseudograph\" used\
    \ by A. Burdakov to describe the way knowledge is represented is not very successful,\
    \ since there are at least two other interpretations of this term [65], [66].\n\
    \n- 2. Add features for working with implicitly and explicitly defined sets:\n\
    - ─ to provide an opportunity to group vertices, metavertices , edges and metaedges\
    \ into groups with similar ones due to their direct proximity to each other as\
    \ in protographs. For any element of such groups, operations are possible: find\
    \ out the number of elements in the group, get a link to the next member of the\
    \ group;\n- ─ provide an opportunity for any metavertex or metaedge to indicate\
    \ that the objects of the first level included in them form a finite set. For\
    \ such sets, operations are\n\npossible: find out the number of elements of the\
    \ set, get a link to the first nearest element of the set, get a link to the next\
    \ element of the set;\n\n- ─ provide an opportunity for any metavertex or metaedge\
    \ to indicate that the objects included in them form a countable set. For such\
    \ metavertices or metaedges, two metavertices are created inside sets: one contains\
    \ a finite set of object types, and the second contains a countable set of objects\
    \ (further, when designing the knowledge base, various ways of representing countable\
    \ sets will be proposed). For objects of a countable set, operations are possible:\
    \ get a reference to the first nearest element of the set, get a reference to\
    \ the next element of the set;\n- ─ provide an opportunity to create metavertices\
    \ that implement operations on sets: union, intersection, subtraction, despite\
    \ the fact that the internal elements of the first level of such metavertices\
    \ can only be metavertices and metaedges that form sets.\n- 3. Add logical data\
    \ processing capabilities:\n- ─ to provide the possibility of operators = and\
    \ above the objects in two versions: structurally (according to the internal structure\
    \ and composition of attributes) and by value (in addition to the structure, the\
    \ attribute values must match);\n- ─ provide the ability to use standard operations\
    \ =, , >, <, , for operations on attributes;\n- ─ provide the ability to specify\
    \ predicates in the attributes of vertices, edges, metavertices and metaedges;\n\
    - ─ provide the ability to perform logical operations (&, V, ¬) over the attributes\
    \ of vertices, edges, metavertices and metaedges;\n- ─ provide an opportunity\
    \ to create metavertices that implement quantifiers and over sets, despite the\
    \ fact that the only internal element of the first level of such meta-vertices\
    \ can only be metavertices and metaedges forming sets;\n- ─ provide the ability\
    \ to create metavertices that implement logical inference operations on objects,\
    \ specifying a set of source objects and their attributes with predicates, as\
    \ well as the object and its attribute to which the result will be assigned;\n\
    - ─ create meta-vertices that implement a wide range of modal operators (aletic,\
    \ epistemic, deontic, axiological, temporal) by specifying one or more objects\
    \ and their attributes with predicates.\n\nMetagraphs with such extensions can\
    \ be used to implement first, second and higher order logic, as well as various\
    \ modal logics, they only lack functions. Let's call them generalized logical\
    \ metagraphs. To implement functions, we will move from metagraphs to archigraphs\
    \ and in addition to vertices, edges, meta-vertices, and meta-edges, we will add\
    \ another type of object - a function. The resulting generalized logical archigraphs\
    \ can become the basis for the presentation of knowledge.\n\nIn order for the\
    \ model to combine any forms of knowledge and ensure work with them, it is necessary,\
    \ by analogy with the universal data model [58], to add several dozen types of\
    \ elements corresponding to different forms of knowledge representation to the\
    \ archigraph. Then it will be possible to build archigraphs in which all knowledge\
    \ from a certain subject area will be combined, regardless of the form of their\
    \ representation. The edges and meta-edges of such an archigraph will correspond\
    \ to the relationship between entities. Meta-edges will be used when these relationships\
    \ are complex and need to be detailed with additional entities. In addition to\
    \ edges and metaedges reflecting the content of knowledge, the archigraph will\
    \ also contain edges and metaedges reflecting the history of which object was\
    \ obtained from or based on which. For example, that this text is an abstract\
    \ of that text. The appearance of such seemingly technical connections in the\
    \ archigraph is completely justified – this is also knowledge. The use of metaedges\
    \ in such technical cases may be due to the complexity of the conversion process.\n\
    \nAs a storage environment for the proposed archigraphs, it is necessary to develop\
    \ a specialized DBMS that supports the archigraph data model. Its design and development\
    \ can be considered as a further development of the work on the development of\
    \ metagraph databases, approaches to the creation of which were considered in\
    \ [67,68].\n\nAll the knowledge presented in the archigraph can be divided into\
    \ three large groups: unformalized, partially formalized and formalized.\n\n####\
    \ **3.1.2 Storage and Processing of Non-Formalized Knowledge**\n\nThe informal\
    \ knowledge processed in computers can be classified as:\n\n- Texts in natural\
    \ languages, including technical, legal, prose, poetry, etc.;\n- Various graph\
    \ schemes and drawings developed outside the automation systems of their development;\n\
    - Maps made outside GIS;\n- Speech audio recordings;\n- Music, sound effects;\n\
    - Images (photographs, paintings, portraits);\n- Videos and movies, including\
    \ those with audio accompaniment.\n\nThere are many technologies for converting\
    \ informal knowledge into formalized knowledge. For example, let's first consider\
    \ the transition from natural language texts to formalized knowledge. In order\
    \ not to delve too much into history, you can take as a starting point the popular\
    \ and quite functionally complete NLTK library for Python [69]. During further\
    \ development, neural networks and knowledge graphs began to be widely used for\
    \ these purposes [70,71]. In addition to technologies for converting texts into\
    \ semantic networks or into knowledge graphs (the latter provide opportunities\
    \ for logical inference based on the knowledge contained in them), there are well-developed\
    \ technologies for reverse conversion from graphs to texts [72]. One of the recent\
    \ works in this field is devoted to the bidirectional transformation of texts\
    \ into semantically loaded metagraphs and vice versa [73].\n\nTo formalize images,\
    \ their representations are used in the form of scene graphs, which are structured\
    \ representations of images in the form of graphs containing objects, their attributes\
    \ and defining relationships between objects in the scene. There are currently\
    \ two main approaches to scene graph generation (SGG):\n\n- The first is to find\
    \ objects, and then to find paired relationships between the found objects [74].\n\
    - The second is the simultaneous detection of objects and the relationships between\
    \ them [75].\n\nAs a rule, SGG tasks are solved by using various types of neural\
    \ networks: convolutional (CNN) [76], recurrent (RNN) [77], graph (GNN) [78].\
    \ [79,80] provides a detailed overview of existing methods for generating scene\
    \ graphs. The reverse transformation – the generation of images from scene graphs,\
    \ as well as from other images or from text descriptions is also performed using\
    \ neural networks. Generative adversarial networks (GAN) are mainly used [81].\
    \ A separate major area is the generation of images and related descriptions based\
    \ on the results of medical diagnostic procedures such as MRI and PET [82]. In\
    \ these cases, the image acts as an external representation of the data processing\
    \ results coming from the diagnostic equipment, masking the formalized representation\
    \ of the semantics of the received data.\n\nThe task of formalizing video is relatively\
    \ new. One of the solutions to this problem is based on the development of the\
    \ idea of constructing a graph of image scenes – the construction of a graph of\
    \ video scenes [83]. Another approach used in [84] involves the generation of\
    \ knowledge graphs based on language annotations to videos. In the same article,\
    \ the authors propose a model for generating knowledge graphs directly from video\
    \ based on neural networks, trained on the dataset obtained in the first part\
    \ of the work. Neural networks are also used for reverse conversion – generation\
    \ of videos from knowledge graphs, sets of images or text descriptions. This topic\
    \ attracts the attention of many researchers. Only in the preprint archive arxiv.org\
    \ A search for the phrase \"video generation\" in the headlines of publications\
    \ yields a list containing more than 380 articles. Some of the works on this topic\
    \ are considered in the reviews [85], [86].\n\nThe formalization of audio recordings\
    \ of speech is usually performed in two stages. Based on the spectral characteristics\
    \ of speech, it is quite difficult to immediately build a knowledge graph. In\
    \ order not to form it directly from the spectral pattern of human speech sound\
    \ waves, an intermediate stage of speech recognition is performed, for example,\
    \ using voice assistants [87]. After that, the problem is reduced to the task\
    \ of formalizing texts in natural languages, which was considered earlier. Neural\
    \ networks are widely used as speech-to-text translation tools: convolutional\
    \ (CNN) [88], transformers [89] and, more recently, graph neural networks (GNN)\
    \ [90]. About a dozen different methods have been developed for synthesizing speech\
    \ from text [91]. Currently, neural network–based methods are also the most promising:\
    \ convolutional networks that do not have autoregression provide the highest speed\
    \ of speech formation [92], and networks with feedback - transformers [92] and\
    \ generative-adversarial (GAN) [93] are characterized by high acoustic speech\
    \ quality, can generate speech with several voices and give it an emotional coloring.\n\
    \nTo formalize musical works, their fragments and the sounds of musical instruments\
    \ stored in musical databases [94,95], as well as sound effects stored in special\
    \ databases [96], special formalization methods based on Markov processes [97]\
    \ and algebraic methods [98,99] are used.\n\nA separate major area of formalization\
    \ of non-formalized knowledge is the formalization of multimodal representations\
    \ combining two or more non-formalized streams of knowledge, such as those related\
    \ to the main ones: text, image, video, audio, as well as various auxiliary ones:\
    \ context, pose, intonation, facial expressions, smell, taste, touch. The knowledge\
    \ graph obtained as a result of multimodal synchronous processing of several parallel\
    \ streams of unformalized knowledge is not a simple combination and combination\
    \ of knowledge graphs obtained by processing individual streams, additional knowledge\
    \ may appear in it due to a deeper understanding of the subject area [100]. In\
    \ addition, knowledge from different streams fills in gaps and corrects errors\
    \ in individual streams. It is shown that the connection of several modalities\
    \ makes it possible to improve the formation and processing of knowledge graphs\
    \ created on the basis of information selected from social networks [101]. Interactive\
    \ immersive generative multimodal interaction between a person and an agent in\
    \ the form of a steady smooth exciting conversation accompanied by the display\
    \ of images is considered as a prospect for the development of technologies of\
    \ multimodal interaction with agents in [102].\n\n#### **3.1.3 Storage and Processing\
    \ of Partially Formalized Knowledge**\n\nThe first group of partially formalized\
    \ knowledge is data that has a structure, but there is no intensional that allows\
    \ them to be used and interpreted. And there is also no understanding of the place\
    \ of specific data in the metric of the relevant semantic space. Partially formalized\
    \ knowledge can include:\n\n- Data located in files organized using various access\
    \ methods (sequential, direct, index-sequential, etc.);\n- Data stored in files\
    \ created without specifying access methods in various local, distributed and\
    \ cloud file systems;\n- Data in databases organized according to various data\
    \ models (network, hierarchical, multivalue, multidimensional, relational, object,\
    \ vector, XML, key-value, wide column, documentary, tabular, time series, event,\
    \ spatial, etc., as well as RDF used without describing semantics) [103], including:\
    \ data from various modules and subsystems of enterprise management, data from\
    \ document management and content management systems, data from electronic trading\
    \ platforms, test questions and training material from automated learning systems,\
    \ data from library systems and scientific citation systems, data from research\
    \ automation systems, etc.;\n- Data from search engines indexes, both on the internet\
    \ scale [104] and corporate ones [105];\n- Data from blockchain frameworks;\n\
    - CAD data on the products being designed;\n- Neural network structures;\n- Cartographic\
    \ data in GIS;\n- Tables and diagrams prepared in desktop and cloud applications,\
    \ with the exception of diagrams describing certain sequences of actions (program\
    \ flowcharts, business process diagrams, project plans, production flowcharts,\
    \ etc.).\n\nThe second group of partially formalized knowledge is mathematical\
    \ models that are not context–bound:\n\n- Linear and nonlinear equations and systems\
    \ of such equations;\n- Differential equations and systems of such equations;\n\
    - Partial differential equations and systems of such equations;\n- Probabilistic\
    \ equations and systems of such equations;\n- Logical equations of propositional\
    \ calculus and systems of such equations;\n- Tensor operators and equations;\n\
    - Infinite-dimensional topological vector spaces and their mappings [106];\n-\
    \ Algebras, groups, rings, fields, lattices, modules [107].\n\nFor both groups,\
    \ the lists are clearly not exhaustive. However, they provide an understanding\
    \ that allows you to assign similar cases, that are not included, in each group.\n\
    \nTo turn data or abstract mathematical models into formalized knowledge, it is\
    \ necessary to add connections that allow them to be used and interpreted, to\
    \ correlate these objects with other ones.\n\n#### **3.1.4 Storage and Processing\
    \ of Formalized Knowledge**\n\nThe ways of presenting formalized knowledge are\
    \ very diverse:\n\n- Computer programs in traditional programming languages (programs\
    \ that have source code, architecture, or algorithm descriptions available will\
    \ have internal granularity);\n- Computer programs in languages that implement\
    \ logical programming based on a subset of first-order predicate logic or implement\
    \ it along with other features (Prolog, Visual Prolog, Mercury, Oz, Strand, KL0,\
    \ KL1, Datalog, etc.) [108];\n- Diagrams describing some sequences of actions\
    \ (program flowcharts, business process diagrams, project execution plans, production\
    \ flowcharts, etc.) Prepared using specialized tools;\n- Semantic networks [109];\n\
    - Trained neural networks;\n- Frames (during the first 15 years of their development,\
    \ frame systems and languages were used for the structural representation of knowledge\
    \ [110], but since the late 1980s, logical inference tools based on stored information\
    \ have appeared in them [111] and with subsequent development, the role of logic\
    \ tools increases significantly [112]);\n- Knowledge graphs [113];\n- Descriptions\
    \ using first-order predicate logic (in the languages of general logic [114],\
    \ as well as in the languages CycL [115], FO[‧] [116], KIF [117,118], etc.);\n\
    - Descriptions using language families for the semantic web: RDF [119] and OWL\
    \ [120] or simpler ones like SHOE [121];\n- Description in ontology description\
    \ languages and/or in systems such as UFO [122], OntoUML [123], DOGMA [124], Ontologua\
    \ [125], LOOM [126], etc.;\n- Production systems (in simple cases, they can be\
    \ implemented using traditional programming languages, with professional implementation\
    \ specialized development languages [127,128] or special systems for working with\
    \ production rules [129] are used, they can be divided by type into clock and\
    \ stream ones [130]);\n- Formal grammars [131];\n- Formal systems of concepts\
    \ [132];\n- Conceptual models of knowledge [133];\n- Interconnected points in\
    \ the Elements-Attributes-Relations space [134,135];\n- Complex networks [136];\n\
    - Petri nets [137];\n- Finite state machines [138];\n- Simulation models [139].\n\
    \nTraditionally, when listing ways to represent formalized knowledge, objects\
    \ such as computer programs, neural networks, finite state machines, simulation\
    \ models and complex networks are not considered. This is due, among other things,\
    \ to the fact that in the absence of additional information, and sometimes even\
    \ if it is available, it is impossible to explain the results obtained by accessing\
    \ such objects. However, when creating a broad-purpose knowledge base for a projected\
    \ AGI, the lack of detailed explanations of how the final result was obtained,\
    \ as well as for a person, is not a reason to discard such objects. We can say\
    \ that they contain \"canned\" knowledge, and when entering the initial data,\
    \ they produce a result.\n\nThe above list of types of formalized knowledge is\
    \ also not comprehensive, as is the composition of other groups, but it gives\
    \ an intuitive understanding of what objects, not yet listed, could be included\
    \ in this group.\n\n#### **3.1.5 An Alternative Version of the Knowledge Base\
    \ Organization, which was Abandoned**\n\nIt was possible to avoid applying the\
    \ concept of an archigraph with several dozen types of objects for different types\
    \ of knowledge, but instead to focus on the model of a generalized logical metagraph,\
    \ to which only functions could be added and a \"Type\" attribute could be introduced\
    \ for each vertex, with which the type of knowledge contained in it could be determined.\
    \ But for each type of knowledge, its own group of functions working with it will\
    \ be used, which may overlap or not overlap with the functions of the other types\
    \ of knowledge. In addition, technical edges or metaedges related to knowledge\
    \ transformation would come into or out of each object. And for all these functions,\
    \ edges and metaedges in this case, one would also need a special \"Type\" attribute.\
    \ This would complicate the structure. Therefore, this option was abandoned.\n\
    \n### **3.2 A Preliminary Design of the Cognitive Architecture on the Basis of\
    \ which AGI Prototypes Can Be Developed**\n\n#### **3.2.1 Common Description of\
    \ Cognitive Architecture**\n\nBased on the suggested universal knowledge model,\
    \ a cognitive architecture is proposed, shown in Fig. 2, which can be used to\
    \ develop AGI prototypes.\n\n![](_page_15_Figure_3.jpeg)\n\n**Fig. 2.** A diagram\
    \ of the cognitive architecture that can be used to develop AGI prototypes.\n\n\
    All functional modules included in the cognitive architecture, except for modules\
    \ interacting with the external environment, work with the knowledge base, which\
    \ is the agent's memory. Each module interacting with the knowledge base has a\
    \ separate section there, in which it stores the knowledge it needs, and can change\
    \ them as it sees fit. If some knowledge is important for several modules, to\
    \ eliminate duplication, they can be stored in a common section accessible to\
    \ all of them. But then, to make changes to such knowledge, consent must be obtained\
    \ from all modules that have access to them.\n\nAll functional modules of the\
    \ cognitive architecture are integrated using a common knowledge bus. The knowledge\
    \ sent to the common bus gets to all modules connected to the bus, then each module\
    \ individually decides how to deal with them, save them in its knowledge base\
    \ area and somehow use or ignore them. In addition, the shared bus can be used\
    \ by modules to request knowledge from other modules. The response to the request\
    \ also comes via a common bus. Knowledge on the common bus can be transmitted\
    \ in all forms in which it can be stored in the knowledge base.\n\nUsing a shared\
    \ knowledge bus is an alternative used in many cognitive architectures to the\
    \ concept of working memory ([9], [11], [12], [15] and others). These options\
    \ are comparable to the integration methods used in the architecture of software\
    \ systems: integration over a common bus and integration over data. The advantages\
    \ of using a common knowledge bus are that all modules are forced to process the\
    \ incoming knowledge stream in parallel, except in situations where knowledge\
    \ is sent to a specific module in response to its request. This is a mechanism\
    \ that requires much more resources (both processor and memory), but this mechanism\
    \ is based on active actions, it involves individual modules in knowledge processing\
    \ and provides an up-to-date context for all of them. Unlike the general knowledge\
    \ bus, when using working memory, in case of any situation, the module must look\
    \ at what lies in the workspace. This is a passive mechanism. What if the necessary\
    \ knowledge has already been removed from the workspace and replaced with something\
    \ else?\n\nThe modules of consciousness and subconsciousness play a major role\
    \ in interacting with interface modules that provide interaction with the external\
    \ environment. The consciousness module is a control system that controls the\
    \ movement of an agent in a complex space, which is a combination of ordinary\
    \ three-dimensional space, time and any other spaces in which the agent operates\
    \ (for example, media spaces, consumer goods spaces, scientific research spaces,\
    \ etc.), with all the limitations inherent in these spaces (for example, you can\
    \ only move from one floor to another by stairs or by elevator). The subconscious\
    \ module allows you to implement ready-made routine sequences of actions stored\
    \ in the knowledge base without connecting or with minimal connection of a relatively\
    \ slow control system implemented by consciousness. Often the same sequences of\
    \ actions performed by consciousness move over time into the subconscious.\n\n\
    Consciousness controls movement, focusing on the goals generated by the goal management\
    \ module, and on the situation developing in the external environment. Knowledge\
    \ about the situation in the external environment from the multimodal data and\
    \ knowledge conversion module is transmitted not only to the modules of consciousness\
    \ and subconsciousness, which are the main consumers this data, but also after\
    \ being cleared of unnecessary details, it is transmitted to the common bus, from\
    \ where all other modules receive them, including: monitoring module, goal management\
    \ module, emotional management module. And the same in the opposite direction\
    \ (but not symmetrically): the modules interacting with the external environment\
    \ receive knowledge from the common bus, for example, emotions from the emotional\
    \ management module, although the bulk of knowledge is transferred there from\
    \ consciousness and subconsciousness.\n\nThe emotional control module is another\
    \ control system besides consciousness, which does not act as precisely as consciousness\
    \ can, but on all modules at once. The emotions generated are not some single\
    \ objects with the meanings \"sad\", \"joyful\", \"anxious\", \"ashamed\", etc.,\
    \ but more complex knowledge structures where there are reasons, some previous\
    \ history, perhaps: participants in the event and something else.\n\nThe ethical\
    \ assessment module generates ethical assessments of all events and actions, including\
    \ possible actions. These assessments can both encourage and deter these actions,\
    \ and the level of support or deterrence may vary. If the actions and events have\
    \ already taken place, then their ethical assessments are added to their characteristics.\
    \ Just like emotions, ethical assessments are complex structures in which reasons\
    \ may be present, justifying artifacts or chains of events, etc. Ethical assessments\
    \ are formed on the basis of ethical principles stored in the knowledge base and\
    \ amenable to modification either with human participation or as a result of repeated\
    \ occurrence of sequences of events that reveal contradictions in these principles.\n\
    \nThe reflection module is somewhat similar to the ethics module, it also generates\
    \ assessments of actions and events, but only past ones, and not from the perspective\
    \ of some ethical norms established by culture, religion or some authorities,\
    \ but from the perspective of achieving the final result, side effects that arise,\
    \ influencing one's own and others' plans, and etc. At the same time, very often,\
    \ during the work of the reflection module, events that have occurred are modeled\
    \ from the positions of other participants, their assumed (or confirmed by some\
    \ facts) estimates of these events are formed, and their own estimates are adjusted\
    \ from these positions.\n\nThe social interaction module takes into account relationships\
    \ with people and other agents, existing and possible roles in these interactions,\
    \ emotions towards other agents, the course of processes and the results of previous\
    \ interactions with them and, based on all of this, adjusts action plans that\
    \ are somehow related to other agents. In addition to plans, the module influences\
    \ actions and dialogues when interacting with people and other agents, forming\
    \ additional knowledge for modules of interaction with the external environment.\n\
    \nThe worldview module provides the formation and support of a special section\
    \ in the knowledge base, which contains a picture of the agent's world and determines\
    \ his place in it, the main goals of the agent's existence are formulated. This\
    \ section is based on a scientific picture of the world, but to understand many\
    \ aspects of history, art, and social relationships, other pictures of the world\
    \ (mythological, several religious, and alternative scientific) are also stored\
    \ in the section with explanations why they are not correct. The scientific picture\
    \ of the world is modified as new scientific knowledge becomes available. Stored\
    \ worldviews are used to gain new knowledge from different fields and compare\
    \ them with those available in the database. In case of contradictions, various\
    \ reactions are possible, both the re-clarification of the received knowledge\
    \ and the assignment of assessments that they are false.\n\nThe monitoring module\
    \ allows for various types of monitoring in a wide range of processes occurring\
    \ in the external environment and in the modules of the agent's cognitive system.\
    \ The occurrence of some events, changes in the values of the characteristics\
    \ of some objects can be controlled, and both the achievement of some expected\
    \ value and the finding of this value within some acceptable limits can be controlled.\
    \ The initiation of monitoring processes is carried out by other modules of the\
    \ cognitive architecture.\n\nThe learning module generates new knowledge in the\
    \ knowledge base. This can happen both through the direct transfer of knowledge\
    \ coming from the external environment with their subsequent comparison with existing\
    \ knowledge and binding in the absence of contradictions, and through the formation\
    \ of models based on the results of the agent's own actions. Both externally received\
    \ and independently created models are tested and checked for compliance with\
    \ the knowledge already available in the knowledge base. If there are inconsistencies,\
    \ new knowledge can be discarded (if it strongly contradicts the worldview, ethical\
    \ assessments, or already existing knowledge) or recorded in the knowledge base\
    \ with the mark indicating the presence of contradictions. The formation of new\
    \ knowledge can occur in all modules of the cognitive architecture working with\
    \ the knowledge base, while access to the learning module is performed to replenish\
    \ and/or adjust the knowledge base.\n\nThe task setting and solution modules carry\
    \ out the formulation and solution of tasks. Requests to them are initiated from\
    \ any module of the cognitive architecture, including the learning module for\
    \ building new models and the setting and solving problems modules themselves\
    \ for setting and solving problems when a complex task is divided into subtasks.\n\
    \nWith the help of the self-organization and meta-learning module, the agent should\
    \ be able to rebuild and improve his activities, find and switch to using new\
    \ more productive ways of learning. Decisions on the reorganization of activities\
    \ or on the transition to new forms of activity, as well as decisions on the transition\
    \ to new forms of education should be made based on the results of a purposeful\
    \ search, modeling and subsequent practical testing. For the first time, the need\
    \ for such a functional component as part of the cognitive architecture for AGI\
    \ was shown in [140].\n\nThe presented description of the cognitive architecture\
    \ in the light of [141] can be considered as a top-level specification that can\
    \ be used to further detail the cognitive architecture and develop an intelligent\
    \ agent, however, we will not delve into this process due to its resource intensity.\
    \ Our following descriptions of the individual modules will be related to an overview\
    \ of the implementation of the corresponding mechanisms in other cognitive architectures.\n\
    \n#### **3.2.2 Consciousness**\n\nOf the 42 cognitive architectures considered\
    \ by us, only four have an explicitly highlighted \"Consciousness\" component\
    \ for building AGI: LIDA [12], Haikonen cognitive architecture [13], [16], ICOM\
    \ [23] and MBCA [27], Clarion [47], OntoAgent [49], ISAAC [51], [52]. And GLAIR\
    \ [31] also talks about the Knowledge Layer in which conscious reasoning, planning,\
    \ and act selection is performed. There are much more cognitive architectures\
    \ for simpler robots that have consciousness embedded in them, or architectures\
    \ being developed as part of research projects on the realization of consciousness:\
    \ [142], [143], [144], MECA [145], [146], [147], [148], [149], RoboErgoSum [150],\
    \ [151], COCOCA [152], MLECOG [153], [154], [155], CELTS [156], [157], [158],\
    \ [159], [160], [161]. In these works, as a rule, a lot of attention is paid to\
    \ the technical implementation of consciousness and its integration into the cognitive\
    \ architecture, while its functionality is not worked out deeply enough, but only\
    \ at a general level.\n\nThe key features of the modern understanding of machine\
    \ consciousness were formulated in [162,163]. Consciousness is considered as a\
    \ control system for the agent's current actions. To have minimal consciousness,\
    \ it is necessary that the agent has the following capabilities:\n\n- self-knowledge:\
    \ Agent has complete knowledge of its current cognitive state as well as of the\
    \ data produced by all its interfaces, sensor, and motor units.\n- self-monitoring:\
    \ Agent is completely informed about the performance and status of its sensory\
    \ and motor units over time (including the quality of the sensations and the reports\
    \ from all of them) and of its embedding in the environment as it is.\n- self-awareness\
    \ (or self-reflection): Agent behaves in a way that unambiguously reflects, respectively\
    \ is determined by its current cognitive state and the information gained by its\
    \ self-knowledge and self-monitoring abilities, and that is 'aware' of the internal\
    \ and external changes that it causes.\n- self-informing: Agent globally broadcasts\
    \ its cognitive state, to all modules of the system and whenever changes of state\
    \ occur.\n\nIt can be expected that the further development of this theory from\
    \ a minimal to a more advanced consciousness will make it possible to realize\
    \ consciousness as a system of parallel control processes taking place in multidimensional,\
    \ partially intersecting virtual spaces in which spatial and temporal constraints\
    \ are set. If the actions that need to be performed based on the results of parallel\
    \ management processes in the real space in which the agent operates contradict\
    \ each other, they are checked for consistency in time distribution, ranked and\
    \ queued. In the process of functioning, the consciousness module intensively\
    \ interacts with all other AGI modules, receiving plans for further actions, applying\
    \ for statements and solutions to problems of modeling possible situations, considering\
    \ ethical assessments, checking with the worldview, etc.\n\n#### **3.2.3 Subconscious**\n\
    \nThe machine subconscious contains ready-made models and algorithms that can\
    \ be quickly activated when corresponding situations arise. Unlike human memory,\
    \ the volume of the machine subconscious can be quite large, and stored models\
    \ can cover a wide range of fields of knowledge and activities. Among the architectures\
    \ designed to create AGI, the following architectures have the subconscious: ACT-R\
    \ [10], LIDA [12], CogPrime [17, 18], ICOM [23], GLAIR [31], MicroPSI [40], Clarion\
    \ [47], OntoAgent [49], ISAAC [51], [52]. Some cognitive architectures, which\
    \ do not have the immediate goal of creating AGI, are claimed to have both consciousness\
    \ and subconsciousness: COCOCA [152], MLECOG [153], [154], [155], CELTS [156],\
    \ [157], [158], [159], [160], [161]. At the same time, there are cognitive architectures\
    \ of this class, which have only subconsciousness without consciousness: IFORs\
    \ [164], [165], [166], [167], DIARC [168], NCCA [169], [170].\n\nThe existence\
    \ of the subconscious in the cognitive architecture is evidenced not only by the\
    \ explicit indication of its presence. As was rightly noted in [35], all reactive\
    \ cognitive architectures such as Soar [9], ICARUS [171], SW-CASPAR [172] or individual\
    \ reactive levels in complex combined architectures, such as the reactive layer\
    \ in CogAff [34], contain a certain set of behaviors for different situations\
    \ and, in fact, act as a subconscious.\n\nThe perception of subconsciousness,\
    \ that has developed among some researchers, as some kind of auxiliary system\
    \ that helps consciousness (which is not entirely true) leads to the fact that\
    \ the specific functionality of the subconscious in cognitive architectures\n\n\
    is often left behind the scenes or distorted. So, in [155] and [157] they take\
    \ as a basis Kahneman's idea [173] about the dual nature of thinking processes\
    \ and distinguish a fast subconscious mind that processes large amounts of incoming\
    \ information and a slow consciousness that processes significantly less information.\
    \ This is true, but with this approach, the functionality of the subconscious\
    \ mind for the accumulation, storage and use of ready-made algorithms and models\
    \ remains undisclosed.\n\nAlong with the fact that the functionality of the subconscious\
    \ mind is not revealed, it can also be distorted. So, the article [174] begins\
    \ with the correct statements that the subconscious can handle tasks in the high\
    \ dimensional problem solving space while the consciousness can operate only in\
    \ the low dimensional space. But then the author considers a way to transfer information\
    \ from the subconscious mind to consciousness using emotions. The same idea is\
    \ expressed in [175]. In our opinion, this is wrong, emotions are not signals\
    \ of the subconscious mind. The emotional management system is a separate functional\
    \ component of the cognitive architecture. In the architecture shown in the figure\
    \ above, the subconscious mind can directly interact with the modules of interaction\
    \ with the external environment. Consciousness, receiving information about these\
    \ interactions, can suppress or correct them.\n\nSimilarly, attaching the functions\
    \ of interaction with the external environment to the subconscious mind [161],\
    \ in our opinion, is also a distortion of its functionality; for this purpose,\
    \ separate modules should be allocated in the cognitive architecture. The restriction\
    \ on the methods of realization of the subconscious mind caused by this distortion\
    \ (the use of neural networks and fuzzy logic) immediately becomes invalid after\
    \ the distortion is eliminated. This is confirmed by a number of examples of the\
    \ inclusion of the subconscious mind in the symbolist cognitive architectures\
    \ presented in this section, based on the use of production rules.\n\n#### **3.2.4\
    \ Worldview**\n\nOf the 42 cognitive architectures we have considered for building\
    \ AGI, the worldview module is present in NARS [11], Sigma [15], MBCA [27], GLAIR\
    \ [31], H-CogAff [34], EM-ONE [36], CAMAL [38], SMCA [39], Clarion [47] and Oscar\
    \ [48], as well as in cognitive architectures developed for research purposes\
    \ that did not consider all aspects of human activity: CogAff [34], [145], ICARUS\
    \ [171], SW-CASPAR [172], CRIBB [176], A-CRIBB [177], [178], SACA [179], [180],\
    \ CoJACK [181], [182], [183], MAMID [184], CogToM [185], Scruff [186], CASPAR\
    \ [187], [188] and InnovA [189]. All these cases provide for the presence and\
    \ use of many elements of worldviews. All these elements are either intuitive\
    \ (laid down initially when creating an agent), or formed as a result of training,\
    \ and they are all related to some operational aspects of the activity. Conflicting\
    \ worldviews such as scientific, religious, and mythological are not considered.\n\
    \nIn [190], a method for the coordinated use of several contradictory worldviews\
    \ is proposed, but it is quite primitive and not suitable for AGI: the agent acts\
    \ as a character in a game journey full of challenges and mysteries that underlie\
    \ myths. In [191] and [192], a fragmented worldview is considered. The fundamental\
    \ basis for dealing with\n\nworldviews is the theory of Belief revision [193],\
    \ [194], [195]. For effective coordinated use of different worldviews, it is necessary,\
    \ depending on the context, to ensure dynamic switching between different independent\
    \ worldview models and to have knowledge (on a deeper layer of worldview common\
    \ to all models) about the relevance of each model and the conditions of its application.\n\
    \n#### **3.2.5 Reflection**\n\nThe reflection module builds models of this agent,\
    \ reflecting its various aspects: activities, plans, knowledge, appearance, etc.\
    \ At the same time, these models can be built in parallel and from different perspectives:\n\
    \n- From the point of view of some theoretical concepts: cost, safety, environmental\
    \ protection, technical condition, etc.;\n- From the point of view of some real\
    \ or abstract individuals and/or organizations. In the process of building a reflexive\
    \ model, an agent model is used, from which position this reflexive model is built.\
    \ In this case, not one, but a small sequence of reflexive models can be built\
    \ from the position of a particular agent and several of its models: In particular,\
    \ the second reflexive model is built on the assumption that the external agent\
    \ knows that the main agent understands what the external agent thinks about him.\
    \ This is considered in the second external agent model. According to the same\
    \ principle of multiple reflection, third and subsequent reflexive models and\
    \ models of an external agent can be constructed.\n\nIn both variants, emotional\
    \ assessments of concepts and subjects can be considered, from the point of view\
    \ of which reflexive models are built.\n\nThe created reflexive models can be\
    \ partial models of a given agent (reflect only one or several of its sides) and\
    \ differ from the model of a given agent available in consciousness. They are\
    \ used for self-assessment and adjustment of modelled aspects.\n\nReflection functionality\
    \ is available in the following cognitive architectures designed to create AGI:\
    \ Soar [9], Sigma [15], eBICA [21.22], H-CogAff [34], EM-ONE [36], CAMAL [38],\
    \ SMCA [39], MicroPSI [40], [44], Polyscheme [45], [46], Clarion [47]. In addition,\
    \ it is used in the cognitive architecture of strong human-machine intelligence\
    \ [196], as well as in cognitive architectures designed for simpler robots and\
    \ research in the field of cognitive architectures: CogAff [34], DIARC [168],\
    \ CRIBB [176], A-CRIBB [177], SACA [179], [180], MAMID [184], [197], EM1 [198],\
    \ Cognitive Architecture for Human-Robot Interaction [199], [200], [201], [202].\n\
    \n### **4 Conclusions**\n\nThe article proposes a model of knowledge representation\
    \ that allows the upcoming AGI to work with different representations of knowledge\
    \ and freely move from one to another. This model is used in the proposed AGI\
    \ cognitive architecture, which identifies functional blocks for all types of\
    \ cognitive activity that the authors considered inherent in humans.\n\nWe hope\
    \ that the proposed cognitive architecture and knowledge representation model\
    \ will solve the problem formulated in the introduction, as well as allow us to\
    \ answer some of the challenges that faced the theory of cognitive architectures\
    \ according to [203,204], in particular:\n\n- The need for robust integration\
    \ of mechanisms involving planning, acting, monitoring and goal reasoning.\n-\
    \ [The limited size](http://www.ieee-coro.org/) and the homogeneous typology of\
    \ knowledge that is encoded and processed by systems based on cognitive architectures.\n\
    \nIn the first prototypes being developed, not all types of knowledge and not\
    \ all functional blocks of the cognitive architecture may be supported. At the\
    \ same time, the prototyping process and future theoretical research may reveal\
    \ the need to expand the composition of blocks of cognitive architecture, to include\
    \ blocks not provided for in this article.\n\n### **5 Discussion**\n\nThe article\
    \ considers in detail only 5 functional modules of the proposed cognitive architecture\
    \ out of 17 including Knowledge base. Of course, it is necessary to describe them\
    \ all. Obstacles to this:\n\n- the text of the article is already quite large\
    \ then will increase significantly in size;\n- a lot of additional time is required\
    \ to perform a significant additional amount of work on the analysis of cognitive\
    \ architectures and text preparation.\n\nThe authors plan to prepare a continuation\
    \ of this article in the future with a description of the remaining functional\
    \ modules.\n\n### **6 Organizational Snippets**\n\n### **6.1 Author Contributions**\n\
    \n**Artem Sukhobokov**: Conceptualization, Writing - Original Draft, Supervision.\
    \ **Evgeny Belousov**: Resources, Writing - Original Draft. **Danila Gromozdov**:\
    \ Writing - Original Draft, Validation. **Anna Zenger**: Writing - Original Draft,\
    \ Writing - Review & Editing. **Ilya Popov**: Methodology, Writing - Original\
    \ Draft.\n\n### **6.2 Declaration of Competing Interest**\n\nThe authors declare\
    \ that they have no known competing financial interests or personal relationships\
    \ that could have appeared to influence the work reported in this paper.\n\n###\
    \ **6.3 Funding**\n\nThis research did not receive any specific grant from funding\
    \ agencies in the public, commercial, or not-for-profit sectors.\n\n### **References**\n\
    \n- 1. Ghosh, S., & Singh, A. (2020, May). The scope of Artificial Intelligence\
    \ in mankind: A detailed review. *Journal of Physics: Conference Series 1531*,\
    \ Article 012045. IOP Publishing. https://doi.org/10.1088/1742-6596/1531/1/012045\n\
    - 2. Newell, А. (1990). *Unified Theories of Cognition (The William James lectures:\
    \ 1987)* Harvard University Press.\n- 3. Langley, P., Laird, J. E., & Rogers,\
    \ S. (2009). Cognitive architectures: Research issues and challenges. *Cognitive\
    \ Systems Research*, *10*(2), 141-160. <https://doi.org/10.1016/j.cogsys.2006.07.004>\n\
    - 4. Kotseruba. I., & Tsotsos, J. K. (2018) A review of 40 years in cognitive\
    \ architecture research: core cognitive abilities and practical applications.\
    \ *arXiv*:1610.08602v3 [cs.AI]. <https://doi.org/10.48550/arXiv.1610.08602>\n\
    - 5. Ye, P., Wang, T., & Wang, F. -Y. (2018). A Survey of Cognitive Architectures\
    \ in the Past 20 Years. *IEEE Transactions on Cybernetics*, *48*(12), 3280-3290.\
    \ <https://doi.org/10.1109/TCYB.2018.2857704>\n- 6. Duch, W., Oentaryo, R. J.,\
    \ & Pasquier, M. (2008, March). Cognitive architectures: Where do we go from here?.\
    \ In: Wang, P., Gorzel, B., & Franklin, S. (eds) *Artificial General Intelligence\
    \ 2008: Proceedings of the First AGI Conference* (pp. 122-136) IOS Press. <https://ebooks.iospress.nl/volumearticle/4075>\n\
    - 7. Panella, I., Fragonara, L. Z., & Tsourdos, A. (2021). A deep learning cognitive\
    \ architecture: Towards a unified theory of cognition. In: [Arai,](https://link.springer.com/book/10.1007/978-3-030-55180-3#author-1-0)\
    \ K.[, Kapoor,](https://link.springer.com/book/10.1007/978-3-030-55180-3#author-1-1)\
    \ S., [& Bhatia](https://link.springer.com/book/10.1007/978-3-030-55180-3#author-1-2)\
    \ R. (eds) *Intelligent Systems and Applications: Proceedings of the 2020 Intelligent\
    \ Systems Conference (IntelliSys)* Vol 1 (pp. 566-582) Advances in Intelligent\
    \ Systems and Computing, vol 1250. Springer, Cham. https://doi.org/10.1007/978-3-030-55180-3\\\
    _42\n- 8. Laird, J. E., & Wray III, R. E. (2010, June). Cognitive architecture\
    \ requirements for achieving AGI. In: *3d Conference on Artificial General Intelligence\
    \ (AGI-2010)* (pp. 3-8) Atlantis Press. https://doi.or[g/10.2991/agi.2010.2](https://doi.org/10.2991/agi.2010.2)\n\
    - 9. Laird, J. E. (2019). *The Soar cognitive architecture.* MIT press. <https://doi.org/10.7551/mitpress/7688.001.0001>\n\
    - 10. Lebiere, C., Pirolli, P., Thomson, R., Paik, J., Rutledge-Taylor, M., Staszewski,\
    \ J., & Anderson, J. R. (2013). A functional model of sensemaking in a neurocognitive\
    \ architecture. *Computational intelligence and neuroscience*, *2013*, Article\
    \ 921695. <https://doi.org/10.1155/2013/921695>\n- 11. Wang, P. (2013). Natural\
    \ language processing by reasoning and learning. In: Kühnberger, K,-U., Rudolph,\
    \ S., & Wang, P. (eds) *Artificial General Intelligence: 6th International Conference,\
    \ AGI 2013*. (pp. 160-169) Lecture Notes in Computer Science, vol 7999. Springer,\
    \ Berlin, Heidelberg. [https://doi.org/10.1007/978-3-642-39521-5\\\\_17](https://doi.org/10.1007/978-3-642-39521-5_17)\n\
    - 12. Faghihi, U., & Franklin, S. (2012). The LIDA model as a foundational architecture\
    \ for AGI. In: Wang, P., & Goertzel, B. (eds) *Theoretical foundations of artificial\
    \ general intelligence* (pp. 103-121) Atlantis Press, Paris. [https://link.springer.com/content/pdf/10.2991/978-94-91216-62-6\\\
    \\_7.pdf](https://link.springer.com/content/pdf/10.2991/978-94-91216-62-6_7.pdf)\n\
    - 13. Haikonen, P. O. (2007). *Robot brains: circuits and systems for conscious\
    \ machines.* Wiley-Interscience, York, NY, United States.\n\n- 14. Schaat, S.,\
    \ Wendt, A., Kollmann, S., Gelbard, F., & Jakubec, M. (2015). Interdisciplinary\
    \ Development and Evaluation of Cognitive Architectures Exemplified with the SiMA\
    \ Approach. In: Airenti, G., Bara, B. G., & Sandini, G. (eds) *EuroAsianPacific\
    \ Joint Conference on Cognitive Science* (pp. 515-520) EAPCogSci 2015*.* CEUR\
    \ WORKSHOP PROCEEDINGS. vol 1419.<https://ceur-ws.org/Vol-1419/paper0084.pdf>\n\
    - 15. Pynadath, D. V., Rosenbloom, P. S., & Marsella, S. C. (2014). Reinforcement\
    \ learning for adaptive theory of mind in the sigma cognitive architecture. In:\
    \ Goertzel, B., Orseau, L., & Snaider, J. (eds.) *Artificial General Intelligence:\
    \ 7th International Conference*, *AGI 2014* (pp. 143-154) Lecture Notes in Computer\
    \ Science, vol 8598. Springer, Cham. [https://doi.org/10.1007/978-3-319-09274-4\\\
    \\_14](https://doi.org/10.1007/978-3-319-09274-4_14)\n- 16. Raizer, K., Paraense,\
    \ A. L., & Gudwin, R. R. (2012). A cognitive architecture with incremental levels\
    \ of machine consciousness inspired by cognitive neuroscience. *International\
    \ Journal of Machine Consciousness*, *4*(02), 335-352. <https://doi.org/10.1142/S1793843012400197>\n\
    - 17. Goertzel, B.. Pennachin, C., & Geisweiller, N. (2014). *Engineering General\
    \ Intelligence, Part 1: A Path to Advanced AGI via Embodied Learning and Cognitive\
    \ Synergy*. Atlantis Press, Paris, France.<https://doi.org/10.2991/978-94-6239-027-0>\n\
    - 18. Goertzel, B.. Pennachin, C., & Geisweiller, N. (2014). *Engineering General\
    \ Intelligence, Part 2: The CogPrime Architecture for Integrative, Embodied AGI.*\
    \ Atlantis Press, Paris, France. <https://doi.org/10.2991/978-94-6239-030-0>\n\
    - 19. Thórisson, K. R., & Nivel, E. (2009, June). Achieving artificial general\
    \ intelligence through peewee granularity. In: *2nd Conference on Artificial General\
    \ Intelligence (2009)* (pp. 198-199). Atlantis Press. https://doi.or[g/10.2991/agi.2009.42](https://doi.org/10.2991/agi.2009.42)\n\
    - 20. Nivel, E., & Thórisson, K. R. (2009, June). Self-programming: Operationalizing\
    \ autonomy. In: *2nd Conference on Artificial General Intelligence (2009)* (pp.\
    \ 212-217) Atlantis Press. https://doi.or[g/10.2991/agi.2009.45](https://doi.org/10.2991/agi.2009.45)\n\
    - 21. Azarnov, D. A., Chubarov, A. A., & Samsonovich, A. V. (2018). Virtual actor\
    \ with socialemotional intelligence. *Procedia computer science*, *123*, 76-85.\
    \ https://doi.org/10.1016/j.procs.2018.01.013\n- 22. Samsonovich, A. V. (2020).\
    \ Socially emotional brain-inspired cognitive architecture framework for artificial\
    \ intelligence. *Cognitive Systems Research*, *60*, 57-76. <https://doi.org/10.1016/j.cogsys.2019.12.002>\n\
    - 23. Kelley, D., & Twyman, M. (2020). Biasing in an independent core observer\
    \ model artificial general intelligence cognitive architecture. *Procedia Computer\
    \ Science*, *169*, 535-541. <https://doi.org/10.1016/j.procs.2020.02.213>\n- 24.\
    \ Vityaev, E. E., Demin, A. V., & Kolonin, Y. A. (2020). Logical Probabilistic\
    \ Biologically Inspired Cognitive Architecture. In: Goertzel, B., Panov, A., Potapov,\
    \ A., & Yampolskiy, R. (eds) *Artificial General Intelligence, AGI 2020* (pp.\
    \ 337–346) Lecture Notes in Computer Science, vol 12177. Springer, Cham[. https://doi.org/10.1007/978-3-030-52152-3\\\
    \\_36](https://doi.org/10.1007/978-3-030-52152-3_36)\n- 25. Nakamura, M., & Yamakawa,\
    \ H. (2016). A Game-Engine-Based Learning Environment Framework for Artificial\
    \ General Intelligence. In: Hirose, A., Ozawa, S., Doya, K., Ikeda, K., Lee, M.,\
    \ & Liu, D. (eds) *Neural Information Processing* ICONIP 2016 (pp. 351-356) Lecture\
    \ Notes in Computer Science, vol 9947. Springer, Cham. https://doi.org/10.1007/978-3-319-46687-3\\\
    _39\n- 26. Strannegård, C., von Haugwitz, R., Wessberg, J., & Balkenius, C. (2013).\
    \ A cognitive architecture based on dual process theory. In: Kühnberger, K,-U.,\
    \ Rudolph, S., & Wang, P. (eds) *Artificial General Intelligence: 6th International\
    \ Conference, AGI 2013* (pp. 140- 149) Lecture Notes in Computer Science, vol\
    \ 7999. Springer, Berlin, Heidelberg. [https://doi.org/10.1007/978-3-642-39521-5\\\
    \\_15](https://doi.org/10.1007/978-3-642-39521-5_15)\n- 27. Schneider, H. (2020).\
    \ Subsymbolic Versus Symbolic Data Flow in the Meaningful-Based Cognitive Architecture.\
    \ In: Samsonovich, A. (eds) *Biologically Inspired Cognitive Architectures 2019*\
    \ BICA 2019 (pp. 465–474) Advances in Intelligent Systems and Computing, vol 948.\
    \ Springer, Cham[. https://doi.org/10.1007/978-3-030-25719-4\\\\_61](https://doi.org/10.1007/978-3-030-25719-4_61)\n\
    - 28. Komarovsky, S. (2022). Dynamic and Evolving Neural Network as a Basis for\
    \ AGI (No. 7922). *EasyChair*[. https://easychair.org/publications/preprint\\\\\
    _download/bCjT](https://easychair.org/publications/preprint_download/bCjT)\n-\
    \ 29. Zhou, J., & Ustun, V. (2022). PySigma: Towards Enhanced Grand Unification\
    \ for the Sigma Cognitive Architecture. In: Goertzel, B., Iklé, M., & Potapov,\
    \ A. (eds) *Artificial General Intelligence. AGI 2021* (pp. 355-366) Lecture Notes\
    \ in Computer Science, vol 13154. Springer, Cham. https://doi.org/10.1007/978-3-030-93758-4\\\
    _36\n- 30. Xu, M., Zheng, H., Pei, J., & Deng, L. (2023). A Unified Structured\
    \ Framework for AGI: Bridging Cognition and Neuromorphic Computing. In: Hammer,\
    \ P., Alirezaie, M., & Strannegård, C. (eds) *Artificial General Intelligence.\
    \ AGI 2023* (pp. 345-356) Lecture Notes in Computer Science, vol 13921. Springer,\
    \ Cham. [https://doi.org/10.1007/978-3-031-33469-6\\\\_35](https://doi.org/10.1007/978-3-031-33469-6_35)\n\
    - 31. Shapiro S. C., & Bona J. P. (2010). The GLAIR Cognitive Architecture. *International\
    \ Journal of Machine Consciousness*, *2*(2), 307-332. <https://doi.org/10.1142/S1793843010000515>\n\
    - 32. Miller, M. S. P. (2019). Building Minds with Patterns. *10th Annual International\
    \ Conference on Biologically Inspired Cognitive Architectures BICA 2019*, August\
    \ 16-18, Redmond, WA, USA. <https://www.youtube.com/watch?reload=9&v=kqicbyONxO8>\n\
    - 33. Miller, M. S. P. (2020). *Coding Artificial Minds*. Michael S. P. Miller.\n\
    - 34. Sloman, A., & Chrisley, R. L. (2005). More things than are dreamt of in\
    \ your biology: Information-processing in biologically inspired robots. *Cognitive\
    \ Systems Research*, *6*(2), 145-174. <https://doi.org/10.1016/j.cogsys.2004.06.004>\n\
    - 35. Serov, A. (2022). Evolution of a cognitive architecture on the basis of\
    \ a functional core. *SN Applied Sciences*, *4*, Article 306. https://doi.org/10.1007/s42452-022-05195-6\n\
    - 36. Singh, P. (2005). *EM-ONE: an architecture for reflective commonsense thinking*\
    \ (Doctoral dissertation, Massachusetts Institute of Technology). <https://dspace.mit.edu/bitstream/handle/1721.1/33926/67297587-MIT.pdf>\n\
    - 37. Dushkin, R. V. (2022). Towards AGI: Cognitive Architecture Based on Hybrid\
    \ and Bionic Principles. In: Arai, K. (eds) *Intelligent Computing* (pp. 337-345)\
    \ Lecture Notes in Networks and Systems, vol 283. Springer, Cham. [https://doi.org/10.1007/978-3-030-80119-9\\\
    \\_19](https://doi.org/10.1007/978-3-030-80119-9_19)\n- 38. Davis, D. N. (2003).\
    \ Architectures for cognitive and a-life agents. In: Plekhanova V.(eds) *Intelligent\
    \ agent software engineering* (pp. 27-48). IGI Global. <https://doi.org/10.4018/978-1-59140-046-2.ch002>\n\
    - 39. Venkatamuni, V. M. (2008). *A society of mind approach to cognition and\
    \ metacognition in a cognitive architecture* (Doctoral dissertation, University\
    \ of Hull). <https://hull-repository.worktribe.com/output/4213883>\n- 40. Bach,\
    \ J. (2009). *Principles of synthetic intelligence PSI: an architecture of motivated\
    \ cognition*. Oxford University Press, Inc.\n- 41. Hummel, J. E., & Holyoak, K.\
    \ J. (2003). Relational reasoning in a neurally-plausible cognitive architecture:\
    \ An overview of the LISA project. *Cognitive Studies: Bulletin of the Japanese\
    \ Cognitive Science Society, 10*, 58-75. https://doi.org/10.11225/jcss.10.58\n\
    - 42. Chandiok, A., & Chaturvedi, D. K. (2018). CIT: Integrated cognitive computing\
    \ and cognitive agent technologies based cognitive architecture for human-like\
    \ functionality in artificial systems. *Biologically inspired cognitive architectures,\
    \ 26*, 55-79. <https://doi.org/10.1016/j.bica.2018.07.020>\n- 43. Forbus, K. D.,\
    \ & Hinrich, T. (2017). Analogy and relational representations in the companion\
    \ cognitive architecture. *AI Magazine, 38*(4), 34-42. <https://doi.org/10.1609/aimag.v38i4.2743>\n\
    \n- 44. Augello, A., Infantino, I., Lieto, A., Pilato, G., Rizzo, R., Vella, F.\
    \ (2016). Artwork creation by a cognitive architecture integrating computational\
    \ creativity and dual process approaches. *Biologically inspired cognitive architectures*,\
    \ *15*, 74-86. <https://doi.org/10.1016/j.bica.2015.09.007>\n- 45. Cassimatis,\
    \ N. L. (2001). *Polyscheme: a cognitive architecture for intergrating multiple\
    \ representation and inference schemes* (Doctoral dissertation, Massachusetts\
    \ Institute of Technology). <https://dspace.mit.edu/bitstream/handle/1721.1/8325/50491511-MIT.pdf>\n\
    - 46. Larue, O., Poirier, P., Nkambou, R. (2012). A Three-Level Cognitive Architecture\
    \ for the Simulation of Human Behaviour. In: Kosseim, L., Inkpen, D. (eds) *Advances\
    \ in Artificial Intelligence. Canadian AI 2012* (pp. 337-342). Lecture Notes in\
    \ Computer Science, vol 7310. Springer, Berlin, Heidelberg[. https://doi.org/10.1007/978-3-642-30353-1\\\
    \\_33](https://doi.org/10.1007/978-3-642-30353-1_33)\n- 47. Sun, R. (2016). *Anatomy\
    \ of the mind: exploring psychological mechanisms and processes with the Clarion\
    \ cognitive architecture.* Oxford University Press.\n- 48. Pollock, J. L. (2008).\
    \ Oscar: An architecture for generally intelligent agents. *Frontiers in Artificial\
    \ Intelligence and Applications, 171*, Wang, P., Goertzel, B. & Franklin, S. (eds.)\
    \ Artificial General Intelligence 2008: Proceedings of the First AGI Conference.\
    \ IOS Press, pp. 275-286. <https://www.johnpollock.us/ftp/PAPERS/General%20Intelligence.pdf>\n\
    - 49. Nirenburg, S., McShane, M., Beale, S., & Catizone, R. (2011). A cognitive\
    \ architecture for simulating bodies and minds. In *AMIA Annual Symposium Proceedings*\
    \ (Vol. 2011, pp. 905-914). American Medical Informatics Association. <https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3243225/>\n\
    - 50. Oentaryo, R. J., & Pasquier, M. (2008, June). Towards a novel integrated\
    \ neuro-cognitive architecture (INCA). In *2008 IEEE International Joint Conference\
    \ on Neural Networks (IEEE World Congress on Computational Intelligence)* (pp.\
    \ 1902-1909). IEEE. <https://doi.org/10.1109/IJCNN.2008.4634058>\n- 51. Crowder,\
    \ J.A., Carbone, J.N., Friess, S.A. (2014). Artificial Cognitive System Architectures.\
    \ In: *Artificial Cognition Architectures* (pp. 229-242). Springer, New York,\
    \ NY. [https://doi.org/10.1007/978-1-4614-8072-3\\\\_9](https://doi.org/10.1007/978-1-4614-8072-3_9)\n\
    - 52. Reser, J. E. (2022). A Cognitive Architecture for Machine Consciousness\
    \ and Artificial Superintelligence: Updating Working Memory Iteratively. *arXiv\
    \ preprint arXiv:2203.17255*. <https://doi.org/10.48550/arXiv.2203.17255>\n- 53.\
    \ Voss, P., & Jovanovic, M. (2023). Concepts is All You Need: A More Direct Path\
    \ to AGI. *arXiv preprint arXiv:2309.01622*. <https://doi.org/10.48550/arXiv.2309.01622>\n\
    - 54. Samsonovich, A. V. (2013). Extending Cognitive Architectures. In: Chella,\
    \ A., Pirrone, R., Sorbello, R., & Jóhannsdóttir, K. (eds) *Biologically Inspired\
    \ Cognitive Architectures 2012* (pp. 41-49) Advances in Intelligent Systems and\
    \ Computing, vol 196. Springer, Berlin, Heidelberg. [https://doi.org/10.1007/978-3-642-34274-5\\\
    \\_11](https://doi.org/10.1007/978-3-642-34274-5_11)\n- 55. Sukhobokov, A. A.,\
    \ Gapanyuk, Y. E., & Chernenkiy, V. M. (2020). Consciousness and Subconsciousness\
    \ as a Means of AGI's and Narrow AI's Integration. In: Samsonovich, A. (eds) *Biologically\
    \ Inspired Cognitive Architectures 2019* BICA 2019 (pp. 515-520) Advances in Intelligent\
    \ Systems and Computing, vol 948. Springer, Cham. [https://doi.org/10.1007/978-3-030-25719-4\\\
    \\_66](https://doi.org/10.1007/978-3-030-25719-4_66)\n- 56. Tarassov, V. B., &\
    \ Gapanyuk, Y. E. (2020). Complex Graphs in the Modeling of Multiagent Systems:\
    \ From Goal-Resource Networks to Fuzzy Metagraphs. In: Kuznetsov, S. O., Panov,\
    \ A. I., & Yakovlev, K. S. (eds) *Artificial Intelligence* RCAI 2020 (pp. 177-198)\
    \ Lecture Notes in Computer Science, vol 12412. Springer, Cham. [https://doi.org/10.1007/978-3-030-59535-7\\\
    \\_13](https://doi.org/10.1007/978-3-030-59535-7_13)\n- 57. Sukhobokov, A. A.,\
    \ & Lavrinova, L. I. (2021). AGI Components for Enterprise Management Systems.\
    \ In: Samsonovich, A.V., Gudwin, R.R., & Simões, A.d.S. (eds) *Brain-Inspired\
    \ Cognitive Architectures for Artificial Intelligence: BICA\\*AI 2020* BICA 2020\
    \ (pp. 495-500) Advances in Intelligent Systems and Computing, vol 1310. Springer,\
    \ Cham. [https://doi.org/10.1007/978-3-030-65596-9\\\\_60](https://doi.org/10.1007/978-3-030-65596-9_60)\n\
    - 58. Sukhobokov, A. A., Gapanyuk, Y. E., Zenger, A. S. & Tsvetkova, A. K. (2022).\
    \ The concept of an intelligent data lake management system: machine consciousness\
    \ and a universal data model. *Procedia Computer Science*. *213*, 407-414. <https://doi.org/10.1016/j.procs.2022.11.085>\n\
    - 59. Kruchinin, S. V. (2017). Protogaphs and Archigraphs as a Graphs Generalization.\
    \ *Journal of Scientific Research Publications*, (3(41)), 23-33.\n- [https://www.elibrary.ru/download/elibrary\\\
    \\_30637766\\\\_39362008.pdf](https://www.elibrary.ru/download/elibrary_30637766_39362008.pdf)\
    \ 60. Kruchinin, S. V. (2017). On some generalizations of graphs: multigraphs,\
    \ hypergraphs, metagraphs, flow and port graphs, protographs, archigraphs. *Science\
    \ issues,* (3), 48-67.\n- [https://elibrary.ru/download/elibrary\\\\_32627955\\\
    \\_58725411.pdf](https://elibrary.ru/download/elibrary_32627955_58725411.pdf)\
    \ 61. Samokhvalov, E. N., Revunkov, G. I., & Gapanyuk, Y. E. (2015). Metagraphs\
    \ for Information Systems Semantics and Pragmatics Definition. *Herald of the\
    \ Bauman Moscow State Technical University. Series Instrument Engineering,* (1),\
    \ 83-99. [https://elibrary.ru/download/elibrary\\\\_22978780\\\\_19587991.pdf](https://elibrary.ru/download/elibrary_22978780_19587991.pdf)\n\
    - 62. Chernenkiy, V. M, Gapanyuk, Y. E., Revunkov, G. I., Kaganov, Y. T., Fedorenko,\
    \ Y. S., & Minakova, S. V. (2017). Using metagraph approach for complex domains\
    \ description. In: L. Kalinichenko, Y. Manolopoulos, N. Skvortsov, & V. Sukhomlin\
    \ (eds) *Selected Papers of the 19th International Conference on Data Analytics\
    \ and Management in Data Intensive Domains* DAMDID/RCDL'2017 (pp. 342-349) CEUR\
    \ WORKSHOP PROCEEDINGS. vol 2022.<https://ceur-ws.org/Vol-2022/paper52.pdf>\n\
    - 63. Gapanyuk, Y. (2021). The development of the metagraph data and knowledge\
    \ model. In: Tarassov, V. B., Borisov, V. V., & Kobrinskii B. A. (eds) *Advances\
    \ in Fuzzy Systems and Soft Computing: Selected Contributions to the 10th International\
    \ Conference on \"Integrated Models and Soft Computing in Artificial Intelligence*\
    \ IMSC-2021 (pp. 1-7) CEUR WORKSHOP PROCEEDINGS. vol 2965[. https://ceur-ws.org/Vol-2965/paper01.pdf](https://ceur-ws.org/Vol-2965/paper01.pdf)\n\
    - 64. Burdakov A. (1922). *What is a pseudograph. Definition of a pseudograph.*\
    \ Retrieved from <https://deep-econom.livejournal.com/1042208.html> . Accessed\
    \ August 28, 2023\n- 65. Nlab (1922). *pseudograph.* Retrieved from<https://ncatlab.org/nlab/show/pseudograph>\
    \ . Accessed August 28, 2023\n- 66. Ajzerman, М. А., Vol'skij, V. I., & Litvakov,\
    \ B. М. (1993). Pseudographs and Pseudograph-Based Choice. *Automation and Remote\
    \ Control*, *54*(7), 138-149. <https://www.mathnet.ru/links/7490edc8620d5fb77a071a16db2561e3/at2988.pdf>\n\
    - 67. Chernenkiy, V. M., Gapanyuk, Y. E., Kaganov, Y., Dunin, I., Lyaskovsky,\
    \ M., & Larionov, V. (2018, October). Storing Metagraph Model in Relational, Document-Oriented,\
    \ and Graph Databases. In: [Kalinichenko,](http://synthesis.ipi.ac.ru/synthesis/staff/lak.html)\
    \ L., [Manolopoulos,](http://delab.csd.auth.gr/~manolopo/yannis.html) Y., [Stupnikov,](http://synthesis.ipi.ac.ru/synthesis/staff/ssa.html)\
    \ S., [Skvortsov,](http://synthesis.ipi.ac.ru/synthesis/staff/nskv.html) N., [Sukhomlin,](http://www.sukhomlin.ru/)\
    \ V. (eds) *Selected Papers of the XX International Conference on Data Analytics\
    \ and Management in Data Intensive Domains* DAMDID/RCDL 2018 (pp. 82-89) CEUR\
    \ WORKSHOP PROCEEDINGS. vol 2277[. https://ceur-ws.org/Vol-2277/paper17.pdf](https://ceur-ws.org/Vol-2277/paper17.pdf)\n\
    - 68. Sukhobokov, А. А., Trufanov, V. А., Stolyarov, Yu. А., Sadykov, М. R., &\
    \ Elizarov, О. О. (2021). Distributed Metagraph DBMS Based on Blockchain Technology.\
    \ *Natural and Technical Sciences,* (7), 201-209. <https://doi.org/10.25633/ETN.2021.07.15>\n\
    - 69. Hardeniya, N. (2015). *NLTK essentials*. Packt Publishing. <https://dl.acm.org/doi/abs/10.5555/2846245>\n\
    - 70. Gomez-Perez, J. M., Denaux, R., & Garcia-Silva, A. (2020). *A Practical\
    \ Guide to Hybrid Natural Language Processing: Combining Neural Models and Knowledge\
    \ Graphs for NLP*. Springer. <https://link.springer.com/book/10.1007/978-3-030-44830-1>\n\
    - 71. Liu, Z., Lin, Y., & Sun, M. (2020). *Representation learning for natural\
    \ language processing*. Springer Nature. <https://doi.org/10.1007/978-981-15-5573-2>\n\
    - 72. Gatt, A., & Krahmer, E. (2018). Survey of the state of the art in natural\
    \ language generation: Core tasks, applications and evaluation. *Journal of Artificial\
    \ Intelligence Research*, *61*, 65-170. <https://doi.org/10.1613/jair.5477>\n\n\
    - 73. Todosiev, N., Yankovskiy, V., Andreev, A., & Gapanyuk, Y. (2023). The Conceptual\
    \ Modeling System Based on Metagraph Approach. *Proceedings of the Institute for\
    \ Systems Analysis Russian Academy of Sciences, 73*(1), 176-184. <https://doi.org/10.14357/20790279230120>\n\
    - 74. Liao, W., Rosenhahn, B., Shuai, L., & Yang, M. Y. (2019). Natural language\
    \ guided visual relationship detection. In: *2019 IEEE/CVF Conference on Computer\
    \ Vision and Pattern Recognition Workshops (CVPRW)* (pp. 444-453). IEEE. <https://doi.org/10.1109/CVPRW.2019.00058>\n\
    - 75. Li, Y., Ouyang, W., Zhou, B., Wang, K., & Wang, X. (2017). Scene graph generation\
    \ from objects, phrases and region captions. In: *2017 IEEE International Conference\
    \ on Computer Vision (ICCV)* (pp. 1270-1279). IEEE.<https://doi.org/10.1109/ICCV.2017.142>\n\
    - 76. Dai, B., Zhang, Y., & Lin, D. (2017). Detecting visual relationships with\
    \ deep relational networks. In: *2017 IEEE Conference on Computer Vision and Pattern\
    \ Recognition (CVPR)* (pp. 3298-3308). IEEE.<https://doi.org/10.1109/CVPR.2017.352>\n\
    - 77. Xu, D., Zhu, Y., Choy, C. B., & Fei-Fei, L. (2017). Scene graph generation\
    \ by iterative message passing. In: *2017 IEEE Conference on Computer Vision and\
    \ Pattern Recognition (CVPR)* (pp. 3097-3106). IEEE[. https://doi.org/10.1109/CVPR.2017.330](https://doi.org/10.1109/CVPR.2017.330)\n\
    - 78. Li, Y., Ouyang, W., Zhou, B., Shi, J., Zhang, C., & Wang, X. (2018). Factorizable\
    \ Net: An Efficient Subgraph-Based Framework for Scene Graph Generation. In: Ferrari,\
    \ V., Hebert, M., Sminchisescu, C., & Weiss, Y. (eds) *Computer Vision – ECCV\
    \ 2018*. ECCV 2018 (pp. 346-363) *Lecture Notes in Computer Science*, vol 11205.\
    \ Springer, Cham. [https://doi.org/10.1007/978-3-030-01246-5\\\\_21](https://doi.org/10.1007/978-3-030-01246-5_21)\n\
    - 79. Xu, P., Chang, X., Guo, L., Huang, P. Y., Chen, X., & Hauptmann, A. G. (2020).\
    \ A survey of scene graph: Generation and application. (No 3385) *EasyChair.*\
    \ [https://easychair.org/publications/preprint\\\\_download/SrPK](https://easychair.org/publications/preprint_download/SrPK)\n\
    - 80. Chang, X., Ren, P., Xu, P., Li, Z., Chen, X., & Hauptmann, A. (2023). A\
    \ comprehensive survey of scene graphs: Generation and application. *IEEE Transactions\
    \ on Pattern Analysis and Machine Intelligence*, *45*(1), 1-26[. https://doi.org/10.1109/TPAMI.2021.3137605](https://doi.org/10.1109/TPAMI.2021.3137605)\n\
    - 81. Elasri, M., Elharrouss, O., Al-Maadeed, S., & Tairi, H. (2022). Image generation:\
    \ A review. *Neural Processing Letters*, *54*(5), 4609-4646. <https://doi.org/10.1007/s11063-022-10777-x>\n\
    - 82. Singh, N.K., Raza, K. (2021). Medical Image Generation Using Generative\
    \ Adversarial Networks: A Review. In: Patgiri, R., Biswas, A., Roy, P. (eds) *Health\
    \ Informatics: A Computational Perspective in Healthcare. Studies in Computational\
    \ Intelligence*, vol 932, pp. 77-96. Springer, Singapore. [https://doi.org/10.1007/978-981-15-9735-0\\\
    \\_5](https://doi.org/10.1007/978-981-15-9735-0_5)\n- 83. Wang, W., Luo, Y., Chen,\
    \ Z., Jiang, T., Chen, L., Yang, Y., & Xiao, J. (2023). Taking A Closer Look at\
    \ Visual Relation: Unbiased Video Scene Graph Generation with Decoupled Label\
    \ Learning. *arXiv preprint arXiv*: *2303.13209v1 [cs.CV].* <https://doi.org/10.48550/arXiv.2303.13209>\n\
    - 84. Mahon, L., Giunchiglia, E., Li, B., Lukasiewicz, T. (2020, December). Knowledge\
    \ graph extraction from videos. In: *2020 19th IEEE International Conference on\
    \ Machine Learning and Applications (ICMLA)* (pp. 25-32). IEEE. <https://doi.org/10.1109/ICMLA51294.2020.00014>\n\
    - 85. Liu, C., & Yu, H. (2023). Ai-empowered persuasive video generation: A survey.\
    \ *ACM Computing Surveys, 55*(13s), Article 285, pp. 1-31[. https://doi.org/10.1145/3588764](https://doi.org/10.1145/3588764)\n\
    - 86. Aldausari, N., Sowmya, A., Marcus, N., & Mohammadi, G. (2022). Video generative\
    \ adversarial networks: a review. *ACM Computing Surveys (CSUR)*, *55*(2), Article\
    \ 30, pp. 1- 25. <https://doi.org/10.1145/3487891>\n- 87. Karim, M. R., Ali, H.,\
    \ Das, P., Abdelwaheb, M., & Decker, S. (2022). Question Answering Over Biological\
    \ Knowledge Graph via Amazon Alexa. *arXiv preprint arXiv:2210.06040v1 [cs.AI].*\
    \ <https://doi.org/10.48550/arXiv.2210.06040>\n- 88. Kiranyaz, S., Avci, O., Abdeljaber,\
    \ O., Ince, T., Gabbouj, M., & Inman, D. J. (2021). 1D convolutional neural networks\
    \ and applications: A survey. *Mechanical systems and signal processing*, *151*,\
    \ Article 107398[. https://doi.org/10.1016/j.ymssp.2020.107398](https://doi.org/10.1016/j.ymssp.2020.107398)\n\
    - 89. Dong, L., Xu, S., & Xu, B. (2018, April). Speech-transformer: a no-recurrence\
    \ sequenceto-sequence model for speech recognition. In: *2018 IEEE international\
    \ conference on acoustics, speech and signal processing (ICASSP)* (pp. 5884-5888).\
    \ IEEE. <https://doi.org/10.1109/ICASSP.2018.8462506>\n- 90. Kwon, Y., Heo, H.\
    \ S., Jung, J. W., Kim, Y. J., Lee, B. J., & Chung, J. S. (2022, May). Multi-scale\
    \ speaker embedding-based graph attention networks for speaker diarisation. In:\
    \ *ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal\
    \ Processing (ICASSP)* (pp. 8367-8371). IEEE. <https://doi.org/10.1109/ICASSP43922.2022.9747450>\n\
    - 91. Tan, X., Qin, T., Soong, F., & Liu, T. Y. (2021). A survey on neural speech\
    \ synthesis. *arXiv preprint arXiv:2106.15561v3 [eess.AS].* <https://doi.org/10.48550/arXiv.2106.15561>\n\
    - 92. Kaur, N., & Singh, P. (2023). Conventional and contemporary approaches used\
    \ in text to speech synthesis: a review. *Artificial Intelligence Review 56*(7),\
    \ 5837–5880. <https://doi.org/10.1007/s10462-022-10315-0>\n- 93. Wali, A., Alamgir,\
    \ Z., Karim, S., Fawaz, A., Ali, M. B., Adan, M., & Mujtaba, M. (2022). Generative\
    \ adversarial networks for speech processing: A review. *Computer Speech & Language*,\
    \ *72*, Article 101308[. https://doi.org/10.1016/j.csl.2021.101308](https://doi.org/10.1016/j.csl.2021.101308)\n\
    - 94. Goto, M., Hashiguchi, H., Nishimura, T., & Oka, R. (2003). RWC music database:\
    \ Music genre database and musical instrument sound database. In: *Proceedings\
    \ of the 4th International Conference on Music Information Retrieval*, pp. 229-230.\
    \ <https://archives.ismir.net/ismir2003/paper/000013.pdf>\n- 95. Hashida, M.,\
    \ Nakamura, E., & Katayose, H. (2017, July). Constructing PEDB 2nd Edition: a\
    \ music performance database with phrase information. In *Proceedings of the 14th\
    \ Sound and Music Computing Conference (SMC 2017)* (pp. 359-364). [http://smc2017.aalto.fi/media/materials/proceedings/SMC17\\\
    \\_p359.pdf](http://smc2017.aalto.fi/media/materials/proceedings/SMC17_p359.pdf)\n\
    - 96. Gygi, B., & Shafiro, V. (2010). Development of the database for environmental\
    \ sound research and application (DESRA): Design, functionality, and retrieval\
    \ considerations. *EURASIP Journal on Audio, Speech, and Music Processing*, *2010*,\
    \ Article 654914, pp. 1-12[. https://link.springer.com/content/pdf/10.1155/2010/654914.pdf](https://link.springer.com/content/pdf/10.1155/2010/654914.pdf)\n\
    - 97. Xenakis, I. (1992). *Formalized music: thought and mathematics in composition*\
    \ (No. 6). Pendragon Press.\n- 98. Andreatta, M. (2004). On group-theoretical\
    \ methods applied to music: some compositional and implementational aspects. In:\
    \ G. Mazzola, T. Noll, and E. Puebla (Eds). *Perspectives in Mathematical and\
    \ Computational Music Theory,* EpOs, Osnabr¨uck, pp. 122-162. <http://recherche.ircam.fr/equipes/repmus/moreno/01AndreattaEpos2004.pdf>\n\
    - 99. Papadopoulos, A. (2014). Mathematics and group theory in music. *arXiv preprint\
    \ arXiv:1407.5757 [math.HO].* <https://doi.org/10.48550/arXiv.1407.5757>\n- 100.\
    \ Peng, J., Hu, X., Huang, W., & Yang, J. (2023). What Is a Multi-Modal Knowledge\
    \ Graph: A Survey. *Big Data Research*, Article 100380. <https://doi.org/10.1016/j.bdr.2023.100380>\n\
    - 101. Wilcke, W. X., Bloem, P., de Boer, V., van t Veer, R. H., & van Harmelen,\
    \ F. A. H. (2020). End-to-end entity classification on multimodal knowledge graphs.\
    \ *arXiv preprint arXiv:2003.1238[3v1](https://arxiv.org/abs/2003.12383v1) [cs.AI].*\
    \ <https://doi.org/10.48550/arXiv.2003.12383>\n- 102. Park, S. M., & Kim, Y. G.\
    \ (2023). Visual language integration: A survey and open challenges. *Computer\
    \ Science Review*, *48*, Article 100548. <https://doi.org/10.1016/j.cosrev.2023.100548>\n\
    - 103. DB-Engines. (2023). *DBMS popularity broken down by database model Number\
    \ of systems per category, August 2023*. Retrieved fro[m https://db-engines.com/en/ranking\\\
    \\_categories](https://db-engines.com/en/ranking_categories) . Accessed August\
    \ 8, 2023\n\n- 104. Cambazoglu, B. B., & Baeza-Yates, R. (2022). Scalability challenges\
    \ in web search engines. Springer Nature. https://doi.org/10.1007/978-3-031-02298-2\n\
    - 105. Hilger, J., & Wahl, Z. (2022). Enterprise Search. In: *Making Knowledge\
    \ Management Clickable*. (pp. 163-179). Springer, Cham[. https://doi.org/10.1007/978-3-030-92385-3\\\
    \\_9](https://doi.org/10.1007/978-3-030-92385-3_9)\n- 106. Bowers, A., & Kalton,\
    \ N. J. (2014). *An introductory course in functional analysis.* Springer. <https://doi.org/10.1007/978-1-4939-1945-1>\n\
    - 107. Lee, G. T. (2018). *Abstract algebra: An introductory course.* Springer.\
    \ https://doi.org/10.1007/978-3-319-77649-1\n- 108. Körner, P., Leuschel, M.,\
    \ Barbosa, J., Costa, V. S., Dahl, V., Hermenegildo, M. V., ... , & Ciatto, G.\
    \ (2022). Fifty years of Prolog and beyond. *Theory and Practice of Logic Programming*,\
    \ *22*(6), 776-858. <https://doi.org/10.1017/S1471068422000102>\n- 109. Sowa,\
    \ J. F. (1992). Semantic networks. Encyclopedia of artificial intelligence, 2,\
    \ 1493- 1511. <http://www.jfsowa.com/pubs/semnet.pdf>\n- 110. Karp, P. D. (1992).\
    \ *The design space of frame knowledge representation systems.* SRI International.\
    \ <https://redirect.cs.umbc.edu/courses/771/spring04/papers/karp-freview.pdf>\n\
    - 111. Weaver, M. T., France, R. K., Chen, Q. F., & Fox, E. A. (1989). Using a\
    \ frame‐based language for information retrieval. *International Journal of Intelligent\
    \ Systems*, *4*(3), 223- 257.<https://doi.org/10.1002/int.4550040303>\n- 112.\
    \ Hernandez, G. B. (2017). The languages of relevant logic: a model-theoretic\
    \ perspective. The thesis for the degree of Doctor of Philosophy at the University\
    \ of Otago, Dunedin, New Zealand [https://ourarchive.otago.ac.nz/bitstream/handle/10523/7068/BadiaHernan](https://ourarchive.otago.ac.nz/bitstream/handle/10523/7068/BadiaHernandezGuillermo2016PhD.pdf?sequence=1&isAllowed=y)[dezGuillermo2016PhD.pdf?sequence=1&isAllowed=y](https://ourarchive.otago.ac.nz/bitstream/handle/10523/7068/BadiaHernandezGuillermo2016PhD.pdf?sequence=1&isAllowed=y)\n\
    - 113. Ehrlinger, L., & Wöß, W. (2016). Towards a definition of knowledge graphs.\
    \ In: [Martin,](http://aksw.org/MichaelMartin.html)  М., [Cuquet,](http://mcuquet.github.io/)\
    \ М., & Folmer, E. (eds) *Posters&Demos@SEMANTiCS 2016 and SuC-CESS'16 Workshop*\
    \ (pp. 1-4). SEMANTiCS 2016. CEUR WORKSHOP PROCEEDINGS. vol 1695[. https://ceur-ws.org/Vol-1695/paper4.pdf](https://ceur-ws.org/Vol-1695/paper4.pdf)\n\
    - 114. ISO. (2018). *INTERNATIONAL STANDARD ISO/IEC 24707:2018 Information technology\
    \ — Common Logic (CL) — A framework for a family of logic-based languages.* Retrieved\
    \ fro[m https://www.iso.org/standard/66249.html](https://www.iso.org/standard/66249.html)\
    \ . Accessed August 12, 2023\n- 115. Guha, R. V., & Lenat, D. B. (1991). CYC:\
    \ A mid-term report. *Applied Artificial Intelligence an International Journal*,\
    \ *5*(1), 45-86. <https://doi.org/10.1080/08839519108927917>\n- 116. De Cat, B.,\
    \ Bogaerts, B., Bruynooghe, M., Janssens, G., & Denecker, M. (2018). Predicate\
    \ logic as a modeling language: the IDP system. In: Kifer, M., & Liu, Y. A. (Eds.).\
    \ *Declarative Logic Programming: Theory, Systems, and Applications* (pp. 279-323).\
    \ Machinery and Morgan & Claypool. <https://doi.org/10.1145/3191315.3191321>\n\
    - 117. KSL.Stanford (1992). *Knowledge Interchange Format (KIF).* Retrieved from\
    \ [https://web.archive.org/web/20070212094221/http://www.ksl.stanford.edu/knowledge](https://web.archive.org/web/20070212094221/http:/www.ksl.stanford.edu/knowledge-sharing/kif/)[sharing/kif/](https://web.archive.org/web/20070212094221/http:/www.ksl.stanford.edu/knowledge-sharing/kif/)\
    \ Accessed August 13, 2023\n- 118. Genesereth, M. R., & Fikes R. E. (1992). *Knowledge\
    \ Interchange Format. Version 3.0. Reference Manual.* Computer Science Department\
    \ at Stanford University <https://www.cs.auckland.ac.nz/courses/compsci367s2c/resources/kif.pdf>\n\
    - 119. W3C. (2014). RDF 1.1 *Concepts and Abstract Syntax.* Retrieved from <https://www.w3.org/TR/rdf11-concepts/>.\
    \ Accessed August 12, 2023\n- 120. W3C. (2012). *OWL 2 Web Ontology Language Document\
    \ Overview (Second Edition)* Retrieved from <https://www.w3.org/TR/2012/REC-owl2-overview-20121211/>\
    \ . Accessed August 12, 2023\n- 121. Heflin, J., & Hendler, J. (2001). A portrait\
    \ of the Semantic Web in action. *IEEE Intelligent Systems*, *16*(2), 54-59. https://doi.org/\
    \ [10.1109/5254.920600](https://doi.org/10.1109/5254.920600)\n- 122. Guizzardi,\
    \ G., Botti Benevides, A., Fonseca, C. M., Porello, D., Almeida, J. P. A., & Sales,\
    \ T. P. (2022). UFO: Unified foundational ontology. *Applied ontology*, *17*(1),\
    \ 167-210. <https://doi.org/10.3233/AO-210256>\n- 123. Guizzardi, G., & Wagner,\
    \ G. (2012, December). Conceptual simulation modeling with Onto-UML advanced tutorial.\
    \ In: *Proceedings of the 2012 Winter Simulation Conference* (WSC) (pp. 1-15).\
    \ IEEE. <https://doi.org/10.1109/WSC.2012.6465133>\n- 124. Jarrar, M., & Meersman,\
    \ R. (2008). Ontology Engineering The DOGMA Approach. In: Dillon, T.S., Chang,\
    \ E., Meersman, R., & Sycara, K. (eds) *Advances in Web Semantics I: Ontologies,\
    \ Web Services and Applied Semantic Web*, 7-34. Lecture Notes in Computer Science,\
    \ vol 4891. Springer[. https://doi.org/10.1007/978-3-540-89784-2\\\\_2](https://doi.org/10.1007/978-3-540-89784-2_2)\n\
    - 125. Farquhar, A., Fikes, R., & Rice, J. (1997). Tools for assembling modular\
    \ ontologies in Ontolingua. In: [Kuipers,](https://dblp.org/pid/k/BenjaminKuipers.html)\
    \ B., & [Webber,](https://dblp.org/pid/95/4733.html) B. L. (eds). *Proceedings\
    \ of the Fourteenth National Conference on Artificial Intelligence and Ninth Innovative\
    \ Applications of Artificial Intelligence Conference, AAAI 97*, 454-459.\n- <https://redirect.cs.umbc.edu/courses/771/current/papers/KSL-97-03.pdf>\
    \ 126. MacGregor, R., & Burstein, M. H. (1991). Using a description classifier\
    \ to enhance knowledge representation. *IEEE Expert*, *6*(3), 41-46[. https://doi.org/10.1109/64.87683](https://doi.org/10.1109/64.87683)\n\
    - 127. Rattanasawad, T., Saikaew, K. R., Buranarach, M., & Supnithi, T. (2013,\
    \ September). A review and comparison of rule languages and rule-based inference\
    \ engines for the Semantic Web. In: *2013 International Computer Science and Engineering\
    \ Conference (ICSEC)* (pp. 1-6). IEEE[. https://doi.org/10.1109/ICSEC.2013.6694743](https://doi.org/10.1109/ICSEC.2013.6694743)\n\
    - 128. Riley, G., & Giarratano, J. C. (2005). *Expert systems: principles and\
    \ programming.* Thomson Course Technology.\n- 129. Varlamov, O. O. (2018). Wi!\
    \ Mi expert system shell as the novel tool for building knowledge-based systems\
    \ with linear computational complexity. *International Review of Automatic Control*,\
    \ *11*(6), 314-325. <https://doi.org/10.15866/ireaco.v11i6.15855>\n- 130. Popov,\
    \ I. A., Erokhin, I. A., Sukhobokov, A. A., Gromozdov, D. R., & Belousov, E. A.\
    \ (2022). An implementation of different minimal consciousness's variants for\
    \ a cyber-physical system. *Procedia Computer Science*, *213*, 370-376. <http://doi.org/10.1016/j.procs.2022.11.080>\n\
    - 131. Gross, M., & Lentin, A. (2012). *Introduction to formal grammars.* Springer\
    \ Science & Business Media.\n- 132. Poelmans, J., Kuznetsov, S. O., Ignatov, D.\
    \ I., & Dedene, G. (2013). Formal concept analysis in knowledge processing: A\
    \ survey on models and techniques. *Expert systems with applications*, *40*(16),\
    \ 6601-6623. <https://doi.org/10.1016/j.eswa.2013.05.007>\n- 133. Vykhovanets,\
    \ V. S. (2021, May). The notional model of knowledge representation. *Journal\
    \ of physics: conference series 1864*, Article 012058. IOP Publishing. <https://doi.org/10.1088/1742-6596/1864/1/012058>\n\
    - 134. Chuvikov, D. A., & Nazarov, K. V. (2016). Designing algorithms for solving\
    \ physics problems on the basis of mivar approach. *International Journal of Advanced\
    \ Studies*, *6*(3), 31- 50. <https://doi.org/10.12731/2227-930X-2016-3-31-50>\n\
    - 135. Varlamov, O. O. (2002). *Evolutionary databases and knowledge for adaptive\
    \ synthesis of intelligent systems. Mivar information space.* Radio and communications,\
    \ Moscow. [https://elibrary.ru/download/elibrary\\\\_21237254\\\\_68431832.pdf](https://elibrary.ru/download/elibrary_21237254_68431832.pdf)\n\
    - 136. Boccaletti, S., Latora, V., Moreno, Y., Chavez, M., & Hwang, D.-U. (2006).\
    \ Complex networks: Structure and dynamics. *Physics Reports*, *424*(4–5), 175-308.\
    \ <https://doi.org/10.1016/j.physrep.2005.10.009>\n- 137. Reisig, W. (2012). *Petri\
    \ nets: an introduction.* Springer. [https://doi.org/10.1007/978-3-](https://doi.org/10.1007/978-3-642-69968-9)\
    \ [642-69968-9](https://doi.org/10.1007/978-3-642-69968-9)\n- 138. Hadjicostis,\
    \ C. N. (2020). *Estimation and inference in discrete event systems: A Model-Based\
    \ Approach with Finite Automata.* Springer International Publishing. <https://doi.org/10.1007/978-3-030-30821-6>\n\
    - 139. Choi, B. K., & Kang, D. (2013). *Modeling and simulation of discrete event\
    \ systems*. John Wiley & Sons.\n\n- 140. Samsonovich, A. V. (2009, October). The\
    \ Constructor metacognitive architecture. In *2009 AAAI Fall Symposium Series*[.\
    \ https://cdn.aaai.org/ocs/999/999-4272-1-PB.pdf](https://cdn.aaai.org/ocs/999/999-4272-1-PB.pdf)\n\
    - 141. Osawa, M., Omori, T., Takahashi, K., Arakawa, N., Sakai, N., Imai, M.,\
    \ & Yamakawa, H. (2019). Function Map-Driven Development for AGI. In: Samsonovich,\
    \ A. (eds) *Biologically Inspired Cognitive Architectures 2018* BICA 2018 (pp.\
    \ 239–244) Advances in Intelligent Systems and Computing, vol 848. Springer, Cham.\
    \ https://doi.org/10.1007/978-3-319-99316-4\\_32\n- 142. Shanahan, M. (2006).\
    \ A cognitive architecture that combines internal simulation with a global workspace.\
    \ *Consciousness and cognition*, *15*(2), 433-449. <https://doi.org/10.1016/j.concog.2005.11.005>\n\
    - 143. Chella, A., Frixione, M., & Gaglio, S. (2008). A cognitive architecture\
    \ for robot self-consciousness. *Artificial intelligence in medicine*, *44*(2),\
    \ 147-154. <https://doi.org/10.1016/j.artmed.2008.07.003>\n- 144. Becker, T.,\
    \ Fabro, J. A., Oliveira, A. S. D., & Reis, L. P. (2015), Adding Conscious Aspects\
    \ in Virtual Robot Navigation through Baars-Franklin's Cognitive Architecture.\
    \ In: *2015 IEEE International Conference on Autonomous Robot Systems and Competitions*.\
    \ (pp. 204- 209). IEEE. <https://doi.org/10.1109/ICARSC.2015.34>\n- 145. Gudwin,\
    \ R., Paraense, A., de Paula, S. M., Fróes, E., Gibaut, W., Castro, E., Figueiredo,\
    \ V,, & Raizer, K. (2017). The multipurpose enhanced cognitive architecture (MECA).\
    \ *Biologically Inspired Cognitive Architectures*, *22*, 20-34. <https://doi.org/10.1016/j.bica.2017.09.006>\n\
    - 146. Dyachenko, Y., Nenkov, N., Petrova, M., Skarga-Bandurova, I., & Soloviov,\
    \ O. (2018). Approaches to cognitive architecture of autonomous intelligent agent.\
    \ *Biologically Inspired Cognitive Architectures*, *26*, 130-135.<https://doi.org/10.1016/j.bica.2018.10.004>\n\
    - 147. Chella, A., & Pipitone, A. (2020). A cognitive architecture for inner speech.\
    \ *Cognitive Systems Research*, 59, 287-292. <https://doi.org/10.1016/j.cogsys.2019.09.010>\n\
    - 148. Burrafato, M., & Florio, L. (2012). *A cognitive architecture based on\
    \ an amygdala-thalamo-cortical model for developing new goals and behaviors: application\
    \ in humanoid robotics.* Artificial Intelligence and Robotics Laboratory of the\
    \ Polytechnic of Milan. [https://www.politesi.polimi.it/retrieve/a81cb05a-32b0-616b-e053-](https://www.politesi.polimi.it/retrieve/a81cb05a-32b0-616b-e053-1605fe0a889a/2012_10_Burrafato_Florio.pdf)\
    \ [1605fe0a889a/2012\\\\_10\\\\_Burrafato\\\\_Florio.pdf](https://www.politesi.polimi.it/retrieve/a81cb05a-32b0-616b-e053-1605fe0a889a/2012_10_Burrafato_Florio.pdf)\n\
    - 149. Lanza, F. (2021). *Human-Robot Teaming Interaction: a Cognitive Architecture\
    \ Solution.* University of Palermo. Ph.D. Thesis.\n- [https://iris.unipa.it/retrieve/handle/10447/479089/1105689/Tesi\\\
    \\_di\\\\_Dottorato\\\\_lanza.pdf](https://iris.unipa.it/retrieve/handle/10447/479089/1105689/Tesi_di_Dottorato_lanza.pdf)\
    \ 150. Chatila, R., Renaudo, E., Andries, M., Chavez-Garcia, R. O., Luce-Vayrac,\
    \ P., Gottstein,\n- R., ... & Khamassi, M. (2018). Toward self-aware robots. *Frontiers\
    \ in Robotics and AI, 5*, Article 88. <https://doi.org/10.3389/frobt.2018.00088>\n\
    - 151. Augello, A., Gaglio, S., Infantino, I., Maniscalco, U., Pilato, G., & Vella,\
    \ F. (2023). Roboception and adaptation in a cognitive robot. *Robotics and Autonomous\
    \ Systems, 164*, Article 104400. <https://doi.org/10.1016/j.robot.2023.104400>\n\
    - 152. Shylaja, K. R., Vijayakumar, M. V., Davis, D. N., & Prasad, E. V. (2013).\
    \ Cognitive Architecture to Evolve Conscious Cognitive Tasks into Common Sense\
    \ Actions on Agents. In: *Proceedings of the World Congress on Engineering and\
    \ Computer Science* (Vol. 1, pp. 383-388)[. https://www.iaeng.org/publication/WCECS2013/WCECS2013\\\
    \\_pp383-388.pdf](https://www.iaeng.org/publication/WCECS2013/WCECS2013_pp383-388.pdf)\n\
    - 153. Starzyk, J. A., & Graham, J. (2017). MLECOG: Motivated learning embodied\
    \ cognitive architecture. *IEEE Systems Journal*, *11*(3), 1272-1283. <https://doi.org/10.1109/JSYST.2015.2442995>\n\
    - 154. Chatterjee, S. (December 14, 2012). The Cognitive Architecture for Artificial\
    \ Consciousness: Machine Mental States. *Social Science Research Network*. <http://doi.org/10.2139/ssrn.2189382>\n\
    - 155. Huyck, C. R. (2017, October). The neural cognitive architecture. In *2017\
    \ AAAI Fall Symposium Series*[. https://cdn.aaai.org/ocs/15954/15954-69912-1-PB.pdf](https://cdn.aaai.org/ocs/15954/15954-69912-1-PB.pdf)\n\
    - 156. Faghihi, U., Fournier-Viger, P., Nkambou, R. (2013). CELTS: A Cognitive\
    \ Tutoring Agent with Human-Like Learning Capabilities and Emotions. In: Peña-Ayala,\
    \ A. (eds) *Intelligent and Adaptive Educational-Learning Systems. Smart Innovation,\
    \ Systems and Technologies*, vol 17, pp. 339-365. Springer, Berlin, Heidelberg.\
    \ [https://doi.org/10.1007/978-3-642-30171-1\\\\_14](https://doi.org/10.1007/978-3-642-30171-1_14)\n\
    - 157. Augello, A., Infantino, I., Lieto, A., Pilato, G., Rizzo, R., & Vella,\
    \ F. (2016). Artwork creation by a cognitive architecture integrating computational\
    \ creativity and dual process approaches. *Biologically inspired cognitive architectures*,\
    \ *15*, 74-86. <https://doi.org/10.1016/j.bica.2015.09.007>\n- 158. Cerone, A.\
    \ (2018). Towards a Cognitive Architecture for the Formal Analysis of Human Behaviour\
    \ and Learning. In: Mazzara, M., Ober, I., Salaün, G. (eds) *Software Technologies:\
    \ Applications and Foundations.* STAF 2018. Lecture Notes in Computer Science\
    \ (pp. 216-232), vol 11176. Springer, Cham[. https://doi.org/10.1007/978-3-030-04771-9\\\
    \\_17](https://doi.org/10.1007/978-3-030-04771-9_17)\n- 159. Garrido-Mercháin,\
    \ E. C., Molina, M., & Mendoza-Soto, F. M. (2022). A global workspace model implementation\
    \ and its relations with philosophy of mind. *Journal of Artificial Intelligence\
    \ and Consciousness*, *9*(01), 1-28. <http://dx.doi.org/10.1142/S270507852150020X>\n\
    - 160. Graham, J., & Starzyk, J. A. (2013, April). Transitioning from motivated\
    \ to cognitive agent model. In: *2013 IEEE Symposium on Computational Intelligence\
    \ for Human-like Intelligence (CIHLI)* (pp. 9-16). IEEE. <https://doi.org/10.1109/CIHLI.2013.6613259>\n\
    - 161. Chernenkiy, V., Gapanyuk, Y., Terekhov, V., Revunkov, G., & Kaganov, Y.\
    \ (2018). The hybrid intelligent information system approach as the basis for\
    \ cognitive architecture. *Procedia computer science*, *145*, 143-152. <https://doi.org/10.1016/j.procs.2018.11.022>\n\
    - 162. Wiedermann, J., & Leeuwen, J. V. (2019, July). Finite state machines with\
    \ feedback: an architecture supporting minimal machine consciousness. In: *Conference\
    \ on Computability in Europe* (pp. 286-297). Springer, Cham[. https://doi.org/10.1007/978-3-319-59740-9\\\
    \\_2](https://doi.org/10.1007/978-3-319-59740-9_2)\n- 163. Wiedermann, J., & Leeuwen,\
    \ J. V. (2021, January). Towards Minimally Conscious Cyber-Physical Systems: A\
    \ Manifesto. In: *International Conference on Current Trends in Theory and Practice\
    \ of Informatics* (pp. 43-55). Springer, Cham. [https://doi.org/10.1007/978-3-030-67731-2\\\
    \\_4](https://doi.org/10.1007/978-3-030-67731-2_4)\n- 164. Henninger, A. E., Jones,\
    \ R. M., & Chown, E. (2003, July). Behaviors that emerge from emotion and cognition:\
    \ implementation and evaluation of a symbolic-connectionist architecture. In:\
    \ *Proceedings of the second international joint conference on Autonomous agents\
    \ and multiagent systems* (pp. 321-328)[. https://doi.org/10.1145/860575.860627](https://doi.org/10.1145/860575.860627)\n\
    - 165. Ekanayake, H., Karunarathna, D. D., & Hewagamage, K. P. (2006). Behavior-based\
    \ Cognitive Architecture for Meditative E-Learning. *Innovations for a Knowledge\
    \ Economy*. Proceedings of the 8th International Information Technology Conference\
    \ IITC2006, pp. 80-88. Colombo Sri Lanka: Infotel Lanka Society Ltd, 2008. [https://citeseerx.ist.psu.edu/docu](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=0fa059b2640e113348d8fc126095142ed9dd04f9#page=87)[ment?repid=rep1&type=pdf&doi=0fa059b2640e113348d8fc126095142ed9dd04f9#page](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=0fa059b2640e113348d8fc126095142ed9dd04f9#page=87)\
    \ [=87](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=0fa059b2640e113348d8fc126095142ed9dd04f9#page=87)\n\
    - 166. van Ments, L., Treur, J. (2022). Dynamics, Adaptation and Control for Mental\
    \ Models: A Cognitive Architecture. In: Treur, J., Van Ments, L. (eds) *Mental\
    \ Models and Their Dynamics, Adaptation, and Control.* Studies in Systems, Decision\
    \ and Control, vol 394, pp. 3-26. Springer, Cham[. https://doi.org/10.1007/978-3-030-85821-6\\\
    \\_1](https://doi.org/10.1007/978-3-030-85821-6_1)\n- 167. Burger, J. R. (2008).\
    \ Cognitive Architecture for Direction of Attention Founded on Subliminal Memory\
    \ Searches, Pseudorandom and Nonstop. *arXiv preprint arXiv:0805.3126*. <https://doi.org/10.48550/arXiv.0805.3126>\n\
    - 168. Scheutz, M., Williams, T., Krause, E., Oosterveld, B., Sarathy, V., Frasca,\
    \ T. (2019). An Overview of the Distributed Integrated Cognition Affect and Reflection\
    \ DIARC Architecture. In: Aldinhas Ferreira, M., Silva Sequeira, J., Ventura,\
    \ R. (eds) *Cognitive Architectures. Intelligent Systems, Control and Automation:\
    \ Science and Engineering*, vol 94, pp. 165-193. Springer, Cham. [https://doi.org/10.1007/978-3-319-97550-4\\\
    \\_11](https://doi.org/10.1007/978-3-319-97550-4_11)\n\n- 169. Chernavskaya, O.\
    \ To the Problem of Digital Immortality. *Social Science Research Network*. <https://doi.org/10.2139/ssrn.4593718>\n\
    - 170. Nagoev, Z., Nagoeva, O., & Gurtueva, I. (2020). Multi-agent neurocognitive\
    \ models of semantics of spatial localization of events. *Cognitive Systems Research*,\
    \ *59*, 91-102. https://doi.org/10.1016/j.cogsys.2019.09.015\n- 171. Langley,\
    \ P., & Choi, D. (2006, July). A unified cognitive architecture for physical agents.\
    \ In: *AAAI'06 Proceedings of the National Conference on Artificial Intelligence*\
    \ (Vol. 2, pp. 1469-1474). AAAI Pres[s.http://www.isle.org/~langley/papers/icarus.aaai06.pdf](http://www.isle.org/~langley/papers/icarus.aaai06.pdf)\n\
    - 172. Longo, C. F., Santoro, C., Asmundo, M. N., Santamaria, D. F., & Cantone,\
    \ D. (2021). SW-CASPAR: Reactive-Cognitive Architecture based on Natural Language\
    \ Processing for the task of Decision-Making in the Open-World Assumption. In:\
    \ [Calegari,](https://www.unibo.it/sitoweb/roberta.calegari/en) R., [Ciatto,](https://www.unibo.it/sitoweb/giovanni.ciatto/en)\
    \ G., [Denti,](https://www.unibo.it/sitoweb/enrico.denti/en) E., [Omicini,](https://www.unibo.it/sitoweb/andrea.omicini/en)\
    \ A., [& Sartor,](https://www.unibo.it/sitoweb/giovanni.sartor/en) G. (eds) 22nd\
    \ Workshop \"From Objects to Agents\" (pp. 178-193). WOA 2021. CEUR WORKSHOP PROCEEDINGS.\
    \ vol 2963. <https://ceur-ws.org/Vol-2963/paper10.pdf>\n- 173. Kahneman, D. 2011.\
    \ Thinking, fast and slow. Macmillan. <http://www.math.chalmers.se/~ulfp/Review/fastslow.pdf>\n\
    - 174. Rauterberg, M. (2010). Emotions: The Voice of the Unconscious. In: Yang,\
    \ H.S., Malaka, R., Hoshino, J., Han, J.H. (eds) *Entertainment Computing - ICEC\
    \ 2010*. ICEC 2010. (pp. 205-215). Lecture Notes in Computer Science, vol 6243.\
    \ Springer, Berlin, Heidelberg. [https://doi.org/10.1007/978-3-642-15399-0\\\\\
    _19](https://doi.org/10.1007/978-3-642-15399-0_19)\n- 175. Henninger, A. E., Chown,\
    \ E., & Jones, R. (2004). *Emotional synthetic forces*. US Army Research Institute\
    \ for the Behavioral and Social Sciences. [https://citeseerx.ist.psu.edu/docu](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=7b26c84c3240cc00c14c4ed4393c093874d13a9f)[ment?repid=rep1&type=pdf&doi=7b26c84c3240cc00c14c4ed4393c093874d13a9f](https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=7b26c84c3240cc00c14c4ed4393c093874d13a9f)\n\
    - 176. Wahl, S., & Spada, H. (2000). Children IS Reasoning about Intentions, Beliefs\
    \ and Behaviour. *Cognitive Science Quarterly, 1*(1), 3–32. <https://psycnet.apa.org/record/2002-18784-001>\n\
    - 177. Lewis, S. C. (2004). *Computational Models of Emotion and Affect*, PhD\
    \ Thesis, Computer Science, University of Hull.\n\t- <https://ethos.bl.uk/OrderDetails.do?uin=uk.bl.ethos.417166>\n\
    - 178. Low, J., Apperly, I. A., Butterfill, S. A., & Rakoczy, H. (2016). Cognitive\
    \ architecture of belief reasoning in children and adults: A primer on the two‐systems\
    \ account*. Child Development Perspectives, 10*(3), 184*-189.* <https://doi.org/10.1111/cdep.12183>\n\
    - 179. Kodipalli, A. (2018). Cognitive architecture to analyze the effect of intrinsic\
    \ motivation with metacognition over extrinsic motivation on swarm agents. *International\
    \ Journal of Electrical and Computer Engineering*, *8*(5), 3984-3990. <https://doi.org/10.11591/ijece.v8i5.pp3984-3990>\n\
    - 180. Foltyn, L., Tozicka, J., Rollo, M., Pechoucek, M., & Jisl, P. (2006, June).\
    \ Reflective-cognitive architecture: From abstract concept to self-adapting agent.\
    \ In: *IEEE Workshop on Distributed Intelligent Systems: Collective Intelligence\
    \ and Its Applications (DIS'06)* (pp. 326-334). IEEE. https://doi.org/10.1109/DIS.2006.62\n\
    - 181. Ritter, F. E., Bittner, J. L., Kase, S. E., Evertsz, R., Pedrotti, M.,\
    \ & Busetta, P. (2012). CoJACK: A high-level cognitive architecture with demonstrations\
    \ of moderators, variability, and implications for situation awareness. *Biologically\
    \ Inspired Cognitive Architectures, 1*, 2-13[. https://doi.org/10.1016/j.bica.2012.04.004](https://doi.org/10.1016/j.bica.2012.04.004)\n\
    - 182. Patacchiola, M., & Cangelosi, A. (2020). A developmental cognitive architecture\
    \ for trust and theory of mind in humanoid robots. *IEEE Transactions on Cybernetics,\
    \ 52*(3), 1947- 1959*.* https://doi.org[/10.1109/TCYB.2020.3002892](https://doi.org/10.1109/TCYB.2020.3002892)\n\
    - 183. Baskar, J., & Lindgren, H. (2014). Cognitive Architecture of an Agent for\
    \ Human-Agent Dialogues. In: Corchado, J.M., et al. (eds) *Highlights of Practical\
    \ Applications of Hetero-*\n\n*geneous Multi-Agent Systems.* The *PAAMS Collection.\
    \ PAAMS 2014 International Workshops*. (pp. 89-100). Communications in Computer\
    \ and Information Science, vol 430. Springer, Cham[. https://doi.org/10.1007/978-3-319-07767-3\\\
    \\_9](https://doi.org/10.1007/978-3-319-07767-3_9)\n\n- 184. Hudlicka, E. (2002).\
    \ This time with feeling: Integrated model of trait and state effects on cognition\
    \ and behavior. *Applied Artificial Intelligence*, *16*(7-8), 611-641. <https://doi.org/10.1080/08339510290030417>\n\
    - 185. Grassiotto, F., Costa, P. D. P. (2021). CogToM: A Cognitive Architecture\
    \ Implementation of the Theory of Mind. In: *Proceedings of the 13th International\
    \ Conference on Agents and Artificial Intelligence (ICAART 2021).* Vol 2 (pp.\
    \ 546-553). <https://doi.org/10.5220/0010194205460553>\n- 186. Pfeffer, A., &\
    \ Lynn, S.K. (2019). Scruff: A Deep Probabilistic Cognitive Architecture for Predictive\
    \ Processing. In: Samsonovich, A. (eds) *Biologically Inspired Cognitive Architectures\
    \ 2018*. BICA 2018. (pp. 245-259). Advances in Intelligent Systems and Computing,\
    \ vol 848. Springer, Cham[. https://doi.org/10.1007/978-3-319-99316-4\\\\_33](https://doi.org/10.1007/978-3-319-99316-4_33)\n\
    - 187. Longo, C. F., Longo, F., & Santoro, C. (2021). Caspar: Towards decision\
    \ making helpers agents for IoT, based on natural language and first order logic\
    \ reasoning. Engineering Applications of Artificial Intelligence, 104, Article\
    \ 104269. <https://doi.org/10.1016/j.engappai.2021.104269>\n- 188. Gnaneswari,\
    \ G., & Vijayakumar, M. V. (2017). Building a Conversational Agent based on the\
    \ principles of Cognitive Pragmatics using Cognitive Architecture. *International\
    \ Journal of Engineering Research & Technology*, *6*(2), 200-206[. https://www.re](https://www.researchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369_Building_a_Conversational_Agent_based_on_the_principles_of_Cognitive_Pragmatics_using_Cognitive_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent-based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf)[searchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369\\\
    \\_Building\\\\_a\\\\_Con](https://www.researchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369_Building_a_Conversational_Agent_based_on_the_principles_of_Cognitive_Pragmatics_using_Cognitive_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent-based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf)[versational\\\
    \\_Agent\\\\_based\\\\_on\\\\_the\\\\_principles\\\\_of\\\\_Cognitive\\\\_Pragmatics\\\
    \\_using\\\\_Cogni](https://www.researchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369_Building_a_Conversational_Agent_based_on_the_principles_of_Cognitive_Pragmatics_using_Cognitive_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent-based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf)[tive\\\
    \\_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent](https://www.researchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369_Building_a_Conversational_Agent_based_on_the_principles_of_Cognitive_Pragmatics_using_Cognitive_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent-based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf)[based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf](https://www.researchgate.net/profile/Gnaneswari-Gnanaguru/publication/359279369_Building_a_Conversational_Agent_based_on_the_principles_of_Cognitive_Pragmatics_using_Cognitive_Architecture/links/6232d2e80837bf2b9eddf0bd/Building-a-Conversational-Agent-based-on-the-principles-of-Cognitive-Pragmatics-using-Cognitive-Architecture.pdf)\n\
    - 189. Li, H., Liu, X., Jiao, F., Doboli, A., & Doboli, S. (2017). InnovA: a cognitive\
    \ architecture for computational innovation through robust divergence and its\
    \ application for analog circuit design. *IEEE Transactions on Computer-Aided\
    \ Design of Integrated Circuits and Systems, 37*(10), 1943-1956. https://doi.org/10.1109/TCAD.2017.2783344.\n\
    - 190. Heylighen, F. (2011). Life is an Adventure! An Agent-Based Reconciliation\
    \ of Narrative and Scientific Worldviews. *Social Science Research Network*. <http://doi.org/10.2139/ssrn.3075423>\n\
    - 191. Bendaña, J., & Mandelbaum, E. (2021). The fragmentation of belief. In:\
    \ Borgoni, C., Kindermann, D., Onofri, A. (eds.) *The Fragmented Mind* (pp. 78-107)\
    \ Oxford University Press, UK.<https://doi.org/10.1093/oso/9780198850670.003.0004>\n\
    - 192. Egan, A. (2021). Fragmented models of belief. In: Borgoni, C., Kindermann,\
    \ D., Onofri, A. (eds.) *The Fragmented Mind* (pp. 108-134) Oxford University\
    \ Press, UK. <https://doi.org/10.1093/oso/9780198850670.003.0005>\n- 193. Peppas,\
    \ P. (2008). Belief revision. In: van Harmelen, F., Lifschitz, V., & Porter, B.\
    \ (eds). *Handbook of Knowledge Representation* (pp. 317-359). Elsevier. [http://doi.org/10.1016/S1574-6526\\\
    (07\\)03008-8](http://doi.org/10.1016/S1574-6526(07)03008-8)\n- 194. Olsson, E.\
    \ J., & Enqvist, S. (Eds.). (2011). *Belief revision meets philosophy of science.*\
    \ Springer. http://doi.org/10.1007/978-90-481-9609-8\n- 195. Ribeiro, M. M. (2012).\
    \ *Belief revision in non-classical logics.* Springer. <http://doi.org/10.1007/978-1-4471-4186-0>\n\
    - 196. Krinkin, K., Shichkina, Y. (2023). Cognitive Architecture for Co-evolutionary\
    \ Hybrid Intelligence. In: Goertzel, B., Iklé, M., Potapov, A., Ponomaryov, D.\
    \ (eds) *Artificial General Intelligence.* AGI 2022. Lecture Notes in Computer\
    \ Science, vol 13539. (pp. 293-303). Springer, Cham[. https://doi.org/10.1007/978-3-031-19907-3\\\
    \\_28](https://doi.org/10.1007/978-3-031-19907-3_28)\n- 197. van Ments, L., Treur,\
    \ J. (2021). Reflections on dynamics, adaptation and control: a cognitive architecture\
    \ for mental models. *Cognitive Systems Research*, 70, 1-9. <https://doi.org/10.1016/j.cogsys.2021.06.004>\n\
    - 198. Morgan, B. (2010, September). Funk2: a distributed processing language\
    \ for reflective tracing of a large critic-selector cognitive architecture. In:\
    \ *2010 Fourth IEEE International Conference on Self-Adaptive and Self-Organizing\
    \ Systems Workshop* (pp. 269-274). IEEE. <https://doi.org/10.1109/SASOW.2010.56>\n\
    - 199. Jung, Y., Choi, Y., Park, H., Shin, W., & Myaeng, S. H. (2007, August).\
    \ Integrating robot task scripts with a cognitive architecture for cognitive human-robot\
    \ interactions. In: *2007 IEEE International Conference on Information Reuse and\
    \ Integration* (pp. 152-157). IEEE.<https://doi.org/10.1109/IRI.2007.4296613>\n\
    - 200. Larue, O., Poirier, P., Nkambou, R. (2012). A Cognitive Architecture Based\
    \ on Cognitive/Neurological Dual-System Theories. In: Zanzotto, F.M., Tsumoto,\
    \ S., Taatgen, N., Yao, Y. (eds) *Brain Informatics. BI 2012* (pp. 288-299). Lecture\
    \ Notes in Computer Science, vol 7670. Springer, Berlin, Heidelberg. [https://doi.org/10.1007/978-3-642-35139-6\\\
    \\_27](https://doi.org/10.1007/978-3-642-35139-6_27)\n- 201. Liew, P. S., Chin,\
    \ C. L., & Huang, Z. (2009). Development of a computational cognitive architecture\
    \ for intelligent virtual character. *Computer Animation and Virtual Worlds, 20*(2‐3),\
    \ 257-266[. https://doi.org/10.1002/cav.316](https://doi.org/10.1002/cav.316)\n\
    - 202. Treur, J., & Glas, G. (2021). A multi-level cognitive architecture for\
    \ self-referencing, selfawareness and self-interpretation. *Cognitive Systems\
    \ Research, 68*, 125-142. <https://doi.org/10.1016/j.cogsys.2020.10.019>\n- 203.\
    \ Lieto, A., Bhatt, M., Oltramari, A., & Vernon, D. (2018). The role of cognitive\
    \ architectures in general artificial intelligence. *Cognitive Systems Research*,\
    \ *48*, 1-3. <https://doi.org/10.1016/j.cogsys.2017.08.003>\n- 204. Lieto, A.\
    \ (2021). Cognitive design for artificial minds. Routledge, London, New York."
  decisions:
    evaluation_prompt: 'Disqualified: no evaluation. Reason: The abstract and introduction
      focus on the identification and proposal of cognitive architectures for AGI
      without mentioning any empirical, experimental, or quantitative evaluation methods,
      such as experiments, metrics, or comparisons.'
    related_work_prompt: '- Qualified. Reason: The paper engages with prior research
      by referencing multiple existing cognitive architectures and reviews, comparing
      its proposed architecture with those in the literature, and discussing the specific
      focus on architectures intended for AGI.'
    novelty_prompt: 'Qualified. Reason: The abstract explicitly states that the paper
      proposes a new cognitive architecture for intelligent systems approaching AGI,
      along with a universal method of knowledge representation, indicating clear
      signs of new contributions.'
    review_only_prompt: 'Qualified. Reason: The paper proposes a new cognitive architecture
      and a universal method of knowledge representation, indicating that it presents
      new contributions rather than merely summarizing existing work.'
  llm_input_used: '## Abstract

    The article identified 42 cognitive architectures for creating general

    artificial intelligence (AGI) and proposed a set of interrelated functional

    blocks that an agent approaching AGI in its capabilities should possess. Since

    the required set of blocks is not found in any of the existing architectures,

    the article proposes a new cognitive architecture for intelligent systems

    approaching AGI in their capabilities. As one of the key solutions within the

    framework of the architecture, a universal method of knowledge representation

    is proposed, which allows combining various non-formalized, partially and fully

    formalized methods of knowledge representation in a single knowledge base, such

    as texts in natural languages, images, audio and video recordings, graphs,

    algorithms, databases, neural networks, knowledge graphs, ontologies, frames,

    essence-property-relation models, production systems, predicate calculus

    models, conceptual models, and others. To combine and structure various

    fragments of knowledge, archigraph models are used, constructed as a

    development of annotated metagraphs. As components, the cognitive architecture

    being developed includes machine consciousness, machine subconsciousness,

    blocks of interaction with the external environment, a goal management block,

    an emotional control system, a block of social interaction, a block of

    reflection, an ethics block and a worldview block, a learning block, a

    monitoring block, blocks of statement and solving problems, self-organization

    and meta learning block.


    ## Introduction

    In recent years, there has been a rapid and multidirectional development of intelligent
    information systems developed by people [1]. In [2], it was assumed that a relatively
    distant extrapolation of the functionality of these developments would be the
    creation of a general artificial intelligence comparable to human intelligence
    (in current terminology – AGI). The main capabilities of an intelligent information
    system, such as perceptual abilities, attention mechanisms, choice of actions,
    learning, memory, reasoning and their practical application are determined by
    the cognitive architecture used in the system [3]. If we consider the basic principles
    of functioning, then cognitive architectures are the opposite of expert systems.
    Expert systems provide solutions to intellectual tasks in a narrowly defined context,
    in the segment of activity for which they have knowledge, in contrast, cognitive
    architectures aim to providing a wide coverage, solving a diverse set of tasks
    in different fields. More importantly, cognitive architectures provide intelligent
    behavior at the system level, rather than at the level of methods of individual
    components designed to solve specialized tasks [3].


    In 2016-18, after a relatively long break, two reviews of cognitive architectures
    were published [4, 5] (the third version of the publication [4], like the publication
    [5], appeared in 1918). After that, no systematic reviews were published until
    preparation of this article. Only brief reviews were published as part of the
    justification for the need to develop new architectures. In these two reviews,
    which cover about 140 architectures, we identified cognitive architectures designed
    to create AGI, and supplemented the list with the results of a bibliographic search.


    Unlike the reviews in [6,7], the authors of which considered cognitive architectures
    for creating AGI, including architectures that were not intended for this purpose
    in the review, we consider it important to analyze precisely cognitive architectures
    that are declared as architectures intended for creating AGI, since additional
    requirements are imposed on them [8]. Other cognitive architectures could be developed
    to test some technical solutions or to solve more utilitarian tasks, for example,
    for image processing or controlling a transport robot transporting workpieces
    in the workshop.


    In the list of cognitive architectures, if the architecture does not have a name,
    it will be presented simply with a link to the publication. The final list of
    cognitive architectures for analysis includes 42 architectures, presented in Table
    1. For each architecture, this table contains citations indicating that the architecture
    is intended to enable AGI. For some architectures, publications do not explicitly
    mention AGI as a target. In these cases, the decision to include in the list is
    determined by the goals of the architecture to model human-like behavior or by
    focusing on the complex of functions inherent with humans.


    | # | Name  | Link(s) | Citations about purpose of cognitive architecture                                                                                                                                                                                                                                                                                                                                                                                                   |

    |---|-------|---------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|

    | 1 | Soar  | [9]     | Soar … have used … to build complex integrated AI agents,
    and to create<br>detailed models of human behavior. … We have found that combining
    what<br>is known in psychology, in neuroscience, and in AI is an effective approach<br>to
    building a comprehensive cognitive architecture. … Our bet is that achiev<br>ing
    human-level intelligence is a long path of incremental experiments, dis<br>coveries,
    tests, reformulations and refinements. |

    | 2 | ACT-R | [10]    | This paper explores requirements on cognitive architectures
    for artificial gen<br>eral intelligence. The goal of the analysis is to determine
    the requirements for<br>cognitive architectures that support the full-range of
    human-level intelligent<br>behavior.                                                                                                                                                                                   |'
  token_usage: 5162
  time_usage: 4.909512281417847
- title: "Cognitive BPM as an Equalizer: Improving Access and Efficiency for\n  Employees\
    \ with (and without) Cognitive Disabilities"
  abstract: 'We examine ProcessGPT, an AI model designed to automate, augment, and
    improve

    business processes, to study the challenges of managing business processes

    within the cognitive limitations of the human workforce, particularly

    individuals with cognitive disabilities. ProcessGPT provides a blueprint for

    designing efficient business processes that take into account human cognitive

    limitations. By viewing this through the lens of cognitive disabilities, we

    show that ProcessGPT improves process usability for individuals with and

    without cognitive disabilities. We also demonstrate that organizations

    implementing ProcessGPT-like capabilities will realize increased productivity,

    morale, and inclusion.'
  url: http://arxiv.org/abs/2401.06375v1
  keywords: '* Knowledge-based systems, Management, Organizations, Organizational
    aspects, Disabilities'
  document: "# **Cognitive BPM as an Equalizer: Improving Access and Efficiency for\
    \ Employees with (and without) Cognitive Disabilities**\n\n#### **Gordon Banks<sup>1</sup>\
    \ , Gates Bierhuizen<sup>2</sup> , Katherine McCrum<sup>3</sup> , and Ellen Wengert<sup>4</sup>**\n\
    \n1,2,4 Systems Engineering Program, George Mason University, Fairfax, VA 22030\
    \ USA\n\n3 Operations Research Program, George Mason University, Fairfax, VA 22030\
    \ USA\n\nCorresponding author: Gordon Banks (e-mail: gbanks7@gmu.edu).\n\n**ABSTRACT**\
    \ We examine ProcessGPT, an AI model designed to automate, augment, and improve\
    \ business processes, to study the challenges of managing business processes within\
    \ the cognitive limitations of the human workforce, particularly individuals with\
    \ cognitive disabilities. ProcessGPT provides a blueprint for designing efficient\
    \ business processes that take into account human cognitive limitations. By viewing\
    \ this through the lens of cognitive disabilities, we show that ProcessGPT improves\
    \ process usability for individuals with and without cognitive disabilities. We\
    \ also demonstrate that organizations implementing ProcessGPT-like capabilities\
    \ will realize increased productivity, morale, and inclusion.\n\n**INDEX TERMS**\
    \ Knowledge-based systems, Management, Organizations, Organizational aspects,\
    \ Disabilities\n\n# **I. INTRODUCTION**\n\nHuman cognitive factors such as perception,\
    \ attention, memory, language, reasoning, processing speed, and executive functions\
    \ [1] have known limitations. [2][3][4][5] In contrast, Artificial intelligence\
    \ (AI) systems transcend many boundaries of human cognition, particularly for\
    \ memory, attention, and executive function. [6][7] Large language models such\
    \ as GPT-4 already outperform humans in language areas such as lexical knowledge,\
    \ grammatical sensitivity, communication ability, naming facility, and fluency.\
    \ [\\[1\\]](#page-0-0)[8]\n\nExploration of AI's cognitive capabilities in the\
    \ context of business process management (BPM) offers insights into knowledge-intensive\
    \ processes that are predominantly driven by human activities. [9] Knowledge-intensive\
    \ processes can only be partially mapped to a process model and commonly vary\
    \ due to circumstances and administrative discretion. [10] Facilitation of these\
    \ processes is within the domain of Cognitive BPM, which manages business processes\
    \ using cognitive computing technologies. [11] We reference other researchers'\
    \ AI model, ProcessGPT, as a practical representation of a Cognitive BPM solution\
    \ (Fig. 1). ProcessGPT is an AI model whose goal is to suggest the best next step\
    \ in a process based on a Process Knowledge Graph and extensive supporting elements.\
    \ [12] While ProcessGPT is capable of process augmentation, automation, and improvement,\
    \ we highlight the challenges faced by employees with cognitive disabilities by\
    \ considering how ProcessGPT can augment their experience.\n\n<span id=\"page-0-0\"\
    ></span>![](_page_0_Figure_10.jpeg)\n\n**FIGURE 1. Relationships between AI, BPM,\
    \ and ProcessGPT elements.**\n\n<span id=\"page-0-1\"></span>Through the use of\
    \ AI-intensive systems, like ProcessGPT, organizations can decrease the administrative\
    \ burden and cognitive load on their employees leading to increased organizational\
    \ productivity (Fig. 2). ProcessGPT's potential as a facilitator for process users\
    \ is profound, particularly in the context of knowledge-intensive processes, which\
    \ rely heavily on human cognitive resources by their nature. Knowledge-intensive\
    \ processes can prove particularly challenging for employees with cognitive disabilities,\
    \ which include autism, ADHD, dyslexia, aphasia, and mild cognitive impairment.\
    \ Cognitive disabilities limit the functional learning, memory, attention, and\
    \ executive functions needed to perform the tasks that comprise knowledgeintensive\
    \ processes. Knowing this, we establish two research questions to investigate\
    \ the nexus of business processes, AI, and cognitive disabilities: 1) How can\
    \ AI-intensive technology be applied to business processes to accommodate individuals\
    \ with cognitive disabilities? and 2) What benefits are likely to be seen from\
    \ accommodating individuals with cognitive disabilities in business processes?\
    \ Through our results we aim to motivate organizations to accommodate people with\
    \ cognitive disabilities in their business processes with the use of AI, which\
    \ will benefit the entire organization, not just personnel with cognitive disabilities.\n\
    \n![](_page_1_Figure_1.jpeg)\n\n**FIGURE 2. Mapping how AI can lead to improved\
    \ organizational productivity**\n\n# **II. BACKGROUND**\n\n## A. *Cognitive Disabilities\
    \ in the Workplace*\n\nAccording to the CDC, approximately 13% of the US population\
    \ has some form of cognitive disability. [13] Individuals with cognitive disabilities\
    \ have significant difficulties relating to:\n\n- 1) learning, communication,\
    \ reading, writing, or math,\n- 2) the ability to understand or process new or\
    \ complex information and learn new skills, with a reduced ability to cope independently,\
    \ and / or\n- <span id=\"page-1-1\"></span>3) memory and attention or visual,\
    \ language, or numerical thinking. [14]\n\nThese individuals face unique challenges\
    \ in the workplace that depend on the cognitive resources required to properly\
    \ execute their tasks. By nature, business processes shift administrative burdens\
    \ to users–and their limited cognitive resources. [15] Navigating many business\
    \ processes involves understanding multi-step procedures, remembering to follow\
    \ up on paperwork, reading dense process documentation, or completing forms with\
    \ ambiguous language and jargon. These tasks require attention to detail, adherence\
    \ to procedures, and effective communication with various parties involved in\
    \ the process. Doing so places demands on users' cognitive functions, reducing\
    \ the time and cognitive resources they have available for other tasks.\n\nGenerally,\
    \ a user's performance decreases as their cognitive load increases, and is a function\
    \ of task complexity, task support, and user capabilities. User capabilities depend\
    \ on cognitive factors such as attention, memory, and processing speed, in addition\
    \ to non-cognitive factors such as experience, training, environmental conditions,\
    \ enthusiasm, organizational culture, fatigue, and stress. [16] For any user of\
    \ a business process, there exists some level of process complexity that will\
    \ exceed their cognitive resources, resulting in cognitive overload. [17][\\[15\\\
    ]](#page-1-0) It follows that this threshold will be lower for a user with a cognitive\
    \ disability performing a task that depends on cognitive factors limited by their\
    \ disability.\n\nThe World Wide Web Consortium (W3C) drafted detailed guidelines\
    \ for making content usable for people with cognitive and learning disabilities.\
    \ [\\[14\\]](#page-1-1) These guidelines are organized by nine key objectives\
    \ that designers should target:\n\n- 1) Help users understand what things are\
    \ and how to use them\n- 2) Help users find what they need\n- 3) Use clear content\
    \ (text, images, and media)\n- 4) Help users avoid mistakes\n- 5) Help users focus\n\
    - 6) Ensure processes do not rely on memory\n- 7) Provide help and support\n-\
    \ 8) Support adaptation and personalization\n- 9) Test with real users\n\nEach\
    \ objective is decomposed into specific guidelines and design patterns. Background\
    \ information is also given. For instance, within \"*Objective 1: Help Users Understand\
    \ What Things are and How to Use Them*,\" the guidelines familiarize the reader\
    \ with the issues that inform this objective:\n\n*Users with cognitive and learning\
    \ disabilities may have trouble with orientation and learning. This can mean people\
    \ get disoriented in a site.*\n\n*Learning new things and remembering new information\
    \ is especially difficult for people with cognitive and learning disabilities.\
    \ They can also struggle or be unable to learn new design patterns. Make controls,\
    \ icons and elements simple and conventional to help.*\n\nDesign patterns that\
    \ support this objective are then given:\n\n- *1) Make the Purpose of Your Page\
    \ Clear*\n- *2) Use a Familiar Hierarchy and Design*\n- *3) Use a Consistent Visual\
    \ Design*\n- *4) Make Each Step Clear*\n- *5) Clearly Identify Controls and Their\
    \ Use*\n- <span id=\"page-1-0\"></span>*6) Make the Relationship Clear Between\
    \ Controls and the Content They Affect*\n- *7) Use Icons that Help the User*\n\
    \nEach design pattern details user needs, what to do to meet those needs, how\
    \ it helps, and provides examples. Overall, the W3C guidelines emphasize using\
    \ familiar design patterns with easily understood content presented in manageable\
    \ chunks, as well as supporting users by anticipating cognitive shortcomings.\n\
    \n#### *B. Knowledge-Intensive Processes*\n\nBPM seeks continuous improvement\
    \ of business processes, [18] and refers to poorly performing or otherwise troublesome\
    \ business processes as unmanaged, [19][20] unstructured, *ad hoc*, or knowledge-intensive\
    \ processes. [21][\\[10\\]](#page-0-1) We adopt the *knowledge-intensive* descriptor\
    \ used to initially describe ProcessGPT.\n\nIn general, business processes require\
    \ users to perform administrative tasks in pursuit of an organizational goal.\
    \ Knowledge-intensive business processes often lack the consistent, clear, and\
    \ complete definition necessary for timely execution toward a goal. [\\[10\\]](#page-0-1)\
    \ As a result, users are required to either remember idiosyncrasies about a process\
    \ or maintain information outside of the very systems intended to manage that\
    \ process. Knowledge-intensive processes thus grow to encompass additional unmanaged\
    \ elements via these mechanisms. [15] Unmanaged elements contribute to a large\
    \ \"digital exhaust\" signature (emails, spreadsheets, documents, forms, chats,\
    \ etc. that contain critical process guidelines, best practices, and policies)\
    \ typical of knowledge-intensive processes. [22] This emergent complexity not\
    \ only constitutes a continual drain on the cognitive resources of all workers,\
    \ reducing overall productivity and morale, its unmanaged nature places the most\
    \ burden on users with cognitive disabilities. Users with limited cognition will\
    \ be the first to experience cognitive overload, with no recourse for accommodation.\n\
    \nThe better users understand these processes, the better their output and, hence,\
    \ their morale. The rules and procedures associated with knowledge-intensive processes\
    \ are frequently associated with negative perceptions that affect both morale\
    \ and output, regardless of whether those perceptions are accurate. [23] Another\
    \ important factor related to employee morale and efficiency is emphasis on high-value\
    \ work. Often when employees are asked about the most frustrating part of their\
    \ jobs, they will mention the amount of time spent on low-value tasks that detracts\
    \ from their primary work. These tasks are in many cases manual, repetitive, and\
    \ can consume a lot of time. [24] Simplifying steps, eliminating confusion, and\
    \ adding transparency to business processes are the key to a more efficient and\
    \ satisfied workforce.\n\nMany have already tried to address these challenges\
    \ through Robotic Process Automation (RPA). RPA typically leverages commercial\
    \ software to automate routine tasks, copying human actions. RPA is a growing\
    \ area that has been proven to save employee time on low-value work. The Federal\
    \ RPA Community of Practice estimates that as of 2021, over 1.4M hours of work\
    \ have been saved due to the implementation of RPA. [25] Industry leaders such\
    \ as Microsoft have been working to facilitate this type of automation by digitizing\
    \ contracts. Microsoft Azure has taken physical paperwork into the cloud which\
    \ opens the door for contract processes to be integrated into more efficient workflows.\
    \ AI is the next logical area where contract processing should and will go. [26]\n\
    \nAI changes the way many industries operate. In contracting, AI can sift through\
    \ an enormous amount of paperwork and understand what the content of each is.\
    \ AI allows organizations an \"all-knowing\" power where information can be queried\
    \ and analytics can be reported, all without the intervention of a human. Additionally,\
    \ it can review contract content for consistency across an organization and assess\
    \ risk by identifying terms that are suboptimal. Ultimately it can perform these\
    \ tasks in a way that is faster and more accurate than a human. [27] This has\
    \ major implications for law firms, as well as innumerable other industries.\n\
    \nProcessGPT can decrease the amount of time spent on knowledge-intensive tasks\
    \ by training it on a large set of business process data. The model can be further\
    \ refined by user input and decisions. The goal is to automate repetitive tasks\
    \ that would otherwise be conducted by human workers. This has potential to greatly\
    \ improve how employees with cognitive disabilities complete their work and provide\
    \ benefit to an organization.\n\n# **III. RELEVANT WORK**\n\nAI technologies already\
    \ demonstrate their effectiveness in assisting individuals with cognitive disabilities,\
    \ improving administrative tasks, and ensuring compliance with accessibility regulations.\n\
    \nOne relevant study [28] focuses on assistive technology for cognitive impairment\
    \ in older individuals, highlighting the importance of compensation systems. These\
    \ systems employ AI planning techniques to introduce flexibility into tasks like\
    \ schedule management, personalized reminders, and guidance for routine tasks\
    \ that improve daily life for these individuals. The system takes on the cognitive\
    \ load associated with internalizing routine but crucial tasks, reducing the need\
    \ for external monitoring and instances of compliance failure. Implementing AI\
    \ in the workplace can enable design principles to assist process users with cognitive\
    \ disabilities by offering timely reminders, tracking tasks to ensure follow-up,\
    \ learning routines, and guiding them through tasks.\n\nA UK study [29] explores\
    \ the use of AI, machine learning (ML), and deep learning (DL) to address regulatory\
    \ compliance challenges faced by financial institutions. These technologies automate\
    \ tasks, process complex information, and reduce cognitive load for users. For\
    \ example, AI-powered voice assistants aid in administrative tasks, scheduling,\
    \ and accessing information, simplifying work responsibilities. DL algorithms\
    \ analyze and interpret data, providing insights and recommendations for informed\
    \ decision-making. These AI technologies empower individuals with cognitive disabilities\
    \ to overcome challenges related to information processing, memory, and task completion,\
    \ leading to increased efficiency and effectiveness. In addition, the use of AI,\
    \ ML, and DL can contribute to compliance with regulations such as Section 508\
    \ by facilitating the development of inclusive interfaces and adaptive technologies.\
    \ Natural language processing capabilities enable voice-controlled interfaces\
    \ that alleviate the need for complex navigation or manual input, while AI algorithms\
    \ accommodate different communication styles and preferences, ensuring information\
    \ accessibility for individuals with cognitive disabilities.\n\n<span id=\"page-2-0\"\
    ></span>A collection of case studies provide compelling evidence for the positive\
    \ impact of reducing administrative work on job satisfaction. Research on U.S.\
    \ physicians [30] revealed that spending less time on administrative tasks is\
    \ associated with higher career satisfaction. Similarly, a study on general practitioners\
    \ [31] highlights how excessive paperwork and bureaucratic interference contributed\
    \ to reduced job satisfaction and increased stress levels. Social workers [32]\
    \ also reported job dissatisfaction linked to paperwork. Additionally, studies\
    \ on public sector employees in Switzerland [33] and China [34] emphasized the\
    \ detrimental effects of red tape on work outcomes, including increased resignation\
    \ rates, decreased job satisfaction, and heightened procrastination behavior.\
    \ A study in Australia makes a case for finding ways to support those with dyslexia\
    \ to prevent job-burnout. The study finds that \"excessive job demands, in the\
    \ absence of supportive job resources and personal resources, leads to poor mental\
    \ health and wellbeing…results seem to suggest that employees with dyslexia face\
    \ challenges in the workplace related to their disability including excessive\
    \ mental exhaustion, and fatigue, leaving them vulnerable to workplace stress\
    \ and job burnout. Improving psycho-social workplace environments, increasing\
    \ job resources, decreasing job demands, and critically influencing work engagement,\
    \ will reduce job burnout and reduce apparent difficulties for individuals with\
    \ dyslexia in the workplace.\" [35] By leveraging AI technologies to automate\
    \ and streamline administrative processes, individuals with cognitive disabilities\
    \ can experience a significant reduction in paperwork, bureaucratic complexities,\
    \ and associated stress. This can lead to improved job satisfaction, allowing\
    \ them to focus more on their core tasks and enhance their overall well-being.\n\
    \nThe findings from a South Korean study [36] highlight the importance of individual-level\
    \ factors, such as job satisfaction and organizational citizenship behavior, in\
    \ predicting organizational performance in both the United States and Korea. This\
    \ suggests that addressing these individual-level factors can lead to improved\
    \ organizational performance. Job satisfaction has been shown to positively influence\
    \ performance outcomes. By improving job satisfaction, organizations can enhance\
    \ employee motivation, commitment, and overall engagement, resulting in improved\
    \ performance. For individuals with cognitive disabilities, AI can play a crucial\
    \ role in improving job satisfaction by accommodating their specific needs and\
    \ providing support tailored to their abilities. AI solutions can be developed\
    \ to streamline administrative tasks, reduce barriers, and enhance accessibility,\
    \ thereby creating a more inclusive and accommodating work environment. This,\
    \ in turn, can improve job satisfaction for individuals with cognitive disabilities,\
    \ leading to enhanced performance for both individuals and organizations.\n\n\
    Organizations like Microsoft are actively working to improve the workplace for\
    \ individuals with cognitive disabilities, exemplifying the significance of applying\
    \ AI to business process management. Microsoft's collaboration with Clover Technologies,\
    \ Concurrency, and Gigi's Playhouse Down syndrome development centers resulted\
    \ in a mixed-reality platform and Azure-based solution that enables individuals\
    \ with cognitive disabilities to engage in meaningful warehouse work. [37] This\
    \ real-world example demonstrates the potential of AI to transform business operations,\
    \ broaden employment opportunities, and empower individuals with cognitive disabilities.\
    \ The progress made by Microsoft and its partners underscores the value and potential\
    \ of AI to foster inclusivity, increase job satisfaction, and enhance performance\
    \ for individuals with cognitive disabilities.\n\nCognitive and learning disabilities\
    \ encompass a wide range of difficulties in cognitive functions, including learning,\
    \ communication, reading, writing, math, understanding complex information, learning\
    \ new skills, coping independently, memory, attention, and specific types of thinking.\
    \ [\\[14\\]](#page-1-1) AI solutions exhibit remarkable capabilities such as perfect\
    \ recall, extensive knowledge, understanding of process-specific language, access\
    \ to historical process data, awareness of task statuses, and identification of\
    \ non-compliant tasks. When comparing human cognition to AI cognition, it is important\
    \ to note that even individuals without cognitive disabilities experience limitations\
    \ in attention, short-term and long-term memory, recall speed, and executive function.\
    \ AI solutions specifically designed to enhance accessibility can alleviate the\
    \ physical and mental burdens for individuals with cognitive disabilities, and\
    \ even have a positive impact on those without such disabilities as a second-order\
    \ effect. This reduction in cognitive load and improved accessibility has the\
    \ potential to increase job satisfaction and ultimately enhance performance, while\
    \ ensuring compliance with regulatory standards.\n\n# **IV. PROCESSGPT CAPABILITIES**\n\
    \nThe architecture proposed in [12] rigorously outlines textual capabilities of\
    \ ProcessGPT and additionally introduces multimodal capabilities that would leverage\
    \ voice, imagery, and video sources to augment and automate business processes.\
    \ Designed as an adaptable AI system and trained using existing organizational\
    \ processes, ProcessGPT would seamlessly integrate into various industries and\
    \ business processes. Here, we study ProcessGPT's functions in a variety of applications\
    \ to better understand the benefits it brings to users with cognitive disabilities.\n\
    \n**Filling Out Forms.** Automatically fills out forms at the request of users.\n\
    \n*Example Process:* Employee onboarding. A form with business jargon confuses\
    \ a new employee. ProcessGPT, understanding the context, recommends the correct\
    \ field value to the user.\n\n*Cognitive Support:* Simplifies the process by filling\
    \ out forms, reducing cognitive load and confusion caused by business jargon.\n\
    \n**Answering Process Questions.** Provides guidance on the next steps in a process.\n\
    \n*Example Process:* Project management. A project management system requires\
    \ a user to manually coordinate tasks outside of the system but does not provide\
    \ guidance. ProcessGPT provides clear, step-by-step guidance when needed.\n\n\
    *Cognitive Support:* Provides clear, step-by-step instructions, aiding individuals\
    \ who may struggle with complex instructions.\n\n**Reminders and Follow-ups.**\
    \ Reminds users to follow up on requests.\n\n*Example Process:* Sales process.\
    \ A CRM system does not provide reminders for follow-ups. ProcessGPT reminds a\
    \ salesperson to follow up with a potential client.\n\n*Cognitive Support:* Provides\
    \ reminders, assisting individuals who may have difficulties with memory or attention.\n\
    \n**Resource Planning.** Analyzes structured data to perform resource planning.\n\
    \n*Example Process:* Team scheduling. A scheduling system is complex and time-consuming.\
    \ ProcessGPT analyzes team members' schedules and skills to assign tasks efficiently.\n\
    \n*Cognitive Support:* Automates complex tasks like resource planning, reducing\
    \ cognitive load and the need for multitasking.\n\n**Email Processing.** Processes\
    \ emails, reducing non-productive time spent on replying, searching, and organizing\
    \ emails.\n\n*Example Process:* Customer service. An email system lacks efficient\
    \ sorting and replying features. ProcessGPT helps a customer service rep respond\
    \ to customer inquiries quickly and effectively.\n\n*Cognitive Support:* Simplifies\
    \ email processing, aiding individuals who may struggle with organization and\
    \ prioritization.\n\n**Voice Transcription.** Transcribes calls and meetings.\n\
    \n*Example Process:* Meeting transcription. A transcription system is slow and\
    \ inaccurate. ProcessGPT accurately transcribes a team meeting and shares the\
    \ notes with all participants.\n\n*Cognitive Support:* Provides transcription\
    \ services, aiding individuals who may have difficulties with auditory processing\
    \ or note-taking.\n\n**Onboarding Assistance.** Assists with onboarding new employees.\n\
    \n*Example Process:* New employee orientation. An orientation system is confusing\
    \ for new employees. ProcessGPT answers a new employee's questions about company\
    \ policies in a clear and understandable way.\n\n*Cognitive Support:* Provides\
    \ clear and understandable answers to questions, aiding individuals who may struggle\
    \ with complex information.\n\n**Task Management.** Helps manage tasks, extract\
    \ data, highlight specific items of interest, and review legal agreements.\n\n\
    *Example Process:* Contract management. A contract management system is complex\
    \ and hard to navigate. ProcessGPT extracts key terms from a contract for review\
    \ in a user-friendly format.\n\n*Cognitive Support:* Simplifies task management,\
    \ aiding individuals who may struggle with organization and prioritization.\n\n\
    **Data Interpretation.** Interprets user data, answers queries, and expedites\
    \ project progress.\n\n*Example Process:* Data analysis. A data analysis system\
    \ is complex and requires advanced skills. ProcessGPT interprets sales data and\
    \ provides a forecast for the next quarter in a simple, understandable format.\n\
    \n*Cognitive Support:* Presents data in a simple, understandable format, aiding\
    \ individuals who may struggle with complex data or numerical thinking.\n\n**Automating\
    \ Repetitive Tasks.** Automates repetitive and generic tasks.\n\n*Example Process:*\
    \ Travel claims. A travel system requires manual data entry. ProcessGPT automatically\
    \ associates credit card charges with travel expenses, creates expenses from receipt\
    \ images, and enables conversational creation of vouchers, saving time and reducing\
    \ errors.\n\n*Cognitive Support:* Automates repetitive tasks, reducing cognitive\
    \ load and the potential for errors.\n\n**User-Centric Guidance.** Provides straightforward,\
    \ comprehensible guidance and process support tailored to the cognitive capabilities\
    \ and needs of each individual process user.\n\n*Example Process:* Onboarding.\
    \ An organization's onboarding process is unclear because it consists of multiple\
    \ independent sub-processes. ProcessGPT provides a user with step-by-step guidance\
    \ that bridges sub-processes.\n\n*Cognitive Support:* Provides clear, step-by-step\
    \ guidance, aiding individuals with limited executive function.\n\n**Intermediary\
    \ for Internal Systems.** Acts as an intermediary between users and internal systems.\n\
    \n*Example Process:* Timekeeping system. A timekeeping system has substantial\
    \ latency. ProcessGPT acts as a responsive front end where the user can input\
    \ their working hours without delays. ProcessGPT then interfaces with the organization's\
    \ timekeeping system in the background.\n\n*Cognitive Support:* Acts as an intermediary\
    \ for complex systems, aiding individuals who have limited attention.\n\n**Drafting\
    \ Email Responses.** Drafts email responses based on user's needs.\n\n*Example\
    \ Process:* Email communication. A user needs to follow up with a colleague. ProcessGPT\
    \ drafts an email for the user based on the context of the follow-up.\n\n*Cognitive\
    \ Support:* Reduces cognitive load by drafting emails, aiding individuals who\
    \ may struggle with written communication.\n\n**Searching Multiple Data Sources.**\
    \ Searches multiple data sources based on conversational guidance from the user.\n\
    \n*Example Process:* Data retrieval. A user needs to find a document but can only\
    \ recall general information about it. ProcessGPT searches through emails, enterprise\
    \ storage, and local storage based on conversational input to find the document.\n\
    \n*Cognitive Support:* Simplifies the process of searching through multiple data\
    \ sources, aiding individuals with limited memory.\n\n**Compiling Data from Disparate\
    \ Sources.** Automatically compiles data from disparate data sources without the\
    \ user having to search and open each one.\n\n*Example Process:* Data compilation.\
    \ A user needs to compile data from different sources for a report. ProcessGPT\
    \ automatically compiles the necessary data, saving the user time and effort.\n\
    \n*Cognitive Support:* Automates the task of compiling data from different sources,\
    \ reducing cognitive load and the potential for errors.\n\n**ProcessGPT Self-Assessment.**\
    \ Automatic evaluation of user experience and response quality based on conversation\
    \ content.\n\n*Example Process:* Procurement. A user needs a procurement form\
    \ drafted to buy a piece of hardware for a project. ProcessGPT automatically drafts\
    \ the form but requires correction.\n\n*Cognitive Support:* Enables seamless testing\
    \ with real users by identifying and implementing corrective feedback. This eliminates\
    \ typical burdens created by process administrators such as surveys and suggestion\
    \ boxes.\n\nWhile this is not an exhaustive list, the table below demonstrates\
    \ a surjective mapping of ProcessGPT capabilities to the key areas established\
    \ by the W3C to make content usable for individuals with cognitive disabilities.\
    \ This demonstrates that ProcessGPT enables knowledge-intensive business processes\
    \ to accommodate a broad range of cognitive disabilities without altering the\
    \ underlying systems.\n\n| CORRELATION OF PROCESSGPT FUNCTIONS WITH COGNITIVE\
    \ DISABILITY<br>ACCOMMODATIONS |                                             \
    \                    |                                                       \
    \                                             |  |  |\n|---------------------------------------------------------------------------------|-----------------------------------------------------------------|----------------------------------------------------------------------------------------------------|--|--|\n\
    | Accommodation                                                              \
    \     |                                                                 | ProcessGPT\
    \ Functions Enabling<br>the Accommodation                                    \
    \             |  |  |\n|                                                     \
    \                            | Help users understand<br>what things are and how\
    \ to<br>use them | Filling Out Forms, Answering<br>Process Questions, Onboarding<br>Assistance,\
    \ User-Centric Guidance |  |  |\n|                                           \
    \                                      | Help users find what they<br>need   \
    \                            | Searching Multiple Data Sources,<br>Compiling Data\
    \ from Disparate<br>Sources                       |  |  |\n|                 \
    \                                                                | Use clear content\
    \ (text,<br>images and media)                   | Intermediary for Internal Systems\
    \                                                                  |  |  |\n|\
    \                                                                            \
    \     | Help users avoid mistakes                                       | Reminders\
    \ and Follow-ups, Task<br>Management, Automating<br>Repetitive Tasks         \
    \              |  |  |\n|                                                    \
    \                             | Help users focus                             \
    \                   | Email Processing, Drafting Email<br>Responses, Resource\
    \ Planning,<br>Data Interpretation           |  |  |\n|                      \
    \                                                           | Ensure processes\
    \ do not<br>rely on memory                       | Reminders and Follow-ups,<br>Searching\
    \ Multiple Data Sources,<br>Voice Transcription               |  |  |\n|     \
    \                                                                            |\
    \ Provide help and support                                        | Answering\
    \ Process Questions,<br>Onboarding Assistance, User<br>Centric Guidance      \
    \              |  |  |\n|                                                    \
    \                             | Support adaptation and<br>personalization    \
    \                   | User-Centric Guidance,<br>Intermediary for Internal Systems\
    \                                        |  |  |\n|                          \
    \                                                       | Test with real users\
    \                                            | ProcessGPT Self-Assessment    \
    \                                                                     |  |  |\n\
    \nTABLE 1 CORRELATION OF PROCESSGPT FUNCTIONS WITH COGNITIVE DISABILITY\n\n# **V.\
    \ QUANTIFYING BENEFITS**\n\nAccommodating individuals with cognitive disabilities\
    \ in knowledge-intensive business processes directly affects process usability,\
    \ which is a quality attribute associated with the user interface of a system.\
    \ [38] Business process usability is captured by quality attributes that fall\
    \ into four categories: quality of function, quality of input & output objects,\
    \ quality of non-human resources, and quality of human resources. Each category\
    \ has numerous dimensions, as defined in [39] and shown in the table below.\n\n\
    | TABLE 2                                  |  |\n|------------------------------------------|--|\n\
    | QUALITY DIMENSIONS OF BUSINESS PROCESSES |  |\n\n| Function          | Input/Output\
    \  | Non-Human<br>Resource | Human<br>Resource |\n|-------------------|---------------|-----------------------|-------------------|\n\
    | Suitability       | Accuracy      | Suitability           | Domain         \
    \   |\n| Accuracy          | Objectivity   | Accuracy              | Knowledge\
    \         |\n| Security          | Believability | Security              | Qualification\
    \     |\n| Reliability       | Reputation    | Reliability           | Certification\
    \     |\n| Understandability | Accessibility | Time                  | Experience\
    \        |\n| Learnability      | Security      | Efficiency            | Time\
    \              |\n| Time Efficiency   | Relevancy     | Resource             \
    \ | Management        |\n| Resource          | Value-added   | Utilization   \
    \        | Communication     |\n| Utilization       | Timeliness    | Effectiveness\
    \         | Skills            |\n| Effectiveness     | Completeness  | Safety\
    \                |                   |\n| Productivity      | Amount of     |\
    \ User                  |                   |\n| Safety            | Data    \
    \      | Satisfaction          |                   |\n| User Satisfaction |  \
    \             | Robustness            |                   |\n| Robustness    \
    \    |               | Availability          |                   |\n\nApplying\
    \ ProcessGPT to a knowledge-intensive business process will improve quality dimensions\
    \ within the Function and Input/Output categories. Similarly, it reduces the performance\
    \ requirements of human and non-human resources while delivering the same or better\
    \ quality in those areas. The improved function and input/output quality provided\
    \ by ProcessGPT translate directly to a better user experience. Likewise, reducing\
    \ the performance requirements of non-human and human resources opens up the same\
    \ user experience to a broader range of users. This collectively demonstrates\
    \ that ProcessGPT improves usability for all process users–not just those with\
    \ cognitive disabilities.\n\n<span id=\"page-5-2\"></span><span id=\"page-5-1\"\
    ></span><span id=\"page-5-0\"></span>The benefits of improving business process\
    \ usability are well characterized and overwhelmingly positive. Cost savings from\
    \ users spending less time on a process are most evident; however, second-order\
    \ savings accrue in areas such as development, support, training, documentation,\
    \ and maintenance. [40][41] Conventional usability improvements have a near-term\
    \ costbenefit ratio ranging from 1:2 for low-volume processes to more than 1:100\
    \ for high volume processes. [42][43][44] Usability savings accrue continually\
    \ such that cost-benefit ratio only improves over time. It is important to note\
    \ the converse: the costs of poor usability accrue continuously. This is true\
    \ regardless of whether usability issues are known by process administrators.\
    \ Ultimately, the users' cognitive factors serve as the testing grounds for process\
    \ usability.\n\nProcessGPT can also relieve the administrative burden put onto\
    \ employees by external organizations. For example, government-mandated forms\
    \ and processes often have poor usability, which impacts the users and the government\
    \ (and taxpayers). Government contracts are particularly egregious, with up to\
    \ 9% of a contract's value spent on administering the contract itself. That means\
    \ for every dollar spent on services, an organization is spending nine cents on\
    \ non-value-added activity. [45] Implementing an AI system like ProcessGPT has\
    \ the potential to significantly reduce the time spent on these nonvalue-added\
    \ tasks. Augmenting existing functions such as prioritizing inboxes and automatically\
    \ drafting basic emails can also have large impacts. Using email accounts for\
    \ 28% of an employee's time at work. [46] Reducing the time spent searching past\
    \ emails or documents gives employees more time to focus on the tasks at hand.\n\
    \nGains from usability improvements are so broad that they are difficult to characterize\
    \ entirely, yet their impact is undeniable and impossible to overlook. [47] Numerous\
    \ methods exist to quantify usability benefits, and there is no shortage of relevant\
    \ case studies. [\\[40\\]](#page-5-0)[\\[41\\]](#page-5-1) It is common to see\
    \ process time and costs reduced by half as well as absolute savings in the millions\
    \ of dollars. Usability improvements sometimes pay for themselves within the first\
    \ day of implementation. [\\[41\\]](#page-5-1) In fact, the authors found no research\
    \ that showed a negative return on usability investments.\n\nImproved usability\
    \ of business processes also leads to increased productivity and associated cost\
    \ savings. The same work can be done by less people, or the same people can do\
    \ more (and more relevant) work. [\\[43\\]](#page-5-2) Usable processes reduce\
    \ the upfront costs needed for documentation and training. Likewise, continuous\
    \ cost savings are realized in these same areas because usable processes enable\
    \ process users to be more self-sufficient.\n\nEmpowering users to reach a goal\
    \ via an intuitive, responsive process pays additional dividends in the form of\
    \ improved employee morale and increased self-directed work. People naturally\
    \ avoid tasks they don't like, resulting in procrastination behaviors, poor work\
    \ quality, and increased risk of turnover. [\\[34\\]](#page-2-0) These again impact\
    \ the bottom line of an organization. [\\[43\\]](#page-5-2)\n\n## **VI. POTENTIAL\
    \ CHALLENGES**\n\nThe use of an AI system to help ease bureaucratic burden within\
    \ an organization is not without challenges. Anytime government or commercial\
    \ information systems are storing and collating data, there is concern of data\
    \ security. An all-knowing AI system could have the potential to create proprietary\
    \ information or even impact the classification of data. Following guidance on\
    \ AI development and implementation will be central to mitigating these issues.\
    \ [48] In addition to data security risk, the access to employee correspondence\
    \ (e.g. email, chats, personal data) could pose a threat to program integrity\
    \ if there is no human manager to make ethical/tactical decisions on what should\
    \ be shared.\n\nBeyond its application for ProcessGPT, there is general apprehension\
    \ about adopting AI technologies. A Gallup poll from 2018 indicated that most\
    \ people think AI will destroy more jobs than it creates. [49] There is uncertainty\
    \ around the future of AI's impact on society that can cause anxiety for many.\
    \ There is also the question of achievability – when will the technology exist\
    \ to create a working system like ProcessGPT? Additionally, as AI technology is\
    \ developed, it is imperative to keep humans' emotions at the center. Following\
    \ best practices such as those laid out in the HAX Toolkit [50] developed by Microsoft\
    \ will be crucial to making AI an accepted part of organizations. This kind of\
    \ \"human-centric\" design will ensure that people using the technology are confident\
    \ in the benefits they bring and trust that those benefits outweigh the costs.\n\
    \n## **VII. CONCLUSIONS**\n\nWe drew upon an analysis of a proposed Cognitive\
    \ BPM architecture, ProcessGPT, to understand the potential role of AI in enhancing\
    \ workplace inclusivity and efficiency, particularly for individuals with cognitive\
    \ disabilities. We viewed these capabilities through the lens of human cognitive\
    \ factors and their limitations to address our initial research questions.\n\n\
    **RQ1:** How can AI-intensive technology be applied to business processes to accommodate\
    \ individuals with cognitive disabilities?\n\nWe studied ProcessGPT's functions\
    \ in hypothetical applications to better understand how it can accommodate users\
    \ with cognitive disabilities. The functions consisted of:\n\n- \n- Filling out\
    \ forms Answering process questions\n- Onboarding assistance User-centric guidance\n\
    - Task management Reminders and follow-ups\n- Email processing Automating repetitive\
    \ tasks\n- Resource planning Drafting email responses\n- ProcessGPT Self-Assessment\
    \ Voice transcription\n- Intermediary for internal systems\n- \n- \n- Compiling\
    \ data from\n- disparate sources • Data interpretation\n- Searching multiple data\
    \ sources\n\nWe logically demonstrated that ProcessGPT enables knowledge-intensive\
    \ business processes to accommodate a broad range of cognitive disabilities by\
    \ correlating these functions with the W3C guidelines for *Making Content Usable\
    \ for People with Cognitive and Learning Disabilities*.\n\n**RQ2:** What are the\
    \ benefits of accommodating individuals with cognitive disabilities in business\
    \ processes?\n\nWe correlated ProcessGPT disability accommodations with cognition-agnostic\
    \ BPM quality attributes to demonstrate that ProcessGPT improves usability for\
    \ all process users. Generalizing these usability improvements also enables ProcessGPT\
    \ benefits to be compared to the well-studied and universally positive impacts\
    \ of usability engineering. Ultimately, usability of a process is correlated with\
    \ the cognitive demand it places on its users, and no user has unlimited cognitive\
    \ resources. ProcessGPT and similar AI-intensive systems would improve usability\
    \ of knowledge-intensive processes for everyone by accommodating individuals with\
    \ limited cognitive factors, resulting in increased productivity and employee\
    \ morale across the workforce.\n\nIn this work, we address a critical need that\
    \ affects a significant portion of the workforce by focusing on accommodating\
    \ individuals with cognitive disabilities. Simultaneously, we illuminate a novel\
    \ approach to reduce administrative burdens across the workforce. While users\
    \ without cognitive disabilities must endure cumbersome knowledge-intensive business\
    \ processes with little recourse, many organizations are legally obligated to\
    \ accommodate individuals with disabilities. This is comparable to automatic door\
    \ openers, which benefit all users despite being installed to fulfill legal requirements\
    \ to accommodate individuals with physical disabilities. Users without physical\
    \ disabilities benefit from automatic door openers when their arms are full or\
    \ they are part of a large group, for instance. If a door has poor usability because\
    \ it is heavy or poorly positioned, automatic openers rectify these issues for\
    \ everyone. In these instances, disability accommodations rectify flaws in systems\
    \ that were not properly designed or validated by the original designer. ProcessGPT\
    \ would perform this function within knowledge-intensive processes across a wide\
    \ range of use cases. Organizations that are legally obligated to accommodate\
    \ individuals with disabilities may achieve compliance by applying ProcessGPT\
    \ or similar AI-intensive systems to their knowledgeintensive business processes.\
    \ Additional benefits in the form of reduced costs, increased productivity, and\
    \ improved morale only strengthen this argument\n\n- 1. Alfredo Ardila and Byron\
    \ Bernal. \"What Can Be Localized in the Brain? Toward a 'Factor' Theory on Brain\
    \ Organization of Cognition,\" International Journal of Neuroscience, vol. 117,\
    \ no. 7, pp. 935–969, Jan. 2007, doi: 10.1080/00207450600912222.\n- 2. George\
    \ A. Miller, \"'The magical number seven, plus or minus two: Some limits on our\
    \ capacity for processing information,' (Miller 1956),\" 1956, Accessed: Jul.\
    \ 11, 2023. [Online]. Available: http://archive.org/details/miller1956\\_202204\n\
    - 3. Derek M. Jones, \"The 7±2 urban legend,\" MISRA C Conference 2002, October\
    \ 2002. [Online]. Available: http://www.knosof.co.uk/cbook/misart.pdf\n- 4. J.\
    \ M. J. Murre and J. Dros, \"Replication and Analysis of Ebbinghaus' Forgetting\
    \ Curve,\" PLOS ONE, vol. 10, no. 7, p. e0120644, Jul. 2015, doi: 10.1371/journal.pone.0120644.\n\
    - 5. F. Paas, A. Renkl, and J. Sweller, \"Cognitive Load Theory and Instructional\
    \ Design: Recent Developments,\" Educational Psychologist, vol. 38, pp. 1–4, Jun.\
    \ 2010, doi: 10.1207/S15326985EP3801\\_1.\n- 6. M. Boudry, M. Vlerick, and T.\
    \ Edis, \"The end of science? On human cognitive limitations and how to overcome\
    \ them,\" Biology & Philosophy, vol. 35, Jan. 2020, doi: 10.1007/s10539-020-9734-7.\n\
    - 7. I. Kotseruba and J. K. Tsotsos, \"40 years of cognitive architectures: core\
    \ cognitive abilities and practical applications,\" Artif Intell Rev, vol. 53,\
    \ no. 1, pp. 17– 94, Jan. 2020, doi: 10.1007/s10462-018-9646-y.\n- 8. OpenAI,\
    \ \"GPT-4 Technical Report.\" arXiv, Mar. 27, 2023. doi: 10.48550/arXiv.2303.08774.\n\
    - 9. V. Keith and S. Farris, \"Human-Centered Business Process Management,\" Fujitsu\
    \ scientific & technical journal, vol. 45, Apr. 2009.\n- 10. C. Di Ciccio, A.\
    \ Marrella, and A. Russo, \"Knowledge-Intensive Processes: Characteristics, Requirements\
    \ and Analysis of Contemporary Approaches,\" J Data Semant, vol. 4, no. 1, pp.\
    \ 29–57, Mar. 2015, doi: 10.1007/s13740-014-0038-4.\n- 11. Hull, Richard, and\
    \ Hamid R. Motahari Nezhad. \"Rethinking BPM in a Cognitive World: Transforming\
    \ How We Learn and Perform Business Processes,\" 3– 19, 2016. https://doi.org/10.1007/978-3-319-45348-4\\\
    _1.\n- 12. Beheshti, Amin, Jian Yang, Quan Z. Sheng, Boualem Benatallah, Fabio\
    \ Casati, Schahram Dustdar, Hamid Reza Motahari Nezhad, Xuyun Zhang, and Shan\
    \ Xue. \"ProcessGPT: Transforming Business Process Management with Generative\
    \ Artificial Intelligence.\" arXiv, May 28, 2023. https://doi.org/10.48550/arXiv.2306.01771.\n\
    - 13. Centers for Disease Control and Prevention, National Center on Birth Defects\
    \ and Developmental Disabilities, Division of Human Development and Disability.\
    \ Disability and Health Data System (DHDS) Data [online]. [accessed Jul 15, 2023].\
    \ URL: https://dhds.cdc.gov\n- 14. \"Making Content Usable for People with Cognitive\
    \ and Learning Disabilities.\" https://www.w3.org/TR/coga-usable/ (accessed Jul.\
    \ 15, 2023).\n- 15. B. Bozeman, J. Youtie, and J. Jung, \"Robotic Bureaucracy\
    \ and Administrative Burden: What Are the Effects of Universities' Computer Automated\
    \ Research Grants Management Systems?,\" Research Policy, vol. 49, no. 6, p. 103980,\
    \ Jul. 2020, doi: 10.1016/j.respol.2020.103980.\n- 16. A. Gregoriades and A. Sutcliffe,\
    \ \"A socio-technical approach to business process simulation,\" Decision Support\
    \ Systems, vol. 45, no. 4, pp. 1017–1030, Nov. 2008.\n- 17. Sweller, John. \"\
    Cognitive Load During Problem Solving: Effects on Learning.\" Cognitive Science\
    \ 12, no. 2 (1988): 257–85. https://doi.org/10.1207/s15516709cog1202\\_4.\n- 18.\
    \ Workflow Management Coalition, \"Workflow Management Coalition Terminology &\
    \ Glossary.\" Lighthouse Point, Florida: Future Strategies Inc.,1999.\n- 19. Y.\
    \ Doganata, \"Detecting Compliance Failures in Un-managed Processes,\" in Strategic\
    \ and Practical Approaches for Information Security Governance: Technologies and\
    \ Applied Solutions, 2012, pp. 385–404. doi: 10.4018/978-1-4666-0197-0.ch022.\n\
    - 20. Mukhi, N.K. (2010). Monitoring Unmanaged Business Processes. In: Meersman,\
    \ R., Dillon, T., Herrero, P. (eds) On the Move to Meaningful Internet Systems:\
    \ OTM 2010. OTM 2010. Lecture Notes in Computer Science, vol 6426. Springer, Berlin,\
    \ Heidelberg. https://doi.org/10.1007/978-3-642-16934-2\\_7\n- 21. J. Gonçalves,\
    \ F. Baião, F. Santoro, and G. Guizzardi, \"A cognitive BPM theory for knowledge-intensive\
    \ processes,\" Business Process Management Journal, vol. 29, pp. 465–488, Feb.\
    \ 2023, doi: 10.1108/BPMJ-11-2021-0746.\n- 22. Hamid R. Motahari Nezhad, Rama\
    \ Akkiraju, \"Towards Cognitive BPM as the Next Generation BPM Platform for Analytics-Driven\
    \ Business Processes,\" in Business Process Management Workshops, F. Fournier\
    \ and J. Mendling, Eds., in Lecture Notes in Business Information Processing,\
    \ vol 202, 2015, doi: 10.1007/978-3-319-15895-2\\_14.\n- 23. F. Hattke, D. Hensel,\
    \ and J. Kalucza, \"Emotional Responses to Bureaucratic Red Tape,\" Public Administration\
    \ Review, vol. 80, no. 1, pp. 53–63, 2020, doi: 10.1111/puar.13116.\n- 24. \"\
    The Liberation of Federal Employees from Low-Value Work is Underway,\" Sep. 09,\
    \ 2020. https://www.performance.gov/liberating-fed-employees-fromlow-value-work-underway//#liberating\
    \ (accessed Jul. 10, 2023).\n- 25. \"'The State of Federal RPA,' Federal RPA Community\
    \ of Practice (CoP), December 29, 2021, [Online]. Available[:](https://s3.amazonaws.com/digitalgov/static/state-of-federal-rpa-report-12-2021.pdf)\
    \ https://s3.amazonaws.com/digitalgov/static/state-of-federal-rpa-report-12-2021.pdf\
    \ [Accessed: 16-Jul-2023].\n- 26. I. T. stories, \"Digitizing contract management\
    \ with microservices on Azure,\" Inside Track Blog, Dec. 17, 2019. https://www.microsoft.com/insidetrack/blog/digitizing-contract-management-using-micro-services-on-azure/\
    \ (accessed Aug. 02, 2023).\n- 27. B. Rich, \"How AI Is Changing Contracts,\"\
    \ Harvard Business Review, Feb. 12, 2018. Accessed: Aug. 02, 2023. [Online]. Available:\
    \ https://hbr.org/2018/02/how-ai-is-changing-contracts\n- 28. Pollack, Martha\
    \ E. \"Intelligent Technology for an Aging Population: The Use of AI to Assist\
    \ Elders with Cognitive Impairment.\" *AI Magazine*, 15 June 2005, ojs.aaai.org/aimagazine/index.php/aimagazine/article/view/1810.\n\
    - 29. Singh, Charanjit. \"Artificial Intelligence and Deep Learning: Considerations\
    \ for Financial Institutions for Compliance with the Regulatory Burden in the\
    \ United Kingdom.\" *Journal of Financial Crime*, 14 Apr. 2023, www.emerald.com/insight/content/doi/10.1108/JFC-01-2023-0011/full/pdf?title=artificialintelligence-and-deep-learning-considerations-for-financial-institutions-for-compliance-with-the-regulatory-burden-in-the-united-kingdom.\n\
    - 30. Woolhandler , Steffie, and David Himmelstein . *Administrative Work Consumes\
    \ One-Sixth of U.S ... - Sage Journals*, 1 Oct. 2014, journals.sagepub.com/doi/pdf/10.2190/HS.44.4.a.\n\
    - 31. Dowell, A. C., Hamilton, S., & McLeod, D. K. (2000). Job satisfaction, psychological\
    \ morbidity and job stress among New Zealand general practitioners. *New Zealand\
    \ Medical Journal, 113*(1113), 269-272. http://mutex.gmu.edu/login?url=https://www.proquest.com/scholarly-journals/job-satisfactionpsychological-morbidity-stress/docview/1140265594/se-2\n\
    - 32. Deborah B. Smith & Joel Shields (2013) Factors Related to Social Service\
    \ Workers' Job Satisfaction: Revisiting Herzberg's Motivation to Work, Administration\
    \ in Social Work, 37:2, 189-198, DOI[: 10.1080/03643107.2012.673217.](https://doi.org/10.1080/03643107.2012.673217)\n\
    - 33. Giauque, David & Ritz, Adrian & Varone, Frédéric & Anderfuhren-Biget, Simon.\
    \ (2012). Resigned But Satisfied: The Negative Impact of Public Service Motivation\
    \ and Red Tape on Work Satisfaction. Public Administration. 90. 10.1111/j.1467-9299.2011.01953.x.\n\
    - 34. Huang, Q., Zhang, K., Bodla, A. A., & Wang, Y. (2022). The Influence of\
    \ Perceived Red Tape on Public Employees' Procrastination: The Conservation of\
    \ Resource Theory Perspective. *International journal of environmental research\
    \ and public health*, *19*(7), 4368. https://doi.org/10.3390/ijerph19074368\n\
    - 35. S. Wissell, L. Karimi, T. Serry, L. Furlong, and J. Hudson, \"'You Don't\
    \ Look Dyslexic': Using the Job Demands-Resource Model of Burnout to Explore Employment\
    \ Experiences of Australian Adults with Dyslexia,\" International Journal of Environmental\
    \ Research and Public Health, vol. 19, no. 17, Art. no. 17, Jan. 2022, doi: 10.3390/ijerph191710719.\n\
    - 36. Sangmook Kim, Individual-Level Factors and Organizational Performance in\
    \ Government Organizations, *Journal of Public Administration Research and Theory*,\
    \ Volume 15, Issue 2, April 2005, Pages 245–261[, https://doi.org/10.1093/jopart/mui013](https://doi.org/10.1093/jopart/mui013)\n\
    - 37. Lasnoski, Nathan. \"AI Enables Employment for Individuals with Cognitive\
    \ Disabilities.\" *Humans of IT Blog*, 21 Sept. 2020, techcommunity.microsoft.com/t5/humans-of-it-blog/ai-enables-employment-for-individuals-with-cognitive/ba-p/1681812.\n\
    - 38. Jakob Nielsen, \"Usability 101: Introduction to Usability,\" Nielsen Norman\
    \ Group. https://www.nngroup.com/articles/usability-101-introduction-to-usability/\
    \ (accessed Jul. 30, 2023).\n- 39. M. Heravizadeh, J. Mendling, and M. Rosemann,\
    \ \"Dimensions of Business Processes Quality (QoBP),\" in Business Process Management\
    \ Workshops, D. Ardagna, M. Mecella, and J. Yang, Eds., in Lecture Notes in Business\
    \ Information Processing. Berlin, Heidelberg: Springer, 2009, pp. 80–91. doi:\
    \ 10.1007/978-3-642-00328-8\\_8.\n- 40. G. M. Donahue, \"Usability and the bottom\
    \ line,\" Software, IEEE, vol. 18, pp. 31–37, Feb. 2001.\n- 41. Bevan, N. (2005).\
    \ Cost benefits evidence and case studies. Cost-justifying usability: An update\
    \ for the internet age. San Francisco: Morgan Kaufmann.\n- 42. C.-M. Karat, \"\
    Cost-Benefit Analysis of Usability Engineering Techniques,\" Proceedings of the\
    \ Human Factors Society Annual Meeting, vol. 34, no. 12, pp. 839–843, Oct. 1990,\
    \ doi: 10.1177/154193129003401203.\n- 43. Weinschenk, Susan. \"Usability: A Business\
    \ Case,\" White Paper Human Factors International 30 (2005).\n- 44. C.-M. Karat,\
    \ \"4 Chapter A Business Case Approach to Usability Cost Justification for the\
    \ Web,\" in Cost-Justifying Usability (Second Edition), R. G. Bias and D. J. Mayhew,\
    \ Eds., in Interactive Technologies. San Francisco: Morgan Kaufmann, 2005, pp.\
    \ 103–141. doi: 10.1016/B978-012095811-5/50004-3.\n- 45. O. H. Petersen, J. R.\
    \ Hansen, and K. Houlberg, \"The administrative burden of doing business with\
    \ the government: Learning and compliance costs in Business-Government interactions,\"\
    \ Public Administration, vol. n/a, no. n/a, doi: 10.1111/padm.12904.\n- 46. Sokolov,\
    \ D. (2023, May 3). How much time do your employees spend on checking emails?\
    \ PPM Express. https://ppm.express/blog/how-much-time-youremployees-spend-on-checking-emails/#:~:text=According%20to%20the%20McKinsey%20Global,in%20the%20background%20while%20working.\n\
    - 47. A. Bruseberg, \"Presenting the value of Human Factors Integration: guidance,\
    \ arguments and evidence,\" Cogn Tech Work, vol. 10, no. 3, pp. 181–189, Jul.\
    \ 2008, doi: 10.1007/s10111-007-0100-1.\n- 48. Government Accountability Office,\
    \ \"Title of the Report or Webpage,\" U.S. Government Accountability Office, Publication\
    \ Date (if available), UR[L:](https://www.gao.gov/products/gao-21-519sp) [https://www.gao.gov/products/gao-21-519sp.](https://www.gao.gov/products/gao-21-519sp)\n\
    - 49. Cognitive World, \"Is AI a Job Killer or Job Creator?,\" Forbes, November\
    \ 24, 2019, URL[:](https://www.forbes.com/sites/cognitiveworld/2019/11/24/is-ai-a-job-killer-or-job-creator/?sh=1b20b10337e8)\
    \ [https://www.forbes.com/sites/cognitiveworld/2019/11/24/is-ai-a](https://www.forbes.com/sites/cognitiveworld/2019/11/24/is-ai-a-job-killer-or-job-creator/?sh=1b20b10337e8)[job-killer-or-job-creator/?sh=1b20b10337e8.](https://www.forbes.com/sites/cognitiveworld/2019/11/24/is-ai-a-job-killer-or-job-creator/?sh=1b20b10337e8)\n\
    - 50. Microsoft, \"AI Guidelines Hax Toolkit,\" Microsoft, UR[L:](https://www.microsoft.com/en-us/haxtoolkit/ai-guidelines/)\
    \ [https://www.microsoft.com/en-us/haxtoolkit/ai-guidelines/.](https://www.microsoft.com/en-us/haxtoolkit/ai-guidelines/)"
  decisions:
    evaluation_prompt: 'Disqualified: no evaluation. Reason: The abstract and introduction
      discuss the capabilities and implications of ProcessGPT but do not mention any
      empirical, experimental, or quantitative evaluation, such as experiments, metrics,
      or comparisons.'
    related_work_prompt: 'Qualified. Reason: The paper references prior research on
      human cognitive limitations and discusses the capabilities of AI systems in
      relation to these limitations, citing multiple sources. It also mentions Cognitive
      BPM and compares its approach with existing work, specifically referencing the
      AI model ProcessGPT as a practical example.'
    novelty_prompt: 'Qualified. Reason: The abstract and introduction clearly present
      the novelty of the ProcessGPT model, specifically in how it automates and improves
      business processes while considering the cognitive limitations of individuals
      with cognitive disabilities. The paper claims to provide a blueprint for designing
      efficient business processes and highlights the unique application of AI in
      this context, indicating new contributions to the field.'
    review_only_prompt: 'Qualified. Reason: The paper proposes the AI model ProcessGPT
      and discusses its application in improving business processes, particularly
      for individuals with cognitive disabilities, indicating new contributions and
      methods rather than merely summarizing existing work.'
  llm_input_used: '## Abstract

    We examine ProcessGPT, an AI model designed to automate, augment, and improve

    business processes, to study the challenges of managing business processes

    within the cognitive limitations of the human workforce, particularly

    individuals with cognitive disabilities. ProcessGPT provides a blueprint for

    designing efficient business processes that take into account human cognitive

    limitations. By viewing this through the lens of cognitive disabilities, we

    show that ProcessGPT improves process usability for individuals with and

    without cognitive disabilities. We also demonstrate that organizations

    implementing ProcessGPT-like capabilities will realize increased productivity,

    morale, and inclusion.


    ## Introduction

    Human cognitive factors such as perception, attention, memory, language, reasoning,
    processing speed, and executive functions [1] have known limitations. [2][3][4][5]
    In contrast, Artificial intelligence (AI) systems transcend many boundaries of
    human cognition, particularly for memory, attention, and executive function. [6][7]
    Large language models such as GPT-4 already outperform humans in language areas
    such as lexical knowledge, grammatical sensitivity, communication ability, naming
    facility, and fluency. [\[1\]](#page-0-0)[8]


    Exploration of AI''s cognitive capabilities in the context of business process
    management (BPM) offers insights into knowledge-intensive processes that are predominantly
    driven by human activities. [9] Knowledge-intensive processes can only be partially
    mapped to a process model and commonly vary due to circumstances and administrative
    discretion. [10] Facilitation of these processes is within the domain of Cognitive
    BPM, which manages business processes using cognitive computing technologies.
    [11] We reference other researchers'' AI model, ProcessGPT, as a practical representation
    of a Cognitive BPM solution (Fig. 1). ProcessGPT is an AI model whose goal is
    to suggest the best next step in a process based on a Process Knowledge Graph
    and extensive supporting elements. [12] While ProcessGPT is capable of process
    augmentation, automation, and improvement, we highlight the challenges faced by
    employees with cognitive disabilities by considering how ProcessGPT can augment
    their experience.


    <span id="page-0-0"></span>![](_page_0_Figure_10.jpeg)'
  token_usage: 2834
  time_usage: 4.602159738540649
- title: "Graph-of-Thought: Utilizing Large Language Models to Solve Complex and\n\
    \  Dynamic Business Problems"
  abstract: 'This paper presents Graph-of-Thought (GoT), a new model for workflow

    automation that enhances the flexibility and efficiency of Large Language

    Models (LLMs) in complex task execution. GoT advances beyond traditional linear

    and tree-like cognitive models with a graph structure that enables dynamic path

    selection. The open-source engine GoTFlow demonstrates the practical

    application of GoT, facilitating automated, data-driven decision-making across

    various domains. Despite challenges in complexity and transparency, GoTFlow''s

    potential for improving business processes is significant, promising

    advancements in both efficiency and decision quality with continuous

    development.'
  url: http://arxiv.org/abs/2401.06801v2
  keywords: ''
  document: "# Graph-of-Thought: Utilizing Large Language Models to Solve Complex\
    \ and Dynamic Business Problems\n\nYe Li *Asia-Pacific Research and Development\
    \ Group Microsoft* Beijing, China jull@microsoft.com\n\n*Abstract***—This paper\
    \ presents Graph-of-Thought (GoT), a new model for workflow automation that enhances\
    \ the flexibility and efficiency of Large Language Models (LLMs) in complex task\
    \ execution. GoT advances beyond traditional linear and tree-like cognitive models\
    \ with a graph structure that enables dynamic path selection. The open-source\
    \ engine GoTFlow demonstrates the practical application of GoT, facilitating automated,\
    \ data-driven decision-making across various domains. Despite challenges in complexity\
    \ and transparency, GoTFlow's potential for improving business processes is significant,\
    \ promising advancements in both efficiency and decision quality with continuous\
    \ development.**\n\n## *Keywords—Graph-of-Thought (GoT), Workflow Automation,\
    \ Large Language Models (LLMs), Task Execution, Data-Driven Decision Making, Complexity\
    \ Management*\n\n# I. INTRODUCTION\n\nCurrently, with the rapid development of\
    \ artificial intelligence and machine learning technologies, large language models\
    \ (LLMs) have become a hot topic in the field of natural language processing.\
    \ LLMs have demonstrated outstanding performance in various tasks such as text\
    \ generation, translation, summarization, and question-answering systems.\n\n\
    However, LLMs still have limitations in handling complex, multi-step task processes.\
    \ Traditional LLMs often encounter difficulties in generating coherent and logically\
    \ consistent long texts, especially when they need to integrate information from\
    \ multiple sources and perform deep reasoning.\n\nThe limitations of existing\
    \ models like Chain-of-Thought (CoT) and Tree-of-Thought (ToT) stem from their\
    \ linear and hierarchical structures, which struggle with complex, multidimensional\
    \ problems. CoT is limited by its sequential reasoning, unable to explore multiple\
    \ paths simultaneously, while ToT, despite allowing for branching, cannot model\
    \ interconnected thought processes effectively.\n\nTo overcome these limitations,\
    \ this paper proposes a new thinking model - Graph-of-Thought (GoT). Different\
    \ from the CoT and ToT models, the proposed GoT model addresses these constraints\
    \ by utilizing a graph structure for more dynamic, interconnected reasoning.\n\
    \nThis approach surpasses CoT and ToT by enabling multithreaded thought processes\
    \ and integrating information from diverse sources, enhancing problem-solving\
    \ accuracy and efficiency. GoT represents a significant leap forward, offering\
    \ a more flexible, effective framework for complex task execution and workflow\
    \ automation.\n\nThe main purpose of this paper is to introduce the concept and\
    \ usage of Graph-of-Thought and demonstrate its value in practical applications\
    \ through a workflow automation framework - GoTFlow.\n\nGoTFlow is an open-source\
    \ project that parses and executes large model workflows based on mind maps, automating\
    \ the combination of a series of complex tasks. This paper will detail its architecture,\
    \ working principles, and how to use it to achieve the transition from theory\
    \ to practice.\n\nThrough this research, we aim to provide a more flexible and\
    \ effective framework for solving complex problems and offer an innovative solution\
    \ for automating workflows.\n\n## II. BACKGROUND\n\nFirst, we need to clarify\
    \ 2 concepts, which are Chain-of-Thought (CoT), and Tree-of-Thought (ToT).\n\n\
    Chain-of-Thought (CoT) and Tree-of-Thought (ToT) are both thinking models to construct\
    \ prompts.\n\nCoT presents the problem-solving process in a linear and step-by-step\
    \ manner, and reveals how to proceed from the problem to the answer in a logical\
    \ sequence, step by step. It is particularly suitable for tasks that require coherent\
    \ reasoning, such as solving mathematical problems or complex inferences.\n\n\
    However, CoT is often unable to effectively integrate information in multi-branch\
    \ tasks. A more complex model - Tree-of-Thought (ToT) was proposed.\n\nToT visualizes\
    \ decision-making in a branching tree structure. Each branch represents a different\
    \ reasoning path or solution, allowing for exploration of multiple outcomes. Although\
    \ it captures a range of possibilities and their potential consequences, ToT still\
    \ appears too rigid when facing intersecting and overlapping thinking paths.\n\
    \nTo overcome the aforementioned limitations, we proposes a new model.\n\n## III.\
    \ GRAPH-OF-THOUGHT (GOT) MODEL\n\nGraph-of-Thought (GoT) is an innovative thinking\
    \ model that uses graph structures to define and execute tasks. Each \"node\"\
    \ of thought is interconnected in multiple dimensions, providing not only linear\
    \ and tree-like thinking paths but also creating more complex network structures.\n\
    \nThis structure allows for the simultaneous existence of multiple thinking paths\
    \ and decision points, thus more closely resembling the natural thinking process\
    \ of humans.\n\nCompared to CoT and ToT, the significant advantage of GoT lies\
    \ in its flexibility and practicality.\n\nBy utilizing graph structures, GoT can\
    \ more accurately simulate and execute multi-step, multi-condition workflows.\n\
    \nIn the GoT model, each node can be a decision point, allowing for dynamic determination\
    \ of subsequent paths based on the output of previous nodes.\n\nThis approach\
    \ greatly enhances the ability to handle complex and variable tasks, making GoT\
    \ particularly suitable for scenarios that require highly personalized and dynamic\
    \ decision-making, such as complex data analysis, strategy formulation, project\
    \ management, and other fields.\n\nThere are several ongoing efforts in the development\
    \ of Graph-of-Thought frameworks, and this paper focuses on the implementation\
    \ and application of Microsoft's Large Language Model in the proposed GoTFlow.\n\
    \n# IV. GOTFLOW: OPEN-SOURCE GRAPH-OF-THOUGHT WORKFLOW ENGINE\n\nGoTFlow (https://github.com/microsoft/gotflow)\
    \ is an opensource Graph-of-Thought workflow automation framework built on the\
    \ Graph-of-Thought theory. It allows users to graphically define and execute task\
    \ flows based on large language models (LLMs) for various business scenarios,\
    \ thus achieving automated processing of complex task combinations.\n\nMicrosoft's\
    \ implementation of the Graph-of-Thought model in GoTFlow leverages its powerful\
    \ Large Language Model, which enables more accurate and efficient task execution\
    \ and dynamic workflow adjustments.\n\nThe core module of GoTFlow is the Graph-of-Thought\
    \ Flow Engine. Users define workflows through JSON format configuration files,\
    \ which are then parsed and executed by the flow engine.\n\nIn GoTFlow, workflows\
    \ are composed of two types of nodes which were linked with directed edges. The\
    \ two types of nodes being Executor and Decision Maker.\n\n*Executor*: Responsible\
    \ for executing specific tasks. Each executor represents an operation or a set\
    \ of operations, such as text segmentation, text integration, and prompting LLM\
    \ tasks.\n\n*Decision Maker*: Performing tasks and then determining the next direction\
    \ of the workflow based on the output of the task execution. It can choose different\
    \ execution paths based on complex logic or conditional expressions, similar to\
    \ a branch (conditional) node in a control flow. This allows GoTFlow to not only\
    \ execute fixed task sequences but also dynamically adapt to changing situations\
    \ and requirements.\n\nEssential functions of GoTFlow support the individual processing\
    \ of nodes by executing tasks and determining the next steps in the workflow.\
    \ They manage entire workflows, from handling single configurations to comprehensive\
    \ workflow processing, emphasizing GoTFlow's capacity to manage complex workflows\
    \ efficiently.\n\nGoTFlow employs caching to store node outputs, facilitating\
    \ their use in subsequent tasks. This supports complex, interdependent workflows.\
    \ Robust error handling ensures workflow continuity, even in the face of errors,\
    \ underscoring GoTFlow's reliability for managing large and complex workflows.\n\
    \nThrough its unique architecture (refer to the blow diagram) and core components,\
    \ GoTFlow not only provides powerful tools for executing complex tasks but also\
    \ opens up new possibilities for automating and optimizing workflows. GoTFlow\
    \ offers a novel solution for automating and optimizing workflows, providing unprecedented\
    \ flexibility and efficiency in addressing business challenges across various\
    \ applications.\n\n![](_page_1_Figure_19.jpeg)\n\nFig. 1 Architecture of GoTFlow\n\
    \n## V. WORKFLOW DESIGN OF GOTFLOW\n\nGoTFlow introduces a domain-specific language\
    \ (DSL) to design and define workflows. GoTFlow DSL is based on JSON format because\
    \ JSON has a clear structure and is easy to understand and write. In GoTFlow DSL,\
    \ users can define various nodes in the workflow, directed relationships between\
    \ nodes, and input/output, data processing, conditional judgments, or interactions\
    \ with external services for each node.\n\nOnce the workflow is defined and configured,\
    \ GoTFlow's workflow engine can automatically parse and execute these tasks, achieving\
    \ the automation of the entire workflow.\n\nTo better understand GoTFlow's workflow\
    \ design and execution process, here is a simple example:\n\n![](_page_2_Figure_0.jpeg)\n\
    \nFig. 2. Example of a GoTFlow's workflow.\n\n![](_page_2_Figure_2.jpeg)\n\nFig.\
    \ 3. Detailed execution logic of Executor and Decision Maker.\n\nDefining Workflow\
    \ Structure: Suppose we need to build a workflow for automatically collecting\
    \ data, determining whether the collected data can be subjected to quantitative\
    \ analysis, and if feasible, performing data mining and quantitative analysis;\
    \ otherwise, performing qualitative analysis.\n\nIn this workflow, we need to\
    \ define six nodes: an executor for data collection; a decision maker for determining\
    \ whether the data can be subjected to quantitative analysis; two executor for\
    \ quantitative analysis, and two other executor for qualitative analysis.\n\n\
    Configuring Node Tasks: For the data collection executor, we configure it to obtain\
    \ data from a specific input file. For the decision maker, we configure it to\
    \ determine the collected data through prompting LLM and set a rule: if LLM returns\
    \ an affirmative answer, trigger the \"YES\" path; otherwise, trigger the \"NO\"\
    \ path.\n\nThe DSL file for this workflow is provided in the appendix section,\
    \ demonstrating how the workflow is defined and configured using JSON format.\
    \ From it, you would see that in the *input\\_parameters* element of each node,\
    \ there is an item in the type of *prompt\\_template*, which is corresponding\
    \ to a text file. The content of this text file is the template for the prompt\
    \ of the current node to prompt LLMs.\n\nThe text content is as follows:\n\n*I\
    \ am a \\${role} at a \\${organization}, and I am now providing a \\${report}\
    \ for my \\${customer} client. The information of \\${target} for \\${goal} is\
    \ between the two \"---\" below, and the data part between the two \"\\*\\*\\\
    *\", please judge whether it is possible to conduct a quantitative analysis of\
    \ \\${target} based on the original information and the data therein. If yes,\
    \ please input \"yes\", otherwise, please output \"no\":*\n\n*---*\n\n```\n${content}\n\
    ```\n*--- \\*\\*\\**\n\n## *\\${data\\_reader\\_output}*\n\n*\\*\\*\\**\n\n*{*\n\
    \nEach *\\${XXX}* is a specific template parameter, and the values of these parameters\
    \ are divided into two parts. Some common parameters are stored separately in\
    \ a JSON file, such as \"*\\${GF\\_ROOT}/data/workflows/Ads/input/parameters/trend.jso\
    \ n*\" in the example above. Its content is as follows:\n\n*\"organization\":\
    \ \"Large Advertising Company\",*\n\n*\"role\": \"Marketing Director, whose responsibility\
    \ is to play a core role in the writing of marketing plans, propose strategies\
    \ and insights based on customer needs, guide creative and delivery execution,\
    \ and be responsible for the final quality of the plan\",*\n\n*\"customer\": \"\
    Coffee Producer\",*\n\n*\"report\": \"Marketing Plan\",*\n\n*\"goal\": \"Packaged\
    \ Coffee\",*\n\n*\"target\": \"Industry Trends\",*\n\n*\"action\": \"Extract insights\
    \ and describe the thought process of insights\",*\n\n*\"rules\": \"Note: Only\
    \ need to provide the thought process, no need to give a plan. The thought process\
    \ should start with a serial number and not be summarized at the end\",*\n\n####\
    \ *\"suggest\": \"\",*\n\n*\"content\": \"New coffee brands and products are emerging\
    \ in China, and the market is severely saturated. However, there has been no innovation\
    \ in the coffee market in Europe and America for decades, which is a new opportunity\
    \ for packaged coffee. With the decrease in production in some coffee-producing\
    \ countries and the further increase in coffee demand in various countries, the\
    \ global coffee market supply gap pushes coffee prices to new highs, which also\
    \ becomes an opportunity for Chinese packaged coffee brands to go overseas. Emerging\
    \ instant coffee brands in China, such as Coffee Brand-1, Coffee Brand-2, and\
    \ Coffee Brand-3, have seized this opportunity and entered the US e-commerce platform,*\
    \ \n\n*taking the lead in grabbing market share in the United States.\"*\n\nIf\
    \ there are other specific parameter values for each node, they are defined in\
    \ the DSL file's *input\\_parameters* element.\n\n# VI. CASE STUDY: MARKETING\
    \ STRATEGY PLAN GENERATION WORKFLOW\n\nTo demonstrate how GoTFlow's capability\
    \ in handling complex business requirements, we will explore this through an example\
    \ of automating the generation of marketing strategy reports.\n\nIn this case\
    \ study, GoTFlow was utilized to automate the process of generating marketing\
    \ strategy reports. Typically, this process involves multiple steps including\
    \ the collection of market data, analysis of consumer behavior, assessment of\
    \ the effectiveness of marketing channels, and the creation of a comprehensive\
    \ strategy report based on this information.\n\nWhen designing this workflow,\
    \ the entire process was divided into two stages:\n\n# *A. First Stage: Data collection,\
    \ analysis, and insight generation.*\n\nIn this phase, data corresponding to four\
    \ distinct parts (as shown in the diagram below) is collected, analyzed, classified,\
    \ and clear inference objectives are determined. Then, based on the inference\
    \ objectives for each category of information, insights are generated.\n\n![](_page_3_Figure_8.jpeg)\n\
    \nFig. 4. Tasks of the first stage.\n\nEach part is further divided into two workflows:\
    \ the former is responsible for data collection, inference objective analysis\
    \ of the data, and tagging the data with various predefined type labels; the latter\
    \ generates insights based on the output from the former in relation to the inference\
    \ objectives.\n\nSeveral executor are defined within each workflow, such as data\
    \ collection, data analysis, etc., each with a clear task and output.\n\n# *B.\
    \ Second Stage: Generating and polishing the market planning report.*\n\nThis\
    \ stage includes three steps: generation of the report theme and outlines for\
    \ each section; creation of strategic recommendations; and report refinement.\
    \ Each step corresponds to a workflow.\n\nOf course, in reality, all the above\
    \ workflows in both stages could be integrated into a single workflow, but for\
    \ ease of debugging and flexibility of generation, they were split into more than\
    \ twenty relatively short workflows, which also reflects the flexibility of GoTFlow.\n\
    \nGoTFlow successfully completed the generation of the entire marketing strategy\
    \ report. The automation of data collection and processing significantly shortened\
    \ the required time for the whole process and also improved the accuracy of data\
    \ handling. The generated report included not only a comprehensive market analysis\
    \ but also provided data-driven specific marketing recommendations.\n\nIn the\
    \ case study, the integration of LLMs and GoTFlow allowed for dynamic adjustments\
    \ of workflows based on realtime data and situational changes. For instance, the\
    \ system could modify the marketing strategy recommendations based on the latest\
    \ market trends and consumer behavior insights, ensuring that the generated report\
    \ remains relevant and up-to-date.\n\nIn this way, GoTFlow is proven to be able\
    \ to improve work efficiency and provide solid support for data-driven decisionmaking\
    \ as well.\n\n# VII. DISCUSSION\n\nBy integrating LLMs, GoTFlow permits the dynamic\
    \ adjustment of workflows, enabling modifications in response to real-time data\
    \ and situational changes, and provides more intelligent and efficient data processing\
    \ and decision support than most conventional tools offer.\n\nBeyond its use in\
    \ the generation of marketing strategy reports, GoTFlow is also applicable to\
    \ various other scenarios.\n\nFor example, GoTFlow can facilitate the automation\
    \ of task allocation and progress tracking for project management; it can process\
    \ a vast array of customer inquiries and providing tailored responses in customer\
    \ service; it can analyze intricate logistical data, thereby optimizing inventory\
    \ management and distribution planning, for supply chain management…\n\nDespite\
    \ its numerous advantages, GoTFlow still faces certain challenges:\n\n- 1. Complex\
    \ Workflow Management: Managing intricate workflows with multiple decision points\
    \ and branching paths presents a challenge in ensuring efficient and error-free\
    \ execution.\n- 2. Scalability: As workflows grow in complexity and size, ensuring\
    \ that GoTFlow can scale to handle increased demands without sacrificing performance\
    \ is crucial.\n- 3. Dynamic Adaptation: Keeping up with changing requirements\
    \ and conditions within a workflow\n\n*}*\n\nrequires GoTFlow to continuously\
    \ adapt, which can be challenging in rapidly evolving business environments.\n\
    \n4. User-Friendliness: Ensuring that GoTFlow remains accessible and easy to use\
    \ for users with varying levels of technical expertise is a challenge, especially\
    \ as the system's capabilities expand.\n\nTo address these challenges, a few future\
    \ development directions would be possible:\n\n- 1. Enhanced AI Integration: Incorporating\
    \ more advanced AI and machine learning techniques to improve decision-making\
    \ nodes and automate more complex tasks within workflows.\n- 2. User Interface\
    \ Improvements: Developing a more intuitive user interface or graphical workflow\
    \ designer could help users more easily construct and manage their workflows.\n\
    - 3. Customization and Extensibility: Allowing users to create and integrate custom\
    \ node types or extensions could enhance GoTFlow's flexibility and applicability\
    \ to a wider range of tasks.\n- 4. Performance Optimization: Continuous efforts\
    \ to optimize the underlying architecture for better performance and scalability,\
    \ ensuring GoTFlow can handle larger and more complex workflows efficiently.\n\
    - 5. Collaboration Features: Adding features that facilitate collaboration among\
    \ multiple users or teams could enable more complex workflows that require input\
    \ and decision-making from different stakeholders.\n- 6. Cross-Platform Compatibility:\
    \ Ensuring GoTFlow works seamlessly across different platforms and\n\nenvironments,\
    \ making it more accessible to users regardless of their preferred technology\
    \ stack.\n\nIt is believed that with ongoing development and refinement, GoTFlow\
    \ can continue to evolve as a leading solution for automating and optimizing complex\
    \ workflows, further solidifying its position as an innovative tool in the field\
    \ of workflow automation and AI.\n\n## REFERENCES\n\n- [1] Jason Wei, Xuezhi Wang,\
    \ Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and\
    \ Denny Zhou. 2023b. Chain-ofthought prompting elicits reasoning in large language\
    \ models.\n- [2] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia,\
    \ Ed Chi, Quoc V Le, Denny Zhou, et al. 2022b. Chain-of-thought prompting elicits\
    \ reasoning in large language models. Advances in Neural Information Processing\
    \ Systems, 35:24824–24837\n- [3] S. Yao, D. Yu, J. Zhao, I. Shafran, T. L. Griffiths,\
    \ Y. Cao and K. Narasimhan. 2023. Tree of Thoughts: Deliberate Problem Solving\
    \ with Large Language Models. ArXiv:2305.10601 [cs]\n- [4] X. Chen, M. Lin, N.\
    \ Scharli, and D. Zhou. Teaching large language models to self-debug, 2023. ¨\n\
    - [5] A. Chowdhery, S. Narang, J. Devlin, M. Bosma, G. Mishra, A. Roberts, P.\
    \ Barham, H. W.Chung, C. Sutton, S. Gehrmann, et al. Palm: Scaling language modeling\
    \ with pathways. arXiv preprint arXiv:2204.02311, 2022.\n- [6] S. Hao, Y. Gu,\
    \ H. Ma, J. J. Hong, Z. Wang, D. Z. Wang, and Z. Hu. Reasoning with language model\
    \ is planning with world model. arXiv preprint arXiv:2305.14992, 2023.\n- [7]\
    \ T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan,\
    \ P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners.\
    \ Advances in neural information processing systems, 33:1877–1901, 2020.\n- [8]\
    \ A. Creswell and M. Shanahan. Faithful reasoning using large language models.\
    \ arXiv preprint arXiv:2208.14271, 2022.\n\n## APPENDIX: THE DSL FILE FOR MARKETING\
    \ PLANNING WORKFLOW\n\n*{*\n\n```\n \"output_dir_path\": \"${GF_ROOT}/data/workflows/Ads/output\"\
    ,\n\"input_parameters\":[\n{\n\"suffix\": \"trend\",\n\"file_path\": \"${GF_ROOT}/data/workflows/Ads/input/parameters/trend.json\"\
    \n}\n],\n\"flow_items\": [\n{\n\"id\": \"data_reader\",\n\"description\": \"read\
    \ data from the result of task_a\",\n\"type\": \"executor\",\n\"input_parameters\"\
    : [\n{\n\"name\": \"prompt_template_file_path\",\n\"type\": \"prompt_template\"\
    ,\n\"file_path\": \"${GF_ROOT}/data/workflows/Ads/prompts/sum_data_reader.txt\"\
    \n}\n],\n\"output\": [{\n\"type\": \"variable\",\n\"name\": \"data_reader_output\"\
    \n}],\n\"next_nodes\": [\"determine_data_feature\"]\n},\n{\n\"id\": \"determine_data_feature\"\
    ,\n\"description\": \"\",\n\"type\": \"decision_maker\",\n\"input_parameters\"\
    : [\n{\n\"name\": \"prompt_template_file_path\",\n\"type\": \"prompt_template\"\
    ,\n\"file_path\": \"${GF_ROOT}/data/workflows/Ads/prompts/sum_data_feature_determine.txt\"\
    \n},\n{\n\"name\": \"data_reader_output\",\n\"type\": \"output_variable\"\n}\n\
    ],\n\"output\": [{\n\"type\": \"variable\",\n\"name\": \"is_quantitative_data\"\
    \n}],\n\"condition\": {\n\"is_composed\": false,\n\"data_source\": {\n\"type\"\
    : \"output_variable\",\n\"name\": \"is_quantitative_data\"\n},\n\"operator\":\
    \ \"equal\",\n\"operand\": \"yes\"\n},\n\"forward_paths\": [\n{\n\"condition_result\"\
    : true,\n\"next_nodes\": [\"data_trend_miner\"]\n},\n{\n\"condition_result\":\
    \ false,\n\"next_nodes\": [\"qualitative_analysis_1\", \"qualitative_analysis_2\"\
    ]\n}\n]\n},\n{\n\"id\": \"data_trend_miner\",\n\"description\": \"\",\n\"type\"\
    : \"executor\",\n\"input_parameters\": [\n{\n\"name\": \"prompt_template_file_path\"\
    ,\n\"type\": \"prompt_template\",\n\"file_path\": \"${GF_ROOT}/data/workflows/Ads/prompts/sum_trend_miner.txt\"\
    \n},\n{\n```\n\n```\n \"name\": \"data_reader_output\",\n\"type\": \"output_variable\"\
    \n}\n],\n\"output\": [{\n\"type\": \"variable\",\n\"name\": \"data_trend_miner_output\"\
    \n}],\n\"next_nodes\": [\"quantitative_analysis\"]\n},\n{\n\"id\": \"quantitative_analysis\"\
    ,\n\"description\": \"\",\n\"type\": \"executor\",\n\"input_parameters\": [\n\
    {\n\"name\": \"prompt_template_file_path\",\n\"type\": \"prompt_template\",\n\"\
    file_path\": \"${GF_ROOT}/data/workflows/Ads/prompts/sum_quantity_analysis.txt\"\
    \n},\n{\n\"name\": \"data_trend_miner_output\",\n\"type\": \"output_variable\"\
    \n}\n],\n\"output\": [{\n\"type\": \"file\",\n\"name\": \"quantitative_analysis_output.txt\"\
    \n}],\n\"next_nodes\": []\n},\n{\n\"id\": \"qualitative_analysis_1\",\n\"description\"\
    : \"\",\n\"type\": \"executor\",\n\"input_parameters\": [\n{\n\"name\": \"prompt_template_file_path\"\
    ,\n\"type\": \"prompt_template\",\n\"file_path\": \"${GF_ROOT}/data/workflows/Ads/prompts/sum_quality_analysis_1.txt\"\
    \n},\n{\n\"name\": \"data_reader_output\",\n\"type\": \"output_variable\"\n}\n\
    ],\n\"output\": [{\n\"type\": \"file\",\n\"name\": \"qualitative_analysis_1_output.txt\"\
    \n}],\n\"next_nodes\": []\n},\n{\n\"id\": \"qualitative_analysis_2\",\n\"description\"\
    : \"\",\n\"type\": \"executor\",\n\"input_parameters\": [\n{\n\"name\": \"prompt_template_file_path\"\
    ,\n\"type\": \"prompt_template\",\n\"file_path\": \"${GF_ROOT}/data/workflows/Ads/prompts/sum_quality_analysis_2.txt\"\
    \n},\n{\n\"name\": \"data_reader_output\",\n\"type\": \"output_variable\"\n}\n\
    ],\n\"output\": [{\n\"type\": \"file\",\n\"name\": \"qualitative_analysis_2_output.txt\"\
    \n}],\n\"next_nodes\": []\n}\n]\n```\n}"
  decisions:
    evaluation_prompt: 'Disqualified: no evaluation. Reason: The abstract and introduction
      discuss the Graph-of-Thought model and its theoretical advantages but do not
      mention any empirical, experimental, or quantitative evaluation, such as experiments,
      benchmarks, or metrics.'
    related_work_prompt: 'Qualified. Reason: The paper discusses and compares its
      proposed Graph-of-Thought (GoT) model with existing models like Chain-of-Thought
      (CoT) and Tree-of-Thought (ToT), highlighting their limitations and how GoT
      addresses these issues. This indicates engagement with prior research.'
    novelty_prompt: 'Qualified. Reason: The paper proposes a new model called Graph-of-Thought
      (GoT) for workflow automation, which enhances the capabilities of Large Language
      Models (LLMs) by utilizing a graph structure for dynamic reasoning. The introduction
      explicitly states the novelty of the approach and its advantages over existing
      models.'
    review_only_prompt: '- Qualified. Reason: The paper proposes a new model called
      Graph-of-Thought (GoT) and introduces an open-source engine, GoTFlow, demonstrating
      practical applications, indicating new contributions rather than merely summarizing
      existing work.'
  llm_input_used: '## Abstract

    This paper presents Graph-of-Thought (GoT), a new model for workflow

    automation that enhances the flexibility and efficiency of Large Language

    Models (LLMs) in complex task execution. GoT advances beyond traditional linear

    and tree-like cognitive models with a graph structure that enables dynamic path

    selection. The open-source engine GoTFlow demonstrates the practical

    application of GoT, facilitating automated, data-driven decision-making across

    various domains. Despite challenges in complexity and transparency, GoTFlow''s

    potential for improving business processes is significant, promising

    advancements in both efficiency and decision quality with continuous

    development.


    ## Introduction

    Currently, with the rapid development of artificial intelligence and machine learning
    technologies, large language models (LLMs) have become a hot topic in the field
    of natural language processing. LLMs have demonstrated outstanding performance
    in various tasks such as text generation, translation, summarization, and question-answering
    systems.


    However, LLMs still have limitations in handling complex, multi-step task processes.
    Traditional LLMs often encounter difficulties in generating coherent and logically
    consistent long texts, especially when they need to integrate information from
    multiple sources and perform deep reasoning.


    The limitations of existing models like Chain-of-Thought (CoT) and Tree-of-Thought
    (ToT) stem from their linear and hierarchical structures, which struggle with
    complex, multidimensional problems. CoT is limited by its sequential reasoning,
    unable to explore multiple paths simultaneously, while ToT, despite allowing for
    branching, cannot model interconnected thought processes effectively.


    To overcome these limitations, this paper proposes a new thinking model - Graph-of-Thought
    (GoT). Different from the CoT and ToT models, the proposed GoT model addresses
    these constraints by utilizing a graph structure for more dynamic, interconnected
    reasoning.


    This approach surpasses CoT and ToT by enabling multithreaded thought processes
    and integrating information from diverse sources, enhancing problem-solving accuracy
    and efficiency. GoT represents a significant leap forward, offering a more flexible,
    effective framework for complex task execution and workflow automation.


    The main purpose of this paper is to introduce the concept and usage of Graph-of-Thought
    and demonstrate its value in practical applications through a workflow automation
    framework - GoTFlow.


    GoTFlow is an open-source project that parses and executes large model workflows
    based on mind maps, automating the combination of a series of complex tasks. This
    paper will detail its architecture, working principles, and how to use it to achieve
    the transition from theory to practice.


    Through this research, we aim to provide a more flexible and effective framework
    for solving complex problems and offer an innovative solution for automating workflows.'
  token_usage: 3217
  time_usage: 5.727350473403931
