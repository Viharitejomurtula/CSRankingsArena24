papers:
- title: Real-Time Air Quality Monitoring with Edge AI and Machine Learning Algorithm
  abstract: Real-time air quality monitoring is essential for public health and environmental
    protection, but typical centralized systems have latency, bandwidth, and privacy
    concerns. This work describes a novel approach to decentralized air quality monitoring
    that employs Edge AI and powerful machine learning techniques. IoT sensors outfitted
    with NVIDIA Jetson devices collect and evaluate air quality data locally. Machine
    learning models, such as Convolutional Neural Networks (CNNs) and Recurrent Neural
    Networks (RNNs), analyze pollutants including PM2.5, CO2, and NOx in real time.
    Implemented across 50 urban sites with varied pollution levels, the technology
    reduced latency by up to 75% and bandwidth use by 60% when compared to typical
    cloud-based solutions. The pollutant detection accuracy was evaluated against
    conventional reference monitors and yielded an average correlation coefficient
    of 0.92. This system also used federated learning to update models based on local
    data, improving model accuracy by up to 15% over six months. This new strategy
    not only increases data processing speed and accuracy, but also protects data
    privacy and lowers operational costs. Significant improvements in latency, bandwidth
    efficiency, and model accuracy demonstrate the utility of decentralized air quality
    monitoring systems in urban settings.**
  keywords: '**—** *Real-time air quality monitoring, Edge AI, Machine learning algorithms,
    Decentralized monitoring, IOT sensors, NVIDIA Jetson devices, Pollutant detection*'
  document: "Proceedings of the 8th International Conference on Electronics, Communication\
    \ and Aerospace Technology (ICECA 2024) IEEE Xplore Part Number: CFP24J88-ART;\
    \ ISBN: 979-8-3503-6790-4\n\n# Real-Time Air Quality Monitoring with Edge AI and\
    \ Machine Learning Algorithm\n\nV.Ramu *Department of CSE (AI&ML) Kakatiya Institute\
    \ of Technology and Science*, Hanamkonda, Telangana, India. rv.csm@kitsw.ac.in\n\
    \nG Shyamala, *Department of Civil Engineering, School of Engineering, SR University*,\
    \ Warangal, Telangana 506371 civilshyamala@gmail.com\n\nUsikela Naresh *Department\
    \ of Computer Science and Engineering (AI&ML), CVR College of Engineering,*  Mangalpalli,\
    \ Rangareddy, Telangana, India. usikelanaresh@gmail.com\n\nDr P Saritha *Department\
    \ of Civil Engineering Malla Reddy Engineering College (Autonomous),*  Maisammaguda,\
    \ Secunderabad, India.\n\nP.Arun Prakash *Department of CSE Sri Eshwar College\
    \ of Engineering,*  Kondampatti [Post], Vadasithur (via), Coimbatore – 641 202,\
    \ Tamil Nadu, India. getinprakasham@gmail.com\n\nDr.Athiraja Atheeswaran *Department\
    \ of CSE (AI&ML) Malla Reddy College of Engineering,*  Hyderabad, India. a.athiraja4@gmail.com\n\
    \n*Abstract***— Real-time air quality monitoring is essential for public health\
    \ and environmental protection, but typical centralized systems have latency,\
    \ bandwidth, and privacy concerns. This work describes a novel approach to decentralized\
    \ air quality monitoring that employs Edge AI and powerful machine learning techniques.\
    \ IoT sensors outfitted with NVIDIA Jetson devices collect and evaluate air quality\
    \ data locally. Machine learning models, such as Convolutional Neural Networks\
    \ (CNNs) and Recurrent Neural Networks (RNNs), analyze pollutants including PM2.5,\
    \ CO2, and NOx in real time. Implemented across 50 urban sites with varied pollution\
    \ levels, the technology reduced latency by up to 75% and bandwidth use by 60%\
    \ when compared to typical cloud-based solutions. The pollutant detection accuracy\
    \ was evaluated against conventional reference monitors and yielded an average\
    \ correlation coefficient of 0.92. This system also used federated learning to\
    \ update models based on local data, improving model accuracy by up to 15% over\
    \ six months. This new strategy not only increases data processing speed and accuracy,\
    \ but also protects data privacy and lowers operational costs. Significant improvements\
    \ in latency, bandwidth efficiency, and model accuracy demonstrate the utility\
    \ of decentralized air quality monitoring systems in urban settings.** \n\n*Keywords***—**\
    \ *Real-time air quality monitoring, Edge AI, Machine learning algorithms, Decentralized\
    \ monitoring, IOT sensors, NVIDIA Jetson devices, Pollutant detection* \n\n# I.\
    \ INTRODUCTION\n\nAir quality monitoring is critical for protecting human health\
    \ and the environment, particularly in metropolitan areas where pollution levels\
    \ can change dramatically [1]. Traditional centralized air quality monitoring\
    \ systems, while effective, are frequently hampered by factors like as latency,\
    \ excessive bandwidth use, and potential privacy concerns. These restrictions\
    \ can cause delays in essential decisionmaking and inefficiencies in data processing\
    \ and analysis. Recent advances in IoT and AI have sparked renewed interest in\
    \ decentralized air quality monitoring. Research has focused on employing IoT\
    \ sensors for localized data collecting in order to reduce latency and bandwidth\
    \ requirements. The use of artificial intelligence, particularly machine learning,\
    \ has showed promise in improving the accuracy and speed of air quality analysis.\
    \ However, many systems continue to rely on centralized processing, limiting their\
    \ real-time capabilities. Furthermore, data privacy and scalability issues exist,\
    \ limiting the widespread adoption of these decentralized techniques in real applications.\
    \ The role of AI in this system is to enhance real-time air quality monitoring\
    \ by utilizing machine learning models, such as Convolutional Neural Networks\
    \ (CNNs) and Recurrent Neural Networks (RNNs), for accurate pollutant detection,\
    \ while Edge AI reduces latency and bandwidth consumption. This research proposes\
    \ a novel decentralized methodology to overcome the constraints of existing air\
    \ quality monitoring methods. This research intends to use Edge AI and advanced\
    \ machine learning techniques to address latency, bandwidth consumption, and data\
    \ privacy issues. This project focuses on deploying IoT sensors integrated with\
    \ NVIDIA Jetson devices to gather and interpret local air quality data. This system\
    \ uses machine learning models such as Convolutional Neural Networks (CNNs) and\
    \ Recurrent Neural Networks (RNNs) to analyze pollutants in real time, including\
    \ PM2.5, CO2, and NOx. The challenge, thus, revolves around improving the efficiency,\
    \ accuracy, and privacy of air quality monitoring via a decentralized approach.\n\
    \n#### II. LITERATURE REVIEW\n\nTraditional centralized systems have long been\
    \ utilized, but these systems exhibit substantial drawbacks, including latency,\
    \ bandwidth consumption, and privacy concerns. Several studies have examined the\
    \ limitations of centralized air quality monitoring systems. [2] highlighted challenges,\
    \ in enabling real-time data processing in minimizing health risks associated\
    \ with air pollution. [3] explored the use of IoT devices for decentralized air\
    \ quality monitoring, finding a reduction in latency but challenges in maintaining\
    \ data accuracy and consistency. [4] investigated edge AI for realtime data processing\
    \ and discovered promising outcomes in terms of bandwidth reduction and processing\
    \ speed. Air quality data has been analyzed using machine learning models such\
    \ as Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).\
    \ [5] used CNNs to detect pollutants such as PM2.5 and CO2, achieving high accuracy\
    \ but encountering challenges in real-time deployment due to processing restrictions.\
    \ [6] used RNNs for time-series analysis, which increased prediction accuracy\
    \ but caused latency issues in centralized systems.\n\n# *A. Gaps in Existing\
    \ Research*\n\nDespite useful insights from existing studies, there are still\
    \ several gaps in air quality monitoring. While edge computing reduces latency,\
    \ maintaining good data accuracy with limited bandwidth remains challenging. Privacy\
    \ problems remain, as decentralized systems frequently lack sufficient ways to\
    \ protect data privacy. Furthermore, continuous model updates based on real-time\
    \ data are required to maintain accuracy, but traditional systems fail to provide\
    \ efficient and secure updates.\n\n# *B. Addressing the Gaps*\n\nWhile IoT and\
    \ AI have made air quality monitoring more advanced, there are still gaps. Current\
    \ research does not focus on fully decentralized systems for local data processing,\
    \ which could improve latency and bandwidth utilization. Most research focuses\
    \ on cloud-based machine learning, ignoring the promise of edge computing for\
    \ real-time analysis. Furthermore, data privacy concerns are underexplored, with\
    \ few research examining the security advantages of decentralized architectures.\
    \ Scalability in decentralized systems, particularly with regard to accuracy across\
    \ numerous sites, has also received little attention. This study seeks to close\
    \ these gaps by introducing a decentralized strategy that employs Edge AI and\
    \ federated learning to improve efficiency, accuracy, and privacy.\n\n# III. METHODOLOGY\n\
    \nThe suggested methodology uses Edge AI and powerful machine learning algorithms\
    \ to create a decentralized air quality monitoring system. This method is intended\
    \ to address the drawbacks of traditional centralized techniques, including latency,\
    \ bandwidth consumption, and privacy problems. This methodology's main components\
    \ include IoT sensors equipped with NVIDIA Jetson devices, Convolutional Neural\
    \ Networks (CNNs) and Recurrent Neural Networks (RNNs) for real-time pollutant\
    \ monitoring, and federated learning for continuous model updates as shown in\
    \ Fig. 1. The selection of machine learning models such as Convolutional Neural\
    \ Networks (CNNs) for spatial pattern detection and Recurrent Neural Networks\
    \ (RNNs) for temporal trend analysis was based on their proven efficiency in real-time\
    \ pollutant monitoring and their ability to handle complex environmental data\
    \ in decentralized systems. The air quality monitoring process can be achieved\
    \ by deploying IoT sensors integrated with Edge AI devices like NVIDIA Jetson,\
    \ which locally process real-time data using machine learning models such as CNNs\
    \ and continuously update these models through federated learning to ensure accurate\
    \ pollutant detection and analysis. To ensure complete monitoring, system has\
    \ been implemented in 50 urban sites with various pollution levels.\n\n![](_page_1_Figure_6.jpeg)\n\
    \nFig. 1. Block diagram of our study\n\n# *A. Iot Sensors and Devices:*\n\nThe\
    \ air quality sensors used in this study are PM2.5 sensors, which measure particulate\
    \ matter with a diameter of less than 2.5 micrometers [13], CO2 sensors, which\
    \ detect carbon dioxide levels, and NOx sensors, which measure nitrogen oxides.\
    \ These sensors were chosen for accuracy, dependability, and adaptability for\
    \ urban contexts, ensuring that the data collected is precise and realistic of\
    \ current air quality conditions. NVIDIA Jetson devices were chosen because of\
    \ their high GPU performance, low power consumption, and appropriateness for real-time\
    \ data processing. These Jetson devices take sensor data, process it locally,\
    \ and run machine learning models, lowering latency and bandwidth use. The combination\
    \ of PM2.5, CO2, and NOx sensors with NVIDIA Jetson devices creates a reliable\
    \ and efficient air quality monitoring system as shown in Fig.2. The sensors continuously\
    \ monitor various contaminants, and the Jetson devices interpret the data in real\
    \ time, allowing for fast analysis and response. This integration improves the\
    \ efficiency and effectiveness of air quality monitoring, addressing important\
    \ environmental and public health issues.\n\n![](_page_1_Figure_11.jpeg)\n\nFig.\
    \ 2. Integration of iot sensors with NVidia device\n\n# *B. Data collection*\n\
    \nSensors installed in 50 urban areas with varied levels of pollution were used\
    \ to collect data on air quality. Each location was equipped with an NVIDIA Jetson\
    \ device, which collected data in real-time, processed it locally, and saved it\
    \ for further analysis as shown in Table I.\n\n| Locati<br>on ID | Urban<br>area\
    \              | Sens<br>or<br>Type        | Polluta<br>nt<br>Measu<br>red | Data<br>Collect<br>ion<br>Device\
    \ | Freque<br>ncy of<br>Data<br>Collecti<br>on | Data<br>Stora<br>ge<br>Meth<br>od\
    \               |\n|-----------------|----------------------------|---------------------------|-------------------------------|----------------------------------|--------------------------------------------|-------------------------------------------------|\n\
    | 1               | Residen<br>tial<br>Area A  | PM2.<br>5,<br>CO2,<br>NOx | PM2.5,<br>CO2,<br>NOx\
    \         | NVIDI<br>A<br>Jetson             | Every<br>5<br>minute<br>s     \
    \             | Local<br>storag<br>e on<br>Jetson<br>devic<br>e |\n| 2       \
    \        | Industri<br>al Zone<br>B   | PM2.<br>5,<br>CO2,<br>NOx | PM2.5,<br>CO2,<br>NOx\
    \         | NVIDI<br>A<br>Jetson             | Every<br>5<br>minute<br>s     \
    \             | Local<br>storag<br>e on<br>Jetson<br>devic<br>e |\n| 3       \
    \        | Traffic<br>Heavy<br>Area C | PM2.<br>5,<br>CO2,<br>NOx | PM2.5,<br>CO2,<br>NOx\
    \         | NVIDI<br>A<br>Jetson             | Every<br>5<br>minute<br>s     \
    \             | Local<br>storag<br>e on<br>Jetson<br>devic<br>e |\n| 4       \
    \        | Residen<br>tial<br>Area D  | PM2.<br>5,<br>CO2,<br>NOx | PM2.5,<br>CO2,<br>NOx\
    \         | NVIDI<br>A<br>Jetson             | Every<br>5<br>minute<br>s     \
    \             | Local<br>storag<br>e on<br>Jetson<br>devic<br>e |\n| 5       \
    \        | Industri<br>al Zone<br>E   | PM2.<br>5,<br>CO2,<br>NOx | PM2.5,<br>CO2,<br>NOx\
    \         | NVIDI<br>A<br>Jetson             | Every<br>5                    \
    \             | Local<br>storag<br>e on<br>Jetson               |\n\nTABLE I.\
    \ DATA COLLECTION SETUP\n\nProceedings of the 8th International Conference on\
    \ Electronics, Communication and Aerospace Technology (ICECA 2024) IEEE Xplore\
    \ Part Number: CFP24J88-ART; ISBN: 979-8-3503-6790-4\n\n|    |               \
    \             |                           |                       |          \
    \            | minute<br>s               | devic<br>e                        \
    \              |\n|----|----------------------------|---------------------------|-----------------------|----------------------|---------------------------|-------------------------------------------------|\n\
    | …  | ….                         | ….                        | ….           \
    \         | ….                   | ….                        | ….            \
    \                                  |\n| 50 | Traffic<br>Heavy<br>Area Z | PM2.<br>5,<br>CO2,<br>NOx\
    \ | PM2.5,<br>CO2,<br>NOx | NVIDI<br>A<br>Jetson | Every<br>5<br>minute<br>s |\
    \ Local<br>storag<br>e on<br>Jetson<br>devic<br>e |\n\n*C.* Data processing and\
    \ analysis:\n\nData processing and analysis are carried out locally at each sensor\
    \ site utilizing Edge AI techniques. This decentralization is critical for lowering\
    \ latency and bandwidth use. The Edge AI devices evaluate the collected data using\
    \ powerful machine learning models such as Convolutional Neural Networks (CNNs)\
    \ and Recurrent Neural Networks (RNNs). Convolutional Neural Networks (CNNs) are\
    \ used in the system for feature extraction, which efficiently detects spatial\
    \ patterns in air quality data related to pollution dispersion. CNN layers are\
    \ made up of convolutional layers that apply filters to input data to detect features\
    \ and pooling layers, which minimize spatial dimensions while keeping critical\
    \ information. These layers contribute to the extraction and refinement of features\
    \ for tasks such as image recognition. Recurrent Neural Networks (RNNs) add to\
    \ this by evaluating temporal patterns, capturing trends and periodic variations\
    \ in pollutant levels. RNN has 3 layers. The input layer receives the information\
    \ to process, and the output layer provides the result. Data processing, analysis,\
    \ and prediction take place in the hidden layer. The combination of CNNs and RNNs\
    \ enables accurate detection and prediction of pollutant concentrations, allowing\
    \ for prompt public health actions based on real-time air quality data as shown\
    \ in Fig.3.\n\n![](_page_2_Figure_4.jpeg)\n\nFig. 3. CNN and RNN model\n\n####\
    \ *D. Decentralized Data Processing*\n\nThis system uses of decentralized data\
    \ processing. Unlike traditional centralized systems, which send data to a cloud\
    \ server for processing, Edge AI devices process data locally [21].\n\nLatency\
    \ Reduction: By processing data on-site, the system reduces the latency associated\
    \ with transmitting data to a central server and waiting for a response. Latency\
    \ can be reduced by processing data locally at each sensor site using Edge AI\
    \ devices, which eliminates the need to transmit data to a central server and\
    \ wait for a response. The reduced latency can be mathematically represented as\
    \ follows:\n\nIn a centralized system:\n\n$$\nT_{\\text{Central}} = T_{\\text{Transmit}}\
    \ + T_{\\text{Process}} + T_{\\text{Return}} \\tag{1}\n$$\n\nIn a decentralized\
    \ (edge computing) system:\n\n$$\nT_{Edge} = T_{Process\\_local}\n$$\n (2)\n\n\
    Since data is processed on-site:\n\n$$\nT_{Edge} \\ll T_{Central} \\tag{3}\n$$\n\
    \nThe reduction in latency, ΔT, can be expressed as:\n\n$$\n\\Delta T = T_{\\\
    text{Central}} - T_{\\text{Edge}} \\tag{4}\n$$\n\nTCentral Total latency in a\
    \ centralized system TTransmitTime taken to transmit data to the central server,\
    \ TProcessTime taken to process data at the central server TReturnTime taken to\
    \ return the processed data to the edge device. This equation shows how local\
    \ processing (using edge computing) significantly reduces latency by eliminating\
    \ the transmission and return times associated with centralized processing.\n\n\
    Bandwidth Efficiency: Decentralized processing improves bandwidth efficiency by\
    \ reducing the amount of raw data that needs to be transferred over the network.\
    \ In a classic centralized system, raw sensor data must be transferred to a central\
    \ server for processing, which requires a large amount of bandwidth. In a centralized\
    \ system:\n\n$$\nB_{\\text{Central}} \\propto D_{\\text{raw}} \\tag{5}\n$$\n\n\
    In a decentralized (edge computing) system:\n\n$$\nB_{Edge} \\propto D_{Proceed}\
    \ \\tag{6}\n$$\n\nThe reduction in bandwidth usage, ΔB, can be calculated as:\n\
    \n$$\n\\Delta B = B_{\\text{Central}} - B_{\\text{Edge}} \\tag{7}\n$$\n\nBCentralBandwidth\
    \ usage in a centralized system, DrawAmount of raw data transmitted to the central\
    \ server, BEdgeBandwidth usage in a decentralized system, DProcessed Amount of\
    \ processed data transmitted from the edge.\n\n#### *E. Federated Learning:*\n\
    \n Federated learning is used in this study to improve machine learning model\
    \ accuracy while protecting data privacy. In this technique, each Edge AI device\
    \ changes its model locally with the data it collects, rather than transmitting\
    \ the raw data to a central server. These local model updates are then combined\
    \ across all devices to improve the global model. This decentralized strategy\
    \ assures that machine learning models are constantly improving based on different,\
    \ location-specific data while protecting privacy and avoiding the need for significant\
    \ data transmission as shown in Fig.4. Over time, federated learning improves\
    \ the accuracy and robustness of air quality monitoring prediction\n\n![](_page_3_Figure_1.jpeg)\n\
    \nFig. 4. Federated learning model\n\n# *F. Experimental Setup:*\n\nThe technology\
    \ was implemented in 50 urban areas with varying levels of pollution. Each area\
    \ was outfitted with air quality sensors and an NVIDIA Jetson device. To collect\
    \ a wide spectrum of pollutant data, deployment sites included residential neighborhoods,\
    \ industrial zones, and heavily trafficked places. Data Collection period: Data\
    \ was collected consistently over six months, resulting in a comprehensive dataset\
    \ for analysis and model training. The performance of the proposed system was\
    \ assessed using the following metrics latency refers to the amount of time it\
    \ takes to process and analyze data. Bandwidth Usage: The amount of data transferred\
    \ to and from edge devices. Model Accuracy: The correlation coefficient between\
    \ anticipated and observed pollution levels. Privacy: An assessment of data privacy\
    \ measures as shown in Fig.5.\n\n![](_page_3_Figure_5.jpeg)\n\nFig. 5. Illustrating\
    \ the experimental setup and performance metrics\n\n# *G. Evaluation and Validation***:**\n\
    \nTo evaluate the system's accuracy, pollution detection findings were compared\
    \ to readings from conventional reference monitors known for their high precision.\
    \ The validation procedure included statistical analysis to determine the correlation\
    \ between the system's readings and those of the reference monitors. The investigation\
    \ found a substantial association, with an average correlation coefficient of\
    \ 0.92 for all contaminants and locations. This high level of accuracy demonstrates\
    \ that the decentralized monitoring system can consistently reproduce the outcomes\
    \ of traditional, centralized systems while providing significant operational\
    \ benefits.\n\n# IV. RESULTS & DISCUSSION\n\nThis section summarizes the findings\
    \ from the evaluation of the decentralized air quality monitoring system. Latency,\
    \ bandwidth use, model accuracy, and data privacy are among the performance criteria\
    \ studied. The results show significant advantages over standard cloud-based systems,\
    \ emphasizing the efficiency and accuracy of the suggested technique. Detailed\
    \ comparisons and validations against common reference monitors are supplied to\
    \ back up these findings.\n\n#### *A. Latency:*\n\nThe proposed system achieved\
    \ a significant reduction in latency compared to traditional cloud-based systems.\
    \ The time taken for data processing and analysis was measured across all deployment\
    \ sites as shown in Table. II and Fig.6.\n\n|                         | TABLE\
    \ II.                  | LATENCY COMPARISON      |                  |  |\n|-------------------------|----------------------------|-------------------------|------------------|--|\n\
    | Location                | Traditional<br>System (ms) | Proposed<br>System (ms)\
    \ | Reduction<br>(%) |  |\n| Residential<br>Area A   | 250                   \
    \     | 60                      | 76               |  |\n| Industrial Area<br>B\
    \    | 300                        | 70                      | 77             \
    \  |  |\n| Traffic-Heavy<br>Area C | 280                        | 65         \
    \             | 77               |  |\n| Average                 | 277       \
    \                 | 65                      | 77               |  |\n\n![](_page_3_Figure_14.jpeg)\n\
    \nFig. 6. System performance comparison\n\nThe proposed system consistently reduced\
    \ latency by approximately 75%, demonstrating its efficiency in real-time data\
    \ processing.\n\n#### *B. Bandwidth Usage:*\n\nBandwidth utilization was tracked\
    \ to determine the system's efficiency. The amount of data sent to and from edge\
    \ devices was greatly reduced as shown in Table. III and Fig.7.\n\n| TABLE III.\
    \              |                            | BANDWIDTH USAGE COMPARISON |   \
    \               |  |\n|-------------------------|----------------------------|----------------------------|------------------|--|\n\
    | Location                | Traditional<br>System (ms) | Proposed<br>System (ms)\
    \    | Reduction<br>(%) |  |\n| Residential<br>Area A   | 20                 \
    \        | 8                          | 60               |  |\n| Industrial Area<br>B\
    \    | 25                         | 10                         | 59          \
    \     |  |\n| Traffic-Heavy<br>Area C | 22                         | 9       \
    \                   | 60               |  |\n| Average                 | 22.3\
    \                       | 9                          | 60               |  |\n\
    \n![](_page_4_Figure_1.jpeg)\n\nFig. 7. Bandwidth usage comparison\n\nThe system\
    \ reduced bandwidth usage by 60%, minimizing operational costs and enhancing scalability.\n\
    \n# *C. Model Accuracy:*\n\nThe accuracy of the machine learning models was determined\
    \ by comparing anticipated pollution levels to actual levels observed by established\
    \ reference monitors. The correlation coefficient was utilized as the metric of\
    \ accuracy as shown in Table. IV and Fig.8.\n\nTABLE IV. Model Accuracy\n\n| Pollutant\
    \ | Correlation Coefficient |\n|-----------|-------------------------|\n| PM2.5\
    \     | 0.93                    |\n| CO2       | 0.91                    |\n|\
    \ NOx       | 0.92                    |\n| Average   | 0.92                  \
    \  |\n\n![](_page_4_Figure_8.jpeg)\n\nFig. 8. Model Accuracy\n\nThe average correlation\
    \ coefficient of 0.92 indicates high accuracy of the models in predicting air\
    \ quality levels. High accuracy can be achieved by continuously improving the\
    \ machine learning models through federated learning, which updates models locally\
    \ based on site-specific data, and by incorporating diverse pollutants and more\
    \ extensive datasets for training.\n\n#### *D. Federated Learning Model Accuracy\
    \ Improvement:*\n\nThe Table. V presents the incremental improvements in the accuracy\
    \ of the machine learning models used in the decentralized air quality monitoring\
    \ system as shown in Fig.9.\n\n| TABLE V.    | FEDERATED     | LEARNING<br>MODEL\
    \ | ACCURACY |\n|-------------|---------------|-------------------|----------|\n\
    | IMPROVEMENT |               |                   |          |\n|            \
    \ | Time          | Model             |          |\n|             | Period(Month)\
    \ | Accuracy          |          |\n|             |               | Improvement\
    \       |          |\n|             | 1             | 2.5               |    \
    \      |\n|             | 2             | 5.0               |          |\n|  \
    \           | 3             | 7.5               |          |\n|             |\
    \ 4             | 10.0              |          |\n|             | 5          \
    \   | 12.5              |          |\n|             | 6             | 15.0   \
    \           |          |\n|             |               |                   |\
    \          |\n|             |               |                   |          |\n\
    |             |               |                   |          |\n\n![](_page_4_Figure_14.jpeg)\n\
    \nThe graph depicts a steady increase in model accuracy, starting at 2.5% in the\
    \ first month and reaching 15% by the sixth month.\n\n#### *E. Privacy:*\n\nData\
    \ privacy was evaluated based on the system's ability to process data locally\
    \ rather than transmit raw data to centralized servers. This ensured that sensitive\
    \ data stayed protected as shown in Table.6.\n\n| Metric             | Traditional\
    \ System | Proposed System |\n|--------------------|--------------------|-----------------|\n\
    | Data Privacy Level | Low                | High            |\n| Raw Data    \
    \       | Yes                | No              |\n| Transmission       |     \
    \               |                 |\n| Federated Learning | No               \
    \  | Yes             |\n| Use                |                    |          \
    \       |\n\nTABLE VI. PRIVACY ASSESSMENT\n\nThe use of federated learning in\
    \ the proposed system ensured high levels of data privacy by keeping raw data\
    \ on local devices. These findings highlight the potential of decentralized systems\
    \ for efficient, accurate, and privacypreserving air quality monitoring in urban\
    \ environments.\n\n#### V. DISCUSSION\n\nThe findings of this study show substantial\
    \ gains in decentralized air quality monitoring using Edge AI and federated learning.\
    \ In comparison to traditional cloud-based systems, the proposed approach reduced\
    \ latency by 75% and bandwidth utilization by 60%. These enhancements demonstrate\
    \ the system's effectiveness and ability to give real-time air quality data with\
    \ minimum delays and operational costs. Model accuracy was high, with an average\
    \ correlation coefficient of 0.92 across contaminants (PM2.5, CO2, and NOx), demonstrating\
    \ the efficiency of the machine learning models used. The use of federated learning\
    \ guaranteed that raw data remained on local devices, thereby improving data privacy—a\
    \ vital factor typically ignored in conventional systems. This strategy solves\
    \ privacy concerns while also ensuring continual model improvement through local\
    \ updates and global model aggregation. Reliability can be achieved by deploying\
    \ the system across diverse locations with varying pollution levels, continuously\
    \ updating the machine learning models through federated learning, and validating\
    \ the results against reference monitors to ensure consistent performance. Precision\
    \ can be improved by incorporating more advanced machine learning models, using\
    \ larger and more diverse datasets for training, and refining the feature extraction\
    \ process through techniques like hyperparameter tuning and cross-validation.\n\
    \n#### VI. CONCLUSION\n\nThis research introduces a novel decentralized air quality\
    \ monitoring system that uses Edge AI and federated learning to overcome the constraints\
    \ of standard cloud-based systems. The key findings are large reductions in latency\
    \ (75%) and bandwidth utilization (60%), as well as strong model accuracy (average\
    \ correlation coefficient of 0.92). These enhancements highlight the system's\
    \ ability to provide realtime, accurate air quality data while reducing operational\
    \ expenses and maintaining data privacy. The integration of NVIDIA Jetson devices\
    \ for local data processing, as well as the usage of powerful machine learning\
    \ models like as CNNs and RNNs, all contribute to the system's outstanding performance.\
    \ Federated learning improves privacy by storing raw data on local devices and\
    \ constantly increasing model accuracy via local updates and global model aggregation.\
    \ However, this study had certain drawbacks. The deployment was confined to 50\
    \ urban areas, and the system was tested on a predetermined set of contaminants.\
    \ Future research should look into increasing the deployment to a wider range\
    \ of places, including rural areas, and incorporating more contaminants for more\
    \ comprehensive monitoring. Optimizing the federated learning framework to handle\
    \ more frequent updates and larger datasets may also enhance system performance.\
    \ Overall, this research indicates the ability of decentralized air quality monitoring\
    \ systems to deliver efficient, accurate, and privacy-preserving solutions critical\
    \ to public health and environmental protection in urban areas.\n\n# REFERENCES\n\
    \n- [1] Dominici, Francesca, Roger D. Peng, Christopher D. Barr, and Michelle\
    \ L. Bell. \"Protecting human health from air pollution: shifting from a single-pollutant\
    \ to a multipollutant approach.\" *Epidemiology* 21, no. 2 (2010): 187-194.\n\
    - [2] Devarakonda, Srinivas, Parveen Sevusu, Hongzhang Liu, Ruilin Liu, Liviu\
    \ Iftode, and Badri Nath. \"Real-time air quality monitoring through mobile sensing\
    \ in metropolitan areas.\" In *Proceedings of the 2nd ACM SIGKDD international\
    \ workshop on urban computing*, pp. 1-8. 2013.\n- [3] Mrissa, Michael, Aleksandar\
    \ Tošić, Niki Hrovatin, Sidra Aslam, Balázs Dávid, László Hajdu, Miklós Krész,\
    \ Andrej Brodnik, and Branko Kavšek. \"Privacy-aware and secure decentralized\
    \ air quality monitoring.\" *Applied sciences* 12, no. 4 (2022): 2147.\n- [4]\
    \ Bourechak, Amira, Ouarda Zedadra, Mohamed Nadjib Kouahla, Antonio Guerrieri,\
    \ Hamid Seridi, and Giancarlo Fortino. \"At the confluence of artificial intelligence\
    \ and edge computing in iot-based applications: A review and new perspectives.\"\
    \ *Sensors* 23, no. 3 (2023): 1639.\n- [5] Cui, Bowen, Minyi Liu, Shanqiang Li,\
    \ Zhifan Jin, Yu Zeng, and Xiaoying Lin. \"Deep learning methods for atmospheric\
    \ PM2. 5 prediction: A comparative study of transformer and CNN-LSTMattention.\"\
    \ *Atmospheric Pollution Research* 14, no. 9 (2023): 101833.\n\n[6] Raparthy,\
    \ Mohan, and Babu Dodda. \"Predictive Maintenance in IoT Devices Using Time Series\
    \ Analysis and Deep Learning.\" *Dandao Xuebao/Journal of Ballistics* 35: 01-10."
  decisions:
    evaluation_prompt: 'Qualified. Reason: The abstract mentions that the pollutant
      detection accuracy was evaluated against conventional reference monitors and
      provides specific metrics, such as an average correlation coefficient of 0.92,
      indicating structured evaluation. Additionally, it discusses the implementation
      of the system across 50 urban sites, which implies empirical evaluation.'
    related_work_prompt: 'Qualified. Reason: The introduction references prior research
      on traditional centralized air quality monitoring systems and discusses the
      limitations of these systems, indicating engagement with existing work. It also
      mentions recent advances in IoT and AI, suggesting a comparison with earlier
      methods. Additionally, the abstract highlights the use of machine learning models
      and compares the proposed approach''s performance with conventional reference
      monitors, further demonstrating engagement with prior research.'
    novelty_prompt: '- Qualified. Reason: The paper proposes a novel decentralized
      methodology for air quality monitoring that utilizes Edge AI and advanced machine
      learning techniques, explicitly stating its contributions in both the abstract
      and introduction.'
    review_only_prompt: '- Qualified. Reason: The paper proposes a novel decentralized
      approach to air quality monitoring using Edge AI and machine learning techniques,
      detailing new methods and improvements in latency, bandwidth, and accuracy,
      rather than summarizing existing work.'
  llm_input_used: '## Abstract

    Real-time air quality monitoring is essential for public health and environmental
    protection, but typical centralized systems have latency, bandwidth, and privacy
    concerns. This work describes a novel approach to decentralized air quality monitoring
    that employs Edge AI and powerful machine learning techniques. IoT sensors outfitted
    with NVIDIA Jetson devices collect and evaluate air quality data locally. Machine
    learning models, such as Convolutional Neural Networks (CNNs) and Recurrent Neural
    Networks (RNNs), analyze pollutants including PM2.5, CO2, and NOx in real time.
    Implemented across 50 urban sites with varied pollution levels, the technology
    reduced latency by up to 75% and bandwidth use by 60% when compared to typical
    cloud-based solutions. The pollutant detection accuracy was evaluated against
    conventional reference monitors and yielded an average correlation coefficient
    of 0.92. This system also used federated learning to update models based on local
    data, improving model accuracy by up to 15% over six months. This new strategy
    not only increases data processing speed and accuracy, but also protects data
    privacy and lowers operational costs. Significant improvements in latency, bandwidth
    efficiency, and model accuracy demonstrate the utility of decentralized air quality
    monitoring systems in urban settings.**


    ## Introduction

    Air quality monitoring is critical for protecting human health and the environment,
    particularly in metropolitan areas where pollution levels can change dramatically
    [1]. Traditional centralized air quality monitoring systems, while effective,
    are frequently hampered by factors like as latency, excessive bandwidth use, and
    potential privacy concerns. These restrictions can cause delays in essential decisionmaking
    and inefficiencies in data processing and analysis. Recent advances in IoT and
    AI have sparked renewed interest in decentralized air quality monitoring. Research
    has focused on employing IoT sensors for localized data collecting in order to
    reduce latency and bandwidth requirements. The use of artificial intelligence,
    particularly machine learning, has showed promise in improving the accuracy and
    speed of air quality analysis. However, many systems continue to rely on centralized
    processing, limiting their real-time capabilities. Furthermore, data privacy and
    scalability issues exist, limiting the widespread adoption of these decentralized
    techniques in real applications. The role of AI in this system is to enhance real-time
    air quality monitoring by utilizing machine learning models, such as Convolutional
    Neural Networks (CNNs) and Recurrent Neural Networks (RNNs), for accurate pollutant
    detection, while Edge AI reduces latency and bandwidth consumption. This research
    proposes a novel decentralized methodology to overcome the constraints of existing
    air quality monitoring methods. This research intends to use Edge AI and advanced
    machine learning techniques to address latency, bandwidth consumption, and data
    privacy issues. This project focuses on deploying IoT sensors integrated with
    NVIDIA Jetson devices to gather and interpret local air quality data. This system
    uses machine learning models such as Convolutional Neural Networks (CNNs) and
    Recurrent Neural Networks (RNNs) to analyze pollutants in real time, including
    PM2.5, CO2, and NOx. The challenge, thus, revolves around improving the efficiency,
    accuracy, and privacy of air quality monitoring via a decentralized approach.'
  token_usage: 3554
  time_usage: 4.595111608505249
- title: Enhancing the Fairness and Performance of Edge Cameras with Explainable AI
  abstract: The rising use of Artificial Intelligence (AI) in human detection on Edge
    camera systems has led to accurate but complex models, challenging to interpret
    and debug. Our research presents a diagnostic method using XAI for model debugging,
    with expert-driven problem identification and solution creation. Validated on
    the Bytetrack model in a real-world office Edge network, we found the training
    dataset as the main bias source and suggested model augmentation as a solution.
    Our approach helps identify model biases, essential for achieving fair and trustworthy
    models.
  keywords: Explainable AI, Edge Camera
  document: '# Enhancing the Fairness and Performance of Edge Cameras with Explainable
    AI


    Truong Thanh Hung Nguyen†‡, Vo Thanh Khang Nguyen‡ , Quoc Hung Cao‡ ,


    Van Binh Truong‡ , Quoc Khanh Nguyen‡ , Hung Cao†


    ‡Quy Nhon AI, FPT Software, Vietnam †Analytics Everywhere Lab, University of New
    Brunswick, Canada


    Email: {hungntt, khangnvt1, hungcq3, binhtv8, khanhnq33}@fpt.com, hcao3@unb.ca


    *Abstract*—The rising use of Artificial Intelligence (AI) in human detection on
    Edge camera systems has led to accurate but complex models, challenging to interpret
    and debug. Our research presents a diagnostic method using XAI for model debugging,
    with expert-driven problem identification and solution creation. Validated on
    the Bytetrack model in a real-world office Edge network, we found the training
    dataset as the main bias source and suggested model augmentation as a solution.
    Our approach helps identify model biases, essential for achieving fair and trustworthy
    models.


    *Index Terms*—Explainable AI, Edge Camera


    #### I. INTRODUCTION


    Human detection through security cameras, a pivotal AI task, employs AI models
    like YOLO and its YOLOX variant for alerts, such as falls and intrusions. Specifically,
    Bytetrack, based on YOLOX, excels in multi-object tracking [1], [2]. Yet, it struggles
    in detecting obscured or disabled individuals (Fig. 1a, Fig. 1b). Given their
    black-box nature, these models pose debugging challenges. Though XAI aids debugging
    in tabular and text data [3], its use in image data is less explored. Hence, our
    paper introduces an XAI-driven framework to debug human detection models in security
    cameras. The approach leverages experts for diagnosing problems and proposing
    solutions, with potential wider relevance to object detection and classification.


    ![](_page_0_Picture_10.jpeg)


    Fig. 1. (a) A security camera on the ceiling of an office can detect ordinary
    people (green boxes), but not people who cover their bodies with a cloth. (b)
    The Bytetrack model cannot detect the disabled woman but still detect the other,
    who is not disabled.


    #### II. RELATED WORK


    #### *A. Human Detection*


    Human detection identifies humans in images or videos and has evolved with various
    methods. Deep Learning (DL) brought forward models that address challenges like
    object size and illumination differences. Capitalizing on YOLOX''s [1] success,
    Bytetrack [2] was designed for human detection, leveraging YOLOX for detection
    and Byte for postprocessing.


    #### *B. Explainable AI*


    AI''s integration into real-world scenarios has led to multiple Explainable AI
    (XAI) strategies: perturbation-based, backpropagation-based, and example-based.
    Perturbation techniques, such as D-RISE [4], which work independently of model
    design, perturb input images, then analyze predictions to gauge pixel or superpixel
    influence on outcomes. While widely applicable, their computational demand can
    be limiting. Backpropagation methods delve into model architecture to fetch explanatory
    data. Recognized techniques include Grad-CAM [5], SeCAM [6]. Example-based methods,
    like Influence Function [7], explain using training data samples to ascertain
    their effects on predictions. While XAI''s application to object detection is
    complex due to the intricate models, some methods, such as D-RISE [4], D-CLOSE
    [8], and G-CAME [9], are adaptations from classification for object detection.


    #### *C. Debugging Model Framework with XAI*


    Many studies utilize XAI methods [10], primarily answering, *"Why does the model
    predict this?"* Yet, the follow-up, *"How can explanations improve the model?"*
    requires using XAI to better the AI system. No research has yet outlined a framework
    for debugging human detection models. This paper, therefore, introduces such a
    framework, leveraging XAI to pinpoint issues and improve model fairness and efficacy.


    #### III. METHODOLOGY


    We present a structured debugging model framework shown in Fig. 2, with seven
    sequential stages. Each stage relies on the results of its predecessor. Where
    multiple methods or assumptions exist per stage, we offer strategy selection guidelines.
    In this framework, XAI aids experts in identifying core model issues and suggesting
    performance-enhancing solutions.


    #### *A. Data Selection and Extraction of Predictions*


    Our framework starts by selecting a training dataset subset for model enhancement,
    addressing potential dataset concerns. Public datasets like CrowdHuman [11], used
    in Bytetrack training, can face data poisoning [12], affecting data quality and
    model results. Error detection in the model or dataset is optimized using random
    testing [13], which randomly picks


    ![](_page_1_Figure_0.jpeg)


    Fig. 2. The Debugging Framework for Human Detection Models


    data for testing, spotting major flaws without full dataset checks. Based on the
    idea that small samples can be indicative, we use statistical sampling heuristics
    to set an optimal sample size, which should not surpass 10% of the full dataset
    or 1000 samples, ensuring a meaningful and efficient subset [14]. After selecting
    the data subset, it''s fed into the model to generate predictions. These are then
    analyzed against the ground truth, helping gauge model metrics like accuracy,
    precision, and areas needing enhancement.


    #### *B. Statistical Analysis of Prediction Results*


    After obtaining predictions, they are categorized by comparing them with the ground-truth.
    This classification is guided by experts and, in our human detection context,
    results in four categories. Initially, dataset categorization relies on whether
    the model''s predicted count aligns with the ground truth. Images are labeled
    as "Under-detection" if the model detects fewer people, and "Over-detection" if
    it detects more. If the model''s count matches the ground truth, detection quality
    is evaluated by comparing model-detected boxes with ground truth boxes using Intersection
    over Union (IoU) values. Images with all box pairs having IoU ≥ 0.5 are deemed
    "Correct Localization", while others are "Mislocalization".


    This process organizes the dataset based on prediction results, with three categories
    signaling potential model enhancements. The next stage delves deeper into error
    sources, laying the groundwork to boost the model''s precision in detecting people
    within images.


    #### *C. Explanation Generation*


    In this phase, we use XAI methods to explain each image category. Given that D-RISE
    [4] is adaptable to diverse models without needing their architecture details
    and offers explanations for ground truth boxes (enabling comparison with modeldetected
    boxes), we opt for D-RISE in human detection. These explanations assist experts
    in identifying the root of incorrect predictions in the following stage.


    #### *D. Problem Identification*


    Using the XAI results from the prior phase, experts analyze each category presented
    in the statistical analysis (Sec. III-B). The XAI indicates the model''s focal
    regions on the input image. Experts assess these areas for relevance and potential
    biases. By comparing these regions across images in the same category, common
    patterns are identified. These patterns are then cross-referenced with other categories
    to spot shared features. Additionally, we compare XAI results across various models
    to further address potential challenges.


    #### *E. Solution Proposal*


    The solution proposal phase is important for enhancing model performance. Once
    the issue is identified, experts review the dataset and model to identify potential
    causes like data distribution, labels, biases, or model design. Solutions may
    involve tweaking model parameters, refining training data, or enhancing the training
    procedure.


    #### *F. Solution Assessment*


    Rather than implementing all possible solutions, we shall assess the feasibility
    of proposed solutions on a small dataset initially. We evaluate the advantages
    and disadvantages of each solution, drawing from prior case studies to assess
    their relevance to the present problem. The infeasible solutions can be identified
    and eliminated, thereby allowing for the selection of the most suitable solution.


    #### *G. Model Enhancement*


    After implementing the effective solution identified earlier, we refine the model
    to address issues highlighted in Sec. III-D. We then assess the model''s enhancement
    by contrasting its performance pre and post-refinement, specifically comparing
    predictive metrics on initially selected images. Additionally, we might test using
    cases the original model struggled with to validate the model''s enhanced capability
    in tackling the pinpointed issue.


    ### IV. EXPERIMENT


    In our study, we detail each step as illustrated in Fig. 2. We experiment using
    the Bytetrack model pre-trained on datasets like MOT17 [15], Cityperson [16],
    ETHZ [17], and CrowdHuman [11].


    #### *A. Data Selection and Prediction Extraction*


    Our training dataset amalgamates four public datasets [11], [15]–[17]. We use
    CrowdHuman for our tests, divided into training (15000 images), validation (4370
    images), and testing (5000 images) sets. These sets, with a combined 470K human
    instances, offer varied bounding box annotations. We choose a random 1000-image
    subset from CrowdHuman''s training set for extracting model predictions, as outlined
    in Sec. III-A.


    #### *B. Analyzing Prediction Results*


    Here, we match predicted boxes with the ground truth. "Under-detection" is the
    predominant issue, constituting 85.5%. While, "Under-detection" accounts for 17%,
    "Overdetection" accounts for 10.8%, and "Mislocalization" accounts for 20%.


    ![](_page_2_Figure_0.jpeg)


    Fig. 3. Examples of XAI Explanations with Bytetrack and YOLOX model. In which,
    each image in the second column is the XAI Explanations for a corresponding box.


    #### *C. Explanation Generation*


    The Bytetrack model is a composite of YOLOX, responsible for detection, and the
    Byte phase that processes these detections. YOLOX is vital as the subsequent Byte
    step relies on its outputs. Byte''s role is to maintain low-score predictions
    possibly hidden by other items [2]. We use D-RISE to interpret YOLOX, referencing
    the final box coordinates from Bytetrack [18]. Additionally, comparing Bytetrack
    and YOLOX using D-RISE on YOLOX''s weights aids in identifying differences, showcased
    in Fig. 3 [1].


    #### *D. Problem Identification*


    The XAI explanations in Fig. 3 indicate Bytetrack''s focus on entire human bodies,
    exposing its struggle to detect individuals showing only their heads. Experiments
    with images of people in wheelchairs, where bodies are partly concealed, amplify
    this limitation, with the model overlooking them as seen in Fig. 1b. Similar misses
    happen with people hidden behind objects, highlighted in Fig. 1a. Hence, Bytetrack''s
    challenge in spotting partially visible humans emerges as a key concern needing
    attention and resolution.


    ## *E. Solution Proposal*


    ![](_page_2_Picture_7.jpeg)


    Fig. 4. Predictions of the Bytetrack model before and after fine-tuning. We pinpointed
    specific issues and proposed assumptions accordingly:


    • Dataset: On average, images have 23 people, making heads smaller than bodies,
    potentially leading to a body bias. We also suspect label issues with ground truth
    box coordinates outside the image, shown in Fig. 3 and Table II.


    • Model: Bytetrack tries to resolve occluded objects [2]. For head-only images,
    Bytetrack expects an associated body.


    TABLE I GROUND TRUTH BOXES'' COORDINATE OF THE INPUT IMAGE IN THE FIRST ROW OF
    FIG. 3, WHERE 7/8 BOXES ARE OUTSIDE THE IMAGE.


    | Left          | -50 | -12  | 308  | 499  | 618  | 608 | 318 | 303 |

    |---------------|-----|------|------|------|------|-----|-----|-----|

    | Top           | 35  | 87   | 292  | 171  | 370  | 61  | -14 | -3  |

    | Right         | 531 | 451  | 635  | 988  | 1034 | 758 | 673 | 444 |

    | Bottom        | 131 | 1325 | 1228 | 1201 | 1243 | 444 | 745 | 437 |

    | Outside image | ×   | ×    | ×    | ×    | ×    |     | ×   | ×   |


    Proposed solutions include:


    - Data enrichment: Add images with mostly obscured body sections.

    - Data blurring: Based on XAI findings, blur bodies to make the model focus on
    heads.

    - Padding: Ensure bounding boxes are fully within images.

    - Relabeling: Adjust bounding boxes to remain inside the image.


    #### *F. Solution Assessment*


    We conduct a comprehensive analysis to identify and implement the most suitable
    solution to the problem. Each solution is evaluated as follows:


    - Data enrichment: The current dataset already has partly hidden figures, so more
    data might not help much.

    - Data blurring: Effective for image classification, but might not suit human
    detection where only humans are predicted.

    - Padding: While sometimes effective, as in Fig. 5, it often fails, especially
    when objects obstruct people.

    - Relabeling: Given dataset inconsistencies and variant model features, relabeling
    seems promising.


    Following this analysis, relabeling emerges as the most impactful solution.


    ![](_page_2_Picture_26.jpeg)


    Fig. 5. Example of padding result. (Top, Left, Right, Bottom) = (100, 200, 200,
    200) signifies padding of 100, 200, 200, and 200 pixels respectively on the top,
    left, right, and bottom.


    #### *G. Model and Dataset Enhancement*


    The CrowdHuman dataset is reannotated by constraining bounding box coordinates
    within the image dimensions, as delineated by x ′ top, left = max(0, xtop, left),
    y ′ top, left = max(0, ytop, left), x ′ bottom, right = min(w, xbottom, right),


    ![](_page_3_Figure_0.jpeg)


    Fig. 6. Model''s prediction on physically disabled person images. After finetuning,
    the model performs better than the original pre-trained model.


    ![](_page_3_Figure_2.jpeg)


    Fig. 7. Model''s prediction on a security camera. The fine-tuned model performs
    better than the original pre-trained model detecting covered people.


    y ′ bottom, right = min(h, ybottom, right). Here, w, h represents the image''s
    width and height, respectively. The coordinates (x ′ top, left, y ′ top, left)
    and (x ′ bottom, right, y ′ bottom, right) denote the adjusted top-left and bottom-right
    points, respectively. Subsequent model refinement occurs over 10 epochs, with
    performance enhancement evaluated in three scenarios:


    - Training Dataset Testing: We test a 1000-image subset after refining the model.
    Both quantitative and qualitative evaluations are made against the original model,
    as seen in Table II and Fig. 4. The updated model better localizes in 855 "Under-detection"
    images, improving by 21 cases.

    - Images of Disabled Individuals: The adjusted model shows better detection in
    images featuring physically disabled people, highlighted in Fig. 6.

    - Detection in Surveillance Footage: We assess the model in real-life contexts,
    like office security footage where people might be partly hidden. Post-refinement
    performance, showcasing improvements, is depicted in Fig. 7.


    | TABLE II                                                      |

    |---------------------------------------------------------------|

    | STATISTICAL RESULT PRE-TRAINED MODEL VERSUS FINE-TUNED MODEL. |

    | THE ARROW ↑/↓ INDICATES THE HIGHER/LOWER VALUE, THE BETTER.   |

    | THE BOLD INDICATES THE BETTER RESULT.                         |


    | Case                     | Pre-trained model | Fine-tuned model |

    |--------------------------|-------------------|------------------|

    | Under-detection (↓)      | 855               | 834              |

    | Over-detection (↓)       | 17                | 13               |

    | Correct Localization (↑) | 108               | 133              |

    | Mislocalization (↓)      | 20                | 20               |


    #### V. CONCLUSION AND FUTURE WORK


    This study introduces a human detection debugging framework using XAI aided by
    experts. Our approach pinpoints data labeling as a significant issue in Bytetrack''s
    biases and can adapt to other detection problems, especially those focusing on
    specific classes.


    #### REFERENCES


    - [1] Z. Ge, S. Liu, F. Wang, Z. Li, and J. Sun, "YOLOX: exceeding YOLO series
    in 2021," *CoRR*, vol. abs/2107.08430, 2021. [Online]. Available: https://arxiv.org/abs/2107.08430

    - [2] Y. Zhang, P. Sun, Y. Jiang, D. Yu, Z. Yuan, P. Luo, W. Liu, and X. Wang,
    "Bytetrack: Multi-object tracking by associating every detection box," *CoRR*,
    vol. abs/2110.06864, 2021. [Online]. Available: https://arxiv.org/abs/2110.06864

    - [3] R. Yousefzadeh and D. P. O''Leary, "Auditing and debugging deep learning
    models via decision boundaries: Individual-level and grouplevel analysis," *CoRR*,
    vol. abs/2001.00682, 2020. [Online]. Available: http://arxiv.org/abs/2001.00682

    - [4] V. Petsiuk, R. Jain, V. Manjunatha, V. I. Morariu, A. Mehra, V. Ordonez,
    and K. Saenko, "Black-box explanation of object detectors via saliency maps,"
    *CoRR*, vol. abs/2006.03204, 2020. [Online]. Available: https://arxiv.org/abs/2006.03204

    - [5] R. R. Selvaraju, A. Das, R. Vedantam, M. Cogswell, D. Parikh, and D. Batra,
    "Grad-cam: Why did you say that? visual explanations from deep networks via gradient-based
    localization," *CoRR*, vol. abs/1610.02391, 2016. [Online]. Available: http://arxiv.org/abs/1610.02391

    - [6] P. Nguyen, H. CAO, K. NGUYEN, H. NGUYEN, and T. YAIRI, "Secam: Tightly accelerate
    the image explanation via region-based segmentation," *IEICE Transactions on Information
    and Systems*, vol. E105.D, pp. 1401–1417, 08 2022.

    - [7] P. W. Koh and P. Liang, "Understanding black-box predictions via influence
    functions," 2017. [Online]. Available: https://arxiv.org/abs/1703.04730

    - [8] V. B. Truong, T. T. H. Nguyen, V. T. K. Nguyen, Q. K. Nguyen, and Q. H.
    Cao, "Towards better explanations for object detection," *arXiv preprint arXiv:2306.02744*,
    2023.

    - [9] Q. K. Nguyen, T. T. H. Nguyen, V. T. K. Nguyen, V. B. Truong, and Q. H.
    Cao, "G-came: Gaussian-class activation mapping explainer for object detectors,"
    *arXiv preprint arXiv:2306.03400*, 2023.

    - [10] T. T. H. Nguyen, V. B. Truong, V. T. K. Nguyen, Q. H. Cao, and Q. K. Nguyen,
    "Towards trust of explainable ai in thyroid nodule diagnosis," *arXiv preprint
    arXiv:2303.04731*, 2023.

    - [11] S. Shao, Z. Zhao, B. Li, T. Xiao, G. Yu, X. Zhang, and J. Sun, "Crowdhuman:
    A benchmark for detecting human in a crowd," *CoRR*, vol. abs/1805.00123, 2018.
    [Online]. Available: http://arxiv.org/abs/1805.00123

    - [12] R. S. S. Kumar, M. Nystrom, J. Lambert, A. Marshall, M. Goertzel, ¨ A.
    Comissoneru, M. Swann, and S. Xia, "Adversarial machine learning - industry perspectives,"
    *CoRR*, vol. abs/2002.05646, 2020. [Online]. Available: https://arxiv.org/abs/2002.05646

    - [13] J. Mayer and C. Schneckenburger, "An empirical analysis and comparison
    of random testing techniques," in *Proceedings of the 2006 ACM/IEEE international
    symposium on Empirical software engineering*, 2006, pp. 105–114.

    - [14] C. R. W. VanVoorhis and B. L. Morgan, "Understanding power and rules of
    thumb for determining sample sizes," 2007.

    - [15] A. Milan, L. Leal-Taixe, I. D. Reid, S. Roth, and K. Schindler, "MOT16:
    ´ A benchmark for multi-object tracking," *CoRR*, vol. abs/1603.00831, 2016. [Online].
    Available: http://arxiv.org/abs/1603.00831

    - [16] S. Zhang, R. Benenson, and B. Schiele, "Citypersons: A diverse dataset
    for pedestrian detection," *CoRR*, vol. abs/1702.05693, 2017. [Online]. Available:
    http://arxiv.org/abs/1702.05693

    - [17] A. Ess, B. Leibe, K. Schindler, and L. Van Gool, "A mobile vision system
    for robust multi-person tracking," in *2008 IEEE Conference on Computer Vision
    and Pattern Recognition*, 2008, pp. 1–8.

    - [18] V. Petsiuk, R. Jain, V. Manjunatha, V. I. Morariu, A. Mehra, V. Ordonez,
    and K. Saenko, "Black-box explanation of object detectors via saliency maps,"
    in *Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition*,
    2021, pp. 11 443–11 452.'
  decisions:
    evaluation_prompt: 'Qualified. Reason: The abstract mentions that the method was
      "validated on the Bytetrack model in a real-world office Edge network," indicating
      empirical evaluation. Additionally, it discusses identifying model biases and
      suggests model augmentation as a solution, which implies structured evaluation
      of the model''s performance.'
    related_work_prompt: '- Qualified. Reason: The introduction mentions specific
      AI models like YOLO and YOLOX, and discusses the Bytetrack model, referencing
      prior work through citations [1], [2], and [3]. It also compares the challenges
      faced by these models with existing approaches, indicating engagement with prior
      research.'
    novelty_prompt: 'Qualified. Reason: The paper introduces a new XAI-driven framework
      for debugging human detection models in security cameras, explicitly stating
      its contribution to the field.'
    review_only_prompt: '- Qualified. Reason: The paper proposes a diagnostic method
      using XAI for model debugging, introduces an XAI-driven framework, and discusses
      experiments validating the approach, indicating new contributions rather than
      merely summarizing existing work.'
  llm_input_used: '## Abstract

    The rising use of Artificial Intelligence (AI) in human detection on Edge camera
    systems has led to accurate but complex models, challenging to interpret and debug.
    Our research presents a diagnostic method using XAI for model debugging, with
    expert-driven problem identification and solution creation. Validated on the Bytetrack
    model in a real-world office Edge network, we found the training dataset as the
    main bias source and suggested model augmentation as a solution. Our approach
    helps identify model biases, essential for achieving fair and trustworthy models.


    ## Introduction

    Human detection through security cameras, a pivotal AI task, employs AI models
    like YOLO and its YOLOX variant for alerts, such as falls and intrusions. Specifically,
    Bytetrack, based on YOLOX, excels in multi-object tracking [1], [2]. Yet, it struggles
    in detecting obscured or disabled individuals (Fig. 1a, Fig. 1b). Given their
    black-box nature, these models pose debugging challenges. Though XAI aids debugging
    in tabular and text data [3], its use in image data is less explored. Hence, our
    paper introduces an XAI-driven framework to debug human detection models in security
    cameras. The approach leverages experts for diagnosing problems and proposing
    solutions, with potential wider relevance to object detection and classification.


    ![](_page_0_Picture_10.jpeg)


    Fig. 1. (a) A security camera on the ceiling of an office can detect ordinary
    people (green boxes), but not people who cover their bodies with a cloth. (b)
    The Bytetrack model cannot detect the disabled woman but still detect the other,
    who is not disabled.'
  token_usage: 2401
  time_usage: 4.750228643417358
- title: Recovering Trace Links Between Software Documentation And Code
  abstract: 'Introduction Software development involves creating various artifacts
    at different levels of abstraction and establishing relationships between them
    is essential. Traceability link recovery (TLR) automates this process, enhancing
    software quality by aiding tasks like maintenance and evolution. However, automating
    TLR is challenging due to semantic gaps resulting from different levels of abstraction.
    While automated TLR approaches exist for requirements and code, architecture documentation
    lacks tailored solutions, hindering the preservation of architecture knowledge
    and design decisions. Methods This paper presents our approach TransArC for TLR
    between architecture documentation and code, using componentbased architecture
    models as intermediate artifacts to bridge the semantic gap. We create transitive
    trace links by combining the existing approach ArDoCo for linking architecture
    documentation to models with our novel approach ArCoTL for linking architecture
    models to code.

    Results We evaluate our approaches with five open-source projects, comparing our
    results to baseline approaches. The model-to-code TLR approach achieves an average
    F1-score of 0.98, while the documentation-to-code TLR approach achieves a promising
    average F1-score of 0.82, significantly outperforming baselines.

    Conclusion Combining two specialized approaches with an intermediate artifact
    shows promise for bridging the semantic gap. In future research, we will explore
    further possibilities for such transitive approaches.'
  keywords: software traceability, software architecture, documentation, transitive
    links, intermediate artifacts, information retrieval
  document: '![](_page_0_Picture_1.jpeg)


    # Recovering Trace Links Between Software Documentation And Code


    Jan Keim jan.keim@kit.edu Karlsruhe Institute of Technology Karlsruhe, Germany


    Tobias Hey hey@kit.edu Karlsruhe Institute of Technology Karlsruhe, Germany


    Sophie Corallo sophie.corallo@kit.edu Karlsruhe Institute of Technology Karlsruhe,
    Germany


    Tobias Telge tobias.telge@alumni.kit.edu Karlsruhe Institute of Technology Karlsruhe,
    Germany


    Dominik Fuchß dominik.fuchss@kit.edu Karlsruhe Institute of Technology Karlsruhe,
    Germany


    Anne Koziolek koziolek@kit.edu Karlsruhe Institute of Technology Karlsruhe, Germany


    # KEYWORDS


    software traceability, software architecture, documentation, transitive links,
    intermediate artifacts, information retrieval


    #### ACM Reference Format:


    Jan Keim, Sophie Corallo, Dominik Fuchß, Tobias Hey, Tobias Telge, and Anne Koziolek.
    2024. Recovering Trace Links Between Software Documentation And Code. In 2024
    IEEE/ACM 46th International Conference on Software Engineering (ICSE ''24), April
    14–20, 2024, Lisbon, Portugal. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3597503.3639130


    ## 1 INTRODUCTION


    During software development, various artifacts are created. These artifacts are
    at different levels of abstraction and cover (partially) different aspects of
    a system. The problem is that the relationships between the artifacts are not
    always apparent and, thus, cannot be used. Making these relationships explicit
    improves software quality and simplifies processes. As such, software traceability
    is an important factor in successful software development. With traceability link
    recovery (TLR), software engineers can connect any uniquely identifiable software
    engineering artifacts by creating explicit trace links, maintain these trace links,
    and use the resulting network to gain knowledge about the software product and
    its development [8].


    Therefore, software quality can be improved by creating and maintaining trace
    links [55]. For example, in collaborative development, TLR can help engineers
    to keep all artifacts synchronized and consistent [51]. Furthermore, traceability
    supports numerous critical software engineering tasks (cf. [7]). For example,
    trace links can improve the efficiency of software maintenance [33, 39], bug localization
    [53], change impact analysis [10], and system security [44, 46]. Trace links are
    also used to demonstrate the safety of systems [38, 40, 45]. Some standards, such
    as ISO 26262 about the functional safety of road vehicles, even mandate traceability.


    Despite all the benefits, the main drawback of traceability is the time-consuming
    and error-prone process of manually creating and maintaining trace links [9, 52].
    This is mainly due to the semantic gap between artifacts of different abstraction
    levels [3], e.g., requirements and code. Some (semi-)automated approaches have
    been designed to assist users but face the same challenge.


    Likewise, automated TLR approaches often only look at requirements and code. However,
    other types of artifacts, such as the documentation of the system''s software
    architecture, are just as relevant. A software''s architecture is key to successfully
    developing,


    ## ABSTRACT


    Introduction Software development involves creating various artifacts at different
    levels of abstraction and establishing relationships between them is essential.
    Traceability link recovery (TLR) automates this process, enhancing software quality
    by aiding tasks like maintenance and evolution. However, automating TLR is challenging
    due to semantic gaps resulting from different levels of abstraction. While automated
    TLR approaches exist for requirements and code, architecture documentation lacks
    tailored solutions, hindering the preservation of architecture knowledge and design
    decisions. Methods This paper presents our approach TransArC for TLR between architecture
    documentation and code, using componentbased architecture models as intermediate
    artifacts to bridge the semantic gap. We create transitive trace links by combining
    the existing approach ArDoCo for linking architecture documentation to models
    with our novel approach ArCoTL for linking architecture models to code.


    Results We evaluate our approaches with five open-source projects, comparing our
    results to baseline approaches. The model-to-code TLR approach achieves an average
    F1-score of 0.98, while the documentation-to-code TLR approach achieves a promising
    average F1-score of 0.82, significantly outperforming baselines.


    Conclusion Combining two specialized approaches with an intermediate artifact
    shows promise for bridging the semantic gap. In future research, we will explore
    further possibilities for such transitive approaches.


    ### CCS CONCEPTS


    • Software and its engineering → Software design engineering; Documentation; Maintaining
    software; Software evolution; Software architectures; • Computing methodologies
    → Natural language processing; Information extraction.


    ![](_page_0_Picture_24.jpeg)


    ICSE ''24, April 14–20, 2024, Lisbon, Portugal © 2024 Copyright held by the owner/author(s).
    ACM ISBN 979-8-4007-0217-4/24/04. https://doi.org/10.1145/3597503.3639130 This
    work licensed under Creative Commons Attribution International 4.0 License.


    ![](_page_1_Figure_1.jpeg)


    Figure 1: Running example: System with software architecture documentation, software
    architecture model, and code<sup>1</sup> .


    maintaining, and evolving the system [41]. Software architecture documentation
    (SAD) preserves the knowledge about the architecture, such as the underlying design
    decisions. Documentation prevents rapid deterioration [50, 65] and enhances the
    benefits of a good software architecture. Using trace links to find relevant knowledge
    in SADs further enhances the utility of software architecture while improving
    the usability for developers and architects. Therefore, linking SADs to other
    software artifacts, such as other design artifacts or code, is beneficial on several
    levels.


    Because different types of artifacts cover different aspects and have different
    views on the system, these artifacts have different levels of abstraction, and,
    as such, there is a semantic gap between them [3]. Automated approaches have been
    developed to bridge this gap by capturing the underlying semantics. However, this
    task is inherently challenging, and such approaches are prone to misinterpretation,
    leading to potential imprecision. To overcome the semantic gap between source
    and target artifacts, some other approaches suggest using intermediate artifacts
    (cf. [2, 44, 47, 64]). The idea is that those intermediate artifacts have a smaller
    semantic gap to the artifacts, allowing for easier pairing. For example, design
    documentation is semantically closer to design artifacts like software architecture
    models (SAMs) than to code. At the same time, SAMs are also closer to code and
    serve as an intermediate artifact between SADs and SAMs. For those smaller semantic
    gaps, more specialized approaches show promising results (cf. [20, 25, 59]). Thus,
    our main idea is to chain trace links from multiple specialized approaches to
    recover trace links for intermediate artifacts and transitively combine the resulting
    links. For example, we can use one approach to recover links between SADs and
    SAMs, and another one to recover trace links between SAMs and code. We can then
    transitively combine the links to obtain trace links between SADs and code, bridging
    the semantic gap.


    Figure 1 depicts an example of SAD to SAM to code<sup>1</sup> . We observe two
    key components: the Controller on the left and the DataPersistence on the right.
    The SAD details their respective responsibilities and their structural relationship
    is visualized in the SAM. The code implementation introduces two essential packages,
    namely service and dataaccess, each of which includes sub-packages such as auth
    and preferences. The Controller class effectively employs the Authenticator to
    verify incoming requests. The classes Products and Users serve as repositories,
    leveraging information from hidden classes within the preferences package to establish
    connections with a database.


    In the example, elements that should be linked with trace links are marked with
    the same color. Consequently, both sentences, due to the references to the terms
    "controller" and "it", are associated with the Controller component and the classes
    within the service package. Similarly, the second sentence is linked to the DataPersistence
    component and the classes in the dataaccess package.


    The example highlights several challenges encountered during the creation of trace
    links. For instance, the description of the controller component is necessary
    to properly link it to the whole service package instead of only the Controller
    class. Another challenge is the changed naming of the "persistence" component
    in the SAD to dataaccess in the code. In such cases, using the DataPersistence
    component in the SAM can help to bridge the gap.


    This paper presents our novel approach using transitive links to recover trace
    links between SADs and code. To bridge the semantic gap between documentation
    and code, we use intermediate artifacts in the form of component-based SAMs that
    describe the structure of the system, such as UML component diagrams. The idea
    is to combine two specialized approaches to improve the results for the wider
    semantic gap between the original artifacts. More specifically, we concatenate
    an approach for linking SADs and SAMs with an approach for linking SAMs to code.
    To link SADs and SAMs, we use the existing Architecture Documentation Consistency
    (ArDoCo) approach by Keim et al. [25] as it is the state of the art for this problem.
    For linking SAMs and code, we present a new approach called ARchitecture-to-COde
    Trace Linking (ArCoTL). The ArCoTL approach uses several heuristics and aggregation
    methods that are concatenated in a graph to recover trace links. To be independent
    of input languages and to support different component-based architecture description
    languages and programming languages, the approach uses abstractions for code and
    architecture. The approach that transitively combines ArDoCo and ArCoTL to recover
    trace links between SADs and code is called Transitive links for Architecture
    and Code (TransArC) (see Figure 2).


    A drawback of our approach is the need for an additional type of artifact, the
    component-based SAMs. We argue that SAMs as artifacts serve additional purposes
    besides our TLR approach. Surveys with practitioners also indicate that a considerable
    fraction of practitioners already have SAMs: 86% of practitioners used UML as
    architecture description language in a study by Malavolta et al. [35] and 26.3%
    of practitioners used architecture modeling or visualization with UML in a study
    by Tian et al. [63]. In addition, there are approaches that (semi-) automatically
    recover SAMs from code


    <sup>1</sup> For readability reasons, we use an abstract representation of the
    code in this example instead of the actual source code our tool uses.


    ![](_page_2_Figure_1.jpeg)


    Figure 2: High-level view of the TransArC approach for linking SADs and code using
    ArDoCo [25] and our novel ArCoTL.


    and deployment artifacts (cf. [5, 11, 27, 30, 61]), reducing the overhead to create
    SAMs. In summary, the required SAMs potentially improve results because they reduce
    the semantic gap, can likely be created in a lightweight manner, and enable additional
    tasks.


    Overall, this paper presents our transitive approach to linking architecture documentation
    and code, including an approach for linking models and code. Consequently, we
    have the following research questions:


    - RQ1 How well can our approach ArCoTL recover trace links between component-based
    software architecture models and code?

    - RQ2 How accurate can our approach TransArC using intermediate artifacts recover
    trace links between software architecture documentation and code?

    - RQ3 How do the results for linking software architecture documentation and code
    compare to state-of-the-art requirements-to-code approaches?


    The main contributions of this paper are:


    - C1 We present an approach for linking component-based software architecture
    models and code.

    - C2 We combine two specialized TLR approaches to transitively link software architecture
    documentation and code using architecture models as intermediate artifacts.

    - C3 We provide code, baselines, evaluation data, and results in a replication
    package [26].


    The remainder of the paper is structured as follows: Related work is examined
    in Section 2. In Section 3, we provide basic information about the approach ArDoCo
    by Keim et al. [25] that we use for linking SADs and SAMs. Our detailed approach
    is presented in Section 4. We evaluate our approach in Section 5 and discuss threats
    to validity in Section 6. Lastly, we conclude this paper in Section 7.


    #### 2 RELATED WORK


    Automated software and system traceability encompasses different domains, use
    cases, and techniques [2, 62]. Most of the successful techniques are based on
    information retrieval (IR) and machine learning (ML) that we look into in Section
    2.1 and Section 2.2, respectively. As we employ transitive tracing techniques,
    we also look into it in Section 2.3. Overall, we focus on related work that involves
    similar source and target models to texts and source code. In these sections,
    we also provide details for the approaches by Gao et al. [15] and by Hey et al.
    [23] as well as CodeBERT [12] that we use as baselines in our evaluation (cf.
    Section 5.3).


    #### 2.1 Information Retrieval-based TLR


    Early breakthroughs of TLR were primarily based on IR techniques. Initial approaches
    utilized general preprocessing and combinations of probabilistic models and vector
    space models (VSM) to identify candidates for trace links. An example of such
    an approach is presented by Antoniol et al. [1], who create trace links between
    code and source code documentation. However, a common challenge in this context
    is handling semantically similar expressions like synonyms. Various methods have
    been proposed to address this problem, including the use of word embeddings [6,
    23, 67], latent semantic indexing [36], incorporation of synonym coefficients
    for similarity calculations [19], and the construction of semanticrelationship
    graphs [60], among others.


    VSM remains a popular technique for TLR [16, 34]. However, since VSM are primarily
    designed for text-based data, several approaches try to reuse structural information
    to capture contexts in source code [29, 49]. These approaches have shown promise
    in improving TLR between requirements and source code [29].


    Lohar et al. [32] compare various combinations of IR techniques to create trace
    links between different artifact types, including requirements and code. In their
    evaluation covering different projects and domains, their approach achieved high
    mean average precisions (MAPs) of 0.80 and 0.86 for recovering trace links between
    use or test cases and code. However, the authors observed a strong dependency
    between configurations, projects, and artifacts, as the best results for projects
    were attained with different configurations.


    To address these challenges, the approach TAROT introduces the use of so-called
    biterms to improve TLR between requirements and code [15]. Biterms, in the textual
    context, refer to two terms within a sentence that have a grammatical relationship.
    Similarly, biterms in the code side represent any combinations of two terms within
    identifiers, with code comments treated analogously to text. The intersection
    of both biterm sets results in consensual biterms, which are subsequently weighted
    based on their frequency and location. Different IR models, including VSM, latent
    semantic indexing (LSI), and probabilistic Jensen Shannon model divergence (JSD),
    are employed to create candidate trace links between requirements and code. In
    their evaluation, TAROT achieves a MAP of 0.62 for the iTrust project when using
    VSM. When TAROT is combined with the CLUSTER enhancing strategy (cf. [14]), the
    MAP is improved to 0.73 using LSI.


    Hey et al. [23] leverage IR-based metrics to retrieve trace links between requirements
    and source code classes. However, their approach FTLR stands out from other works
    as it employs a more fine-grained technique. In FTLR, both artifact types are
    split into smaller units, with requirements divided into sentences and code elements
    represented by their public method signatures, extended by the name of the containing
    class and their documenting comments.


    The elements of both artifact types are preprocessed. The preprocessing steps
    include stop word removal, lemmatization, and word length filtering. The resulting
    artifact element types are represented as Bag-of-Embeddings, using the pre-trained
    word embedding representations of fastText [42].


    Finally, trace links are generated in two steps. First, the finegrained elements
    are mapped based on the Word Mover''s Distance (WMD) of the Bag-of-Embeddings.
    Second, the resulting element


    trace links are filtered using a threshold. FTLR then creates trace links for
    a class based on a majority vote, linking it to the most frequently mapped requirements
    among its methods. With the best configuration, the authors report an average
    F1-score of 0.327 for this approach in their evaluation.


    Overall, IR-based TLR approaches can achieve accurate results when the semantic
    gap is small, but can struggle with larger ones. In this study, we explore how
    intermediate artifacts can help to bridge such larger semantic gaps.


    #### 2.2 Machine learning-based TLR


    As for most areas, the progress made by ML and language models has significantly
    advanced TLR approaches. ML is applied in various ways, including combining recurrent
    neural networks (RNNs) and word embeddings [17], combining feedforward neural
    networks and cluster-pair rank models [66], ranking embeddings [68], using pre-trained
    language models, such as CodeBERT [31], and using pre-trained classifiers based
    on textual features [54]. Other researchers employ active learning [43] to tackle
    the challenge of the availability of training data. However, these approaches
    use initial trace links of the projects to train their models and therefore tackle
    a different kind of TLR problem than our approach. Their out-of-the-box performance
    for recovering trace links of unseen projects without initial trace links is unclear.
    As large language models can be used for transfer learning across tasks and projects,
    they are promising candidates for the TLR task tackled in this paper. Therefore,
    we use CodeBERT [12] as a baseline besides the two previously mentioned IR-based
    techniques.


    #### 2.3 Utilizing intermediate artifact types


    Instead of attempting to bridge large semantic gaps, some approaches suggest using
    transitive trace links. The Connecting Links Method (CLM) focuses on establishing
    transitive trace links between two artifacts using a third artifact [47, 64].
    In this process, CLM generates trace links to the intermediate artifact by employing
    a VSM. When two trace links share the same element in the intermediate artifact,
    they are connected.


    A similar strategy is adopted by COMET, which leverages a hierarchical probabilistic
    model to infer trace links [44]. The process involves several steps: (1) initial
    trace links are generated using IR and ML techniques; (2) these links are reviewed
    by developers in a second stage; (3) the final phase operates on an approximation
    of the previous steps. Transitive links between two artifacts are established
    when two links from one artifact refer to the same element in another artifact.
    The similarity for the intermediate element is derived either from textual similarity
    (for requirements) or from execution traces (for test cases).


    In a different approach, Rodriguez et al. [57] utilize existing artifacts as intermediates.
    For instance, design artifacts are used to map requirements to subsystem requirements.
    Unlike COMET, the transitive trace links in this approach can connect different
    artifacts. In their evaluation, Rodriguez et al. compare LSI and VSM as techniques
    for direct trace links with transitive trace links. The transitive trace links
    are retrieved by applying different methods to generate the required trace links
    to the intermediate artifacts. Additionally, they compare these results to hybrid
    approaches, which


    ![](_page_3_Figure_10.jpeg)


    Figure 3: Overview of the ArDoCo approach [25]


    combine the results of direct and transitive trace links. The evaluation demonstrates
    that, in most cases, the best transitive techniques significantly outperform the
    direct techniques ( ≤ 0.001). Although hybrid approaches often slightly outperform
    transitive approaches, this difference was not statistically significant. This
    shows that transitive approaches for TLR are helpful for improving the performance,
    supporting our idea.


    As such, we use some ideas from these approaches and apply them to our TLR scenario.
    Moreover, we adapt them using different approaches for the specific intermediate
    steps to benefit from specialized approaches.


    #### 3 BACKGROUND: ARDOCO


    As this work uses ArDoCo [25], we introduce their approach in this section. ArDoCo
    is a tool for TLR and inconsistency detection between natural language SADs and
    SAMs like UML.


    The tool is designed as an extendable pipeline that incorporates agent-based heuristics.
    The pipeline, depicted in Figure 3, comprises various steps for TLR. The first
    two pipeline steps process the artifacts individually and independently.


    Initially, the approach processes the input SAD text using traditional natural
    language processing (NLP) techniques, including part-of-speech tagging, sentence
    splitting, lemmatization, and dependency parsing. These techniques aid in extracting
    structural information from the text.


    Next, the text extraction step identifies name- and type-like mentions from the
    processed text. For instance, in the running example in Figure 1, words like "controller",
    "persistence", or "component" are extracted. Similar mentions, i.e., identical
    or very similar words are clustered, similar to coreference resolution. Each cluster
    is annotated with confidence values that indicate whether the underlying element
    is considered a name or a type. To achieve this, ArDoCo leverages phrase structures
    (cf. [37]). In the running example, the approach would confidently annotate "component"
    as a type, while the other two highlighted words are likely names.


    The model extraction step analyzes the SAM and its meta-model, extracting elements
    like types and architecture components.


    Following this, the element identification identifies potential model elements
    based on the mentions in the text and the extracted information from the meta-model.
    This process creates so-called recommended instances, which can be seen as special
    named entities representing potential model elements.


    Finally, the element connection establishes trace links between the SAD and the
    SAM by mapping recommended instances to similar elements of the instantiated model.
    To calculate similarity, ArDoCo


    ![](_page_4_Figure_1.jpeg)


    Figure 4: Intermediate model for architecture models


    provides different metrics, including string-based, vector-based, and other approaches.


    For their evaluation, Keim et al. use five open-source projects to assess the
    performance of their approach. The overall evaluation results show an average
    precision of 0.87, an average recall of 0.82, and an average F1-score of 0.82.


    #### 4 APPROACH


    Our approach TransArC to recover trace links between SAD and code involves three
    steps, incorporating two distinct approaches (see Figure 2). In the initial step,
    we utilize the ArDoCo approach, as presented by Keim et al. [25] (see Section
    3), to establish links between SAD and SAM. Moving on to the second step, we introduce
    our novel ArCoTL approach for linking SAM to code. The approach transforms the
    artifacts into generalized intermediate representations and computes trace links
    using a computational graph. Detailed insights into this approach are provided
    in Section 4.1. In the final step, we combine the outcomes of both approaches
    in a transitive manner to create the desired trace links between SAD and code.
    The procedure for this step is elaborated in Section 4.2.


    #### 4.1 ArCoTL: Linking SAM to Code


    Our strategy for establishing links between SAM and code involves a two-step approach,
    namely ArCoTL.


    In the first step, we transform both types of artifacts into generalized intermediate
    representations. In the second step, we employ various heuristics and aggregations
    to examine potential hints that signify a link between an architecture element
    and a code element. To combine the different heuristics, we use a computational
    graph.


    4.1.1 Intermediate Representations. The primary objective of intermediate representations
    for both artifacts is to provide an abstraction from the concrete languages used
    for architecture description and programming: First, they capture the essential
    commonalities present in each respective part, enabling us to simplify complex
    inputs and focus solely on the aspects that are required for further processing.
    Second, these representations allow us to define heuristics at a more abstract
    level, free from the intricacies of individual languages. As a result, our heuristics
    become independent of the particular input languages used, offering greater flexibility
    and applicability.


    Our representation for architecture models, as depicted in Figure 4, is characterized
    by its simplicity. The architecture model consists of architecture items subdivided
    into components, interfaces, and signatures. Components may contain sub-components
    and can provide or require interfaces that have signatures.


    ![](_page_4_Figure_12.jpeg)


    Figure 5: Intermediate model for code


    The code model in Figure 5 is similarly straightforward. We base the model on
    the Knowledge Discovery Metamodel (KDM) by the OMG [48] and are using an excerpt
    of the KDM for our code model.


    Code items fall into three categories: modules, computational objects, and datatypes.
    Modules encompass packages, compilation units, or code assemblies, representing
    the structural elements of code. Computational objects represent functional parts
    of the code, such as methods. Lastly, the code model includes datatypes, specifically
    classes and interfaces that can exist within the code.


    We designed our models to maintain simplicity and generality, enabling easy integration
    of additional architecture description languages or programming languages through
    adapters. These adapters transform the input into our intermediate representations,
    representing either the architecture or code model. The advantage of this approach
    is that an adapter only has to be defined once for each language, eliminating
    the need for adaptations in other parts of our methodology, such as the computational
    graph with its associated heuristics. Currently, our implementation supports UML
    components diagrams and PCM [56] as architecture description languages, along
    with Java and Bash as programming languages. The rationale behind selecting these
    languages is to demonstrate our approach''s versatility and applicability with
    different languages.


    Leveraging these intermediate representations, we are also able to define trace
    links formally: A trace link comprises an architecture item paired with a corresponding
    code item. To facilitate our calculations, we construct a repository representing
    the traceability matrix, encompassing all combinations of architecture and code
    items. This matrix is the foundation for our traceability analysis.


    4.1.2 Computational Graph. Our approach employs a variety of heuristics and aggregators
    for conducting its calculations. The heuristics evaluate each pair of entities,
    i.e., architecture and code items. We categorize our heuristics into two distinct
    types: standalone and dependent heuristics. The outputs of each heuristic are
    mappings that contain each entity pair together with the heuristic''s confidence
    for this pair. The aggregators combine the mappings


    and filter out unlikely pairs. We organize the calculations in a computational
    graph. The outputs of the computational graph are the identified trace links,
    i.e., pairs of architecture and code entities.


    | (archItems, codeItems)<br>Algorithm 1 StandaloneHeuristic𝐻 |

    |------------------------------------------------------------|

    | mappings ← ∅                                               |

    | for all archItem ← archItems, codeItem ← codeItems do      |

    | confidence ← similarity𝐻<br>(archItem,codeItem)            |

    | mappings ← mappings ∪ (archItem, codeItem, confidence)     |

    | return mappings                                            |


    Standalone heuristics operate independently, not relying on other heuristics for
    their execution. Thus, they get the input artifacts, i.e., pairs of architecture
    and code items, and calculate their similarity to create mappings, as is shown
    in Algorithm 1. We use the following standalone heuristics:


    | Package | Compares package name with name of components      |  |  |  |

    |---------|----------------------------------------------------|--|--|--|

    | Path    | Compares the path of a compilation unit with the   |  |  |  |

    |         | names of components                                |  |  |  |

    | Method  | Compares method names with names of signatures     |  |  |  |

    | Names   | Compares names of architecture elements with names |  |  |  |


    of compilation units and datatypes


    When comparing entity names, we determine if one entity''s name contains parts
    of the other entity''s name. We identify parts of an entity based on word boundaries
    and camel casing, hyphenations, underscores, periods, and similar separators.
    However, we disregard capitalization during the equality checks. The approach
    derives confidence in this comparison from the ratio of the contained parts. Consequently,
    this comparison is asymmetric. For instance, the name "DatabaseAdapter" contains
    the name "database", resulting in a similarity score of 50%. Conversely, no containment
    in the opposite direction leads to no similarity.


    This asymmetric comparison is vital for controlling which entity can be contained
    within another and for increasing precision, especially for heuristics like Package
    or Path, where containment plays a crucial role.


    Many programming languages encode package names in the path structure. However,
    slight differences can exist, so we employ both heuristics and incorporate this
    relationship. To avoid redundant consideration of the package name via both the
    name and the path, we exclude the package from the path. For example, given the
    package mediastore.persistence and the path ms-database/src/main/java/mediastore/persistence,
    we only utilize the beginning of the path, i.e., ms-database/src/main/java. In
    this example, a difference between both heuristics becomes apparent: The beginning
    of the path represents the folder that can indicate the component name and provide
    additional information compared to only the package name. This situation can arise
    if the project utilizes multiple modules.


    Dependent heuristics use the resulting mappings of previous heuristics as their
    input. As shown in Algorithm 2, dependent heuristics check for affected mappings
    and calculate the updated confidence. There are the following dependent heuristics:


    Hint Inheritance Inherits results from other heuristics (mappings) along extends-
    and implements-relations.


    | (mappings)<br>Algorithm 2 DependentHeuristic𝐻      |  |

    |----------------------------------------------------|--|

    | for all 𝑚<br>← mappings do                         |  |

    | for all 𝑚𝑎<br>(𝑚)<br>← affectedMappings𝐻<br>do     |  |

    | 𝑚𝑎.confidence<br>(𝑚𝑎,𝑚)<br>← getUpdatedConfidence𝐻 |  |

    | return mappings                                    |  |

    |                                                    |  |


    | Common Words    | Checks if names differ only in common words                                    |  |  |  |

    |-----------------|--------------------------------------------------------------------------------|--|--|--|

    |                 | or prefixes/suffixes (e.g., Test, Impl, I).                                    |  |  |  |

    | Amb. Sub-pkg.   | Detects ambiguously mapped sub-packages.                                       |  |  |  |

    | Component rel.  | Looks at relations between components to re                                    |  |  |  |

    |                 | solve ambiguity.                                                               |  |  |  |

    | Interface prov. | Checks if a provide-relation of the architecture<br>exists
    in the source code. |  |  |  |


    The Hint Inheritance heuristic uses the assumption that there is a strong coupling
    between a class and its parent. Consequently, this heuristic inherits mappings
    that regard a class and applies them to the extending or implementing class.


    The Common Words heuristic adapts the results of the Names heuristic. When two
    entities'' names only differ in common words, prefixes, or suffixes, the approach
    increases the confidence score. For example, common words include "Test", "Exception",
    and "Factory". We regard well-known prefixes and suffixes, e.g., "Impl", used
    to indicate implementations of abstract classes.


    When dealing with packages, it is possible for a component and its packages to
    be included in the packages of another component, creating an ambiguous mapping.
    For instance, the package dataaccess.preferences can be mapped to both the DataPersistence
    and the Preferences component. The Ambiguous Sub-package heuristic is employed
    to address this ambiguity in two possible cases: In the first case, when the heuristic
    finds another location where the component (e.g., Preferences) is implemented,
    it is assumed that there is no actual relation between the package (dataaccess.preferences)
    and said component. We reason that the implementation of a component should not
    be scattered in the code. Consequently, the heuristic revokes the mapping to the
    (Preferences) component. In the second case, if the approach finds no other location,
    the sub-package likely is a component (here: Preferences), and the heuristic removes
    the mapping to the DataPersistence component.


    The Component relation and the Interface provision heuristics are used to check
    for relations between components and/or interfaces that can be detected in the
    code. These heuristics adapt previous results based on the existence and absence
    of such relations. They play a significant role if multiple mappings exist between
    an architecture element and code elements. In these cases, they can help remove
    mappings with source code elements that cannot be associated with the relations
    in the architecture.


    Aggregators. To combine mappings, we adopt two types of aggregators: combiners
    and selectors. The first category, combiners, consists of aggregators that, as
    the name suggests, combine the mappings generated by one or more heuristics about
    the same entity pair. The Max combiner utilizes a maximum function, which sets
    the confidence score of an entity pair to the highest confidence of mappings for
    this pair. We use the maximum function to indicate that one result of competing
    heuristics covering different


    ![](_page_6_Figure_2.jpeg)


    Figure 6: The computational graph of ArCoTL


    aspects is sufficient and to avoid negative influence from single low confidence
    mappings.


    The second category of aggregators, selectors, facilitates the selection of mappings
    based on specific criteria. The Best criterion focuses on the mappings of multiple
    heuristics concerning one certain fixed entity and selects only the highest confidence
    hint. Consequently, we have two variants of this criterion, one focussing on code
    items and one on architecture items. The First criterion operates by examining
    the order of the heuristics and selecting, for one entity, the first mapping from
    an ordered list of heuristics. Consequently, the mappings are assessed sequentially
    for each entity, and a mapping is chosen over others if its confidence is greater
    than 0. We base this approach on the idea that heuristics and, thus, the mappings
    are not equally important and need to be weighted. We do this weighting according
    to their order, which proves particularly relevant for specific combinations.


    Lastly, we employ filters to remove mappings that contain negative evidence from
    dependent heuristics such as Ambiguous Subpackage, Component relation, and Interface
    provision. These filters play a crucial role in refining the final results of
    our approach.


    Computational graph. The computational graph in Figure 6 constitutes the backbone
    of ArCoTL. It comprises our five standalone heuristics as the entry points into
    the computation process. Mappings from these heuristics are then filtered with
    the Best criterion.


    Initially, our approach selects the best code items for each architecture item,
    i.e., the set of code items that share the highest confidence for each corresponding
    architecture item. Subsequently, the computation proceeds with the inverse procedure,
    selecting the best architecture item for the previously selected code items.


    For the Names heuristic for components, filtering is based solely on the best
    architecture items for each code item. We intentionally skip the other direction,
    as architecture elements are generally implemented with one or more code elements,
    and limiting architecture items to only the best code items could hinder the recall
    of the results. In general, we apply both directions to have precise result pairs
    and only one direction for exploration.


    We make use of one First matcher when combining the Packageand Names-parts, prioritizing
    package names. Here, we first look at the package name to leverage our underlying
    assumption that


    package structures and component structures might exhibit similarities. Additionally,
    some names can also be part of the package. Therefore, we first select the results
    of the Package heuristic and resort to the Names heuristic otherwise.


    We use various dependent heuristics to adjust confidence values and filter out
    improbable mappings as part of the calculation process. Toward the end, the approach
    merges the computation results using the maximum combiner to select only mappings
    with the highest confidence for each entity pair. The results are further filtered
    using the Interface provision heuristic. This refinement step enhances the precision
    of the final results.


    Finally, we generate trace links for each remaining mapping, i.e., pair of architecture
    item and code item with confidence > 0.


    #### 4.2 TransArC: Transitively Link SAD and Code


    To finally establish trace links between documentation and code, we combine two
    distinct approaches for our approach TransArC: ArDoCo [25], which facilitates
    trace links between SADs and SAMs, and our approach ArCoTL for linking SAMs to
    code.


    The combination of these two approaches is achieved by creating transitive links.
    This process involves linking SADs to code by aggregating the trace links from
    the other two approaches that share the same model elements from the SAM. This
    integration of specialized approaches allows us to bridge the semantic gap more
    effectively, particularly when linking SAMs and code. We can improve the results
    by leveraging the structural information in SAMs, which may not be as explicitly
    represented in SADs.


    While transitive links provide comprehensive traceability, there might be instances
    where code entities are mentioned in the documentation but cannot be directly
    linked to the design artifact. We could utilize existing IR approaches to establish
    the missing links in such cases. However, based on our experience, architecture
    documentation seldom refers directly to code entities (e.g., classes), as they
    are typically not represented in design artifacts. Architecture documentation
    typically emphasizes architecture components over implementation details. To avoid
    introducing imprecision, we currently refrain from applying such approaches.


    #### 5 EVALUATION


    This section evaluates our approaches for TLR between code, SAMs, and documentation
    to answer our research questions. Overall, we want to demonstrate the performance
    of our approach ArCoTL for TLR between SAM and code and the performance of our
    approach TransArC for TLR between SAD and code, including a comparison to state-of-the-art
    approaches.


    We first provide a detailed description of the evaluation dataset in Section 5.1.
    We introduce and explain the metrics to quantify the performance of our approaches
    employed in the evaluation in Section 5.2. In Section 5.3, we describe the baseline
    approaches utilized for comparative analyses. Finally, we present the detailed
    results of our evaluation in Section 5.4, including the comparative assessment
    of our approach to the baselines. To benefit the research community and ensure
    our findings'' reproducibility, we make our approach, the baselines, all our results,
    and the experimental data available in a dedicated replication package [26].


    Table 1: Number of artifacts per artifact type and number of trace links in the
    gold standard for each project


    | Artifact Type |                  | MS | TS  | TM    | BBB   | JR    |

    |---------------|------------------|----|-----|-------|-------|-------|

    | SAD           | # Sentences      | 37 | 43  | 198   | 85    | 13    |

    | SAM           | # Model elements | 23 | 19  | 16    | 24    | 6     |

    | Code          | # Files          | 97 | 205 | 832   | 547   | 1,979 |

    | SAM-Code      | # Trace links    | 60 | 164 | 1,616 | 730   | 1,956 |

    | SAD-Code      | # Trace links    | 50 | 707 | 7,610 | 1,295 | 8,240 |


    #### 5.1 Dataset


    To assess the effectiveness of our approaches, we utilized the benchmark dataset
    provided by Fuchß et al. [13]. This dataset comprises five open-source projects,
    each differing in size and domain. The projects are MediaStore (MS), TeaStore
    (TS), TEAMMATES (TM), BigBlueButton (BBB), and JabRef (JR). The benchmark contains
    the documentation of the projects created by the respective developers. Additionally,
    the benchmark contains the development view (cf. [28]) in the form of structural
    architecture models that originate from other researchers (MS, TS, TM) or are
    reverse-engineered (BBB, JR) (cf. [13, 25]). The benchmark contains gold standards
    for the trace links between these projects'' SADs and SAMs. These gold standards
    were created in small user studies.


    Since the benchmark projects are open-source, we have access to their source code.
    Through a rigorous process, we established corresponding gold standards for both
    scenarios, SAD to code and SAM to code. At least two researchers independently
    generated the gold standards. We resolved discrepancies through discussions and
    merged the resulting gold standards. Table 1 gives an overview of the dataset
    and gold standards.


    Gold Standard for TLR between SAMs and Code. The gold standard for TLR between
    code and SAMs consists of a mapping between the model elements of the SAMs and
    their corresponding relative paths to the source code files. We carefully map
    model elements, such as components, to the best-fitting code elements. Due to
    the difference in abstraction levels between code and SAMs, one model element
    may be mapped to multiple code elements. For example, an interface IDownload can
    be mapped to multiple interfaces in the code, such as IDownload and IDownloadCache.
    Sometimes, the best mapping is not at the file level but at the folder/package
    level. For instance, in the running example illustrated in Figure 1, we map the
    component DataPersistence to the package dataaccess. In such situations, all contained
    elements are considered part of the component, and we trace them accordingly.


    Gold Standard for TLR between SADs and Code. The gold standard for trace links
    recovery between SADs and code encompasses a mapping between the sentences of
    the SADs and the corresponding source code files. Once again, we map the relative
    path to a file or the contents within a folder of the source code to the corresponding
    sentence in the SAD. For example, the first sentence in the running example depicted
    in Figure 1 is mapped to the files Controller.java and Authenticator.java.


    #### 5.2 Metrics


    For our evaluation, we use the metrics Precision (P), Recall (R), and F1-score
    (F1), their harmonic mean. These metrics are commonly used in TLR and comparable
    research areas (cf. [7, 19]).


    Generally, we define the true positives (TP), false positives (FP), and false
    negatives (FN) as follows: TPs are found trace links between one artifact and
    another artifact that are also contained in the gold standard. FPs are found trace
    links between one artifact and another artifact that are not contained in the
    gold standard. FNs are trace links between one artifact and another artifact that
    are contained in the gold standard but not found by the approach.


    In addition to these metrics, we present two distinct average values. First, we
    provide the overall average across all projects, regardless of size. This average
    offers valuable insight into the expected performance per project. Second, we
    offer a weighted average considering the number of expected trace links for each
    project. This weighting enables more profound insights into the anticipated efficacy
    of an approach per trace link.


    #### 5.3 Baseline Approaches


    This section outlines the baseline approaches utilized for comparison in our study.
    Specifically, we have chosen to include the approaches TAROT [15], FTLR [23],
    and CodeBERT [12]. We further adapt ArDoCo [25] to create trace links between
    SAD and code.


    TAROT [15] and FTLR [23] both represent recent and state-ofthe-art IR-based solutions
    for linking requirements and code, and CodeBERT [12] is a large language model
    trained on finding the most semantically related source code for a given natural
    language description. Therefore, all three demonstrate promising results for similar
    TLR problems (cf. Section 2). Since these approaches can handle natural language
    input and code, they are well-suited for addressing our specific TLR problem.
    Moreover, their replication packages<sup>2</sup> allow us to use and adapt these
    approaches. Despite their ability to handle natural language texts, they are targeted
    towards different artifact types (method documentation and requirements) than
    SADs. As SADs, method documentation, and requirements are on different levels
    of abstraction, the results of these approaches can be negatively influenced and
    might perform worse if applied to SADs. Still, these are suitable approaches that
    can be used for comparison in our scenario. As an additional baseline suited towards
    SADs, we adapt ArDoCo to directly operate with our code models (cf. Section 4.1.1).


    TAROT. To be able to apply TAROT as-is to our scenario, we interpret each sentence
    of the SAD as a requirement. We use a threshold to filter TAROT''s similarity
    matrix to generate trace links. We evaluate TAROT''s different IR methods, i.e.,
    JSD, LSI, and VSM. For our comparison, we optimize the threshold for each project
    and method based on the resulting F1-score, thus obtaining the most favorable
    results from TAROT.


    FTLR. To be able to use FTLR as a baseline, we utilize the most recent version
    of FTLR [21, 22]. We treat FTLR similarly to TAROT and interpret the sentences
    of the SAD as requirements. FTLR offers different modes of operation. We apply
    the different modes and select the best-suited mode (WMD as similarity measure,
    taking


    <sup>2</sup>https://github.com/huiAlex/TAROT,


    https://github.com/tobhey/finegrained-traceability


    Table 2: Results for TLR between models and code


    | Project                     | Precision    | Recall       | F1-score     |

    |-----------------------------|--------------|--------------|--------------|

    | MediaStore (MS)             | 0.98         | 1.00         | 0.99         |

    | TeaStore (TS)               | 0.98         | 0.98         | 0.98         |

    | TEAMMATES (TM)              | 1.00         | 1.00         | 1.00         |

    | BigBlueButton (BBB)         | 0.94         | 0.96         | 0.95         |

    | JabRef (JR)                 | 1.00         | 1.00         | 1.00         |

    | Average<br>weighted Average | 0.98<br>0.99 | 0.99<br>0.99 | 0.98<br>0.99 |


    method comments into account) for comparison. The generation of trace links in
    FTLR also relies on thresholds. For our comparison, we use the results obtained
    using the best possible threshold for each project. In our replication package
    [26], we additionally provide the results for FTLR''s default thresholds and further
    modes of operation for comprehensive comparison and analysis.


    CodeBERT. We fine-tune the CodeBERT language model [12] for the Java code search
    task of the CodeSearchNet dataset [24] to apply CodeBERT in our scenario. This
    dataset consists of pairs of Java methods and their corresponding method documentation,
    and the task requires the language model to predict whether certain method documentation
    belongs to a method implementation. This task can be interpreted as similar to
    linking sentences in SADs to their corresponding source code classes. To fine-tune
    the model, we adapted the code provided in the replication package of Trace-BERT
    (T-BERT)<sup>3</sup> , as it includes support for applying and evaluating CodeBERT
    models to the TLR task. In particular, we make use of the SINGLE architecture
    with online negative sampling, which performed best on the CodeSearchNet dataset
    [31]. After training on the CodeSearchNet dataset, we use the fine-tuned model
    to predict links between SAD and code.


    Adapting ArDoCo: ArDoCode. To add a baseline that is more geared towards SADs,
    we adapt ArDoCo to create trace links between SADs and code, calling it ArDoCode.
    For this, we interpret the intermediate code model as a kind of SAM, again resolving
    packages to create trace links to the contained elements.


    More details on the baselines can be found in our replication package [26].


    #### 5.4 Results


    In this section, we present the results of our evaluation.


    Traceability Link Recovery between SAMs and Code. First, we address our first
    research question (cf. Section 1), which focuses on the performance of our approach
    in recovering trace links between software architecture models and code. We present
    precision, recall, and F1-score for each project, along with the average and weighted
    average over all projects in Table 2.


    The results of our approach are exceptional, indicating a nearperfect linkage
    of artifacts. This is expected as SAMs and code are closely related. The approach
    can utilize many of the similar structures that can be found in both types of
    artifacts. Ultimately, the semantic gap is relatively small between these artifacts,
    which


    is also one of our intentions for the overall approach to link SAD and code transitively
    via SAMs.


    However, we still observe some naming-related issues, which can impact the results.
    As such, false positives occur due to the similar naming of different elements.
    For example, in BBB, classes in the folder bbb-graphql-middleware/demo/client
    are erroneously mapped to the HTML5 Client interface of BBB because of the similarity
    of the folder name. Likewise, the class DbException in the MediaStore project
    is incorrectly mapped to the IDB interface instead of the intended DB component.
    Regarding TS and BBB, our approach produces some false negatives. Here, the challenge
    lies in mapping elements with significantly different naming conventions, especially
    when dealing with abbreviations. For instance, due to too dissimilar naming, the
    component BBB web of BigBlueButton could not be mapped to the folder bigbluebutton-web.
    Automated expansion of abbreviations might improve this (cf. [4, 18]).


    Concluding RQ1, our approach achieves an average F1-score of 0.98 (weighted 0.99)
    for the trace links between SAMs and code. According to the classification scheme
    of Hayes et al. [19], our TLR approach achieves excellent results. Moreover, these
    results represent a solid foundation for our transitive approach.


    Traceability Link Recovery between SADs and Code. In the second part of the evaluation,
    we focus on the TLR between SADs and code. Thus, we aim to address our second
    research question, evaluating the effectiveness of our approach in recovering
    trace links between software architecture documentation and code using transitive
    trace links. Additionally, we compare the results obtained by our approach with
    those of the baseline approaches to answer our RQ3.


    To measure the quality of the recovery and facilitate comparison with the baselines,
    we calculate the precision, recall, and F1-score for each project. The baseline
    approaches are initially designed for different tasks, so we optimize their thresholds
    to maximize the F1-score. We then select the results of the mode of operation
    with the best average F1-score.


    In our evaluation, we find that TAROT''s best mode of operation utilizes IR in
    combination with JSD. For FTLR, the best mode of operation uses WMD along with
    method comments (cf. Section 5.3). The results of all approaches are shown in
    Table 3. We highlight the best results for each metric and project.


    The baseline approaches perform worse, achieving an average F1-score of 0.22 for
    TAROT, 0.21 for FTLR, 0.28 for CodeBERT, and 0.37 for ArDoCode. TAROT has a weighted
    average F1-score of 0.29, FTLR of 0.28, and CodeBERT of 0.36. ArDoCode has a weighted
    average F1-score of 0.62 due to its good performance on the larger projects TM
    and JR. All baselines achieve better recall than precision. Comparing the results
    with the reported results of FTLR [23] for its original task, linking requirements
    and code, we observe similar outcomes. This suggests a certain degree of similarity
    in the underlying problem to the extent that the performance of the approaches
    in both scenarios is comparable to some extent.


    Comparing our approach to the baselines, our transitive approach combining two
    specialized approaches outperforms the baselines with an average F1-score of 0.82
    (weighted 0.87). For MS and TS, we achieve perfect precision, while for JR, we
    achieve perfect recall. This result highlights the project dependency, influenced
    by the project''s characteristics. These characteristics include the


    <sup>3</sup>https://github.com/jinfenglin/TraceBERT


    Table 3: Results for TLR between documentation and code


    |          | MS  |     |     | TS  |     |     | TM  |     |     | BBB |     |     |
    JR  |     |     | Avg. |     |     | w. Avg. |     |     |

    |----------|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|-----|------|-----|-----|---------|-----|-----|

    | Approach | P   | R   | F1  | P   | R   | F1  | P   | R   | F1  | P   | R   |
    F1  | P   | R   | F1  | P    | R   | F1  | P       | R   | F1  |

    | TAROT    | .09 | .24 | .13 | .19 | .44 | .27 | .06 | .32 | .11 | .07 | .18 |
    .10 | .32 | 1.0 | .49 | .15  | .44 | .22 | .19     | .63 | .29 |

    | FTLR     | .15 | .26 | .19 | .19 | .25 | .21 | .06 | .30 | .10 | .04 | .42 |
    .07 | .32 | .93 | .48 | .15  | .43 | .21 | .19     | .59 | .28 |

    | CodeBERT | .29 | .12 | .17 | .26 | .57 | .36 | .09 | .22 | .12 | .07 | .49 |
    .12 | .49 | .83 | .61 | .24  | .45 | .28 | .28     | .53 | .36 |

    | ArDoCode | .05 | .66 | .09 | .20 | .74 | .31 | .37 | .92 | .53 | .07 | .57 |
    .13 | .66 | 1.0 | .80 | .27  | .78 | .37 | .47     | .92 | .62 |

    | TransArC | 1.0 | .52 | .68 | 1.0 | .71 | .83 | .71 | .91 | .80 | .77 | .91 |
    .84 | .89 | 1.0 | .94 | .87  | .81 | .82 | .81     | .94 | .87 |


    similarity and consistency of the names in the two artifacts. Moreover, projects
    may use similar terms corresponding to different entities, making it hard to link
    them correctly.


    We use Wilcoxon''s signed rank test to calculate the significance of our approach''s
    F1-scores compared to the baselines. TransArC is significantly outperforming the
    baseline approaches (at the 0.05 level). This outcome can likely be attributed
    to the larger semantic gap the baseline approaches try to bridge. Moreover, TAROT,
    FTLR, and CodeBERT are fine-tuned for similar but different scenarios.


    Nevertheless, the combination of our two specialized approaches proves highly
    effective. Accordingly, this methodology facilitates the practical use of TLR
    (cf. [19]). Comparing the results of Ar-DoCode and TransArC, intermediate artifacts
    seem to play a vital role in bridging the semantic gap. We argue that creating
    intermediate artifacts is worthwhile, especially given their other applications
    and the possibility to reverse engineer them (cf. Section 1).


    In summary, our transitive approach TransArC performs promisingly with an average
    F1-score of 0.82 (weighted 0.87). Thus, we can confidently answer RQ2: According
    to the classification scheme of Hayes et al. [19], our approach excellently recovers
    trace links between SADs and code. Additionally, we can briefly answer RQ3: Our
    approach significantly outperforms the baselines in all projects concerning precision,
    recall, and F1-score.


    #### 6 THREATS TO VALIDITY


    In this section, we discuss threats to validity based on the guidelines by Runeson
    and Höst [58].


    To ensure Construct Validity, we employ commonly used metrics and select projects
    that have been previously studied in research. Additionally, we deliberately choose
    projects with diverse characteristics, such as different domains, sizes, and relative
    sizes of documentation to lines of code. By doing so, we aim to mitigate potential
    confounding factors that could hinder us from effectively addressing our research
    questions.


    Regarding Internal Validity, there is the threat that we examine TLR in a way
    that there are other influencing factors that affect our evaluation. Moreover,
    we might misinterpret the cause of certain results, leading to wrong conclusions.
    To address internal validity concerns, we follow established practices to minimize
    threats. Specifically, we define and evaluate trace links on a sentence level
    and map them to code files, akin to requirements-to-code traceability. We use
    the same selection of open-source projects as Keim et al. [25]. This methodology
    helps mitigate the risk of selection bias. However, it is essential to acknowledge
    that open-source projects


    can vary significantly in code quality, documentation, and consistency. Consequently,
    noise and errors in the data can potentially impact the evaluation process, leading
    to inflated or deflated performance metrics. Lastly, we might have misjudged the
    influence of the semantic gap. To mitigate this and to determine the influence,


    we adapted ArDoCo to work directly with the code model. Our research design is
    subject to certain threats to External Validity. First, we focus solely on (structural)
    component-based architecture models, potentially limiting the generalizability
    of our findings w.r.t. other architectural paradigms or views. According to Tian
    et al. [63], this view is commonly used for architecture. The results still may
    vary if, e.g., more logical descriptions and views of the architecture are used,
    or if the abstraction levels are more different. Second, among the evaluated projects,
    there are academic projects designed to mimic real applications, but they may
    exhibit certain differences, making clear statements about generalizability challenging.
    While our projects encompass different domains and sizes, they do not fully represent
    all possible application variants. Certain types of projects or specific project
    characteristics may be overrepresented or underrepresented in our dataset, potentially
    skewing the evaluation results and restricting the applicability of our findings
    to different projects and real-world scenarios.


    To address threats to validity regarding Reliability, we utilize benchmark datasets
    previously employed in published research. However, we still need to create a
    gold standard for TLR between SAM and code, as well as SAD and code. For this,
    we adopt a rigorous approach where at least two researchers independently generated
    the gold standards, to reduce a potentially biased influence by a single person.
    These gold standards are merged through comparison and discussion to decide any
    differences. Still, it is important to acknowledge possible bias, such as researchers
    interpreting artifacts differently, which impacts reliability to some extent.


    #### 7 CONCLUSION AND FUTURE WORK


    In conclusion, this scientific study investigated the use of traceability link
    recovery (TLR) for linking software architecture documentation (SAD) to code.
    The approach achieves this utilizing a transitive method that combines the results
    from two specialized approaches, namely TLR for SAD to component-based software
    architecture model (SAM) using the ArDoCo approach by Keim et al. [25] and a novel
    approach for TLR between SAM and code.


    The proposed approach for model-to-code-TLR utilizes heuristics and aggregators,
    seamlessly integrated within a computational graph. The efficacy of this method
    was evaluated on a dataset comprising five diverse projects. To answer RQ1 (performance
    for TLR


    between SAM and code), the evaluation results for the SAM to code TLR exhibit
    outstanding performance. Thanks to using both name similarity and structural information,
    the approach achieved an average F1-score of 0.98. Answering RQ2 (performance
    for TLR between SAD and code) and RQ3 (comparison to baselines), the results for
    transitive links between SAD and code display exceptional results with an average
    F1-score of 0.82 (weighted 0.87), surpassing the baseline approaches, including
    the LLM-based approach Code-BERT, significantly. These results further validate
    the effectiveness of our approach to bridge the semantic gap. The results also
    show that LLMs are not always the best solution.


    In summary, this research contributes a promising methodology for documentation-to-code
    linkage, and the remarkable achieved performance demonstrates its potential applicability
    in real-world scenarios. These findings open up exciting possibilities for improving
    traceability linkage. To ensure replicability and transparency, we have made available
    a comprehensive replication package [26], encompassing the implemented approach,
    baseline models, evaluation data, and the obtained results. By sharing this package,
    we aim to facilitate the reproduction of our study and enable fellow researchers
    to validate and build upon our findings.


    In our evaluation, we used projects from different domains with SADs in different
    styles and slightly different levels of abstraction. Therefore, we believe that
    our results are to a certain degree generalizable. The results can vary with vastly
    diverging SADs. Additionally, SAMs that do not encapsulate the structural components
    or focus on a too different abstraction can cause a degradation of our approach''s
    performance. However, the general idea to bridge the semantic gap by using multiple
    specialized approaches should hold for other artifacts that are semantically in
    between the original gap. Still, we need to explore this theory further in future
    work.


    Consequently, our plan includes extending the generalizability of our approach
    in future work. First, we aim to evaluate the approach with additional projects
    to assess its capabilities in different settings, domains, and scenarios. Second,
    we will investigate the adaptability of our transitive approach for other instances
    of TLR, such as linking requirements to code. This will entail exploring and identifying
    various reasonable and efficient intermediate artifacts.


    To improve upon the promising results, we plan to make various improvements in
    future work to further refine the approach.


    For our transitive approach, we prioritize precision by disregarding direct mentions
    of classes in SADs that cannot be linked to SAMs. In future research, we intend
    to explore opportunities to combine our approach with other (IR) approaches, to
    address cases where documentation mentions code entities not explicitly represented
    in the design artifact. This will further strengthen the overall efficacy and
    completeness of our approach. Moreover, we plan to extend the inconsistency detection
    capabilities of ArDoCo [25] to SAD and code using TransArC for establishing the
    required links.


    By focusing on these avenues of enhancement, we aim to create a more robust and
    versatile TLR framework that can further TLR and aid various software engineering
    tasks in an array of contexts.


    #### ACKNOWLEDGMENTS


    This work was supported by funding from the pilot program Core Informatics at
    KIT (KiKIT) of the Helmholtz Association (HGF). This work was also supported by
    funding from the topic Engineering Secure Systems of the HGF and by KASTEL Security
    Research Labs.


    #### REFERENCES


    - [1] G. Antoniol, G. Canfora, G. Casazza, A. De Lucia, and E. Merlo. 2002. Recovering
    Traceability Links between Code and Documentation. IEEE Transactions on Software
    Engineering 28, 10 (Oct. 2002), 970–983. https://doi.org/10.1109/TSE. 2002.1041053

    - [2] Thazin Win Win Aung, Huan Huo, and Yulei Sui. 2020. A Literature Review
    of Automatic Traceability Links Recovery for Software Change Impact Analysis.
    In Proceedings of the 28th International Conference on Program Comprehension (Seoul,
    Republic of Korea) (ICPC ''20). Association for Computing Machinery, New York,
    NY, USA, 14–24. https://doi.org/10.1145/3387904.3389251

    - [3] T.J. Biggerstaff, B.G. Mitbander, and D. Webster. 1993. The concept assignment
    problem in program understanding. In [1993] Proceedings Working Conference on
    Reverse Engineering. 27–43. https://doi.org/10.1109/WCRE.1993.287781

    - [4] Shanqing Cai, Subhashini Venugopalan, Katrin Tomanek, Ajit Narayanan, Meredith
    Ringel Morris, and Michael P. Brenner. 2022. Context-Aware Abbreviation Expansion
    Using Large Language Models. arXiv:2205.03767 [cs.CL]

    - [5] Yuanfang Cai, Hanfei Wang, Sunny Wong, and Linzhang Wang. 2013. Leveraging
    Design Rules to Improve Software Architecture Recovery. In Proceedings of the
    9th International ACM Sigsoft Conference on Quality of Software Architectures
    (Vancouver, British Columbia, Canada) (QoSA ''13). Association for Computing Machinery,
    133–142. https://doi.org/10.1145/2465478.2465480

    - [6] Lei Chen, Dandan Wang, Junjie Wang, and Qing Wang. 2019. Enhancing Unsupervised
    Requirements Traceability with Sequential Semantics. In 2019 26th Asia-Pacific
    Software Engineering Conference (APSEC). 23–30. https://doi.org/10. 1109/APSEC48747.2019.00013

    - [7] Jane Cleland-Huang, Orlena Gotel, Andrea Zisman, et al. 2012. Software and
    systems traceability. Vol. 2. Springer.

    - [8] CoEST. 2023. Center of Excellence for Software & Systems Traceability. https:
    //web.archive.org/web/20230518011309/http://www.coest.org/. Accessed: 2023- 05-18.

    - [9] Alexander Egyed, Florian Graf, and Paul Grünbacher. 2010. Effort and Quality
    of Recovering Requirements-to-Code Traces: Two Exploratory Experiments. In 2010
    18th IEEE International Requirements Engineering Conference. 221–230. https://doi.org/10.1109/RE.2010.34

    - [10] Davide Falessi, Justin Roll, Jin L.C. Guo, and Jane Cleland-Huang. 2020.
    Leveraging Historical Associations between Requirements and Source Code to Identify
    Impacted Classes. IEEE Transactions on Software Engineering 46, 4 (2020), 420–441.
    https://doi.org/10.1109/TSE.2018.2861735

    - [11] Jean-Marie Favre. 2005. Foundations of model (Driven)(Reverse) engineering.
    In Dagstuhl Seminar Proceedings. Schloss Dagstuhl-Leibniz-Zentrum für Informatik.

    - [12] Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong,
    Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. 2020. CodeBERT: A
    Pre-Trained Model for Programming and Natural Languages. In Findings of the Association
    for Computational Linguistics: EMNLP 2020. Association for Computational Linguistics,
    Online, 1536–1547. https://doi.org/10.18653/v1/2020.findingsemnlp.139

    - [13] Dominik Fuchß, Sophie Corallo, Jan Keim, Janek Speit, and Anne Koziolek.
    2023. Establishing a Benchmark Dataset for Traceability Link Recovery between
    Software Architecture Documentation and Models. In Software Architecture. ECSA
    2022 Tracks and Workshops, Thais Batista, Tomáš Bureš, Claudia Raibulet, and Henry
    Muccini (Eds.). Springer International Publishing, Cham, 455–464. https://doi.org/10.1007/978-3-031-36889-9\_30

    - [14] Hui Gao, Hongyu Kuang, Xiaoxing Ma, Hao Hu, Jian Lü, Patrick Mäder, and
    Alexander Egyed. 2022. Propagating Frugal User Feedback through Closeness of Code
    Dependencies to Improve IR-based Traceability Recovery. Empir Software Eng 27,
    2 (Jan. 2022), 41. https://doi.org/10.1007/s10664-021-10091-5

    - [15] Hui Gao, Hongyu Kuang, Kexin Sun, Xiaoxing Ma, Alexander Egyed, Patrick
    Mäder, Guoping Rong, Dong Shao, and He Zhang. 2023. Using Consensual Biterms from
    Text Structures of Requirements and Code to Improve IR-Based Traceability Recovery.
    In Proceedings of the 37th IEEE/ACM International Conference on Automated Software
    Engineering (ASE ''22). Association for Computing Machinery, New York, NY, USA,
    1. https://doi.org/10.1145/3551349.3556948

    - [16] M. Gethers, R. Oliveto, D. Poshyvanyk, and A. D. Lucia. 2011. On Integrating
    Orthogonal Information Retrieval Methods to Improve Traceability Recovery. In
    2011 27th IEEE International Conference on Software Maintenance (ICSM). 133–142.
    https://doi.org/10.1109/ICSM.2011.6080780

    - [17] Jin Guo, Jinghui Cheng, and Jane Cleland-Huang. 2017. Semantically Enhanced
    Software Traceability Using Deep Learning Techniques. In Proceedings of the 39th
    International Conference on Software Engineering (ICSE ''17). IEEE Press,


    Piscataway, NJ, USA, 3–14. https://doi.org/10.1109/ICSE.2017.9


    - [18] Hussein Hasso, Katharina Großer, Iliass Aymaz, Hanna Geppert, and Jan Jürjens.
    2022. Abbreviation-Expansion Pair Detection for Glossary Term Extraction. In Requirements
    Engineering: Foundation for Software Quality, Vincenzo Gervasi and Andreas Vogelsang
    (Eds.). Springer International Publishing, Cham, 63–78.

    - [19] Jane Huffman Hayes, Alex Dekhtyar, and Senthil Karthikeyan Sundaram. 2006.
    Advancing Candidate Link Generation for Requirements Tracing: The Study of Methods.
    IEEE TSE 32, 1 (Jan. 2006), 4–19. https://doi.org/10.1109/TSE.2006.3

    - [20] Jane Huffman Hayes, Alex Dekhtyar, Senthil Karthikeyan Sundaram, E Ashlee
    Holbrook, Sravanthi Vadlamudi, and Alain April. 2007. REquirements TRacing On
    target (RETRO): improving software maintenance through traceability recovery.
    Innovations in Systems and Software Engineering 3 (2007), 193–202.

    - [21] Tobias Hey. 2023. Automatische Wiederherstellung von Nachverfolgbarkeit
    zwischen Anforderungen und Quelltext. https://doi.org/10.5445/IR/1000162446

    - [22] Tobias Hey. 2023. Fine-Grained Traceability Link Recovery (FTLR). Zenodo.
    https://doi.org/10.5281/zenodo.8367392

    - [23] Tobias Hey, Fei Chen, Sebastian Weigelt, and Walter F. Tichy. 2021. Improving
    Traceability Link Recovery Using Fine-grained Requirements-to-Code Relations.
    In 2021 IEEE International Conference on Software Maintenance and Evolution (ICSME)
    (2021-09). 12–22. https://doi.org/10.1109/ICSME52107.2021.00008

    - [24] Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, and Marc
    Brockschmidt. 2020. CodeSearchNet Challenge: Evaluating the State of Semantic
    Code Search. arXiv:1909.09436 (June 2020). https://doi.org/10.48550/arXiv.1909.
    09436 arXiv:1909.09436 [cs, stat]

    - [25] Jan Keim, Sophie Corallo, Dominik Fuchß, and Anne Koziolek. 2023. Detecting
    Inconsistencies in Software Architecture Documentation Using Traceability Link
    Recovery. In 2023 IEEE 20th International Conference on Software Architecture
    (ICSA). 141–152. https://doi.org/10.1109/ICSA56044.2023.00021

    - [26] Jan Keim, Sophie Corallo, Dominik Fuchß, Tobias Hey, Tobias Telge, and
    Anne Koziolek. 2023. Replication Package for "Recovering Trace Links Between Software
    Documentation And Code". Zenodo. https://doi.org/10.5281/zenodo. 10411853

    - [27] Yves R. Kirschner, Jan Keim, Nico Peter, and Anne Koziolek. 2023. Automated
    Reverse Engineering of the Technology-Induced Software System Structure. In Software
    Architecture, Bedir Tekinerdogan, Catia Trubiani, Chouki Tibermacine, Patrizia
    Scandurra, and Carlos E. Cuesta (Eds.). Springer Nature Switzerland, Cham, 283–291.

    - [28] P.B. Kruchten. 1995. The 4+1 View Model of architecture. IEEE Software
    12, 6 (1995), 42–50. https://doi.org/10.1109/52.469759

    - [29] Hongyu Kuang, Patrick Mäder, Hao Hu, Achraf Ghabi, LiGuo Huang, Jian Lü,
    and Alexander Egyed. 2015. Can Method Data Dependencies Support the Assessment
    of Traceability Between Requirements and Source Code? J. Softw. Evol. Process
    27, 11 (Nov. 2015), 838–866. https://doi.org/10.1002/smr.1736

    - [30] Michael Langhammer, Arman Shahbazian, Nenad Medvidovic, and Ralf H Reussner.
    2016. Automated extraction of rich software models from limited system information.
    In 2016 13th Working IEEE/IFIP Conference on Software Architecture (WICSA). IEEE,
    99–108.

    - [31] Jinfeng Lin, Yalin Liu, Qingkai Zeng, Meng Jiang, and Jane Cleland-Huang.
    2021. Traceability Transformed: Generating More Accurate Links with Pre-Trained
    BERT Models. In 2021 IEEE/ACM 43rd International Conference on Software Engineering
    (ICSE). 324–335. https://doi.org/10.1109/ICSE43902.2021.00040

    - [32] Sugandha Lohar, Sorawit Amornborvornwong, Andrea Zisman, and Jane Cleland-Huang.
    2013. Improving Trace Accuracy Through Data-driven Configuration and Composition
    of Tracing Features. In Proceedings of the 2013 9th Joint Meeting on Foundations
    of Software Engineering (ESEC/FSE 2013). ACM, New York, NY, USA, 378–388. https://doi.org/10.1145/2491411.2491432

    - [33] Patrick Mäder and Alexander Egyed. 2015. Do developers benefit from requirements
    traceability when evolving and maintaining a software system? Empirical Software
    Engineering 20 (2015), 413–441. https://doi.org/10.1007/s10664-014- 9314-z

    - [34] Anas Mahmoud and Nan Niu. 2015. On the Role of Semantics in Automated Requirements
    Tracing. Requirements Eng 20, 3 (Sept. 2015), 281–300. https: //doi.org/10.1007/s00766-013-0199-y

    - [35] Ivano Malavolta, Patricia Lago, Henry Muccini, Patrizio Pelliccione, and
    Antony Tang. 2012. What industry needs from architectural languages: A survey.
    IEEE Transactions on Software Engineering 39, 6 (2012), 869–891.

    - [36] Andrian Marcus and Jonathan I. Maletic. 2003. Recovering Documentation-tosource-code
    Traceability Links Using Latent Semantic Indexing. In Proceedings of the 25th
    International Conference on Software Engineering (ICSE ''03). IEEE Computer Society,
    Washington, DC, USA, 125–135. https://dl.acm.org/doi/10. 5555/776816.776832

    - [37] Peter Hugoe Matthews et al. 1981. Syntax. Cambridge University Press.

    - [38] Christoph Mayr-Dorn, Michael Vierhauser, Stefan Bichler, Felix Keplinger,
    Jane Cleland-Huang, Alexander Egyed, and Thomas Mehofer. 2021. Supporting Quality
    Assurance with Automated Process-Centric Quality Constraints Checking. In 2021
    IEEE/ACM 43rd International Conference on Software Engineering (ICSE). 1298–1310.
    https://doi.org/10.1109/ICSE43902.2021.00118

    - [39] Patrick Mäder and Alexander Egyed. 2012. Assessing the effect of requirements
    traceability for software maintenance. In 2012 28th IEEE International Conference
    on Software Maintenance. https://doi.org/10.1109/ICSM.2012.6405269

    - [40] Patrick Mäder, Paul L. Jones, Yi Zhang, and Jane Cleland-Huang. 2013. Strategic
    Traceability for Safety-Critical Projects. IEEE Software 30, 3 (2013), 58–66.
    https: //doi.org/10.1109/MS.2013.60

    - [41] Nenad Medvidovic and Richard N. Taylor. 2010. Software architecture: foundations,
    theory, and practice. In 2010 ACM/IEEE 32nd International Conference on Software
    Engineering, Vol. 2. 471–472. https://doi.org/10.1145/1810295.1810435

    - [42] Tomas Mikolov, Edouard Grave, Piotr Bojanowski, Christian Puhrsch, and
    Armand Joulin. 2018. Advances in Pre-Training Distributed Word Representations.
    In Proceedings of the Eleventh International Conference on Language Resources
    and Evaluation (LREC 2018). European Language Resources Association (ELRA), Miyazaki,
    Japan. https://aclanthology.org/L18-1008

    - [43] Chris Mills, Javier Escobar-Avila, Aditya Bhattacharya, Grigoriy Kondyukov,
    Shayok Chakraborty, and Sonia Haiduc. 2019. Tracing with Less Data: Active Learning
    for Classification-Based Traceability Link Recovery. In 2019 IEEE International
    Conference on Software Maintenance and Evolution (ICSME). 103–113. https://doi.org/10.1109/ICSME.2019.00020

    - [44] Kevin Moran, David N. Palacio, Carlos Bernal-Cárdenas, Daniel McCrystal,
    Denys Poshyvanyk, Chris Shenefiel, and Jeff Johnson. 2020. Improving the Effectiveness
    of Traceability Link Recovery Using Hierarchical Bayesian Networks. In Proceedings
    of the ACM/IEEE 42nd International Conference on Software Engineering (ICSE ''20).
    Association for Computing Machinery, New York, NY, USA, 873–885. https://doi.org/10.1145/3377811.3380418

    - [45] Shiva Nejati, Mehrdad Sabetzadeh, Davide Falessi, Lionel Briand, and Thierry
    Coq. 2012. A SysML-based approach to traceability management and design slicing
    in support of safety certification: Framework, tool support, and case studies.
    Information and Software Technology 54, 6 (2012), 569–590. https: //doi.org/10.1016/j.infsof.2012.01.005

    - [46] Armstrong Nhlabatsi, Yijun Yu, Andrea Zisman, Thein Tun, Niamul Khan, Arosha
    Bandara, Khaled M. Khan, and Bashar Nuseibeh. 2015. Managing Security Control
    Assumptions Using Causal Traceability. In IEEE/ACM 8th SST. 43–49. https: //doi.org/10.1109/SST.2015.14

    - [47] Kazuki Nishikawa, Hironori Washizaki, Yoshiaki Fukazawa, Keishi Oshima,
    and Ryota Mibe. 2015. Recovering transitive traceability links among software
    artifacts. In 2015 IEEE International Conference on Software Maintenance and Evolution
    (ICSME). 576–580. https://doi.org/10.1109/ICSM.2015.7332517

    - [48] Object Management Group (OMG). 2006. Knowledge Discovery Metamodel (KDM)
    Specification, Version 1.4. OMG Document Number formal/2016-12 (https://www.omg.org/spec/KDM/1.4/About-KDM/).

    - [49] A. Panichella, C. McMillan, E. Moritz, D. Palmieri, R. Oliveto, D. Poshyvanyk,
    and A. De Lucia. 2013. When and How Using Structural Information to Improve IR-Based
    Traceability Recovery. In 2013 17th European Conference on Software Maintenance
    and Reengineering. 199–208. https://doi.org/10.1109/CSMR.2013.29

    - [50] D.L. Parnas. 1994. Software aging. In Proceedings of 16th International
    Conference on Software Engineering. 279–287. https://doi.org/10.1109/ICSE.1994.296790

    - [51] Cosmina Cristina Raţiu, Wesley K. G. Assunção, Rainer Haas, and Alexander
    Egyed. 2022. Reactive Links across Multi-Domain Engineering Models. In Proceedings
    of the 25th International Conference on Model Driven Engineering Languages and
    Systems (Montreal, Quebec, Canada) (MODELS ''22). ACM, New York, NY, USA, 76–86.
    https://doi.org/10.1145/3550355.3552446

    - [52] B. Ramesh and M. Jarke. 2001. Toward reference models for requirements
    traceability. IEEE Transactions on Software Engineering 27, 1 (2001), 58–93. https://doi.org/10.1109/32.895989

    - [53] Michael Rath, David Lo, and Patrick Mäder. 2018. Analyzing Requirements
    and Traceability Information to Improve Bug Localization. In Proceedings of the
    15th International Conference on Mining Software Repositories (Gothenburg, Sweden)
    (MSR ''18). Association for Computing Machinery, New York, NY, USA, 442–453. https://doi.org/10.1145/3196398.3196415

    - [54] Michael Rath, Jacob Rendall, Jin L. C. Guo, Jane Cleland-Huang, and Patrick
    Mäder. 2018. Traceability in the Wild: Automatically Augmenting Incomplete Trace
    Links. In Proceedings of the 40th International Conference on Software Engineering
    (ICSE ''18). ACM, New York, NY, USA, 834–845. https://doi.org/10.1145/3180155.3180207

    - [55] Patrick Rempel and Parick Mäder. 2017. Preventing Defects: The Impact of
    Requirements Traceability Completeness on Software Quality. IEEE Transactions
    on Software Engineering 43, 8 (2017). https://doi.org/10.1109/TSE.2016.2622264

    - [56] Ralf H Reussner, Steffen Becker, Jens Happe, Robert Heinrich, Anne Koziolek,
    Heiko Koziolek, Max Kramer, and Klaus Krogmann. 2016. Modeling and simulating
    software architectures: The Palladio approach. MIT Press.

    - [57] Alberto D. Rodriguez, Jane Cleland-Huang, and Davide Falessi. 2021. Leveraging
    Intermediate Artifacts to Improve Automated Trace Link Retrieval. In 2021 IEEE
    International Conference on Software Maintenance and Evolution (ICSME). 81–92.
    https://doi.org/10.1109/ICSME52107.2021.00014

    - [58] Per Runeson and Martin Höst. 2008. Guidelines for conducting and reporting
    case study research in software engineering. 14, 2 (2008), 131. https://doi.org/
    10.1007/s10664-008-9102-8


    - [59] Aaron Schlutter and Andreas Vogelsang. 2021. Improving Trace Link Recovery
    Using Semantic Relation Graphs and Spreading Activation. In Requirements Engineering:
    Foundation for Software Quality, Fabiano Dalpiaz and Paola Spoletini (Eds.). Springer
    International Publishing, Cham, 37–53.

    - [60] Aaron Schlutter and Andreas Vogelsang. 2021. Improving Trace Link Recovery
    Using Semantic Relation Graphs and Spreading Activation. In Requirements Engineering:
    Foundation for Software Quality, Fabiano Dalpiaz and Paola Spoletini (Eds.). Springer
    International Publishing, Cham, 37–53. https://doi.org/10.1007/ 978-3-030-73128-1\_3

    - [61] Marcelo Schmitt Laser, Nenad Medvidovic, Duc Minh Le, and Joshua Garcia.
    2020. ARCADE: an extensible workbench for architecture recovery, change, and decay
    evaluation. In Proceedings of the 28th ACM Joint Meeting on European Software
    Engineering Conference and Symposium on the Foundations of Software Engineering.
    1546–1550.

    - [62] Kamal Souali, Othmane Rahmaoui, and Mohammed Ouzzif. 2016. An overview
    of traceability: Definitions and techniques. In 2016 4th IEEE International Colloquium
    on Information Science and Technology (CiSt). 789–793. https://doi.org/10.1109/
    CIST.2016.7804995

    - [63] Fangchao Tian, Peng Liang, and Muhammad Ali Babar. 2022. Relationships
    between software architecture and source code in practice: An exploratory survey


    and interview. Information and Software Technology 141 (2022), 106705.


    - [64] Ryosuke Tsuchiya, Kazuki Nishikawa, Hironori Washizaki, Yoshiaki Fukazawa,
    Yuya Shinohara, Keishi Oshima, and Ryota Mibe. 2019. Recovering transitive traceability
    links among various software artifacts for developers. IE-ICE TRANSACTIONS on
    Information and Systems 102, 9 (2019), 1750–1760. https://search.ieice.org/bin/summary.php?id=e102-d\_9\_1750

    - [65] Zhiyuan Wan, Yun Zhang, Xin Xia, Yi Jiang, and David Lo. 2023. Software
    Architecture in Practice: Challenges and Opportunities. arXiv preprint arXiv:2308.09978
    (2023). accepted for ESEC/FSE 2023.

    - [66] W. Wang, N. Niu, H. Liu, and Z. Niu. 2018. Enhancing Automated Requirements
    Traceability by Resolving Polysemy. In 2018 IEEE 26th International Requirements
    Engineering Conference (RE). 40–51. https://doi.org/10.1109/RE.2018.00-53

    - [67] Meng Zhang, Chuanqi Tao, Hongjing Guo, and Zhiqiu Huang. 2021. Recovering
    Semantic Traceability between Requirements and Source Code Using Feature Representation
    Techniques. In 2021 IEEE 21st International Conference on Software Quality, Reliability
    and Security (QRS). 873–882. https: //doi.org/10.1109/QRS54544.2021.00096

    - [68] T. Zhao, Q. Cao, and Q. Sun. 2017. An Improved Approach to Traceability
    Recovery Based on Word Embeddings. In 2017 24th Asia-Pacific Software Engineering
    Conference (APSEC). 81–89. https://doi.org/10.1109/APSEC.2017.14'
  decisions:
    evaluation_prompt: '- Qualified. Reason: The abstract mentions that the authors
      evaluate their approaches using five open-source projects and provide performance
      metrics (average F1-scores) comparing their results to baseline approaches,
      indicating structured evaluation.'
    related_work_prompt: '- Qualified. Reason: The paper discusses the challenges
      of traceability link recovery (TLR) and mentions existing automated TLR approaches
      for requirements and code, indicating engagement with prior research. It also
      references various critical software engineering tasks supported by traceability
      and cites multiple sources, demonstrating a clear connection to earlier work
      in the field.'
    novelty_prompt: '- Qualified. Reason: The paper proposes a new approach called
      TransArC for traceability link recovery (TLR) between architecture documentation
      and code, which includes a novel method for linking architecture models to code.
      This indicates a clear claim of novelty in addressing the semantic gap in software
      development.'
    review_only_prompt: '- Qualified. Reason: The paper proposes a novel approach
      (TransArC) for traceability link recovery between architecture documentation
      and code, and it includes experimental results demonstrating the effectiveness
      of this approach.'
  llm_input_used: '## Abstract

    Introduction Software development involves creating various artifacts at different
    levels of abstraction and establishing relationships between them is essential.
    Traceability link recovery (TLR) automates this process, enhancing software quality
    by aiding tasks like maintenance and evolution. However, automating TLR is challenging
    due to semantic gaps resulting from different levels of abstraction. While automated
    TLR approaches exist for requirements and code, architecture documentation lacks
    tailored solutions, hindering the preservation of architecture knowledge and design
    decisions. Methods This paper presents our approach TransArC for TLR between architecture
    documentation and code, using componentbased architecture models as intermediate
    artifacts to bridge the semantic gap. We create transitive trace links by combining
    the existing approach ArDoCo for linking architecture documentation to models
    with our novel approach ArCoTL for linking architecture models to code.

    Results We evaluate our approaches with five open-source projects, comparing our
    results to baseline approaches. The model-to-code TLR approach achieves an average
    F1-score of 0.98, while the documentation-to-code TLR approach achieves a promising
    average F1-score of 0.82, significantly outperforming baselines.

    Conclusion Combining two specialized approaches with an intermediate artifact
    shows promise for bridging the semantic gap. In future research, we will explore
    further possibilities for such transitive approaches.


    ## Introduction

    During software development, various artifacts are created. These artifacts are
    at different levels of abstraction and cover (partially) different aspects of
    a system. The problem is that the relationships between the artifacts are not
    always apparent and, thus, cannot be used. Making these relationships explicit
    improves software quality and simplifies processes. As such, software traceability
    is an important factor in successful software development. With traceability link
    recovery (TLR), software engineers can connect any uniquely identifiable software
    engineering artifacts by creating explicit trace links, maintain these trace links,
    and use the resulting network to gain knowledge about the software product and
    its development [8].


    Therefore, software quality can be improved by creating and maintaining trace
    links [55]. For example, in collaborative development, TLR can help engineers
    to keep all artifacts synchronized and consistent [51]. Furthermore, traceability
    supports numerous critical software engineering tasks (cf. [7]). For example,
    trace links can improve the efficiency of software maintenance [33, 39], bug localization
    [53], change impact analysis [10], and system security [44, 46]. Trace links are
    also used to demonstrate the safety of systems [38, 40, 45]. Some standards, such
    as ISO 26262 about the functional safety of road vehicles, even mandate traceability.


    Despite all the benefits, the main drawback of traceability is the time-consuming
    and error-prone process of manually creating and maintaining trace links [9, 52].
    This is mainly due to the semantic gap between artifacts of different abstraction
    levels [3], e.g., requirements and code. Some (semi-)automated approaches have
    been designed to assist users but face the same challenge.


    Likewise, automated TLR approaches often only look at requirements and code. However,
    other types of artifacts, such as the documentation of the system''s software
    architecture, are just as relevant. A software''s architecture is key to successfully
    developing,'
  token_usage: 3646
  time_usage: 4.043757200241089
- title: Multidimensional Static Code Analysis Method for Automotive Software
  abstract: The accelerated development of automotive intelligence and connectivity
    has raised higher requirements for the quality and security of automotive software
    code. In this paper, a multi-dimensional static code analysis method is proposed
    by integrating lexical analysis with rule verification. This method employs Abstract
    Syntax Tree (AST) technology, data flow and control flow analysis techniques,
    combined with parallel analysis technology, to achieve comprehensive, accurate,
    and efficient static analysis of source code. Through comparative experimental
    validation, the static code analysis tool designed in this paper exhibits excellent
    performance in detection accuracy, efficiency, compatibility, and reliability,
    providing strong support for quality control and risk management in the software
    development process.**
  keywords: ''
  document: "# Multidimensional Static Code Analysis Method for Automotive Software\n\
    \nQiujun Zhao China Automotive Technology & Research Center Co. Ltd; CATARC Software\
    \ Testing (Tianjin) Co. Ltd Intelligent Communication Research Department Tianjin,\
    \ China zhaoqiujun@catarc.ac.cn\n\nShuhua Zhou China Automotive Technology & Research\
    \ Center Co. Ltd; CATARC Software Testing (Tianjin) Co. Ltd Intelligent Communication\
    \ Research Department Tianjin, China zhoushuhua@catarc.ac.cn\n\nZiwei Tian China\
    \ Automotive Technology & Research Center Co. Ltd; CATARC Software Testing (Tianjin)\
    \ Co. Ltd Intelligent Communication Research Department Tianjin, China tianziwei@catarc.ac.cn\n\
    \nYu Su China Automotive Technology & Research Center Co. Ltd; CATARC Software\
    \ Testing (Tianjin) Co. Ltd Intelligent Communication Research Department Tianjin,\
    \ China suyu@catarc.ac.cn\n\n*Abstract***—The accelerated development of automotive\
    \ intelligence and connectivity has raised higher requirements for the quality\
    \ and security of automotive software code. In this paper, a multi-dimensional\
    \ static code analysis method is proposed by integrating lexical analysis with\
    \ rule verification. This method employs Abstract Syntax Tree (AST) technology,\
    \ data flow and control flow analysis techniques, combined with parallel analysis\
    \ technology, to achieve comprehensive, accurate, and efficient static analysis\
    \ of source code. Through comparative experimental validation, the static code\
    \ analysis tool designed in this paper exhibits excellent performance in detection\
    \ accuracy, efficiency, compatibility, and reliability, providing strong support\
    \ for quality control and risk management in the software development process.**\n\
    \n### *Keywords—AST, Data Flow, Control Flow, Multidimensional Static Code Analysis,\
    \ Test tool, Automotive Software*\n\n# I. INTRODUCTION\n\nWith the rapid advancement\
    \ of automotive intelligence and networking, the quality and safety of software\
    \ code have become crucial considerations.[1] Although traditional code test and\
    \ analysis tools can assist developers in identifying code defects to some extent,\
    \ their built-in static code analysis methods are often limited to single dimensional\
    \ checks, such as syntax validation or security vulnerability scanning. This single\
    \ perspective analysis is difficult to comprehensively and profoundly reveal the\
    \ overall quality of the code, especially in the face of complex and hidden non\
    \ functional issues such as memory leaks, buffer overflows, null pointer references,\
    \ etc.[2] These tools are often inadequate and difficult to effectively detect\
    \ these problems.[3] In the current market, automotive code checking tools such\
    \ as Code Climate, Codacy, FindBugs, and Checkstyle each have their own advantages:\
    \ Code Climate provides comprehensive code quality assessment and visual display,\
    \ compatible with multiple programming languages and IDE extensions; Codacy focuses\
    \ on checking code quality, syntax compliance, and functional availability, but\
    \ SaaS service integration has limitations; FindBugs used to exist as a lightweight\
    \ Java static analysis tool, but it has now ceased maintenance;[4] Checkstyle,\
    \ on the other hand, focuses on code formatting and style specifications, with\
    \ relatively limited ability to detect bugs.[5] 863 2024 IEEE 4th International\
    \ Conference on Data Science and Computer Application (ICDSCA) 979-8-3503-6823-9/24/\\\
    $31.00 ©2024 IEEE Dalian, China, November 22-24, 2024 2024 IEEE 4th International\
    \ Conference on Data Science and Computer Application (ICDSCA) | 979-8-3503-6823-9/24/\\\
    $31.00 ©2024 IEEE | DOI: 10.1109/ICDSCA63855.2024.10859504\n\nTo enhance the accuracy\
    \ and efficiency of automotive code inspection, this paper proposes a multi-dimensional\
    \ static code analysis method that integrates lexical analysis with rule verification.\
    \ This method utilizes Abstract Syntax Tree (AST)[6] technology to trace the flow\
    \ of data within programs, precisely capturing issues such as data overflow. Simultaneously,\
    \ it combines control flow analysis[7] to deeply dissect program execution paths,\
    \ effectively revealing potential logical errors like null pointer references.\
    \ Furthermore, this method innovatively introduces parallel analysis technology,\
    \ employing dedicated parsers to process different MISRA C rules in parallel,\
    \ significantly reducing the analysis cycle. Additionally, it integrates test\
    \ tools to generate comprehensive test reports. This parallel processing mechanism\
    \ not only accelerates the detection process but also enhances the capability\
    \ to detect deep-seated and complex logical errors, providing more detailed and\
    \ accurate code quality feedback for quality control and risk management in the\
    \ software development process, thereby laying a solid foundation.\n\n# II. STATIC\
    \ CODE ANALYSIS METHOD\n\n#### *A. Multidimensional Static Code Analysis Method*\n\
    \nIn order to improve the efficiency of code detection, this article proposes\
    \ a method that can screen out code errors, defects, or non compliant issues in\
    \ the system without the need for comprehensive research on all details of the\
    \ system. This method integrates AST, data flow, control flow, and parallel processing\
    \ technologies, and constructs multiple unit modules to optimize the detection\
    \ efficiency of code analysis. The multidimensional static code analysis method\
    \ is divided into four units: code compilation, text syntax analysis, basic parser\
    \ verification, and sub-parser detection. The relationship between the units is\
    \ shown in Figure 1.\n\n![](_page_0_Figure_15.jpeg)\n\nFigure 1. Schematic diagram\
    \ of the units structure of multi-dimensional static code analysis method\n\n\
    #### (1) Code Compilation Unit\n\nCompile the source code to check for syntax\
    \ errors. If the compilation fails, the error messages will be generated and the\
    \ errors must be corrected before attempting to recompile. Upon successful compilation,\
    \ proceed to the subsequent static analysis steps. The specific steps are shown\
    \ in Figure 2.\n\n![](_page_1_Figure_1.jpeg)\n\nFigure 2. Flowchart of the code\
    \ compilation unit\n\n#### (2) Text Syntax Analysis Unit\n\nPerform syntax analysis\
    \ on successfully compiled source code to generate code structure files.[8] Figure\
    \ 3 shows the implementation process and explains it in detail:\n\nStep1: Read\
    \ the successfully compiled source code text from the input buffer. Use predefined\
    \ lexical rules to identify word boundaries and split the source code into lexical\
    \ units (Tokens).\n\nStep2: Classify the Tokens and identify their respective\
    \ categories (such as keywords, identifiers, constants, operators, etc.).\n\n\
    Step3: Assign corresponding tags to each classified Tokens and construct a linear\
    \ sequence of Tokens. During this process, irrelevant characters such as comments\
    \ and spaces will be removed from the source code to ensure the accuracy of the\
    \ analysis.\n\nStep4: If any grammar errors are found during the analysis process,\
    \ summarize the error messages and provide corresponding error prompts and repair\
    \ suggestions.\n\n![](_page_1_Figure_9.jpeg)\n\nFigure 3. Flowchart of the text\
    \ syntax analysis unit\n\n#### (3) Basic Parser Verification Unit\n\nBased on\
    \ the code structure file, perform parser verification on the source code to discover\
    \ potential code logic errors. The specific implementation process is shown in\
    \ figure 4 and explained below:\n\nStep1: Organize classified Tokens into an AST\
    \ according to predefined syntax rules. The formula is as follows:\n\n$$\nAST\
    \ = f(Tokens)\n$$\n (1)\n\nWhere f represents the function that converts Tokens\
    \ into the corresponding AST.\n\nStep2: Traverse the AST and perform data flow\
    \ and control flow analysis. Data flow analysis checks the definition, usage,\
    \ and assignment of variables to ensure that data flow meets expectations.[9]\
    \ Formula (2) encapsulates the core concept of data flow analysis.\n\n$$\nDflow(AST)\
    \ = Def(AST) \\cup Use(AST)\n$$\n (2)\n\nWhere Def(AST) represents the set of\
    \ definitions in AST, Use(AST) represents the set of uses for AST, and DFlow(AST)\
    \ denotes the result of the data flow analysis.\n\nControl flow analysis determines\
    \ the program execution path, checks the correctness of control structures (such\
    \ as loops and conditional statements), and detects issues such as dead code and\
    \ unreachable paths. The structure of the control flow graph is delineated by\
    \ the following formula:\n\n$$\nCFG = (Nodes, Edges) \\tag{3}\n$$\n\nWhere CFG\
    \ stands for the Control Flow Graph, Nodes represent the basic blocks or statements\
    \ in the code, and Edges depict the control flow between these nodes.\n\nStep3:\
    \ Pass the analyzed AST (including data flow and control flow analysis results)\
    \ to the symbol table for symbol analysis. Note that this step typically involves\
    \ using the analysis results to update or query the symbol table, rather than\
    \ directly outputting to it.\n\nStep4: Handle error situations, provide error\
    \ prompts and repair suggestions.\n\n![](_page_1_Figure_24.jpeg)\n\nFigure 4.\
    \ Flowchart of the basic parser verification unit\n\n#### (4) Sub Parser Detection\
    \ Unit\n\nBased on code structure files and code logic error information, develop\
    \ corresponding sub parsers for different MISRA C rules[10] to detect violations\
    \ of source code rules. Figure 5 shows the implementation process of this unit,\
    \ which is detailed below:\n\nStep1: Write corresponding sub parsers for each\
    \ MISRA C rule, with each sub parser inheriting from the base parser.\n\nStep2:\
    \ The sub parser provides a unified interface to receive source code files and\
    \ configuration files as inputs, and output analysis results and reports. The\
    \ configuration file can specify the MISRA C rule entries to be checked.\n\nStep3:\
    \ The sub parser module summarizes the analysis results, collects information\
    \ on rule violations, violation frequency, and severity, and displays the analysis\
    \ results and recommendations.\n\n| MISRA C rule 1 | MISRA C rule 2       | MISRA\
    \ C rule n |\n|----------------|----------------------|----------------|\n|  \
    \              |                      |                |\n| Sub parser 1   | Sub\
    \ parser 2         | Sub parser n   |\n|                |                    \
    \  |                |\n|                | Rule parsing results |             \
    \   |\n\nFigure 5. Flowchart of the sub parser detection unit\n\n#### *B. Tool\
    \ Integration*\n\nIn addition, based on the above static code, a memory and\n\n\
    processor device are provided, wherein the memory stores a computer program, and\
    \ the processor executes the steps of the multi-dimensional static code testing\
    \ and analysis method when the computer program is executed. And a visual report\
    \ generation unit is integrated into the test tool, which can summarize the final\
    \ parsing results based on code logic error information and rule parsing results\
    \ to generate visual reports. The report includes the following contents:\n\n\
    ①Line number: Display the specific line number where the rule was violated or\
    \ a defect was discovered.\n\n②Violation rule number: Display the specific rule\
    \ number violated.\n\n③Defect severity level: such as fatal, severe, warning,\
    \ etc.\n\n④Defect information: Provide a detailed description of the defect and\
    \ possible causes.\n\n⑤ Context information: Provide the context of code snippets\
    \ that violate rules or discover defects.\n\n⑥Suggested repair plan: Provide suggested\
    \ repair plans or best practices for each defect.\n\n⑦ Scope of Impact Analysis:\
    \ Analyze the impact of defects on system functionality, performance, or security.\n\
    \n⑧ Historical comparison: Compare the differences between current analysis results\
    \ and historical results.\n\n⑨Source code file path: Display the complete path\
    \ of the source code file.\n\n#### *C. Evaluation Metrics*\n\nIn order to fully\
    \ assess the detection effectiveness of static code analysis tools, the following\
    \ key metrics are used in this study:\n\n#### (1) Violations Number\n\nThis metric\
    \ measures the total number of potential problems or violations detected by the\
    \ tool in the code base. It reflects the tool's sensitivity and ability to detect\
    \ code quality.\n\n#### (2) False Positives\n\nFalse positives refer to instances\
    \ of code that the tool incorrectly flags as violations but are not actually problematic.\
    \ The level of false positives has a direct impact on developer trust and the\
    \ efficiency of the tool.\n\n(3) False Negatives\n\nFalse Negatives are the actual\
    \ offending code that the tool fails to detect. The level of False Negatives is\
    \ directly related to the accuracy and completeness of the tool's detection capability.\n\
    \nBy considering these metrics comprehensively, this study is able to comprehensively\
    \ assess the performance of static code analysis tools in practical applications\
    \ and provide data support for their improvement and optimization.\n\n#### III.\
    \ EXPERIMENTAL VERIFICATION\n\n# *A. Experimental conditions*\n\nTo verify the\
    \ effectiveness and practicality of the multidimensional static code analysis\
    \ method proposed in this paper, a detailed experimental plan was designed. The\
    \ experiment selected C language program sets from two automobile manufacturers\
    \ as the experimental objects, covering the logic code of automobile transmission\
    \ ECU control and automobile inverter INV control, respectively, as code sets\
    \ one and two. The specific information is shown in Table I.\n\n#### TABLE I EXPERIMENTAL\
    \ SUBJECTS\n\n| Code set   | . c files | . h files | Code's lines |\n|------------|-----------|-----------|--------------|\n\
    | Code set 1 | 186       | 44        | 102671       |\n| Code Set 2 | 421    \
    \   | 152       | 228544       |\n|            |           |           |     \
    \         |\n\nThe experimental environment configurations are shown in Table\
    \ II.\n\nTABLE II EXPERIMENTAL ENVIRONMENT\n\n| Configuration<br>Name |      \
    \               | Model                                                      |\
    \  |  |\n|-----------------------|---------------------|------------------------------------------------------------|--|--|\n\
    | hardware              | processor           | 11th Gen Intel(R) Core(TM) i7-1165G7<br>@\
    \ 2.80GHz 1.69 GHz |  |  |\n|                       | Memory              | 16.0\
    \ GB                                                    |  |  |\n| software  \
    \            | operating<br>system | Windows 11 Professional, 64 bit         \
    \                   |  |  |\n\n#### *B. Experimental Results and Comparison*\n\
    \nIn the same experimental environment, a comparative analysis was conducted on\
    \ the experimental subjects using the static code analysis device designed in\
    \ this article and three other code detection tools (C++Test, Codacy, and FindBugs)\
    \ for the above code set. The code set 1's experimental results are shown in figure\
    \ 6 and table III.\n\n![](_page_2_Figure_30.jpeg)\n\nFigure 6. Code Set 1 Test\
    \ Time\n\nTABLE III CODE SET 1 TEST RESULTS\n\n| Tools             | This<br>paper\
    \ | C++Test | Codacy | Find Bugs |\n|-------------------|---------------|---------|--------|-----------|\n\
    | Violations number | 677           | 593     | 509    | 668       |\n| false\
    \ positives   | 15            | 18      | 20     | 30        |\n| false negatives\
    \   | 64            | 151     | 237    | 88        |\n\nObserving the test results\
    \ of Code Set 1 in Table III, it was found that the total number of violations\
    \ detected by the tool in this paper is 677, slightly lower than Find Bugs, but\
    \ its false positives and false negatives were the lowest, proving that the device\
    \ in this article has high detection accuracy in static code analysis. Comparing\
    \ the test time in figure 6, it was found that the parsing of the device in this\
    \ article only takes 204 seconds. When the total number of detected violations\
    \ is similar, Find Bugs takes 394 seconds, which further proves that the detection\
    \ device in this article has high detection efficiency.\n\nThe code set 2's experimental\
    \ results are shown in figure 7 and table IV.\n\n![](_page_2_Figure_36.jpeg)\n\
    \n![](_page_2_Figure_37.jpeg)\n\nTABLE IV CODE SET 2 TEST RESULTS\n\n| Tools \
    \            | This paper | C++Test | Codacy | Find Bugs |\n|-------------------|------------|---------|--------|-----------|\n\
    | Violations number | 1202       | 986     | 934    | 1067      |\n| false positives\
    \   | 56         | 124     | 166    | 208       |\n| false negatives   | 300 \
    \       | 696     | 790    | 699       |\n\nAs shown in Table IV, the test tool\
    \ designed in this paper performs best on Code Set 2, with a total of 1202 violations\
    \ detected. The number of false positives and false negatives is as low as 56\
    \ and 300, respectively. Additionally, it boasts the shortest test time (figure\
    \ 7). These fully demonstrates that the detection tool designed in this paper\
    \ possesses high accuracy and efficiency.\n\nBesides, to verify the compatibility\
    \ and reliability of the device, tests are conducted on current mainstream operating\
    \ systems and processor architectures, and the test results are shown in Table\
    \ V.\n\nTABLE V EQUIPMENT COMPATIBILITY AND RELIABILITY TEST RESULTS\n\n| Operatin\
    \ | X86          | X86          | ARM          | ARM          |\n|----------|--------------|--------------|--------------|--------------|\n\
    | g system | architecture | architecture | architecture | architecture |\n| Windows\
    \  | compatible   | reliable     | compatible   | reliable     |\n| Linux    |\
    \ compatible   | reliable     | compatible   | reliable     |\n| macOS    | compatible\
    \   | reliable     | compatible   | reliable     |\n\nThe detection results show\
    \ that the test tool designed in this paper can be used normally in different\
    \ operating systems and processor architectures, indicating that the tool has\
    \ strong compatibility and reliability.\n\n#### IV. CONCLUSION\n\nThe multidimensional\
    \ static code analysis method and its application scenarios proposed in this paper\
    \ have significant advantages and practical value. This method integrates lexical\
    \ analysis and rule checking, AST technology, data flow and control flow analysis\
    \ technology, and parallel analysis technology, which can deeply, comprehensively,\
    \ and efficiently detect source code. The experimental results show that the static\
    \ code analysis device designed in this paper outperforms traditional tools such\
    \ as C++Test, Codacy, and FindBugs in terms of detection accuracy, efficiency,\
    \ compatibility, and reliability. In the code sets test provided by two car manufacturers,\
    \ this tool not only significantly reduced the number of false positives and false\
    \ negatives, but also greatly shortened the test time. In addition, the tool demonstrates\
    \ good compatibility and reliability across different operating systems and processor\
    \ architectures, providing solid quality assurance for software development. Looking\
    \ ahead to the future, we will continue to optimize and improve this method and\
    \ its equipment to enhance the level of intelligence, conduct cross platform optimization,\
    \ and expand functionality, in order to better meet the needs of software development\
    \ in the context of automotive intelligence and networking, and provide more comprehensive,\
    \ accurate, and efficient support for quality assurance and risk control in the\
    \ software development process.\n\n#### REFERENCES\n\n- [1] Fei Ding, Nan Zhang,\
    \ Shengbo Li, Yougang Bian, En Tong, Keqiang Li. Overview of the Architecture\
    \ and Key Technologies of Intelligent Connected Vehicle Road Cloud Collaboration\
    \ System [J]. Journal of Automation, 2022, 48 (12): 2863-2885\n- [2] Rezvina S.\
    \ Keep Code Review from Wasting Everyone's Time: Code Climate[J]. 2019.\n- [3]\
    \ Gautam S. Comparison of Java Programming Testing Tools[J]. International Journal\
    \ of Engineering Technologies and Management Research, 2020, 5(2): 66-76.\n- [4]\
    \ Hovemeyer, D.; Pugh, W. Finding bugs is easy. ACM SIGPLAN Not. 2004, 39, 92–106.\n\
    - [5] Yiu C C. Checkstyle for Legacy Applications[J].Itestra De. 2023.\n- [6]\
    \ Mou, L., Jin, Z. (2018). TBCNN for Programs' Abstract Syntax Trees. In: Tree-Based\
    \ Convolutional Neural Networks. SpringerBriefs in Computer Science.\n- [7] Springer,\
    \ Singapore. Schaumont, P.R. (2013). Analysis of Control Flow and Data Flow. In:\
    \ A Practical Introduction to Hardware/Software Codesign. Springer, Boston, MA.\n\
    - [8] Wang Z ,Jabar A A M ,Jalis M M F .Cross-Disciplinary Analysis of the Syntactic\
    \ and Lexical Features of Chinese Master Thesis Titles[J]. Theory and Practice\
    \ in Language Studies,2024,14(9):2760-2772.\n- [9] Mogensen, T. (2017). Data-Flow\
    \ Analysis and Optimisation. In: Introduction to Compiler Design. Undergraduate\
    \ Topics in Computer Science. Springer, Cham.\n- [10] Bagnara, R., Bagnara, A.,\
    \ Hill, P.M. (2018). The MISRA C Coding Standard and its Role in the Development\
    \ and Analysis of Safety- and Security-Critical Embedded Software. In: Podelski,\
    \ A. (eds) Static Analysis. SAS 2018. Lecture Notes in Computer Science, vol 11002.\
    \ Springer, Cham."
  decisions:
    evaluation_prompt: '- Qualified. Reason: The abstract mentions "comparative experimental
      validation" and discusses the performance of the static code analysis tool,
      indicating structured evaluation through experiments and metrics related to
      detection accuracy, efficiency, compatibility, and reliability.'
    related_work_prompt: '- Qualified. Reason: The paper discusses various existing
      automotive code checking tools and compares their capabilities, indicating engagement
      with prior research. It also references specific technologies and methods, demonstrating
      a clear connection to the existing body of work in static code analysis.'
    novelty_prompt: 'Qualified. Reason: The paper proposes a new multi-dimensional
      static code analysis method that integrates lexical analysis with rule verification,
      which is explicitly stated in both the abstract and introduction. This claim
      of novelty in methodology qualifies the paper for further consideration.'
    review_only_prompt: '- Qualified. Reason: The paper proposes a new multi-dimensional
      static code analysis method and discusses its implementation and experimental
      validation, indicating that it contains new contributions rather than just summarizing
      existing work.'
  llm_input_used: '## Abstract

    The accelerated development of automotive intelligence and connectivity has raised
    higher requirements for the quality and security of automotive software code.
    In this paper, a multi-dimensional static code analysis method is proposed by
    integrating lexical analysis with rule verification. This method employs Abstract
    Syntax Tree (AST) technology, data flow and control flow analysis techniques,
    combined with parallel analysis technology, to achieve comprehensive, accurate,
    and efficient static analysis of source code. Through comparative experimental
    validation, the static code analysis tool designed in this paper exhibits excellent
    performance in detection accuracy, efficiency, compatibility, and reliability,
    providing strong support for quality control and risk management in the software
    development process.**


    ## Introduction

    With the rapid advancement of automotive intelligence and networking, the quality
    and safety of software code have become crucial considerations.[1] Although traditional
    code test and analysis tools can assist developers in identifying code defects
    to some extent, their built-in static code analysis methods are often limited
    to single dimensional checks, such as syntax validation or security vulnerability
    scanning. This single perspective analysis is difficult to comprehensively and
    profoundly reveal the overall quality of the code, especially in the face of complex
    and hidden non functional issues such as memory leaks, buffer overflows, null
    pointer references, etc.[2] These tools are often inadequate and difficult to
    effectively detect these problems.[3] In the current market, automotive code checking
    tools such as Code Climate, Codacy, FindBugs, and Checkstyle each have their own
    advantages: Code Climate provides comprehensive code quality assessment and visual
    display, compatible with multiple programming languages and IDE extensions; Codacy
    focuses on checking code quality, syntax compliance, and functional availability,
    but SaaS service integration has limitations; FindBugs used to exist as a lightweight
    Java static analysis tool, but it has now ceased maintenance;[4] Checkstyle, on
    the other hand, focuses on code formatting and style specifications, with relatively
    limited ability to detect bugs.[5] 863 2024 IEEE 4th International Conference
    on Data Science and Computer Application (ICDSCA) 979-8-3503-6823-9/24/\$31.00
    ©2024 IEEE Dalian, China, November 22-24, 2024 2024 IEEE 4th International Conference
    on Data Science and Computer Application (ICDSCA) | 979-8-3503-6823-9/24/\$31.00
    ©2024 IEEE | DOI: 10.1109/ICDSCA63855.2024.10859504


    To enhance the accuracy and efficiency of automotive code inspection, this paper
    proposes a multi-dimensional static code analysis method that integrates lexical
    analysis with rule verification. This method utilizes Abstract Syntax Tree (AST)[6]
    technology to trace the flow of data within programs, precisely capturing issues
    such as data overflow. Simultaneously, it combines control flow analysis[7] to
    deeply dissect program execution paths, effectively revealing potential logical
    errors like null pointer references. Furthermore, this method innovatively introduces
    parallel analysis technology, employing dedicated parsers to process different
    MISRA C rules in parallel, significantly reducing the analysis cycle. Additionally,
    it integrates test tools to generate comprehensive test reports. This parallel
    processing mechanism not only accelerates the detection process but also enhances
    the capability to detect deep-seated and complex logical errors, providing more
    detailed and accurate code quality feedback for quality control and risk management
    in the software development process, thereby laying a solid foundation.'
  token_usage: 3808
  time_usage: 4.338926076889038
- title: 'Collaborative Sketching: Human-AI Collaboration Modes for Enhancing Designers''
    Performance and Experience in Sketching'
  abstract: '*Index Terms*—design sketching, designer-AI collaboration, generative
    AI, product design methods'
  keywords: design sketching, designer-AI collaboration, generative AI, product design
    methods
  document: "# Collaborative Sketching: Human-AI Collaboration Modes for Enhancing\
    \ Designers' Performance and Experience in Sketching\n\nQianya Lou<sup>1</sup>\
    \ , Yang Bai<sup>1</sup> , Haotian Ying<sup>2</sup> , Lei Cai<sup>1</sup> , Xinqi\
    \ Feng<sup>2</sup> , Xusheng Zhang<sup>1</sup><sup>∗</sup>\n\n<sup>1</sup>College\
    \ of Computer Science and Technology, Zhejiang University, Hangzhou, China\n\n\
    <sup>2</sup>Polytechnic Institute, Zhejiang University, Hangzhou, China\n\nEmail:\
    \ zhangxs001@zju.edu.cn\n\n### *Abstract*—The rapid development of artificial\
    \ intelligence (AI) technology is changing the working patterns of designers.\
    \ AI is becoming a key collaboration partner for designers, supporting them in\
    \ performing design tasks and inspiring creative thought. Although studies have\
    \ investigated the collaborative framework between designers and AI, its guidance\
    \ for specific design practices is limited. This study proposes three designer-AI\
    \ collaboration modes with typical operable processes during sketching. We conducted\
    \ a user experiment to compare the effects of different collaboration modes on\
    \ the quantity, novelty, variety of design outcomes, and the designer's experience.\
    \ The results show that the collaboration modes can significantly affect the sketch's\
    \ quantity and variety, as well as the designer's overall satisfaction. Our study\
    \ focuses on the sketching stage and mainly contributes to bridging the theoretical\
    \ research and design practice regarding designer-AI collaboration.\n\n*Index\
    \ Terms*—design sketching, designer-AI collaboration, generative AI, product design\
    \ methods\n\n# I. INTRODUCTION\n\nThe rapid development of artificial intelligence\
    \ (AI) technology is changing the working patterns of designers. AI is becoming\
    \ a key collaboration partner for designers, supporting them in not only performing\
    \ tasks such as information retrieval, data processing, idea visualization, and\
    \ style transfer [1], but also inspiring their creative thought [2]. Existing\
    \ research on the designer-AI collaboration framework mainly concentrates on basic\
    \ theoretical frameworks [3][4][5] and provides limited guidance for specific\
    \ design practices.\n\nTo help bridge the theoretical research and design practice,\
    \ this study focuses on the sketching stage and proposes three designer-AI collaboration\
    \ modes with typical operable processes during sketching: visual-aid, subcontract,\
    \ and cocreation. We conducted an experiment involving 30 participants to compare\
    \ the effects of different collaboration modes on the quantity, novelty, variety\
    \ of design outcomes, and the designer's experience. Results show that the co-creation\
    \ mode performs best in enhancing the sketch quantity and overall satisfaction,\
    \ while the visual-aid mode produces sketches with the most variety. Our findings\
    \ contribute to exploring better design workflow based on designer-AI collaboration.\n\
    \n# II. RELATED WORKS\n\n# *A. Designer-AI Collaboration*\n\nThe role of AI in\
    \ the design process is evolving from a mere auxiliary tool to a vital collaboration\
    \ partner for designers. AI and designers have complementary strengths: human\
    \ designers excel in problem insight and strategic thinking [6], while AI usually\
    \ outperforms them in tasks like information retrieval, data processing, idea\
    \ visualization, and style transfer [1]. Consequently, designers can use AI to\
    \ broaden their creative reach and enhance AI's performance by inputting their\
    \ expertise and tacit design knowledge, thus achieving a win-win situation. Although\
    \ concerns about \"AI replacing human labor\" remain, prioritizing collaboration\
    \ over competition is viewed as more advantageous for improving the capabilities\
    \ of humans and AI to coexist and co-create [6].\n\nDesigner-AI collaboration\
    \ has attracted increasing attention from researchers. At the beginning of this\
    \ century, Parasuraman et al. [7] proposed a human-computer trade-off model situated\
    \ between complete human autonomy and complete computer autonomy. They maintained\
    \ the assumption of zerosum competition in human-computer dynamics. Later, Muller\
    \ et al. [5] noted that the human-AI relationship involves not only competition\
    \ but also a collaborative growth of both human and AI initiatives. To explain\
    \ the creative process in the AI era, Wu et al. [6] proposed the human-AI cocreation\
    \ model and the concept of AI creativity. Although many studies have highlighted\
    \ AI's potential in design and the significance of human-AI collaboration, current\
    \ research primarily focuses on improving the theoretical frameworks for human-AI\
    \ collaboration and provides limited guidance for design practices. As sketching\
    \ is foundational to any design process, examining the designer-AI collaboration\
    \ mode in this context may provide valuable insights into the challenges AI poses\
    \ for design [8].\n\n# *B. Design Sketching with AI*\n\nSketching is a vital part\
    \ of the design process [9]. Its specific functions include supporting design\
    \ communication [10], externalizing and visualizing problems [11], facilitating\
    \ iterative reinterpretation [12], refining ideas [13], etc. Generally, sketching\
    \ serves as a visual thinking tool and helps stimulate designers' creativity [14].\n\
    \nThe rapid development of AI technology, particularly generative AI (GenAI),\
    \ empowers sketch creation in various aspects. GenAI is a branch of AI that focuses\
    \ on content generation. It has transformed the production of text, images, videos,\
    \ etc. When it comes to design, first, AI functions as a creative stimulation\
    \ tool [15] that generates diverse multimodal content and aids in solving fixation\
    \ effects [16]. Second, AI offers an efficient image editing tool, such as the\
    \ AI retouching function in Adobe Photoshop, which enables designers to develop\
    \ and iterate their sketches quickly. Third, to further boost efficiency, AI encourages\
    \ designers to improve their AI workflow. However, the uncertainty of AI capabilities\
    \ and the complexity of its outputs make it challenging for designers to grasp\
    \ AI's ability boundary in sketching [8]. It also raises the demand for designer's\
    \ ability to plan their collaboration mode with AI.\n\n# III. DESIGNER-AI COLLABORATION\
    \ MODES FOR DESIGN SKETCHING\n\nOptimizing the designer-AI collaboration mode\
    \ is essential to enhance designer-AI collaboration efficiency during sketching.\
    \ The benefits of a well-structured division of labor and workflow have been demonstrated\
    \ in the case of comparing the waterfall model and the agile development framework.\n\
    \nTo describe potential designer-AI collaboration modes in sketching, we propose\
    \ two dimensions: accessibility of the design object and accessibility of the\
    \ design process. The two dimensions decompose the domains of power for designers\
    \ and AI [7][5]. As shown in Fig. 1, the vertical axis represents design object\
    \ accessibility, indicating the proportion of design tasks accessible to AI; the\
    \ horizontal axis represents design process accessibility, related to the time\
    \ of AI's intervention in conceptualization [6]. We integrate these dimensions\
    \ to distinguish designer-AI collaboration modes during sketching and get three\
    \ modes: visual-aid, subcontract, and co-creation, ranked by AI initiative [5].\n\
    \n![](_page_1_Figure_4.jpeg)\n\nFig. 1. Designer-AI Collaboration Modes for Design\
    \ Sketching. <sup>∗</sup>As for optimization modes, we don't distinguish whether\
    \ the design object processed by AI is complete. Limited by current technological\
    \ conditions, designers still face challenges in precisely modifying sketches\
    \ with mainstream models like DALL·E 3, Stable Diffusion, and Midjourney.\n\n\
    The typical operational processes for the three collaboration modes are illustrated\
    \ in Fig. 2.\n\n- The visual-aid mode. AI merely serves as a sketch optimization\
    \ assistant for the designers and lacks the initiative to influence conception.\
    \ This mode features oneway commands and mostly includes a single round of dialog.\n\
    - The subcontract mode. Due to a clear division of labor, AI assists designers\
    \ with some easy design tasks and possesses some initiative to influence partial\
    \ conception. This mode features one-way task assignment and mostly includes a\
    \ single round of dialog.\n- The co-creation mode. AI and designers collaboratively\
    \ take responsibility for the complete design task and inspire each other throughout\
    \ the design process. AI's initiative increases further. This mode features continuous\
    \ two-way communication and includes multiple rounds of dialog.\n\n![](_page_1_Figure_10.jpeg)\n\
    \nFig. 2. Typical Processes of the Three Designer-AI Collaboration Modes.\n\n\
    # IV. METHODS\n\nIn the following section, we conducted a user experiment to compare\
    \ the effects of different collaboration modes on the design outcomes (quantity,\
    \ novelty, and variety) and the designer's experience. The only independent variable\
    \ was the designer-AI collaboration mode.\n\n# *A. Participant*\n\nWe recruited\
    \ 30 participants (16 females, 14 males, mean age = 22.17, SD = 1.56). They were\
    \ students from design disciplines such as industrial design, product design,\
    \ and digital media arts, each with at least two years of design experience (M\
    \ = 3.13, SD = 1.11). They all had basic experience with AI products and had used\
    \ AI tools for no more than 10 hours in the last three months.\n\n# *B. Procedure*\n\
    \nOur experiment utilized BingAI platform equipped with OpenAI's GPT-4 and DALL·E\
    \ 3. Before the experiment, all participants had 10 minutes to familiarize themselves\
    \ with the AI platform and the process.\n\nWe employed a Latin square design to\
    \ organize the participant grouping and task order. Participants were randomly\
    \ divided into six groups (Fig. 3), and each was required to experience the three\
    \ collaboration modes in a specified order to minimize impacts from learning effects\
    \ and fatigue. The design tasks differed in objects but had similar complexity\
    \ in the design object and application scenario. As in Fig. 4, each task lasted\
    \ 30 minutes, with a 15-minute break in between. During the break, they completed\
    \ a Net Promoter Score (NPS) questionnaire to report overall satisfaction. When\
    \ all tasks were completed, participants received a semi-structured interview\
    \ to report on their evaluation of communication efficiency, AI-generated content\
    \ quality, and collaboration fluency.\n\n![](_page_2_Figure_3.jpeg)\n\nFig. 3.\
    \ Tasks and Participants Grouping for the Experiment.\n\n# *C. Evaluation*\n\n\
    To facilitate the observation of user behavior, we recorded the computer interface\
    \ and AI-generated results throughout the experiment. The evaluation covered both\
    \ design outcomes and user experience.\n\n*Design Outcomes.* Dependent variables\
    \ included the quantity, novelty, and variety of sketches. The formula for novelty\
    \ [17] is (1), where m is the number of key functions or features, f is the weight,\
    \ and S is the score allocated to different proposals for specific functions.\
    \ The formula for diversity [17] is (2), where m is the number of key working\
    \ principles, f is the weight, S is the scores allocated to specific levels of\
    \ the working principle, b is the number of branches at a specific level, and\
    \ n is the total number of sketches.\n\n$$\nM_1 = \\sum_{j=1}^{m} f_j S_{1j}\n\
    $$\n (1)\n\n$$\nM_2 = \\sum_{j=1}^{m} f_j \\sum_{k=1}^{4} S_k b_k / n \\tag{2}\n\
    $$\n\n*User Experience.* We used the Net Promoter Score (NPS) questionnaire to\
    \ assess participants' overall satisfaction with\n\n![](_page_2_Figure_12.jpeg)\n\
    \n![](_page_2_Figure_14.jpeg)\n\nFig. 4. Experiment Procedure.\n\nthe three collaboration\
    \ modes. NPS is a customer feedback tool that asks respondents how likely they\
    \ are to recommend a product or service, helping researchers measure user loyalty\
    \ and satisfaction. To calculate the NPS value, we subtracted the percentage of\
    \ detractors (scores 0-6) from the percentage of promoters (scores 9-10). Moreover,\
    \ the results from the semi-structured interview constituted valuable supplements\
    \ to the quantitative results of both design outcomes and user experience.\n\n\
    # V. RESULTS AND DISCUSSION\n\n*Design Outcomes.* The experimental data are shown\
    \ in Table I and Fig. 5. The Shapiro-Wilk W test indicates a normal distribution\
    \ of data. According to one-way ANOVA, we found that the co-creation mode produced\
    \ the most sketches and the subcontract mode produced the least (p < 0.001). There\
    \ was no significant difference in novelty (p = 0.16). As for variety, the visual-aid\
    \ mode achieved the highest average score, and the co-creation mode achieved the\
    \ lowest (p < 0.001). Overall, (i) the visual-aid mode exhibited the most variety,\
    \ largely due to AI's ability to supplement and optimize design details automatically;\
    \ (ii) the co-creation mode generated the most sketches but the least diversity,\
    \ as some participants reported a tendency to iterate on specific ideas and neglect\
    \ exploration for diversity; (iii) the subcontract mode generated the fewest sketches,\
    \ primarily due to the contradiction between uncertain AI-generated results and\
    \ designers' expectations.\n\n*User Experience.* Participants reported the highest\
    \ overall satisfaction with the co-creation mode and the lowest with the visual-aid\
    \ mode (p < 0.001). In the co-creation mode, designers engaged in deep interaction\
    \ with AI during data collection and sketch generation, allowing AI to complete\
    \ tasks in ways more aligned with designer requirements, thus enhancing usability\
    \ and collaboration fluency ratings. In the visual-aid mode, users passively filtered\
    \ AI-generated results, easily resulting in dissatisfaction if the outputs did\
    \ not meet expectations.\n\nTABLE I MEANS OF NUMBER OF SKETCHES, NOVELTY, VARIETY,\
    \ AND NPS OF OVERALL SATISFACTION.\n\n| Evaluation                  | Experiment\
    \ Groups |             |             |\n|-----------------------------|-------------------|-------------|-------------|\n\
    | Dimensions                  | Visual-aid        | Subcontract | Co-creation\
    \ |\n| Sketch Quantity             | 7.88              | 4.00        | 12.63 \
    \      |\n| Novelty                     | 4.84              | 5.17        | 5.01\
    \        |\n| Variety                     | 9.56              | 8.55        |\
    \ 4.01        |\n| NPS of Overall Satisfaction | -40.00%           | 13.33%  \
    \    | 23.33%      |\n\n![](_page_3_Figure_4.jpeg)\n\nFig. 5. Visualization of\
    \ Experiment Results: Number of Sketches, Novelty, Variety, and NPS of Overall\
    \ Satisfaction.\n\n# VI. CONCLUSION\n\nThis study proposes three designer-AI collaboration\
    \ modes with typical operable processes during sketching. The user experiment\
    \ shows that the collaboration modes significantly affect the quantity and variety\
    \ of design outcomes and overall satisfaction, but have no significant impact\
    \ on the novelty. The co-creation mode performs best in enhancing the sketch quantity\
    \ and overall satisfaction, while the visual-aid mode produces sketches with the\
    \ most variety. Our study strengthens the evidence for AI's potential as an effective\
    \ design collaborator and helps designers improve the sketch-creation workflow\
    \ with AI. Future studies could further refine the processes of the existing modes\
    \ and assess the conclusions' applicability for other stages except sketching\
    \ and designers of different levels, thus providing broader theoretical and practical\
    \ support for human-AI collaborative design.\n\n### REFERENCES\n\n- [1] Y. Shi,\
    \ T. Gao, X. Jiao, and N. Cao, \"Understanding design collaboration between designers\
    \ and artificial intelligence: a systematic literature review,\" *Proceedings\
    \ of the ACM on Human-Computer Interaction*, vol. 7, no. CSCW2, pp. 1–35, 2023.\n\
    - [2] T. Lawton, K. Grace, and F. J. Ibarrola, \"When is a tool a tool? user perceptions\
    \ of system agency in human–ai co-creative drawing,\" in *Proceedings of the 2023\
    \ ACM Designing Interactive Systems Conference*, 2023, pp. 1978–1996.\n- [3] A.\
    \ Erlei, A. Sharma, and U. Gadiraju, \"Understanding choice independence and error\
    \ types in human-ai collaboration,\" in *Proceedings of the CHI Conference on\
    \ Human Factors in Computing Systems*, 2024, pp. 1–19.\n- [4] L. Yan, V. Echeverria,\
    \ G. M. Fernandez-Nieto, Y. Jin, Z. Swiecki, L. Zhao, D. Gasevi ˇ c, and R. Martinez-Maldonado,\
    \ \"Human-ai collab- ´ oration in thematic analysis using chatgpt: A user study\
    \ and design recommendations,\" in *Extended Abstracts of the CHI Conference on\
    \ Human Factors in Computing Systems*, 2024, pp. 1–7.\n- [5] M. Muller and J.\
    \ Weisz, \"Extending a human-ai collaboration framework with dynamism and sociality,\"\
    \ in *Proceedings of the 1st Annual Meeting of the Symposium on Human-Computer\
    \ Interaction for Work*, 2022, pp. 1–12.\n- [6] Z. Wu, D. Ji, K. Yu, X. Zeng,\
    \ D. Wu, and M. Shidujaman, \"Ai creativity and the human-ai co-creation model,\"\
    \ in *Human-Computer Interaction. Theory, Methods and Tools: Thematic Area, HCI\
    \ 2021, Held as Part of the 23rd HCI International Conference, HCII 2021, Virtual\
    \ Event, July 24–29, 2021, Proceedings, Part I 23*. Springer, 2021, pp. 171–190.\n\
    - [7] R. Parasuraman, T. B. Sheridan, and C. D. Wickens, \"A model for types and\
    \ levels of human interaction with automation,\" *IEEE Transactions on systems,\
    \ man, and cybernetics-Part A: Systems and Humans*, vol. 30, no. 3, pp. 286–297,\
    \ 2000.\n- [8] Q. Yang, A. Steinfeld, C. Rose, and J. Zimmerman, \"Re-examining\
    \ ´ whether, why, and how human-ai interaction is uniquely difficult to design,\"\
    \ in *Proceedings of the 2020 chi conference on human factors in computing systems*,\
    \ 2020, pp. 1–13.\n- [9] N. Cross, \"Natural intelligence in design,\" *Design\
    \ studies*, vol. 20, no. 1, pp. 25–39, 1999.\n- [10] S. A. Scrivener and S. M.\
    \ Clark, \"Sketching in collaborative design,\" *Interacting with virtual environments.\
    \ Wiley, Chichester, UK*, 1994.\n- [11] D. Kernohan, \"Externalizing the design\
    \ process,\" *Design Studies*, vol. 2, no. 1, pp. 27–32, 1981.\n- [12] D. A. Schon\
    \ and G. Wiggins, \"Kinds of seeing and their functions in designing,\" *Design\
    \ studies*, vol. 13, no. 2, pp. 135–156, 1992.\n- [13] G. F. Smith, \"Idea-generation\
    \ techniques: A formulary of active ingredients,\" *The Journal of Creative Behavior*,\
    \ vol. 32, no. 2, pp. 107–134, 1998.\n- [14] M. Hua, \"The roles of sketching\
    \ in supporting creative design,\" *The Design Journal*, vol. 22, no. 6, pp. 895–904,\
    \ 2019.\n- [15] P. Karimi, J. Rezwana, S. Siddiqui, M. L. Maher, and N. Dehbozorgi,\
    \ \"Creative sketching partner: an analysis of human-ai co-creativity,\" in *Proceedings\
    \ of the 25th international conference on intelligent user interfaces*, 2020,\
    \ pp. 221–230.\n- [16] D. P. Moreno, M. C. Yang, A. A. Hernandez, J. S. Linsey,\
    \ and K. L. ´ Wood, \"A step beyond to overcome design fixation: a design-by-analogy\
    \ approach,\" in *Design Computing and Cognition'14*. Springer, 2015, pp. 607–624.\n\
    - [17] J. Han, H. Forbes, and D. Schaefer, \"An exploration of how creativity,\
    \ functionality, and aesthetics are related in design,\" *Research in Engineering\
    \ Design*, vol. 32, no. 3, pp. 289–307, 2021."
  decisions:
    evaluation_prompt: 'Qualified. Reason: The introduction mentions conducting an
      experiment with 30 participants to compare different collaboration modes, which
      indicates structured evaluation through empirical methods.'
    related_work_prompt: 'Qualified. Reason: The introduction references existing
      research on designer-AI collaboration frameworks and discusses the limitations
      of prior work, indicating engagement with earlier studies. Additionally, it
      cites specific works to support its claims, demonstrating a clear connection
      to prior research.'
    novelty_prompt: 'Qualified. Reason: The introduction explicitly states that the
      study "proposes three designer-AI collaboration modes," indicating a new contribution
      to the field of design practices involving AI.'
    review_only_prompt: '- Qualified. Reason: The paper proposes new collaboration
      modes for designer-AI interaction and includes experimental results, indicating
      it presents original contributions rather than merely summarizing existing work.'
  llm_input_used: '## Abstract

    *Index Terms*—design sketching, designer-AI collaboration, generative AI, product
    design methods


    ## Introduction

    The rapid development of artificial intelligence (AI) technology is changing the
    working patterns of designers. AI is becoming a key collaboration partner for
    designers, supporting them in not only performing tasks such as information retrieval,
    data processing, idea visualization, and style transfer [1], but also inspiring
    their creative thought [2]. Existing research on the designer-AI collaboration
    framework mainly concentrates on basic theoretical frameworks [3][4][5] and provides
    limited guidance for specific design practices.


    To help bridge the theoretical research and design practice, this study focuses
    on the sketching stage and proposes three designer-AI collaboration modes with
    typical operable processes during sketching: visual-aid, subcontract, and cocreation.
    We conducted an experiment involving 30 participants to compare the effects of
    different collaboration modes on the quantity, novelty, variety of design outcomes,
    and the designer''s experience. Results show that the co-creation mode performs
    best in enhancing the sketch quantity and overall satisfaction, while the visual-aid
    mode produces sketches with the most variety. Our findings contribute to exploring
    better design workflow based on designer-AI collaboration.'
  token_usage: 1999
  time_usage: 4.086793899536133
- title: Deductive Software Architecture Recovery via Chain-of-thought Prompting
  abstract: 'As software evolves, software architecture recovery techniques can help
    for effective maintenance. We envision a deductive software architecture recovery
    approach supported by Large Language Models (LLMs). Unlike existing inductive
    (bottom-up) recovery techniques, which reconstruct architecture by considering
    the properties observed at implementation level, our top-down approach starts
    with architectural properties and seeks their manifestations in the implementation.
    It employs a known Reference Architecture (RA) and involves two phases: RA definition
    and code units classification. A proof-of-concept with GPT-4 emulates deductive
    reasoning via chain-of-thought prompting. It demonstrates the deductive SAR approach,
    applying it to the Android application K-9 Mail and achieving a 70% accuracy in
    classifying 54 classes and 184 methods. The future plans focus on evaluating and
    refining the approach through ground-truth assessments, deeper exploration of
    reference architectures, and advancing toward automated human-like software architecture
    explanations. We highlight the potential for LLMs in achieving more comprehensive
    and explainable software architecture recovery.'
  keywords: software architecture, software architecture recovery, deductive SAR,
    chain-of-thought prompting
  document: '# Deductive Software Architecture Recovery via Chain-of-thought Prompting


    Satrio Adi Rukmono Eindhoven University of Technology Eindhoven, The Netherlands
    Institut Teknologi Bandung Bandung, Indonesia s.a.rukmono@tue.nl


    Lina Ochoa Eindhoven University of Technology Eindhoven, The Netherlands l.m.ochoa.venegas@tue.nl


    Michel R.V. Chaudron Eindhoven University of Technology Eindhoven, The Netherlands
    m.r.v.chaudron@tue.nl


    # ABSTRACT


    As software evolves, software architecture recovery techniques can help for effective
    maintenance. We envision a deductive software architecture recovery approach supported
    by Large Language Models (LLMs). Unlike existing inductive (bottom-up) recovery
    techniques, which reconstruct architecture by considering the properties observed
    at implementation level, our top-down approach starts with architectural properties
    and seeks their manifestations in the implementation. It employs a known Reference
    Architecture (RA) and involves two phases: RA definition and code units classification.
    A proof-of-concept with GPT-4 emulates deductive reasoning via chain-of-thought
    prompting. It demonstrates the deductive SAR approach, applying it to the Android
    application K-9 Mail and achieving a 70% accuracy in classifying 54 classes and
    184 methods. The future plans focus on evaluating and refining the approach through
    ground-truth assessments, deeper exploration of reference architectures, and advancing
    toward automated human-like software architecture explanations. We highlight the
    potential for LLMs in achieving more comprehensive and explainable software architecture
    recovery.


    # CCS CONCEPTS


    • Software and its engineering → Software maintenance tools.


    ## KEYWORDS


    software architecture, software architecture recovery, deductive SAR, chain-of-thought
    prompting


    #### ACM Reference Format:


    SatrioAdi Rukmono, Lina Ochoa, and Michel R.V. Chaudron. 2024. Deductive Software
    Architecture Recovery via Chain-of-thought Prompting. In New Ideas and Emerging
    Results (ICSE-NIER''24), April 14–20, 2024, Lisbon, Portugal. ACM, New York, NY,
    USA, 5 pages. https://doi.org/10.1145/3639476.3639776


    # 1 INTRODUCTION


    During the evolution of software, the source code typically changes in ways that
    violate the integrity of the architecture of a system. This results in degradation
    in the form of drift or erosion [21]. To


    ![](_page_0_Picture_15.jpeg)


    This work licensed under Creative Commons Attribution-NonCommercial International
    4.0 License.


    ICSE-NIER''24, April 14–20, 2024, Lisbon, Portugal © 2024 Copyright held by the
    owner/author(s). ACM ISBN 979-8-4007-0500-7/24/04. https://doi.org/10.1145/3639476.3639776


    detect such degradation, one needs to compare a representation of the system''s
    intended architecture to the implementation.


    Link et al. define Software Architecture Recovery (SAR) as "the process of recovering
    a system''s architecture from its implementation artifacts, such as its source
    code" [11]. SAR is of special importance when documentation about the system''s
    architecture is outdated, incomplete, or simply lacking [11, 19]. To the best
    of our knowledge, current SAR techniques follow what we call an inductive recovery,
    where certain facts from the source code (e.g. software components, control- and
    data-flow dependencies, textual input) are extracted and clustered to recover
    the structure of the current architecture [1–3, 8, 16, 23]. However, we posit
    that to manage the deterioration of a system''s architecture—and consequently
    rectify its evolution—one must follow a deductive recovery approach. That is,
    a known reference architecture [22] should be provided to assess how the current
    implementation deviates from the intended system architecture design.


    In our approach, the Reference Architecture (RA) is an abstract representation
    of key aspects of an architectural design. Our RA considers two viewpoints: the
    component viewpoint, which is concerned with the structure and grouping of the
    elements, and the interaction viewpoint, which focuses on the interaction and
    coordination among components [22].


    To illustrate the rationale for our deductive approach, consider the notion of
    layering in architecture. Existing techniques for recovering architectural layers
    involve analyzing a system''s dependency graph to look for classes that no other
    class depends on, designating them as top-layer classes. However, when a human
    developer is getting acquainted with an unfamiliar system that employs a layered
    architecture, they often start by recognizing that the top layer in such system
    typically corresponds to the presentation layer, which comprises classes responsible
    for User Interface (UI) widgets such as buttons and text fields [22]. Hence, when
    a developer encounters a class that deals with UI buttons, they can deductively
    infer that the class belongs to the top layer. This approach thus relates to the
    observation that many existing recovery techniques "do not reflect the way engineers
    actually map entities to components" [8]. In particular, there is an aspect of
    the semantics of the implementation that current recovery techniques do not take
    into account.


    To bridge the aforementioned gap, we present in Section 2 our vision of deductive
    software architecture recovery, an approach that classifies code units (e.g.,
    methods, classes) according to an RA. We demonstrate our vision via a proof of
    concept in Section 3 that utilizes transformer-based language models and chain-of-thought
    prompting to emulate deductive reasoning. We apply the deductive SAR approach
    to the Android application K-9 Mail to obtain preliminary results on the feasibility
    of the approach in Section 4. Future research directions and conclusions are elaborated
    in Section 5 and Section 6.


    # 2 VISION: DEDUCTIVE SOFTWARE ARCHITECTURE RECOVERY


    In this section, we describe the general approach for deductive software architecture
    recovery. The approach is depicted in Figure 1. It is structured into two phases:
    the RA definition phase and the code units classification phase. These phases,
    along with their corresponding steps, are described below.


    ![](_page_1_Figure_5.jpeg)


    Figure 1: The general approach for deductive SAR.


    #### 2.1 Phase I: Reference Architecture Definition


    The first phase of deductive SAR consists of defining the RA to be used in the
    recovery process. The RA provides a blueprint to classify and organize the architectural
    elements recovered from the system''s source code. We emphasize that by reference
    architecture, we do not mean an actual instance of architecture with specific
    components rather, it is an abstract description of how architectural elements
    are organized.


    Step 1: Select the reference architecture. The RA that applies to a particular
    software system is intended to come from one of the system''s architects or engineers.
    In case this is not available, it may suffice to select one of the more common
    RA—e.g., layered architecture, pipes-and-filters [22], and model-view-controller
    (MVC) [5]. The approach applies broadly to any reference architecture, as long
    as one can describe it in terms of components and interactions between components,
    as elaborated in the next steps.


    Step 2: Define the architectural components. This step focuses on the component
    viewpoint of the RA definition. The natural course of action is, therefore, to
    define the distinct architectural components that are to be used as a reference
    for later code unit classification. Note that the component terminology pertains
    to the general organization of elements as suggested by Wirfs-Brock et al. [22].
    For


    example, in a layered architecture, the components include, e.g., presentation
    layer and application services layer, while in an MVC architecture, the components
    are models, views, and controllers.


    Step 3: Define component- & interaction-indicators. To complete the definition
    of the RA, this step focuses on how architectural components and interactions
    between them are manifested in source code. In particular, each architectural
    component (defined in Step 2) holds a specific responsibility that also defines
    how components interact with each other. This step, thus, involves breaking down
    these responsibilities and interactions into a set of specific indicators that
    source code units (e.g., methods, classes) corresponding to the particular architectural
    component may exhibit. The indicators may come from best practices of the particular
    RA. They can also depend on the specific technology stack used to implement the
    system.


    #### 2.2 Phase II: Code Units Classification


    In this phase, source code units are evaluated and classified into an architectural
    components-type as defined in the RA definition phase. The results are then aggregated,
    and this process cascades to code units defined at a higher level of abstraction
    until the system''s architecture is recovered:


    Step 4: Evaluate source code units against indicators. In this phase, low-level
    source code units are classified into the componenttypes specified in Step 2.
    A low-level source code unit is defined as a source code construct at the lowest
    level of abstraction for analytical purposes. Instances of low-level units can
    include statements, methods, or classes. To perform the classification, the approach
    evaluates whether the syntax and semantics of these units align with the indicators
    defined for each architectural component. This shows the deductive nature of our
    recovery approach: we start with a set of architectural properties and try to
    find evidences within the implementation, rather than starting with properties
    exhibited by the implementation. We leave the details of the compliance analysis
    non-specific here, firstly, because the details may vary depending on each indicator
    and RA, and secondly, to keep it open to the application of diverse techniques.
    However, as we demonstrate in the coming sections, the idea of deductive SAR is
    sparked and made effective by transformer-based language models, specifically
    via the chain-of-thought prompting technique, which entices deductive pseudo-reasoning
    in LLMs via step-by-step "thinking" process.


    Step 5: Aggregate the classification results. After evaluating and classifying
    individual source code units, the subsequent task involves aggregating this information
    to classify more abstract compositions of source code units. For instance, if
    the preceding step involved classifying methods, this current step entails aggregating
    that information to classify classes. Subsequently, this aggregation process can
    extend to higher abstraction levels, facilitating the construction of a comprehensive
    depiction of the system''s architecture.


    In the following section, we showcase an instance of the deductive SAR approach
    and its application to an open-source system.


    #### 3 PROOF OF CONCEPT


    Recently, Large Language Models (LLMs) have been applied to support different
    coding-based tasks in the software engineering practice. Examples of such tasks
    include defect and clone detection, code comprehension, code summarization, among
    others [13]. Deductive Software Architecture Recovery via Chain-of-thought Prompting
    ICSE-NIER''24, April 14–20, 2024, Lisbon, Portugal


    However, software engineering is not limited to coding and this technology can
    be leveraged to perform effective software design and maintenance. In this section,
    we demonstrate how we leverage GPT4, a transformer-based language model, to emulate
    deductive reasoning in deductive SAR, and support the RA definition using natural
    language.


    In this proof of concept, we aim to recover the architecture of the Android email
    application, K-9 Mail. We first select a layered architecture (Step 1). We follow
    a description of layered architecture [22] that includes the following architectural
    components and their responsibilities (Step 2): (1) the presentation layer [Pr]
    provides interfaces to interact with the user; (2) the application services layer
    [Ap] controls flow and coordinates responses to events; (3) the domain services
    layer [Do] provides information and services related to the system''s problem
    domain, and; (4) the technical services layer [Te] connects to external devices
    and programs.


    For Step 3, we elect to define the architectural control indicators at the method
    level, i.e., each indicator describes a characteristic of a typical Java method
    in an Android application for an architectural component. To illustrate this,
    an excerpt of the indicators we use for the proof-of-concept is shown in Table
    1. Thanks to the LLM, the indicators can be specified in natural language without
    the need of depending on any sort of domain specific language. However, the results
    of the recovery process might be hindered if the RA is not properly defined.


    #### Table 1: Sample indicators for components of layered architecture in an Android
    email client.


    | № |  | Indicator (A method in this layer ) |  |  |

    |---|--|-------------------------------------|--|--|

    |---|--|-------------------------------------|--|--|


    |     | Presentation Layer [Pr]                                          |

    |-----|------------------------------------------------------------------|

    | Pr1 | . sets the attributes of UI components, e.g., sets the text of a |

    |     | TextView.                                                        |

    | Pr2 | . notifies listeners about user events, such as button clicks or |

    |     | list item selections.                                            |

    | Pr3 | . transforms domain objects into visual representations.         |

    | Pr4 | . performs validation on user input.                             |

    |     | Technical Services Layer [Te]                                    |

    | Te1 | .interacts with databases or other persistence services, e.g.,   |

    |     | inserts a row into an SQLite database.                           |

    | Te2 | . performs network operations, e.g., sends a request to an       |

    |     | email server.                                                    |

    | Te3 | .interacts with the file system, e.g., saves an email attachment |

    |     | to disk.                                                         |

    | Te4 | . uses Android''s hardware-related APIs, e.g., checks if the      |

    |     | device is connected to the internet.                             |


    As we move on to the code units classification phase, we digress from the details
    of the steps to discuss the role of static analysis and LLMs for achieving the
    classification. In classical SAR techniques, analysis of software units is performed
    based on information extracted from static analysis—such as metrics and dependency
    graphs. In our approach, indicators are phrased in natural language and can be
    either generic or application-specific.


    Relying on static analysis for our classification would lead into roadblocks.
    For example, checking for code statements that write data to a file [Te3] is possible
    (e.g., in Java: statements that call the methods of BufferedWriter), but some
    indicators are harder to implement as static analysis—e.g., there can be countless
    ways that domain objects can be transformed into visual representations [Pe3].
    Even with the indicators that can be implemented as static analysis, there can
    be variations, and they may depend a lot on the specific implementation technology,
    which may prevent good recall. The Te3 example above will not work, for instance,
    when the class in question depends on another class that wraps BufferedWriter
    instead of using it directly.


    On the other hand, LLMs are trained with vast amounts of data including source
    code from various programming languages, frameworks, and problem domains. This
    makes it work particularly well for classification and clustering tasks [6], providing
    opportunities for LLM utilization to evaluate source code units against the sets
    of indicators. In particular, our approach benefits from the ''semantic clustering''
    in LLMs that manifests from the notion of similarity in embedding models that
    they utilize [7, 12].


    We return to the classification phase in our proof of concept. For Step 4, we
    perform the classification of Java methods with the help of OpenAI''s GPT-4 model
    [14]. We construct LLM prompts asking to evaluate Java methods against each control
    indicator in a chain-of-thought manner [20]. Every single prompt includes: (1)
    information about the system and its problem domain, (2) the qualified name of
    the class that contains the method, (3) the method''s source code, (4) the architectural
    layer being evaluated, including a description of its responsibility, and (5)
    all control indicators for the architectural layer. The prompt continues with
    a request to check whether the method satisfies each indicator and specify the
    reasoning. For ease of output parsing, we ask the LLM to end its response with
    a boolean list corresponding to the "verdict" for each indicator. The prompt template
    that we use can be found in Figure 2. We ask the LLM to end its response in a
    specific format for ease of parsing.


    | In a layered software architecture, one of the layers is the<br>(layer_name)
    layer, which (layer_responsibility). |

    |-------------------------------------------------------------------------------------------------------------------|

    | Consider the context of an Android Java project "(project_name)":<br>(project_domain_description)                 |

    | Here are some indicators that a Java method in the project may<br>belong to
    a class in the (layer_name) layer:    |

    | (layer_indicators)                                                                                                |

    | The class ''(class_name)'' contains the method ''(method_name)'':                                                     |

    | (method_source_code)                                                                                              |

    | Check whether this method satisfies each indicator above. Mention                                                 |

    | the specific line of code that supports your reason. At the very last                                             |

    | line, write the boolean verdicts separated by a comma, e.g., ''true,                                               |

    | true, false, true''. If indeterminate, say ''false''.                                                                |


    #### Figure 2: Prompt template for method classification.


    Finally, our proof of concept ends with Step 5, in which we aggregate the method
    evaluation results at the class level. We do this by counting how many times each
    indicator appear in a class. We then decide the layer for each class based on
    which indicated layer dominates the class.


    #### 4 PRELIMINARY RESULTS AND ANALYSIS


    To initiate the evaluation of our approach, we implemented the technique on a
    subset of K-9 Mail, version 5.304<sup>1</sup> . We randomly selected 54 out of
    779 classes to apply deductive SAR. We commenced by defining our own reference
    layered architecture for each selected class through manual inspection of their
    source code. Then, we extracted the source code of the public methods from each
    class, totaling 184 methods. Subsequently, we executed the LLM request for each
    method and architectural layer. We then tallied the number of times an indicator
    is exhibited by the methods of each class and assign the class to the architectural
    layer with the most indicator occurrences. Notice that in different implementations,
    engineers can set the classification thresholds based on their own criteria.


    In the K-9 Mail case, we found that each Java package contains classes either
    from a single layer, or two adjacent layers. This suggests a good source code
    organizational choice. The relative comparison between our automated classification
    and the manual one is presented in Figure 3. It exhibits an overall accuracy—fraction
    of corrected classified cases—of 70%, with additional classification performance
    metrics provided in Table 2. In cases with tied aggregates, i.e., code units that
    are classified into two different layers, we consider them to be true positives
    as long as one of the predicted label matches the manually classified layer.


    |                    |    |    |   | Automated<br>classification |    |       |

    |--------------------|----|----|---|-----------------------------|----|-------|

    |                    |    | Pr |   | Ap Do                       | Te | Total
    |

    |                    | Pr | 8  | 1 | 1                           | 1  | 11    |

    | Manual<br>classif. | Ap | 4  | 7 | 2                           | 0  | 13    |

    |                    | Do | 0  | 0 | 13                          | 0  | 13    |

    |                    | Te | 1  | 2 | 4                           | 10 | 17    |


    Figure 3: Confusion matrix for sampled classes of K-9 Mail.


    Table 2: Summary of the preliminary experiment results.


    |           | Average | Layer |     |      |     |  |  |

    |-----------|---------|-------|-----|------|-----|--|--|

    |           |         | Pr    | Ap  | Do   | Te  |  |  |

    | Precision | 72%     | 62%   | 70% | 65%  | 91% |  |  |

    | Recall    | 71%     | 73%   | 54% | 100% | 59% |  |  |

    | F1-score  | 69%     | 67%   | 61% | 79%  | 71% |  |  |


    #### 5 FUTURE PLANS


    To reach our vision, we have defined a research roadmap that focuses on the following
    three main aspects.


    Evaluation of the current approach. As stated by Garcia et al., SAR techniques
    usually suffer from inaccuracies that are hardly detected due to the lack of reference
    architectures [9]. Reflecting the exact intended architecture of a system, as
    envisioned by its architect(s), is a daunting task. Garcia et al. proposed to
    recover the so-called ground-truth architectures. These architectures are obtained
    by performing a SAR technique that extracts an authoritative


    architecture—an architecture generated without the involvement of the system''s
    experts—and then putting it under the scrutiny of the system''s engineers to correct
    or complete it. We aim to reuse the existing ground-truth architectures of four
    open-source systems (i.e., Apache Hadoop, Bash, ArchStudio, and Apache OODT) [9]
    to perform an accuracy evaluation of the output of our approach. Additionally,
    we plan to conduct industrial case studies. We aim for qualitative studies in
    the form of field experiments [18] where the systems'' experts are consulted to
    validate the recovered architecture and the followed process. If the studied companies
    consent, these recovered architectures can be fed back into the set of ground-truth
    architectures available for future research.


    Research on reference architectures. Our proposed technique relies on the definition
    of a reference architecture. In the future, we plan to dive deeper into this area
    and design a "gold standard" RA including its components, interactions, and indicators—that
    works reasonably well for general-purpose software architecture recovery. The
    existence of such reference can then eliminate phase I for the majority of cases.
    We intuit that layered architecture is a good base for a gold standard, because,
    regardless of the specific architecture, software systems can always be divided
    into parts that communicate with clients (e.g., users or other systems) and parts
    that communicate with the hardware.


    Software architecture explanation. The ultimate step in this research line is
    to be able to provide software architecture explanations in a human-like manner.
    This approach aims at addressing the well-known problem of incomplete, dispersed,
    or dated documentation of a system [2, 4, 17]. We advocate extending the on-demand
    developer documentation proposed by Robillard et al. [15] to an ondemand software
    architecture explanation. We speculate that such explanations should maintain
    the question-answering style that arises naturally in certain software engineering
    scenarios, such as onboarding processes, where an engineer needs to quickly become
    familiar with the system to be productive [10], or during an architecture conformance
    check, where the alignment of the current architecture with the intended design
    decisions is subject to examination.


    #### 6 CONCLUSIONS


    We have presented our vision for deductive software architecture recovery and
    its concretization using LLMs. LLMs favor the definition of a reference architecture
    using natural language and help exploiting both syntactic and semantic aspects
    of the system''s implementation to recover its architecture. The deductive SAR
    approach shows promising results after applying it to a sample of 54 classes in
    the K-9 Mail application spanning 184 Java methods. Our approach exhibits a 70%
    accuracy for this specific case. However, further evaluation needs to be performed
    using ground-truth- and industrial-architectures. We, therefore, expect our approach
    to benefit the field of software architecture recovery by aligning better with
    how software is designed, and allowing explainable software architecture recovery:
    when deciding if a source code unit complies with a particular architectural component,
    our indicators written using natural language are used to explain why. This is
    a step forward in the quest of providing software architecture explanations in
    a human-like manner.


    <sup>1</sup>https://github.com/thundernest/k-9/tree/5.304


    Deductive Software Architecture Recovery via Chain-of-thought Prompting ICSE-NIER''24,
    April 14–20, 2024, Lisbon, Portugal


    ### REFERENCES


    - [1] Alvine Boaye Belle, Ghizlane El Boussaidi, and Sègla Kpodjedo. 2016. Combining
    Lexical and Structural Information to Reconstruct Software Layers. Information
    and Software Technology 74 (2016), 1–16. https://doi.org/10.1016/j.infsof.2016.01.
    008

    - [2] Tingting Bi, Peng Liang, Antony Tang, and Chen Yang. 2018. A Systematic
    Mapping Study on Text Analysis Techniques in Software Architecture. Journal of
    Systems and Software 144 (2018), 533–558. https://doi.org/10.1016/j.jss.2018.
    07.055

    - [3] Ghizlane El Boussaidi, Alvine Boaye Belle, Stéphane Vaucher, and Hafedh
    Mili. 2012. Reconstructing Architectural Views from Legacy Systems. In 2012 19th
    Working Conference on Reverse Engineering. 345–354. https://doi.org/10.1109/ WCRE.2012.44

    - [4] Rafael Capilla, Anton Jansen, Antony Tang, Paris Avgeriou, and Muhammad
    Ali Babar. 2016. 10 Years of Software Architecture Knowledge Management: Practice
    and Future. Journal of Systems and Software 116 (2016), 191–205. https://doi.
    org/10.1016/j.jss.2015.08.054

    - [5] John Deacon. 2009. Model-view-controller (MVC) Architecture. Online][Citado
    em: 10 de março de 2006.] http://www. jdl. co. uk/briefings/MVC. pdf 28 (2009).

    - [6] Bosheng Ding, Chengwei Qin, Linlin Liu, Lidong Bing, Shafiq Joty, and Boyang
    Li. 2022. Is GPT-3 a good data annotator? arXiv preprint arXiv:2212.10450 (2022).

    - [7] Ábel Elekes, Martin Schäler, and Klemens Böhm. 2017. On the various semantics
    of similarity in word embedding models. In 2017 ACM/IEEE Joint Conference on Digital
    Libraries (JCDL). IEEE, 1–10.

    - [8] Joshua Garcia, Igor Ivkovic, and Nenad Medvidovic. 2013. A Comparative Analysis
    of Software Architecture Recovery Techniques. In 28th IEEE/ACM International Conference
    on Automated Software Engineering. 486–496. https: //doi.org/10.1109/ASE.2013.6693106

    - [9] Joshua Garcia, Ivo Krka, Chris Mattmann, and Nenad Medvidovic. 2013. Obtaining
    Ground-truth Software Architectures. In 35th International Conference on Software
    Engineering. 901–910. https://doi.org/10.1109/ICSE.2013.6606639

    - [10] An Ju, Hitesh Sajnani, Scot Kelly, and Kim Herzig. 2021. A Case Study of
    Onboarding in Software Teams: Tasks and Strategies. In IEEE/ACM 43rd International
    Conference on Software Engineering. 613–623. https://doi.org/10.1109/ICSE43902.
    2021.00063

    - [11] Daniel Link, Pooyan Behnamghader, Ramin Moazeni, and Barry Boehm. 2019.
    The Value of Software Architecture Recovery for Maintenance. In Proceedings of
    the 12th Innovations on Software Engineering Conference (Formerly Known as India
    Software Engineering Conference). Association for Computing Machinery, New York,
    Article 17, 10 pages. https://doi.org/10.1145/3299771.3299787

    - [12] Claudio Lucchese, Giorgia Minello, Franco Maria Nardini, Salvatore Orlando,
    Raffaele Perego, and Alberto Veneri. 2023. Can Embeddings Analysis Explain Large
    Language Model Ranking?. In Proceedings of the 32nd ACM International Conference
    on Information and Knowledge Management. 4150–4154.

    - [13] Changan Niu, Chuanyi Li, Vincent Ng, Dongxiao Chen, Jidong Ge, and Bin
    Luo. 2023. An Empirical Comparison of Pre-trained Models of Source Code. arXiv
    (2023). https://doi.org/10.48550/arXiv.2302.04026

    - [14] OpenAI. 2023. GPT-4 technical report. Technical Report. OpenAI. https://doi.
    org/10.48550/arXiv.2303.08774

    - [15] Martin P. Robillard, Andrian Marcus, Christoph Treude, Gabriele Bavota,
    Oscar Chaparro, Neil Ernst, Marco Aurélio Gerosa, Michael Godfrey, Michele Lanza,
    Mario Linares-Vásquez, Gail C. Murphy, Laura Moreno, David Shepherd, and Edmund
    Wong. 2017. On-demand Developer Documentation. In IEEE International Conference
    on Software Maintenance and Evolution. 479–483. https://doi.org/10.1109/ICSME.2017.17

    - [16] Amir M. Saeidi, Jurriaan Hage, Ravi Khadka, and Slinger Jansen. 2015. A
    Searchbased Approach to Multi-view Clustering of Software Systems. In IEEE 22nd
    International Conference on Software Analysis, Evolution, and Reengineering. 429–
    438. https://doi.org/10.1109/SANER.2015.7081853

    - [17] Christoph Johann Stettina and Werner Heijstek. 2011. Necessary and Neglected?
    An Empirical Study of Internal Documentation in Agile Software Development Teams.
    In Proceedings of the 29th ACM International Conference on Design of Communication.
    Association for Computing Machinery, New York, 159–166. https://doi.org/10.1145/2038476.2038509

    - [18] Klaas-Jan Stol and Brian Fitzgerald. 2018. The ABC of Software Engineering
    Research. ACM Trans. Softw. Eng. Methodol. 27, 3, Article 11 (sep 2018), 51 pages.
    https://doi.org/10.1145/3241743

    - [19] Richard N. Taylor, Nenad Medvidovic, and Eric M. Dashofy. 2009. Software
    architecture: foundations, theory, and practice. Wiley Publishing.

    - [20] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Brian Ichter, Fei
    Xia, Ed Chi, Quoc V Le, and Denny Zhou. 2022. Chain-of-Thought Prompting Elicits
    Reasoning in Large Language Models. In Advances in Neural Information Processing
    Systems, S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (Eds.),
    Vol. 35. Curran Associates, Inc., 24824–24837.

    - [21] Erik Whiting and Sharon Andrews. 2020. Drift and Erosion in Software Architecture:
    Summary and Prevention Strategies. In 4th International Conference on Information
    System and Data Mining. Association for Computing Machinery,


    New York, 132–138. https://doi.org/10.1145/3404663.3404665


    - [22] Rebecca Wirfs-Brock, Alan McKean, Ivar Jacobson, and John Vlissides. 2002.
    Object Design: Roles, Responsibilities, and Collaborations. Pearson Education.

    - [23] Tianfu Yang, Zhiyong Jiang, Yanhong Shang, and Monire Norouzi. 2021. Systematic
    Review on Next-generation Web-based Software Architecture Clustering Models. Computer
    Communications 167 (2021), 63–74. https://doi.org/10.1016/j. comcom.2020.12.022


    Received 14 September 2023; accepted 22 November 2023'
  decisions:
    evaluation_prompt: 'Qualified. Reason: The abstract mentions a proof-of-concept
      that applies the deductive software architecture recovery approach to the Android
      application K-9 Mail, achieving a 70% accuracy in classifying code units, indicating
      empirical evaluation. Additionally, the future plans include evaluating and
      refining the approach through ground-truth assessments, which suggests structured
      evaluation is part of the research.'
    related_work_prompt: 'Qualified. Reason: The paper engages with prior research
      by referencing existing Software Architecture Recovery (SAR) techniques and
      comparing its proposed deductive approach to these inductive methods. It cites
      specific works and definitions, indicating a clear connection to the existing
      body of knowledge in the field.'
    novelty_prompt: 'Qualified. Reason: The paper proposes a new deductive software
      architecture recovery approach that utilizes Large Language Models (LLMs) and
      contrasts it with existing inductive techniques, indicating a novel contribution
      to the field.'
    review_only_prompt: '- Qualified. Reason: The paper proposes a new deductive software
      architecture recovery approach supported by Large Language Models, describes
      a proof-of-concept implementation, and outlines future research directions,
      indicating that it contains new contributions rather than merely summarizing
      existing work.'
  llm_input_used: '## Abstract

    As software evolves, software architecture recovery techniques can help for effective
    maintenance. We envision a deductive software architecture recovery approach supported
    by Large Language Models (LLMs). Unlike existing inductive (bottom-up) recovery
    techniques, which reconstruct architecture by considering the properties observed
    at implementation level, our top-down approach starts with architectural properties
    and seeks their manifestations in the implementation. It employs a known Reference
    Architecture (RA) and involves two phases: RA definition and code units classification.
    A proof-of-concept with GPT-4 emulates deductive reasoning via chain-of-thought
    prompting. It demonstrates the deductive SAR approach, applying it to the Android
    application K-9 Mail and achieving a 70% accuracy in classifying 54 classes and
    184 methods. The future plans focus on evaluating and refining the approach through
    ground-truth assessments, deeper exploration of reference architectures, and advancing
    toward automated human-like software architecture explanations. We highlight the
    potential for LLMs in achieving more comprehensive and explainable software architecture
    recovery.


    ## Introduction

    During the evolution of software, the source code typically changes in ways that
    violate the integrity of the architecture of a system. This results in degradation
    in the form of drift or erosion [21]. To


    ![](_page_0_Picture_15.jpeg)


    This work licensed under Creative Commons Attribution-NonCommercial International
    4.0 License.


    ICSE-NIER''24, April 14–20, 2024, Lisbon, Portugal © 2024 Copyright held by the
    owner/author(s). ACM ISBN 979-8-4007-0500-7/24/04. https://doi.org/10.1145/3639476.3639776


    detect such degradation, one needs to compare a representation of the system''s
    intended architecture to the implementation.


    Link et al. define Software Architecture Recovery (SAR) as "the process of recovering
    a system''s architecture from its implementation artifacts, such as its source
    code" [11]. SAR is of special importance when documentation about the system''s
    architecture is outdated, incomplete, or simply lacking [11, 19]. To the best
    of our knowledge, current SAR techniques follow what we call an inductive recovery,
    where certain facts from the source code (e.g. software components, control- and
    data-flow dependencies, textual input) are extracted and clustered to recover
    the structure of the current architecture [1–3, 8, 16, 23]. However, we posit
    that to manage the deterioration of a system''s architecture—and consequently
    rectify its evolution—one must follow a deductive recovery approach. That is,
    a known reference architecture [22] should be provided to assess how the current
    implementation deviates from the intended system architecture design.


    In our approach, the Reference Architecture (RA) is an abstract representation
    of key aspects of an architectural design. Our RA considers two viewpoints: the
    component viewpoint, which is concerned with the structure and grouping of the
    elements, and the interaction viewpoint, which focuses on the interaction and
    coordination among components [22].


    To illustrate the rationale for our deductive approach, consider the notion of
    layering in architecture. Existing techniques for recovering architectural layers
    involve analyzing a system''s dependency graph to look for classes that no other
    class depends on, designating them as top-layer classes. However, when a human
    developer is getting acquainted with an unfamiliar system that employs a layered
    architecture, they often start by recognizing that the top layer in such system
    typically corresponds to the presentation layer, which comprises classes responsible
    for User Interface (UI) widgets such as buttons and text fields [22]. Hence, when
    a developer encounters a class that deals with UI buttons, they can deductively
    infer that the class belongs to the top layer. This approach thus relates to the
    observation that many existing recovery techniques "do not reflect the way engineers
    actually map entities to components" [8]. In particular, there is an aspect of
    the semantics of the implementation that current recovery techniques do not take
    into account.


    To bridge the aforementioned gap, we present in Section 2 our vision of deductive
    software architecture recovery, an approach that classifies code units (e.g.,
    methods, classes) according to an RA. We demonstrate our vision via a proof of
    concept in Section 3 that utilizes transformer-based language models and chain-of-thought
    prompting to emulate deductive reasoning. We apply the deductive SAR approach
    to the Android application K-9 Mail to obtain preliminary results on the feasibility
    of the approach in Section 4. Future research directions and conclusions are elaborated
    in Section 5 and Section 6.'
  token_usage: 4765
  time_usage: 4.523145437240601
- title: 'Demystifying AI: A Robust and Comprehensive Approach to Explainable AI'
  abstract: The adoption of Artificial Intelligence (AI) and Machine Learning (ML)
    in various computing platforms and areas, necessitates the development of strong
    Explainable AI (XAI) techniques. Most current AI models are opaque about their
    decision-making process thereby impeding trust, debugging, and improvement. The
    goal of this research is to develop comprehensive robust XAI methods capable of
    explaining the reasoning and decision-making processes in Autonomic, Edge, Server-less,
    Quantum computing platforms and IoT, Business Automation, Service Innovation domains
    where these AI models are deployed.This study comprehensively addresses the opacity
    in AI models through solutions for balanced test-train splits, model evaluation,
    feature importance, metric imbalances, ROC curve and precision-recall curve analysis,
    accuracy and statistical metrics, benefits of manual review. This research aims
    at increasing transparency and trustworthiness within AI systems through developing
    as well as applying such XAI methods that can detect and mitigate biases while
    enhancing ethical debugging; responsible development for AI enabled computing
    purposes.**
  keywords: ''
  document: "# Demystifying AI: A Robust and Comprehensive Approach to Explainable\
    \ AI\n\n Vasanth S *Department of Computer Science and Engineering RMK College\
    \ of Engineering and Technology Thiruvallur, India. vasacs188@rmkcet.ac.in* \n\
    \n Keerthana S *Department of Artificial Intelligence and Machine Learning St.Joesph's\
    \ College of Engineering Chennai. 22am245@stjosephs.ac.in*\n\n Saravanan G *Department\
    \ of ECE Sri Sai Ram Institute of Technology West Tambaram, Chennai.* \n\n*saravanang.ece@sairamit.edu.in*\
    \ \n\n*Abstract***—The adoption of Artificial Intelligence (AI) and Machine Learning\
    \ (ML) in various computing platforms and areas, necessitates the development\
    \ of strong Explainable AI (XAI) techniques. Most current AI models are opaque\
    \ about their decision-making process thereby impeding trust, debugging, and improvement.\
    \ The goal of this research is to develop comprehensive robust XAI methods capable\
    \ of explaining the reasoning and decision-making processes in Autonomic, Edge,\
    \ Server-less, Quantum computing platforms and IoT, Business Automation, Service\
    \ Innovation domains where these AI models are deployed.This study comprehensively\
    \ addresses the opacity in AI models through solutions for balanced test-train\
    \ splits, model evaluation, feature importance, metric imbalances, ROC curve and\
    \ precision-recall curve analysis, accuracy and statistical metrics, benefits\
    \ of manual review. This research aims at increasing transparency and trustworthiness\
    \ within AI systems through developing as well as applying such XAI methods that\
    \ can detect and mitigate biases while enhancing ethical debugging; responsible\
    \ development for AI enabled computing purposes.** \n\n*Keywords—Explainable AI\
    \ (XAI),Interpretability, Explainability, Artificial Intelligence (AI),Machine\
    \ Learning (ML),Transparency,Trust* \n\n# I. INTRODUCTION\n\nAs the use of Artificial\
    \ Intelligence (AI) and Machine Learning (ML) exhibits a steady increase, there\
    \ is an increasing pressure on the development of Explainable AI (XAI) as a form\
    \ of assistance in understanding why certain AI models make certain choices. Because\
    \ of the way contemporary AI models are structured, people find it hard to trust\
    \ them, they cannot tell if the model is performing well, or even seek to improve\
    \ it, and this is more so because of the fear of extending the deficits found\
    \ in the training set B. As AI technology increases acceptance and usage in context\
    \ such as hiring [6] and healthcare [12], where fairness is highly emphasized,\
    \ and where general decisions have high stakes, the demand for XAI methods that\
    \ eliminate bias, and enforcement of fairness and accountability is even more\
    \ helpful.\n\nAccording to the stand of the European Data Protection Supervisor\
    \ (EDPS), the use of XAI is precisely through It is illegal to discriminate against\
    \ customers and also any purpose. Also, more and more studies have proved that\
    \ XAI is a useful tool in enabling AI to make better and more defendable decisions\
    \ [5] and encourages people to trust AI more [11]. But even with all progress\
    \ there is still a long\n\nway to go in creating adequate, efficient XAI that\
    \ can serve the purpose without excessive sculpting.\n\nThis research analysis\
    \ seeks to resolve this problem by creating a unique XAI framework which is capable\
    \ of providing transparent and interpretable explanations of AI model decisions\
    \ made at different computing platforms and in different domains. Our approach\
    \ draws from improvements in XAI [4, 10] and human-computer interaction for AI\
    \ applications [7], ethics of AI [9], and causality [15]. By designing a more\
    \ complete and effective XAI framework, we wish to participate in the creation\
    \ of the trustworthy computing enabling AI with the high degree of transparency,\
    \ accountability, and trust in the systems.\n\n# II. REVIEW OF LITERATURE\n\n\
    The concept of Explainable AI (XAI) is playing an important role in the last few\
    \ years, since there is a stronger presence of systems based on artificial intelligence\
    \ in areas where stakes are high and decision making comes into play [7]. The\
    \ trouble with the opacity created by present day AI is that it prevents trust,\
    \ makes troubleshooting and enhancement hard and creates issues of upholding the\
    \ biases contained within the training data [1, 2]. To alleviate these issues,\
    \ several XAI approaches were proposed that aim at giving intelligible and transparent\
    \ justifications for the decisions made by AI [4 ,10].\n\nA key issue that arises\
    \ when designing methods for XAI is reconciling improving systems and being held\
    \ accountable for them at the same time [3]. The balance between these two has\
    \ been recently promoted by the European Data Protection Supervisor as in the\
    \ case of XAI [3]. In the last few years, studies have shown the capabilities\
    \ of XAI in making AI decisions more comprehensible [5] and increasing the confidence\
    \ of people in the AI-assisted solution [11].\n\nNevertheless, regardless of those\
    \ achievements, the quest to come up with all inclusive and effective XAI methods\
    \ remains a work in progress. A variety of techniques have been explored aiming\
    \ at reducing bias in the artificial intelligence systems, such as fair causal\
    \ data generation [2], explainable artificial intelligence for recruitment [6].\n\
    \nCertainly, there is a gap or a deficiency that calls for the further commitment\
    \ of time and finances even in the development of the particular XAI methods in\
    \ practical settings influencing practical domains.\n\nTherefore, the Improving\
    \ the trust in AI systems is a major focus and in doing so seeking ways to make\
    \ AI systems safe and reliable safer through expanding horizons in Research in\
    \ development of XAI methods is one of the approaches that can help in addressing\
    \ this challenge. More effective and complete XAI methods should be created, which\
    \ in turn will explain why certain decisions were made by AI models in a comprehensible\
    \ manner, while maintaining various systems and applications. This will aid in\
    \ building trust in AI systems, reducing bias and enabling fairness and responsibility\
    \ in the decision-making processes in AI systems.\n\n## III. METHODOLOGY\n\nThe\
    \ research applies a holistic methodology to build and evaluate Explainable AI\
    \ (XAI) techniques for divergent computing architectures and contexts, in response\
    \ to major obstacles and shortcomings of existing XAI approaches. The process\
    \ includes literature review to inform framework development, data collection\
    \ and preprocessing from diverse sources, development of new XAI algorithms through\
    \ evaluation, gathering user feedback on effectiveness and usability through user\
    \ studies, iterative refining and optimization based on performance metrics and\
    \ user feedbacks, deployment and integration into real-world applications.\n\n\
    # *A. Phase 1: Reviewing Literature and Developing Framework*\n\nExamine relevant\
    \ papers from top conferences and journals (e.g. NeurIPS, IJCAI, AAAI, IEEE Transactions\
    \ on Neural Networks and Learning Systems) in order to conduct a comprehensive\
    \ review of the existing XAI techniques, their applications and limitations.Combine\
    \ human-centered design principles with technical feasibility and domainspecific\
    \ requirements to develop an XAI framework.\n\n# *B. Phase 2: Collecting Data\
    \ and Preprocessing It*\n\n• Among other domains we collect and preprocess datasets,\
    \ such as autonomous computing, edge computing, serverless computing, quantum\
    \ computing, internet of things (IoT), business automation or service innovation.Ensure\
    \ that the data is correctly collected or processed by having its quality intact\
    \ while also adopting diversity to mitigate against any form of bias or error.\n\
    \n#### *C. Phase 3: Developing and Evaluating XAI Techniques*\n\nCarry out user\
    \ studies to collect opinions on the efficiency and ease of working with XAI techniques.Let's\
    \ get suggestions from domain experts, developers and endusers for possible areas\
    \ to improve on and develop.\n\n#### *D. Phase 5:Iterative Refining and Validation*\n\
    \n• The techniques of XAI should be made better and optimized through the feedback\
    \ given by the users and performance metrics.XAI techniques need to be tested\
    \ using real-world data sets and scenarios which helps in validation of results.\n\
    \n# *E. Phase 6:Deployment and Integration*\n\n• XAI Techniques must be deployed\
    \ and integrated in different computing platforms or domains.A strategic\n\n•\
    \ alliance with industry partners or stakeholders is key to ensuring seamless\
    \ integration.\n\n#### IV. SYSTEM MODEL\n\nThe system model of Explainable AI\
    \ (XAI) proposed to facilitate the design, evaluation, and deployment of XAI strategies\
    \ across various computing platforms and domains. The system model has several\
    \ components:\n\n#### *A. Data Ingestion Module:*\n\nThis module is in charge\
    \ of acquiring and preprocessing data from different sources that may include\
    \ but not limited to:Public repository datasets such as UCI machine learning repository\
    \ .Different domains APIs like health care, finance .User data collected through\
    \ questionnaires and feedback forms.\n\n#### *B. Module for Developing XAI Techniques:*\n\
    \nThis module designs new methodologies in XAI that can be implemented may consist\
    \ of: Model interpretability methods such as LIME and SHAP.Model explainability\
    \ methods like saliency maps or feature importance.Hybrid methods combining multiple\
    \ XAI techniques.\n\n#### *C. Model Evaluation Module:*\n\nIt measures how the\
    \ existing models perform using various metrics such as: Accuracy ,F1-score ,\
    \ Mean Absolute Error (MAE) , Mean Squared Error (MSE).\n\n#### *D. User Study\
    \ Module:*\n\nThis module performs user studies to get opinions on whether XAI\
    \ techniques are effective, usable etc including but not limited to: Surveys/questionnaires\
    \ Interviews/Focus groups Usability testing/A/B testing.\n\n## *E. Deploying Module:*\n\
    \nThe module deploys XAI techniques in practical applications such as: Incorporation\
    \ of interpretability models into web-based platforms .Integrating explainability\
    \ models with mobile apps.Integration into current systems and platforms.\n\n\
    Considering the proposed model, many XAI research data points that can be employed\
    \ in making new XAI approaches are explained and their usefulness measured when\
    \ implementing them practically. This paper gives a detailed exposition of its\
    \ versatility and choice of models in various domains especially computing platform\
    \ as well it uses clarity and reproducibility at all stages of the experiment\
    \ done.\n\n![](_page_2_Figure_0.jpeg)\n\nFigure.1.Flow of system model\n\n# V.\
    \ RESULT AND DISCUSSION\n\nWe assessed our proposed framework with a dataset comprising\
    \ of 1000 samples, dividing 500 for training purpose and reserving 500 for testing\
    \ purpose. The results are presented in below:\n\n![](_page_2_Figure_4.jpeg)\n\
    \nFigure.2.Baseline\n\nIn all the metrics depicted in the table as in terms of\
    \ accuracy, F1 score, AUC ROC, transparency, fairness among other pertinent metrics,\
    \ our proposed framework beats the baseline model. For instance, the proposed\
    \ framework has an accuracy of 95.2%, which is 3.1% above the baseline model.\
    \ Similarly, there have been improvements in other parameters such as the F1 score\
    \ and AUC ROC, where the framework managed to attain 94.5% and 97.1% respectively.\n\
    \n![](_page_2_Figure_7.jpeg)\n\nFigure.3.Performance Comparison\n\nOur proposed\
    \ XAI framework has surpassed earlier contributions in the area of explainable\
    \ AI. For instance, the work of Hofeditz et al. [1] has an accuracy of 92.1 percent\
    \ implementation which is less than that reached by our proposed framework of\
    \ 95.2 percent. Similarly, the work of Zhang et al. [2] has an accuracy of F1-Score\
    \ of 91.3 percent that is much lower than our proposed F1-Score complimentary\
    \ to the framework work, which is 94.5 percent.\n\nIn the same way, intervening\
    \ under rule-based approaches manages to result in fair and undistorted outcomes.\
    \ The work by Thiebes et al [6] achieves transparency of only 85.1% where as,\
    \ the proposed framework achieves transparency of 92.5 %. The same case applies\
    \ to work by Mittelstadt et al. [9] where a fairness score of and only 84.5% is\
    \ reached whereas, a busting fairness score of 90.2% is attained with the aid\
    \ of the proposed framework.\n\nTo sum up, the proposed XAI framework represents\
    \ considerable progress in comparison to previously presented works on explainable\
    \ AI. It is important because the framework has high accuracy, fairness, and provides\
    \ a transparent and interpretable explanation of AI model decisions increasing\
    \ the number of possible domains for its usage.Its ability to provide transparent\
    \ and interpretable explanations of AI model decisions, combined with its high\
    \ accuracy and fairness scores, make it a valuable tool for a wide range of applications.\n\
    \n# VI. CONCLUSION AND FUTURE ENHANCEMENT\n\nA new Explainable AI (XAI) model\
    \ was thus proposed in this study that is more flexible, adjustable and clear\
    \ than the previous models. Thus, our model outperforms other methods that exist\
    \ in terms of interpretability, accuracy, and explainability, transparency, fairness.\
    \ so it can be used for many real life applications.Therefore, our approach is\
    \ efficient enough to show how decisions are made by AI models.Thus, the proposed\
    \ model is superior to existing ones due to its ability to handle complex data\
    \ distributions, adapt to new data as well as provide transparent explanations.Such\
    \ strengths thus imply that health care and finance could be among areas best\
    \ suited for application of the model.\n\n# FUTURE ENHANCEMENT:\n\nWhile achieving\
    \ the state-of-the-art performance with our model, there are some possible next\
    \ steps for further improvements:\n\n*Multi-model Explanations*:Currently, our\
    \ model explains through feature importance scores. The future studies can thus\
    \ focus on developing multimodal explanations involving visualizations, natural\
    \ language explanations as well as interactive dashboards.\n\n*Explainability\
    \ in Real Time*: Our hypothesis explains the batch data. In future, real-time\
    \ explainability could be developed to allow streaming data explanations by the\
    \ model.\n\n*Human-in-the-Loop*: Our training relies on automated feature engineering\
    \ and selection. On the other hand, there may be a possibility of incorporating\
    \ human-in-the-loop\n\ntechniques into machine learning models that allow domain\
    \ experts provide their input in order to select and engineer features.\n\n*Explainability\
    \ for Deep Learning Models*:This explanation is designed for traditional machine\
    \ learning models. The future research might concentrate on developing certain\
    \ ways through which deep learning models can be explained since they have been\
    \ increasingly applied in various practical domains.\n\n*Explainability for Multi-Agent\
    \ Systems*: It only works as expected for single-agent systems. Finally, further\
    \ study should explore how to develop explanations for multi-agent systems, which\
    \ are gaining importance particularly with regard to autonomous vehicles and smart\
    \ cities.\n\n*Explainability for Edge AI*: The rising rate of Edge AI implementation\
    \ calls for future research on developing explainability techniques that work\
    \ on edge devices such as smart sensors and IoT devices.\n\n*Explainability in\
    \ Transfer Learning*: Our model is designed to learn a single task. Future researches\
    \ can look into explainability techniques for transfer learning which makes models\
    \ adaptable to new tasks and domains.\n\nThese improvements cover what is planned\
    \ for the next stage, thereby making our proposed XAI model even more powerful\
    \ in real-world applications than we currently realize.\n\n#### REFERENCES\n\n\
    - 1. L. Hofeditz, S. Clausen, A. Rieß, M. Mirbabaie, and S. Stieglitz,\"Applying\
    \ XAI to an AI-based system for candidate management to mitigate bias and discrimination\
    \ in hiring.\" *Electronic Markets*, 32(4),2207-2233, 2022.\n- 2. R. González-Sendino,\
    \ E. Serrano, and J. Bajo, \"Mitigating bias inartificial intelligence: Fair data\
    \ generation via causal models fortransparent and explainable decision-making.\"\
    \ *Future Generation Computer Systems*, *155*, 384-401, 2024.\n- 3. European Data\
    \ Protection Supervisor (EDPS). \"TechDispatch#2/2023 - Explainable Artificial\
    \ Intelligence: Balancing Transparency and Accountability.\" EDPS Reports, 2023.\n\
    - 4. Viso.ai. \"Explainable AI (XAI): The Complete Guide.\" Viso.ai Reports, 2024.\n\
    - 5. P. Mavrepis, G. Makridis, G. Fatouros, V. Koukos, M. M. Separdani,and D.\
    \ Kyriazis, \"XAI for all: Can large language models simplifyexplainable AI?.\"\
    \ *arXiv preprint arXiv:2401.13110, 2024*.\n- 6. S. Thiebes, et al. \"The Role\
    \ of Explainable AI in Reducing Bias inHiring Processes: A Systematic Review.\"\
    \ *Computers in Human Behavior*, 145, 105-117, 2024.\n- 7. K. Gajos, \"Human-AI\
    \ Interaction: The Importance of Explainability in High-Stakes Decisions.\" *AI\
    \ & Society*, 39(1), 45-58, 2024.\n- 8. U. Qamar, and K. Bilal, \"Explainable\
    \ AI: Bridging the Gap BetweenAI and Human Understanding.\" *AlgoVista: Journal\
    \ of AI & ComputerScience, 1(2)*, 2024.\n- 9. B. Mittelstadt, et al. \"Ethics\
    \ of AI: The Role of Explainability in Fairness and Accountability.\" *AI Ethics\
    \ Journal*, 3(2), 123-135, 2024.\n- 10. A. Barredo Arrieta, et al. \"Explainable\
    \ Artificial Intelligence: A Survey on Methods and Applications.\" *Journal of\
    \ Machine Learning Research*, 25(1), 1-30, 2024.\n- 11. Y. Hojjati, Y. Chen, and\
    \ U. Raja, \"The Impact of Explainability inCollective Interest-Based AI Recommendation\
    \ Systems.\", 2024.\n- 12. S. Liu, et al. \"Explainable AI for Healthcare: Enhancing\
    \ Trust andTransparency in Medical Decision-Making.\" *Health Informatics Journal*,\
    \ 30(1), 34-46, 2024.\n- 13. R. Patel, et al. \"Exploring the Intersection of\
    \ Explainable AI andEthical Decision-Making.\" *Ethics and Information Technology*,\
    \ 26(2),123-135, 2024.\n- 14. J. Smithson, et al. \"The Future of XAI: Challenges\
    \ and Opportunitiesin Ensuring Fairness and Accountability.\" *Artificial Intelligence\
    \ Review*, 57(5), 789-805, 2024\n- 15. T. Zhao, et al. \"Enhancing Model Interpretability\
    \ Through CausalInference Techniques in XAI.\" *Journal of Data Science*, 22(1),\
    \ 67-80,2024."
  decisions:
    evaluation_prompt: 'Qualified. Reason: The abstract mentions "model evaluation,
      feature importance, metric imbalances, ROC curve and precision-recall curve
      analysis, accuracy and statistical metrics," indicating structured evaluation
      methods are employed in the research.'
    related_work_prompt: '- Qualified. Reason: The paper references prior work and
      studies on Explainable AI (XAI), mentioning specific domains such as hiring
      and healthcare, and discusses the importance of fairness and accountability.
      It also cites various sources to support its claims and indicates that the research
      builds upon existing improvements in XAI and related fields.'
    novelty_prompt: '- Qualified. Reason: The paper claims to create a unique XAI
      framework capable of providing transparent and interpretable explanations of
      AI model decisions across various computing platforms and domains, indicating
      a new contribution to the field of Explainable AI.'
    review_only_prompt: '- Qualified. Reason: The paper proposes the development of
      a unique Explainable AI (XAI) framework and discusses its application across
      various computing platforms and domains, indicating new contributions rather
      than merely summarizing existing work.'
  llm_input_used: '## Abstract

    The adoption of Artificial Intelligence (AI) and Machine Learning (ML) in various
    computing platforms and areas, necessitates the development of strong Explainable
    AI (XAI) techniques. Most current AI models are opaque about their decision-making
    process thereby impeding trust, debugging, and improvement. The goal of this research
    is to develop comprehensive robust XAI methods capable of explaining the reasoning
    and decision-making processes in Autonomic, Edge, Server-less, Quantum computing
    platforms and IoT, Business Automation, Service Innovation domains where these
    AI models are deployed.This study comprehensively addresses the opacity in AI
    models through solutions for balanced test-train splits, model evaluation, feature
    importance, metric imbalances, ROC curve and precision-recall curve analysis,
    accuracy and statistical metrics, benefits of manual review. This research aims
    at increasing transparency and trustworthiness within AI systems through developing
    as well as applying such XAI methods that can detect and mitigate biases while
    enhancing ethical debugging; responsible development for AI enabled computing
    purposes.**


    ## Introduction

    As the use of Artificial Intelligence (AI) and Machine Learning (ML) exhibits
    a steady increase, there is an increasing pressure on the development of Explainable
    AI (XAI) as a form of assistance in understanding why certain AI models make certain
    choices. Because of the way contemporary AI models are structured, people find
    it hard to trust them, they cannot tell if the model is performing well, or even
    seek to improve it, and this is more so because of the fear of extending the deficits
    found in the training set B. As AI technology increases acceptance and usage in
    context such as hiring [6] and healthcare [12], where fairness is highly emphasized,
    and where general decisions have high stakes, the demand for XAI methods that
    eliminate bias, and enforcement of fairness and accountability is even more helpful.


    According to the stand of the European Data Protection Supervisor (EDPS), the
    use of XAI is precisely through It is illegal to discriminate against customers
    and also any purpose. Also, more and more studies have proved that XAI is a useful
    tool in enabling AI to make better and more defendable decisions [5] and encourages
    people to trust AI more [11]. But even with all progress there is still a long


    way to go in creating adequate, efficient XAI that can serve the purpose without
    excessive sculpting.


    This research analysis seeks to resolve this problem by creating a unique XAI
    framework which is capable of providing transparent and interpretable explanations
    of AI model decisions made at different computing platforms and in different domains.
    Our approach draws from improvements in XAI [4, 10] and human-computer interaction
    for AI applications [7], ethics of AI [9], and causality [15]. By designing a
    more complete and effective XAI framework, we wish to participate in the creation
    of the trustworthy computing enabling AI with the high degree of transparency,
    accountability, and trust in the systems.'
  token_usage: 3397
  time_usage: 4.36959433555603
- title: Evaluating the Features of Indoor Positioning Systems Using Explainable AI
  abstract: This paper investigates the application of Explainable AI (XAI) techniques
    in evaluating the features of indoor positioning systems, with a focus on improving
    model transparency and interpretability. Indoor positioning systems, crucial for
    location-based services in complex environments, rely heavily on machine learning
    models that often operate as black boxes. By performing SHAP (Shapley Additive
    explanations) and LIME (Local Interpretable Model-agnostic Explanations), this
    study aims to determine the most influential features by driving model predictions
    and provide a deeper understanding of their roles within the system. In this study,
    we investigate the features of RSSI values to check their importance and interactions,
    enhance the interpretability of the model through SHAP and LIME analyses, and
    guide future improvements in system accuracy and reliability.**
  keywords: ''
  document: '# Evaluating the Features of Indoor Positioning Systems Using Explainable
    AI


    S.A.K.Dhananjaya *Department of Electrical, Electronic & Systems Engineering Faculty
    of Engineering NSBM Green University* Homagama, Sri Lanka sakdhananjaya@students.nsbm.ac.lk


    H.K.I.S.Lakmal *Department of Mechatronic & Industrial Engineering Faculty of
    Engineering NSBM Green University* Homagama, Sri Lanka isuru.l@nsbm.ac.lk


    W.C.Nirmal *Department of Mechatronic & Industrial Engineering Faculty of Engineering
    NSBM Green University*  Homagama, Sri Lanka wcnirmal@students.nsbm.ac.lk


    meaningful information using Filtering techniques such as Moving Average, Fast
    Fourier Transform and Kalman Filter.


    After preprocessing, the data was analyzed using various supervised models and
    neural networks, including Decision Tree, Random Forest (RF), Support Vector Regression
    (SVR), Linear Regression (LR), XGBoost (XGB), and Feedforward Neural Network (FNN).
    The performance of each model was evaluated using R² and Root Mean Squared Error
    (RMSE), with the Random Forest model on FFT data achieving the best results. This
    study aims to improve Indoor Positioning System (IPS) accuracy and interpretability
    by using Explainable AI (XAI) techniques, specifically SHAP (Shapley Additive
    Explanations) and LIME (Local Interpretable Model-agnostic Explanations), to identify
    and evaluate the most influential features. These XAI techniques provide insights
    into the model''s decision-making process, enhancing both the model''s transparency
    and our understanding of the factors driving IPS predictions. This approach clarifies
    the current model''s behavior. It is a roadmap for refining feature selection
    and preprocessing strategies, ultimately contributing to more accurate, interpretable,
    and robust IPS models for dynamic, real-world applications.


    ## II. RELATED WORKS


    The rapid expansion of technology could lead to a potential rise in the demand
    for Indoor positioning systems. It is used for asset tracking, navigating buildings,
    and other location-based services. In estimating positions, various localization
    algorithms have been proposed, broadly classified into two categories: they are
    divided into range-based and range-free two categories. Range-based techniques
    use some beacon nodes, such that when information is given from three or more
    beacon nodes, the range of an unknown node can be calculated. The node''s position
    is then derived from this range of information. Some of the range-based algorithms
    are RSSI, AOA, TOA, and TDoA. On the other hand, range-free algorithms such as
    DV-Hop only depend on connectivity or proximity data of unknown nodes. The most
    used range-based method is the RSSI [8], considered the most accessible parameter
    for measuring the procedure. Still, it provides the most comprehensive interval
    of distance estimations, mainly if the environment is indoors, since the distance
    influences fading, shadowing, refraction, scattering, and reflections. As a result,
    several filters, such as the Extended Kalman Filter (EKF), FFT, and Moving Average
    Filter, have been used to reduce the variations in the RSSI signals [3].


    FFT-based IPS uses the frequency domain representation of signals to derive features
    that can be used in positioning. These systems transverse time-domain signal to
    frequencydomain using FFT to detect diverse signal features related to


    *Abstract***—This paper investigates the application of Explainable AI (XAI) techniques
    in evaluating the features of indoor positioning systems, with a focus on improving
    model transparency and interpretability. Indoor positioning systems, crucial for
    location-based services in complex environments, rely heavily on machine learning
    models that often operate as black boxes. By performing SHAP (Shapley Additive
    explanations) and LIME (Local Interpretable Model-agnostic Explanations), this
    study aims to determine the most influential features by driving model predictions
    and provide a deeper understanding of their roles within the system. In this study,
    we investigate the features of RSSI values to check their importance and interactions,
    enhance the interpretability of the model through SHAP and LIME analyses, and
    guide future improvements in system accuracy and reliability.**


    #### *Keywords— explainable ai, wireless sensor network, indoor positioning, machine
    learning*


    ### I. INTRODUCTION


    Indoor positioning systems (IPS) are potentially increasing for accurate location-based
    services within complex indoor environments such as multi-compartment buildings,
    shopping malls, and airports. Outdoor localization is heavily based on methods
    such as global positioning systems (GPS) and global navigation satellite systems
    (GNSS). However, with issues like irregular signal movements and complex environments
    [1], [2] those traditional methods cannot be used in indoor settings. Researchers
    introduce various indoor positioning techniques such as Wireless Sensor Networks
    (WSN), infrared (IR), Acoustic signals, Magnetic Field Mapping, and Vision-Based
    Localization to overcome these issues. WSNbased indoor positioning systems use
    various ranging techniques such as Received Signal Strength Indicator (RSSI) [3],
    Time of Arrival (ToA) [4], Time Difference of Arrival (TDoA) [5], Angle of Arrival
    (AoA) [6], Fingerprinting [3] and Hybrid Techniques [7] to determine the user''s
    position or an object we are looking for.


    This research uses WSN-based indoor positioning systems, leveraging signal strength
    indicators like the Wi-Fi Received Signal Strength Indicator (RSSI) to estimate
    the user''s position. Because we can use existing infrastructures for WSN-based
    indoor positioning systems, it increases scalability, cost-effectiveness, low
    power consumption, and robust performance. For this research, we utilized the
    RSSI values of three Wi-Fi access points in the equilateral triangle on the ceiling
    to create a reliable reference network. We collected data in various time frames
    and situations, such as high population and non-population, with timestamps to
    increase the reliability and accuracy of data collection. We use the ESP 32 module
    to collect the RSSI values of fixed nodes and record them in an Excel file using
    Python script, which is the pre-processed data to remove the noise and extract
    location information. [9]. Above range-based and range-free techniques utilize
    various access technologies such as wireless sensor networks (WSN), infrared (IR),
    ultra-wideband (UWB), and radio-frequency identification tags (RFID) for precise
    indoor positioning [10]. The WSN can easily be scalable to any number of nodes
    and is cost-effective compared to other methods. Also, WSN can easily integrate
    with ML. Most positioning systems require the existence of one or more fixed nodes
    at known locations; the fixed nodes receive a signal from the mobile node, and
    the received signal is used to measure the parameter of the positioning [11].


    Machine learning offers several advantages. Some machine learning algorithms can
    adapt when limited RSS data is available. The application of actual Wi-Fi eliminates
    the necessity of paying to add new tags, and the ability to work in non-line-of-sight
    (NLOS) conditions improves the accuracy of indoor usage. The approach described
    in the report, which is based on machine learning, leverages the available Wi-Fi
    in indoor environments that exist today. This prevents the requirement for further
    specific hardware or systems, which makes the method efficient and realistic for
    implementation in a realistic world [12]. RF is an ensemble learning approach
    that constructs many decision trees while utilizing the outcomes of each tree
    and avoiding overfitting. This reduces the chances of getting a wrong result since
    this method averages the results of several decision trees. This approach will
    help us to overcome the problem of the high probability of overfitting and will
    allow us to deal with significant amounts of data with higher dimensions. [13].


    The need for adaptive IPS is crucial in dynamic Environments. Some literature
    proposed an adaptive learning framework to integrate positioning systems based
    on real-time environmental feedback [14]. In this approach, parameters were continuously
    updated based on changes in the signal conditions to maintain the system''s accuracy.
    Another dimension implemented by reinforcement learning involves learning the
    best positioning strategies through the system''s interaction with the given environment
    [15]. Various features can affect the output of indoor positioning systems. When
    implementing indoor positioning systems, explainable AI (XAI) technologies can
    analyze the importance of features and offer a transparent view of the predicted
    machine learning models. Long Short-Term Memory (LSTM) and Convolutional Neural
    Networks (CNN) deep learning models combined to capture the signal patterns used
    in indoor positioning systems that Enhance the fingerprinting data with particle
    filters and autoencoders with the help of XAI techniques [16]. XAI is incorporated
    into the proposed system to provide an understanding of transparency and clarity
    on how the models we use make decisions [17].


    This study''s contributions include the Ability to identify the factors affecting
    the model''s predictions by analyzing the inputs, which will serve to guide future
    efforts in optimizing feature selection, data collection strategies, and overall
    model performance in indoor positioning systems.


    ## III. METHODOLOGY


    This section describes the methodology used to evaluate the features of the proposed
    IPS through the application of SHAP and LIME. The process involves data collection,
    preprocessing, model training, and feature importance extraction using XAI techniques.


    ## *A. Data Collection and Preprocessing*


    In the current study, data was collected from three Wi-Fi access points in the
    ceiling in an equilateral triangle arrangement shown in Fig. 1. The dataset consists
    of RSSI values from three Wi-Fi access points configured as AP1, AP2, and AP3.
    The data was collected from the experimental setup where the mapped grid was one
    meter by one-meter square. All the data points are labeled in X and Y coordinates
    to experiment. The experimental area covered 193 m2, as shown in Fig. 2. We collected
    data using an ESP32 module configured as a Wi-Fi scanner to acquire the RSSI values
    from Access points at each grip point in the mapped grid. ESP32 module was moved
    only to the X-axis and Y-axis to limit the study area to 2D space.


    ![](_page_1_Picture_8.jpeg)


    Fig. 1. Experimental Area with Three APs


    ![](_page_1_Figure_10.jpeg)


    Fig. 2. Experimental Area Grid Map


    Using a Python script, the data set was saved in an Excel file with columns named
    Timestamp, RSSI\_AP1, RSSI\_AP2, RSSI\_AP3, X coordinate, and Y coordinate. To
    increase the accuracy and reliability of the data, readings are taken at a frequency
    of 1Hz at each data point, and measurements are taken in different situations,
    such as high population and nonpopulation.


    Data pre-processing is another crucial step in the study, as it removes the noise
    and extracts meaningful information from the data set. First, we clean the data
    set to remove the missing values and then ensure that RSSI values are within the
    valid range of -100dBm to 0dBm. Then, Fast Fourier Transform (FFT) filtering is
    used to enhance the quality of the RSSI signals. FFT was chosen due to its ability
    to reduce noise and extract relevant frequency components from the time-domain
    RSSI signals. The filtered data was normalized to ensure consistent scaling across
    features, facilitating better model training and analysis.


    ## *B. Model Training*


    The pre-processed data was used to train a machine learning model to predict the
    accurate position of the user. We used the Python 3.12.4 version to train the
    models with the help of libraries such as scikit-Learn, TensorFlow, pandas, NumPy,
    matplotlib, scipy, and filterpy. R<sup>2</sup> and RMSE are used to evaluate the
    performance of models. R² value measures the proportion of the variance in the
    dependent variable that is predictable from the independent variables. If the
    R² value is closer to 1, the model shows a high proportion of the variance. RMSE
    measures the average magnitude of the prediction errors, providing insight into
    the model''s accuracy by indicating how far the predicted position deviates from
    the actual position. A lower RMSE indicates better model performance.


    The model was trained to predict the X and Y coordinates based on the FFT-filtered
    RSSI values. This process involved splitting the dataset into 70% for training
    and 30% for testing, ensuring that the model was evaluated on unseen data to assess
    its generalization capabilities.


    ## *C. Application of Explainable AI Technique.*


    Explainable AI encompasses strategies and processes intended to clarify and explain
    the decision-making process of AI models to humans. In the machine learning domain,
    where models are sometimes treated as ''black boxes,'' XAI contributes insights
    into the reasoning behind a model''s decisions rather than merely presenting a
    result. This is critical for applications such as indoor positioning, wherein
    the accuracy and clarity of decisions are fundamental for reliability, safety,
    and user trust. We employed two Explainable AI techniques to analyze the importance
    of features and offer a transparent view of the predicted machine learning model:
    Shapley Additive explanations (SHAP) and Local Interpretable Model-agnostic Explanations
    (LIME).


    ### *1) SHAP Analysis*


    A robust cooperative game theory-based technique called SHAP analysis clarifies
    the output of any machine learning model by assigning importance levels (SHAP
    values) to all features. Within indoor positioning systems (IPS), SHAP is used
    to analyze how each input feature, particularly the filtered RSSI values from
    access points labeled AP1, AP2, and AP3, relates to the prediction of an object
    or user location. SHAP measures the global importance of features in all predictions
    and local explanations or individual predictions. A SHAP summary plot was used
    to capture the overall effect of each feature on the model. Furthermore, SHAP
    dependence plots were employed to visualize the interactions between individual
    features and the corresponding SHAP values.


    ## *2) LIME Analysis*


    LIME was used to produce localized explanations of specific predictions. Being
    model agnostic, LIME can be applied to any machine learning model. In this research,
    LIME locally approximates the behavior of the Random Forest model for a selected
    instance by fitting a simple and interpretable model, such as linear regression,
    on the input data that has been slightly modified around the selected instance.
    The use of LIME analysis enabled the understanding of how alterations to RSSI
    values impacted the predicted coordinates for cases and offered a more explicit
    model decision-making perspective.


    ### IV. RESULTS AND DISCUSSION


    This section presents the SHAP and LIME results, providing insights into the importance
    of the feature and its impact on indoor positioning system predictions due to
    environmental factors. The results from both methods have been conducted and compared
    to validate the consistency and reliability of the findings, thus enabling actionable
    insights for improvement in the feature selection and preprocessing techniques
    in future iterations of the IPS.


    ### *A. SHAP Analysis*


    The SHAP analysis estimated the global and local importance of the RSSI features
    (RSSI1\_fft, RSSI2\_fft, RSSI3\_fft). The SHAP summary plots provide a comprehensive
    view of the contribution of each of the features toward the model prediction for
    a particular instance, positively or negatively. Positive sharp values show how
    the feature increases the predicted X or Y coordinate, and negative SHAP values
    show how the feature decreases the prediction. The magnitude of the feature values
    is represented using the color gradient. Blue indicates the weak RSSI values,
    and red means the Strong RSSI values.


    ![](_page_2_Figure_15.jpeg)


    Fig. 3. SHAP Value for X Coordinates


    ![](_page_2_Figure_17.jpeg)


    Fig. 4. SHAP Values for Y Coordinates


    Fig. 3 shows the impact on the model''s prediction for X coordinates. The most
    influential negative feature was RSSI3\_fft since it has a much spread of the
    negative side of SHAP values. It means that this feature often decreases the predicted
    X coordinate. Also, it shows the more extensive spread of the SHAP values, indicating
    a strong influence for X coordinates pulling down the value. The value of RSSI2\_fft
    is clustered around zero, showing that features don''t heavily influence the model''s
    prediction. RSSI1\_fft showed a high influence on low feature values and a low
    influence on higher feature values. Therefore, changes in RSSI1\_fft show more
    variability in how they influence the model predictions, and it shows the opposite
    effect on the X coordinate predictions.


    Fig. 4 shows the impact on the model''s prediction for the Y coordinate. In this
    plot, RSSI2\_fft shows the wide range of SHAP values, and it has a solid negative
    influential feature for the model''s prediction of Y coordinates. RSSI1\_fft shows
    the more prominent spread of the SHAP values, with low feature values negatively
    impacting Y coordinate predictions and higher values having a positive impact.
    In this plot, RSSI3\_fft has the least impact compared to other values, which
    generally contributes negatively to the prediction.


    ### *B. LIME Analysis*


    LIME was used to provide a local explanation for any instance, describing how
    the model reaches any prediction. Fig. 5 and Fig. 6 show the LIME explanation
    for one such instance. The LIME explanation for the X prediction plot shows how
    RSSI values change the predicted X coordinates. In Fig. 5, RSSI2\_fft has the
    most positive contribution to the prediction of X coordinates, and it increases
    the prediction. RSSI1\_fft has a negative impact on the prediction. RSSI3\_fft
    also positively impacts prediction but is not as good as RSSI2\_fft. The LIME
    explanation for the Y prediction shows how the RSSI values lead to changes in
    the Predicted Y coordinates.it is shown in Fig. 6. As shown in the figure, RSSI1\_fft
    has the most positive impact on the prediction, and the RSSI2\_ftt and RSSI3\_fft
    have a negative effect on the prediction, and they reduce the prediction.


    ![](_page_3_Figure_3.jpeg)


    Fig. 5. LIME Explanation for X Coordinates


    ![](_page_3_Figure_5.jpeg)


    Fig. 6. LIME Explanation for Y Coordinates


    ## *C. Comparative Analysis of SHAP and LIME Results*


    RSSI1\_fft and RSSI2\_fft show the strongest contribution to both X and Y predictions
    in the LIME plot. When comparing both techniques, RSSI3\_fft influences the X
    coordinate more, and RSSI2\_fft influences the Y coordinate more. When discussing
    the impact of access point imbalance on data collection setup in Fig. 2, three
    APs are fixed in the equilateral triangle on the ceiling. A slight imbalance can
    be due to environmental factors such as obstacles and free space. For example,
    obstacles near AP1 and AP2 or more open space near AP3 cause RSSI3\_fft to have
    more data and, hence, a stronger influence on the model, particularly for the
    X coordinates prediction. As seen in the SHAP values for the Y coordinate, RSSI3\_fft
    has a strong negative influence due to this imbalance. Also, RSSI2\_fft''s neutral
    effect on X coordinate prediction might be because less is collected from AP2,
    weakening its influence on prediction. In contrast, RSSI2\_fft strongly impacts
    the Y coordinate, potentially indicating that AP2 plays a more significant role
    in determining positions along the Y-axis, where environmental imbalance less
    affects data coverage. The consistency between SHAP and LIME results aligns the
    predictions and validity of the feature importance findings.


    ### V. CONCLUSION


    This study applied Explainable AI techniques, specifically SHAP and LIME, to evaluate
    the importance of features in a wireless sensor network-based indoor positioning
    system. Predictions of the X and Y coordinates of the user''s position were obtained
    from a Random Forest model trained on FFTfiltered RSSI values. SHAP analysis provided
    global interpretability by highlighting the importance of each RSSI value. LIME
    offered a local explanation, reinforcing the importance of RSSI2\_fft for X predictions
    and RSSI1\_fft for Y predictions. The coherence between the SHAP and LIME results
    validates the reliability of the same results, allowing a greater level of transparency
    in the model''s decision-making process. These insights guide further feature
    selection and preprocessing improvements to make indoor positioning systems more
    accurate.


    Considering these insights, future work could focus on retraining the model using
    the most impactful features identified by XAI analysis. This targeted approach
    has the potential to streamline the model, improve interpretability, and possibly
    boost prediction accuracy by reducing noise from less informative features. Additionally,
    data rebalancing strategies should be considered to address the imbalance in data
    collection from the access points. This may be done by altering the access point
    configuration or obtaining further data from sections of the map that were not
    sampled.


    Furthermore, derivative feature engineering or suitable regularization techniques
    could be explored to ensure that the model does not overly rely on any single
    feature, promoting a balanced prediction outcome. The insights from SHAP also
    underscore the need to improve model explainability, particularly in environments
    prone to signal interference or physical obstructions. By addressing these considerations,
    future iterations of indoor positioning systems could achieve greater accuracy,
    robustness, and practical applicability in complex indoor environments.


    ### REFERENCES


    - [1] S. Xia *et al.*, "Indoor Fingerprint Positioning Based on Wi-Fi: An Overview,"
    *ISPRS International Journal of Geo-Information 2017, Vol. 6, Page 135*, vol.
    6, no. 5, p. 135, Apr. 2017, doi: 10.3390/IJGI6050135.

    - [2] A. Tahat, G. Kaddoum, S. Yousefi, S. Valaee, and F. Gagnon, "A Look at the
    Recent Wireless Positioning Techniques with a Focus on Algorithms for Moving Receivers,"
    *IEEE Access*, vol. 4, pp. 6652– 6680, 2016, doi: 10.1109/ACCESS.2016.2606486.

    - [3] L. Polak, S. Rozum, M. Slanina, T. Bravenec, T. Fryza, and A. Pikrakis,
    "Received Signal Strength Fingerprinting-Based Indoor Location Estimation Employing
    Machine Learning," *Sensors 2021, Vol. 21, Page 4605*, vol. 21, no. 13, p. 4605,
    Jul. 2021, doi: 10.3390/S21134605.

    - [4] S. Wu, S. Zhang, and D. Huang, "A TOA-Based Localization Algorithm with
    Simultaneous NLOS Mitigation and Synchronization Error Elimination," *IEEE Sens
    Lett*, vol. 3, no. 3, Mar. 2019, doi: 10.1109/LSENS.2019.2897924.

    - [5] M. Yang, D. R. Jackson, J. Chen, Z. Xiong, and J. T. Williams, "A TDOA Localization
    Method for Nonline-of-Sight Scenarios," *IEEE Trans Antennas Propag*, vol. 67,
    no. 4, pp. 2666–2676, Apr. 2019, doi: 10.1109/TAP.2019.2891403.

    - [6] B. Yimwadsana, V. Serey, and S. Sanghlao, "Performance Analysis of an AoA-based
    Wi-Fi Indoor Positioning System," *Proceedings - 2019 19th International Symposium
    on Communications and Information Technologies, ISCIT 2019*, pp. 36–41, Sep. 2019,
    doi: 10.1109/ISCIT.2019.8905238.

    - [7] A. Baniukevic, C. S. Jensen, and H. Lu, "Hybrid indoor positioning with
    Wi-Fi and Bluetooth: Architecture and performance," *Proceedings - IEEE International
    Conference on Mobile Data Management*, vol. 1, pp. 207–216, 2013, doi: 10.1109/MDM.2013.30.

    - [8] A. Youssef and M. Youssef, "A Taxonomy of Localization Schemes for Wireless
    Sensor Networks".

    - [9] J. M. Rocamora, I. W. H. Ho, and M. W. Mak, "The Application of Machine
    Learning Techniques on Channel Frequency Response Based Indoor Positioning in
    Dynamic Environments," *2018 IEEE*


    *International Conference on Sensing, Communication and Networking, SECON Workshops
    2018*, pp. 1–4, Jun. 2018, doi: 10.1109/SECONW.2018.8396358.


    - [10] S. M. Asaad and H. S. Maghdid, "A Comprehensive Review of Indoor/Outdoor
    Localization Solutions in IoT era: Research Challenges and Future Perspectives,"
    *Computer Networks*, vol. 212, p. 109041, Jul. 2022, doi: 10.1016/J.COMNET.2022.109041.

    - [11] S.Sundar and H. Kittur, "Survey Of Indoor Positioning Techniques And Systems
    For Mobile Nodes," 2020.

    - [12] J. Bai, Y. Sun, W. Meng, and C. Li, "Wi-Fi Fingerprint-Based Indoor Mobile
    User Localization Using Deep Learning," *Wirel Commun Mob Comput*, vol. 2021,
    2021, doi: 10.1155/2021/6660990.

    - [13] B. Jia, J. Liu, T. Feng, B. Huang, T. Baker, and H. Tawfik, "TTSL: An indoor
    localization method based on Temporal Convolutional Network using time-series
    RSSI," *Comput Commun*, vol. 193, pp. 293–301, Sep. 2022, doi: 10.1016/J.COMCOM.2022.07.003.

    - [14] J. M. Batalla, C. X. Mavromoustakis, G. Mastorakis, N. N. Xiong, and J.
    Wozniak, "Adaptive Positioning Systems Based on Multiple Wireless Interfaces for
    Industrial IoT in Harsh Manufacturing Environments," *IEEE Journal on Selected
    Areas in Communications*, vol. 38, no. 5, pp. 899–914, May 2020, doi: 10.1109/JSAC.2020.2980800.

    - [15] J. Gao, W. Ye, J. Guo, and Z. Li, "Deep Reinforcement Learning for Indoor
    Mobile Robot Path Planning," *Sensors 2020, Vol. 20, Page 5493*, vol. 20, no.
    19, p. 5493, Sep. 2020, doi: 10.3390/S20195493.

    - [16] Z. Turgut and A. G. Kakisim, "An explainable hybrid deep learning architecture
    for WiFi-based indoor localization in Internet of Things environment," *Future
    Generation Computer Systems*, vol. 151, pp. 196–213, Feb. 2024, doi: 10.1016/J.FUTURE.2023.10.003.

    - [17] A. H. M. Kamal, M. G. R. Alam, M. R. Hassan, T. S. Apon, and M. M. Hassan,
    "Explainable indoor localization of BLE devices through RSSI using recursive continuous
    wavelet transformation and XGBoost classifier," *Future Generation Computer Systems*,
    vol. 141, pp. 230–242, Apr. 2023, doi: 10.1016/J.FUTURE.2022.11.001.'
  decisions:
    evaluation_prompt: 'Qualified. Reason: The abstract and introduction mention the
      use of SHAP and LIME for evaluating feature importance, as well as data collection
      and analysis methods, indicating structured evaluation through empirical analysis
      of indoor positioning systems.'
    related_work_prompt: 'Qualified. Reason: The paper discusses various indoor positioning
      techniques and compares its approach using Explainable AI (XAI) with existing
      methods, referencing multiple prior works and studies throughout the introduction.'
    novelty_prompt: 'Qualified. Reason: The paper explicitly states contributions
      in the introduction, including the ability to identify factors affecting model
      predictions and the use of Explainable AI (XAI) techniques to enhance transparency
      and interpretability in indoor positioning systems.'
    review_only_prompt: 'Qualified. Reason: The paper proposes the use of Explainable
      AI techniques (SHAP and LIME) to evaluate features of indoor positioning systems
      and discusses its contributions to improving model transparency and interpretability,
      indicating new methods and insights rather than merely summarizing existing
      work.'
  llm_input_used: '## Abstract

    This paper investigates the application of Explainable AI (XAI) techniques in
    evaluating the features of indoor positioning systems, with a focus on improving
    model transparency and interpretability. Indoor positioning systems, crucial for
    location-based services in complex environments, rely heavily on machine learning
    models that often operate as black boxes. By performing SHAP (Shapley Additive
    explanations) and LIME (Local Interpretable Model-agnostic Explanations), this
    study aims to determine the most influential features by driving model predictions
    and provide a deeper understanding of their roles within the system. In this study,
    we investigate the features of RSSI values to check their importance and interactions,
    enhance the interpretability of the model through SHAP and LIME analyses, and
    guide future improvements in system accuracy and reliability.**


    ## Introduction

    Indoor positioning systems (IPS) are potentially increasing for accurate location-based
    services within complex indoor environments such as multi-compartment buildings,
    shopping malls, and airports. Outdoor localization is heavily based on methods
    such as global positioning systems (GPS) and global navigation satellite systems
    (GNSS). However, with issues like irregular signal movements and complex environments
    [1], [2] those traditional methods cannot be used in indoor settings. Researchers
    introduce various indoor positioning techniques such as Wireless Sensor Networks
    (WSN), infrared (IR), Acoustic signals, Magnetic Field Mapping, and Vision-Based
    Localization to overcome these issues. WSNbased indoor positioning systems use
    various ranging techniques such as Received Signal Strength Indicator (RSSI) [3],
    Time of Arrival (ToA) [4], Time Difference of Arrival (TDoA) [5], Angle of Arrival
    (AoA) [6], Fingerprinting [3] and Hybrid Techniques [7] to determine the user''s
    position or an object we are looking for.


    This research uses WSN-based indoor positioning systems, leveraging signal strength
    indicators like the Wi-Fi Received Signal Strength Indicator (RSSI) to estimate
    the user''s position. Because we can use existing infrastructures for WSN-based
    indoor positioning systems, it increases scalability, cost-effectiveness, low
    power consumption, and robust performance. For this research, we utilized the
    RSSI values of three Wi-Fi access points in the equilateral triangle on the ceiling
    to create a reliable reference network. We collected data in various time frames
    and situations, such as high population and non-population, with timestamps to
    increase the reliability and accuracy of data collection. We use the ESP 32 module
    to collect the RSSI values of fixed nodes and record them in an Excel file using
    Python script, which is the pre-processed data to remove the noise and extract
    location information. [9]. Above range-based and range-free techniques utilize
    various access technologies such as wireless sensor networks (WSN), infrared (IR),
    ultra-wideband (UWB), and radio-frequency identification tags (RFID) for precise
    indoor positioning [10]. The WSN can easily be scalable to any number of nodes
    and is cost-effective compared to other methods. Also, WSN can easily integrate
    with ML. Most positioning systems require the existence of one or more fixed nodes
    at known locations; the fixed nodes receive a signal from the mobile node, and
    the received signal is used to measure the parameter of the positioning [11].


    Machine learning offers several advantages. Some machine learning algorithms can
    adapt when limited RSS data is available. The application of actual Wi-Fi eliminates
    the necessity of paying to add new tags, and the ability to work in non-line-of-sight
    (NLOS) conditions improves the accuracy of indoor usage. The approach described
    in the report, which is based on machine learning, leverages the available Wi-Fi
    in indoor environments that exist today. This prevents the requirement for further
    specific hardware or systems, which makes the method efficient and realistic for
    implementation in a realistic world [12]. RF is an ensemble learning approach
    that constructs many decision trees while utilizing the outcomes of each tree
    and avoiding overfitting. This reduces the chances of getting a wrong result since
    this method averages the results of several decision trees. This approach will
    help us to overcome the problem of the high probability of overfitting and will
    allow us to deal with significant amounts of data with higher dimensions. [13].


    The need for adaptive IPS is crucial in dynamic Environments. Some literature
    proposed an adaptive learning framework to integrate positioning systems based
    on real-time environmental feedback [14]. In this approach, parameters were continuously
    updated based on changes in the signal conditions to maintain the system''s accuracy.
    Another dimension implemented by reinforcement learning involves learning the
    best positioning strategies through the system''s interaction with the given environment
    [15]. Various features can affect the output of indoor positioning systems. When
    implementing indoor positioning systems, explainable AI (XAI) technologies can
    analyze the importance of features and offer a transparent view of the predicted
    machine learning models. Long Short-Term Memory (LSTM) and Convolutional Neural
    Networks (CNN) deep learning models combined to capture the signal patterns used
    in indoor positioning systems that Enhance the fingerprinting data with particle
    filters and autoencoders with the help of XAI techniques [16]. XAI is incorporated
    into the proposed system to provide an understanding of transparency and clarity
    on how the models we use make decisions [17].


    This study''s contributions include the Ability to identify the factors affecting
    the model''s predictions by analyzing the inputs, which will serve to guide future
    efforts in optimizing feature selection, data collection strategies, and overall
    model performance in indoor positioning systems.'
  token_usage: 5408
  time_usage: 4.078083276748657
- title: 'Cyber-Resilient Edge Computing: A Holistic Approach with Multi-Level MAPE-K
    Loops'
  abstract: As edge computing continues to play a pivotal role in modern computing
    architectures, ensuring robust cybersecurity becomes imperative. This paper introduces
    our emerging results on a comprehensive approach to bolster the cyber-resilience
    of edge computing systems by incorporating the MAPE-K (Monitor, Analyze, Plan,
    Execute, and Knowledge) loop. The proposed methodology involves the application
    of the MAPE-K loop at different levels of an edge computing architecture, aiming
    to create a holistic defense mechanism against cyber attacks. We present a prototype
    of our framework and assess its viability and efficacy by leveraging real-world
    edge devices deployed in an industrial production setting. Initial evidence from
    our results suggests that this novel approach leads us to reconsider how we construct
    more resilient edge computing architectures.
  keywords: Edge Computing, MAPE-K Loop, Cyber Attack Resilience
  document: '# Cyber-Resilient Edge Computing: A Holistic Approach with Multi-Level
    MAPE-K Loops


    Marco Stadler, Johannes Sametinger *LIT Secure and Correct Systems Lab Dept. of
    Business Informatics – Software Engineering Johannes Kepler University Linz*,
    Austria {first name}.{last name}@jku.at


    Michael Riegler *IT Platforms and Operations ENGEL AUSTRIA GmbH* Schwertberg,
    Austria michael.riegler@engel.at


    *Abstract*—As edge computing continues to play a pivotal role in modern computing
    architectures, ensuring robust cybersecurity becomes imperative. This paper introduces
    our emerging results on a comprehensive approach to bolster the cyber-resilience
    of edge computing systems by incorporating the MAPE-K (Monitor, Analyze, Plan,
    Execute, and Knowledge) loop. The proposed methodology involves the application
    of the MAPE-K loop at different levels of an edge computing architecture, aiming
    to create a holistic defense mechanism against cyber attacks. We present a prototype
    of our framework and assess its viability and efficacy by leveraging real-world
    edge devices deployed in an industrial production setting. Initial evidence from
    our results suggests that this novel approach leads us to reconsider how we construct
    more resilient edge computing architectures.


    *Index Terms*—Edge Computing, MAPE-K Loop, Cyber Attack Resilience


    ## I. INTRODUCTION


    Edge Computing Systems (ECSs) are more popular than ever before. Media portray
    ECSs as one of the most significant phenomena of our time. Recent industry forecasts
    predict that market values will reach 317 billion U.S. dollars by 2026 [18], and
    scientific research communities have demonstrated a growing interest in ECS research
    in recent years. For example, a search for "edge computing" in the ACM Digital
    Library (16.10.2023) returns 675,121 results, of which 176,725 (or more than 26%)
    were published only in the last five years [1].


    The concept of edge computing entails the placement of substantial computing and
    storage resources at the outer edges of the Internet, i.e., in close proximity
    to the sensors [17]. For this reason, ECSs provide numerous benefits. ECSs satisfy
    ultra-low latency requirements, shift sensitive data processing from the cloud
    closer to the device, and combat the everincreasing energy demand [3]. ECSs are
    employed in a wide range of application scenarios. For example, in the context
    of smart manufacturing [14] or cyber-physical systems [4].


    While the ECS''s concept is widely used and has yielded promising results thus
    far, these systems'' unique design characteristics make them especially susceptible
    to malicious attacks [21]: (1) Most access control models only offer Coarse-Grained
    Access Control, which is unsatisfactory in edge computing due to the system''s
    complexity. (2) Due to the Operating System and Protocol Heterogeneity utilized
    by ECSs, it is challenging for security engineers to design a unified protection
    mechanism for edge computing. (3) Due to their rudimentary design, edge devices
    provide limited user feedback, resulting in increased Attack Unawareness among
    users. (4) ECSs are supplied with Weaker Computational Power compared to cloud
    servers. Therefore, these systems employ weaker defense systems and are consequently
    more susceptible to existing attacks.


    A prominent example of attacks leveraging these attack surfaces are Denial of
    Service (DoS) attacks, and the even more pervasive and severe Distributed Denial
    of Service (DDoS) attacks [19]. DoS attacks are defined as the deliberate endeavor
    of an attacker to obstruct the access of authorized users to the targeted resources
    of a service. This can be accomplished, for example, by flooding the (edge) device
    with requests, thereby obstructing legitimate traffic [10].


    Current architectural solutions to secure ECSs against these types of attacks
    lack the consideration of security-by-design (i), are not able to migrate security
    frameworks (ii), provide only fragmented coarse-grained access control (iii),
    or only provide isolated and passive defense mechanisms (iv) [21]. While all of
    these issues must be tackled in order to ensure the security of systems, the primary
    emphasis of this paper will be on the latter (iv).


    In summary, the threat posed by DoS attacks remains high and indicates that current
    countermeasures cannot prevent such attacks. New strategies will be required in
    the future to secure ECSs. Hence, we report in this paper our ongoing research,
    emerging results, and initial efforts toward securing ECS architectures by leveraging
    a self-adaptive holistic system architecture.


    The paper commences with an illustrative example from the real world (Section
    II). Following this, background information is presented in (Section III), accompanied
    by a description of the proposed approach in Section IV. The results are examined
    in the discussion (Section V), with Section VI reviewing related work. Future
    research directions are proposed in Section VII. Section VIII provides a comprehensive
    summary of the contributions made in the paper.


    ## II. MOTIVATING EXAMPLE


    *Azure*, the cloud platform developed by Microsoft, presently holds the position
    of one of the most prominent cloud provider. "Azure Stack Edge" is the part of
    the *Azure* platform used to conduct edge computing [11].


    Despite Microsoft''s extensive infrastructure resources and years of experience,
    it remains vulnerable to DDoS attacks, as evidenced by the incident that occurred
    in June 2023. A massive DDoS attack caused disruptions in some of Microsoft''s
    services, including *Azure* and its services [20]. The attackers used several
    types of DDoS attack traffic, including an *HTTP(S) flood attack*. In this scenario,
    the attacker sent a large number (millions) of HTTP(S) requests from various source
    IPs all over the world. As a result, the application backend''s computing resources
    (CPU and memory) were depleted [12].


    The present case demonstrates that attacks on ECSs are not only more prevalent
    than ever before but also capable of targeting anyone, even those with the most
    recent, cuttingedge security features. Hence, a question emerges as to how one
    might enhance the resilience of their infrastructure against such forms of attacks.
    We advocate for the implementation of defense mechanisms that approach architecture
    in a more holistic manner. In this paper, one step toward accomplishing this objective
    is outlined: Implementing multi-level MAPE-K loops to increase the resilience
    of ECSs under attack.


    ## III. BACKGROUND


    Two concepts underpin our efforts to develop more resilient ECSs: the "native"
    edge computing architecture and the MAPE-K loop. Thus, a brief summary of these
    principles is presented in this section.


    ECSs are frequently implemented using a hierarchical multilayered architecture.
    An overview of the layers can be found in Fig. 2.


    The architecture consists of multiple layers [9, 15, 22]:


    • *Device Layer*: The lowest layer in the architecture, which is accountable for
    gathering parameter data from various sensors, transmitting it to the *Edge Layer*,
    and awaiting control instructions from the *Edge Layer*, thereby establishing
    data and control flow connectivity between the *Device Layer* and *Edge Layer*.


    • *Edge Layer*: This layer provides time-sensitive services, including edge data
    analysis, intelligent computation, process optimization, real-time control, and
    security and privacy protection, in addition to receiving, processing, and forwarding
    data flow from the *Device Layer*.


    • *Fog Layer*: This layer facilitates the transfer of data, storage, processing,
    and networking operations from the cloud to end devices through the utilization
    of network nodes that are in close proximity to the initial layers. As data proceeds
    from the lower layers to the *Cloud Layer*, it inevitably encounters processes
    such as computation, storage, networking, decisionmaking, and data management.


    • *Cloud Layer*: The responsibility of extracting potential value from vast amounts
    of data and ensuring efficient resource distribution at the enterprise, regional,
    or national level falls within the responsibility of the *Cloud Layer*. Furthermore,
    by collaborating in the cloud, the *Cloud Layer* is capable of exchanging data,
    which enables more comprehensive and diverse data value extraction.


    Contemporary software engineering systems have evolved beyond their predecessors
    in terms of complexity and integration. Component interactions of these enormous
    systems were challenging for architects. In response, self-adaptation was introduced,
    which enabled software systems to independently adapt to changes occurring either
    internally or externally in their environment, ensuring high efficiency despite
    the growing intricacy, unpredictability, and dynamism [7].


    A widely acknowledged engineering methodology for achieving self-adaptation involves
    the utilization of a feedback control loop known as MAPE-K. An overview of the
    MAPE-K feedback loop is depicted in Fig. 1.


    ![](_page_1_Figure_14.jpeg)


    Fig. 1. MAPE-K Feedback Loop


    The MAPE-K loop seeks to Monitor, Analyze, Plan, and Execute self-adaptation utilizing
    a common Knowledge base: A managed system and its environment are initially monitored
    by sensors (*M*). Then the information is compiled, analyzed, and stored in the
    knowledge base for future reference (*K*). In addition, patterns in the knowledge
    base are compared with event data to extract symptoms and patterns (*A*). The
    planner utilizes the sensor data to formulate a course of action recommendation
    and propose an adaptation strategy (*P*). The execution of this strategy ultimately
    leads to an adaptation of the managed system (*E*) [2, 7].


    ECSs frequently possess great complexity; thus, the MAPE-K loop is regarded as
    an effective tool for managing these systems and, more precisely, for addressing
    the system''s complexity.


    ## IV. APPROACH


    ## *A. Multi-Level MAPE-K Loops*


    ECSs often follow a hierarchical System of Systems (SoS) architecture; respectively
    we propose to use a MAPE-K loop for a hierarchical control pattern [5] as part
    of our larger Security Adaptation Manager component, see Fig. 2. The hierarchical
    control pattern incorporates complete MAPE-K loops at each level of the hierarchy.
    MAPE-K loops at various levels exchange information to communicate. The MAPE-K
    loop at a specific level can transmit directives to the level below concerning
    adaptation strategies that lead after considering all other multiple relevant
    security intelligence in the hierarchy (multi-level) to corresponding reactions,
    and conversely. It can also share information about locally planned actions that
    it has collected, potentially aggregated, or filtered.


    ![](_page_2_Figure_0.jpeg)


    Fig. 2. Multi-Level MAPE-K Loops


    We leverage this communication and adaptation flow to transmit security-relevant
    data (c.f. Security Knowledge Base). During an attack, a layer engages in self-adaptation
    (i.e., enforces security policies via the Multi-Level Policy Handler) to counter
    the attack and enhance its resilience. The adaptation is subsequently transmitted
    to the remaining layers, potentially inducing further adaptation in those layers.
    Thus, other layers may adapt their behavior preemptively, prior to the attack''s
    arrival.


    For example, let''s consider a scenario where an attack occurs at the edge layer.
    The targeted device adapts its behavior (i.e., security level) in response to
    the attack and communicates the changes to the relevant fog layer node. Based
    on the level of significance, the fog layer can adjust its behavior or instruct
    its other edge nodes which have not yet been targeted, to proactively modify their
    behavior, making the entire system more resilient.


    ## *B. Evaluation*


    To demonstrate the *viability* and *efficacy* of our proposed architecture, we
    implemented a Proof of Concept (PoC), deployed the PoC to an ECS, and conducted
    DoS attacks on the ECS.


    For the PoC, we use physical hardware, including edge devices typically employed
    to manage injection molding machines and other computing nodes to construct an
    ECS. The ECS in our simulation setting consists of one cloud node, two fog nodes,
    and three edge nodes. At the device layer, we employed measurements at the software
    level, such as RAM usage, as well as external hardware sensors, like temperature
    and humidity sensors, to monitor the systems and the surrounding environment.
    The data collected by the sensors is transmitted via the Message Queue Telemetry
    Transport (MQTT) protocol. MQTT is a protocol specifically designed for efficient
    communication in IoT environments. The protocol operates on a server-client system
    in which the server, referred to as a broker, transmits updates to MQTT clients
    utilizing the publish-subscribe communication model. Although the protocol is
    efficient, it is susceptible to DoS attacks and thus serves as an adequate use
    case to evaluate the proposed architecture [6].


    For implementing the self-adaptation and attack states, we use defense readiness
    condition (DEFCON) levels. The DEF-CON levels, their triggers, and the enforced
    security policies


    ![](_page_2_Figure_8.jpeg)


    Fig. 3. Adaptability rate (AR) of the nodes in the evaluation


    can be found in Table I. The determination of the thresholds was accomplished
    via iterative testing.


    For measuring the *viability*, we randomly seed threshold exceeding data (c.f.
    Table I) into the system and measure the architecture''s adaptability rate (AR).
    AR refers to the time to adapt. The AR commences when the initial node in the
    ECS initiates the adaptation process and concludes when all subsequent nodes in
    the ECS have also adapted.


    To evaluate the *efficacy* of our approach, we conducted DoS attacks against the
    ECS. Since the goal of a DoS is to flood the network and ultimately make the system
    unavailable, we rely on the cumulative CPU usage of the whole ECS as a metric.
    This metric facilitates an assessment of both the attack''s impact and the system''s
    resilience against such disruptions. In the event of a successful DoS attack,
    CPU utilization peaks, rendering the device non-functional in our use-case. To
    contextualize the metric, we compare three scenarios: the cumulative CPU usage
    in normal operation without a DoS attack (*NO*), the cumulative CPU usage when
    under a DoS attack without our resilient architecture (*DA*), and finally, the
    cumulative CPU usage under DoS attack with our resilient architecture (*DAR*).


    The repository, alongside our evaluation results, is publicly available on GitHub1.


    | DEFCON | Triggers             | Security Policies              |

    |--------|----------------------|--------------------------------|

    | 5      | CPU-usage < 30% OR   | Regular Attack Monitoring:     |

    |        | MQTT < 80k msgs/min  | Normal operating readiness     |

    | 4      | CPU-usage < 40% OR   | Increased Attack Monitoring:   |

    |        | MQTT < 100k msgs/min | Promptly detect attacks        |

    | 3      | CPU-usage < 50% OR   | Rate Limiting:                 |

    |        | MQTT < 120k msgs/min | Limit sensor data forwarding   |

    | 2      | CPU-usage < 60% OR   | Increase QoS of Critical Data: |

    |        | MQTT < 140k msgs/min | Ensure crit. data transmission |

    | 1      | CPU-usage > 60% OR   | Localize (shut down MQTT):     |

    |        | MQTT > 140k msgs/min | Prevent system outage          |


    TABLE I DEFCON LEVELS USED IN THE EVALUATION


    ## *C. Results*


    • Viability: We conducted three 20-minute simulation runs for every ECS node (6
    nodes in total). Randomly every minute, a threshold exceeding data point was seeded
    for each node (i.e., 20 adaptations per run per node; 60 adaptations per node
    in total). To minimize the impact of variability and random anomalies, we aggregated
    the AR into box plots in Fig. 3.


    Out of the 360 triggers, all were handled and responded to as expected by the
    deployed architecture. Every time one of


    <sup>1</sup>https://github.com/jku-lit-scsl/ecs-demo


    ![](_page_3_Figure_0.jpeg)


    Fig. 4. Results of the efficacy evaluation


    the nodes received a trigger, the node adapted the DEFCON level and enforced the
    respective policy accordingly. The AR of the nodes in Fig. 3 shows, that our architecture
    is viable to adapt timely in the event of a security incident.


    • Efficacy: To measure the efficacy, we conducted three simulation runs, one for
    each scenario (*NO*, *DA*, and *DAR*), and monitored the CPU usage of every node
    once a second. For the DoS attack runs (*DA* and *DAR*), we started the DoS attack
    5 minutes into the experiment and gradually attacked the other MQTT brokers in
    the ECS after 5 minutes.


    Fig. 4 displays the cumulative CPU usage of the ECS over 20 minutes for the different
    scenarios. In our evaluation three MQTT brokers were installed, leading to an
    increase in CPU at minutes 5, 10, and 15 for *DA*. In contrast, using our resilient
    architecture (c.f. *DAR*), the ECS nodes adapted once the first attack was detected,
    resulting in a lower cumulative CPU usage compared to *DA* throughout the attack.


    ## V. DISCUSSION


    The evaluation of our PoC has illuminated a balanced spectrum of advantages and
    challenges inherent to our proposed architecture. At the forefront of our findings
    is the system''s dynamic adaptability and resilience, particularly showcased through
    the integration and independent functionality of the MAPE-K loops across different
    architectural levels. This design not only fosters collaboration between layers
    but also ensures that the architecture can maintain operational integrity in scenarios
    of network disruption. Such flexibility is critical, allowing the system to continue
    functioning via a local MAPE-K loop and seamlessly resume inter-node knowledge
    sharing once connectivity is restored.


    The strategic implementation of DEFCON levels enhances the architecture''s adaptability,
    allowing dynamic adjustment of defenses against current threats and future vulnerabilities.
    However, this adaptability also introduces potential vulnerabilities, as attackers
    could exploit the system''s behavior by manipulating DEFCON criteria to induce
    specific responses, potentially compromising functionality or availability.


    Compounding this concern is the challenge of defining precise thresholds for DEFCON
    levels. Establishing these parameters requires extensive testing to ascertain
    the network''s and devices'' tolerance to different loads and threat scenarios.


    In our architecture, self-adaptation enabled by MAPE-K loops enhances system self-protection
    by dynamically adjusting to threats, highlighting the importance of self-adaptive
    processes in bolstering edge computing resilience against cyberattacks. Our proof
    of concept demonstrates the architecture''s potential in cybersecurity adaptability
    and resilience, while also emphasizing the need for precise calibration and protection
    against exploitation to optimize defense mechanisms against a wide range of threats.


    ## VI. RELATED WORK


    The literature survey conducted by Lara *et al.* [8] focuses on adaptive security
    systems that are based on MAPE-K. Although the discussed studies pertain to the
    same subject domain, their emphasis diverges from that of our study. They either
    prioritize other aspects of security, such as authorization, address predominantly
    domain-specific issues, such as those related to intelligent vehicles, or struggle
    to meet the SoS demands associated with ECS.


    Moreover, existing literature [13] that addresses ECS tends to broach the subject
    from a broader perspective. Such discussions, while valuable, stop short of offering
    tangible solutions or architectural frameworks tailored to the intricate demands
    of ECS. The explicit treatment of DoS attacks; when these threats are considered,
    the responses typically lack a multilayered architectural strategy for system
    defense. For instance, studies [16] might acknowledge the threat posed by DoS
    attacks but propose countermeasures that rely on a singular management component
    for security policy coordination. This approach contrasts with our proposed holistic
    model, which employs a novel, multi-level architectural strategy to bolster system
    security against such attacks.


    In essence, our work introduces a nuanced methodological approach that leverages
    the hierarchical nature of ECS to offer a comprehensive, adaptive security architecture.
    This architecture is designed to effectively counteract a spectrum of cybersecurity
    threats, including DoS attacks, through a multitiered adaptive strategy that goes
    beyond the conventional methodologies discussed.


    ## VII. FUTURE PLANS


    To validate the effectiveness of our proposed enhancements, we will conduct real-world
    testing in diverse environments. This will not only provide insights into the
    practical challenges of deployment but also help fine-tune our architecture to
    meet the nuanced needs of different operational contexts.


    We plan to develop more sophisticated anomaly detection algorithms to mitigate
    the risk of attackers exploiting our system''s adaptive behavior. These algorithms
    will leverage machine learning and artificial intelligence to identify and respond
    to unusual patterns that could indicate manipulation attempts, enhancing the system''s
    ability to distinguish between genuine threats and false triggers.


    Looking further ahead, we envision developing a predictive cybersecurity model.
    This ambitious goal involves harnessing big data and predictive analytics to forecast
    potential security threats before they materialize, allowing preemptive defensive
    measures to be enacted and thus redefining the landscape of proactive cybersecurity.


    ## VIII. CONCLUSION


    In conclusion, our study presents a novel advancement in the domain of software
    architectures by integrating a multilevel MAPE-K loop approach into edge computing
    systems to bolster cyber-resilience. This study showcases the practical utility
    and effectiveness of our proposed framework in an industrial setting, highlighting
    its potential to enhance security in edge computing environments against complex
    cyber threats. Through initial testing and evaluation, we have shown that our
    approach enhances edge computing systems'' adaptability, robustness, and security,
    paving the way for more resilient software architectures. Looking forward, we
    are committed to further refining our framework to address emerging threats and
    challenges, as well as to establish more robust defenses for edge computing architectures.
    Our work contributes to the broader discourse on cybersecurity, offering a scalable,
    dynamic solution that can be adapted across various industries and applications.
    As we continue to explore this promising field, we invite collaboration and further
    research to extend the boundaries of what can be achieved in securing edge computing
    infrastructures.


    ## ACKNOWLEDGMENT


    This work has been supported by the LIT Secure and Correct Systems Lab funded
    by the State of Upper Austria and the Linz Institute of Technology (LIT-2019-7-INC-316).


    ## REFERENCES


    - [1] Association for Computing Machinery. *ACM Digital Library*. 2023. URL: https
    : / / dl . acm . org/ (visited on 10/16/2023).

    - [2] Yuriy Brun et al. "Engineering Self-Adaptive Systems through Feedback Loops".
    In: *Software Engineering for Self-Adaptive Systems*. Vol. 5525. 2009, pp. 48–70.

    - [3] Keyan Cao et al. "An Overview on Edge Computing Research". In: *IEEE Access*
    8 (2020), pp. 85714–85728.

    - [4] Kun Cao et al. "A Survey on Edge and Edge-Cloud Computing Assisted Cyber-Physical
    Systems". In: *IEEE Transactions on Industrial Informatics* 17.11 (2021), pp.
    7806–7819.

    - [5] Rogério De Lemos et al. "Software Engineering for Self-Adaptive Systems:
    A Second Research Roadmap". In: *Software Engineering for Self-Adaptive Systems
    II*. Vol. 7475. 2013, pp. 1–32.

    - [6] Dan Dinculeana and Xiaochun Cheng. "Vulnerabilities ˘ and Limitations of
    MQTT Protocol Used between IoT Devices". In: *Applied Sciences* 9.5 (2019), p.
    848.

    - [7] Jeffrey O. Kephart and David M. Chess. "The vision of autonomic computing".
    In: *Computer* 36.1 (2003), pp. 41–50.

    - [8] Evangelina Lara et al. "Adaptive Security Based on MAPE-K: A Survey". In:
    *Applied Decision-Making: Applications in Computer Sciences and Engineering*.
    2019, pp. 157–183.

    - [9] Mohammed Laroui et al. "Edge and fog computing for IoT: A survey on current
    research activities & future directions". In: *Computer Communications*180 (2021),
    pp. 210–231.

    - [10] Felix Lau et al. "Distributed denial of service attacks". In: *SMC 2000
    Conference Proc.* Vol. 3. Oct. 2000, pp. 2275–2280.

    - [11] Microsoft. *Azure Stack Edge | Microsoft Azure*. 2024. URL: https://azure.microsoft.com/en-us/products/azurestack/edge
    (visited on 01/08/2024).

    - [12] Microsoft Security Response Center.*Microsoft Response to Layer 7 Distributed
    Denial of Service (DDoS) Attacks | MSRC Blog | Microsoft Security Response Center*.
    2023. URL: https://msrc.microsoft.com/blog/ 2023/ 06/microsoft - response - to
    - layer - 7 - distributed denial-of-service-ddos-attacks/ (visited on 01/08/2024).

    - [13] Victor Casamayor Pujol et al. "Edge Intelligence—Research Opportunities
    for Distributed Computing Continuum Systems". In:*IEEE Internet Computing* 27.4
    (2023), pp. 53–74.

    - [14] Qinglin Qi and Fei Tao. "A Smart Manufacturing Service System Based on
    Edge Computing, Fog Computing, and Cloud Computing". In: *IEEE Access*7 (2019),
    pp. 86769–86777.

    - [15] Tie Qiu et al. "Edge Computing in Industrial Internet of Things: Architecture,
    Advances and Challenges". In: *IEEE Communications Surveys & Tutorials*22.4 (2020),
    pp. 2462–2488.

    - [16] Michael Riegler, Johannes Sametinger, and Michael Vierhauser. "A Distributed
    MAPE-K Framework for Self-Protective IoT Devices". In: *18th Symposium on Software
    Engineering for Adaptive and Self-Managing Systems*. 2023, pp. 202–208.

    - [17] Mahadev Satyanarayanan. "The Emergence of Edge Computing". In: *Computer*
    50.1 (2017), pp. 30–39.

    - [18] Statista. *Edge computing market revenue worldwide from 2019 to 2025*.
    2023. URL: https://www.statista. com/ statistics/ 1175706/ worldwide - edge -
    computing market-revenue/ (visited on 10/16/2023).

    - [19] Ryhan Uddin, Sathish A. P. Kumar, and Vinay Chamola. "Denial of service
    attacks in edge computing layers: Taxonomy, vulnerabilities, threats and solutions".
    In:*Ad Hoc Networks* 152 (2024), p. 103322.

    - [20] Arielle Waldman. *Microsoft: DDoS attacks caused M365, Azure disruptions
    | TechTarget*. 2023.URL: https: //www.techtarget.com/searchsecurity/news/366542236/
    Microsoft - DDoS - attacks - caused - M365 - Azure disruptions (visited on 01/08/2024).

    - [21] Yinhao Xiao et al. "Edge Computing Security: State of the Art and Challenges".
    In: *Proc. of the IEEE*107.8 (2019), pp. 1608–1631.

    - [22] Ashkan Yousefpour et al. "All one needs to know about fog computing and
    related edge computing paradigms: A complete survey". In: *Journal of Systems
    Architecture* 98 (2019), pp. 289–330.'
  decisions:
    evaluation_prompt: 'Qualified. Reason: The abstract mentions assessing the viability
      and efficacy of the proposed methodology by leveraging real-world edge devices,
      indicating structured evaluation through empirical validation.'
    related_work_prompt: 'Qualified. Reason: The introduction discusses the unique
      design characteristics of edge computing systems and their susceptibility to
      attacks, referencing specific issues and existing architectural solutions. It
      also cites various sources (e.g., [1], [3], [4], [14], [19], [21]) that indicate
      engagement with prior research and related work in the field of edge computing
      and cybersecurity.'
    novelty_prompt: '- Qualified. Reason: The paper introduces a new methodology for
      enhancing the cyber-resilience of edge computing systems by incorporating the
      MAPE-K loop, which is explicitly stated as a novel approach in the abstract.'
    review_only_prompt: 'Qualified. Reason: The paper proposes a novel methodology
      for enhancing the cybersecurity of edge computing systems using the MAPE-K loop,
      presents a prototype framework, and discusses initial results, indicating new
      contributions rather than merely summarizing existing work.'
  llm_input_used: '## Abstract

    As edge computing continues to play a pivotal role in modern computing architectures,
    ensuring robust cybersecurity becomes imperative. This paper introduces our emerging
    results on a comprehensive approach to bolster the cyber-resilience of edge computing
    systems by incorporating the MAPE-K (Monitor, Analyze, Plan, Execute, and Knowledge)
    loop. The proposed methodology involves the application of the MAPE-K loop at
    different levels of an edge computing architecture, aiming to create a holistic
    defense mechanism against cyber attacks. We present a prototype of our framework
    and assess its viability and efficacy by leveraging real-world edge devices deployed
    in an industrial production setting. Initial evidence from our results suggests
    that this novel approach leads us to reconsider how we construct more resilient
    edge computing architectures.


    ## Introduction

    Edge Computing Systems (ECSs) are more popular than ever before. Media portray
    ECSs as one of the most significant phenomena of our time. Recent industry forecasts
    predict that market values will reach 317 billion U.S. dollars by 2026 [18], and
    scientific research communities have demonstrated a growing interest in ECS research
    in recent years. For example, a search for "edge computing" in the ACM Digital
    Library (16.10.2023) returns 675,121 results, of which 176,725 (or more than 26%)
    were published only in the last five years [1].


    The concept of edge computing entails the placement of substantial computing and
    storage resources at the outer edges of the Internet, i.e., in close proximity
    to the sensors [17]. For this reason, ECSs provide numerous benefits. ECSs satisfy
    ultra-low latency requirements, shift sensitive data processing from the cloud
    closer to the device, and combat the everincreasing energy demand [3]. ECSs are
    employed in a wide range of application scenarios. For example, in the context
    of smart manufacturing [14] or cyber-physical systems [4].


    While the ECS''s concept is widely used and has yielded promising results thus
    far, these systems'' unique design characteristics make them especially susceptible
    to malicious attacks [21]: (1) Most access control models only offer Coarse-Grained
    Access Control, which is unsatisfactory in edge computing due to the system''s
    complexity. (2) Due to the Operating System and Protocol Heterogeneity utilized
    by ECSs, it is challenging for security engineers to design a unified protection
    mechanism for edge computing. (3) Due to their rudimentary design, edge devices
    provide limited user feedback, resulting in increased Attack Unawareness among
    users. (4) ECSs are supplied with Weaker Computational Power compared to cloud
    servers. Therefore, these systems employ weaker defense systems and are consequently
    more susceptible to existing attacks.


    A prominent example of attacks leveraging these attack surfaces are Denial of
    Service (DoS) attacks, and the even more pervasive and severe Distributed Denial
    of Service (DDoS) attacks [19]. DoS attacks are defined as the deliberate endeavor
    of an attacker to obstruct the access of authorized users to the targeted resources
    of a service. This can be accomplished, for example, by flooding the (edge) device
    with requests, thereby obstructing legitimate traffic [10].


    Current architectural solutions to secure ECSs against these types of attacks
    lack the consideration of security-by-design (i), are not able to migrate security
    frameworks (ii), provide only fragmented coarse-grained access control (iii),
    or only provide isolated and passive defense mechanisms (iv) [21]. While all of
    these issues must be tackled in order to ensure the security of systems, the primary
    emphasis of this paper will be on the latter (iv).


    In summary, the threat posed by DoS attacks remains high and indicates that current
    countermeasures cannot prevent such attacks. New strategies will be required in
    the future to secure ECSs. Hence, we report in this paper our ongoing research,
    emerging results, and initial efforts toward securing ECS architectures by leveraging
    a self-adaptive holistic system architecture.


    The paper commences with an illustrative example from the real world (Section
    II). Following this, background information is presented in (Section III), accompanied
    by a description of the proposed approach in Section IV. The results are examined
    in the discussion (Section V), with Section VI reviewing related work. Future
    research directions are proposed in Section VII. Section VIII provides a comprehensive
    summary of the contributions made in the paper.'
  token_usage: 4522
  time_usage: 4.594760894775391
