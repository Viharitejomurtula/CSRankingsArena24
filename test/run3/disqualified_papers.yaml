papers:
- title: '**Quantum-dot Cellular Automata (QCA): A Survey**'
  abstract: ''
  keywords: '**— QCA (Quantum-dot Cellular Automata), Defect, fault model, testing.**'
  document: "#### I. INTRODUCTION\n\nContinued and fast dimensional scaling of CMOS\
    \ eventually will approach the fundamental limit [1]. Also, Short channel effects,\
    \ high power dissipation, quantum effects are limiting the further scaling of\
    \ current CMOS technology devices [2-3]. Emerging device technology can overcome\
    \ the scaling limitation in the current CMOS technology [1]. Single Electron Transistor\
    \ (SET) [4], Quantum-dot Cellular Automata (QCA) [5] and Resonant Tunneling Diodes\
    \ (RTD) [6] are some of the \"Beyond CMOS\" technologies. Among these evolving\
    \ nanotechnologies, Quantum-dot Cellular Automata is the most favorable technology\
    \ [1]. QCA is transistorless computational paradigm which can achieve device density\
    \ of 10<sup>12</sup> devices/cm<sup>2</sup> and operating speed of THz. QCA device\
    \ paradigm replaces FET based logic and exploit the quantum effects of small size.\n\
    \nQuantum-dot Cellular Automata is a mean of representing binary information on\
    \ cells, through which no current flows, and achieving device performance by the\
    \ coupling of those cells [5,7].\n\nThis paper presents the state of art survey\
    \ on QCA basics, implementation, fabrication, tools, defect characterization,\
    \ fault model and testing. Also the paper addresses the issues in some of the\
    \ methods and techniques. Further, the paper suggests the possible research area\
    \ of QCA.\n\nThe rest of the paper is organized as follows, Section II describes\
    \ the QCA background. Section III describes QCA defect analysis, fault model and\
    \ testing. The paper concludes in Section IV.\n\n#### II. QCA BACKGROUND\n\n#\
    \ A. *QCA Cell*\n\nUnlike current switching in CMOS technology, QCA encodes the\
    \ binary information as per the position of individual electrons. QCA is the array\
    \ of cells in which each cell consists of quantum dots also considered as sites\
    \ that are positioned at the corners of the square cell. The charge is localized\
    \ in the dots. Also, the cell consists of two mobile electrons that can tunnel\
    \ between the dots. Electron tunneling out of the cell is not possible due to\
    \ the potential barriers between cells. Two free electrons resides at the corners\
    \ of the cells, always diagonally due to Coulombic repulsion. Cell configurations\
    \ with four, five and six are available [5,7-8]. The four dot QCA cell with quantum\
    \ dot's number (site) is shown in Fig. 1 (a). The polarization (P) of the cell\
    \ is calculated by equation (1) [8].\n\n$$P = \\frac{\\left(\\rho\\_{\\perp} +\
    \ \\rho\\_{\\perp}\\right) - \\left(\\rho\\_{\\perp} + \\rho\\_{\\perp}\\right)}{\\\
    rho\\_{\\perp} + \\rho\\_{\\perp} + \\rho\\_{\\perp} + \\rho\\_{\\perp}}\\tag{1}$$\n\
    \nWhere *ρi* is expectation value of the number operator on site (dot) for the\
    \ ground state eigenfunction as given by equation (2). Where i is the quantum\
    \ dot's number 1, 2, 3, and 4 as depicted in Fig. 1 (a).\n\n$$\\rho\\_i = \\langle\
    \ \\mathbb{\\psi}\\_{\\,^0} \\vert \\stackrel{\\frown}{\\mathcal{U}}\\_{\\,^l}\
    \ \\vert \\mathbb{\\psi}\\_{\\,^0} \\rangle \\tag{2}$$\n\nWhere ψ 0 is ground\
    \ state of the cell and it is given in the equation (3)\n\n$$\\left|\\boldsymbol{\\\
    psi}\\_{\\;0}\\right\\rangle = \\sum\\_{j} \\boldsymbol{\\psi}^{\\;0}\\_{\\;j}\
    \ \\left|\\boldsymbol{\\phi}\\_{\\;j}\\right\\rangle \\tag{3}$$\n\nWhere φ *j*\
    \ is the *j th* basis vector and 0 ψ *j* is the coefficient of the basis vector.\
    \ It is determined by direct diagonalization of the Hamiltonian.\n\n![](_page_0_Figure_20.jpeg)\n\
    \nFig. 1. QCA cell (a) schematic (b) with polarization P = \"- 1\" (c) with polarization\
    \ P = \"+1\".\n\nElectrons are located diagonally for which cell polarization\
    \ is calculated. If the electrons are located as shown in Fig. 1(b) then according\
    \ to the equation 1, cell polarization P = - 1 is encoded as binary 0 (Logic 0).\
    \ In the same way, considering the electrons location as shown in Fig. 1(c), the\
    \ cell polarization P = +1 is encoded as binary 1 (Logic 1). Coulombic coupling\
    \ between cells causes the information flow in the QCA array.\n\nCell to Cell\
    \ response function is shown in Fig. 2. [9].\n\n![](_page_1_Figure_2.jpeg)\n\n\
    Fig. 2. The cell–cell response [9].\n\n, *ji*\n\nThe cell to cell response is\
    \ computed by solving the two particle Schrodinger equation [8]. In two-cells\
    \ *i, j* system, polarization of cell *j* is aligned with its neighbor cell *i*.\
    \ In this case cell *i* is considered as a driver. In N-cell system, for single\
    \ cell *i*, the two state model is calculated by the Hamiltonian given in equation\
    \ (4).\n\n$$\n\\hat{H}\\_i = \\begin{pmatrix}\n-\\frac{1}{2} \\sum\\_j E\\_{i,j}^k\
    \ P\\_j & -\\mathcal{Y}\\_i \\\\\n\\mathcal{Y}\\_i & \\frac{1}{2} E\\_{i,j}^k\
    \ P\\_j\n\\end{pmatrix} \\tag{4}\n$$\n\nWhere *<sup>i</sup>* γ is the tunneling\
    \ energy, *<sup>k</sup> E* , *ji* is the Kink energy between cells *i* and *j*\
    \ given by equation (5). Pj is the polarization of cell *j*. The Coulombic interaction\
    \ between two cells can be described by the kink energy Ekink. Kink energy is\
    \ the difference of electrostatic energies of two cells with opposite polarization\
    \ and same polarization [8].\n\n$$E\\_{kink}^{i,j} = E\\_{opposite}^{i,j} - E\\\
    _{same}^{i,j} \\tag{5}$$\n\n*<sup>E</sup>opposite* : Energy between cell *i* &\
    \ *j* with opposite polarization.\n\n, *ji <sup>E</sup>same* : Energy between\
    \ cell *i* & *j* with same polarization.\n\nThe electrostatic energy between two\
    \ cells is used to find the state energy. The electrostatic energy between cells\
    \ i and j is given by (6).\n\n$$E^{i,j} = \\frac{1}{4\\pi\\varepsilon\\_0\\varepsilon\\\
    _r} \\sum\\_{n=1}^{4} \\sum\\_{m=1}^{4} \\frac{q\\_n^i q\\_m^j}{\\left| r\\_n^i\
    \ - r\\_m^j \\right|} \\tag{6}$$\n\nWhere ε0 is the permittivity of free space,\
    \ εr is the relative permittivity of material, *i n q* is the charge in dot *n*\
    \ of cell *i*, *j m q* is the charge in dot m of cell *j*, *i n r* is the position\
    \ of nth dot in cell *i*, *j m r* is the position of mth dot in cell *j*, thus\
    \ *j m i n r* − *r* is the distance between nth dot in cell *i* and mth dot in\
    \ cell *j.*\n\n### B. *QCA Implementation*\n\nAccording to the material used to\
    \ realize QCA cell, the types of QCA are metal island [10, 11, 13-15], molecular\
    \ [16-20], magnetic [21-23] and semiconductor [9,24]. Among these realizations,\
    \ Molecular QCA is the most favorable, since it can operate at room temperature.\
    \ Also, from the fabrication point of view, molecular QCA is the most viable type.\
    \ Molecular QCA will be able to operate at the speed of THz with ultra low power\
    \ and extremely high device density [25].\n\n### 1. Metal QCA\n\nIn [10], the\
    \ Al-AlOx-Al tunnel junctions are fabricated on an oxidized Si substrate by a\
    \ standard electron beam– lithography and shadow evaporation techniques. This\
    \ metal QCA cell consists of four aluminum islands as dots, D1 to D4 which are\
    \ coupled with aluminum oxide tunnel junctions and capacitors. The two dots E1\
    \ and E2 are SET electrometers for sensing the output [11]. Ballistic pointcontacts,\
    \ STM method, and SET electrometer can be used to read the output. The cell is\
    \ shown in Fig. 3. [11, 12]. The metal based QCA latch is implemented and demonstrated\
    \ in [15] which was operated at the temperature of 70mK.\n\n![](_page_1_Picture_17.jpeg)\n\
    \nFig. 3. Metal QCA cell (a) Simplified Schematic Diagram of Four-dot Metal QCA\
    \ Cell [12] (b) shows the scanning electron micrograph of this QCA cell [13,14].\n\
    \n# 2. Molecular QCA\n\nMolecular QCA (mQCA) is considered as the promising implementation\
    \ for QCA circuits. It operates at room temperature with high device density,\
    \ and high operating speed. Molecular QCA cell is presented in [16-18].\n\nMolecular\
    \ implementation could also be fabricated with much higher uniformity than those\
    \ achievable with semiconductor or metal-island QCA implementations. Each molecule\
    \ acts as a cell in which redox centers acts as dots and tunneling is provided\
    \ by bridging ligands. Binary information is encoded with charge configurations.\
    \ Molecular QCA cell is shown in Fig.4. [19, 20].\n\n![](_page_2_Figure_1.jpeg)\n\
    \nFig. 4. Three states of six dot molecular QCA [16, 18]\n\nAn ab initio quantum\
    \ chemistry analysis of a molecular QCA, {(η5-C5H5)Fe(η5-C5H4)}4(η4-C4)Co(η5-C5H5)2+\
    \ molecule has been carried out in [19].\n\n#### 3. Magnetic\n\nCowburn and Welland\
    \ have developed and proposed a magnetic implementation of quantum dot cellular\
    \ automata (MQCA) [21, 22]. Unlike other types of QCA, it is based on the interaction\
    \ between magnetic nano-particles. In MQCA, information is propagated through\
    \ magnetic interactions. It is predicted that magnetic QCA can reach a speed of\
    \ about 100 MHz. The binary logic representation in magnetic quantum-dot cellular\
    \ automata is shown in Fig.5. A threeinput majority gate in magnetic QCA has been\
    \ fabricated in [23].\n\n![](_page_2_Figure_6.jpeg)\n\nFig. 5. Binary logic representation\
    \ in magnetic QCA. (a) Logic '1', (b) Logic '0', and (c) Null state.\n\n### 4.\
    \ Semiconductor\n\nSemiconductor quantum dots are nano-structured created from\
    \ a standard semiconductor material such as InAs/GaAs and GaAs/AlGaAs [9]. In\
    \ a semiconductor QCA, four semiconductor quantum-dots are placed at four different\
    \ corners of the substrate. Cell polarization is encoded as charge position, and\
    \ quantum-dot interaction relies on the electrostatic coupling. The advantage\
    \ of using semiconductor QCA is that it is based on materials that are well understood\
    \ and many fabrication techniques have been created to work with them. A possible\
    \ physics implementation of a QCA cell is shown in Fig 6. The\n\nelectric field\
    \ in the substrate is introduced by the top metal gate to deplete electrons in\
    \ the 2–D electron gas formed at the junction of the dielectric layer and the\
    \ substrate. Quantum dots are formed at locations where the metal gate is removed\
    \ to leave an exposed surface. Fabrication using GaAs/AlGaAs heterostructure with\
    \ a high-mobility twodimensional electron gas below the surface is demonstrated\
    \ in [24].\n\n![](_page_2_Figure_11.jpeg)\n\nFig. 6. The physical representation\
    \ of the semiconductor QCA cell.\n\n# *C. QCA Clocking*\n\nIn CMOS technology,\
    \ the clock is used to control the timing, mostly in sequential circuits. In QCA,\
    \ Clock provides the switching and power gain to the circuits [26]. The clock\
    \ signal is given to the each QCA cell in combinational as well as sequential\
    \ circuits to raise or lower the tunneling barrier between dots. The clock signals\
    \ are generated using the electric field. It is originated from wires buried below\
    \ the QCA surface using CMOS wires or CNT<sup>S</sup> (Carbon Nano Tube) [27].\n\
    \nIn [9], two types of switching method, abrupt and adiabatic are discussed. QCA\
    \ circuit may enter into metastable state in abrupt switching, hence it is not\
    \ suitable. Hence, adiabatic switching is used in which the cells are in the nonpolarized\
    \ state at the low barrier and allowed to change the polarization at the high\
    \ barrier.\n\nThe clocking scheme is proposed in [20]. It consists of 4 clock\
    \ signals or zones and each clock signal consists of four phases namely switch,\
    \ hold, release and relax as shown in Fig. 7. The frequency of each clock is same\
    \ with the phase shift of 90<sup>0</sup>each. One of the clock signals can be\
    \ considered the reference (phase = 0) and the others are delayed one (phase =\
    \ π/2), two (phase = π) and three (phase = 3π/2) quarters of a period as shown\
    \ in Fig. 7. Clocking is done by electrostatically switching the cell from a null\
    \ state, in which cell holds no binary information. In switch phase, the cell\
    \ state is determined by its neighbors, to a locked state, in which the state\
    \ is independent of its neighbors. The whole QCA circuit is divided into different\
    \ clock zones and each clock signal is given to its respective zone. During the\
    \ information flow, the cells of each clock zone passes through all four phases\
    \ of that respective clock zone. The information is transfer after these four\
    \ phases.\n\n![](_page_3_Figure_0.jpeg)\n\nFig. 7. Clocking scheme.\n\nIn the\
    \ switch phase, the barriers are raised and the cells become polarized according\
    \ to the polarization of their driver. This is the clock phase during which actual\
    \ computation occurs. At the end of this clock phase, the barriers are high and\
    \ it suppress any kind of tunneling. Now the cell polarization is fixed. During\
    \ the hold phase, the barriers are held at high value and the cell is now acting\
    \ as an input to the next stage. Next, in the release phase, the barriers are\
    \ lowered and the cells are allowed to relax to an unpolarized state. In the relaxed\
    \ phase, the cell barriers remain lowered, keeping the cells in an unpolarized,\
    \ neutral state. After this fourth phase, the subsystem will return to the first\
    \ clock phase and repolarize. For reliable kink-free computation the number of\
    \ cells allowed in one clock zone *E*\n\nmust be <= *TK B k e* , Where Ek is kink\
    \ energy, KB is Boltzmann constant and T is the operating temperature in degree\
    \ Kelvin. Two dimensional (2D) clocking scheme is proposed in [28**,** 29]. It\
    \ is based on the parallel execution and processing in clocking zones within a\
    \ different timing framework. Ripple Clock Schemes for QCA Circuits is proposed\
    \ in [30]. Bennett clocking of QCA has been described in [31].\n\n*Assigning four\
    \ clock signal causes delay in the final output as per the number of clocks required\
    \ for the particular circuit. So large circuit may have more delay. Clock zone\
    \ assignment is the critical part during QCA circuit layout implementation and\
    \ simulation. Hence, development of concrete and novel clocking scheme is required.\
    \ Research in advanced clocking scheme can be carried out.* \n\n#### D. *QCA Basic\
    \ Elements*\n\nThe basic building blocks of QCA are Majority voter (MV), inverter\
    \ and binary wire [32]. Also, 45<sup>0</sup> inverter chain, coplanar wire crossing\
    \ and multilayer crossover are proposed in [32].\n\nThe MV is the 3-input basic\
    \ primitives which consists of 5 cell configuration as shown in Fig. 8 (a). The\
    \ cells A, B, C are input cells, the middle cell is the device cell which has\
    \ the polarization of the majority of the inputs and right hand side cell is the\
    \ output cell which has same polarization as device cell.\n\n![](_page_3_Figure_8.jpeg)\n\
    \nFig. 8. QCA Elements (a) Majority Voter (b) MV as AND and OR gates (c) inverter\
    \ (d) binary wire\n\nThe output of the MV, as indicated by the name is determined\
    \ by the majority of its three inputs. MV implements the Boolean function F =\
    \ AB + BC + AC. Where F is the output and A, B and C are the inputs.\n\nFor example,\
    \ if two of the inputs are low, the output is low. If two of the inputs are high,\
    \ then output is high. Here high refers to the polarization state P = +1, and\
    \ low refers to the polarization state P = -1. The truth table of a majority gate\
    \ covering all possible combination of inputs and corresponding output is shown\
    \ in Table 1. 2-input AND and OR logic implementations are possible by keeping\
    \ one of the inputs of MV to fixed polarization P = -1 and P = +1 respectively\
    \ as shown in Fig. 8(b).\n\nTable 1 Truth table of majority gate\n\n| A | B |\
    \ C | F |\n|---|---|---|---|\n| 0 | 0 | 0 | 0 |\n| 0 | 0 | 1 | 0 |\n| 0 | 1 |\
    \ 0 | 0 |\n| 0 | 1 | 1 | 1 |\n| 1 | 0 | 0 | 0 |\n| 1 | 0 | 1 | 1 |\n| 1 | 1 |\
    \ 0 | 1 |\n| 1 | 1 | 1 | 1 |\n\nQCA inverter is shown in Fig. 8(c), is another\
    \ fundamental logic gate in QCA with one input and one output. It takes the input\
    \ logic and produces its complement logic on output. The truth table of it is\
    \ given in Table 2. If the input is logic high, the output will be low. If the\
    \ input is logic low, the output will be high. Many implementations are possible\
    \ for inverter but the inverter shown in Fig. 8(c) is considered as robust as\
    \ inversion take place in two paths.\n\n|    |     | Table 2 Truth table for QCA\
    \ inverter |\n|----|-----|--------------------------------------|\n| In | Out\
    \ |                                      |\n| 0  | 1   |                     \
    \                 |\n| 1  | 0   |                                      |\n\nThe\
    \ QCA binary wire shown in Fig. 8(d) is used to transfer information from one\
    \ part of the circuit to another. In a QCA circuit, a wire not only helps in information\
    \ transfer, it actually can performs some computational operation on the information\
    \ to be transferred.\n\n# E. *Fabrication*\n\nThe key issue in the QCA fabrication\
    \ is the expensive nanoscale lithography. Self-assembly method is the alternative\
    \ to it. The possibility of molecular manipulation through the use of Scanning\
    \ Acoustic Microscopy (SAMs) and supramolecular Chemistry using self-assembly\
    \ is presented in [33]. Lithographic resolution of 5 nm using a cold-development\
    \ technique is demonstrated in [34]. In [34] high-resolution Electron Beam Lithography\
    \ (EBL) and molecular lift-off is applied to pattern Creutz–Taube molecules on\
    \ the scale of a few nanometers for QCA. Molecular QCA array by electric field\
    \ from the FeIII-RuII configuration to the FeII-RuIII configuration is demonstrated\
    \ in [35]. Two ferrocene and two ferrocenium moieties as a component for charge-coupled\
    \ QCA circuits as a assembly of a symmetric square Cell is shown in [36]. Ions\
    \ and the associated counter ions can disrupt the correct flow of information\
    \ in molecular QCA. Self-doping mechanism which incorporates the counterion covalently\
    \ into the structure of a neutral molecular cell is presented in [37]. All discussed\
    \ fabrication of QCA is done as experimental point of view only.\n\n# F. *Tools*\n\
    \nThe research has been done in QCA simulation and synthesis tools. The available\
    \ tools are MAQUINAS [38], QBert [39], QCA-LG [40], and QCADesigner [41]. MAQUINAS\
    \ and QCADesigner are rely on a simulation engine that solves the Schrödinger\
    \ equation for modeling physical interactions within the considered set of cells\
    \ in the circuit. MAQUINAS uses adiabatic switching and time independent Schrodinger\
    \ equation is solved to calculate polarization state of each cell. Fast simulator\
    \ for QCA digital logic, QBART is developed in [39]. Automatic layout generation\
    \ tool QCA-LG is developed in [40]. QCADesigner [41] is the most widely used QCA\
    \ layout simulator. It uses two simulation engines namely bistable approximation\
    \ and coherence vector. All versions of QCADesigner are available on [42]. The\
    \ library of basic QCA elements in Hardware Description Language, Verilog (HDLQ)\
    \ is proposed in [43]. This library also incorporated with fault injection and\
    \ bidirectionality. In [44] a SPICE macro model for QCA has been proposed and\
    \ experimentally verified. Polarization error and power estimation tool for QCA,\
    \ QCAPro is proposed in [45]. CAD tool, HDLM for magnetic QCA, based on Verilog\
    \ HDL is proposed in [46]. HDL models for a magnetic QCA cell and building blocks\
    \ are proposed which ensure magnetization, clocking, and signal propagation.\n\
    \n Synthesis is the significant process in any digital design flow. Synthesis\
    \ methods for digital logics into QCA basic primitives are proposed in [47-51].\
    \ Zhang et al [48] have proposed AND/OR-based logic synthesis for QCA combinational\
    \ circuit. This method reduces the number of MVs to compute three variable Boolean\
    \ functions by simplifying the conversion of Sum-of-Product (SOP) expressions\
    \ into QCA majority logic. Zhang et al [48] have proposed the logic synthesis\
    \ tool MALS for MV-based logic. In [48], each decomposed subcircuits using maximum\
    \ four MVs are implemented. In [49] efficient decomposition scheme is introduced\
    \ which removes the redundancies produced in the process of converting a decomposed\
    \ network into a majority network. Minimal majority gate mapping with a Majority\
    \ expression Look-Up Table (MLUT) based algorithm is developed in [50].\n\nAbove\
    \ discussed methods for logic synthesis are limited for small Boolean functions\
    \ and so fundamental algebra for nmajority is developed in [51]. Recently, heuristic\
    \ based majority/minority logic synthesis methodology is proposed in [52]. More\
    \ research is required for the development of synthesis methods and tools.\n\n\
    *Research in QCA CAD tool development needs much attention and can be carried\
    \ out. As of now no commercial simulation and synthesis tool is available.* \n\
    \n# III. DEFECT, FAULT, FAULT MODELS AND TESTING OF QCA DEVICES AND CIRCUITS\n\
    \n# A. *Defects*\n\nQCA devices are prone to defects due to the nanoscale. The\
    \ survey of defect characterization has been carried out and presented in [53].\
    \ QCA defect classification is shown in Fig. 9. Defects during molecular QCA manufacturing\
    \ can occur in two phases namely synthesis and deposition. In the synthesis phase,\
    \ the individual cells (molecule) are manufactured and in the deposition phase\
    \ the cells are placed in a specific location on the surface. Possibility of defects\
    \ in metal and molecular QCA implementations are discussed in [54]. It is stated\
    \ that wrong dot size or shape is possible because the targeted region is either\
    \ under or over exposed during EBL. Single Electron Fault (SEF) in QCA are characterized\
    \ and analysed in [55].\n\nAs mentioned in [56], occurrence of missing and extra\
    \ dot or electrons is very less due to the ease of purification of small inorganic\
    \ molecules. It is considered that these defects causes fatal errors and are easy\
    \ to detect. Perhaps defects like cell misalignment, rotation, displacement, missing,\
    \ addition occurs in the deposition phase are to be analyzed.\n\n![](_page_5_Figure_0.jpeg)\n\
    \nFig. 9. QCA Defect Classification [48].\n\n# 1. Cell Misalignment Defects\n\n\
    In misalignment defect, the cell of the defect free QCA device get displaced horizontally\
    \ from its original position. If the cell is displace laterally then it is considered\
    \ as cell displacement defects. Initially, Tahoori et al [57, 58] described the\
    \ cell misalignment and displacement defects in basic QCA primitive MV, binary\
    \ wire and inverter chain. Extensive simulation analysis of cell misalignment\
    \ and displacement defects for MV is carried out using QCADesigner.\n\nThe displacement\
    \ and misalignment of input cells of MV is shown Fig. 10 and 11 respectively [57].\
    \ Displacement defect in double inverter chain and binary wire is also reported\
    \ in [57]. It observed that the horizontal cell input cell (input B) is most dominant\
    \ cell. In MV, cell misalignment by the distance of greater or equal to half of\
    \ the cell size causes undesired output. The cell displacement defect has less\
    \ catastrophic effects on the functionality of an MV compared to cell misalignment\
    \ defects. It is analysed that the double binary wire is more defect tolerant\
    \ than the inverter chain in case of cell displacement defects.\n\nKink energy\
    \ discussed earlier can be used to calculate the output cell polarization of any\
    \ QCA device in case of cell misalignment and displacement defects.\n\nThe misalignment\
    \ defects have more catastrophic effect on MV functionality compared to displacement\
    \ defect, because if any cell get misaligned in right or left direction then the\
    \ kink energy calculation differs and the output cell polarization may be undesired\
    \ depending upon the distance. In cell displacement defect in MV, if cell get\
    \ displaced by the distance less than or equal to the radius of effect then the\
    \ output remains unaffected. Radius of effect is a distance from the centre of\
    \ one cell to another cell which interacted with each other. Cells are not interacting\
    \ if a cell to cell distance is more than the radius of effect. The radius of\
    \ effect can be set during the simulation in QCADesigner tool.\n\n![](_page_5_Figure_8.jpeg)\n\
    \nFig. 10. Displacement in MV. (a) Fault free. (b) Displace A. (c) Displace B.\
    \ (d) Displace all inputs and output. (e) Displace all inputs. (f) Displace A\
    \ and B.\n\n![](_page_5_Figure_10.jpeg)\n\nFig. 11. Misalignments in MV (a) A\
    \ misalignment (b) A misalignment (c) C misalignment (d) C misalignment (e) A,\
    \ C misalignment (f) A, C misalignment (g) B misalignment.\n\n*Yongqiang et al*\
    \ [59] examined the effect of cell movement in horizontal and vertical directions\
    \ at the same time (twodimensions) for QCA fundamental devices MV, Inverter and\
    \ wire. *Gabriel et al* [60] analyzed the behavior of QCA building blocks under\
    \ the influence of random cell displacement defect. In [61], cell displacements\
    \ of interconnect is analysed and maximum allowable displacement is determined.\n\
    \n#### 2. Cell Rotation Defects\n\nYang et al [62] analysed the behaviour of QCA\
    \ devices in presence of cell rotation. Further they have presented model for\
    \ cell rotation effect using modified coherence vector formalism for permissible\
    \ rotational angle.\n\n3. Missing and Additional Cell Defects\n\nDuring the lithography\
    \ process, improper removal of resist causes extra cell attachment (additional)\
    \ or missing cell defects. These defects also depends on the chemical\n\ncompound\
    \ used during the lithography. Modelling of additional cell can be done by adding\
    \ extra cell to the periphery of device and circuit. In the same way modelling\
    \ of missing cell can be done by removing the cell from device or circuit [56].\
    \ *Dysart et al* [56] analyzed the effects of missing cell defects in QCA wire\
    \ assembled by a molecular implementation.\n\n*Momenzadeh et al* [63] modeled\
    \ single missing and additional cell defects in molecular QCA devices like Majority\
    \ Voter (MV), inverter, fanout and L-Shaped. Also fault set corresponding to single\
    \ missing and additional cell defects is proposed in [63] and mentioned in Table\
    \ 3. It is observed that binary wire is less prone to the single missing cell\
    \ defects. Additional cell does not alter the functionality of QCA devices except\
    \ inverter for some cases. Huang et al [64] presented the single missing and additional\
    \ cell defect characterization of sequential QCA circuits which is based on molecular\
    \ QCA.\n\nTable 3 Fault Set caused by single missing cell [63]\n\n| Device   \
    \         | Fault Set       |  |\n|-------------------|-----------------|--|\n\
    | Majority<br>Voter | S_a_B           |  |\n| (MV)              | Maj (A', B,\
    \ C') |  |\n| Inverter          | S_a_A           |  |\n| L-shaped wire     |\
    \ S_a_A'          |  |\n| Fanout            | S_a_A'          |  |\n\nSimulation\
    \ based single cell omission defect in MV, binary wire and wire crossing for 1-bit\
    \ full adder has been reported in [57]. It is analyzed that the input cell B of\
    \ MV is dominating cell. Output of MV doesn't altered due to missing of input\
    \ cell B. Inversion of input A and C takes place in case of device missing cell.\
    \ Single additional and missing cell defects in QCA sequential circuit are analyzed\
    \ in [65].\n\nAgain the kink based energy calculation can be applied to calculate\
    \ the polarization of device output cell in case of single missing and additional\
    \ cell defect.\n\n# 4. Defects in Clock Circuitry\n\nPossibility of defect occurrence\
    \ in clock circuitry is discussed in [66]. Phase shifts can result from manufacturing\
    \ variations in each of the four required clock sources or from uneven path lengths\
    \ [66]. The impact of QCA device scaling on defects is presented in [67]. Liu\
    \ et al [68] explored the behavior of metal-dot QCA systems under stressed caused\
    \ by the high temperature operation, high speed operation, and random variation\
    \ in parameter values. Defect caused by fabrication variations in Magnetic Quantum-dot\
    \ Cellular Automata at device, circuit, and architectural level is analyzed in\
    \ [69]. Information-theoretic approach for investigation relationship between\
    \ defect tolerance and redundancy in QCA devices is presented in [70].\n\nFault\
    \ tolerant QCA devices and circuits are presented in [71-77]. Fault analysis of\
    \ QCA combination circuit at layout and logic level is presented in [78]. Fabrication\
    \ defects of a real molecular QCA wire built with ad hoc synthesized bisferrocene\
    \ Molecules are analyzed in [79]. Also, in [80], the possible defects and causes\
    \ of faults for a molecular QCA device are identified. The process variations\
    \ effects in terms of yield and output error Rate for QCA based NanoMagnet Logic\
    \ has been studied in [81].\n\n*Apart from the available defect, multiple missing\
    \ or additional cell defects can occur and possibly must be analyzed. Since self-assembly\
    \ fabrication process for molecular QCA is prone to defects, in near future if\
    \ QCA circuit and system exists, the key issue, defects must be addressed to avoid\
    \ the failure of it. Looking into the reliability of QCA, extreme need for fault\
    \ tolerant circuit is required. Also analysis of QCA oriented defects, its modeling\
    \ and development of corresponding fault model is required.* \n\n# *B. Faults,\
    \ Fault models and Testing*\n\nThe present-day technology uses single stuck at\
    \ fault model (SSF) where the line is observed to be permanently stuck at either\
    \ logic 0 (S\\_A\\_0) or logic 1 (S\\_A\\_1). The existing stuck-at-fault model\
    \ can provide test generation for QCA circuits. Also, conventional ATPG tool can\
    \ be exploited for QCA [58]\n\nInitially the logic level testing of QCA is presented\
    \ in [57]. Following properties for QCA MV with A, B, C as input lines of MV and\
    \ Z as output line are investigated in [57-58, 82]\n\n- For MV with input values\
    \ *a, b* and *c* and output *z,* if all inputs are flipped, *abc→a΄b΄c΄*, then\
    \ the output will also be flipped, i.e. *z→z΄.*\n- If there is inversion at any\
    \ input and/or the output of the MV, above property still holds\n- The stuck-at-v\
    \ fault on any input or output line of the voter is detectable by *abc* if and\
    \ only if the stuck-at-*v΄* fault on that line is detectable by *a΄b΄c΄*\n- If\
    \ there are some inversions at any inputs and/or the output of the MV, then above\
    \ property still holds\n- Any vector that detects an input S\\_A\\_0 fault will\
    \ also detect an output S\\_A\\_0 fault\n\nThe stuck at test set is developed\
    \ to test all the simulated defects in MV [57]. It shown that the few test vector\
    \ set is effectively detects all the simulated defects in MV with 100% test coverage.\
    \ Design for Testability (DFT) scheme for QCA circuit is proposed in [57-58,82].\
    \ Two lines used to make MV as AND and OR gate can be viewed as control lines\
    \ to implement DFT scheme in the network of MVs acting as AND and OR gates.\n\n\
    First comprehensive test generation methodology based on Boolean satisfiability\
    \ (SAT) for combinational QCA circuits is proposed in [83,84]. The authors have\
    \ shown that SSF set is not sufficient to detect all the simulated QCA defects\
    \ in MV sothat further test generation is required for additional test vectors.\
    \ Proposed ATPG generated test vectors are given to the fault simulator, the track\
    \ on test vector applied to each MV is kept.\n\nIf there exists a majority gate\
    \ which does not receive a 100% defect test set, additional test generation is\
    \ performed. Once all the defects have been covered, a test set containing the\
    \ SSF test set and additional QCA vectors is obtained. The proposed ATPG is tested\
    \ on MCNC *(*Microelectronics Center of North Carolina*)* benchmark circuits.\
    \ All of the benchmarks were first synthesized into multi-level majority networks\
    \ using the logic synthesis tool MALS [48]. The bridging faults in QCA interconnects\
    \ are also targeted in [83,84].\n\n*Faisal Karim et al* [85] also developed the\
    \ combinational ATPG using extended version of PODEM algorithm for majority and\
    \ minority logic networks mostly targeting QCA. A genetic algorithm was used to\
    \ fill-in the unspecified values in the test patterns produced by the ATPG in\
    \ order to achieve compaction on the final test set size. The modified PODEM algorithm\
    \ was tested on a set of MCNC benchmark circuits. Probability based controllability\
    \ and observability approaches were taken into consideration to guide this ATPG.\n\
    \n*Probability based testability approach is applicable to the fanout-free combinational\
    \ circuits. It fails for the circuits containing fanout points due to the reconvergent\
    \ path. So, Sandia Controllability Observability Analysis Program (SCOAP) based\
    \ testability approach can be the alternative to probability based testability\
    \ approach.* \n\nBasic fault model for single input missing cell deposition defect\
    \ for QCA MV is developed in [86]. In [86], test generation for single input missing\
    \ cell deposition defects in the QCA circuit consists of MV as AND and OR gate\
    \ is carried out using the proposed properties and corresponding fault model.\
    \ The proposed properties are as follows:\n\n**Property 1**. If S\\_A\\_B fault\
    \ is present at the output of MV as AND gate then assign A=0 or B' and B=1.\n\n\
    **Property 2.** If S\\_A\\_B fault is present at the output of MV as OR gate then\
    \ assign A=1 or B' and B=0.\n\n**Property 3.** While propagating the values at\
    \ the output of MV as AND or OR gate, justify remaining fanin by the noncontrolling\
    \ value of the gate.\n\nIn [87], test vectors to exhaustively test the functionality\
    \ of any 3-input majority gate and arithmatic circuit are generated to find crosstalk\
    \ which is modelled as dominant bringing faults. Method for In-Circuit-Testing\
    \ of QCA circuits is shown in [88].\n\n*Available literature suggested the application\
    \ of test generation method for current silicon technology to the QCA. Different\
    \ type of test generation for QCA oriented fault models can be possible and explored.\
    \ Also the conventional test generation algorithms and fault models can be explored\
    \ for QCA combinational and sequential circuits.* \n\n# IV. CONCLUSION AND DISCUSSION\n\
    \nThe systematic survey on QCA, its defect analysis and testing method is carried\
    \ out in this paper. Solid need of CAD tools for QCA circuit simulation and synthesis\
    \ is required.\n\nAs occurrence of defects are possible in QCA devices due to\
    \ the nanoscale nature, this paper more emphasizes on the QCA defect, fault model\
    \ and testing.\n\nMostly the simulation based defect analysis is carried out in\
    \ the referred literature. Defect analysis through mathematical representation\
    \ is required. Apart from the available defects in synthesis and deposition phase,\
    \ defects like multiple missing cells, multiple additional cell during the deposition\
    \ phase must be looked upon.\n\nNovel QCA oriented fault model must be evolved\
    \ to develop the test generation methods. Perhaps, the available test generation\
    \ algorithms can also be explored.\n\nThis paper will be useful to understand\
    \ the QCA in depth for the beginners. Also, it will be helpful for the researcher\
    \ to find the various area to work upon.\n\n#### REFERENCES\n\n[1] \"International\
    \ Technology Roadmap for Semiconductors (ITRS)\", 2015 Edition,\n\nhttps://www.semiconductors.org/clientuploads/Research\\\
    _Technology/I TRS/2015/6\\_2015 ITRS 2.0 Beyond CMOS.pdf\n\n- [2] Peercy, Paul\
    \ S. \"The drive to miniaturization.\" *Nature* 406, no. 6799 (2000): 1023-1026.\n\
    - [3] Meindl, James D. \"Beyond Moore's law: The interconnect era.\" *Computing\
    \ in Science & Engineering* 5, no. 1 (2003): 20-24.\n- [4] Likharev, Konstantin\
    \ K. \"Single-electron devices and their applications.\" *Proceedings of the IEEE*\
    \ 87, no. 4 (1999): 606-632.\n- [5] Lent, Craig S., and P. Douglas Tougaw. \"\
    Lines of interacting quantum‐ dot cells: A binary wire.\" *Journal of applied\
    \ Physics* 74, no. 10 (1993): 6227-6233.\n- [6] Chen, Kevin J., Koichi Maezawa,\
    \ and Masafumi Yamamoto. \"InP-based high-performance monostable-bistable transition\
    \ logic elements (MOBILEs) using integrated multiple-input resonant-tunneling\
    \ devices.\" *IEEE Electron Device Letters* 17, no. 3 (1996): 127-129.\n- [7]\
    \ Lent, Craig S., P. Douglas Tougaw, Wolfgang Porod, and Gary H. Bernstein. \"\
    Quantum cellular automata.\" *Nanotechnology* 4, no. 1 (1993): 49-57.\n- [8] Lent,\
    \ Craig S., P. Douglas Tougaw, and Wolfgang Porod. \"Quantum cellular automata:\
    \ the physics of computing with arrays of quantum dot molecules.\" In *Physics\
    \ and Computation, 1994. PhysComp'94, Proceedings. Workshop on*, pp. 5-13. IEEE,\
    \ 1994.\n- [9] Lent, Craig S., and P. Douglas Tougaw. \"A device architecture\
    \ for computing with quantum dots.\" *Proceedings of the IEEE* 85, no. 4 (1997):\
    \ 541-557.\n- [10]Orlov, A. O., I. Amlani, G. H. Bernstein, C. S. Lent, and G.\
    \ L. Snider. \"Realization of a functional cell for quantum-dot cellular automata.\"\
    \ *Science* 277, no. 5328 (1997): 928-930.\n- [11]Amlani, Islamshah, Alexei O.\
    \ Orlov, Gregory L. Snider, Craig S. Lent, and Gary H. Bernstein. \"External charge\
    \ state detection of a double-dot system.\" *Applied physics letters* 71, no.\
    \ 12 (1997): 1730-1732.\n\n[12]Lombardi, Fabrizo, and Jing Huang. Design and test\
    \ of digital circuits by quantum-dot cellular automata. Artech House, Inc., 2007.\n\
    \n- [13]Amlani, Islamshah, Alexei O. Orlov, Gregory L. Snider, Craig S. Lent,\
    \ and Gary H. Bernstein. \"Demonstration of a functional quantum-dot cellular\
    \ automata cell.\" *Journal of Vacuum Science & Technology B: Microelectronics\
    \ and Nanometer Structures Processing, Measurement, and Phenomena* 16, no. 6 (1998):\
    \ 3795-3799.\n- [14]Amlani, Islamshah, Alexei O. Orlov, Gregory L. Snider, Craig\
    \ S. Lent, and Gary H. Bernstein. \"Demonstration of a six-dot quantum cellular\
    \ automata system.\" *Applied Physics Letters* 72, no. 17 (1998): 2179-2181.\n\
    - [15]Orlov, Alexei O., Ravi K. Kummamuru, Rajagopal Ramasubramaniam, Geza Toth,\
    \ Craig S. Lent, Gary H. Bernstein, and Gregory L. Snider. \"Experimental demonstration\
    \ of a latch in clocked quantum-dot cellular automata.\" *Applied Physics Letters*\
    \ 78, no. 11 (2001): 1625-1627.\n- [16]Lieberman, Marya, Sudha Chellamma, Bindhu\
    \ Varughese, Yuliang Wang, Craig Lent, Gary H. Bernstein, Gregory Snider, and\
    \ Frank C. Peiris. \"Quantum‐dot cellular automata at a molecular scale.\" *Annals\
    \ of the New York Academy of Sciences* 960, no. 1 (2002): 225-239.\n- [17]Lent,\
    \ Craig S., Beth Isaksen, and Marya Lieberman. \"Molecular quantum-dot cellular\
    \ automata.\" *Journal of the American Chemical Society* 125, no. 4 (2003): 1056-1063.\n\
    - [18]Blair, Enrique P., and Craig S. Lent. \"Quantum-dot cellular automata: an\
    \ architecture for molecular computing.\" In *Simulation of Semiconductor Processes\
    \ and Devices, 2003. SISPAD 2003. International Conference on*, pp. 14-18. IEEE,\
    \ 2003.\n- [19]Lu, Yuhui, and Craig S. Lent. \"Theoretical study of molecular\
    \ quantumdot cellular automata.\" *Journal of Computational Electronics* 4, no.\
    \ 1-2 (2005): 115-118.\n- [20]Lent, Craig S., and Beth Isaksen. \"Clocked molecular\
    \ quantum-dot cellular automata.\" *IEEE Transactions on Electron Devices* 50,\
    \ no. 9 (2003): 1890-1896.\n- [21]Cowburn, R. P., and M. E. Welland. \"Room temperature\
    \ magnetic quantum cellular automata.\" *Science* 287, no. 5457 (2000): 1466-1468.\n\
    - [22]Bernstein, Gary H., Alexandra Imre, V. Metlushko, A. Orlov, L. Zhou, L.\
    \ Ji, György Csaba, and Wolfgang Porod. \"Magnetic QCA systems.\" *Microelectronics\
    \ Journal* 36, no. 7 (2005): 619-624.\n- [23]Imre, Alexandra, G. Csaba, L. Ji,\
    \ A. Orlov, G. H. Bernstein, and W. Porod. \"Majority logic gate for magnetic\
    \ quantum-dot cellular automata.\" *Science* 311, no. 5758 (2006): 205-208.\n\
    - [24]Perez-Martinez, F., I. Farrer, D. Anderson, G. A. C. Jones, D. A. Ritchie,\
    \ S. J. Chorley, and C. G. Smith. \"Demonstration of a quantum cellular automata\
    \ cell in a Ga As⁄ Al Ga As heterostructure.\" *Applied physics letters* 91, no.\
    \ 3 (2007): 032102.\n- [25]Lent, Craig S., and Gregory L. Snider. \"The development\
    \ of quantumdot cellular automata.\" In *Field-Coupled Nanocomputing*, pp. 3-20.\
    \ Springer Berlin Heidelberg, 2014.\n- [26]Toth, Geza, and Craig S. Lent. \"Quasiadiabatic\
    \ switching for metalisland quantum-dot cellular automata.\" *Journal of Applied\
    \ physics* 85, no. 5 (1999): 2977-2984.\n- [27]Frost, Sarah E., Timothy J. Dysart,\
    \ Peter M. Kogge, and C. S. Lent. \"Carbon nanotubes for quantum-dot cellular\
    \ automata clocking.\" In *Nanotechnology, 2004. 4th IEEE Conference on*, pp.\
    \ 171-173. IEEE, 2004.\n- [28]Vankamamidi, Vamsi, Marco Ottavi, and Fabrizio Lombardi.\
    \ \"Twodimensional schemes for clocking/timing of QCA circuits.\" *IEEE Transactions\
    \ on Computer-Aided Design of Integrated Circuits and Systems* 27, no. 1 (2008):\
    \ 34-44.\n- [29]Vankamamidi, Vamsi, Marco Ottavi, and Fabrizio Lombardi. \"Clocking\
    \ and cell placement for QCA.\" In *Nanotechnology, 2006. IEEE-NANO 2006. Sixth\
    \ IEEE Conference on*, vol. 1, pp. 343-346. IEEE, 2006.\n- [30]Purohit, Prafull.\
    \ *Ripple clock schemes for quantum-dot cellular automata circuits*. Rochester\
    \ Institute of Technology, 2012.\n- [31]Lent, Craig S., Mo Liu, and Yuhui Lu.\
    \ \"Bennett clocking of quantumdot cellular automata and the limits to binary\
    \ logic scaling.\" *Nanotechnology* 17, no. 16 (2006): 4240.\n- [32]Tougaw, P.\
    \ Douglas, and Craig S. Lent. \"Logical devices implemented using quantum cellular\
    \ automata.\" *Journal of Applied physics* 75, no. 3 (1994): 1818-1825.\n- [33]Parviz,\
    \ B. Amir, Declan Ryan, and George M. Whitesides. \"Using selfassembly for the\
    \ fabrication of nano-scale electronic and photonic\n\ndevices.\" *IEEE transactions\
    \ on advanced packaging* 26, no. 3 (2003): 233-241.\n\n- [34]Hu, Wenchuang, Koshala\
    \ Sarveswaran, Marya Lieberman, and Gary H. Bernstein. \"High-resolution electron\
    \ beam lithography and DNA nanopatterning for molecular QCA.\" *IEEE Transactions\
    \ on Nanotechnology* 4, no. 3 (2005): 312-316.\n- [35]Niemier, Michael T., and\
    \ Peter M. Kogge. \"The\" 4-diamond circuit\"-a minimally complex nano-scale computational\
    \ building block in qca.\" In *VLSI, 2004. Proceedings. IEEE Computer society\
    \ Annual Symposium on*, pp. 3-10. IEEE, 2004.\n- [36]Jiao, J., G. L. Long, F.\
    \ Grandjean, A. M. Beatty, and T. P. Fehiner. \"Building Blocking for the Molecular\
    \ Expressionof QCA, Isolation and Characterization of a Covalently Bounded Square\
    \ Array of two Ferrocenium and TwoFerrocene Complexes.\" *Journal of the Am. Chem.\
    \ Society (JACS Communications)* 125, no. 25 (2003): 7522-7523.\n- [37]Lu, Yuhui,\
    \ and Craig Lent. \"Self-doping of molecular quantum-dot cellular automata: mixed\
    \ valence zwitterions.\" *Physical Chemistry Chemical Physics* 13, no. 33 (2011):\
    \ 14928-14936.\n- [38]Blair, E. P., \"Tools for the Design and Simulation of Clocked\
    \ Molecular Quantum-dot Cellular Automata Circuits,\" Master's thesis, University\
    \ of Notre Dame, Department of Electrical Engineering, 2003.\n- [39]Niemier, M.,\
    \ M. Kontz, and P. Kogge, \"A design of and Design tools for A novel quantum dot\
    \ based microprocessor*,\" in Proc. of the 37th Annual Design Automation Conference*,\
    \ pp. 227–232, 2000.\n- [40]Teodósio, Tiago, and Leonel Sousa. \"QCA-LG: A tool\
    \ for the automatic layout generation of QCA combinational circuits.\" In *Norchip,\
    \ 2007*, pp. 1-5. IEEE, 2007.\n- [41]K. Walus, T. Dysart, G. A. Jullien, and R.\
    \ A. Budiman, \"QCADesigner: A rapid design and simulation tool for quantum-dot\
    \ cellular automata,\" *IEEE Trans. Nanotechnology,* vol. 3, no. 1, pp. 26–31,\
    \ Mar. 2004.\n- [42]http://waluslab.ece.ubc.ca/qcadesigner/qca-designer-downloads/\n\
    - [43]M. Ottavi, L. Schiano, and F. Lombardi, \"HDLQ: A HDL environment for QCA\
    \ design,\" *ACM J. Emerging Technol. Comput. Syst.,* vol. 2, no. 4, pp. 243–261,\
    \ Oct. 2006.\n- [44]Tang, R., F. Zhang, and Y. B. Kim, \"Quantum-Dot Automata\
    \ SPICE Macro Model\", *ACM Great Lake Symposium on VLSI 2005*, 2005, pp. 108-111.\n\
    - [45]Srivastava, S., et al., \"QCAPro-An Error-Power Estimation Tool for QCA\
    \ Circuit Design*,\" in Proc. of the IEEE International Symposium on Circuits\
    \ and Systems,* pp. 2377–2380, 2011.\n- [46]Ottavi, Marco, et al. \"An HDL Model\
    \ of Magnetic Quantum-Dot Cellular Automata Devices and Circuits.\" Nanoelectronic\
    \ Device Applications Handbook\n- [47]Zhang, R., et al., \"A method of majority\
    \ logic reduction for quantum cellular automata,\" *IEEE Transactions on Nanotechnology,*\
    \ vol 3 (4), pp. 443-450, 2004.\n- [48]Zhang, R., P. Gupta, N. K. Jha, \"Synthesis\
    \ of majority and minority networks and its application to QCA, TPL, and SET based\
    \ nanotechnologies\", *IEEE Conference on VLSI Design held jointly with International\
    \ Conference on Embedded Systems Design,* 2005, pp. 229- 234.\n- [49]Kong, Kun,\
    \ Yun Shang, and Ruqian Lu. \"An optimized majority logic synthesis methodology\
    \ for quantum-dot cellular automata.\" *IEEE Transactions on Nanotechnology* 9,\
    \ no. 2 (2010): 170-183.\n- [50]Wang, Peng, Mohammed Y. Niamat, Srinivasa R. Vemuru,\
    \ Mansoor Alam, and Taylor Killian. \"Synthesis of Majority/Minority Logic Networks.\"\
    \ *IEEE Transactions on Nanotechnology* 14, no. 3 (2015): 473-483.\n- [51]Devadoss,\
    \ Rajeswari, Kolin Paul, and M. Balakrishnan. \"MajSynth: Ann-inputMajorityAlgebrabasedLogicSynthesisToolfor\
    \ QuantumdotCellularAutomata.\" (2015).\n- [52]Mishra, Vipul Kumar, and Himanshu\
    \ Thapliyal. \"Heuristic Based Majority/Minority Logic Synthesis for Emerging\
    \ Technologies.\" In *VLSI Design and 2017 16th International Conference on Embedded\
    \ Systems (VLSID), 2017 30th International Conference on*, pp. 295-300. IEEE,\
    \ 2017.\n- [53]Dhare, Vaishali, and Usha Mehta. \"Defect characterization and\
    \ testing of QCA devices and circuits: A survey.\" In *VLSI Design and Test (VDAT),\
    \ 2015 19th International Symposium on*, pp. 1-2. IEEE, 2015.\n\n[54]Dysart, Timothy\
    \ J., and Peter M. Kogge. \"Strategy and prototype tool for doing fault modeling\
    \ in a nano-technology.\" In *Nanotechnology, 2003. IEEE-NANO 2003. 2003 Third\
    \ IEEE Conference on*, vol. 1, pp. 356-359. IEEE, 2003.\n\n- [55]Mukherjee, Rijoy,\
    \ et al. \"Characterization and analysis of single electron fault of QCA primitives.\"\
    \ *Microelectronics, Computing and Communications (MicroCom), 2016 International\
    \ Conference on*. IEEE, 2016.\n- [56]Dysart, Timothy J., Peter M. Kogge, Craig\
    \ S. Lent, and Mo Liu. \"An analysis of missing cell defects in quantum-dot cellular\
    \ automata.\" In *IEEE International Workshop on Design and Test of Defect-Tolerant\
    \ Nanoscale Architectures (NANOARCH)*, vol. 3, pp. 1-8. 2005.\n- [57]Tahoori,\
    \ Mehdi Baradaran, Mariam Momenzadeh, Jin Huang, and Fabrizio Lombardi. \"Defects\
    \ and faults in quantum cellular automata at nano scale.\" In *VLSI Test Symposium,\
    \ 2004. Proceedings. 22nd IEEE*, pp. 291-296. IEEE, 2004.\n- [58]Tahoori, Mehdi\
    \ B., Jing Huang, Mariam Momenzadeh, and Fabrizio Lombardi. \"Testing of quantum\
    \ cellular automata.\" *IEEE Transactions on Nanotechnology* 3, no. 4 (2004):\
    \ 432-442.\n- [59]Zhang, Yongqiang, Hongjun Lv, Shuai Liu, Yunlong Xiang, and\
    \ Guangjun Xie. \"Defect-tolerance analysis of fundamental quantum-dot cellular\
    \ automata devices.\" *The Journal of Engineering* 1, no. 1 (2015).\n- [60]Schulhof,\
    \ Gabriel, Konrad Walus, and Graham A. Jullien. \"Simulation of random cell displacements\
    \ in QCA.\" *ACM Journal on Emerging Technologies in Computing Systems (JETC)*\
    \ 3, no. 1 (2007): 2.\n- [61]Karim, Faizal, and Konrad Walus. \"Characterization\
    \ of the displacement tolerance of QCA interconnects.\" *Design and Test of Nano\
    \ Devices, Circuits and Systems, 2008 IEEE International Workshop on*. IEEE, 2008.\n\
    - [62]Yang, Xiaokuo, Li Cai, Shuzhao Wang, Zhuo Wang, and Chaowen Feng. \"Reliability\
    \ and performance evaluation of QCA devices with rotation cell defect.\" *IEEE\
    \ Transactions on Nanotechnology* 11, no. 5 (2012): 1009-1018.\n- [63]Momenzadeh,\
    \ Mariam, Marco Ottavi, and Fabrizio Lombardi. \"Modeling QCA defects at molecular-level\
    \ in combinational circuits.\" In *Defect and Fault Tolerance in VLSI Systems,\
    \ 2005. DFT 2005. 20th IEEE International Symposium on*, pp. 208-216. IEEE, 2005.\n\
    - [64]Huang, Jing, Mariam Momenzadeh, and Fabrizio Lombardi. \"Analysis of missing\
    \ and additional cell defects in sequential quantum-dot cellular automata.\" *INTEGRATION,\
    \ the VLSI journal* 40, no. 4 (2007): 503-515.\n- [65]Momenzadeh, Mariam, Jing\
    \ Huang, and Fabrizio Lombardi. \"Defect characterization and tolerance of QCA\
    \ sequential devices and circuits.\" In *Defect and Fault Tolerance in VLSI Systems,\
    \ 2005. DFT 2005. 20th IEEE International Symposium on*, pp. 199-207. IEEE, 2005.\n\
    - [66]Ottavi, Marco, Hamid Hashempour, Vamsi Vankamamidi, Faizal Karim, Konrad\
    \ Walus, and André Ivanov. \"On the error effects of random clock shifts in quantum-dot\
    \ cellular automata circuits.\" In *Defect and Fault-Tolerance in VLSI Systems,\
    \ 2007. DFT'07. 22nd IEEE International Symposium on*, pp. 487-498. IEEE, 2007.\n\
    - [67]Huang, Jing, Mariam Momenzadeh, Mehdi Baradaran Tahoori, and Fabrizio Lombardi.\
    \ \"Defect characterization for scaling of QCA devices [quantum dot cellular automata].\"\
    \ In *Defect and Fault Tolerance in VLSI Systems, 2004. DFT 2004. Proceedings.\
    \ 19th IEEE International Symposium on*, pp. 30-38. IEEE, 2004.\n- [68]Liu, Mo,\
    \ and Craig S. Lent. \"Reliability and defect tolerance in metallic quantum-dot\
    \ cellular automata.\" *Journal of Electronic Testing* 23, no. 2- 3 (2007): 211-218.\n\
    - [69]Niemier, Michael, Michael Crocker, and X. Sharon Hu. \"Fabrication variations\
    \ and defect tolerance for nanomagnet-based QCA.\" In *Defect and Fault Tolerance\
    \ of VLSI Systems, 2008. DFTVS'08. IEEE International Symposium on*, pp. 534-542.\
    \ IEEE, 2008.\n- [70]Dai, Jianwei, Lei Wang, and Fabrizio Lombardi. \"An informationtheoretic\
    \ analysis of quantum-dot cellular automata for defect tolerance.\" *ACM Journal\
    \ on Emerging Technologies in Computing Systems (JETC)* 6, no. 3 (2010): 9.\n\
    - [71]Wei, Tongquan, Kaijie Wu, Ramesh Karri, and Alex Orailoglu. \"Fault tolerant\
    \ quantum cellular array (QCA) design using triple modular redundancy with shifted\
    \ operands.\" In *Proceedings of the 2005 Asia and South Pacific Design Automation\
    \ Conference*, pp. 1192-1195. ACM, 2005.\n\n[72]Ma, Xiaojun, and Fabrizio Lombardi.\
    \ \"Fault tolerant schemes for QCA systems.\" In *Defect and Fault Tolerance of\
    \ VLSI Systems, 2008. DFTVS'08. IEEE International Symposium on*, pp. 236-244.\
    \ IEEE, 2008.\n\n- [73]Dalui, Mamata, Bibhash Sen, and Biplab K. Sikdar. \"Fault\
    \ tolerant QCA logic design with coupled majority-minority gate.\" *Int. J. Comput.\
    \ Appl* 1, no. 29 (2010): 81-87.\n- [74]Farazkish, Razieh. \"A new quantum-dot\
    \ cellular automata fault-tolerant five-input majority gate.\" *Journal of nanoparticle\
    \ research* 16, no. 2 (2014): 2259.\n- [75]Roohi, Arman, Ronald F. DeMara, and\
    \ Navid Khoshavi. \"Design and evaluation of an ultra-area-efficient fault-tolerant\
    \ QCA full adder.\" *Microelectronics Journal* 46, no. 6 (2015): 531-542.\n- [76]Farazkish,\
    \ Razieh. \"A new quantum-dot cellular automata fault-tolerant full-adder.\" *Journal\
    \ of Computational Electronics* 14, no. 2 (2015): 506- 514.\n- [77]Sen, Bibhash,\
    \ Yashraj Sahu, Rijoy Mukherjee, Rajdeep Kumar Nath, and Biplab K. Sikdar. \"\
    On the reliability of majority logic structure in quantum-dot cellular automata.\"\
    \ *Microelectronics Journal* 47 (2016): 7- 18.\n- [78]Dhare, Vaishali, and Usha\
    \ Mehta. \"Fault analysis of QCA combinational circuit at layout & logic level.\"\
    \ In *Electrical and Computer Engineering (WIECON-ECE), 2015 IEEE International\
    \ WIE Conference on*, pp. 22- 26. IEEE, 2015.\n- [79]Pulimeno, Azzurra, Mariagrazia\
    \ Graziano, Alessandro Sanginario, Valentina Cauda, Danilo Demarchi, and Gianluca\
    \ Piccinini. \"Bisferrocene molecular QCA wire: Ab initio simulations of fabrication\
    \ driven fault tolerance.\" *IEEE transactions on nanotechnology* 12, no. 4 (2013):\
    \ 498-507.\n- [80]Graziano, Mariagrazia, Azzurra Pulimeno, Ruiyu Wang, Xiang Wei,\
    \ Massimo Ruo Roch, and Gianluca Piccinini. \"Process variability and electrostatic\
    \ analysis of molecular QCA.\" *ACM Journal on Emerging Technologies in Computing\
    \ Systems (JETC)* 12, no. 2 (2015): 18.\n- [81]Turvani, Giovanna, Fabrizio Riente,\
    \ Mariagrazia Graziano, and Maurizio Zamboni. \"A quantitative approach to testing\
    \ in quantum dot cellular automata: Nanomagnet logic case.\" In *Ph. D. Research\
    \ in Microelectronics and Electronics (PRIME), 2014 10th Conference on*, pp. 1-4.\
    \ IEEE, 2014.\n- [82]Tahoori, Mehdi Baradaran, and Fabrizio Lombardi. \"Testing\
    \ of quantum dot cellular automata based designs.\" In *Proceedings of the conference\
    \ on Design, automation and test in Europe-Volume 2*, p. 21408. IEEE Computer\
    \ Society, 2004.\n- [83]Gupta, Pallav, Niraj K. Jha, and Loganathan Lingappan.\
    \ \"A test generation framework for quantum cellular automata circuits.\" *IEEE\
    \ transactions on very large scale integration (VLSI) systems* 15, no. 1 (2007):\
    \ 24-36.\n- [84]Gupta, Pallav, Niraj K. Jha, and Loganathan Lingappan. \"Test\
    \ generation for combinational quantum cellular automata (QCA) circuits.\" In\
    \ *Design, Automation and Test in Europe, 2006. DATE'06. Proceedings*, vol. 1,\
    \ pp. 1-6. IEEE, 2006.\n- [85]Karim, Faizal, Konrad Walus, and Andre Ivanov. \"\
    Testing of combinational majority and minority logic networks.\" In *Mixed-Signals,\
    \ Sensors, and Systems Test Workshop, 2008. IMS3TW 2008. IEEE 14th International*,\
    \ pp. 1-6. IEEE, 2008.\n- [86]Dhare, Vaishali, and Usha Mehta. \"Development of\
    \ basic fault model and corresponding ATPG for single input missing cell deposition\
    \ defects in Majority Voter of QCA.\" In *Region 10 Conference (TENCON), 2016\
    \ IEEE*, pp. 2354-2359. IEEE, 2016.\n- [87]Karim, Faizal, Konrad Walus, and André\
    \ Ivanov. \"Crosstalk in QCA arithmetic circuits.\" In *PROCEEDINGS-SPIE THE INTERNATIONAL\
    \ SOCIETY FOR OPTICAL ENGINEERING*, vol. 6313, p. 631306. International Society\
    \ for Optical Engineering; 1999, 2006.\n- [88]Kazemi-fard, Nasim, Maryam Ebrahimpour,\
    \ Mostafa Rahimi, Mohammad Tehrani, and Keivan Navi. \"Performance evaluation\
    \ of incircuit testing on QCA based circuits.\" In *Design & Test Symposium (EWDTS),\
    \ 2008 East-West*, pp. 375-378. IEEE, 2008."
  decisions:
    evaluation_prompt: 'Disqualified: no evaluation. Reason: The paper is a survey
      and discussion of Quantum-dot Cellular Automata (QCA) technologies, defects,
      and testing methods, but it lacks any empirical, experimental, or quantitative
      evaluation of its own. It does not include sections or paragraphs dedicated
      to evaluation, experiments, results, or empirical analysis, nor does it present
      any benchmarks, metrics, comparisons, datasets, or performance measurements.'
    related_work_prompt: '- Qualified. Reason: The paper meaningfully engages with
      prior research by providing numerous academic citations throughout the text,
      discussing various aspects of Quantum-dot Cellular Automata (QCA) technology,
      and comparing different implementations and methodologies. It includes a comprehensive
      survey of existing literature, tools, defect analysis, and testing methods,
      demonstrating a thorough engagement with previous work in the field.'
    novelty_prompt: 'Disqualified: no novelty. Reason: The paper is a comprehensive
      survey on Quantum-dot Cellular Automata (QCA) technology, covering its basics,
      implementation, fabrication, tools, defect characterization, fault models, and
      testing. It does not propose any new methods, algorithms, architectures, datasets,
      or insights, nor does it apply known techniques in a novel context or domain.
      The paper primarily summarizes existing literature and suggests potential research
      areas without making any clear claims of novel contributions.'
    review_only_prompt: 'Disqualified: review paper. Reason: The title contains the
      word "survey," and the main body primarily summarizes existing work on Quantum-dot
      Cellular Automata (QCA) basics, implementation, fabrication, tools, defect characterization,
      fault model, and testing without introducing new methods, datasets, experiments,
      or frameworks.'
- title: 'Machine Learning in VLSI Design: A Comprehensive Review'
  abstract: ''
  keywords: Machine Learning, VLSI, EDA, CAD
  document: '#### I. INTRODUCTION


    As ASIC development grows in complexity, manufacturing constraints emerge, influencing
    both cost and time-tomarket. The escalating number of physical features in VLSI
    circuits presents a serious challenge. This growth results in a massive flux of
    data processed by EDA tools'' engines[1]. Fig 1 illustrates the data growth across
    technology advancements, complicating the task of gathering and identifying underlying
    data correlations and patterns. Consequently, this surge in data directly impacts
    costs and extends the development runtime.


    ![](_page_0_Figure_9.jpeg)


    Fig. 1 EDA Data capacity vs. chip technology node


    Recently, Machine Learning (ML) became the focal point and is extensively applied
    in VLSI design. It has empowered designers with the capability to discover patterns
    and functions within complex unexplored data, and provides the opportunity to
    gain more knowledge on circuit behavior. As we advance toward physical layout
    implementation, more detailed and accurate physical information becomes accessible.
    However, there is a point where metrics settle, and EDA heuristics face limitations
    due to excessive pessimism. This presents a challenge for EDA companies, urging
    them to explore new methodologies, particularly in handling significant amounts
    of data. ML emerges as a solution to surpass these predictability limitations.
    Through training on massive datasets, ML-based models may offer high-accuracy
    predictions for Quality of Results (QoR) as in Fig 2, which depicts the potential
    impact of ML predictions on modifying the trade-off curve between cost and accuracy
    [2].


    ![](_page_0_Figure_14.jpeg)


    Fig. 2 ML Accuracy improvement versus Cost/Runtime


    This paper provides a comprehensive exploration of ML in EDA and VLSI design.
    Our focus involved reviewing several state-of-the-art ML applications and outlining
    the key challenges and limitations that researchers encounter. The scope of this
    review spans from high-level synthesis to postlayout verification of ASIC flow.
    We close the review by identifying potential promises and future directives. The
    remainder of this paper is structured as follows. Section 2 provides an overview
    of the fundamentals of ML and Neural network. Section 3 offers a literature review,
    this section is divided into multiple subsections based on different parts of
    the ASIC flow. Section 4, presents a results discussion and offers insights into
    future perspectives.


    #### II. BACKGROUND AND ML FUNDAMENTALS


    #### *A. AI/ML Role*


    AI frameworks consist of data-driven models able to process, perceive, and interpret
    the environment, engage in reasoning, and make informed decisions. The AI comprises
    several sub-fields, among which are Machine Learning and Deep Learning. ML focuses
    on creating models that improve their performance by learning from data using
    predefined algorithms, aiming to discern patterns and correlations within datasets.
    The model acquires knowledge through training and can subsequently generate predictions
    for new unseen data. ML techniques are classified into three primary subsets:
    *Supervised*, *Unsupervised*, and *Reinforcement Learning*.


    #### *B. Dataset and Feature Engineering*


    Each ML models build knowledge by learning from a training dataset. Datasets typically
    include input and output variables, often referred to as features (independent
    variables) and targets (dependent variables). Consequently, each line in the dataset
    represents one sample along with the corresponding target value. We often represent
    independent variables as matrix *X* with *m* rows of data, each with *n* features,
    while *Y* is a vector containing m target dependent variables. [3]


    $$X = \begin{bmatrix} X\_{11} & X\_{12} & \dots & X\_{1n} \\ X\_{21} & X\_{22}
    & \dots & X\_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ X\_{m1} & X\_{m2} &
    \dots & X\_{mn} \end{bmatrix} \begin{bmatrix} Y\_1 \\ Y\_2 \\ \vdots \\ Y\_m \end{bmatrix}$$


    Real-world data requires preprocessing before training. In the following paragraph,
    we detail various methods used for data reprocessing. [4] [5] [6]


    - *Data cleaning* addresses missing and duplicate values using the *imputation
    technique* which refers to replacing missing values with estimations.

    - *Handling Outliers* aims to filter noise and irregular data points that may
    significantly deviate from the rest of data using methods such as *Z-Score* and
    *Interquartile Range (IQR)*.

    - *Data Scaling* brings features to a common scale and makes sure that all features
    have the same range, preventing large values from disproportionating and dominating
    the model. The common scaling techniques are *Min-Max*, *normal scaling*, *Z-score
    Standardization*, and *Robust Scaling*.

    - *Feature Engineering* aims to create new features from the existing features
    to form an informative dataset.

    - *Handling categorical data* involves employing techniques such as *one-hot encoding*,
    which transform categorical variables into binary vectors.

    - *Feature selection* involves choosing the most relevant features to train the
    model and improve model performance, as not all features have equal weight and
    contribution.

    - *Dataset splitting* balances between training, testing, and evaluation sets.
    The *training set* is the portion that enables the model to learn the patterns
    and feature''s relationships. The model adjusts its internal parameters to minimize
    prediction error. The *validation set* is used to fine-tune the model''s hyperparameters,
    a common method is *k-fold cross-validation*, where the dataset is divided into
    k subsets/folds. The model is trained and validated *k* times, with each fold
    serving as a validation, while the remaining *k-1* folds form the training set.
    In case the performance degrades on the validation set, it indicates an overfitting.
    The *testing set* evaluates the model''s performance on unseen data, offering
    an estimate of the model''s accuracy when applied to real-world new data.


    ### *C. Supervised Learning: Labeled Data*


    Supervised learning algorithms learn from labeled datasets, focusing on adjusting
    the model''s parameters and creating an inferred function that maps inputs to
    outputs with a minimized prediction error. The supervised models learn from a
    pair of input vectors and a corresponding target value. Two primary types of supervised
    learning exist, *Classification* and *Regression*. Classification algorithms allocate
    the input vector to a predefined category or class. The *classification* is either
    binary classification (two target categories) or multi-class classification (multiple
    categories). While Regression algorithms focus on predicting continuous numeric
    values.


    Various regression algorithms exist, each for a distinct needs. *Linear Regression*
    (LR) presumes a linear association between features and the target. The *Polynomial
    Regression* (PR) captures non-linear relationships through polynomial functions.
    The *Decision Trees* (DT) recursively split the dataset into subsets based on
    the most significant attributes, thus creating a tree structure that leads to
    average prediction. The *Random Forest* (RF) is an ensemble method that combines
    multiple decision trees to improve prediction accuracy. The *Extra-Trees* or *Extremely
    Randomized Trees* is another ensemble method that constructs decision trees with
    randomized feature splits. The *Support Vector Regressor* (SVR) aims to find a
    hyperplane that minimizes the prediction error while allowing a tolerance margin.
    The *k-Nearest Neighbors* (KNN) is a non-parametric algorithm that predicts the
    target value by averaging the values of its k-nearest neighbors. While *Naive
    Bayes Regressor* (NBR) relies on probabilistic principles. The *Gradient Boosting*
    (GB) constructs a model by combining multiple weak decision tree models and gradually
    reducing the prediction error by fitting each tree to the residual errors of the
    previous trees. The list is still extensive, other methods and neural network
    algorithms exist that have not been included. [7] [8] [9] [3] [10] [6]


    A model exhibits good *generalization capabilities* when it provides accurate
    predictions for unseen data. If the inferred model is too simplistic and predicts
    inaccurate values for the training set, it risks *Underfitting* the training data.
    On the other hand, when the training data is insufficient, we risk having an *Overfitting*
    where the model produces good predictions on the training set but fails when facing
    new data, the model then has a low generalization capability. As a result, it''s
    crucial to strike a balance for model complexity and find a well-balanced spot
    between underfitting and overfitting as depicted in Fig 3.


    ![](_page_1_Figure_17.jpeg)


    Fig. 3 Underfitting and Overfitting


    Journal of Integrated Circuits and Systems, vol. 19, n. 2, 2024 3


    ## *D. Unsupervised Learning: Discovering Patterns in Data*


    In unsupervised learning, we provide input data without the guidance of labeled
    outputs. The purpose is to extract the underlying knowledge and common structure
    within the given inputs without target values. One of the most common unsupervised
    learning techniques is clustering, a method that groups input values into clusters
    based on their similarities and resemblances. Another known technique is *Transformation*
    or *Dimensionality Reduction*, which transforms the high-dimensional data to low
    dimensions while preserving essential features.


    Unsupervised learning is frequently applicable in the visualization of representative
    data. Among the *Clustering* algorithms, the *K-means* divides data into k-clusters
    by minimizing the sum of squared distances between data points and cluster centroids.
    Meanwhile, *DBSCAN* (Density-Based Spatial Clustering of Applications with Noise)
    identifies clusters grounded in their density. The *Principal Component Analysis*
    (PCA) is also a dimensionality reduction technique, which discovers a set of orthogonal
    axes, referred to as principal components that capture the data variance. [7]
    [8] [9] [3] [10] [6]


    #### *E. Reinforcement: Learning from Experience*


    Reinforcement Learning (RL) stands apart from supervised and unsupervised learning.
    It is an interactive learning paradigm where an agent interacts with the environment
    and makes decisions to achieve specific predictions. The agent receives feedback
    in the form of rewards or punishments based on its prediction choices, and it
    learns to optimize its strategy over time to maximize cumulative rewards. Several
    prominent Reinforcement algorithms include *Q-Learning*, *Policy Gradient Methods*,
    *Markov Decision Processes* (MDP), and *Monte Carlo Tree Search* (MCTS).[11][10]


    #### *F. Deep Learning and Neural Networks*


    Neural Networks (NN) can be adapted for supervised, unsupervised, and reinforcement
    learning. NNs have shown remarkable performance in handling complex data structures.
    In this section, we introduce a single neuron basic building block structure and
    the architecture of a vanilla feed-forward neural network. We provide an overview
    of the concept of Backpropagation and review commonly used Deep Neural Networks
    (DNNs).


    *F..1 Perceptron*A neuron or perceptron, is the fundamental component in neural
    networks that processes input and makes decisions. It assigns weights to its multi-input
    values based on its importance, then linearly combines the weighted inputs and
    introduces a bias term. The result undergoes a non-linearity through an *activation
    function*. In Fig 4, multiple inputs represent features, denoted as *x1, x2,...,
    xn*. Each input has an associated weight or importance to the output. (eq.1)[12]


    $$Yin = \sum\_{i=1}^{n} (x\_i \cdot w\_i) + Bo \tag{1}$$


    ![](_page_2_Figure_10.jpeg)


    Fig. 4 Perceptron


    Non-linearity is introduced through an activation function, unless the network
    would operate as a linear function. As a result, when numerous neurons with non-linear
    activation functions are stacked in a large network, it becomes capable of approximating
    highly complex functions. Some commonly used activation functions are presented
    below with their respective equations (eq. 2). Fig 5 illustrates the graphical
    representations of below activation functions. [12]


    - The *Step function* produces binary outputs determined by a predefined threshold.
    It operates as a binary function, yielding an output of ''1'' when the input exceeds
    ''0'' and ''-1'' otherwise.

    - The *Sigmoid* function maps the weighted sum to the range ''0;1''. It''s often
    used in binary classification. The sigmoid smoothly transforms input values into
    a probability-like output. It maps large negative inputs to ''0'' and large positive
    inputs to ''1''.

    - The *Hyperbolic Tangent* (tanh) is similar to the sigmoid. However, the output
    ranges from ''-1'' to ''1''. It maps the weighted sum to -1;1, offering a centered
    output.

    - The *Rectified Linear Unit* (ReLU) activation function outputs the weighted
    sum if the result is positive and ''0'' otherwise.


    $$\begin{aligned} \text{Step:} \quad f(x) &= \begin{cases} 1 & \text{if } x >
    0 \\ -1 & \text{if } x \le 0 \end{cases} \\ \text{Sigmoid:} \quad f(x) &= \frac{1}{1
    + e^{-x}} \\ \tanh: \quad f(x) &= \tanh(x) = \frac{e^x - e^{-x}}{e^x + e^{-x}}
    \\ \text{ReLU:} \quad f(x) &= \max(0, x) \end{aligned} \tag{2}$$


    Equation eq.3 represents the output *Y* after being passed through the activation
    function, where *Yin* is the result from eq.1 (Fig 4). The Sigmoid function then
    constrains the result between ''0'' and ''1''.


    $$Y = \frac{1}{1 + e^{-(Y \dot{m})}} \tag{3}$$


    ![](_page_3_Figure_2.jpeg)


    Fig. 5 Common activation functions


    *F..2 Multilayer*A Multilayer Perceptron (MLP) is the fundamental Artificial Neural
    Network (ANN). It comprises multiple layers of interconnected neurons. In Fig
    6, the network is a Feedforward neural network (FNN) of three hidden layers. The
    network adjusts weights during training. and each neuron in the hidden layer receives
    the results of all previous layer neurons, processes the linear weighted combination,
    and passes the results through the activation function. [12]


    ![](_page_3_Figure_5.jpeg)


    Fig. 6 Feedforwad Neural Network


    Eventually, the *Output layer* represents the predicted targets variables, either
    for regression tasks or classes in classification tasks. The output layer may
    comprise multiple neurons, each corresponding to a specific class. The matrix
    in eq.4 represents the output values (Y ) for m hidden neuron.


    $$Y = \sigma \left( X \cdot W + b \right) \tag{4}$$


    $$

    \begin{bmatrix} Y\_1 \\ Y\_2 \\ \vdots \\ Y\_m \end{bmatrix} = \sigma(\begin{bmatrix}
    x\_1 \\ x\_2 \\ \vdots \\ x\_n \end{bmatrix}, \begin{bmatrix} w\_{11} & w\_{12}
    & \dots & w\_{1m} \\ w\_{21} & w\_{22} & \dots & w\_{2m} \\ \vdots & \vdots &
    \ddots & \vdots \\ w\_{n1} & w\_{n2} & \dots & w\_{nm} \end{bmatrix} + \begin{bmatrix}
    b\_1 \\ b\_2 \\ \vdots \\ b\_m \end{bmatrix})

    $$


    - Y: output values in the 1st hidden layer, for *m* neuron.

    - X: *n* input features.

    - W: weight, *Wij* with *i* input and *j* neuron.

    - b: biases vector for *m* neuron..

    - σ is the activation function applied element-wise.


    *F..3 Cost function*During the forward propagation, each neuron computes its weighted
    sum and applies non-linearity. The *Cost function* or *Loss function* refers to
    the error on the output layer obtained by comparing the predicted versus target
    values. The cost function estimates the error for the entire network, then propagate
    it backward through through the gradient descent of the cost. This process is
    the *Backpropagation* and allows the adjustment of weights and biases for all
    neurons to minimize the final cost. Some common loss functions are *Mean Squared
    Error* (MSE) for regression or *Cross-entropy* for classification.


    *F..4 Backpropagation*The Backpropagation is fundamental for weights and bias
    updates. The network calculates the *cost gradient* for each weight and bias in
    the output layer and backpropagates to adjust all weights and biases. The gradient
    reflects how small or large the weight and bias changes affect the cost function,
    and points the direction for weight adjustments to minimize the error. The weight
    update is the subtraction of the learning rate multiplied by the gradient eq.5.
    The learning rate controls the step size of the weight updates and influences
    convergence speed and training stability.[12]


    $$

    \Delta w\_{ij} = -\eta \frac{\partial E}{\partial w\_{ij}}\tag{5}

    $$


    *F..5 Deep Learning*A Deep Neural Network (DNN) is a feed-forward network with
    multiple hidden layers trained using backpropagation. *Convolutional Neural Networks*
    (CNNs) are tailored for grid-like data, such as image classification and object
    detection, to detect local patterns. *Recurrent Neural Networks* (RNNs) are specialized
    for sequential data, where the element order is significant. They utilize recurrent
    connections to manage and update hidden states and are valuable in *Natural Language
    Processing* (NLP) and speech recognition. The *Long Short-Term Memory Networks*
    (LSTMs) are a specialized type of RNN designed to overcome the vanishing gradient
    problem and capture long-range dependencies in sequential data. *Gated Recurrent
    Unit Networks* (GRUs) are also RNNs, with a simpler architecture, offering efficiency
    for tasks like natural language understanding and speech synthesis. Lastly, *Autoencoders*
    are networks used for unsupervised learning and dimensionality reduction, mapping
    input data to a lowerdimensional representation and a decoder network reconstructing
    the input.[12]


    Even though deep learning has been around for decades, the hardware support for
    neural networks has only recently come to realization. The development of accelerated
    parallel computing CPU-GPU architectures has made deep learning achievable. As
    a result, model training times have been reduced from weeks to hours.


    ## III. LITERATURE REVIEW: ML IN VLSI DESIGN AND CAD EDA


    The field of Computer-Aided Design (CAD) is rapidly evolving to address the increasing
    complexities of modern VLSI chips [1]. AI integration into design automation tools
    represents an approach to stay at the forefront of technological advancements.
    Extensive research has been conducted focusing on reducing design runtime and
    improving QoR through AI/ML integration [13][14][15][16][14][17][16][18]. A similar
    review has been provided in [13], offering an extensive examination of the AI/ML
    methodologies suggested in existing literature. This review primarily encompasses
    all stages of VLSI abstraction, including architectural considerations, physical
    design, circuit simulation, manufacturing, and VLSI testing. In this section,
    we provide an overview of the state-of-the-art and survey recent research and
    draw some key limitations and highlight possible enhancements.


    #### *A. ML in VLSI functional Verification*


    The study made in [64] and [43] demonstrates the importance of data mining in
    EDA. In [19], data mining and pattern extraction have exhibited the potential
    of the Support Vector Machine (SVM) in reducing runtime and enhancing simulation
    coverage during functional verification. As illustrated in Fig 7, a standard set
    of unit tests typically attains maximum functional coverage upon 6,000 tests.
    By employing the SVM-based model, a subset of merely 310 tests accomplished equivalent
    coverage, leading to a notable 95% reduction in simulation runtime. The model
    is capable of predicting coverage overlap and captures test similarities, as depicted
    in Fig 8. In [20], the author proposed a classification learning method to enhance
    functional coverage based on assertions. The model identifies how frequently an
    assertion is triggered, highlighting the significance of each unit test. The objective
    is to extract knowledge that can activate assertions with lower coverage. To achieve
    this, the authors employed a feature-based analysis, utilizing supervised classification
    and unsupervised association rules.


    ![](_page_4_Figure_4.jpeg)


    Fig. 7 Runtime saving using SVM-based mode


    ![](_page_4_Figure_6.jpeg)


    Fig. 8 Increasing Coverage using SVM-based mode


    #### *B. ML at High Level Synthesis*


    ML application on High-Level Synthesis (HLS) has raised the challenge of design
    space exploration (DSE). In [21], the author presents a learning-based model for
    DSE that speeds up the convergence toward the optimal RTL design architecture.
    The results from Random Forest and randomized selection algorithms yielded the
    highest accuracy for optimal Pareto for RTL architecture. Similarly, [22] harnesses
    the power of RF and Extra-Tree to guide DSE in discovering Pareto-optimal combinations
    of area and performance. [23] implemented a Simulated Annealing (SA) probabilistic
    algorithm. The author introduces a faster SA method based on decision trees (DT),
    resulting in a similar performance to a standard SA but with a gain up to 43%
    on average runtime improvement. Lastly, [24] delves into the challenges posed
    by DSE on systems with multicore processors. The author leverages reinforcement
    techniques such as Imitation Learning (IL) to enhance the computational efficiency
    of these manycore systems.


    ### *C. ML in Physical Design*


    ML finds application also in the physical design stages, where data continues
    to grow alongside technological progress. In this section, we explore cutting-edge
    applications within backend design.


    *C..1 ML for Floorplanning and Placement Optimization* Traditional Place-and-Rout
    (PnR) tools typically generate a floorplan without exploring multiple alternatives,
    regardless of timing, wire length, congestion, power, routability, and other QoR
    metrics. In [25], the author introduces a deeplearning neural network that explores
    various floorplan alternatives, considering different aspect ratios and placement
    styles. The model automatically generates an optimal floorplan for subsequent
    PnR stages based on dataflow and DSE information. In [26], the author presents
    a reinforcement learning agent that undergoes training across multiple chip blocks
    to produce optimized chip placements. This approach involves the sequential macro
    and standard cell placement on the chip canvas. The model''s rewards are based
    on the cost associated with wirelength and routing congestion.


    In [27] and [28], two deep learning-based models are introduced to enhance design
    testability (DFT). The model uses a Graph Convolutional Neural Network (CNN) for
    control and observation (CP-OP) point insertion. The graph CNN aims to minimize
    the number of CP-OPs while maximizing fault coverage. In [29] employs a DNN framework
    to accelerate cell placement. The results significantly improved the QoR and routing
    congestion. While the model still achieves good placement quality comparable to
    state-ofthe-art placers. The model has accelerated the global placement runtime
    by a factor of 30.


    Typically, an effective placement aims to minimize the half-perimeter wirelength
    (HPWL). Nevertheless, handling datapaths can yield varying QoR, thus offering
    different placements. In both [30] and [31], the authors proposed a model that
    combines SVM and ANN. The models classify datapaths by their order of importance
    and guide a wire length-driven placement strategy, focusing on the highly weighted
    datapaths. The results led to a reduction of 7% in HPWL and 12% in Steiner Wire
    Length (StWL).


    *C..2 ML for Clock Network Optimization*In synchronous circuits, the primary challenges
    concern the clock network as it is one of the most critical networks. Achieving
    a zeroskew clock network has always been a challenge. A common strategy to optimize
    clock skew, minimize clock-tree length, and mitigate clock network power consumption
    involves placing latches in proximity to local clock buffers, a technique discussed
    in [32] and [30]. The authors introduce


    |      |      |       | Stage |            |                 |     |       |               |               |
    ML algorithm           |              |               |

    |------|------|-------|-------|------------|-----------------|-----|-------|---------------|---------------|------------------------|--------------|---------------|

    |      | Year | Tech. | Verif | HLS<br>DSE | Floor.<br>Place | CTS | Route | Phy.<br>Verif
    | Power<br>Grid | Supervised             | Unsupervised | Reinforcement |

    | [19] | 2012 | 28nm  | ✓     |            |                 |     |       |               |               |
    SVM                    |              |               |

    | [20] | 2013 | 28nm  | ✓     |            |                 |     |       |               |               |
    Classification         | Association  |               |

    | [21] | 2013 | 45nm  |       | ✓          |                 |     |       |               |               |
    RF Random Selection    |              |               |

    | [22] | 2008 | -     |       | ✓          |                 |     |       |               |               |
    RF Extra-Tree          |              |               |

    | [23] | 2014 | 45nm  |       | ✓          |                 |     |       |               |               |
    Decision Tree          |              |               |

    | [24] | 2018 | -     |       | ✓          |                 |     |       |               |               |                        |              |
    Imitation     |

    |      |      |       |       |            |                 |     |       |               |               |                        |              |
    Learning      |

    | [25] | 2020 | -     |       |            | ✓               |     |       |               |               |                        |              |
    -             |

    | [26] | 2020 | -     |       |            | ✓               |     |       |               |               |                        |              |
    MDP           |

    | [27] | 2020 | -     | ✓     |            | ✓               |     |       |               |               |
    Graph CNN              |              |               |

    | [28] | 2019 |       |       |            |                 |     |       |               |               |                        |              |               |

    | [29] | 2019 |       |       |            |                 |     |       |               |               |                        |              |               |

    | [30] | 2012 | -     |       |            | ✓               |     |       |               |               |
    SVM ANN                |              |               |

    | [31] | 2015 |       |       |            |                 |     |       |               |               |                        |              |               |

    | [32] | 2013 | 22nm  |       |            | ✓               | ✓   |       |               |               |
    Decision Tree          |              |               |

    | [33] | 2019 | -     |       |            | ✓               |     |       | ✓             |               |
    CNN                    |              |               |

    | [34] | 2016 | 28nm  |       |            | ✓               |     | ✓     |               |               |
    SVM MARS               |              |               |

    |      |      | 45nm  |       |            |                 |     |       |               |               |                        |              |               |

    |      |      | 65nm  |       |            |                 |     |       |               |               |                        |              |               |

    | [35] | 2016 | 28nm  |       |            | ✓               |     | ✓     |               |
    ✓             | GPR                    |              |               |

    | [36] | 2017 | 14nm  |       |            | ✓               |     | ✓     | ✓             |               |
    LR LogR SVM classifier |              |               |

    | [37] | 2018 | -     |       |            |                 |     | ✓     | ✓             |               |
    ANN                    |              |               |

    | [38] | 2014 | 45nm  |       |            |                 |     | ✓     | ✓             |               |
    MARS                   |              |               |

    | [39] | 2015 |       |       |            |                 |     |       |               |               |                        |              |               |

    | [40] | 2019 | -     |       |            | ✓               |     | ✓     | ✓             |               |
    CNN                    |              |               |

    | [41] | 2015 | 28nm  |       |            |                 |     | ✓     | ✓             |               |
    ANN SVM                |              |               |

    | [42] | 2019 | -     |       |            |                 |     | ✓     | ✓             |               |                        |
    Autoencoders |               |

    | [43] | 2016 | 45nm  |       |            |                 |     |       | ✓             |               |
    SVM Classifier         |              |               |

    | [44] | 2011 |       |       |            |                 |     |       |               |               |                        |              |               |

    | [45] | 2012 | -     |       |            |                 |     |       | ✓             |               |
    CNN                    |              |               |

    | [46] | 2018 | -     |       |            |                 |     |       |               |
    ✓             | XGB CNN                |              |               |

    | [47] | 2012 | 90nm  |       |            |                 |     |       |               |
    ✓             | LR                     |              |               |

    | [48] | 2018 | 16nm  |       |            |                 |     |       |               |
    ✓             | ANN                    |              |               |

    |      |      | 45nm  |       |            |                 |     |       |               |               |                        |              |               |

    | [49] | 2017 | 180nm |       |            |                 |     |       |               |
    ✓             |                        | K-means      |               |

    |      |      |       |       |            |                 |     |       |               |               |                        |
    Mean-Shift   |               |

    |      |      |       |       |            |                 |     |       |               |               |                        |
    DBSCAN       |               |

    | [50] | 2014 | 45nm  |       |            |                 |     |       |               |
    ✓             | SVM                    |              |               |

    | [51] | 2020 | -     |       |            |                 |     |       |               |
    ✓             | ANN                    |              |               |

    | [52] | 2021 | -     |       |            |                 |     |       |               |
    ✓             | ANN LogR               |              |               |

    | [53] | 2020 | 15nm  |       | ✓          | ✓               |     |       |               |               |
    PR SVR ANN             |              |               |

    | [54] | 2007 | 90nm  |       |            | ✓               |     | ✓     |               |               |
    SVM classifier         |              |               |

    | [55] | 2008 | 90nm  |       |            | ✓               |     | ✓     |               |               |
    ϵ-SVR                  |              |               |

    | [56] | 2014 | 28nm  |       |            |                 |     | ✓     |               |               |
    ANN SVR RF             |              |               |

    |      |      | 45nm  |       |            |                 |     |       |               |               |                        |              |               |

    | [57] | 2019 | 45nm  |       |            |                 |     | ✓     |               |               |
    ANN RF                 |              |               |

    | [58] | 2013 | -     |       |            |                 |     | ✓     |               |               |
    Regressor classifier   |              |               |

    | [59] | 2018 | 28nm  |       |            | ✓               |     | ✓     |               |               |
    RF                     |              |               |

    | [60] | 2016 | 28nm  |       |            | ✓               |     | ✓     |               |               |
    Lasso SVM GB ANN       |              |               |

    | [61] | 2021 | 7nm   |       |            | ✓               |     |       |               |               |
    LR RF DT               |              |               |

    | [62] | 2022 | 130nm |       |            |                 |     | ✓     |               |               |
    GNN                    |              |               |

    | [63] | 2020 | 7nm   |       |            |                 |     | ✓     |               |               |
    LR ANN RF XGBoost      |              |               |


    Table I. State-of-the-art works of Machine Learning application in VLSI Design.


    LR:Linear Regression, LogR:Logistic Regression, PR:Polynomila Regression, DT:Decision
    Tree, RF:Random Forest, GB:Gradient Boosting, XGBoost:eXtreme Gradient Boosting,
    SVM:SupportVectorMachine ,SVR:SupportVectorRegressor, MDP:Markov Decision Processes,
    ANN:Artificial Neural Networks, CNN:Convolutional Neural Network, MARS:Multivariate
    Adaptive Regression Splines, GPR:Gaussian process regression, GNN:Graph Neural
    Network


    a DT model to reduce latch redundancies and propose an optimized latch placement
    solution. The approach significantly reduces clock skew and has a positive impact
    on placement, indirectly benefiting power consumption.


    *C..3 ML for Congestion*Routing congestion is a critical factor that significantly
    affects the timing behavior and routeability. However, congestion is not always
    accurately predicted from early placement stages, which misleads the router and
    results in longer wires and routing detours. Tools can restructure the logic and
    adjust functionality to mitigate routing congestion hotspots. In [33], the author
    introduces a deep learning approach based on CNN to predict routing congestion
    hotspots on a pre-placed netlist. The model utilizes various features, including
    the netlist graph, cell type, function, pin count, geometry, and other cell characteristics
    for training. The ground truth during training was the routed congestion map.
    The model employs Graph Attention Networks (GAT) [65] and identifies common patterns
    in gatelevel netlists, helping to pinpoint the logic elements contributing to
    congestion. The model achieves 75% accuracy in predicting congestion at lower
    metal layers, compared to the baseline congestion map''s accuracy of 29%.


    *C..4 ML for Routing Optimization*Advanced technology nodes have raised new challenges
    in routeability. Numerous factors, such as placement quality, timing constraints,
    and aspect ratio, significantly influence the design routeability. A bad routeability
    results in excessive runtime, stretching to weeks for large designs, and sometimes
    it ends up unrouteable. Although the congestion map can aid in predicting routeability,
    however, it may still prove insufficiency or mislead the router. New research
    has focused on ML to predict placement solution routeability without fully performing
    global or detailed routing.


    In [34], the author developed SVM-based and Multivariate Adaptive Regression Splines
    (MARS) models to predict routeability from the placement stage. The models were
    trained using designs at 28nm and 45nm technology nodes to predict the Pareto
    frontiers of utilization. After dividing the layout into grids, various grid division
    features were extracted, including pin density per grid area, and pin proximity,
    cell count, net count, and edges count. The classification model achieved a prediction
    accuracy of 85.9%, and 90.4% for 45nm, and 28nm, respectively. Thus, surpassing
    the standard prediction based on the congestion map, which barely achieved 61.7%
    and 73.5%.


    In [35], the authors focus on predicting wirelength based on the circuit''s power
    distribution network (PDN). An optimized PDN network reduces wirelength, while
    an unoptimized PDN can lead to inefficient placement of power rails and vias,
    resulting in suboptimal wire routing. Inefficient routing increases wirelength
    as signals take longer paths to avoid congested areas and routing obstacles caused
    by inefficient power networks. To mitigate this, the authors employ a Gaussian
    process regression (GPR) model, which considers relevant PDN attributes and placement
    features to reduce the total wirelength.


    Congestion maps identify potential Design Rule violations (DRV) at the routing
    stage. These congestion maps aid in optimizing placement by adjusting cell positions
    and reducing detailed-route DRV. However, in advanced sub-microns, congestion
    map-based placement may leave significant design rule checks (DRC) violations
    to be addressed manually or through iterating, making it a less reliable predictor
    and potentially misleading the global router. Fig 9 illustrates the mismatch between
    actual DRC violations and congestion map hotspots.


    In [36], the authors employ multiple learning models, including Linear Regression,
    Logistic Regression, and SVM classifiers, to reduce DRC violations during detailed
    routing. Binary classifiers categorize globally routed cells based on whether
    they contribute to a DRC violation. The models were trained using features such
    as fan-in, fan-out, connectivity parameters, pin proximity, local pin density,
    and local overflow. The SVM model has successfully reduced the DRC violations
    by an average of around 20%, with some cases achieving up to a remarkable 76%,
    all without impacting design timing. Fig 10 illustrates a DRC hotspot detection
    using the SVM model.


    ![](_page_6_Figure_9.jpeg)


    Fig. 9 Actual DRC vs. Congestion map DRC violations


    ![](_page_6_Figure_11.jpeg)


    Fig. 10 Actual DRC vs. model''s DRC hotspot predictions


    In a similar context, a study conducted in [37] predicts detailed routing violations
    from an early placement stage by estimating congested regions based on StWL estimations
    and pin density, thus avoiding the need for a global router. The authors developed
    a binary classification model where the output indicates the presence or absence
    of violations. The model was trained on features extracted from the placement
    stage, targeting detailed routing shorts of already routed designs. The implemented
    neural network model consists of 20 nodes in one hidden layer. It has achieved
    an average shorts prediction accuracy of 90%, within a reduced runtime compared
    to the standard congestion map method.


    Similar efforts to estimate routability and routing congestion from an early placement
    stage using supervised learning have been conducted in [38] and [39] with the
    use of multivariate adaptive regression splines models. The learning framework
    aims to detect routing violations directly from the placement stage without relying
    on a global router, resulting in reliably accurate results and shorter runtime.


    Routability may also be impacted from the macro placement stage, particularly
    in large complex designs with high macro and IP counts that occupy significant
    chip areas. In [40], the authors propose a routability-driven macro placement
    prediction using CNN to find the optimal macroplacement with minimal DRC violations.
    The model forecasts design routeability for optimal macro-placement by exploring
    different configurations and evaluating wirelength, power, and timing constraints.
    The CNN model is trained using extracted features such as macro density map, pin
    density map, and connectivity density map. The CNN model has reduced the DRV count
    and lowered the average total wirelength, then it was integrated into the original
    macro placement engine. Simulated annealing optimization was then applied to assess
    whether the resulting macro placement was near-optimal.


    Signal integrity (SI) may also impact delays as it influences the propagation
    of signals and overall timing performance. SI effects create coupling capacitance
    due to the switching activity in neighboring nets which alters wire delays and
    transition time (slew) in adjacent nets. Most EDA tools include a Static Timing
    Analysis (STA) engine with an SI mode, which introduces additional pessimism to
    the total delay based on aggressor and victim dependencies. However, timing analysis
    with SI mode enabled can be timeconsuming, especially for large designs.


    In [41], the authors developed a model to predict transition time, incremental
    delays, and path delays in SI mode. Fig 11 illustrates the incremental delay divergence
    in SI mode between a commercial tool and a signoff SI tool, with an inaccuracy
    reaching 60ps. The training parameters include diverse design features, such as
    clock period, toggle rate, coupling capacitance, resistance, aggressors count,
    differences in max-min arrival times, transition time, and incremental delay in
    non-SI mode. The authors trained ANN and SVM models using a 28nm technology library
    and combined the predictions to obtain final values for incremental transition
    time, incremental delay, and path delay in SI mode. The prediction accuracy reduced
    the absolute error by 15.7%. Fig 12 shows the actual versus predicted incremental
    delays considering SI, with a worst-case absolute error of 5.2ps.


    ![](_page_7_Figure_4.jpeg)


    Fig. 11 Delay Inaccuracy between SI and Non SI mode


    [42] presents an approach to estimating SI effects. The framework uses autoencoder
    and anomaly detection (AD) methods to uncover relevant features from the circuit
    outputs and to detect anomalies. The authors proposed a semisupervised LSAnomaly
    algorithm to identify anomalies in the output signal waveform based on time-domain
    waveform signals.


    ![](_page_7_Figure_7.jpeg)


    Fig. 12 Model''s predictions of Delay on SI mode


    *C..5 ML for Physical Verification*Machine Learning is also employed in detecting
    layout hotspots, a topic discussed in depth in both [43] and [44]. Conventionally,
    hotspots are detected using lithography commercial simulation tools. However,
    ML have remarkably enhanced the hotspot detection accuracy while preserving short
    runtime. A lithography simulator determines the good and bad layout samples. These
    samples are used to train an SVM binary classifier to highlight the boundary overlaps,
    as in Fig 13. Fig14 compares the model-predicted hotspots and the original lithography
    simulation.


    ![](_page_7_Figure_10.jpeg)


    Fig. 13: ML flow for Layout hotspots detection through lithography simulation


    ![](_page_7_Figure_12.jpeg)


    Fig. 14: Layout hotspots detection using lithography simulator vs. model prediction


    Lithography layout distortions may occur even if the design passes design rule
    checks (DRC). The design may still contain layout hotspots that are sensitive
    to the lithographic process. In a similar approach presented in [45], the authors
    propose an accurate hotspot detection CNN-based framework that applies a two-stage
    filter to identify these layout hotspots. Compared to a state-of-the-art DRC tool,
    the model''s result shows nearly 100% accuracy in a short runtime.


    *C..6 ML for Power Optimization*One of the challenges in power and timing performance
    is the IR drop. IR drop may slow down circuit timing behavior and lead to timing
    violations. Conventionally, IR drop signoff analysis is performed at the end of
    the IC design flow, especially during engineering change orders (ECO), before
    tape out. The challenge in fixing IR drop is that it cannot be fixed simultaneously,
    during the design phase. Resolving IR drop during the early design phase might
    be challenging as the primary focus is meeting timing, area, constraints, and
    routeability. However, IR drop fixing is addressed mostly during ECO, using power
    integrity analysis tools and simulations that help identify potential IR drop
    hotspots. In [46], the authors employed XG-Boost and CNN models to predict ground-bounce
    and dynamic cell IR-drop regions where IR-drop violations may occur. Various features
    were extracted, including total path resistance from the power pad to the cell,
    total cell power, peak and average current, toggle rate, load cell capacitance,
    cell type, and cell timing windows.


    Similar research has explored the static IR-drop prediction using Linear Regression
    in [47] and ANN in [48]. In [49], the author introduced a clustering method that
    partitioned the layout into multiple clusters, identifying areas with high power
    density. This approach helps to prevent IR drops and Electromigration (EM) noise
    at early design stages. The authors applied K-means, Mean Shift, and DBSCAN, to
    predict power-critical areas and prepare countermeasures for power hotspots.


    Voltage droop is a phenomenon that occurs momentarily when a high current demand
    occurs in a portion of logic gates, leading to timing violations as it impacts
    the rise and fall delays of cells. Voltage droop can potentially result in setup
    and hold time violations. It''s a common practice to include a static pessimism
    based on worst-case conditions to mitigate voltage droop, which often leads to
    unnecessary pessimism. In [50], an SVM model was developed to predict real-time
    voltage droop.


    IR-drop and Electromigration effects need to be addressed during the power grid
    (PG) design phase to prevent impacting chip interconnects and power grid network
    failure. [51] aimed at minimizing the impact of IR drop and EM on the chip''s
    power grid, the authors developed an ML approach for predicting chip power grid
    design and creating an EM-aware grid network. The model considers the current
    source coordinates (x and y) and the metal line width and employs a neural network
    to predict the optimal widths of the metal lines in the power network. Once the
    optimal widths are determined, the model generates an IR drop map. The predicted
    IR drop map closely matches the map obtained from the conventional approach, as
    illustrated in Fig 15. The model also achieved a significantly faster runtime
    of up to 6 times compared to the conventional approach.


    ![](_page_8_Figure_5.jpeg)


    Fig. 15 Actual IR drop vs. model prediction


    A similar approach in [52] predicts the on-chip power grid network aging using
    an EM-aware model. The author involved a neural network-based regression and a
    logistic regression classifier to identify potential EM-affected metal segments
    within the PG network.


    *C..7 ML for Timing Optimization*Data mining was also employed to identify the
    timing discrepancies. The research detailed in [66] uses the Support Vector Classifier
    (SVC) to uncover features that reveal timing inconsistencies between observed
    silicon timing and estimated timing provided by commercial analysis tools. The
    research findings revealed that a portion of predicted critical timing paths were
    found to be non-critical in silicon. Conversely, numerous critical paths in silicon
    were not flagged as critical during prediction. The learning model revealed significant
    rules and identified paths that exhibit slower performance than estimated.


    The study in [53] addresses the discrepancy in gate delay timing between single-input
    switching (SIS) and multi-input switching (MIS) gates. The influence of MIS on
    gate delay calculations could lead to either delay overestimations or underestimations.
    To mitigate the gate delay discrepancies, polynomial regression, SVR, and ANN
    models were employed. The models were trained using gate load and slew attributes,
    and then it was integrated into the timing library to facilitate timing adjustments
    and tested on benchmark designs. The results obtained using the ANN model demonstrated
    a significant improvement in delay prediction accuracy, as it has reduced misestimations
    from 120% in traditional SIS to less than 3%. In Fig 16, the approach involved
    extracting SIS and MIS for each standard cell using SPICE simulation. The SIS
    referred to commonly used delay computation models like NLDM and CCS, while MIS
    represented the golden multi-input switching models. The flow in Fig 16 feeds
    SIS, MIS, and MIS-SIS difference (MSD) to the ANN model. The ANN model aims to
    make SIS delay predictions based on the gate''s input transitions (trA, trB),
    load capacitance (CL), and the temporal distance or skew between both input transitions
    (SA-B). This work led to significant enhancement in timing accuracy at early design
    stages.


    ![](_page_8_Figure_11.jpeg)


    Fig. 16 MIS and SIS delay convergence using ANN


    In [54], the focus was on the pre-silicon and post-silicon timing correlation.
    The author extracted the post-silicon path delay testing (PDT) and their corresponding
    estimated presilicon delays from a static timing analyzer. Eq.6 describes a path-based
    cell and net timing differences, where P P c<sup>i</sup> and n<sup>i</sup> express
    the total cell and net delay and α<sup>c</sup> and α<sup>n</sup> are the correlation
    coefficients. This study encompassed 240 different designs and revealed a noticeable
    over-pessimism in


    $$\alpha\_c \* \sum c\_i = \sum c''\_i \quad ; \quad \alpha\_n \* \sum n\_i =
    \sum n''\_i \qquad (6)$$


    - αc, αn: Cell/Net correlation factors on critical path.

    - c<sup>i</sup> , n<sup>i</sup> : Post-silicon (PDT) measured cell/net delays.

    - c ′ i , n ′ i : Pre-silicon (STA) estimated cell/net delays.


    ![](_page_9_Figure_5.jpeg)


    Fig. 17: Discrepancies in path delays between Post-Silicon and Pre-Silicon estimations


    Multiple factors can cause timing discrepancies, including circuit implementation,
    process, environment variations, and tool uncertainties. It becomes critical to
    pinpoint the factors contributing to the timing differences. In [55], the focus
    was identifying timing path variations between estimated and observed. To accomplish
    this, the author employed a statistical regression approach using support vector
    ϵ-insensitive regression (ϵ-SVR) to rank the feature''s importance in terms of
    their impact on path timing deviations. The model considered a wide range of features,
    including cell and net attributes, as well as layout-related features such as
    the number of vias in the path, transistor types, location-related parameters,
    and dynamic environment characteristics such as temperature, power grid behavior,
    voltage droop, and switching activity. This analysis aimed to shed light on the
    root causes of timing mismatches and improve the overall understanding of circuit
    performance.


    The study in [56] aimed to improve timing correlation in setup time, cell delays,
    wire delays, stage delays, and endpoints slack between an implementation tool
    and a signoff tool, in 28nm and 45nm technology designs. The approach employed
    ANN, SVM Regressor, and RF. Fig18 depict timing discrepancies that reach 110ps
    between two commercial signoff timing tools, *T1* and *T2*, and path slack discrepancies
    of 100ps between a signoff timing tool and a commercial design implementation
    tool *T1* and *D1*.


    The study in [57] presents a pre-routing timing convergence model, employing Neural
    Networks and Random Forest to reduce net delay pessimism at the pre-routing phase.
    Fig 19 illustrates a pre-routing slack estimation for a design operating at 2ns
    clock period. The red line indicates an ideal estimation of pre-routing slack
    delays using a sign-off timing analysis. The figure highlights a significant worst-case


    ![](_page_9_Figure_10.jpeg)


    Fig. 18: Slack discrepancies between signoff tools *T1* and *T2*, and commercial
    design implementation tool *D1* vs. *T1*


    ![](_page_9_Figure_12.jpeg)


    Fig. 19: Slack discrepancies at pre-pouting stage for a 2ns Clock Period Design


    scenario where slack surpasses the clock period, leading to an over-pessimism
    and over-design.


    In [58], the focus was on aligning net delays and transition time (Slew) using
    learning models. The research aimed to converge estimated wire and slew delays
    to wire and slew delays obtained from the signoff STA tool. Consequently, the
    proposed methodology reduces accumulated timing errors and maintains the correlation
    between wire and slew delays. [59] investigated the Graph-based timing analysis
    (GBA) and Path-based timing analysis (PBA) convergence. Employing the RF algorithm,
    the study aimed to align PBA estimated arrival times and slack to GBA values.
    The model implementation has effectively decreased PBA-GBA timing pessimism within
    a brief inference time.


    In [60], a learning-based method identifies memory timing errors from the pre-placement
    stage. The research uses Lasso, SVM, Gradient Boosting, and ANN models to predict
    post-layout slack from early design phases. The author in [61] tries to improve
    the circuit switching power accuracy using LR, RF, and DT models. The methodology
    trains models using multiple runs with back-annotated RC parasitics extracted
    from Standard Parasitic Exchange Format (SPEF) files. The study developed a "Spefless
    flow" capable of predicting a cell''s switching power regardless of the SPEF file.


    [62] improves pre-routing net delay and pin arrival times without relying on the
    routing engine. The author presents a Graph Neural Networks (GNN) model to rectify
    endpoint arrival times and slack at the pre-route stage. This study is conducted
    on 21 benchmark designs of 130nm. In [63], the author investigates the LR, ANN,
    RF, and XGBoost to predict crosstalk-prone nets, aiming to enhance design routability
    and timing accuracy during the routing phase. The study encompasses 12 benchmark
    designs at the 7nm scale, ranging from 3,500 to 74,000 instances. For model training,
    20 net features were employed, covering aspects such as net topology, wire delay,
    output slew, and both electrical and logical characteristics, including source
    and sink capacitance, fan-in, fan-out, wirelength, congestion, as well as neighboring
    nets'' drive strength. Among the models assessed, XGBoost exhibited the highest
    accuracy, achieving 91.12% accuracy in predicting coupling capacitance, 84.63%
    in crosstalk noise, and 87.56% in incremental delay.


    #### IV. RESULTS ANALYSIS AND DISCUSSION


    In Table I, we summarize the state-of-the-art works of ML applications in VLSI
    and CAD. We extracted relevant information such as the implemented models, the
    related PnR stage, and the design technology node employed during the training
    process. Our goal is to highlight the main findings from the literature review,
    identify gaps and limitations or weaknesses in the existing literature, and propose
    future directives.


    Most studies have implemented supervised learning models due to their reliance
    on labeled data. Regression and classification algorithms stand out as extensively
    applied, especially tree-based models Random Forest and Decision Trees, along
    with Support Vector Regressor and Gradientbased models. However, there is an evident
    surge in deep learning and Neural Networks applications. Most studies tend to
    adopt Artificial Neural Networks (ANNs), Convolutional Neural Networks (CNNs),
    and Graph Neural Networks (GNNs).


    Although significant progress has been made to enhance design placement, verification,
    timing, and power accuracy at PnR early stages, the majority of prior studies
    have focused on small and medium-sized designs, mainly within higher technology
    nodes like 28nm, 45nm, and higher. There have been limited works, such as those
    referenced in [36][48][53][63], and [61], that use 16nm, 15nm, and 7nm design
    technologies, thus representing a minority.


    Previous studies have consistently demonstrated the superior predictive accuracy
    of tree-based methodologies and neural networks. Nevertheless, these investigations
    often encountered limitations by relying on a limited set of features, typically
    around 4 to 20 input parameters. This restriction in feature selection might have
    a repercussion on the overall accuracy.


    In this review, we evaluated the quality of data used for the training process.
    The findings revealed that previous studies tend to use a limited selection of
    design architectures. This limitation restricts the scope of training data, which
    fails to achieve robust generalization capabilities, while models need exposure
    to varied design architectures during the training phase. Consequently, when subjected
    to new, unseen data, these models exhibit a lower ability to generalize, resulting
    in reduced overall accuracy.


    Another crucial aspect lies in tuning hyperparameters which is often overlooked
    in many studies. It is essential to optimize further the model''s performance.
    By neglecting hyperparameter fine-tuning, models may not achieve their maximum
    potential. Most studies have either omitted or did not mention due to space limitations.
    In addition, various studies use a reduced set of features to train models. The
    inclusion of multiple features enhances the prediction accuracy depending on the
    feature''s importance and contribution to the predictions.


    As future directives and key contributions, we suggest:


    - *Involving diverse technology nodes on the same training set*: this emphasizes
    the importance of developing models capable of accommodating different cutting-edge
    technology nodes within the same learning framework. This approach intends to
    enhance the models'' adaptability and accuracy.

    - *Incorporating large-scale industrial designs with diverse internal architectures*:
    during training, models have to learn and adapt to various design architectures
    to reflect real-world scenarios. This exposure to diverse implementations enhances
    models'' adaptability and improves the generalization.

    - *Multi-frequency runs*: one crucial aspect often overlooked and which could
    significantly enhance models'' accuracy and generalization, is conducting design
    runs at various clock frequencies. Many studies have neglected to incorporate
    running designs across a spectrum of clock frequencies. By including frequency
    as a feature in the training dataset, the model gains exposure to the behavior
    at different speeds. This offers an opportunity to enrich the model''s learning
    dataset.

    - *Use of relevant features*: a varied training feature set captures various aspects
    of circuit behavior and characteristics. This broad coverage enhances prediction
    accuracy.

    - *Hyperparameter tuning*. Tuning hyperparameters involves meticulous adjustments
    to find the most effective configuration, ensuring the model operates at its peak
    performance. This procedure identifies the best hyperparameters that enhance the
    overall accuracy.


    #### V. CONCLUSION


    Machine learning presents promising solutions to enhance the VLSI design and EDA.
    As technology progresses, following Moore''s law and the reduction in transistor
    sizes, the increase in design complexity continues. The integration of Learning
    frameworks has advanced EDA tools resulting in considerable enhancements across
    various applications. These advancements have contributed to improved chip performance,
    detection of power leaks, optimization of chip area, reduction in power consumption,
    identification of potential fabrication defects, and improved QoR accuracy.


    After conducting our review, we have identified certain limitations. Earlier studies
    were constrained by reliance on small to medium-sized designs within higher technology
    nodes like 28nm and 45nm. The incorporation of large-scale industrial designs
    enriches model learning, improving generalization. Additionally, we suggest conducting
    design runs at varied clock frequencies to exploit data at different operational
    speeds with a rich set of input features and hyperparameter tuning.


    Our ongoing endeavor involves NN application leveraging an extensive dataset of
    multiple cutting-edge 7nm and 16nm technology designs with around 100 extracted
    features. This initiative aims to enhance timing prediction accuracy at the pre-placement
    stage. This forthcoming project is built upon our previous work referenced in
    [67]. Addressing these contributions in future research endeavors will potentially
    enhance model accuracy and adaptability.


    #### REFERENCES


    - [1] M. Pandey, "Machine learning and systems for building the next generation
    of eda tools," in *2018 23rd Asia and South Pacific Design Automation Conference
    (ASP-DAC)*. IEEE, 2018, pp. 411–415.

    - [2] A. B. Kahng, "Machine learning for cad/eda: the road ahead," *IEEE Design
    & Test*, vol. 40, no. 1, pp. 8–16, 2022.

    - [3] A. C. Muller and S. Guido, ¨ *Introduction to machine learning with Python:
    a guide for data scientists*. " O''Reilly Media, Inc.", 2016.

    - [4] G. Dong and H. Liu, *Feature engineering for machine learning and data analytics*.
    CRC press, 2018.

    - [5] A. Zheng and A. Casari, *Feature engineering for machine learning: principles
    and techniques for data scientists*. " O''Reilly Media, Inc.", 2018.

    - [6] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,
    M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg *et al.*, "Scikit-learn: Machine
    learning in python," *the Journal of machine Learning research*, vol. 12, pp.
    2825–2830, 2011.

    - [7] L. Buitinck, G. Louppe, M. Blondel, F. Pedregosa, A. Mueller, O. Grisel,
    V. Niculae, P. Prettenhofer, A. Gramfort, J. Grobler, R. Layton, J. VanderPlas,
    A. Joly, B. Holt, and G. Varoquaux, "API design for machine learning software:
    experiences from the scikit-learn project," in *ECML PKDD Workshop: Languages
    for Data Mining and Machine Learning*, 2013, pp. 108–122.

    - [8] T. Hastie, R. Tibshirani, J. H. Friedman, and J. H. Friedman, *The elements
    of statistical learning: data mining, inference, and prediction*. Springer, 2009,
    vol. 2.

    - [9] A. Geron, ´ *Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow*.
    " O''Reilly Media, Inc.", 2022.

    - [10] S. Rogers and M. Girolami, *A first course in machine learning*. Chapman
    and Hall/CRC, 2016.

    - [11] R. S. Sutton and A. G. Barto, *Reinforcement learning: An introduction*.
    MIT press, 2018.

    - [12] A. M. Wichert and L. Sa-Couto, *Machine Learning-A Journey to Deep Learning:
    With Exercises and Answers*. World Scientific, 2021.

    - [13] D. Amuru, A. Zahra, H. V. Vudumula, P. K. Cherupally, S. R. Gurram, A.
    Ahmad, and Z. Abbas, "Ai/ml algorithms and applications in vlsi design and technology,"
    *Integration*, 2023.

    - [14] S. Saini, K. Lata, and G. Sinha, *VLSI and Hardware Implementations Using
    Modern Machine Learning Methods*. CRC Press, 2021.

    - [15] P. A. Beerel and M. Pedram, "Opportunities for machine learning in electronic
    design automation," in *2018 IEEE International Symposium on Circuits and Systems
    (ISCAS)*. IEEE, 2018, pp. 1–5.

    - [16] A. Malhotra and A. Singh, "Implementation of ai in the field of vlsi: A
    review," in *2022 Second International Conference on Power, Control and Computing
    Technologies (ICPC2T)*. IEEE, 2022, pp. 1–5.

    - [17] L. Wang and M. Luo, "Machine learning applications and opportunities in
    ic design flow," in *2019 international symposium on VLSI design, automation and
    test (VLSI-DAT)*. IEEE, 2019, pp. 1–3.

    - [18] A. B. Kahng, "Machine learning applications in physical design: Recent
    results and directions," in *Proceedings of the 2018 international symposium on
    physical design*, 2018, pp. 68–73.

    - [19] W. Chen, N. Sumikawa, L.-C. Wang, J. Bhadra, X. Feng, and M. S. Abadir,
    "Novel test detection to improve simulation efficiency: a commercial experiment,"
    in *Proceedings of the International Conference on Computer-Aided Design*, 2012,
    pp. 101–108.

    - [20] W. Chen, L.-C. Wang, J. Bhadra, and M. Abadir, "Simulation knowledge extraction
    and reuse in constrained random processor verification," in *Proceedings of the
    50th Annual Design Automation Conference*, 2013, pp. 1–6.

    - [21] H.-Y. Liu and L. P. Carloni, "On learning-based methods for designspace
    exploration with high-level synthesis," in *Proceedings of the 50th annual design
    automation conference*, 2013, pp. 1–7.

    - [22] B. Ozisikyilmaz, G. Memik, and A. Choudhary, "Efficient system design space
    exploration using machine learning techniques," in *Proceedings of the 45th annual
    design automation conference*, 2008, pp. 966–969.

    - [23] A. Mahapatra and B. C. Schafer, "Machine-learning based simulated annealer
    method for high level synthesis design space exploration," in *Proceedings of
    the 2014 Electronic System Level Synthesis Conference (ESLsyn)*. IEEE, 2014, pp.
    1–6.

    - [24] R. G. Kim, J. R. Doppa, and P. P. Pande, "Machine learning for design space
    exploration and optimization of manycore systems," in *2018 IEEE/ACM International
    Conference on Computer-Aided Design (IC-CAD)*. IEEE, 2018, pp. 1–6.

    - [25] T.-C. Chen, P.-Y. Lee, and T.-C. Chen, "Automatic floorplanning for ai
    socs," in *2020 International Symposium on VLSI Design, Automation and Test (VLSI-DAT)*.
    IEEE, 2020, pp. 1–2.

    - [26] A. Mirhoseini, A. Goldie, M. Yazgan, J. Jiang, E. Songhori, S. Wang, Y.-J.
    Lee, E. Johnson, O. Pathak, S. Bae *et al.*, "Chip placement with deep reinforcement
    learning," *arXiv preprint arXiv:2004.10746*, 2020.

    - [27] C.-K. Lee, "Deep learning creativity in eda," in *2020 International Symposium
    on VLSI Design, Automation and Test (VLSI-DAT)*. IEEE, 2020, pp. 1–1.

    - [28] Y. Ma, H. Ren, B. Khailany, H. Sikka, L. Luo, K. Natarajan, and B. Yu,
    "High performance graph convolutional networks with applications in testability
    analysis," in *Proceedings of the 56th Annual Design Automation Conference 2019*,
    2019, pp. 1–6.

    - [29] Y. Lin, S. Dhar, W. Li, H. Ren, B. Khailany, and D. Z. Pan, "Dreamplace:
    Deep learning toolkit-enabled gpu acceleration for modern vlsi placement," in
    *Proceedings of the 56th Annual Design Automation Conference 2019*, 2019, pp.
    1–6.

    - [30] B. Yu, D. Z. Pan, T. Matsunawa, and X. Zeng, "Machine learning and pattern
    matching in physical design," in *The 20th Asia and South Pacific design automation
    conference*. IEEE, 2015, pp. 286–293.

    - [31] S. Ward, D. Ding, and D. Z. Pan, "Pade: A high-performance placer with
    automatic datapath extraction and evaluation through high dimensional data learning,"
    in *Proceedings of the 49th Annual Design Automation Conference*, 2012, pp. 756–761.

    - [32] S. I. Ward, N. Viswanathan, N. Y. Zhou, C. C. Sze, Z. Li, C. J. Alpert,
    and D. Z. Pan, "Clock power minimization using structured latch templates and
    decision tree induction," in *2013 IEEE/ACM International Conference on Computer-Aided
    Design (ICCAD)*. IEEE, 2013, pp. 599–606.

    - [33] R. Kirby, S. Godil, R. Roy, and B. Catanzaro, "Congestionnet: Routing congestion
    prediction using deep graph neural networks," in *2019 IFIP/IEEE 27th International
    Conference on Very Large Scale Integration (VLSI-SoC)*. IEEE, 2019, pp. 217–222.

    - [34] W.-T. J. Chan, Y. Du, A. B. Kahng, S. Nath, and K. Samadi, "Beol stack-aware
    routability prediction from placement using data mining techniques," in *2016
    IEEE 34th international conference on computer design (ICCD)*. IEEE, 2016, pp.
    41–48.


    Journal of Integrated Circuits and Systems, vol. 19, n. 2, 2024 13


    - [35] W.-H. Chang, L.-D. Chen, C.-H. Lin, S.-P. Mu, M. C.-T. Chao, C.- H. Tsai,
    and Y.-C. Chiu, "Generating routing-driven power distribution networks with machine-learning
    technique," in *Proceedings of the 2016 on International Symposium on Physical
    Design*, 2016, pp. 145–152.

    - [36] W.-T. J. Chan, P.-H. Ho, A. B. Kahng, and P. Saxena, "Routability optimization
    for industrial designs at sub-14nm process nodes using machine learning," in *Proceedings
    of the 2017 ACM on International Symposium on Physical Design*, 2017, pp. 15–21.

    - [37] A. F. Tabrizi, N. K. Darav, S. Xu, L. Rakai, I. Bustany, A. Kennings, and
    L. Behjat, "A machine learning framework to identify detailed routing short violations
    from a placed netlist," in *Proceedings of the 55th Annual Design Automation Conference*,
    2018, pp. 1–6.

    - [38] Z. Qi, Y. Cai, and Q. Zhou, "Accurate prediction of detailed routing congestion
    using supervised data learning," in *2014 IEEE 32nd international conference on
    computer design (ICCD)*. IEEE, 2014, pp. 97–103.

    - [39] Q. Zhou, X. Wang, Z. Qi, Z. Chen, Q. Zhou, and Y. Cai, "An accurate detailed
    routing routability prediction model in placement," in *2015 6th Asia Symposium
    on Quality Electronic Design (ASQED)*. IEEE, 2015, pp. 119–122.

    - [40] Y.-H. Huang, Z. Xie, G.-Q. Fang, T.-C. Yu, H. Ren, S.-Y. Fang, Y. Chen,
    and J. Hu, "Routability-driven macro placement with embedded cnn-based prediction
    model," in *2019 Design, Automation & Test in Europe Conference & Exhibition (DATE)*.
    IEEE, 2019, pp. 180–185.

    - [41] A. B. Kahng, M. Luo, and S. Nath, "Si for free: machine learning of interconnect
    coupling delay and transition effects," in *2015 ACM/IEEE International Workshop
    on System Level Interconnect Prediction (SLIP)*. IEEE, 2015, pp. 1–8.

    - [42] R. Medico, D. Spina, D. V. Ginste, D. Deschrijver, and T. Dhaene, "Machine-learning-based
    error detection and design optimization in signal integrity applications," *IEEE
    Transactions on Components, Packaging and Manufacturing Technology*, vol. 9, no.
    9, pp. 1712– 1720, 2019.

    - [43] L.-C. Wang, "Experience of data analytics in eda and test—principles, promises,
    and challenges," *IEEE Transactions on Computer-Aided Design of Integrated Circuits
    and Systems*, vol. 36, no. 6, pp. 885– 898, 2016.

    - [44] D. Ding, J. A. Torres, and D. Z. Pan, "High performance lithography hotspot
    detection with successively refined pattern identifications and machine learning,"
    *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*,
    vol. 30, no. 11, pp. 1621–1634, 2011.

    - [45] Y.-T. Yu, Y.-C. Chan, S. Sinha, I. H.-R. Jiang, and C. Chiang, "Accurate
    process-hotspot detection using critical design rule extraction," in *Proceedings
    of the 49th Annual Design Automation Conference*, 2012, pp. 1167–1172.

    - [46] Y.-C. Fang, H.-Y. Lin, M.-Y. Sui, C.-M. Li, and E. J.-W. Fang, "Machine-learning-based
    dynamic ir drop prediction for eco," in *2018 IEEE/ACM International Conference
    on Computer-Aided Design (IC-CAD)*. IEEE, 2018, pp. 1–7.

    - [47] Y. Yamato, T. Yoneda, K. Hatayama, and M. Inoue, "A fast and accurate per-cell
    dynamic ir-drop estimation method for at-speed scan test pattern validation,"
    in *2012 IEEE International Test Conference*. IEEE, 2012, pp. 1–8.

    - [48] S.-Y. Lin, Y.-C. Fang, Y.-C. Li, Y.-C. Liu, T.-S. Yang, S.-C. Lin, C.-M.
    Li, and E. J.-W. Fang, "Ir drop prediction of eco-revised circuits using machine
    learning," in *2018 IEEE 36th VLSI Test Symposium (VTS)*. IEEE, 2018, pp. 1–6.

    - [49] H. Dhotre, S. Eggersgluß, and R. Drechsler, "Identification of efficient
    ¨ clustering techniques for test power activity on the layout," in *2017 IEEE
    26th Asian Test Symposium (ATS)*. IEEE, 2017, pp. 108–113.

    - [50] F. Ye, F. Firouzi, Y. Yang, K. Chakrabarty, and M. B. Tahoori, "On-chip
    voltage-droop prediction using support-vector machines," in *2014 IEEE 32nd VLSI
    Test Symposium (VTS)*. IEEE, 2014, pp. 1–6.

    - [51] S. Dey, S. Nandi, and G. Trivedi, "Powerplanningdl: Reliability-aware framework
    for on-chip power grid design using deep learning," in *2020 Design, Automation
    & Test in Europe Conference & Exhibition (DATE)*. IEEE, 2020, pp. 1520–1525.

    - [52] ——, "Machine learning for vlsi cad: A case study in on-chip power grid
    design," in *2021 IEEE Computer Society Annual Symposium on VLSI (ISVLSI)*. IEEE,
    2021, pp. 378–383.

    - [53] O. S. Ram and S. Saurabh, "Modeling multiple-input switching in timing
    analysis using machine learning," *IEEE Transactions on Computer-Aided Design
    of Integrated Circuits and Systems*, vol. 40, no. 4, pp. 723–734, 2020.

    - [54] L.-C. Wang, P. Bastani, and M. S. Abadir, "Design-silicon timing correlation:
    A data mining perspective," in *Proceedings of the 44th annual Design Automation
    Conference*, 2007, pp. 384–389.

    - [55] P. Bastani, N. Callegari, L.-C. Wang, and M. S. Abadir, "Statistical diagnosis
    of unmodeled systematic timing effects," in *Proceedings of the 45th annual Design
    Automation Conference*, 2008, pp. 355–360.

    - [56] S.-S. Han, A. B. Kahng, S. Nath, and A. S. Vydyanathan, "A deep learning
    methodology to proliferate golden signoff timing," in *2014 Design, Automation
    & Test in Europe Conference & Exhibition (DATE)*. IEEE, 2014, pp. 1–6.

    - [57] E. C. Barboza, N. Shukla, Y. Chen, and J. Hu, "Machine learningbased pre-routing
    timing prediction with reduced pessimism," in *2019 56th ACM/IEEE Design Automation
    Conference (DAC)*. IEEE, 2019, pp. 1–6.

    - [58] A. B. Kahng, S. Kang, H. Lee, S. Nath, and J. Wadhwani, "Learningbased
    approximation of interconnect delay and slew in signoff timing tools," in *2013
    ACM/IEEE International Workshop on System Level Interconnect Prediction (SLIP)*.
    IEEE, 2013, pp. 1–8.

    - [59] A. B. Kahng, U. Mallappa, and L. Saul, "Using machine learning to predict
    path-based slack from graph-based timing analysis," in *2018 IEEE 36th International
    Conference on Computer Design (ICCD)*. IEEE, 2018, pp. 603–612.

    - [60] W.-T. J. Chan, K. Y. Chung, A. B. Kahng, N. D. MacDonald, and S. Nath,
    "Learning-based prediction of embedded memory timing failures during initial floorplan
    design," in *2016 21st Asia and South Pacific Design Automation Conference (ASP-DAC)*.
    IEEE, 2016, pp. 178–185.

    - [61] M. Chentouf, C. Naimy, and Z. E. A. A. Ismaili, "Machine learning application
    for early power analysis accuracy improvement: A case study for cells switching
    power," in *2021 International Conference on Microelectronics (ICM)*. IEEE, 2021,
    pp. 17–20.

    - [62] Z. Guo, M. Liu, J. Gu, S. Zhang, D. Z. Pan, and Y. Lin, "A timing engine
    inspired graph neural network model for pre-routing slack prediction," 2022.

    - [63] R. Liang, Z. Xie, J. Jung, V. Chauha, Y. Chen, J. Hu, H. Xiang, and G.-
    J. Nam, "Routing-free crosstalk prediction," in *2020 IEEE/ACM International Conference
    On Computer Aided Design (ICCAD)*. IEEE, 2020, pp. 1–9.

    - [64] L.-C. Wang and M. S. Abadir, "Data mining in eda-basic principles, promises,
    and constraints," in *Proceedings of the 51st Annual Design Automation Conference*,
    2014, pp. 1–6.

    - [65] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Lio, Y. Bengio *et
    al.*, "Graph attention networks," *stat*, vol. 1050, no. 20, pp. 10– 48 550, 2017.

    - [66] J. Chen, B. Bolin, L.-C. Wang, J. Zeng, D. Drmanac, and M. Mateja, "Mining
    ac delay measurements for understanding speed-limiting paths," in *2010 IEEE International
    Test Conference*. IEEE, 2010, pp. 1–10.

    - [67] Y. Attaoui, M. Chentouf, Z. E. A. A. Ismaili, and A. El Mourabit, "Machine
    learning application for cell delay accuracy improvement at post-placement stage:
    A case study for combinational cells," *Integration*, 2023.'
  decisions:
    evaluation_prompt: 'Qualified. Reason: The paper contains a "Results Analysis
      and Discussion" section, multiple references to empirical studies, and figures
      and tables presenting quantifiable outcomes, indicating structured evaluation.'
    related_work_prompt: 'Qualified. Reason: The paper includes a comprehensive literature
      review section that meaningfully engages with prior research. It cites numerous
      academic sources throughout the text, compares its methods to previous work,
      and discusses the state-of-the-art in the field of ML applications in VLSI design
      and CAD EDA.'
    novelty_prompt: 'Disqualified: no novelty. Reason: The paper provides a comprehensive
      review of existing machine learning applications in VLSI design and EDA, but
      it does not propose any new methods, algorithms, architectures, datasets, or
      insights. It primarily summarizes and discusses the state-of-the-art without
      making any clear claims of novel contributions or applications.'
    review_only_prompt: 'Disqualified: review paper. Reason: The title contains the
      word "review," and the main body primarily summarizes existing work without
      introducing new methods, datasets, experiments, or frameworks.'
- title: Towards Next-Generation Intelligent Assistants Leveraging LLM Techniques
  abstract: ''
  keywords: conversational AI, large language models, multi-modal conversation, knowledge
    grounding, personalization, federated learning
  document: '#### 1.1 Introduction


    We will start with an introduction discussing the basics of virtual assistant,
    and the new challenges we face in building an AR/VR assistant. We will discuss
    what is an ideal assistant; that is, an agent that knows the user and the world,
    can receive requests from the user in a reactive fashion, or predict the users
    needs in a proactive fashion, then provide the user the right services at the
    right time, with the user''s permission.


    #### 1.2 Conversational AI Basics


    Before diving deep into cutting-edge techniques addressing the novel challenges
    for AR/VR assistants, we first provide a high-level overview of the conventional
    language-oriented assistant system. We introduce the overall design of both open-domain
    end-to-end conversational AI and modularized task-oriented dialog systems, but
    put more focus on the latter as they are the backbone of virtual assistants in
    industry. We dive deeper into key components: Automatic Speech Recognition (ASR),
    Natural Language Understanding (NLU), Dialog State Tracking, Dialog Policy Learning,
    Natural Language Generation (NLG), and Text-to-Speech (TTS). Due to time constraints,
    the tutorial will review basic construction with focus on modern modeling designs
    of each component, and leave implementation details as references. Links to public
    datasets will also be provided for training and evaluating dialogue-based assistants.


    Permission to make digital or hard copies of part or all of this work for personal
    or classroom use is granted without fee provided that copies are not made or distributed
    for profit or commercial advantage and that copies bear this notice and the full
    citation on the first page. Copyrights for third-party components of this work
    must be honored. For all other uses, contact the owner/author(s).


    <span id="page-1-0"></span>


    #### 1.3 Multi-modal Context-Aware Conversations


    We envision that the next generation of virtual assistants will be able to process
    multimodal inputs and provide multimodal outputs beyond the traditional NLP stack.
    Specifically, the AR/VR settings pose a situated multimodal context, where the
    user and the assistant are continually co-observing the same context, dynamically
    updated over time. The assistant for AR/VR thus requires (1) understanding of
    the multimodal context from diverse sources (e.g. vision, gestures, sensor signals),
    and (2) joint grounding of the situated context with the conversational context.


    We review the related literature across multiple domains and tasks, including
    the visual question and answering systems the visual navigation tasks and more
    general task-oriented multimodal agents. We will then dive deeper into the state-of-the-art
    modeling techniques that address the key challenges, such as multimodal co-reference
    resolution, multimodal dialog state tracking, and contextual understanding of
    user states.


    ## 1.4 Knowledge-Enhanced and Personalized Conversations


    To better assist a user in a personalized and contextualized manner, it is important
    for an assistant system to be able to (1) manage personal knowledge through memory
    grounded dialogue system, and (2) incorporate the world and personal knowledge
    as part of the grounding context for conversations. Incorporating personal memories
    as part of conversational interactions will be particularly important for AR devices
    that reside more closely to users'' everyday life, incurring more frequent usage.
    We will go through in detail the relevant work in the recent literature on inferring
    new knowledge from unstructured utterances, utilizing memory graphs, knowledge
    graphs and online-searches for conversational recommendations, question and answering,
    media retrieval, and knowledge grounded open-ended conversations.


    ### 1.5 On-device & Federated Learning for Privacy Preserving Assistant


    AR/VR devices have strict privacy constraints because they can access sensitive
    data from cameras, microphones and other sensors. This necessitates running model
    inference and training on-device, under challenging compute, memory and power
    constraints. We first review the state-of-the-art on-device modeling methods used
    in practice to downsize neural models (e.g. quantization, knowledge distillation,
    automated architecture search, accommodating for the limited memory and compute
    resources of wearable devices.


    We then discuss the unique challenge of training these models while preserving
    user privacy. We start with an overview of production federated learning systems,
    and then discuss the problems that arise when training data is spread across edge
    devices, like the impact of data and device heterogeneity, model personalization,
    and differential privacy.


    #### 1.6 Conclusions & Future Directions


    We conclude our tutorial by stating a number of open problems we need to solve
    to move towards the goal of building next-generation assistants for AR/VR devices.
    The open problems include 1) ondevice machine learning to provide assistant services
    with sporadic connections, 2) seamless integration of search, question answering,
    recommendation for information-driven needs, 3) proactive service suggestion at
    the right time, 4) leveraging public and personal knowledge graphs to improve
    context-aware services, 5) scalable graph mining from knowledge graphs, social
    graphs, and behavior graphs for better assistance, and many others.


    #### 2 PREVIOUS EDITIONS


    Below is a list of the tutorials on similar topics.


    - A related tutorial, titled ["Deeper Conversational AI",](https://neurips.cc/media/Slides/nips/2020/virtual(07-08-00)-07-08-00UTC-16657-track2_deeper.pdf)
    was given at NeurIPS 2020. The authors first reviewed general conversational AI
    architectures of the key components. Then they deep dived into generational seq2seq
    deep conversational AI techniques, pointed out limitations and solutions of vanilla
    models such as lack of diversity, consistency, knowledge etc. Finally, the authors
    touched upon various challenges and research directions, including reinforcement
    learning, few/zero shot learning, lifelong learning.

    - Another related tutorial titled ["Achieving Common Ground](https://acl2020.org/program/tutorials/#t5-achieving-common-ground-in-multi-modal-dialogue-cutting-edge-)
    [in Multi-modal Dialogue"](https://acl2020.org/program/tutorials/#t5-achieving-common-ground-in-multi-modal-dialogue-cutting-edge-)
    was given at ACL 2020. It reviewed theories and practices of incrementally achieving
    common ground between a robotic agent and a human participant during an open-domain
    dialog, with an emphasis on leveraging verbal and non-verbal behavior signals
    to orchestrate an effective engagements. The authors considered roles of a wide
    range of modalities including gazing, pointing, nodding, facial expressions and
    other non-verbal cues.


    Our tutorial is more focused on the context of building AR/VR assistants. On the
    one hand, we go beyond multi-modal conversations to discuss contextual AI and
    personalized assistant services. On the other hand, we discuss the practical challenges
    we face and the industrial solutions in building real assistant systems.


    Finally, a first edition of this tutorial is accepted by WebConf 2023. Our new
    version of the tutorial would add how the recent progress on LLM (Large Language
    Model) can further improve intelligent assistant.


    #### 3 AUDIENCE PARTICIPATION


    To help the audience understand challenges brought by multimodality, contextualization,
    and personalization, we will use one real-world scenario with progressive add-ons
    throughout the tutorial to illustrate the challenges and opportunities, and demonstrate
    the technical solutions. In addition, we will set aside time for Q & A in each
    subsection and encourage the audience to ask questions to ensure they understand
    the material and stays engaged. All slides will be made available publicly before
    the start of the tutorial.


    #### 4 POTENTIAL SOCIETAL IMPACTS


    In recent years, the use of virtual assistants has become increasingly popular,
    impacting various aspects of people''s lives. Our tutorial will encourage discussions
    on developing virtual assistants with integrity and responsibility in mind. Such
    considerations include but not limited to ensuring transparency and privacy, improving
    accessibility, avoiding bias, and promoting inclusivity.'
  decisions:
    evaluation_prompt: 'Disqualified: no evaluation. Reason: The paper lacks any form
      of empirical, experimental, or quantitative evaluation. It primarily consists
      of design discussions, conceptual proposals, and literature reviews without
      structured or reproducible testing.'
    related_work_prompt: '- Qualified. Reason: The paper meaningfully engages with
      prior research by reviewing related literature across multiple domains and tasks,
      discussing state-of-the-art modeling techniques, and comparing its focus with
      previous tutorials on similar topics. It provides context and discussion of
      previous work in sections such as "Multi-modal Context-Aware Conversations"
      and "Knowledge-Enhanced and Personalized Conversations," and references prior
      tutorials in the "PREVIOUS EDITIONS" section.'
    novelty_prompt: '- Qualified. Reason: The paper proposes novel insights and applications
      in the context of AR/VR assistants, such as processing multimodal inputs, managing
      personal knowledge, and addressing privacy concerns with on-device and federated
      learning. It also claims to focus on practical challenges and industrial solutions
      specific to AR/VR, which are not covered in previous tutorials. Additionally,
      it mentions incorporating recent progress on large language models to improve
      intelligent assistants, indicating a novel contribution.'
    review_only_prompt: 'Disqualified: review paper. Reason: The paper primarily summarizes
      existing work and techniques related to AR/VR assistants, conversational AI,
      and multimodal interactions without introducing any novel methods, datasets,
      experiments, or frameworks. The content is structured as a tutorial, focusing
      on reviewing state-of-the-art methods and literature rather than presenting
      original contributions.'
- title: '**European Data Protection Supervisor**'
  abstract: ''
  keywords: ''
  document: '> … > [TechSonar](https://edps.europa.eu/data-protection/technology-monitoring/techsonar_en)
    > Large language models (LLM)


    ![](_page_0_Picture_0.jpeg)


    # **European Data Protection Supervisor**


    # Translate this page **Large language models (LLM)**


    ![](_page_0_Picture_4.jpeg)


    **Author:** Xabier Lareo


    Language models are artificial intelligence (AI) systems designed to learn grammar,
    syntax and semantics of one or more languages to generate coherent and context-relevant
    language. Language models have been developed using neural networks since the
    1990s, but the results were modest.


    The evolution to large language models (LLMs) was made possible by technical developments
    that improved the performance and efficiency of AI systems.


    These developments included the advent of large-scale pre-trained models, the
    development of transformers (which learn context and meaning by tracking relationships
    in sequential data), and self-attention mechanisms (which allow models to weigh
    the importance of different elements in an input sequence and dynamically adjust
    their influence on the output).


    As a type of generative AI system, LLMs create new content in response to user
    commands based on their training data. They are trained on huge amounts of text
    sources (from billions to billions of words) from a variety of sources, including
    public sources, and their size can be measured by the number of parameters used.


    They''re also considered a type of ''foundation model'', which is a model trained
    on large amounts of data (usually using large-scale selfmonitoring) that can be
    adapted to a variety of applications, including text generation, summarising,
    translating, answering questions, and more.


    The number of parameters in LLMs has increased over time: while version 2 of the
    Generative Pre-trained Transformer (GPT-2) had 1.5 billion parameters, the Pathways
    Language Model (PaLM) reached 540 billion parameters. At a certain point, the
    development of competitive highperformance LLMs seemed to be something that only
    the most resourceful technology companies, such as Google, Meta or OpenAI, could
    achieve.


    However, two developments changed that trend and made LLM development more broadly
    available. First, the publication of research showing that there is an optimal
    set of values when selecting computing power, model size and training dataset
    size. Second, the appearance of parameter efficient fine-tuning techniques (e.g.
    LoRA), which have greatly reduced the amount of resources needed to train an LLM
    - PALM 2 already following this trend and, although it appears to have been trained
    with a much larger dataset, it has fewer parameters than its predecessor (340
    billion against PaLM''s 540 billion).


    Some LLM service providers have made their models publicly available – previous
    registration and, in several cases, using a subscription model through web interfaces
    that allow users to enter commands (prompts) and view the output generated by
    the models. Publicly accessible models are sometimes presented as research previews
    or testing versions that might produce erroneous or harmful output. LLM service
    providers also tend to offer access to their models (usually for a fee) through
    an application programming interface (API) that allows their LLM to be embedded
    into customers'' IT systems.


    LLMs are currently being used or tested for a wide variety of tasks in different
    domains, including translation; customer care (e.g. chatbots); education (e.g.
    language training); natural language processing (e.g. named entity recognition
    or summarisation); supporting the generation of images from a given prompt output;
    preparation of programming code; or even the creation of artistic works.


    As LLMs continue to evolve, they both offer opportunities and important challenges
    for privacy and data protection.


    # **Positive impacts foreseen on data protection:**


    LLMs could be used to support certain privacy activities in very specific scenarios,
    if designed, developed and deployed in a responsible and trustworthy manner, respecting
    the principles of data protection, privacy, human control and transparency.


    For example:


    **Detection of personal data**


    Identifying personal data in unstructured data, such as in text fields is relatively
    easy for humans, but difficult to automate using simple rules. However, human
    review does not scale well and becomes impractical or unfeasible in large-text
    files or web-scraped datasets. The natural language processing capabilities of
    LLMs could help detect and better manage personal data on unstructured information
    (e.g. a text field containing family history). LLMs could also help reduce the
    personal data included in their training datasets, by automatically identifying,
    redacting or obfuscating personal data.


    # **Negative impacts foreseen on data protection:**


    The vast majority of the data used to train state-of-the-art LLMs are texts scraped
    from publicly available Internet resources (e.g. the latest Common Crawl dataset,
    which contains data from more than 3 billion pages). These web-scraped datasets
    contain personal data of public figures, but also of other individuals. Personal
    data contained in these datasets could be accurate or inaccurate. These datasets
    could also contain plain misinformation. Implementing controls to address the
    data protection risks posed by the use of these datasets is very challenging.
    Moreover, if not properly secured, LLM output might reveal sensitive or private
    information included in the datasets used for training, leading to potential or
    real data breaches.


    LLMs sometimes suffer from so-called ''hallucinations'', meaning they produce
    erroneous information that appears to be correct. When hallucinating, an LLM can
    produce false or misleading information about individuals. Inaccurate information
    can affect individuals not only because it can damage their public image, but
    also because it can lead to decisions that affect them. LLMs, if trained on biased
    data, could perpetuate or even amplify biases present in their training data.
    This might lead to unfair or discriminatory outputs, potentially violating the
    principle of fair processing of personal data.


    LLMs store the data they learn in the form of the value of billions or trillions
    of parameters, rather than in a traditional database. For this reason, rectifying,
    deleting or even requesting access to personal data learned by LLMs, whether it
    is accurate or made up of "hallucinations", may be difficult or impossible.


    ## **Suggestions for further reading:**


    [https://edps.europa.eu/system/files/2023-10/edps-gpa-resolution-on-generative-ai-systems\\_en.pdf](https://edps.europa.eu/system/files/2023-10/edps-gpa-resolution-on-generative-ai-systems_en.pdf)


    ## **Training LLMs is a data-intensive activity, which can include personal data**


    ### **"Hallucinations", data accuracy and bias**


    ### **Implementing data subjects'' rights is difficult**


    Vaswani, Ashish, Noam M. Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan
    N. Gomez, Lukasz Kaiser and Illia Polosukhin. "Attention is All you Need.", 2017,<https://doi.org/10.48550/arXiv.1706.03762>


    Kaplan, Jared, Sam McCandlish, T. J. Henighan, Tom B. Brown, Benjamin Chess, Rewon
    Child, Scott Gray, Alec Radford, Jeff Wu and Dario Amodei. "Scaling Laws for Neural
    Language Models.", 2020, <https://doi.org/10.48550/arXiv.2001.08361>


    Hu, Edward J., Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
    Wang, Lu Wang, and Weizhu Chen. "LoRA: Low-rank adaptation of large language models",
    2021, [https://arxiv.org/abs/2106.09685v2.](https://arxiv.org/abs/2106.09685v2)


    Naveed, Humza, Asad Ullah Khan, Shi Qiu, Muhammad Saqib, Saeed Anwar, Muhammad
    Usman, Nick Barnes, and Ajmal Mian. "A comprehensive overview of large language
    models." , 2023,<https://doi.org/10.48550/arXiv.2307.06435>


    Global Privacy Assembly Resolution on Generative Artificial Intelligence Systems,
    2023,'
  decisions:
    evaluation_prompt: 'Disqualified: no evaluation. Reason: The paper contains only
      design discussions, conceptual proposals, and subjective reflections on large
      language models without any structured or reproducible testing or empirical
      evaluation.'
    related_work_prompt: '- Disqualified: no related work. Reason: The paper does
      not meaningfully engage with prior research. It lacks a discussion or comparison
      of its methods to previous work and does not provide context or discussion for
      the citations it includes. The citations are listed without integration into
      the text, and there is no explanation of how the current work relates to or
      builds upon these prior studies.'
    novelty_prompt: 'Disqualified: no novelty. Reason: The paper provides an overview
      of large language models (LLMs) and their implications for data protection,
      but it does not propose any new methods, applications, or insights. It summarizes
      existing knowledge and developments in the field without making any clear claims
      of novel contributions.'
    review_only_prompt: 'Disqualified: review paper. Reason: The paper primarily summarizes
      existing work on large language models, discussing their development, applications,
      and impacts on data protection without introducing any novel methods, datasets,
      experiments, or frameworks. The title and content indicate it is a review of
      existing technologies and their implications.'
- title: '**A Comprehensive Review of the Influence of Technology on Psychology**'
  abstract: ''
  keywords: ''
  document: "![](_page_0_Picture_0.jpeg)\n\n**International Journal of Scientific\
    \ Research in \\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\\
    _\\_\\_\\_\\_\\_\\_ Review Paper. Multidisciplinary Studies E-ISSN:** 2454-9312\
    \ Vol.7, Issue.9, pp.60-65, September (2021) **P-ISSN:** 2454-6143\n\n# **A Comprehensive\
    \ Review of the Influence of Technology on Psychology**\n\n**S. Bhattacharya1\\\
    *, S. Samaddar<sup>2</sup> , A. Banerjee<sup>3</sup>**\n\n<sup>1</sup>Masters\
    \ of Technology, Department of Electronics and Communication Engineering (VLSI\
    \ design), Heritage Institute of Technology, Kolkata, India\n\n<sup>2</sup>Bachelor\
    \ of Arts, Department of Psychology, Bagbazar Women's College, University of Calcutta,\
    \ Kolkata, India\n\n<sup>3</sup>Bachelor of Technology, Department of Electronics\
    \ and Communication Engineering, Techno India University, Kolkata,\n\nIndia\n\n\
    *\\*Corresponding Author: [sohambhattacharya36@gmail.com,](mailto:sohambhattacharya36@gmail.com)\
    \ Tel: +91 8910018323* \n\n#### **Available online at[: www.isroset.org](http://www.isroset.org/)**\n\
    \n## Received: 18/Sept/2021, Accepted: 20/Sept/2021, Online: 30/Sept/2021\n\n\
    *Abstract-* Psychology is the logical investigation of the mind and its behavioral\
    \ activities. Analysts are effectively engaged with contemplating and understanding\
    \ mental cycles, cerebrum capacities, and conduct. The area of Psychology is considered\
    \ as a \"Hub Science\" with solid associations with the clinical sciences, social\
    \ sciences, education, and much more. Technology is the branch of knowledge concerned\
    \ with the development and application of specialized tools, as well as their\
    \ interactions with life, society, and the environment, drawing on areas such\
    \ as mechanical engineering, applied science, and pure science. This study aims\
    \ to shed light on the relationship between the field of psychology and technological\
    \ progress nowadays. This paper also provides a detailed investigation of the\
    \ effect of technology on the discipline of psychology.\n\n*Keywords-* Psychology,\
    \ Technology, Machine Learning, Artificial Intelligence, Nanotechnology.\n\n#\
    \ **I. INTRODUCTION**\n\nPsychology is the coherent examination of how people\
    \ act, think, and feel. Sometime before 400-500 years B.C., Socrates, Plato, Aristotle\
    \ underscored the philosophical direction. Freedom of thought versus determinism,\
    \ memory; nature versus support, the fascination was their spaces of conversation.\
    \ In the early days, there were two predominant viewpoints: structuralism and\
    \ functionalism. It is said that the name 'structuralism' was spearheaded by Wilhelm\
    \ Wundt (1832-1920). The methodology predominantly centered on the breaking of\
    \ the psychological cycles into the most fundamental parts. Wundt's idea was huge\
    \ because it recognized psychology from theory, considering a more coordinated\
    \ examination of the psyche's activities. Then again, William James, an American\
    \ psychologist, fostered one more methodology which came to be known as 'functionalism'.\
    \ Both structuralism and functionalism were repudiated. Our brains are continually\
    \ changing, as indicated by William James, so searching for the construction of\
    \ mindful experience is awkward; all things considered, he focused on how and\
    \ why a creature performs something, for example, the mind's motivation.\n\nSigmund\
    \ Freud, who was the father of psychology, gave us psychoanalysis. He accepted\
    \ that individuals might be treated by acquiring an understanding of their oblivious\
    \ thoughts and inspirations and making them cognizant. Sigmund Freud's therapy\
    \ was the first psychodynamic hypothesis, yet it envelops different speculations\
    \ dependent on his ideas, including Jung, Adler, and Erikson. Afterward, different\
    \ methodologies made a gigantic commitment to the area of psychology, specifically\
    \ the behaviorist methodology and the humanistic methodology. The behaviorist\
    \ technique, regularly known as 'behavioral psychology', is a hypothesis that\
    \ affirms that all practices are instructed through some type of contact with\
    \ the climate named molding. Behaviorism just spotlights improvement practices.\
    \ Afterward, the humanistic methodology turned into one more methodology in which\
    \ the essential spotlight is on emotional experience and self-awareness.\n\nDuring\
    \ the 1960s and 1970s, an intellectual upset dependent on lab tests started in\
    \ the discipline of psychology, with applications to memory, discernment, and\
    \ intellectual turn of events, mental sickness, and significantly more. Analysts\
    \ focus on everything about the human experience, from the basic activities of\
    \ the human brain to insight, memory, thinking, and language to the character\
    \ and enthusiastic prosperity. At whatever point any individual is managing any\
    \ sort of mental pressure, confusion, or any type of human conduct change, clinicians\
    \ partake in tackling issues in our day-to-day routines. As a piece of science,\
    \ psychology not just deals with the means of human reasoning and conduct, but\
    \ additionally assists with taking care of the issues confronted and managing\
    \ the imperative cycles. As technology grows from day to day, major research areas\
    \ are now focused on presenting the needs of human behavior to match them with\
    \ the rehabilitation of devices or machines. A major hot topic which is the cup\
    \ of tea of our daily lives is 'Engineering Psychology' or 'Human Factors Engineering'.\
    \ 'Engineering Psychology' is the study of human behavior and capability, which\
    \ applies to the design of any device or system, or technology upbringing [1].\
    \ It is an application of ergonomics that states the relationship of human beings\
    \ and machines by reforming types of equipment, interactions, or environments\
    \ they can take place.\n\nTechnology nowadays takes a great step towards making\
    \ an impact in the field of psychology through computer simulations, algorithms,\
    \ and applications. Different treatments are nowadays being provided to patients\
    \ with the help of technological growth or advancement. New issues have been created\
    \ to get further inspection of the research areas through the help of technology\
    \ in this immense field.\n\n## **II. RELATED WORK**\n\nSome definite objectives\
    \ or intentions can be said in the area of psychology that does not just guide\
    \ in molding the conduct of one just like others. It is shown that describing,\
    \ explaining, predicting, and changing others' manner and mental cycles are the\
    \ four fundamental motivations behind psychology.\n\n- •**To describe:** The main\
    \ objective of psychology is to describe and assist scientists in fostering certain\
    \ overall laws of human conduct.\n- •**To explain:** After describing, analysts\
    \ will generally clarify the course of the conduct, hence clarifying how or why\
    \ this happens.\n- •**To predict:** Through exact exploration, psychology plans\
    \ to foresee future behavior.\n- •**To change:** Once the entirety of the objectives\
    \ have been met, endeavoring to change or control conduct is conceivable. The\
    \ four points have a wide scope of utilization in our regular routines, including\
    \ business, marketing, education, medication, and self-improvement.\n\nTechnology\
    \ isn't simply changing how individuals interface with the world; it's additionally\
    \ changing how researchers concentrate on human conduct and also the brain. San\
    \ Francisco is a world-popular center of innovation and a fitting area for a discussion\
    \ on research on tech and the human experience. In a Cross-Cutting Theme Program\
    \ at the 30th APS Annual Convention, speakers introduced interdisciplinary work\
    \ on how innovation shapes learning, consideration, conduct, and our public activities\
    \ from youth through advanced age. Inperson treatment, for example, is not available\
    \ nowadays. Several apps are available through which patients and analysts can\
    \ converse with the help of websites, applications, and teleconferencing, which\
    \ is ultimately the growth of modern-day's technology. Moreover, treatments or\
    \ detection of any kind of stress or disorder nowadays is\n\nIn this current world,\
    \ we as individuals are turning out to be more careful about our emotional well-being\
    \ and, along these lines; we are offering significance to our state of mind, which,\
    \ in another way, assists us with acquiring compassion towards one another. With\
    \ the improvement of this field or this subject, we can comprehend or we can realize\
    \ that individuals can experience the ill effects of mental torment, enthusiastic\
    \ agony, and not simply actual torment. Many psychological applications focus\
    \ on protecting people from emotional and physical risks while also giving them\
    \ the basic mental transmission capacity to deal with the mental threats that\
    \ many people experience daily. An analyst can assist an individual with further\
    \ developing their dynamic, their capacity to think, and in particular, they can\
    \ allow the patient to discuss whatever they feel like. The investigation of psychology\
    \ is farreaching today, and various parts of psychology are generally perceived\
    \ and oftentimes utilized in many pieces of business.\n\nThe rise of computer\
    \ technology has characterized this mental function as information processing.\
    \ This gave rise to the cognitive dominant model of the mind, which is combined\
    \ with the internal mental beliefs and study of the mind. With the progress of\
    \ technology, neuropsychology and cognitive neuroscience have taken an immense\
    \ part in the most active areas in modern-day psychology. With the involvement\
    \ of different fields like computer science, philosophy, and neuroscience, cognitive\
    \ science has created a great impact on such studies in a positive way [2].\n\n\
    In [3], it has been stated that technology has turned into a crucial power in\
    \ forming the personality, intellectual, and full of feeling measures, and social\
    \ exercises of our understudies, customers, and exploration members. Though the\
    \ family was once, by a wide margin, the most significant climate for molding\
    \ mentalities and convictions, today's teenagers are exposed to a lot more good\
    \ examples, values, perspectives, and decisions than at any other time. Computer\
    \ games permit individuals to build and experience augmented realities unconstrained\
    \ by the standards and upsides of general society (Gentile, Saleem, and Anderson,\
    \ 2007). The Internet upholds the framing of elective networks (Turkle, 1996)\
    \ around shared thoughts as opposed to as if they were through actual contact.\
    \ Virtual people groups can provide friendship for people who are unable to connect\
    \ with others in their immediate surroundings.\n\nPsychology has never been held\
    \ back by technology; rather, it has always attempted to apply itself to everyday\
    \ practices. If we look into the history of science, we can find out that many\
    \ psychologists, psychiatrists, and neurologists created devices based on technological\
    \ evolution over time. Many scientists, analysts, and\n\n#### Int. J. Sci. Res.\
    \ in Multidisciplinary Studies Vol.**7**, Issue.**9**, Sept **2021**\n\nphysicians\
    \ have used magnets, sensors, and computer programming languages to detect several\
    \ mental disorders. For example, Frank Mesmer, an Australian physician, used magnets\
    \ to detect human mental disorders in the eighteenth century. Then, he created\
    \ his famous \"health tanks\" and they were used by the patients to apply one\
    \ of these points to the aching side.\n\n## **III. METHODOLOGY AND THE BACKGROUND**\n\
    \nTechnology makes it possible to get numerous sets of data in real-time, including\
    \ self-report, physiological data, observed behavior, and so on. Scientists are\
    \ always attempting to bridge the gap between human feelings and technological\
    \ advancement. Why do we need computers to comprehend humans, when we're talking\
    \ about technology and psychology? For example, if a system does not recognize\
    \ that the user is becoming annoyed, the user may find it more difficult to use\
    \ the system. According to studies, when dealing with humans and robots, robots\
    \ who apologize more are significantly more likely to be favored than robots who\
    \ do not apologize.\n\nCell phones and wearable devices (e.g., smartwatches, fitness\
    \ trackers) make it simple to collect data as it happens, rather than relying\
    \ on self-reporting later. Human memory is fallible, and therefore the quicker\
    \ the knowledge is entered, the more likely it's accurate. Some software systems\
    \ mechanically enter data, like programs that measure exercise and sleep habits.\
    \ Alternative data must still be entered manually (for example, a food log), but\
    \ it can be done more quickly and conveniently on a phone we carry with us all\
    \ the time. Technology additionally permits researchers to perform measurements\
    \ in natural settings instead of being confined to the research laboratory.\n\n\
    Sensors in little devices that we use every day play an important part in tracking\
    \ and measuring human behavior, such as blood pressure, heart rate, sleep tracking,\
    \ dozing, skin conductance, and much more, but the issue remains as to what we\
    \ will do with all of this information. According to Dr. Eric Topol, author of\
    \ \"*The Creative Destruction of Medicine: How the Digital Revolution Will Create\
    \ Better Health Care,*\" when information about something is constantly returned\
    \ to a person, he or she becomes aware of stress or health abnormalities that\
    \ they were previously unaware of.\n\nTechnology has introduced new ways of accumulating\
    \ data, some of which are tremendous upgrades over more seasoned techniques. One\
    \ of the most challenging aspects of psychological research is repeating the results.\
    \ So, as technology is moving ahead, scientists have created some special instruments\
    \ which can obtain précised measurements from the larger samples. The bigger the\
    \ number of samples, the higher the measurement capacity. For example, computer-generated\
    \ reality tech permits analysts to assemble information without really going to\
    \ a particular climate. In addition to the fact that this is less costly and more\
    \ helpful, it likewise disposes of certain moral concerns and dependence on self-report.\
    \ Capacity innovation has permitted the advancement of immense data sets of data.\
    \ A large number of these index human conduct that can be utilized in the investigation\
    \ of psychology. For instance, data sets have data on everything from wrongdoing\
    \ measurements to lack of sleep. Moreover, these data sets gather data from a\
    \ huge and varied population, making them ideal for fulfilling legitimacy concerns.\
    \ This presents clinicians with colossal stores of data in which to investigate.\n\
    \n Nowadays, several methods have been used to detect various disorders or changes\
    \ in the human psyche or behavior. Some of them are Artificial Intelligence, Machine\
    \ Learning, Deep Learning, and much more. Using these technological instances,\
    \ nowadays, psychologists, scientists, and analysts have been creating different\
    \ devices to detect different conflicts in the human mind or behavior. These innovations\
    \ have stepped up with a great movement in recent years to detect several disorders,\
    \ stress, and changes in humans. Recognizing emotional information necessitates\
    \ the collection of data and the identification of various patterns, which is\
    \ accomplished with the use of machine learning, which processes voice recognition,\
    \ facial detection, and other tasks. 'Affective computing' comes into play here.\
    \ Rosalind Picard's 1995 work on emotional computing gave birth to the more contemporary\
    \ area of computer science. It's the study of machines and systems that can detect\
    \ and analyze human emotions. Changes in a user's language, tone of voice, and\
    \ variations in facial expression are detected and responded to by affective computing-enabled\
    \ devices. They do it by gathering data from users via physical sensors such as\
    \ video cameras and microphones and evaluating it using past experiences and data\
    \ sets. As a result of its activities and growth in recent years, technology is\
    \ revolutionizing the area of psychology.\n\n![](_page_2_Picture_10.jpeg)\n\n\
    Source: \"How is Technology changing Psychology?\" (2021) Figure 1: The effect\
    \ of Technology on the Human Mind.\n\n#### **IV. IN-DEPTH DISCUSSION OF PSYCHOLOGY\
    \ IN RELATION TO TECHNOLOGY**\n\nIn [4], the authors have stated that throughout\
    \ the nineteenth and twentieth century, a wide range of technologies has been\
    \ created to check the human state of mind. The authors also gave an example of\
    \ a subject that is whether telling the truth or lying using technology. Furthermore,\
    \ several computing technologies have recently been developed which use different\
    \ computer algorithms and face recognition software to detect the state of the\
    \ human mind.\n\nBig Data is the arrangement of innovations made to store, dissect\
    \ and deal with this mass information, a large-scale apparatus made to recognize\
    \ designs in the disorder of this blast in data to configuration keen arrangements.\
    \ It is now used in fields as diverse as medicine, farming, gambling, and environmental\
    \ insurance. In [5], the author has stated the use of 'Big Data' upon psychological\
    \ science. The author also stated an example relating it to the daily crime statistics\
    \ to the environmental state. Data sets exist that consider detailed investigations\
    \ of the impacts of conventional mental ward factors like lack of sleep, cold,\
    \ and abundance levels on wonders identified with everything from working memory\
    \ to hazard perspectives — and at just remarkable scales.\n\nIn 1956, a small\
    \ group of experts from diverse areas, including mathematics, psychology, engineering,\
    \ economics, and political science, founded the subject of artificial intelligence\
    \ study. They started talking about creating an artificial brain. Neurological\
    \ studies have recently revealed that the brain is an electrical network of neurons\
    \ that fire in all or nothing pulses. Artificial intelligence systems prefer to\
    \ make choices based on realtime data. The objective of artificial intelligence\
    \ is to give programming that can reason and include and clarify output. Artificial\
    \ intelligence helps in furnishing humanlike connections with programming and\
    \ proposition choice help for explicit undertakings, but it's not a replacement\
    \ for the human mind and behavior and will not be at any point shortly. Forms\
    \ of Artificial Intelligence are classified into four parts, such as reactive\
    \ machines, limited memory, theory of mind, and self-awareness. In [6], the authors\
    \ state that the need for artificial intelligence towards the lifestyle of human\
    \ beings. In contemporary times, Artificial Intelligence has utilized its methods\
    \ to create systems that can act, think, and learn just like human beings. It\
    \ is stated that artificial intelligence is an integral part of our existence.\
    \ For example, starting from our phone, whenever anyone searches for any music\
    \ videos on any music streaming platform, the system, which is specialized in\
    \ those Artificial Intelligence methodologies, recommends other music videos related\
    \ to that person's preferences. So, using artificial intelligence, a machine can\
    \ perform the same task as the human thought process.\n\n Mainly, artificial intelligence\
    \ is very much related to human psychology. It mainly focuses on human neurological\
    \ functions. A new form of psychology that was established in the late 19th century\
    \ is known as \"Artificial Psychology\" [7] and it is with the recent utilization\
    \ of Artificial Intelligence. In [8,9], the authors have analyzed human psychology\
    \ methods with the help of information science research methods and artificial\
    \ intelligence to investigate more deeply human mind philosophy. In 1963, Dan\
    \ Curtis considered artificial intelligence, which approaches the level of complex\
    \ analyzed intelligence is measured based on two conditions:\n\n## **The first\
    \ condition is:**\n\n- Makes all of the decisions independently.\n- Makes any\
    \ decision based on data that is new, abstract, or incomplete.\n- Capable of reprogramming\
    \ the new data.\n- It is capable of solving its programming disputes, even if\
    \ the data is incomplete.\n\n# **Condition II:**\n\n All the criteria are not\
    \ in line with the original operating system.\n\n![](_page_3_Picture_14.jpeg)\n\
    \nSource: \"Implementing Artificial Intelligence\" (2021) Figure 2: The interconnection\
    \ of Artificial Intelligence with the human touch.\n\nNow, the facts about how\
    \ machine learning is helpful in the field of psychology. Machine learning is\
    \ nothing but a sub-field of artificial intelligence through which it entertains\
    \ any system or device which can learn from data, identify patterns, and make\
    \ decisions with minimal human intervention. In [10], the authors have shown the\
    \ possibilities of some prediction of Internet addiction based on a set of predictor\
    \ variables. The indicator variable set was chosen with the end goal of ensuring\
    \ that there exists a solid connection between the boundaries considered to have\
    \ an impact on tricky Internet utilization.\n\nBipolar disorder is a mental illness\
    \ with lots of mood swings and emotional highs and lows. Whenever any person becomes\
    \ depressed, he or she faces instant mood highs and lows and loses interest in\
    \ any activities. The authors of [11] used a random Forest Algorithm with Magnetic\
    \ Resonance Imaging (MRI) data to detect this disorder. The author had also shown\
    \ that CNN-MDRP (Multimodal Disease Risk Prediction) had higher accuracy in predicting\
    \ than other algorithms using machine learning for Bipolar Disorder detection.\n\
    \n Web-based intellectual conduct treatment has shown positive outcomes for an\
    \ assortment of mental problems, including misery, uneasiness, and post-awful\
    \ pressure issues (PTSD). There is a blast of web-related psychotherapeutic treatment.\
    \ Quite a bit of this is gotten to through sites and applications. Although some\
    \ applications are just conductors to teletherapy administrations, many are crossovers\
    \ that offer education, self-improvement, and online help on a case-by-case basis.\
    \ Most web-based treatments utilize intellectual conduct standards.\n\nSeveral\
    \ apps in today's technology world are available to help people with their mental\
    \ disorders, behavioral changes, and many more. Some surveys have been conducted\
    \ on a daily or monthly basis to detect the changes in human behavior, to detect\
    \ their stress and depression with percentages. For example, an application named\
    \ \"Code Blue\" was created to help teenagers suffering from depression and bullying\
    \ with support whenever they need it. As the commonness of psychological instabilities\
    \ like depression and anxiety keeps on developing, clinicians have gone to versatile\
    \ applications as instruments for helping their patients' treatment. These applications\
    \ can be particularly useful for teens and youthful grown-ups experiencing psychological\
    \ instability because of their incessant utilization of innovation as a method\
    \ for correspondence.\n\n[From an internet source of the \"Top 10 Mental Apps\"\
    ]\n\n Also, in 2018, Melina Uncapher of the University of California stated in\
    \ a report \"Technology meets Neuroscience\" that it's not possible to bring an\
    \ MRI scanner to every classroom, but they have turned it into a mobile technology\
    \ so that everyone can access it. The Neuroscape Center at UCSF has created 'ACE',\
    \ a tabletbased intellectual evaluation, which has permitted Uncapher and her\
    \ partners to concentrate on leader work inside a gathering of more than 1,000\
    \ rudimentary and center school understudies across nine diverse Bay Area schools.\
    \ These tweaked Neuroscape computer games utilize versatile calculations to change\
    \ the degree of game trouble, permitting analysts to utilize similar precise intellectual\
    \ assignments for offspring of any age across tests, and across time. Fundamentally,\
    \ this permits highaccuracy, high-dimensional estimation of insight across improvement.\n\
    \nIn this modern era of technology, the relationship between machines and humans\
    \ is very diverse and emergent in all fields. The authors of [12] have reviewed\
    \ the effects of technology on humans. The authors claimed that the situational\
    \ changing of human behavior affected most of the interactions between machines\
    \ and humans. The authors showed that the branch of Engineering Psychology helped\
    \ to improve the relationship between humans and machines by interacting with\
    \ each other. The authors also reviewed the existing research in the field of\
    \ Engineering Psychology.\n\nThe authors of [13] developed a mobile application\
    \ that can analyze mental illnesses based on lifestyle and psychometric data from\
    \ people of all ages. The authors also proposed an ideology on how Artificial\
    \ Neural Networks (ANN) can be applied to the dataset to analyze and detect the\
    \ type of mental disorder it contains.\n\nIn [14], the author has utilized a dataset\
    \ comprised of substance abuse patients from the United States and the Convolutional\
    \ Neural Organization characterization comprised of opioid addicts to get the\
    \ precision of the psychological issue forecast framework. The author has also\
    \ proposed a new method for detecting mental disorders using data mining.\n\n\
    Another field that has recently attracted the attention of the contemporary field\
    \ is \"Nanotechnology\". \"Nanotechnology\" is the study of matter at the nanoscale,\
    \ with dimensions ranging from 1 to 100 nanometers. Nanotechnology involves imaging,\
    \ measuring, and modeling. Nanotechnology encompasses disciplines such as physics,\
    \ biology, chemistry, and nanometer-scale technology. In psychiatry, nanotechnology\
    \ has a wide range of uses. Pharmacology, living analysis, and central nervous\
    \ system modeling are the three most common applications. If properly used, nanotechnology\
    \ and quantum physics can be used to create artificial intelligence and mental\
    \ disease models [15]. Psychology is linked with several areas, or we might say\
    \ that it incorporates every significant technological advancement [16]. The National\
    \ Science Foundation has invested heavily in building a foundation on which nanotechnologies\
    \ can be further developed. The National Institutes of Health, on the other hand,\
    \ is putting in a lot of effort because of the potential for medical applications.\
    \ The National Nanotechnology Initiative, on the other hand, involves more than\
    \ a dozen agencies. With the advancement of nanotechnology, psychologists interested\
    \ in the dissemination of innovation, decision-making, and social impact should\
    \ dive right in. Certain psychological groups have identified nanotechnology as\
    \ a powerful tool for addressing challenges related to human cognition, perception,\
    \ emotion, and activity. Day by day, new technologies emerge, which will ultimately\
    \ aid the study of psychology. Psychophysiological recording, for example, accurately\
    \ supplies visual and auditory stimuli as well as response time assessment.\n\n\
    #### **V. CONCLUSION**\n\nThe exploration of this article is an entry through\
    \ which the greatness of technology can be moved forward through its innovations\
    \ in the field of psychology. Starting from the usage of smartphones, applications,\
    \ websites to the concept of using technology for medical as well as mental illness\
    \ treatments of human minds, technology has created a greater impact and it is\
    \ also progressing daily through several innovations and research. Different methodological\
    \ innovations provide scientists with fresh ways to deal with the mysteries of\
    \ human minds in research labs everywhere on the planet. These days, various medications\
    \ are being given to patients with the assistance of mechanical development or\
    \ progression. As a whole, we are welcoming this immense innovation for the growth\
    \ of the field of psychology in several spheres every day. It has prompted advancement\
    \ in treatment, education, estimation, and exploration. Technology, as a rule,\
    \ gives a more advantageous and less expensive elective when utilized for assessment\
    \ and treatment purposes. Perhaps most importantly, it has enabled more people\
    \ to acquire data and access emotional wellness administrations. The major goal\
    \ is to develop new technologies that will help psychologists work more correctly\
    \ and efficiently in the future.\n\n#### **ACKNOWLEDGMENT**\n\nWe would like to\
    \ thank all of our professors and our prestigious institutions for providing us\
    \ with the information we needed to conduct the research.\n\n#### **REFERENCES**\n\
    \n- [1] Wikipedia on *\"Engineering Psychology\"*.\n- [2] Mandler, G., \"*A history\
    \ of modern experimental psychology: From James and Wundt to cognitive science*.\"\
    \ **Cambridge**, MA: MIT Press, **2007**.\n- [3] Annual Report of the APA Policy\
    \ and Planning Board on *\"How Technology Changes Everything (Or Nothing) in Psychology\"\
    ,*  **2008**.\n- [4] *\"Mind Reading as Cultural Practice\",* International Conference\
    \ to be held at the Institute for Cultural Theory and History, Humboldt University\
    \ Berlin, **Germany**, **22-23 March 2018**, Laurens Schlicht and Christian Fassung\
    \ (Humboldt University Berlin, Germany), Simone Natale (Loughborough University,\
    \ UK).\n- [5] *\"Technology, Psychology, and a Coming Revolution in the Study\
    \ of Decision Making\",* Paul W. Glimcher, **2014**.\n- [6] \"*Artificial psychology:\
    \ an attainable scientific research on the human brain*\", (**1999**), Proceedings\
    \ of the Second International Conference on Intelligent Processing and Manufacturing\
    \ of Materials. IPMM'99 (Cat. No.99EX296), Intelligent Processing and Manufacturing\
    \ of Materials, **1999**. IPMM '**99**. Proceedings of the Second International\
    \ Conference On, **1067**.\n- [7] Wikipedia on *\"Artificial Psychology\".*\n\
    - [8] Wang*, Zhiliang, Smith, Michael J.; Salvendy, Gavriel (eds.). \"Artificial\
    \ Psychology\". Human Interface and the Management of Information. Methods, Techniques,\
    \ and Tools in Information Design.\",* Lecture Notes in Computer Science. Springer\
    \ Berlin Heidelberg**. 4557**: **208–217**, **2007**.\n- [9] *Zhiliang Wang; Lun\
    \ Xie \"Artificial psychology: an attainable scientific research on the human\
    \ brain\",* Proceedings of the Second International Conference on Intelligent\
    \ Processing and Manufacturing of Materials, IPMM'99 (Cat. No.99EX296). **2**:\
    \ **1067–1072** vol.**2**, **July 1999.**\n- [10] Suma S.N., Nataraja P., Sharma\
    \ M.K *\"Internet Addiction Predictor: Applying Machine Learning in Psychology\"\
    .* In: Chiplunkar N., Fukao T. (eds) Advances in Artificial Intelligence and Data\
    \ Engineering. Advances in Intelligent Systems and Computing, vol. **1133**. Springer,\
    \ **Singapore**, **2021**.\n- [11] *\"Detection of bipolar disorder using machine\
    \ learning with MRI\"*, Sudha Radha, **2021** International Semantic Intelligence\
    \ Conference: At **New Delhi**, **2021**.\n- [12] Grether, F, *\"Engineering psychology\
    \ in the United States\",* American Psychologist. **23 (10)**: **743–751**, **1962**.\n\
    - [13] *\"Prediction of Mental Disorder using Artificial Neural Network and Psychometric\
    \ Analysis\",* D.D. Sapkal, Chintan Mehta,\n\nMohit Nimgaonkar, Rohan Devasthale,\
    \ Shreyas Phansalkar, Chapter: Data Management, Analytics, and Innovation, **2020**.\n\
    \n- [14] *\"Predicting Mental Disorders Using Convolutional Neural Networks Classifier\"\
    ,* Karim Hashim Kraidi Al- Saedi, Journal of Physics Conference Series, **2021**.\n\
    - [15] G. Fond et.al Eur Neuropsychopharmacol: *\"Nanopsychiatry – the potential\
    \ role of nanotechnologies in the future of psychiatry: a systematic review\"\
    ,* National Library of Medicine, National Center of Biotechnology Information,\
    \ **2013**.\n- [16] Steven Breckler, \"*Small Science is big*\", Psychological\
    \ Science Agenda, **2008**, APA.\n\n#### **AUTHORS PROFILE**\n\n**Soham Bhattacharya**\
    \ received the degree of Masters of Technology from Heritage Institute of Technology,\
    \ Kolkata in 2020. Before that, he had done a Bachelor of Technology in Electronics\
    \ and Communication Engineering from the same institution. At present, he is currently\
    \ looking for a doctoral position in the field of\n\n![](_page_5_Picture_26.jpeg)\n\
    \nElectrical and Computer Engineering. He has published many international and\
    \ national articles in the field of VLSI and Electronics and Communication Engineering.\
    \ He had been awarded as 'Young Researcher' by the Institute of Scholars. His\
    \ fields of research interest include VLSI, Reversible Computing, Embedded systems,\
    \ Artificial Intelligence, Electronics, and Communication Engineering.\n\n**Srija\
    \ Samaddar** is currently pursuing a Bachelor of Arts in Psychology from Bagbazar\
    \ Women's College, Kolkata under the affiliation of Calcutta University. Her fields\
    \ of research interest include counseling psychology, clinical psychology. She\
    \ did internships on Basic Counseling skills,\n\n![](_page_5_Picture_29.jpeg)\n\
    \nClinical Psychology, Fashion Psychology, which was organized by Fortis Mental\
    \ Healthcare services.\n\n**Anwesha Banerjee** is currently pursuing a Bachelor\
    \ of Technology from Techno India University, Kolkata. Her fields of research\
    \ interest include Digital Circuits, VLSI, Artificial Intelligence, and Big Data.\n\
    \n![](_page_5_Picture_32.jpeg)"
  decisions:
    evaluation_prompt: 'Disqualified: no evaluation. Reason: The paper lacks any form
      of empirical, experimental, or quantitative evaluation. It primarily consists
      of a review and discussion of existing literature and concepts without presenting
      any structured or reproducible testing, benchmarks, metrics, or performance
      measurements.'
    related_work_prompt: '- Qualified. Reason: The paper meaningfully engages with
      prior research throughout its sections, including the Introduction, Related
      Work, and In-Depth Discussion. It includes numerous citations and discussions
      of previous studies, theories, and methodologies, comparing them to the current
      work.'
    novelty_prompt: 'Disqualified: no novelty. Reason: The paper is a comprehensive
      review of existing literature on the influence of technology on psychology but
      does not propose any new methods, algorithms, applications, or insights. It
      summarizes existing knowledge and applications without making any clear claims
      of novel contributions or applying known techniques in a novel context.'
    review_only_prompt: 'Disqualified: review paper. Reason: The title contains the
      word "review," and the main body primarily summarizes existing work without
      introducing new methods, datasets, experiments, or frameworks.'
- title: Use of large language model (LLM) to enhance content and structure of a school
    of dentistry LibGuide Emily P. Jones
  abstract: ''
  keywords: ''
  document: '96


    # Use of large language model (LLM) to enhance content and structure of a school
    of dentistry LibGuide Emily P. Jones


    *See end of article for authors'' affiliations.*


    A librarian used a large language model (LLM) to revise a dentistry subject LibGuide.
    Prompts were used to identify methods for optimizing navigational structure for
    usability, highlight library-specific information students need additional help
    with, and write summaries of page content. Post-revision, LibGuide access increased,
    and students provided anecdotal feedback that they perceive the changes positively.
    LLMs may enhance LibGuide discoverability and usability without adding significant
    time and resource burdens for librarians.


    Keywords: Generative AI; Artificial Intelligence (AI); LibGuides; Large Language
    Models


    Virtual Projects are published on an annual basis in the *Journal of the Medical
    Library Association* (*JMLA*) following an annual call for virtual projects in
    *MLAConnect* and announcements to encourage submissions from all types of libraries.
    An advisory committee of recognized technology experts selects project entries
    based on their currency, innovation, and contribution to health sciences librarianship.


    # BACKGROUND


    Large language models (LLMs) lik[e Chat-GPT](https://chatgpt.com/) [\[1\]](https://sciwheel.com/work/citation?ids=16941172&pre=&suf=&sa=0&dbf=0)
    and [Claude.ai](https://claude.ai/) [\[2\]](https://sciwheel.com/work/citation?ids=16941177&pre=&suf=&sa=0&dbf=0)
    are useful tools for summarizing, predicting, and generating text. These tools
    have potential to increase productivity and decrease the time burden of common,
    text-based tasks for librarians like LibGuide content creation.


    ## VIRTUAL PROJECT DESCRIPTION


    In June 2024, a librarian used an LLM, Claude.ai, to facilitate a major redesign
    of a [dentistry LibGuide.](https://guides.lib.unc.edu/dentistry) Through a series
    of prompts, the librarian consulted the LLM to generate introductions summarizing
    content of specific pages and to restructure the LibGuide, formerly organized
    by resource format. Screenshots of the LibGuide pre- and post-revision, as well
    as examples of prompts provided to, and responses received from, Claude.ai are
    accessibl[e via the author''s institutional repository.](https://cdr.lib.unc.edu/concern/scholarly_works/g445ct56k)


    There was a 131% increase in LibGuide access from June - September 2024 (n = 2,288)
    compared to the same period the year before (n = 989). To the author''s knowledge,
    no other changes were made that would significantly impact usage like new outreach
    or instruction. In addition to the increase in usage statistics, students have
    provided anecdotal feedback that they perceive the LibGuide to be more user-friendly
    and useful after the revision.


    # DISCUSSION


    LLMs are cost-effective, as most are free, low-cost, or institutionally provided,
    and time-saving. Large amounts of text can be generated in a matter of seconds,
    whereas comparable output by a librarian may take hours. Additionally, LLMs can
    be used across various aspects of medical librarianship across any discipline
    and can be used to generate or clarify text about complex research topics like
    systematic reviews and data management.


    While there are advantages to using LLMs like increasing efficiency and productivity,
    there are challenges as well. Concerns have been raised about accuracy of responses,
    privacy, and algorithm bias [\[3\].](https://sciwheel.com/work/citation?ids=15520745&pre=&suf=&sa=0&dbf=0)
    While LLMs are skilled at text-based tasks, they may not be able to adequately
    produce responses that require nuance, context, or complexity of thought. Therefore,
    it is best practice to review LLM responses for clarity and accuracy before using
    them. Additionally, LLM responses are highly dependent upon prompts received.
    Responses also change each time they''re provided, even if the same prompt is
    provided, whether by the same or different individuals.


    ### CONCLUSION


    This project demonstrates a practical example of how librarians can apply generative
    artificial intelligence (AI) technologies to routine tasks like LibGuide revision
    and content creation. Using LLMs to develop page


    DOI: dx.doi.org/10.5195/jmla.2025.2084


    introductions and to reorganize content resulted in a usage increase. While not
    causative, while not causative, this increase may be correlated to increased discoverability
    and usability from using generative AI developed text and suggestions. LLMs can
    enhance the instructional component of LibGuides without adding a significant
    time burden for the creator.


    #### REFERENCES


    - 1. OpenAI. ChatGPT-4 [Internet]. 2024 [cited 2024 Sep 18]. Available from[:
    https://chatgpt.com/.](https://chatgpt.com/)

    - 2. Anthropic. Claude 3.5 Sonnet [Internet]. 2024 [cited 2024 Sep 18]. Available
    from[: https://claude.ai/new.](https://claude.ai/new)

    - 3. Meyer JG, Urbanowicz RJ, Martin PCN, O''Connor K, Li R, Peng P-C, Bright
    TJ, Tatonetti N, Won KJ, Gonzalez-Hernandez G, Moore JH. ChatGPT and large language
    models in academia: opportunities and challenges. BioData Min. 2023 Jul 13;16(1):20.


    #### AUTHORS'' AFFILIATIONS


    Emily P. Jones[, epjones3@email.unc.edu,](mailto:epjones3@email.unc.edu) [https://orcid.org/0000-](https://orcid.org/0000-0002-4294-7564)
    [0002-4294-7564,](https://orcid.org/0000-0002-4294-7564) University of North Carolina
    at Chapel Hill (UNC) Health Sciences Library, Chapel Hill, NC


    *Received October 2024; accepted October 2024*


    ![](_page_1_Picture_10.jpeg)


    Articles in this journal are licensed under [a Creative](https://creativecommons.org/licenses/by/4.0/)
    [Commons Attribution 4.0 International License.](https://creativecommons.org/licenses/by/4.0/)


    ![](_page_1_Picture_12.jpeg)


    This journal is published by th[e University Library System](http://www.library.pitt.edu/)
    of the [University of Pittsburgh](http://www.pitt.edu/) as part of it[s D-Scribe](http://www.library.pitt.edu/d-scribe-digital-collections)  [Digital
    Publishing Program](http://www.library.pitt.edu/d-scribe-digital-collections)
    and is cosponsored by the [University of Pittsburgh Press.](http://upress.pitt.edu/)


    ISSN 1558-9439 (Online)


    ![](_page_1_Picture_18.jpeg)'
  decisions:
    evaluation_prompt: '- Qualified. Reason: The paper provides empirical evidence
      of evaluation through the reported 131% increase in LibGuide access post-revision,
      compared to the same period the previous year. This is a quantifiable outcome
      indicating structured evaluation of the method''s impact.'
    related_work_prompt: 'Disqualified: no related work. Reason: The paper does not
      meaningfully engage with prior research. It contains few academic citations,
      and the references included are primarily to tools (ChatGPT and Claude) without
      context or discussion of previous academic work. There is no explanation or
      comparison of the method to previous work, and it lacks a discussion of prior
      research entirely.'
    novelty_prompt: '- Qualified. Reason: The paper demonstrates novelty by applying
      a known technique, the use of large language models (LLMs), in a novel context—specifically,
      the enhancement of a dentistry LibGuide. The paper also claims a contribution
      by showing a significant increase in LibGuide access post-revision, suggesting
      improved usability and discoverability due to the application of LLMs.'
    review_only_prompt: 'Qualified. Reason: The paper describes a practical application
      of large language models (LLMs) to enhance a dentistry LibGuide, resulting in
      increased access and positive feedback. It includes novel contributions such
      as the use of LLMs for restructuring and summarizing content, and presents original
      data on the impact of these changes.'
- title: A Survey on Effective Invocation Methods of Massive LLM Services
  abstract: Language models as a service (LMaaS) enable users to accomplish tasks
    without requiring specialized knowledge, simply by paying a service provider.
    However, numerous providers offer massive large language model (LLM) services
    with variations in latency, performance, and pricing. Consequently, constructing
    the cost-saving LLM services invocation strategy with low-latency and high-performance
    responses that meet specific task demands becomes a pressing challenge. This paper
    provides a comprehensive overview of the LLM services invocation methods. Technically,
    we give a formal definition of the problem of constructing effective invocation
    strategy in LMaaS and present the LLM services invocation framework. The framework
    classifies existing methods into four different components, including input abstract,
    semantic cache, solution design, and output enhancement, which can be freely combined
    with each other. Finally, we emphasize the open challenges that have not yet been
    well addressed in this task and shed light on future research.
  keywords: ''
  document: '# A Survey on Effective Invocation Methods of Massive LLM Services


    Can Wang<sup>1</sup> , Bolin Zhang<sup>1</sup> , Dianbo Sui<sup>1</sup> , Zhiying
    Tu<sup>1</sup> <sup>∗</sup> , Xiaoyu Liu <sup>1</sup> , Jiabao Kang <sup>1</sup>
    ,


    <sup>1</sup>Harbin Institute of Technology,


    23B903072@stu.hit.edu.cn, {brolin, tzy hit,suidianbo}@hit.edu.cn, 2201110719@stu.hit.edu.cn,
    18538796936@163.com


    ### Abstract


    Language models as a service (LMaaS) enable users to accomplish tasks without
    requiring specialized knowledge, simply by paying a service provider. However,
    numerous providers offer massive large language model (LLM) services with variations
    in latency, performance, and pricing. Consequently, constructing the cost-saving
    LLM services invocation strategy with low-latency and high-performance responses
    that meet specific task demands becomes a pressing challenge. This paper provides
    a comprehensive overview of the LLM services invocation methods. Technically,
    we give a formal definition of the problem of constructing effective invocation
    strategy in LMaaS and present the LLM services invocation framework. The framework
    classifies existing methods into four different components, including input abstract,
    semantic cache, solution design, and output enhancement, which can be freely combined
    with each other. Finally, we emphasize the open challenges that have not yet been
    well addressed in this task and shed light on future research.


    ### 1 Introduction


    Large Language Models (LLM) are becoming a fundamental tool for various natural
    language processing tasks [\[Yang](#page-8-0) *et al.*, [2023\]](#page-8-0), as
    they have shown amazing emergent abilities, like in-context learning, multi-step
    reasoning, instruction following and tool learning. Due to commercial reasons,
    the potential risk of misuse and expensive tuning cost, LLMs, such as GPT-3, GPT-4
    and Claude, are usually released as LLM services through application programming
    interface (API) instead of open sourcing model weights [Yu *et al.*[, 2023\]](#page-8-1),
    which is called Language Models as a Service (LMaaS).


    Via accessing these powerful LLMs as services through their opened API, novice
    users do not need to possess extensive computational resources and expertise in
    deep learning, as they can solve the tasks of interest by crafting task-specific
    input query. However, invoking LLM services is not free and using them for high-throughput
    applications can be very expensive. Estimated by Claudia Slowik, a business supporting
    15,000 customer interactions with text-davinci-003 could have a monthly cost exceeding
    \$14,400.


    <span id="page-0-0"></span>


    | Provider  | LLM                  | Input Cost | Output Cost |

    |-----------|----------------------|------------|-------------|

    | OpenAI    | gpt-4                | \$30.0     | \$60.0      |

    |           | gpt-4-turbo          | \$10.0     | \$30.0      |

    |           | gpt-3.5-turbo-1106   | \$1.00     | \$2.00      |

    | Anthropic | Claude-2.0           | \$11.02    | \$32.68     |

    |           | Claude-instant-1.2   | \$1.63     | \$5.51      |

    | AI21      | Jurassic-2 Ultra     | \$15.0     | \$15.0      |

    |           | Jurassic-2 Mid       | \$10.0     | \$10.0      |

    |           | Jurassic-2 Light     | \$3.00     | \$3.00      |

    | Textsynth | M2M100 1.2B          | \$0.15     | \$3.00      |

    |           | GPT-J 6B             | \$0.20     | \$5.00      |

    |           | Falcon 7B            | \$0.20     | \$5.00      |

    |           | Mistral 7B           | \$0.20     | \$2.00      |

    |           | Llama2 7B            | \$0.20     | \$2.00      |

    |           | Flan-T5-XXL          | \$0.20     | \$5.00      |

    |           | Falcon 40B           | \$3.30     | \$10.00     |

    | Cohere    | command              | \$1.00     | \$2.00      |

    |           | command-light        | \$0.30     | \$0.60      |

    | Baidu     | Llama-2-13B-Chat     | ¥6.00      | ¥6.00       |

    |           | Llama-2-70B-Chat     | ¥35.0      | ¥35.0       |

    |           | ERNIE-Bot 4.0        | ¥150       | ¥300        |

    |           | ChatGLM2-6B-32K      | ¥4.00      | ¥4.00       |

    |           | Llama-2-7B-Chat      | ¥4.00      | ¥4.00       |

    |           | ERNIE-Bot            | ¥12.0      | ¥12.0       |

    |           | BLOOMZ-7B            | ¥4.00      | ¥4.00       |

    |           | ERNIE-Bot-turbo-0922 | ¥8.00      | ¥12.0       |


    Table 1: Price list of different LMaaS. The cost is priced per 1 million tokens.
    Note that Baidu''s LLM services are priced in Chinese Yuan (), while other LLM
    services are priced in US Dollars (\$). The data updated to 24 January 2024.


    Typically, the cost of invoking LLM services consists of two components: (1) input
    cost (proportional to the length of the input prompt), (2) output cost (proportional
    to the length of the generated sequence). In Table [1,](#page-0-0) we present
    the cost associated with using 25 different LLM services from some top-tier providers,
    like OpenAI, Anthropic, AI21 and Textsynth. From the table, we could find that
    the costs of different LLM services can vary by up to two orders of magnitude:
    the input cost for 1 million tokens is \$10 for OpenAI''s GPT-4 but only \$0.2
    for Mistral 7B hosted by Textsyth.


    In addition to cost considerations, various factors, including performance for
    the same input query and response time, can also impact the user experience in
    the usage of LLM services. [Ahia *et al.*[, 2023;](#page-7-0) Lai *et al.*[, 2023\]](#page-7-1)
    find that different languages, prompt methods or the inclusion of simple


    <sup>∗</sup>Corresponding author.


    <span id="page-1-0"></span>![](_page_1_Figure_0.jpeg)


    Figure 1: Vision of efficient invocation strategy construction for massive LLM
    services.


    enhancements can also lead to notable alterations in performance. Meanwhile, [Chen
    *et al.*[, 2023\]](#page-7-2) discovers that affordable LLMs often complement
    expensive ones. For example, on the CoQA [\[Reddy](#page-8-2) *et al.*, 2019]
    dataset, GPT-4 makes a mistake about 11% of the questions, where cheaper and smaller
    GPJ-J can give right answers.


    Considering the heterogeneity in pricing does not necessarily correlate with the
    user experience, it is a great need to explore effective invocation methods for
    LLM services in practice. As shown in Figure [1,](#page-1-0) we expect to make
    use of massive LLM services to construct an effective invocation strategy according
    to different methods, meeting targets in different scenarios. To this end, we
    attempts to provide a comprehensive study of the development and recent advances
    on effective invocation methods in LMaaS. In detail, We first formalizes the task
    of constructing effective invocation strategy as a multiobjective optimization
    problem. This entails simultaneous consideration of latency, performance, and
    cost factors. Then, we propose a taxonomy to provide a unified view on effective
    invocation methods in LMaaS where the existing methods are categorized into: input
    abstract, semantic cache, solution design, and output enhancement. These four
    components can be flexibly combined and unified in a flexible framework. Finally,
    we highlight the challenges and potential directions and hope our work can provide
    a useful roadmap for beginners interested in this area and shed light on future
    research.


    The contributions of this survey can be concluded as follows:


    - Comprehensive Taxonomy. As shown in Figure [2,](#page-2-0) a taxonomy of effective
    invocation methods in LMaaS is proposed, which categorizes existing methods from
    four different aspects: input abstract, semantic cache, solution design and output
    enhancement.

    - Flexible Framework. As shown in Figure [3,](#page-3-0) the framework can unify
    the four type components, allowing each of them to work independently or simultaneously,
    during the life cycle of the LLM service invocation.

    - Related Resources. To facilities the methods of this task, the price rules of
    popular LMaaS products is present in Table. [1](#page-0-0) and the paper list
    of existing works is available. [1](#page-1-1)


    The rest of the survey is organized as follows. Section [2](#page-1-2) describes
    the task definition of constructing effective invocation strategy for LMaaS and
    outlines the unified LLM services invocation framework. Section [3](#page-2-1)
    reviews the input abstract component, Section [4](#page-4-0) reviews the semantic
    cache component, Section [5](#page-5-0) reviews the solution design component
    and Section [6](#page-6-0) reviews the output enhancement component. Section [7](#page-6-1)
    emphasize the open challenges and future direction of this task and summarizes
    the paper.


    ### <span id="page-1-2"></span>2 Background


    #### 2.1 Task Definition


    In our topic, the problem is defined as how to construct an effective (low-latency,
    high-performance, and costsaving) invocation strategy s given a task T among massive
    LLM services LLMs. The given task T consists of multiple identical query-answer
    pairs, represented as T = {(q1, a1),(q2, a2), ...(qn, an)}, where q represents
    input query and a represents output answer. Let, considering a fixed LLM, a LLM
    service published through API. Input a query q, by invocation the service, the
    process of getting the response a˜ can be represented as:


    $$

    \tilde{a} = LLM(q) \tag{1}

    $$


    To characterize the concerns for the construction of effective invocation strategy
    with a given query q and LLM service LLM, we use three functions: latency fl(LLM,
    q), performance fp(LLM, q), and cost fc(LLM, q). These three functions are fixed
    values in a specific practical invocation and can be estimated using certain methods.
    For example, f<sup>l</sup> might be a function of the length of the input and
    output tokens. f<sup>p</sup> often uses a metric function r(,) to compare the
    difference between a and a˜. While f<sup>c</sup> involves two different pricing
    components we mentioned before. We adopt the definition of the sum of the number
    of input tokens multiplied by the price of input tokens and the number of generated
    tokens multiplied by the price of generated tokens, as shown in the Eq. [2,](#page-1-3)
    where α<sup>i</sup> is a constant representing the unit price.


    <span id="page-1-3"></span>

    $$f\_c \triangleq \alpha\_1 ||\tilde{a}|| + \alpha\_2 ||q|| + \alpha\_3 \tag{2}$$


    Then we extend a single LLM service to K different LLM services, LLM<sup>s</sup>
    = {LLM1, LLM2, ...LLMK}. Our problem is formalized as Eq. [3,](#page-1-4) where
    in the search space S, we seek the optimal invocation strategy s that minimizes
    latency f<sup>l</sup> , maximizes performance fp, and minimizes cost f<sup>c</sup>
    on task T. The best strategy s includes a sequence of selected LLM services, represented
    as s = {LLM1, LLM<sup>i</sup> , ..., LLMk}, k ≤ K, which is highly flexible, such
    as choosing a single service or accessing some in a specific order.


    <span id="page-1-4"></span>

    $$\min \sum\_{LLM\_i \in s, q\_j \in T} F(f\_l(LLM\_i, q\_j), -f\_p(LLM\_i, q\_j),
    f\_c(LLM\_i, q\_j)) \tag{3}$$


    This is a multi-objective optimization problem, and here, we combine them in a
    simplified form using the function F. In the construction strategy of a specific
    invocation, weighted averages may be used, or constraints may be introduced, treating
    certain targets as conditions while optimizing others. For example, in the scenario
    of limited funds, the cost f<sup>c</sup> is used as a condition to obtain a invocation
    strategy with highperformance f<sup>p</sup> and low-latency f<sup>l</sup> .


    <span id="page-1-1"></span><sup>1</sup> <https://github.com/W-caner/Effective-strategy-for-LMaas>


    <span id="page-2-0"></span>![](_page_2_Figure_0.jpeg)


    Figure 2: Taxonomy of effective invocation methods of LMaaS


    #### 2.2 LLM Services Invocation Framework


    Similarly, we focus solely on the methods related to LLM services invocation and
    do not consider others related to the internal details of LLM. According to the
    different construction ways, the methods are summarized into four categories,
    as shown in Figure [2.](#page-2-0)


    Using the taxonomy, we proposed the effective LLM services invocation framework
    illustrated in Figure [3,](#page-3-0) where different categories represented in
    the form of components that can work independently or simultaneously. Following
    the idea that building an effective invocation strategy requires an understanding
    of the key resources involved in the LLM service life cycle [Bai *et al.*[, 2024\]](#page-7-17),
    we divide the LLM services invocation into three phases : before invocation, invocation
    and after invocation.


    Before invocation, the user enters a query q, and we consider that in general,
    q consists of a question and multiple possible prompts. Where the question represents
    the user''s goal, and the prompts are optional information to help accomplish
    the goal.


    The processing of the input query q to express more meaningful information in
    a more concise language is the first step to construct an effective invocation
    strategy. The methods in this aspect are summarized as input abstract (Section
    [3\)](#page-2-1), which is divided into sentence simplification and prompt optimization
    according to the different ways. The former reduce the latency f<sup>l</sup> and
    cost f<sup>c</sup> by simplifying the query without changing its semantics. The
    latter is used to improve the prompts for better performance fp.


    Semantic cache (Section [4\)](#page-4-0) is also an important strategy to improve
    service performance, reduce latency and cost before invocation, which is divided
    into traditional cache and neural cache according to different structures. It
    checks whether there is a semantically similar query in the cache, if so, it directly
    returns, otherwise it goes into the invocation phase.


    Solution design (Section [5\)](#page-5-0) aims to construct the best invocation
    solution s by leveraging the complementary capabilities of massive LLM services.
    It evaluates LLM services LLM<sup>i</sup> with a given query q, and the method
    of evaluation is called scoring function. It is often done before the invocation,
    such as an estimate of f<sup>c</sup> can be used to guide the design of a lowcost
    solution. And in the invocation phase, the scoring function is used to guide the
    organized routing between services, which is called LLM router. Through different
    routing structures, the advantages of different services are utilized to build
    a satisfactory solution for users.


    After invocation, output enhancement (Section [6\)](#page-6-0) focuses on the
    information returned to the user. The output a˜ is adjusted to suit different
    targets and returned in a suitable form. In addition, the input and output of
    this invocation are stored into the semantic cache for future invocations.


    ## <span id="page-2-1"></span>3 Input Abstract


    Input abstract is designed to reduce the length of the input query without changing
    the semantics, while optimizing the prompt for better performance at lower cost
    and latency to invoke a given LLM.


    <span id="page-3-0"></span>![](_page_3_Figure_0.jpeg)


    Figure 3: LLM services invocation framework, shown by the phase of invocation.


    The generalization and in-context capabilities allow LLM services to get good
    answers on untrained samples[\[Dong](#page-7-18) *et al.*, [2023\]](#page-7-18).
    Thus, a variety of different natural language tasks can be accomplished just by
    inputting different queries. This also leads to the LLM service''s dependence
    on input when invoked. After the service is selected, the input content and quality
    directly affect the latency, price and performance of the service. For example,
    concatenating the prompt "just tell me the option, do not explain other things"
    with the question as input to the LLM will generate shorter output, reducing invocation
    cost and latency. However, it may at the same time cause the LLM to lose its ability
    to think step by step, resulting in performance degradation.


    We grouped the methods into two categories based on different goals. Most LLM
    services charge based on the length of tokens. Therefore, by reducing the input
    length, sentence simplification can effectively reduce the use cost and latency.
    Prompt optimization ensures the quality of the information and improves the performance
    for the invocation.


    #### <span id="page-3-1"></span>3.1 Sentence Simplification


    Sentence simplification aims to improve the performance of language models, reduce
    latency and cost by reducing the complexity and length of language expressions.
    In short, it is the process of making input more concise while retaining its core
    meaning by modifying, removing, or replacing words, phrases, or structures in
    a sentence.


    This problem is similar to the summarization task, and many methods used in summarization
    can be applied [\[Huang](#page-7-19) *et al.*, [2021;](#page-7-19) [Watanangura](#page-8-19)
    *et al.*, 2024; [Antony](#page-7-20) *et al.*, 2023; [Mridha](#page-8-20) *et
    al.*[, 2021\]](#page-8-20). We collate the methods available for LMaaS and divide
    them into extractive and generative methods based on whether they derived entirely
    from the original input.


    Extractive methods. From long original input, extractive methods select sentences
    by extracting key sentences or phrases to form a new input, where the content
    is entirely sourced from original. Pruning semantically irrelevant tokens according
    to the relevance to the contexts is a good choice [\[Liu](#page-7-3) *et al.*[,
    2023a\]](#page-7-3). By employing an intermediate "attacker" and using a greedy
    invocation, iterative deletion and substitution of tokens are performed on the
    input [Si *et al.*[, 2023\]](#page-8-3). [\[Kim](#page-7-4) *et al.*[, 2022\]](#page-7-4)
    based on the attention mechanism, to remove unimportant tokens.


    This approach is straightforward and efficient, making it very convenient for
    immediate use. However, the extraction idea may ignore the global information.
    Furthermore, it has limitations in tasks such as language translation, as it cannot
    discern which parts need to be translated or deleted.


    Generative methods. The generative methods refers to the compression and rewriting
    of the content based on the original input, allowing for the generation of new
    words. Language encoding is a simple processing method applied to the input, [Ahia
    *et al.*[, 2023\]](#page-7-0) conducted extensive experiments with different languages
    and tokenizers, where the cost varied by up to 5 times. AE.studio [2](#page-3-3)
    employs encryption to provide an online platform that sacrifices readability,
    reducing the length of input tokens by half. Utilizing fast and low cost generative
    natural language models [Liu *et al.*[, 2023a;](#page-7-3) Li *et al.*[, 2023\]](#page-7-5)
    also presents a viable option for sentence simplification.


    This category of methods is more flexible, as the generated sentences contain
    less redundant information while preserving the main content. However, it may
    introduce grammatical or factual errors. And this approach may rely on complex
    structures such as graphs, trees, or neural networks.


    #### <span id="page-3-2"></span>3.2 Prompt Optimization


    Prompt optimization is the design and adjustment of userprovided input prompts
    to guide LLMS to produce output that more accurate, useful, or tailored. The effectiveness
    of prompt optimization stems from the LLM''s ability to learn from the


    <span id="page-3-3"></span><sup>2</sup> Prompt Reducer-Cut Down GPT-4 Token Costs
    [\(https://www.](https://www.promptreducer.com/) [promptreducer.com/\)](https://www.promptreducer.com/)


    few-shot or even zero-shot [Liu *et al.*[, 2023b\]](#page-7-15), where appropriate
    prompts can complement the context of the task, highlight key information, or
    improve the explain ability.


    Based on the different granularity of optimization objective, we distinguish two
    types of prompt optimization methods. By selecting or combining some prompts,
    it is possible to guide LLM to handle various inputs more effectively and efficiently.
    Prompt enhancement is concerned with the quality of the content and wants to maximize
    the potential of the context.


    Prompt selection. Prompt selection selects the most meaningful prompt from possible
    prompts to accurately guide LLM. It removes the interference of irrelevant prompts,
    and helps in efficient invocation. [Zhou *et al.*[, 2020\]](#page-8-4) selecting
    representative samples and it can be highly beneficial in few-shot tasks. Another
    way for prompt selection is to combine the prompts for the same type tasks, allowing
    LLM to process prompt information shared by multiple queries at once. [\[Santra](#page-8-5)
    *et al.*, [2023\]](#page-8-5) combines various methods involving instructions,
    examples, and additional context to propose a more compact method for providing
    historical information in dialogues. [\[Arefeen](#page-7-6) *et al.*[, 2023\]](#page-7-6)
    considers the concatenation of prompts and retrieves the most important k sentences
    using comparative methods, enabling the shared use of prompts for similar questions.


    Prompt selection can directly guide LLM to focus on specific aspects of information
    and understand user needs more accurately. For some generic tasks, standard selection
    methods can be used without too much personalization. However, for complex prompts,
    this approach does not maximize its potential because no additional knowledge
    is introduced.


    Prompt augmentation. Prompt augmentation considers the understanding ability of
    LLM to elicit more accurate and desirable responses. Knowledge retrieval is a
    direct method of enhancement, it helps achieve a comprehensive understanding during
    model inference. [\[Haurum](#page-7-7) *et al.*, 2023] investigates the limitations
    of factual knowledge in LLMs and optimizes the reasoning process with minimal
    retrieval cost. Optimization through fine-tuning is a recent advance, [Yu *et
    al.*[, 2023;](#page-8-1) Zhou *et al.*[, 2020\]](#page-8-4) proposes a black-box
    fine-tuning framework that accesses only API to optimize continuous prompts using
    non-derivative methods. Model alignment [Liu *et al.*[, 2023c\]](#page-7-8) and
    chain of thought reasoning [Wu *et al.*[, 2023\]](#page-8-6), are also key focuses
    in prompt optimization.


    The improvement in invocation performance through prompt augmentation is significant,
    despite the likelihood of resulting in more complex processing procedures. And
    the general method is difficult to explore, which requires some professional knowledge.


    ### <span id="page-4-0"></span>4 Semantic Cache


    Semantic cache is an approach to improve LLM invocation efficiency and performance
    by storing and quickly retrieving semantic information. Different from traditional
    data cache, semantic cache focuses more on storing high-level semantics such as
    meaning, context and relationship of data, rather than just raw data. The semantic
    cache is checked before the service is invoked. If hit, the output given by the
    cache is returned without the follow cumbersome procedures.


    Cache technology often requires long-term data accumulation and is not suitable
    for cold start scenarios. However, with the gradual increase in the scale of LLM,
    it plays a more important role in accelerating computation, reducing data transmission
    costs, and supporting high concurrent requests [\[Miao](#page-8-21) *et al.*[,
    2023\]](#page-8-21), providing users with low-cost, low-latency and high-performance
    services.


    There are two typical structures for the implementation of semantic cache in LMaaS,
    and unlike other subsections, they generally cannot be used together. Traditional
    caches use keyvalue pairs for storage and retrieval. When similar input appears
    again, the system can quickly search the semantic cache by the key and return
    the same value. Neural cache borrows ideas from neural networks to response in
    a predictive rather than retrieval way. It learns semantic relationships between
    input data without relying on a specific storage structure.


    #### <span id="page-4-1"></span>4.1 Traditional Cache


    The current paradigm of traditional cache consists of three parts: the cache manager,
    similarity evaluator, and post processor. The cache manager is responsible for
    storing content in the form key-value pairs, and managing eviction. The similarity
    evaluator is used to determine if any of the keys in the cache match the input
    query. The post processor organizes the final response to be returned to the user.
    If no similar query is found in the cache, the LLM service is invoked by the post
    processor to generate the output and then the generated output is stored in the
    cache.


    [\[Bang, 2023\]](#page-7-9) represents a typical application of traditional cache,
    which utilizes question embeddings for similarity matching and provides various
    matching methods such as exact match and embedding distance. The open-source application
    Zep [3](#page-4-3) also supports storage, aggregation, embedding, and indexing
    of LLM applications. Through theoretical proof, [Zhu *et al.*[, 2023\]](#page-8-8)
    gives the cache scheme with minimum expected cost considering the query frequency.
    Furthermore, methods for query and conversations cache [Tao *et al.*[, 2021;](#page-8-7)
    [Barrios and Kumar, 2024\]](#page-7-10) can be easily migrated to LMaaS.


    Implementing traditional cache is usually relatively simple, requiring only basic
    data structures such as hash that are easy to manage. This approach is general,
    but it may not capture semantic similarity between inputs because it relies heavily
    on the key matching.


    #### <span id="page-4-2"></span>4.2 Neural Cache


    Neural cache uses neural networks or deep learning models to learn and store data
    representations. It maps the input data into a high-dimensional space by learning
    the representation of the data. The learned representation should capture the
    semantic similarity of the input data so that similar inputs are close in the
    representation space.


    [\[Ram´ırez](#page-8-9) *et al.*, 2023] trains a student model using T5 base[4](#page-4-4)
    for providing early feedback in classification tasks, and the model is periodically
    updated. To address the effectiveness testing issue of semantic cache, [\[Rasool](#page-8-10)
    *et al.*, 2024] generates similar input to hit the cache as much as possible.
    Additionally, a retrieval-based dialogue response selection model can also serve
    as an alternative choice. [Tao *et al.*[, 2021\]](#page-8-7) provides a survey
    that categorizes most models into three framework and among them, representation-based
    model can be used as neural cache.


    <span id="page-4-3"></span><sup>3</sup>Zep: Fast, scalable building blocks for
    LLM apps [\(https://github.](https://github.com/getzep/zep) [com/getzep/zep\)](https://github.com/getzep/zep)


    <span id="page-4-4"></span><sup>4</sup>T5-base model [\(https://huggingface.co/docs/transformers/model](https://huggingface.co/docs/transformers/model_doc/t5)
    [doc/t5\)](https://huggingface.co/docs/transformers/model_doc/t5)


    These types of methods often outperform traditional cache especially in domain-specific
    problems. However, their implementation and updates can be relatively complex.
    And it is important to carefully consider the effectiveness of the cache to avoid
    incurring unnecessary waste.


    ### <span id="page-5-0"></span>5 Solution Design


    Solution design is an approach to leveraging LLM services with heterogeneous costs
    and performance. It considers different scenarios and different targets, dynamically
    selects one or more LLM services that are most suitable for a specific invocation
    according to the query, and organizes them in some form to provide flexible and
    efficient solutions. This methods allows users to select LLM services that best
    suit their specific needs. When new queries arise or requirements change, the
    configuration of the solution can be flexibly updated to achieve the best performance
    and cost effectiveness.


    Solution design has two main parts that work together to achieve dynamic LLM services
    selection and routing. The scoring function is responsible for evaluating the
    performance of each available LLM service, which can reflect the concerned indicators
    of the invocation such as quality, speed, and so on. The router, based on the
    evaluation results of the scoring function, performs query routing between services
    and selects the appropriate one in a dynamic manner.


    #### <span id="page-5-1"></span>5.1 Scoring Function


    The scoring function is a comprehensive evaluation of LLM services given a specific
    task or query, considering both targets and scenarios, and often used to guide
    the routing path in the solution. It may be influenced by multiple factors such
    as response time, query cost, accuracy of answers, etc. The scoring function plays
    a decision-making role, and helps to understand the relative performance of each
    LLM service so that it can make more intelligent choices.


    Defined metrics. Defined metrics provide a measurable way to achieve direct quantification
    of the factors of concern. For instance, accuracy in classification tasks, BLEU
    score in generation tasks, metrics like packet loss, and quality of service (QoS)
    are all applicable indicators. [\[Ram´ırez](#page-8-9) *et al.*, 2023] use interval
    sampling and predictive entropy to determine whether to invoke LLM services for
    different time dimensions of the invocation. Considering three sources of consistency,
    decisionmaking for LLM services is performed through sampling and voting [Yue
    *et al.*[, 2023\]](#page-8-11). Cost expectations between two models are calculated,
    [Zhu *et al.*[, 2023\]](#page-8-8) extend the selection invocation to multiple
    LLMs. Reward ranking from answers provided by different services is used as an
    evaluation criterion by [Lu *et al.*[, 2023\]](#page-7-11), incurring minimal
    computational cost in the solution.


    The defined metrics are intuitive and easily understandable. They are often based
    on statistical data or experiments, providing high reliability and being less
    susceptible to subjective factors. However, setting thresholds can be challenging
    and may not adapt well to dynamic and changing environments. Additionally, certain
    crucial factors may be difficult to capture with specific metrics, leading to
    limitations in scoring.


    Scorers. A scorer is a tool for scoring each LLM services based on metrics that
    are not defined by a particular formula. The scorer utilizes prior knowledge,
    training data, or rules to provide scores in an often less interpretable manner,
    typically using smaller neural networks [Chen *et al.*[, 2023\]](#page-7-2). AlBert
    is employed as a scorer, with the query and predicted output as x, the accuracy
    of predicted output and label as y during training [\[Sakota](#page-8-12) *et
    al.*, 2023]. Another methods involves using DistilBert as a scoring model, with
    query and model ID as x, and whether it can solve the problem as y during training
    [\[Shnitzer](#page-8-13) *et al.*[, 2023\]](#page-8-13). A comparison of LLM performances
    on different benchmark datasets is conducted, [Zhang *et al.*[, 2023\]](#page-8-14)
    modeling it as a binary selection problem, providing guiding suggestions. For
    specific tasks, such as the execution results in the task of code generation [\[Zhang](#page-8-14)
    *et al.*, 2023], the classifier according to the query difficulty in the task
    of question and answer [\[Anonymous, 2024;](#page-7-12) [Madaan](#page-8-15) *et
    al.*, 2023], and estimate the capabilities of LLM services in the task of dataset
    benchmark test [\[Shnitzer](#page-8-13) *et al.*, 2023] are all reasonable scorers.


    Compared to metrics defined by formulas, scorers can be updated based on real-time
    data and feedback, demonstrating strong generalization across different scenarios.
    However, this approach is equivalent to scoring using a more powerful model, incurring
    scorers own training and usage costs. And it still requires some labeled examples,
    leading to the fact that it makes sense only when the query dataset is larger
    than the training.


    #### <span id="page-5-2"></span>5.2 LLM Router


    LLM routing emphasizes the organizational structure between services, connecting
    multiple independent services in a specific order logically. It focus on constructing
    a flexible and reusable LLM service solution to address continuously changing
    queries or targets. Depending on the different scoring function and position used,
    LLM routing can construct target-oriented solution, such as cost-oriented or performanceoriented.


    Sequential Structure. The simplest method is to select one or several models from
    the massive LLM services available and invoke them sequentially. A scoring function
    is employed to decide whether to accept the answer or proceed to the next step
    in routing [Chen *et al.*[, 2023\]](#page-7-2). When using a sequential structure,
    the number of models is typically limited to three, and possible options are determined
    through permutation, with pruning techniques applied [\[Ram´ırez](#page-8-9) *et
    al.*, 2023; Yue *[et al.](#page-8-11)*, [2023\]](#page-8-11). The use of small
    models as a cache, with large models being invoked in sequence when cache misses
    occur, can be considered a fixed sequential structure [\[Ram´ırez](#page-8-9)
    *et al.*, 2023; Yue *et al.*[, 2023\]](#page-8-11). For problems like code generation
    [\[Zhang](#page-8-14) *et al.*[, 2023\]](#page-8-14), an initial response is obtained
    using a cost-effective LLM, and successful information is tracked as context for
    subsequent queries.


    This structure is simple and effective, and a limited number of permutations can
    be searched quickly in the entire space. However, the sequential structure may
    result in the invocation of all models in the sequential structure. And it is
    difficult to extend the structure, which all models need to be rearranged when
    adapting to new requirements.


    Other Structure. A parallel structure, similar to the bagging and boosting in
    machine learning, can enhance the correctness and consistency of LLM services,
    with task decomposition and merging being key aspects [Jiang *et al.*[, 2023\]](#page-7-13).
    A star-shaped structure, as seen in [\[Sakota](#page-8-12) *et al.*, 2023; Lu
    *et al.*[, 2023\]](#page-7-11), involves decision-making by a meta-model, allocating
    the current query to the most suitable model. For the third category of unsolvable
    queries, pruning is applied by [\[Madaan](#page-8-15) *et al.*, 2023] to prevent
    unnecessary expenses for par-


    <span id="page-6-2"></span>![](_page_6_Figure_0.jpeg)


    Figure 4: A simple invocation strategy composed of existing methods, using Prompt
    Reducer in input abstract, Zep in semantic cache, FrugalGPT in solution design,
    and nothing in output enhancement.


    ticularly challenging problems. The tree structure is considered promising, combining
    aspects of both star-shaped and sequential structures. It initially routes query
    to the most probable branch, and then invokes services in sequence. Additionally,
    certain selection solutions specific to HTTP services [\[Hossein](#page-7-14)zadeh
    *et al.*[, 2020;](#page-7-14) [Manqele](#page-8-17) *et al.*, 2017] are also noteworthy
    for inspiration.


    ### <span id="page-6-0"></span>6 Output Enhancement


    Output Enhancement refers to the process of further optimizing and adjusting the
    output generated by the invocation. This process aims to improve the syntactic
    correctness, semantic accuracy, and overall fluency of the generated output to
    meet the needs of the user and the specific scenario.


    To the best of our knowledge, the output enhancement methods still relies on the
    methods mentioned above, but it emphasizes customization according to the needs
    of specific tasks, improving the adaptability of the model to application, reducing
    the need for subsequent manual intervention, and providing users with low-latency,
    high-performance, and low-latency services. For example, [Liu *et al.*[, 2023b\]](#page-7-15)
    guides the LLM to make concise answers can reduce unnecessary output tokens. Aggregating
    responses from multiple low-cost models is another way to improve quality [Chen
    *et al.*[, 2022\]](#page-7-16), and is often used for multi-label tasks. Work
    on model alignment [\[Shen](#page-8-18) *et al.*[, 2023\]](#page-8-18) can also
    be used to correct syntax and logic to reduce the need for subsequent manual work.


    ### <span id="page-6-1"></span>7 Conclusion and Challenges


    In conclusion, this paper has provided a comprehensive overview of effective invocation
    methods in the realm of LMaaS. Through the establishment of a taxonomy, we categorize
    existing methods into four categories: input abstract, semantic cache, solution
    design, and output enhancement. Then we formalize the problem of effective LLM
    services strategy construction, and propose a LLM services invocation framework.
    Each component in the framework can work independently or simultaneously to form
    effective strategy for LLM service invocation that are low-latency, high-performance,
    and cost-saving.


    Existing methods tend to focus on only one component of the framework, and we
    can use them as plugins. A case is shown in Figure [4,](#page-6-2) a simple invocation
    strategy constructed from three existing methods. The development prospects of
    this field are promising, and here are some open challenges.


    Input Abstract. In the input abstract component, one of the main challenges faced
    is multi-modal input processing [\[Yin](#page-8-22)


    *et al.*[, 2023\]](#page-8-22). More comprehensive and balanced methods are needed
    to shorten and optimize multiple types of input such as text, image, and speech.
    Input abstract methods to dynamically changing inputs are also worth exploring,
    such as realtime data streaming [Rath ¨ *et al.*[, 2023\]](#page-8-23) or user
    interaction with the system. Furthermore, depending on the granularity, the input
    abstract can also be divided into document level, sentence level and phrase level.
    methods at different granularities may interoperate and often compose multi-stage
    methods.


    Semantic Cache. In the semantic cache part, how to design and select cache methods[Brais
    *et al.*[, 2021\]](#page-7-21) more efficiently to accommodate different types
    of inputs and queries is the main challenge faced in traditional cache, while
    semantic representation [\[Brito, 2023\]](#page-7-22) is concerned by neural cache.


    Solution Design. In terms of solution design, the evaluation problem of LLM services
    [\[Chang](#page-7-23) *et al.*, 2023] is an extension of scoring function, which
    needs to pay more attention to adaptation and interpretability in the future.
    While LLM router will focus on designing more powerful services integration methods,
    not only focusing on the task itself, but also considering the requirements of
    different resources [Xu *et al.*[, 2024\]](#page-8-24). A more effective combination
    of the two, such as dynamic decision making, will lead to a better solution.


    Output Enhancement. The importance of output enhancement is also gradually seen
    by people. The balance between specification and diversity of output is a key
    issue. When the task is completed, the user''s satisfaction is then an important
    indicator to measure the service quality, and future research may focus on building
    more intelligent and user-oriented [\[Je](#page-7-24)[ung and Huang, 2023\]](#page-7-24)
    output enhancement methods.


    Other Chanllenges. Basic work such as qualitative description and quantitative
    comparison in experiments is still a gap to be filled, and the lack of data sets
    makes there is no uniform standard for the comparison of service methods. Some
    technical details, such as how to choose the tokenizer [\[Alyafeai](#page-7-25)
    *et al.*[, 2023\]](#page-7-25) with the shortest input, the guidance on the cache
    size [\[Vavouliotis](#page-8-25) *et al.*, 2022], and the choice of different
    pricing methods for the same LLM service, need to be explored. In additionally,
    We specifically call for attention to fairness [Sah *et al.*[, 2024\]](#page-8-26)
    and privacy issues [Luo *et al.*[, 2024;](#page-7-26) Utpala *et al.*[, 2023\]](#page-8-27)
    in LMaaS. The efficient construction of methods using middleware could potentially
    be exploited for personal gain or malicious purposes. We look forward to future
    research further advancing the field, providing users with low-latency, high-performance,
    and cost-effective LLM services solution, and promoting the healthy development
    of the LMaaS ecosystem.


    ### References


    - <span id="page-7-0"></span>[Ahia *et al.*, 2023] Orevaoghene Ahia, Sachin Kumar,
    Hila Gonen, Jungo Kasai, David R. Mortensen, Noah A. Smith, and Yulia Tsvetkov.
    Do all languages cost the same? tokenization in the era of commercial language
    models. In *Proc. of EMNLP*, 2023.

    - <span id="page-7-25"></span>[Alyafeai *et al.*, 2023] Zaid Alyafeai, Maged Saeed
    Al-Shaibani, Mustafa Ghaleb, and Irfan Ahmad. Evaluating various tokenizers for
    arabic text classification. *Neural Process. Lett.*, 2023.

    - <span id="page-7-12"></span>[Anonymous, 2024] Anonymous. Hybrid LLM: Cost-efficient
    and quality-aware query routing. In *Proc. of ICLR*, 2024.

    - <span id="page-7-20"></span>[Antony *et al.*, 2023] Dinu Antony, Sumit Abhishek,
    Sujata Singh, Siddu Kodagali, Narayana Darapaneni, Mukesh Rao, Anwesh Reddy Paduri,
    and Sudha BG. A survey of advanced methods for efficient text summarization. In
    *13th IEEE Annual Computing and Communication Workshop and Conference, CCWC 2023,
    Las Vegas, NV, USA, March 8-11, 2023*, 2023.

    - <span id="page-7-6"></span>[Arefeen *et al.*, 2023] Md. Adnan Arefeen, Biplob
    Debnath, and Srimat Chakradhar. Leancontext: Cost-efficient domain-specific question
    answering using llms. *CoRR*, 2023.

    - <span id="page-7-17"></span>[Bai *et al.*, 2024] Guangji Bai, Zheng Chai, Chen
    Ling, Shiyu Wang, Jiaying Lu, Nan Zhang, Tingwei Shi, Ziyang Yu, Mengdan Zhu,
    Yifei Zhang, Carl J. Yang, Yue Cheng, and Liang Zhao. Beyond efficiency: A systematic
    survey of resource-efficient large language models. *CoRR*, 2024.

    - <span id="page-7-9"></span>[Bang, 2023] Fu Bang. Gptcache: An open-source semantic
    cache for llm applications enabling faster answers and cost savings. 2023.

    - <span id="page-7-10"></span>[Barrios and Kumar, 2024] Carlos Barrios and Mohan
    Kumar. Service caching and computation reuse strategies at the edge: A survey.
    *ACM Comput. Surv.*, 2024.

    - <span id="page-7-21"></span>[Brais *et al.*, 2021] Hadi Brais, Rajshekar Kalayappan,
    and Preeti Ranjan Panda. A survey of cache simulators. *ACM Comput. Surv.*, 2021.

    - <span id="page-7-22"></span>[Brito, 2023] Eduardo Brito. *Explainable Resource-Aware
    Representation Learning via Semantic Similarity*. PhD thesis, 2023.

    - <span id="page-7-23"></span>[Chang *et al.*, 2023] Yupeng Chang, Xu Wang, Jindong
    Wang, Yuan Wu, Kaijie Zhu, Hao Chen, Linyi Yang, Xiaoyuan Yi, Cunxiang Wang, Yidong
    Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, and Xing Xie. A survey
    on evaluation of large language models. *CoRR*, 2023.

    - <span id="page-7-16"></span>[Chen *et al.*, 2022] Lingjiao Chen, Matei Zaharia,
    and James Zou. Efficient online ML API selection for multi-label classification
    tasks. In *Proc. of ICML*, 2022.

    - <span id="page-7-2"></span>[Chen *et al.*, 2023] Lingjiao Chen, Matei Zaharia,
    and James Zou. Frugalgpt: How to use large language models while reducing cost
    and improving performance. *CoRR*, 2023.

    - <span id="page-7-18"></span>[Dong *et al.*, 2023] Qingxiu Dong, Lei Li, Damai
    Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, Lei Li, and Zhifang
    Sui. A survey on in-context learning, 2023.

    - <span id="page-7-7"></span>[Haurum *et al.*, 2023] Joakim Bruslund Haurum, Sergio
    Escalera, Graham W. Taylor, and Thomas B. Moeslund. Which tokens to use? investigating
    token reduction in vision transformers. In *Proc. of ICCV*, 2023.

    - <span id="page-7-14"></span>[Hosseinzadeh *et al.*, 2020] Mehdi Hosseinzadeh,
    Hawkar Kamaran Hama, Marwan Yassin Ghafour, Mohammad Masdari, Omed Hassan Ahmed,
    and Hemn Khezri. Service selection using multi-criteria decision making: A comprehensive
    overview. *J. Netw. Syst. Manag.*, 2020.

    - <span id="page-7-19"></span>[Huang *et al.*, 2021] Yi-Chong Huang, Xia-Chong
    Feng, Xiao-Cheng Feng, and Bing Qin. The factual inconsistency problem in abstractive
    text summarization: A survey. *CoRR*, 2021.

    - <span id="page-7-24"></span>[Jeung and Huang, 2023] Jun Li Jeung and Yi-Ching
    Janet Huang. Correct me if I am wrong: Exploring how AI outputs affect user perception
    and trust. In *Computer Supported Cooperative Work and Social Computing, CSCW
    2023, Minneapolis, MN, USA, October 14-18, 2023*, 2023.

    - <span id="page-7-13"></span>[Jiang *et al.*, 2023] Dongfu Jiang, Xiang Ren,
    and Bill Yuchen Lin. Llm-blender: Ensembling large language models with pairwise
    ranking and generative fusion. In *Proc. of ACL*, 2023.

    - <span id="page-7-4"></span>[Kim *et al.*, 2022] Sehoon Kim, Sheng Shen, David
    Thorsley, Amir Gholami, Woosuk Kwon, Joseph Hassoun, and Kurt Keutzer. Learned
    token pruning for transformers. In *Proc. of KDD*, 2022.

    - <span id="page-7-1"></span>[Lai *et al.*, 2023] Viet Dac Lai, Nghia Trung Ngo,
    Amir Pouran Ben Veyseh, Hieu Man, Franck Dernoncourt, Trung Bui, and Thien Nguyen.
    Chatgpt beyond english: Towards a comprehensive evaluation of large language models
    in multilingual learning. In *Proc. of EMNLP Findings*, 2023.

    - <span id="page-7-5"></span>[Li *et al.*, 2023] Jiazheng Li, Runcong Zhao, Yulan
    He, and Lin Gui. Overprompt: Enhancing chatgpt capabilities through an efficient
    in-context learning approach. *CoRR*, 2023.

    - <span id="page-7-3"></span>[Liu *et al.*, 2023a] Junyi Liu, Liangzhi Li, Tong
    Xiang, Bowen Wang, and Yiming Qian. TCRA-LLM: token compression retrieval augmented
    large language model for inference cost reduction. In *Proc. of EMNLP Findings*,
    2023.

    - <span id="page-7-15"></span>[Liu *et al.*, 2023b] Pengfei Liu, Weizhe Yuan,
    Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. Pre-train, prompt,
    and predict: A systematic survey of prompting methods in natural language processing.
    *ACM Comput. Surv.*, 2023.

    - <span id="page-7-8"></span>[Liu *et al.*, 2023c] Yixin Liu, Budhaditya Deb,
    Milagro Teruel, Aaron Halfaker, Dragomir Radev, and Ahmed Hassan Awadallah. On
    improving summarization factual consistency from natural language feedback. In
    *Proc. of ACL*, 2023.

    - <span id="page-7-11"></span>[Lu *et al.*, 2023] Keming Lu, Hongyi Yuan, Runji
    Lin, Junyang Lin, Zheng Yuan, Chang Zhou, and Jingren Zhou. Routing to the expert:
    Efficient reward-guided ensemble of large language models. *CoRR*, 2023.

    - <span id="page-7-26"></span>[Luo *et al.*, 2024] Jinglong Luo, Yehong Zhang,
    Jiaqi Zhang, Xin Mu, Hui Wang, Yue Yu, and Zenglin Xu. Secformer: Towards fast
    and accurate privacy-preserving inference for large language models. *CoRR*, 2024.

    - <span id="page-8-15"></span>[Madaan *et al.*, 2023] Aman Madaan, Pranjal Aggarwal,
    Ankit Anand, Srividya Pranavi Potharaju, Swaroop Mishra, Pei Zhou, Aditya Gupta,
    Dheeraj Rajagopal, Karthik Kappaganthu, Yiming Yang, Shyam Upadhyay, Mausam, and
    Manaal Faruqui. Automix: Automatically mixing language models. *CoRR*, 2023.

    - <span id="page-8-17"></span>[Manqele *et al.*, 2017] Lindelweyizizwe Manqele,
    Mqhele E. Dlodlo, Louis Coetzee, and George Sibiya. A survey for service selection
    approaches in dynamic environments. In *IEEE AFRICON 2017, Cape Town, South Africa,
    September 18-20, 2017*, 2017.

    - <span id="page-8-21"></span>[Miao *et al.*, 2023] Xupeng Miao, Gabriele Oliaro,
    Zhihao Zhang, Xinhao Cheng, Hongyi Jin, Tianqi Chen, and Zhihao Jia. Towards efficient
    generative large language model serving: A survey from algorithms to systems.
    *CoRR*, 2023.

    - <span id="page-8-20"></span>[Mridha *et al.*, 2021] Muhammad F. Mridha, Aklima
    Akter Lima, Kamruddin Nur, Sujoy Chandra Das, Mahmud Hasan, and Muhammad Mohsin
    Kabir. A survey of automatic text summarization: Progress, process and challenges.
    *IEEE Access*, 2021.

    - <span id="page-8-9"></span>[Ram´ırez *et al.*, 2023] Guillem Ram´ırez, Matthias
    Lindemann, Alexandra Birch, and Ivan Titov. Cache & distil: Optimising API calls
    to large language models. *CoRR*, 2023.

    - <span id="page-8-10"></span>[Rasool *et al.*, 2024] Zafaryab Rasool, Scott Barnett,
    David Willie, Stefanus Kurniawan, Sherwin Balugo, Srikanth Thudumu, and Mohamed
    Abdelrazek. Llms for test input generation for semantic caches, 2024.

    - <span id="page-8-23"></span>[Rath ¨ *et al.*, 2023] Timo Rath, Ngozichukwuka
    Onah, and ¨ Kai-Uwe Sattler. Interactive data cleaning for real-time streaming
    applications. In *Proceedings of the Workshop on Human-In-the-Loop Data Analytics,
    HILDA 2023, Seattle, WA, USA, 18 June 2023*, 2023.

    - <span id="page-8-2"></span>[Reddy *et al.*, 2019] Siva Reddy, Danqi Chen, and
    Christopher D. Manning. Coqa: A conversational question answering challenge. *Trans.
    Assoc. Comput. Linguistics*, 2019.

    - <span id="page-8-26"></span>[Sah *et al.*, 2024] Chandan Kumar Sah, Xiaoli Lian,
    and Muhammad Mirajul Islam. Unveiling bias in fairness evaluations of large language
    models: A critical literature review of music and movie recommendation systems.
    *CoRR*, 2024.

    - <span id="page-8-16"></span>[Saha *et al.*, 2023] Swarnadeep Saha, Omer Levy,
    Asli Celikyilmaz, Mohit Bansal, Jason Weston, and Xian Li. Branch-solve-merge
    improves large language model evaluation and generation. *CoRR*, 2023.

    - <span id="page-8-12"></span>[Sakota *et al.*, 2023] Marija Sakota, Maxime Peyrard,
    and Robert West. Fly-swat or cannon? cost-effective language model choice via
    meta-modeling. *CoRR*, 2023.

    - <span id="page-8-5"></span>[Santra *et al.*, 2023] Bishal Santra, Sakya Basak,
    Abhinandan De, Manish Gupta, and Pawan Goyal. Frugal prompting for dialog models.
    In *Proc. of EMNLP Findings*, 2023.

    - <span id="page-8-18"></span>[Shen *et al.*, 2023] Tianhao Shen, Renren Jin,
    Yufei Huang, Chuang Liu, Weilong Dong, Zishan Guo, Xinwei Wu, Yan Liu, and Deyi
    Xiong. Large language model alignment: A survey. *CoRR*, 2023.

    - <span id="page-8-13"></span>[Shnitzer *et al.*, 2023] Tal Shnitzer, Anthony
    Ou, M´ırian Silva, Kate Soule, Yuekai Sun, Justin Solomon, Neil Thompson, and
    Mikhail Yurochkin. Large language model routing with benchmark datasets. *CoRR*,
    2023.

    - <span id="page-8-3"></span>[Si *et al.*, 2023] Wai Man Si, Michael Backes, and
    Yang Zhang. Mondrian: Prompt abstraction attack against large language models
    for cheaper API pricing. *CoRR*, 2023.

    - <span id="page-8-7"></span>[Tao *et al.*, 2021] Chongyang Tao, Jiazhan Feng,
    Rui Yan, Wei Wu, and Daxin Jiang. A survey on response selection for retrieval-based
    dialogues. In *Proc. of IJCAI*, 2021.

    - <span id="page-8-27"></span>[Utpala *et al.*, 2023] Saiteja Utpala, Sara Hooker,
    and Pin-Yu Chen. Locally differentially private document generation using zero
    shot prompting. In *Proc. of EMNLP Findings*, 2023.

    - <span id="page-8-25"></span>[Vavouliotis *et al.*, 2022] Georgios Vavouliotis,
    Gino Chacon, Lluc Alvarez, Paul V. Gratz, Daniel A. Jimenez, and Marc ´ Casas.
    Page size aware cache prefetching. In *Proc. of MI-CRO*, 2022.

    - <span id="page-8-19"></span>[Watanangura *et al.*, 2024] Patcharapruek Watanangura,
    Sukit Vanichrudee, On Minteer, Theeranat Sringamdee, Nattapong Thanngam, and Thitirat
    Siriborvornratanakul. A comparative survey of text summarization techniques. *SN
    Comput. Sci.*, 2024.

    - <span id="page-8-6"></span>[Wu *et al.*, 2023] Dingjun Wu, Jing Zhang, and Xinmei
    Huang. Chain of thought prompting elicits knowledge augmentation. In *Proc. of
    ACL Findings*, 2023.

    - <span id="page-8-24"></span>[Xu *et al.*, 2024] Mengwei Xu, Wangsong Yin, Dongqi
    Cai, Rongjie Yi, Daliang Xu, Qipeng Wang, Bingyang Wu, Yihao Zhao, Chen Yang,
    Shihe Wang, Qiyang Zhang, Zhenyan Lu, Li Zhang, Shangguang Wang, Yuanchun Li,
    Yunxin Liu, Xin Jin, and Xuanzhe Liu. A survey of resource-efficient LLM and multimodal
    foundation models. *CoRR*, 2024.

    - <span id="page-8-0"></span>[Yang *et al.*, 2023] Jingfeng Yang, Hongye Jin,
    Ruixiang Tang, Xiaotian Han, Qizhang Feng, Haoming Jiang, Bing Yin, and Xia Hu.
    Harnessing the power of llms in practice: A survey on chatgpt and beyond. *CoRR*,
    2023.

    - <span id="page-8-22"></span>[Yin *et al.*, 2023] Shukang Yin, Chaoyou Fu, Sirui
    Zhao, Ke Li, Xing Sun, Tong Xu, and Enhong Chen. A survey on multimodal large
    language models. *CoRR*, 2023.

    - <span id="page-8-1"></span>[Yu *et al.*, 2023] Lang Yu, Qin Chen, Jiaju Lin,
    and Liang He. Black-box prompt tuning for vision-language model as a service.
    In *Proc. of IJCAI*, 2023.

    - <span id="page-8-11"></span>[Yue *et al.*, 2023] Murong Yue, Jie Zhao, Min Zhang,
    Liang Du, and Ziyu Yao. Large language model cascades with mixture of thoughts
    representations for cost-efficient reasoning. *CoRR*, 2023.

    - <span id="page-8-14"></span>[Zhang *et al.*, 2023] Jieyu Zhang, Ranjay Krishna,
    Ahmed Hassan Awadallah, and Chi Wang. Ecoassistant: Using LLM assistant more affordably
    and accurately. *CoRR*, 2023.

    - <span id="page-8-4"></span>[Zhou *et al.*, 2020] Jianyi Zhou, Feng Li, Jinhao
    Dong, Hongyu Zhang, and Dan Hao. Cost-effective testing of a deep learning model
    through input reduction. In *31st IEEE International Symposium on Software Reliability
    Engineering, ISSRE 2020, Coimbra, Portugal, October 12-15, 2020*, 2020.

    - <span id="page-8-8"></span>[Zhu *et al.*, 2023] Banghua Zhu, Ying Sheng, Lianmin
    Zheng, Clark W. Barrett, Michael I. Jordan, and Jiantao Jiao. On optimal caching
    and model multiplexing for large model inference. *CoRR*, 2023.'
  decisions:
    evaluation_prompt: 'Disqualified: no evaluation. Reason: The paper is a survey
      and does not contain any empirical, experimental, or quantitative evaluation
      of its own. It discusses various methods and frameworks but does not present
      any structured evaluation or testing of these methods.'
    related_work_prompt: 'Qualified. Reason: The paper meaningfully engages with prior
      research throughout the text, including in the Introduction, Background, and
      various sections discussing components like input abstract, semantic cache,
      solution design, and output enhancement. It provides citations and comparisons
      to previous work, demonstrating a comprehensive review of existing methods and
      situating its contributions within the context of prior research.'
    novelty_prompt: '- Qualified. Reason: The paper proposes a comprehensive taxonomy
      and framework for effective invocation methods in Language Models as a Service
      (LMaaS), categorizing existing methods into input abstract, semantic cache,
      solution design, and output enhancement. It formalizes the problem as a multi-objective
      optimization task and highlights open challenges, providing novel insights and
      a roadmap for future research in this domain.'
    review_only_prompt: 'Disqualified: review paper. Reason: The title contains the
      word "survey," and the main body primarily summarizes existing work without
      introducing new methods, datasets, experiments, or frameworks.'
- title: 'ACM Reference Format:'
  abstract: ''
  keywords: ''
  document: '-


    ALVARO CINTAS CANTO, Marymount University, USA JASMIN KAUR, University of South
    Florida, USA MEHRAN MOZAFFARI KERMANI, University of South Florida, USA REZA AZARDERAKHSH,
    Florida Atlantic University, USA


    This survey is on forward-looking, emerging security concerns in post-quantum
    era, i.e., the implementation attacks for 2022 winners of NIST post-quantum cryptography
    (PQC) competition and thus the visions, insights, and discussions can be used
    as a step forward towards scrutinizing the new standards for applications ranging
    from Metaverse/Web 3.0 to deeply-embedded systems. The rapid advances in quantum
    computing have brought immense opportunities for scientific discovery and technological
    progress; however, it poses a major risk to today''s security since advanced quantum
    computers are believed to break all traditional publickey cryptographic algorithms.
    This has led to active research on PQC algorithms that are believed to be secure
    against classical and powerful quantum computers. However, algorithmic security
    is unfortunately insufficient, and many cryptographic algorithms are vulnerable
    to side-channel attacks (SCA), where an attacker passively or actively gets side-channel
    data to compromise the security properties that are assumed to be safe theoretically.
    In this survey, we explore such imminent threats and their countermeasures with
    respect to PQC. We provide the respective, latest advancements in PQC research,
    as well as assessments and providing visions on the different types of SCAs.


    CCS Concepts: • Security and privacy → Digital signatures; Hardware attacks and
    countermeasures.


    Additional Key Words and Phrases: Embedded security, Secure post-quantum cryptography,
    side-channel attacks.


    ## ACM Reference Format:


    Alvaro Cintas Canto, Jasmin Kaur, Mehran Mozaffari Kermani, and Reza Azarderakhsh.
    2023. Algorithmic Security is Insufficient: A Comprehensive Survey on Implementation
    Attacks Haunting Post-Quantum Security. ACM Comput. Surv. -, -, Article - (May
    2023), [16](#page-15-0) pages. <https://doi.org/10.1145/nnnnnnn.nnnnnnn>


    ## 1 INTRODUCTION


    Shor''s algorithm is a known quantum algorithm that allows solving discrete-logarithm
    and integerfactorization problems, making public key cryptographic standards vulnerable
    under the presence of quantum computers. RSA, DSA, and elliptic curve cryptography
    (ECC) are the main public key cryptographic algorithms that are used currently.
    ECC has replaced RSA in many applications due


    Authors'' addresses: Alvaro Cintas Canto, Marymount University, Arlington, VA,
    22207, USA, acintas@marymount.edu; Jasmin Kaur, University of South Florida, Tampa,
    FL, 33620, USA, jasmink1@usf.edu; Mehran Mozaffari Kermani, University of South
    Florida, Tampa, FL, 33620, USA, mehran2@usf.edu; Reza Azarderakhsh, Florida Atlantic
    University, Boca Raton, FL, 33431, USA, razarderakhsh@fau.edu.


    Permission to make digital or hard copies of all or part of this work for personal
    or classroom use is granted without fee provided that copies are not made or distributed
    for profit or commercial advantage and that copies bear this notice and the full
    citation on the first page. Copyrights for components of this work owned by others
    than ACM must be honored. Abstracting with credit is permitted. To copy otherwise,
    or republish, to post on servers or to redistribute to lists, requires prior specific
    permission and/or a fee. Request permissions from permissions@acm.org.


    0360-0300/2023/05-ART- \$15.00


    <https://doi.org/10.1145/nnnnnnn.nnnnnnn>


    <sup>© 2023</sup> Association for Computing Machinery.


    to its efficient realizations with the same security level. Nevertheless, the
    introduction of highperformance quantum computers has increased the need for the
    creation of public key cryptosystems which are resistant to the cyber-attacks
    enabled by quantum-based computing systems. The National Institute of Standards
    and Technology (NIST) announced in late 2016 the commencement of a project to
    standardize one or more quantum computer-resistant public-key cryptography and
    digital signature algorithms [1]. After more than five years and multiple rounds
    of reviews, NIST has recently, in 2022, chosen four candidate algorithms for standardization
    and left four others for another round of evaluation. Table 1 shows the current
    state of the NIST post-quantum cryptography (PQC) standardization process, where
    PKE and KEM stand for public-key encryption and key encapsulation mechanism, respectively.
    KEMs, unlike general-purpose PKEs, are not intended for encrypting application
    data. Instead, they are specifically created to establish a shared secret between
    communication partners in cryptographic protocols such as Transport Layer Security
    (TLS), just like the Diffie-Hellman Key-Exchange method, which is currently one
    of the best available options.


    PQC cryptography englobes five major types: Lattice-based, code-based, multivariate-based,
    hash-based, and isogeny-based cryptography. Lattice-based cryptography mathematical
    problem is related to lattices, which are geometric structures formed by repeating
    patterns of points in space; code-based cryptography is formed on error-correcting
    codes, a technique used to detect and correct errors in data transmission; multivariate-based
    cryptography relies on the hardness of solving equations with multiple variables
    (there are not multivariate-based standards or finalists); hash-based cryptography
    relies on hash functions, which are one-way functions where any-size input is
    mapped into a fixed value; and lastly, isogeny-based cryptography uses isogenies,
    which are mappings between elliptic curves.


    Most of the aforementioned PQC algorithms have large designs and complex operations.
    This aspect as well as the continuous advancements in very-large-scale integration
    (VLSI) technologies make post-quantum cryptosystems vulnerable to implementation
    attacks which are commonly referred to as side-channel attacks (SCAs). SCAs can
    be divided into passive or active attacks. Passive attacks are those whose aim
    is to exfiltrate sensitive information by analyzing various physical parameters
    of the system, e.g., power consumption, timing information, or electromagnetic
    radiation. Active attacks, on the other hand, intend to reveal the internal states
    of cryptographic implementations by injecting transient faults into the system,
    e.g., differential fault analysis (DFA). The consequences of these attacks range
    from the exploitation of sensitive data by third parties to causing an entire
    system to malfunction.


    Therefore, it is extremely important and necessary to explore countermeasures
    against SCAs for securing emerging post-quantum cryptosystems. This survey is
    on forward-looking, emerging security concerns in post-quantum era, i.e., the
    implementation attacks for 2022 winners of NIST PQC competition and thus the visions,
    insights, and discussions can be used as a step forward towards scrutinizing the
    new standards for applications ranging from Metaverse/Web 3.0 to deeplyembedded
    systems.


    The remainder of this survey is outlined as follows: Section 2 gives a technical
    background of the different PQC standards and finalists that are currently under
    a fourth evaluation round in the NIST PQC standardization process; Section 3 comprehensively
    reviews and analyzes different types of SCAs that have been implemented as well
    several countermeasures to counter them; and lastly, Section 4 concludes the survey.


    #### 2 PRELIMINARIES


    As shown in Table 1, three out of four standards are lattice-based, i.e., CRYSTALS-Kyber,
    CRYSTALS-Dilithium, and FALCON, while one of them, SPHINCS<sup>+</sup> is hash-based.
    The finalists are mostly


    code-based, except for SIKE, which is isogeny-based. However, after a classic
    attacks on only one core mounted by excellent research works, SIKE''s team acknowledged
    that SIKE and SIDH are insecure and should not be used.


    CRYSTALS-Kyber: It is the only PQC PKE/KEM that has been standardized. Its security
    depends on the hardness of solving the learning-with-errors (LWE) problem over
    module lattices. Both PKE and KEM are very similar; how-


    ever, the KEM uses a slightly tweaked Fujisaki–Okamoto (FO) transform. The LWE
    problem involves finding a small secret vector 𝑠 (secret key) when given a matrix𝐴
    over a constantsize polynomial ring and a vector 𝑏 = 𝐴𝑠 + 𝑒. To encode a message
    𝑚, a particular seed value 𝜇 is used, binomial sampling is employed to select
    random values (𝑟, 𝑒1, 𝑒2), and a uniform distribution is used to sample 𝐴 𝑇 .
    The values of 𝑢 and 𝑣 are then calculated by combining these elements with the
    message. Lastly, the ciphertext 𝑐 is formed by compressing 𝑢 and 𝑣 using a com-


    |              | Table 1. Current state of the NIST PQC Standardiza |

    |--------------|----------------------------------------------------|

    | tion Process |                                                    |


    | PQC Algorithm      | Status   | Type    | PKE/KEM vs.<br>Signature |  |

    |--------------------|----------|---------|--------------------------|--|

    | CRYSTALS-Kyber     |          |         | PEK/KEM                  |  |

    | CRYSTALS-Dilithium | Standard | Lattice | Signature                |  |

    | FALCON             |          |         |                          |  |

    | SPHINCS+           |          | Hash    |                          |  |

    | BIKE               |          |         |                          |  |

    | Classic McEliece   | Round 4  | Code    | PKE/KEM                  |  |

    | HQC                |          |         |                          |  |

    | SIKE               | Broken   | Isogeny |                          |  |


    pression algorithm. To decode the message, an approximation of 𝑣 is recovered
    by computing the product of the secret key and 𝑢. CRYSTALS-Kyber requires polynomial
    ring multiplications and it uses number-theoretic transform (NTT), which is an
    efficient way to perform multiplications in lattice-based cryptosystems; however,
    it is one of the major vulnerable points against SCA.


    CRYSTALS-Dilithium: Its security is based on the hardness of finding short vectors
    in lattices, known as the Shortest Vector Problem (SVP), and it operates over
    the ring 𝑍<sup>𝑞</sup> [𝑋]/(𝑋 <sup>𝑛</sup> + 1) with 𝑞 = 2 <sup>23</sup>−2 <sup>13</sup>+1
    and 𝑛 = 256. The key generation algorithm creates a matrix𝐴 and secret key vectors
    𝑠<sup>1</sup> and 𝑠<sup>2</sup> in such polynomial ring. The public key is then
    computed as𝑡 = 𝐴·𝑠<sup>1</sup> +𝑆2. The bulk of the signing and verification procedures
    in CRYSTALS-Dilithium involve two operations: expanding an XOF (eXtendable Output
    Function) using SHAKE-128 or SHAKE-256, and performing polynomial ring multiplication
    using NTT. To compute the signature, a masking vector of polynomials 𝑦 is multiplied
    with 𝐴 (where 𝑤<sup>1</sup> are the high-order bits), and a challenge 𝑐 is then
    created as the hash of the message and 𝑤1. Lastly, the potential signature is
    computed as 𝑧 = 𝑦 + 𝑐 · 𝑠1. Then, the verifier uses the public key and computes
    𝑤 ′ 1 to be the high-order bits of 𝐴 · 𝑧 − 𝑐 · 𝑡 and accepts the signature if
    all coefficients of 𝑧 are less than a threshold.


    FALCON: One of the major drawbacks of CRYSTALS-Dilithium is their large size signatures.
    Therefore, FALCON, another lattice-based cryptosystem whose signatures are of
    smaller size, has been standardized. Its underlying hard problem is the short
    integer solution problem (SIS) over NTRU lattices. The FALCON scheme is based
    on a GPV framework, which provides a way to construct signature schemes using
    lattice-based primitives. Another important aspect of FALCON is the use of Fast
    Fourier sampling, which improves FALCON''s efficiency and performance. In the
    key generation, two random polynomials 𝑓 and 𝑔 are chosen and the NTRU equation
    is solved to find a matching 𝐹 and 𝐺. To sign, the message is hashed along with
    a random nonce, into a polynomial 𝑐 modulo 𝜙, where 𝜙 = 𝑥 <sup>𝑛</sup> + 1 (𝑛
    is typically 512 or 1024). The signer then uses the secret lattice basis (𝑓 ,
    𝑔, 𝐹 , 𝐺) to produce a pair of short polynomials (𝑠1, 𝑠2) such that 𝑠1 = 𝑐 − 𝑠2ℎ
    mod 𝜙 mod 𝑞 (where ℎ = 𝑔/𝑓 and 𝑞 = 12289) and 𝑠<sup>2</sup> is the signature.
    The verifier needs to recompute 𝑠<sup>1</sup> from 𝑐 and 𝑠<sup>2</sup> and verify
    that (𝑠1, 𝑠2) is an appropriately short vector.


    SPHINCS<sup>+</sup> : It is the only stateless hash-based PQC cryptosystem that
    has been standardized to avoid relying only on the security of lattices for signatures.
    Depending on the hash function that


    -


    SPHINCS<sup>+</sup> is instantiated with, there are three different schemes: SPHINCS
    + -SHAKE256, SPHINCS<sup>+</sup> SHA-256, and SPHINCS<sup>+</sup> -Haraka. SPHINCS<sup>+</sup>
    is constructed using a Merkle tree structure where its leaves are the hash values
    of the message to be signed. First, the public and private keys are generated
    using a deterministic algorithm that takes a seed of length 𝑛 as input. SPHINCS<sup>+</sup>
    iteratively hashes and concatenates the leaf values with the intermediate values
    of the Merkle tree until the root value is obtained. The root value is then signed
    using the private key to generate the signature.


    BIKE: BItFlipping Key Encapsulation, or BIKE, may be regarded as the utilization
    of quasicyclic moderate density parity check (QC-MDPC) codes to instantiate the
    McEliece cryptosystem, using the equivalent Niederreiter scheme. BIKE has three
    different variants targeting two different security properties: Chosen plaintext
    attacks (CPA) and chosen ciphertext attacks (CCA) security. The key generation
    is almost identical in both the PKE and KEM processes. First, the secret key 𝑠𝑘
    is formed by two low-weight vectors ℎ<sup>0</sup> and ℎ<sup>1</sup> of length
    𝑟 that are uniformly picked from a secret key space 𝐻<sup>𝑤</sup> (a value 𝜎 is
    also used in case there is an error in the decapsulation KEM process). Then, the
    public key is computed as ℎ = ℎ1ℎ<sup>0</sup> − 1. For the PKE encryption process,
    the plaintext is represented by the sparse vector (𝑒0, 𝑒1), and the ciphertext
    by its syndrome 𝑠 obtained by following 𝑠 = 𝑒<sup>0</sup> + 𝑒<sup>1</sup> · ℎ.
    To decrypt it, a Black-Gray-Flip (BGF) decoder, which is defined in [2], is used
    to obtain the plaintext such as 𝐷𝑒𝑐𝑜𝑑𝑒𝑟(𝑠 · ℎ0, ℎ0, ℎ1). In the KEM encapsulation
    process, a random bitstring 𝑚 is selected and hashed, obtaining an error vector
    (𝑒0, 𝑒1) of weight 𝑡. A ciphertext 𝑐 is then calculated in two parts such as𝑐
    = (𝑒<sup>0</sup> +𝑒<sup>1</sup> ·ℎ,𝑚 ⊕𝐿(𝑒0, 𝑒1)), where 𝐿 is a hash function.
    Lastly, a shared key 𝐾 is obtained by hashing𝑚 and 𝑐. In the KEM decapsulation
    process, the shared key is obtained by using 𝑐 and 𝑠𝑘. First, an error vector
    𝑒 ′ is obtained by 𝑒 ′ = 𝐷𝑒𝑐𝑜𝑑𝑒𝑟( (𝑒0+𝑒1ℎ)ℎ0,ℎ0, ℎ1). Then, 𝑚′ = (𝑚 ⊕ 𝐿(𝑒0, 𝑒1))
    ⊕ 𝐿(𝑒 ′ ); if 𝑒 ′ matches 𝐻(𝑚) then 𝐾 is 𝐾(𝑚′ , 𝑐), otherwise 𝐾 is 𝐾(𝜎, 𝑐).


    Classic McEliece: It is a code-based cryptosystem based on binary Goppa codes
    and is widely regarded as secure. However, its large public key size is not desirable.
    McEliece generates a pair of keys using a code subspace dimension 𝑚, a maximum
    number of errors that can be corrected 𝑡, and a code length 𝑛. The private key
    consists of a monic irreducible polynomial called the Goppa polynomial with degree
    𝑡, which is generated randomly and all its coefficients are elements of a finite
    field 𝐺𝐹 (2 <sup>𝑚</sup>). The public key is obtained by constructing a control
    matrix 𝐻 based on the private key, permutating it using a random permutation matrix
    𝑃, and transforming it into a systematic form 𝐺. To encode a plaintext message
    𝑝, a random error vector 𝑒 of length 𝑛 and weight 𝑡 is created and the ciphertext𝑐
    is calculated as𝑐 = 𝑝 ·𝐺 ⊕ 𝑒. To decode the ciphertext, the error vector 𝑒 is
    first located using an error locator polynomial 𝜎(𝑥) and then the original plaintext
    is reconstructed.


    HQC: Hamming Quasi-Cyclic, or HQC, is an efficient encryption scheme based on
    coding theory. To have smaller keys than other code-based cryptosystems, HQC uses
    two different types of codes: A decodable [𝑛, 𝑘] code 𝐶 with a fixed generator
    matrix 𝐺 ∈ 𝐹 𝑘×𝑛 2 and error correction capability based on concatenated Reed-Muller
    and Reed-Solomon codes, and a random doublecirculant [2𝑛, 𝑛] code with a parity
    check matrix ℎ. In the key generation for both PKE and KEM, the parity check matrix
    ℎ in 𝑅 is generated and the secret key 𝑠𝑘 is created using polynomials 𝑥 and 𝑦
    in 𝑅 2 . Next, the public key 𝑝𝑘 is set such as 𝑝𝑘 = (𝐻, 𝑠 = 𝑥 +𝐻 ·𝑦). In the
    KEM process, three hash functions, named 𝐺, 𝐾, and 𝐻, are required. To encapsulate
    any random generated message 𝑚, the randomness 𝜃 for the encryption is first derived
    by 𝐺(𝑚). Then, a ciphertext𝑐 is generated by encrypting 𝑚 using 𝑝𝑘 and 𝜃. Lastly,
    a symmetric key 𝐾 is derived such as 𝑘 = 𝐾(𝑚, 𝑐) and the other party receives
    (𝑐, 𝑑), where 𝑑 = 𝐻(𝑚). To decapsulate,𝑐 is decrypted using 𝑠𝑘, obtaining 𝑚′ .
    To verify the integrity of 𝑐, 𝑚′ is re-encrypted using 𝜃 ′ , obtain another ciphertext𝑐
    ′ . If 𝑐 ′ matches 𝑐 and 𝑑 matches 𝐻(𝑚′ ), then 𝐾(𝑚, 𝑐) is the shared key. On
    the other hand, in the PKE process,


    | Algorithm       | Security<br>level | 𝑠𝑘 size<br>(bytes) | 𝑝𝑘 size<br>(bytes)
    | 𝑐𝑡 size<br>(bytes) | 𝑠𝑠 size<br>(bytes) | Other Parameters                          |

    |-----------------|-------------------|--------------------|--------------------|--------------------|--------------------|-------------------------------------------|

    | Kyber-512       | 1                 | 1,632              | 800                |
    768                | 32                 | 𝑛 = 256; 𝑘 = 2; 𝑞 = 3,329                 |

    | Kyber-768       | 3                 | 2,400              | 1184               |
    1088               | 32                 | 𝑛 = 256; 𝑘 = 3; 𝑞 = 3,329                 |

    | Kyber-1024      | 5                 | 3,168              | 1568               |
    1568               | 32                 | 𝑛 = 256; 𝑘 = 4; 𝑞 = 3,329                 |

    | BIKE-1          | 1                 | 2,244              | 12,323             |
    12,579             | 32                 | 𝑟 = 12,323; 𝑤 = 142; 𝑡 = 134              |

    | BIKE-3          | 3                 | 3,346              | 24,659             |
    24,915             | 32                 | 𝑟 = 24,659; 𝑤 = 206; 𝑡 = 199              |

    | BIKE-5          | 5                 | 4,640              | 40,973             |
    41,229             | 32                 | 𝑟 = 40,973; 𝑤 = 274; 𝑡 = 264              |

    | mceliece348864  | 1                 | 6,492              | 261,120            |
    96                 | 32                 | 𝑚 = 12; 𝑛 = 3,488; 𝑡 = 64                 |

    | mceliece460896  | 3                 | 13,608             | 524,160            |
    156                | 32                 | 𝑚 = 13; 𝑛 = 4,608; 𝑡 = 96                 |

    | mceliece6688128 | 5                 | 13,932             | 1,044,992          |
    208                | 32                 | 𝑚 = 13; 𝑛 = 6,688; 𝑡 = 128                |

    | mceliece6960119 | 5                 | 13,948             | 1,047,319          |
    194                | 32                 | 𝑚 = 13; 𝑛 = 6,960; 𝑡 = 119                |

    | mceliece8192128 | 5                 | 14,120             | 1,357,824          |
    208                | 32                 | 𝑚 = 13; 𝑛 = 8,192; 𝑡 = 128                |

    | hqc-128         | 1                 | 40                 | 2,249              |
    4,481              | 64                 | 𝑛1 = 46; 𝑛2 = 384;<br>𝑛 = 17,669; 𝑤
    = 66  |

    | hqc-192         | 3                 | 40                 | 4,522              |
    9,026              | 64                 | 𝑛1 = 56; 𝑛2 = 640;<br>𝑛 = 35,851; 𝑤
    = 100 |

    | hqc-256         | 5                 | 40                 | 7,245              |
    14,469             | 64                 | 𝑛1 = 90; 𝑛2 = 640;<br>𝑛 = 57,637; 𝑤
    = 131 |


    Table 2. Parameters of different post-quantum PKE/KEM algorithms


    Parameters for Kyber: 𝑛 is the polynomial length; 𝑘 is the size of polynomial
    vectors; 𝑞 is the prime modulus, BIKE: 𝑟 is the block size; 𝑤 is the row weight;
    𝑡 is the error weight, McEliece: 𝑚 is the code subspace; 𝑛 is the code length;
    𝑡 is the guaranteed error-correction capability, HQC: 𝑛<sup>1</sup> is the Reed-Solomon
    code length; 𝑛<sup>2</sup> is the Reed-Muller code length; 𝑛 is the vectors dimension;
    𝑤 is the vectors weight.


    vectors𝑟1, 𝑟2, and 𝑒, with a fixed hamming weight, are first sampled. Then, the
    ciphertext𝑐, which is a tuple 𝑒 with 𝑢 = 𝑟<sup>1</sup> + ℎ · 𝑟<sup>2</sup> and
    𝑣 = 𝑚𝐺 + 𝑠 · 𝑟<sup>2</sup> + 𝑒, is calculated. To decrypt 𝑐 and obtain the original
    message 𝑚, the term 𝑣 − 𝑢 · 𝑦 is decoded.


    #### 3 SCA AGAINST POST-QUANTUM ALGORITHMS AND COUNTERMEASURES


    This section evaluates some of the most up-to-date works on SCAs and respective
    countermeasures. Tables 2 and 3 show the different PQC scheme variants depending
    on their parameters.


    As previously mentioned, there are two types of attacks: Passive attacks and active
    attacks, also known as invasive attacks. For both types of attacks, the adversary
    needs to have access to the actual device where the cryptographic implementation
    is taking place. Once the adversary has access to the system, they can passively
    observe and analyze different leakages or actively influence it and evaluate their
    effects as shown in Fig. 1. In the following subsections, we summarize first the
    most common types of SCAs,


    Table 3. Parameters of different post-quantum signature algorithms.


    | Algorithm         | Security<br>level | 𝑝𝑘 size<br>(bytes) | signature<br>size
    (bytes) | Other parameters       |

    |-------------------|-------------------|--------------------|---------------------------|------------------------|

    | Dilithium2        | 2                 | 1,312              | 2,420                     |
    𝑛 = 256; 𝑞 = 8,380,417 |

    | Dilithium3        | 3                 | 1,952              | 3,293                     |
    𝑛 = 256; 𝑞 = 8,380,417 |

    | Dilithium5        | 5                 | 2,592              | 4,595                     |
    𝑛 = 256; 𝑞 = 8,380,417 |

    | FALCON-512 I      | 1                 | 897                | 666                       |
    𝑛 = 512; 𝑞 = 12,289    |

    | FALCON-1024 V     | 5                 | 1,793              | 1,280                     |
    𝑛 = 1,024; 𝑞 = 12,289  |

    | SPHINCS+<br>-128s | 1                 | 32                 | 7,856                     |
    𝑛 = 16; ℎ = 63; 𝑑 = 7  |

    | SPHINCS+<br>-128f | 1                 | 32                 | 17,088                    |
    𝑛 = 16; ℎ = 66; 𝑑 = 22 |

    | SPHINCS+<br>-192s | 3                 | 48                 | 16,224                    |
    𝑛 = 24; ℎ = 63; 𝑑 = 7  |

    | SPHINCS+<br>-192f | 3                 | 48                 | 35,664                    |
    𝑛 = 24; ℎ = 66; 𝑑 = 22 |

    | SPHINCS+<br>-256s | 5                 | 64                 | 29,792                    |
    𝑛 = 32; ℎ = 64; 𝑑 = 8  |

    | SPHINCS+<br>-256f | 5                 | 64                 | 49,856                    |
    𝑛 = 32; ℎ = 68; 𝑑 = 17 |


    Parameters for Dilithium: 𝑛 is the ring degree; 𝑞 is the prime modulus, FALCON:
    𝑛 is the ring degree; 𝑞 is the prime modulus, McEliece:𝑛 is the size of the hash
    output and the WOTS<sup>+</sup> and FORS signatures; ℎ is the height of each Merkle
    tree (determines the number of WOTS<sup>+</sup> signatures per layer); 𝑑 is the
    depth of the hypertree.


    then we discuss the most well-known countermeasures, and lastly, we present different
    SCA attacks found in the literature and several countermeasures against them for
    each PQC algorithm.


    #### 3.1 Types of SCAs and Countermeasures


    As mentioned previously, there are many types of SCAs and they can be either active
    or passive. Most of the current research focuses on passive differential power
    analysis (DPA) by analyzing the power consumption during one or multiple operations
    and active differential fault analysis (DFA); however, there are some other attacks
    that need to be considered, e.g., deep-learning-based SCAs to analyze patterns
    from the information extracted, and also timing/cache/algebraic/electromagnetic
    attacks. Profiling attacks entail the attacker possessing prior knowledge of the
    cryptosystem''s implementation for training and testing before the attack. Conversely,
    non-profiling attacks are characterized by the attacker''s lack of knowledge about
    the cryptosystem''s implementation, making them more challenging to execute than
    profiling attacks.


    Robust and adaptive countermeasures are essential for secure data communication
    against SCAs.


    These countermeasures can be implemented as either software-based solutions for
    passive SCAs or hardware-based implementations for active SCAs such as fault detection.
    Passive SCA countermeasures rely on obfuscating sensitive information via masking
    or shuffling to avoid any correlation between the plaintext data and the information
    leaked through power consumption, electromagnetic emissions, or timing variations.
    The software-based countermeasures include 1) Algorithmic modifica-


    ![](_page_5_Figure_5.jpeg)


    Fig. 1. SCA representation.


    tions, such as masking and blinding techniques, 2) Compiler-based modifications
    that obfuscate code order, and 3) Code obfuscation to create incoherence. Hardware-based
    countermeasures concentrate on physically securing the cryptographic algorithms
    against active SCA by adopting techniques such as power and electromagnetic shielding
    (threshold implementation) and error detection/correction codes to identify fault
    injections. Another effective strategy against SCAs involves increasing the system''s
    entropy.


    ### 3.2 CRYSTALS-Kyber SCAs and Countermeasures


    CRYSTALS-Kyber is the only PKE/KEM standardized in the PQC NIST competition and
    thus, one of the most evaluated and tested against SCAs. Carrera et al. [3] propose
    a non-profiled correlation electromagnetic analysis against a field programmable
    gate array (FPGA) implementation of Kyber-512, recovering the secret subkeys with
    a success rate of 100%, given the knowledge of register reference values (not
    full knowledge). Ji et al. [4] demonstrate a successful message (session key)
    recovery by using a profiling SCA, in particular a deep learning-based power analysis
    on a hardware implementation of Kyber768. All messages with the same enumeration
    were recovered due to their novel method called sliced multi-bit error injection.


    Some other attacks target specific building blocks or operations. In 2017, Primas
    et al. [5] presented the first single-trace attack on lattice-based encryption,
    claiming that a single side-channel observation is needed for full key recovery.
    This attack targets the NTT building block, which is part of the CRYSTALS-Kyber
    cryptosystem. Xu et al. [6] also targeted the NTT computation and proposed adaptive
    electromagnetic SCAs with carefully constructed ciphertexts, extracting the full
    secret key with between 8 and 960 traces. Pessl and Primas [7] changed the target
    to encryption to increase the single-trace attack performance. They implemented
    a successful attack against


    CRYSTALS-Kyber on an ARM Cortex M4 microcontroller assembly-optimized and designed
    to operate in constant time. Ravi et al. targeted the message decoding by proposing
    electromagnetic emanation-based SCAs and fault injection attacks [8].


    Dubrova et al. [9] perform deep learning-based message recovery attacks against
    CRYSTALS-Kyber using a new neural network training method called recursive learning.
    To train such neural networks, in the profiling stage, 30K power traces were collected
    from the decapsulation process of different ciphertexts for the same KEM pair
    and with a known keypair. The results showed that recovering a message bit from
    a single trace of a first-order masked implementation without cyclic rotations
    has a probability of 0.127%, but with cyclic rotations, the percentage increases
    to 87%. Furthermore, works [10, 11] present side-channel assisted message recovery
    attacks against CRYSTALS-Kyber to demonstrate that secret key recovery is possible
    in shuffled and masked implementations.


    In terms of active attacks (even though some previous works involved some fault
    injection), Espitau et al. [12] presented loop-abort faults on several lattice-based
    cryptosystems including CRYSTALS-Kyber. In this attack, a fault is injected into
    the cryptosystem causing a loop that samples random Gaussian secret coefficients
    to abort prematurely. This premature abortion results in the generation of abnormally
    low-dimensional secrets, which can be exploited to carry out a key recovery attack.
    However, the actual attack was not carried out for CRYSTALS-Kyber. In 2021, Pessl
    and Prokop [13] presented an attack requiring a single instruction-skipping fault
    in the decoding process. Through fault simulations, they demonstrated that a minimum
    of 6,500 faulty decapsulations are necessary to completely recover the key for
    Kyber512 running on a Cortex M4. Pessl and Prokop claimed that shuffling may make
    their attack unsuccessful. Therefore, in the same year, Hermelink et al. [14]
    use a combination of fault injections with chosen-ciphertext attacks against CRYSTALS-Kyber
    claiming that their attack may not be mitigated by shuffling the decoder. Their
    results show a successful secret key recovery with 7,500 inequalities for Kyber-512,
    10,500 inequalities for Kyber-768, and 11,000 inequalities for Kyber-1024. A year
    later, Delvaux [15] overhauled the SCA from [14] to make it easier to perform
    and harder to protect against by following four different strategies: Enlargement
    of the attack surface; relaxation of the fault model; applying masking and blinding
    methods; and accelerating and improving the error tolerance of solving the system
    of linear inequalities.


    Several SCA countermeasures have been proposed and a few of them have been implemented.
    Masking is one of the most common forms of protecting CRYSTALS-Kyber against SCAs,
    especially DPA attacks [16, 17, 18, 19]. Schneider et al. [16] introduce a secure
    binomial sampler that can provide protection against SCAs at any order. This is
    achieved through a Boolean and arithmetic (B2A) masking scheme conversion for
    prime moduli, suitable for CRYSTALS-Kyber. In [17], Bache et al. develop a more
    efficient higher-order masking scheme for lattice-based schemes with prime modulus.
    The scheme is proven in a probing model and tested on an ARM Cortex-M4F microcontroller,
    taking only 1.5-2.2 𝑚𝑠 to execute and protecting first-order leakage after collecting
    1 million power traces and applying 𝑡-test methodology. Bos et al. [18] also propose
    a masking implementation for a complete CRYSTALS-Kyber decapsulation, at both
    first and higher orders. Their approaches mask a one-bit compression and decompressed
    comparison and do not detect leakage after a Test Vector Leakage Assessment (TVLA)
    of 100,000 measurements. Kamucheka et al. [19] also propose a masked pure-hardware
    implementation of Kyber-512 and obtain 1.08x and 1.06x overheads in clock cycles
    and hardware resources when hiding and masking techniques are applied.


    Howe et al. [20] propose countermeasures against SCAs that use the statistical
    characteristics of the error samples, which are either Gaussian or binomial. The
    proposed countermeasures involve conducting statistical tests to ensure that the
    samplers are functioning correctly and take around 85% of the overall area consumption.
    Ausmita et al. [21] introduce new error detection schemes based on recomputing
    and embedded efficiently in the NTT accelerator architecture on FPGA. The results
    show a low overhead to detect close to 100% of errors. Moreover, also using recomputing,
    Cintas-Canto et al. [22] propose error detection schemes for lattice-based KEMs
    and implemented them on FPGA. Lastly, Heinz and Poppelmann [23] proposed an updated
    redundant number representation (RNR) approach to protect CRYSTALS-Kyber''s NTT
    architecture. Furthermore, a novel DFA countermeasure is derived and implemented
    using the Chinese Remainder Theorem (CRT). These techniques aim to protect the
    arithmetic operations of lattice-based cryptosystems and obtained a 2.2x computational
    overhead when applied to one execution of NTT of the Kyber-768 decryption process.


    #### 3.3 CRYSTALS-Dilithium SCAs and Countermeasures


    As we have seen for CRYSTALS-Kyber, the NTT architecture is a point of vulnerability
    against SCAs, especially DPA. While some works explore attacks on the NTT building
    block of specific cryptosystems, e.g., CRYSTALS-Kyber, they might apply to other
    lattice-based cryptosystems that use NTT such as CRYSTALS-Dilithium and FALCON.
    In [24], Steffen et al. presented the first power SCAs of CRYSTALS-Dilithium in
    reconfigurable hardware which include: Several profiled simple power analyses
    on Dilithium-2 and Dilithium-5 targeting the decoding and first NTT stage; and
    a correlation power analysis attack on the polynomial multiplication. The former
    had a 94.2% success probability to recover the correct coefficient when using
    single-trace attacks; successfully recovered the target coefficient with 50,000
    profiling traces when using multi-trace attacks on decoding; and was capable of
    full key recovery with 350,000 profiling traces when using multitrace attacks
    on first NTT stage. In regards to the CPA attack, they successfully recovered
    secret coefficients with 66,000 traces.


    Before such research, other works on DPA against CRYPTALS-Dilithium were investigated.
    In [25], Ravi et al. proposed a power analysis attack on the polynomial multiplier
    in CRYPTALS-Dilithium''s signing process, successfully retrieving a part of the
    secret key. Next, Karabulut et al. [26] proposed a single-trace SCA on 𝜔-small
    polynomial sampling software that reduces the challenge of polynomial''s entropy
    for CRYSTALS-Dilithium between 39 to 60 bits. The experiment was done using ARM
    Cortex-M4F. In the same year, Marzougui et al. [27] proposed an end-to-end (equivalent)
    key recovery attack on CRYSTALS-Dilithium based on a profiling-based power analysis
    attack combined with machine learning. The process only runs sections of the signature
    process and collects only the relevant power trace snippet to increase the attack
    efficiency, recovering the secret key after tracing the unpack polynomial function
    for 756,589 signatures.


    In 2018, Bruinderink and Pessl [28] presented a DFA attack on deterministic lattice
    signatures, which included CRYSTALS-Dilithium. By using linear algebra and lattice-basis
    reduction techniques, they show that a single random fault in the signing process
    can lead to a scenario of nonce-reuse (enabling key recovery) and that 65.2% of
    CRYSTALS-Dilithium''s execution time is susceptible to an unprofiled attack. A
    year later, also pointing out the determinism in lattice-based signatures, Ravi
    et al. [29] performed skip-addition fault attacks targeting the signing operation
    to extract a portion of the secret key. Additionally, they introduced a novel
    forgery method, enabling an attacker to sign any message using only that portion
    of the secret key. In [29], the authors also present a zero-cost mitigation strategy
    based on re-ordering the operations within the signing procedure to defend CRYSTALS-Dilithium
    against their attack, which increases the attack''s time and effort complexity
    by a 2<sup>20</sup> .


    Other CRYSTALS-Dilithium SCA countermeasures are found in [30, 20, 24]. Although
    there are no specific countermeasures for the CRYSTALS-Dilithium cryptosystem
    in [30], Bindel et al. mentioned several countermeasures such as masking, switching
    the order of operands, or storing the


    result of the addition in a variable different from the operands, applicable to
    several lattice-based signature schemes. Howe et al. [20], as mentioned earlier,
    propose fault attack countermeasures based on statistical tests for error samplers,
    which are designed to introduce noise and hide computations on secret information.
    The work of Steffen et al. [24] also presents different countermeasures based
    on arithmetic masking and integration of decoding into the first NTT stage, being
    able to protect the CRYSTALS-Dilithium cryptosystem from the attack previously
    mentioned.


    ## 3.4 FALCON SCAs and Countermeasures


    While several works perform SCAs against the Gaussian sampling algorithms used
    in FALCON, there are not too many specific attacks against the FALCON cryptosystem.
    In 2019, McCarthy et al. [31] proposed the first fault attack on the FALCON signature
    scheme, using a Basis Extraction by Aborting Recursion or Zeroing (BEARZ) technique.
    Through this attack, it is shown that FALCON is vulnerable to fault attacks on
    its Gaussian sampler and the output can reveal the private key. Moreover, three
    different countermeasures are proposed in [31]: Computing the signature twice,
    running the verification process immediately after signing, and applying a zero-check
    scheme, where the sampled vector is checked that does not go to zero at some point
    along its length at the end of the 𝑓 𝑓 𝑆𝑎𝑚𝑝𝑙𝑒𝑟 algorithm. The latter is proven
    to be the more successful against the SCAs carried in their work.


    A year later, Fouque et al. [32] pinpoint a particular timing leakage in the FALCON
    implementations, employing algebraic number theoretic techniques to retrieve the
    secret key. Such key retrieval transpires as a result of information exposure
    regarding the Gram-Schmidt norm, a crucial component for converting a group of
    linearly independent vectors into an orthonormal basis within the FALCON encryption
    system. The Gram-Schmidt process inherently reveals certain numerical properties
    of the original vectors allowing the full recovery of the secret key in FALCON-512.


    Karabulut and Aysu [33] propose an electromagnetic attack on the FALCON-512 cryptosystem
    to extract the secret signing keys by targeting the floating-point multiplications
    within FALCON''s Fast Fourier Transform. Their extend-and-prune strategy extracts
    the sign, mantissa, and exponent variables without false positives; showing that
    ~10k measurements are enough to reveal the secret key. Guerreau et al.[34] improve
    the attack of [33] in 2022 by exploiting the fact that the polynomial coefficients
    are integers. This leads to a reduction of the amount of traces needed (~5,000
    traces) for full key recovery. Additionally, they propose a practical but computationally
    expensive power analysis of FALCON''s Gaussian sampling algorithm, applying a
    parallelepiped-learning attack and needing ~10<sup>6</sup> traces for full key
    recovery in FALCON-512.


    Due to such expense, Zhang et al. [35] have developed several power analysis attacks
    on FAL-CON to significantly lower the requirement of measurements and computation
    resources from [34]. For the first attack, they discovered that the covariance
    of the samples in the slice, i.e., filtered signatures, suffices to reveal the
    secret, needing 220,000 traces instead of 10<sup>6</sup> . Moreover, they perform
    a practical power analysis targeting the integer Gaussian sampler of FALCON, relying
    on the leakage of random sign flip within the integer Gaussian sampling. This
    allows practical key recovery of FALCON-512 with 170,000 traces.


    In terms of SCAs countermeasures, besides [31] and [34], which briefly discuss
    a small modification of the C code to practically lower the Hamming weight gap,
    Sarker et al. [36] provide error detection schemes based on recomputing for FALCON''s
    sampler. Such schemes can detect close to 100% of the errors induced in the Gaussian
    sampler.


    # 3.5 SPHINCS<sup>+</sup> SCAs and Countermeasures


    SPHINCS<sup>+</sup> is the third and last PQC signature algorithm that has been
    standardized. The majority of SPHINCS<sup>+</sup> SCAs have been active attacks,
    and research has found that SPHINCS<sup>+</sup> is the most sensitive to fault
    attacks [37, 38, 40]. Castelnovi et al. proposed the first fault attack on the
    foundation of the SPHINCS<sup>+</sup> cryptosystem [37]. This two-phase attack
    allows the forgery of any message signature with just one faulty message. The
    first stage, known as the faulting phase, involves requesting two signatures for
    the same message. During the computation of the second signature, a fault is induced,
    causing a one-time signature (OTS) within the SPHINCS framework to sign a different
    value than previously. The subsequent stage, referred to as the grafting phase,
    demonstrates that the information from both signatures—the accurate one and the
    faulty one—can be utilized to uncover portions of the secret key from the OTS
    that experienced the fault, resulting in a partial compromise. The attacker then
    exploits this weakened OTS as a means of authenticating a distinct tree from the
    one it was intended to authenticate. The assailant generates a tree entirely under
    their control and employs the compromised OTS to graft it onto the SPHINCS tree.


    In efforts to provide a practical verification of [37], Genet et al. propose the
    first practical fault attack applied on an Arduino board for SPHINCS in [38],
    showing how a low-cost injection of a single glitch is sufficient to obtain exploitable
    faulty signatures. In the same year, 2018, Amiet et al. [39] presented the first
    hardware-based implementation of SPHINCS<sup>+</sup> and a fault attack against
    such hardware implementation. Amiet et al. discovered that a fault occurring in
    WOTS<sup>+</sup> subtree computations results in an altered root node value. This
    incorrect root node is subsequently signed with the next WOTS<sup>+</sup> level,
    leaking portions of the associated WOTS<sup>+</sup> private key. Consequently,
    such work demonstrates that, through a glitch attack, gathering private data to
    forge a signature can be accomplished in a matter of seconds. Additionally, a
    countermeasure based on doubling the entire SPHINCS<sup>+</sup> coprocessor is
    proposed in [40], similar to the recomputing approach suggested by [9]. Kannwischer
    et al. entirely exclude fault injection attacks to analyze the DPA vulnerability
    of XMSS and SPHINCS [40], and show a practical attack on the BLAKE-256-based PRF
    used within SPHINCS-256. Other works exclusively focus on providing SCA countermeasures
    for SPHINCS<sup>+</sup> cryptosystem [41, 42, 43]. Mozaffari-Kermani et al. [41,
    42] propose reliable and error detection hash trees for stateless hash-based signatures
    suitable to SPHINCS<sup>+</sup> . Their work presents two different approaches:
    Recomputing with swapped nodes (RESN) in the hash-tree constructions and combined
    signatures, and recomputing with encoded operands (REEO) for ChaCha, which is
    a stream cipher that SPHINCS uses for deriving two hash functions. The schemes
    detected close to 100% transient and permanent faults, adding up to 14.6% degradation
    overhead on applicationspecific integrated circuit (ASIC). The issue with these
    countermeasures is that they do not cover the entire SPHINCS<sup>+</sup> signing
    procedure. With this in mind, Genet [43] introduces a fault attack countermeasure
    based on caching the intermediate W-OTS<sup>+</sup> . However, this approach is
    useful for stateful schemes such as XMSS𝑀𝑇 but not for stateless schemes such
    as SPHINCS<sup>+</sup> . Therefore, recomputing schemes are suggested to be used
    to protect SPHINCS<sup>+</sup> against fault attacks [43].


    ## 3.6 BIKE SCAs and Countermeasures


    BIKE can be described as the McEliece scheme instantiated with QC-MDPC codes.
    In 2016, Guo et al. [44] introduced an attack using a recognized correlation between
    error patterns in decoding failures and the secret key, under the assumption that
    the scheme operates in a static key environment needing IND-CCA security. Such
    attack is implemented for 80-bit security QC-MDPC scheme, recovering the key in
    minutes. Two years later, an error amplification attack, built on the previous
    attack, is proposed [45]. This attack improves it by using just a single initial
    error vector,


    which leads to a decoding failure. It then adjusts this vector to efficiently
    produce numerous additional error vectors that also result in decoding failures.
    However, the attacks from [44, 45] can be avoided by stronger parameters.


    A more recent generic power/electromagnetic attack based on the Fujisaki–Okamoto
    (FO) transformation and its variants are proposed by Ueno et al. in [46]. This
    attack exploits side-channel leakage during the non-protected pseudorandom function
    (PRF) execution in the re-encryption of the KEM decapsulation and can be applied
    to CRYSTALS-Kyber, HQC, and BIKE.


    Since none of these attacks considered the non-constant time rejection sampling
    routine, which BIKE and HQC use to generate random vectors with a specific Hamming
    weight, Guo et al. [47] propose two novel timing attacks against BIKE and HQC
    achieving full secret key recovery. These attacks examine the time discrepancies
    caused by rejection sampling, as they could reveal whether the input message to
    the deterministic re-encryption process (or a hash function) in the IND-CCA transformation
    remains unaltered. Possessing such secret information is sufficient for retrieving
    the secret key of BIKE and HQC schemes. To fix the non-isochronous design of BIKE,
    Sendrier [48] replaces the rejection sampling in the encapsulation and the decapsulation
    with an algorithm that has no rejection, generating a non-uniform distribution
    of the indices. Additionally, Drucker et al. [49] propose to use the fixed sampling
    number (FSN) version of the errors-vector generation (EVG), with some predetermined
    value of X. This value does not change the required uniform distribution property
    of the generated errors-vector.


    Chou et al. [50] also propose a constant-time implementation for QC-MDPC code-based
    cryptography to counter timing attacks. Nevertheless, this countermeasure was
    later identified as susceptible to a DPA in private syndrome computation [51],
    although the attack was unable to fully retrieve the correct secret indices. Thus,
    Sim et al. [52] enhance existing multiple-trace attacks on timing attack countermeasures
    and propose a novel single-trace attack, which allows to recover secret indices
    even when using ephemeral keys or DPA countermeasures.


    #### 3.7 McEliece SCAs and Countermeasures


    Timing attacks are one of the first SCAs carried on the McEliece cryptosystem
    [53, 54, 55]. Strenzke et al. [53] present a timing attack on the degree of the
    error locator polynomial, which is executed successfully against a software implementation
    of the McEliece cryptosystem. Therefore, raising its degree artificially is proposed
    as a countermeasure. Avanzi et al. improve the timing attack from [53] with a
    setup stage that involves profiling the algorithm for all correctable error weights,
    followed by an iterative procedure that approximates the random error vector.
    Additionally, a "non-support" countermeasure is proposed. In [54], Shoufan et
    al. propose a timing attack against the Patterson algorithm in the McEliece cryptosystem.
    In [56], Lahr et al. adapt the side-channel attack from [54] and perform an electromagnetic
    attack using a reaction-based attack combined with a technique that they call
    iterative chunking. This method allows them to progressively increase the quantity
    of discovered error positions (chunks) within a single (cumulative) query. Such
    attack is performed on a microcontroller targeting the matrix-vector multiplication
    of the encryption process and recovering the message from one faulty syndrome
    and the public key. A practical evaluation of the attack is performed on FPGA
    and it is shown that ~560 measurements are sufficient to mount a successful plaintext
    recovery attack. Moreover, Strenzke [55] develops a strategy how to exploit a
    vulnerability in the Patterson algorithm, enabling the attacker to obtain information
    about the secret permutation via a timing side channel.


    Not only timing attacks have been studied, but also fault injection attacks [57,
    58, 59], power analysis attacks [60, 61], and message-recovery attacks [62]. In
    [57], Cayrel and Dusart present a fault injection attack on different variables
    of the McEliece schemes and the possible outcomes are discussed; however, no implementation
    is performed. A few years later, Cayrel et al. [58] perform a message-recovery
    laser fault injection attack targeting the syndrome decoding problem on the Classic
    McEliece cryptosystem. Several experiments are conducted on a 6-core CPU clocked
    at 2.8 GHz and 32 GB of RAM desktop computer to validate the success of the attack,
    which show the secret message can be retrieved in less than three seconds. Pircher
    et al. [59] recently introduced a key-recovery fault injection attack targeting
    the Goppa code''s error-locator polynomial and the decryption algorithm''s validity
    checks, thus making a chosen ciphertext attack feasible.


    When considering power analysis attacks, Molter et al. [60] introduced a simple
    SCA on a McEliece cryptoprocessor using power analysis. This FPGA-based attack
    exploits an information leak resulting from the correlation between the error
    vector weight and the number of iterations in the extended Euclidean algorithm
    used in the Patterson Algorithm (as in [54]). In a separate study, Guo et al.
    [61] formulated an attack algorithm where unique ciphertexts, corresponding to
    single-error cases, are submitted to the decryption oracle. Decoding these ciphertexts
    involves only a single entry in an extensive secret permutation, which forms part
    of the secret key. By identifying a leak in the additive FFT step, which is used
    to evaluate the error locator polynomial, it is possible to determine a single
    entry of the secret permutation. Repeating this process for other entries results
    in full secret key recovery. The attack employs power analysis on FPGA and ARM
    Cortex-M4, alongside a machine-learning-based classification algorithm to identify
    the error locator polynomial from a single trace. The findings show that full
    key recovery can be achieved with less than 800 traces. Lastly, in [62], Colombier
    et al. conduct a side-channel attack by analyzing power consumption during the
    matrix-vector multiplication phase of the encryption process.


    Other SCA countermeasures are discussed in [63, 64, 65, 66, 67, 68, 69]. The simple
    power analysis countermeasure proposed in [63] is based on avoiding branch statements
    and data-dependent timing on the implementation of the McEliece cryptosystem.
    This countermeasure is tested on an ARM Cortex-M3, preventing simple power analysis
    and timing attacks but increasing the latency by a factor of 3. In [64, 65], natural
    and injected fault detection schemes based on CRC and cyclic codes are proposed,
    respectively. These schemes target the finite field multipliers used in codebased
    cryptosystems such as Classic McEliece and are implemented on FPGA detection close
    to 100% faults. Moreover, Cintas-Canto et al. present error detection schemes
    based on single parity, interleaved parity, CRC, and Hamming codes for the 𝐺𝐹
    (2 <sup>𝑚</sup>) inversion block [66, 67] and composite field arithmetic architectures
    [68] that the McEliece cryptosystem employs. Additionally, fault detection schemes
    based on CRC are proposed for the different blocks of the McEliece key generator
    in [69]. After being implemented on FPGA, the schemes detected close to 100% of
    faults and added a worst-case area and delay overhead of 49%.


    ## 3.8 HQC SCAs and Countermeasures


    Some BIKE SCAs are applicable to the HQC cryptosystem since they share some operational
    architectures. One example of this is the work of Guo et al. [47], which as it
    was mentioned before, proposes two novel timing attacks against BIKE and HQC achieving
    full secret key recovery. Another timing attack is presented in [70] by Huang
    et al., in which a cache-timing-based distinguisher for implementing a plaintext-checking
    (PC) oracle is presented. This PC oracle employs side-channel information to verify
    whether a given ciphertext decrypts to a specific message. Furthermore, a practical
    attack is presented on an HQC execution on Intel SGX, necessitating an average
    of 53,857 traces for complete key recovery. This attack demands significantly
    fewer PC oracle calls than Guo et al.''s timing attack in [47].


    Apart from timing attacks, HQC has also been a target of power analysis attacks.
    In [71], Schamberger et al. propose the first power SCA on the KEM version of
    HQC. This attack uses a power side-channel to create an oracle that determines
    whether the BCH decoder in HQC''s decryption algorithm rectifies an error for
    a chosen ciphertext. Considering the decoding algorithm employed


    in HQC, it is demonstrated how to craft queries so that the oracle''s response
    enables the extraction of a significant portion of the secret key. The remaining
    part of the key can subsequently be discovered using a linear algebra-based algorithm.
    Experiments show that fewer than 10,000 measurements are enough to successfully
    execute the attack on the HQC reference implementation running on an ARM Cortex-M4
    microcontroller. Another power analysis attack is presented in [72], where the
    authors showcase a novel, proven power SCA that enables a successful power SCA
    against the updated round three version of the HQC cryptosystem (a Reed-Muller
    and Reed-Solomon version of HQC). This attack reduces the required attack queries
    of [47] by a factor of 12 and eliminates the inherent uncertainty of their employed
    timing oracle. The general idea of the attack is to choose 𝑣 such that the decoding
    result depends on 𝑦 (0) 𝑖 (where 𝑦 is the secret key polynomial), revealing its
    support. This attack is also implemented on an ARM Cortex-M4 microcontroller.
    Lastly, Goy et al. [73] introduce a new key recovery side-channel attack on HQC
    with chosen ciphertext. This attack exploits the reuse of a static secret key
    on a microcontroller, recovering the static secret key by targeting the Reed-Muller
    decoding step of the decapsulation, specifically focusing on the Hadamard transform.
    The side-channel information obtained in the function is used to build an Oracle
    that distinguishes between several decoding patterns of the Reed-Muller codes.
    Moreover, they show how to query the Oracle such that the responses give full
    information about the static secret key. Experiment results indicate that fewer
    than 20,000 electromagnetic attack traces are enough to recover the entire static
    secret key that the decapsulation uses. As a countermeasure, the authors propose
    a masking-based structure against Reed-Muller decoding distinguisher.


    # 4 CONCLUSION


    Due to the imminent threat that quantum computers pose to current public-key cryptographic
    algorithms, there has been a extensive research on PQC. This survey englobes a
    comprehensive exploration of PQC, highlighting that PQC, while designed to be
    secured against classical and quantum computers, is still vulnerable to SCAs.
    These attacks, both passive and active, are a significant risk as they facilitate
    key recovery. This review further elaborates on several forms of SCAs and countermeasures
    to mitigate them. It is evident that while advancements in PQC are significant,
    the reliability of these algorithms is greatly influenced by their vulnerability
    to SCA. Thus, the field of PQC needs ongoing research and development to ensure
    not just security from quantum computing threats, but also reliability against
    SCAs.


    ## ACKNOWLEDGEMENTS


    This work was supported by the US National Science Foundation (NSF) award SaTC-1801488.


    ## REFERENCES


    - [1] D. Moody. Post-Quantum Cryptography: NIST''s Plan for the Future. Feb. 2016.

    - [2] N. Drucker, S. Gueron, D. Kostic. QC-MDPC decoders with several shades of
    gray. PQCrypto, pp. 35-50, 2020.

    - [3] R. C. Rodriguez, F. Bruguier, E. Valea, and P. Benoit. Correlation electromagnetic
    analysis on an FPGA implementation of CRYSTALS-Kyber. Cryptology ePrint Archive,
    2022.

    - [4] Y. Ji, R. Wang, K. Ngo, and E. Dubrova. A side-channel attack on a HW implementation
    of Kyber. ETS, 2023.

    - [5] R. Primas, P. Pessl, and S. Mangard. Single-trace side-channel attacks on
    masked lattice-based encryption. CHES 2017, pp. 513-533, Springer, 2017.

    - [6] Z. Xu, O. Pemberton, S. Roy, D. Oswald, and Z. Zheng. Magnifying side-channel
    leakage of lattice-based cryptosystems with chosen ciphertexts: The case study
    of kyber. IEEE Trans. Comput., vol. 71, no. 9, pp. 2163-2176, 2021.

    - [7] P. Pessl and R. Primas. More practical single-trace attacks on the number
    theoretic transform. LATINCRYPT. vol. 6, pp. 130-149, Springer, 2019.

    - [8] P. Ravi, S. Bhasin, S. S. Roy, and A. Chattopadhyay. Drop by drop you break
    the rock-exploiting generic vulnerabilities in lattice-based PKE/KEMs using EM-based
    physical attacks. IACR Cryptology ePrint Archives, Report 549, 2020.

    - [9] E. Dubrova, K. Ngo, and J. Grtner. Breaking a fifth-order masked implementation
    of CRYSTALS-Kyber by copy-paste. Cryptology ePrint Archive, 2022.

    - [10] L. Backlund, K. Ngo, J. Grtner, and E. Dubrova. Secret key recovery attacks
    on masked and shuffled implementations of CRYSTALS-Kyber and Saber. Cryptology
    ePrint Archive, 2022.

    - [11] P. Ravi, S. Bhasin, S. S. Roy, and A. Chattopadhyay. On exploiting message
    leakage in (few) NIST PQC candidates for practical message recovery attacks. IEEE
    Trans. Information Forensics and Security, vol. 17, pp. 684-699, 2021.

    - [12] T. Espitau, P. A. Fouque, B. Gerard, and M. Tibouchi. Loop-abort faults
    on lattice-based signature schemes and key exchange protocols. IEEE Transactions
    on Computers, vol. 67, no. 11, pp.1535-1549, 2018.

    - [13] P. Pessl and L. Prokop. Fault attacks on CCA-secure lattice KEMs. IACR
    Transactions on Cryptographic Hardware and Embedded Systems, pp. 37-60, 2021.

    - [14] J. Hermelink, P. Pessl, and T. Poppelmann. Fault-enabled chosen-ciphertext
    attacks on Kyber. INDOCRYPT, pp. 311- 334. Springer, 2021.

    - [15] J. Delvaux. Roulette: A diverse family of feasible fault attacks on masked
    Kyber. Cryptology ePrint Archive, 2021.

    - [16] T. Schneider, C. Paglialonga, T. Oder, and T. Guneysu. Efficiently masking
    binomial sampling at arbitrary orders for lattice-based crypto. PKC 2019. pp.
    534-564, Springer, 2019.

    - [17] F. Bache, C. Paglialonga, T. Oder, T. Schneider, and T. Guneysu. High-speed
    masking for polynomial comparison in lattice-based KEMs. IACR Transactions on
    Cryptographic Hardware and Embedded Systems, pp. 483-507, 2020.

    - [18] J. W. Bos, M. Gourjon, J. Renes, T. Schneider, and C. V. Vredendaal. Masking
    Kyber: First-and higher-order implementations. IACR Transactions on Cryptographic
    Hardware and Embedded Systems, pp. 173-214, 2021.

    - [19] T. Kamucheka, A. Nelson, D. Andrews, and M. Huang. A masked pure-hardware
    implementation of Kyber cryptographic algorithm. ICFPT. pp. 1-9, 2022.

    - [20] J. Howe, A. Khalid, M. Martinoli, F. Regazzoni, and E. Oswald. Fault attack
    countermeasures for error samplers in lattice-based cryptography. ISCAS. pp. 1-5,
    2019.

    - [21] A. Sarker, A. Cintas-Canto, M. Mozaffari-Kermani, and R. Azarderakhsh.
    Error detection architectures for hardware/software co-design approaches of number
    theoretic transform. IEEE Transactions on Computer-Aided Design Integrated Circuits
    Systems, accepted, to appear 2023.

    - [22] A. Cintas-Canto, A. Sarker, J. Kaur, M. Mozaffari-Kermani, and R. Azarderakhsh.
    Error detection schemes assessed on FPGA for multipliers in lattice-based key
    encapsulation mechanisms in post-quantum cryptography. IEEE Transactions on Emerging
    Topics in Computing, accepted, to appear 2023.

    - [23] D. Heinz and T. Poppelmann. Combined fault and DPA protection for lattice-based
    cryptography. IEEE Transactions on Computers, 2022.

    - [24] H. Steffen, G. Land, L. Kogelheide, and T. Guneysu. Breaking and protecting
    the crystal: Side-channel analysis of Dilithium in hardware. Cryptology ePrint
    Archive, 2022.

    - [25] P. Ravi, M. P. Jhanwar, J. Howe, A. Chattopadhyay, and S. Bhasin. Side-channel
    assisted existential forgery attack on Dilithium-a NIST PQC candidate. Cryptology
    ePrint Archive, 2018.

    - [26] E. Karabulut, E. Alkim, and A. Aysu. Single-trace side-channel attacks
    on w-small polynomial sampling: with applications to NTRU, NTRU prime, and CRYSTALS-Dilithium.
    HOST, pp. 35-45, 2021.

    - [27] S. Marzougui, V. Ulitzsch, M. Tibouchi, and J. P. Seifert. Profiling side-channel
    attacks on Dilithium: A small bit-fiddling leak breaks it all. Cryptology ePrint
    Archive, 2022.

    - [28] L. G. Bruinderink and P. Pessl. Differential fault attacks on deterministic
    lattice signatures. IACR Transactions on Cryptographic Hardware and Embedded Systems,
    pp. 21-43, 2018.

    - [29] P. Ravi, M. P. Jhanwar, J. Howe, A. Chattopadhyay, and S. Bhasin. Exploiting
    determinism in lattice-based signatures: Practical fault attacks on pqm4 implementations
    of NIST candidates. ACM Asia CCS, pp. 427-440, 2019.

    - [30] N. Bindel, J. Krmer, and J. Schreiber. Hampering fault attacks against
    lattice-based signature schemes: countermeasures and their efficiency (special
    session). Hardware/Software Codesign and System Synthesis Companion, pp. 1-3,
    2017.

    - [31] S. McCarthy, J. Howe, N. Smyth, S. Brannigan, and M. O''Neill. BEARZ attack
    FALCON: implementation attacks with countermeasures on the FALCON signature scheme.
    Cryptology ePrint Archiv, 2019.

    - [32] P. A. Fouque, P. Kirchner, M. Tibouchi, A. Wallet, and Y. Yu. Key recovery
    from Gram–Schmidt norm leakage in hash-and-sign signatures over NTRU lattices.
    EUROCRYPT, pp. 34-63, Springer, 2020.

    - [33] E. Karabulut and A. Aysu. FALCON down: Breaking FALCON post-quantum signature
    scheme through side-channel attacks. DAC, pp. 691-696, 2021.

    - [34] M. Guerreau, A. Martinelli, T. Ricosset, and M. Rossi. The hidden parallelepiped
    is back again: Power analysis attacks on FALCON. IACR Transactions on Cryptographic
    Hardware and Embedded Systems, pp. 141-164, 2022.

    - [35] S. Zhang, X. Lin, Y. Yu, and W. Wang. Improved Power Analysis Attacks on
    FALCON. EUROCRYPT. pp. 565-595, Springer, 2023.


    - [36] A. Sarker, M. Mozaffari-Kermani, and R. Azarderakhsh. Efficient error detection
    architectures for post-quantum signature FALCON''s Sampler and KEM Saber. IEEE
    Trans. VLSI Systems, vol. 30, no. 6, pp. 794-802, 2022.

    - [37] L. Castelnovi, A. Martinelli, and T. Prest. Grafting trees: a fault attack
    against the SPHINCS framework. PQCrypto, Proceedings 9, pp. 165-184, Springer,
    2018.

    - [38] A. Gent, M. J. Kannwischer, H. Pelletier, and A. McLauchlan. Practical
    fault injection attacks on SPHINCS. Cryptology ePrint Archive, 2018.

    - [39] D. Amiet, L. Leuenberger, A. Curiger, and P. Zbinden. FPGA-based SPHINCS<sup>+</sup>
    implementations: Mind the glitch. DSD, pp. 229-237, 2020.

    - [40] M. J. Kannwischer, A. Gent, D. Butin, J. Krmer, and J. Buchmann. Differential
    power analysis of XMSS and SPHINCS. COSADE, pp. 168-188, Springer, 2018.

    - [41] M. Mozaffari-Kermani, R. Azarderakhsh, and A. Aghaie. Fault detection architectures
    for post-quantum cryptographic stateless hash-based secure signatures benchmarked
    on ASIC. ACM Transactions on Embedded Computing Systems, vol. 16, no. 2, pp. 59:1-19,
    2016.

    - [42] M. Mozaffari-Kermani and R. Azarderakhsh. Reliable hash trees for post-quantum
    stateless cryptographic hash-based signatures. DFTS, pp. 103-108, 2015.

    - [43] A. Gent. On protecting SPHINCS<sup>+</sup> against fault attacks. Cryptology
    ePrint Archive, 2023.

    - [44] Q. Guo, T Johansson, and P. Stankovski. A key recovery attack on MDPC with
    CCA security using decoding errors. ASIACRYPT, pp. 789-815, Springer, 2016.

    - [45] A. Nilsson, T. Johansson, and P. S. Wagner. Error amplification in code-based
    cryptography. Cryptology ePrint, 2018.

    - [46] R. Ueno, K. Xagawa, Y. Tanaka, A. Ito, J. Takahashi, and N. Homm. Curse
    of re-encryption: A generic power/em analysis on post-quantum kems. IACR Trans.
    Cryptographic Hardware and Embedded Systems, pp. 296-322, 2022.

    - [47] Q. Guo, C. Hlauschek, T. Johansson, N. Lahr, A. Nilsson, and R. L. Schrder.
    Don''t reject this: Key-recovery timing attacks due to rejection-sampling in HQC
    and BIKE. IACR Trans. CHES, pp. 223-263, 2022.

    - [48] N. Sendrier. Secure sampling of constant-weight words–application to bike.
    Cryptology ePrint Archive, 2021.

    - [49] N. Drucker, S. Gueron, and D. Kostic. To reject or not reject: That is
    the question. The case of BIKE post quantum KEM. Information Technology-New Generations,
    pp. 125-131, Springer, 2012.

    - [50] T. Chou. QcBits: constant-time small-key code-based cryptography. CHES,
    pp. 280-300, Springer, 2016.

    - [51] M. Rossi, M. Hamburg, M. Hutter, and M. E. Marson. A side-channel assisted
    cryptanalytic attack against QcBits. CHES, pp. 3-23, Springer, 2017.

    - [52] B.Y. Sim, J. Kwon, K. Y. Choi, J. Cho, A. Park, and D.-G. Han. Novel side-channel
    attacks on quasi-cyclic code-based cryptography. IACR Transactions on Cryptographic
    Hardware and Embedded Systems, pp. 180-212, 2019.

    - [53] F. Strenzke, E. Tews, H. G. Molter, R. Overbeck, and A. Shoufan. Side channels
    in the McEliece PKC. PQCrypto, pp. 216-229, Springer, 2008.

    - [54] A. Shoufan, F. Strenzke, H. G. Molter, and M. Stttinger. A timing attack
    against Patterson algorithm in the McEliece PKC. ICISC, pp. 161-175, Springer,
    2010.

    - [55] F. Strenzke. A timing attack against the secret permutation in the McEliece
    PKC.PQCrypto, pp. 95-107, Springer, 2010.

    - [56] N. Lahr, R. Niederhagen, R. Petri, and S. Samardjiska. Side channel information
    set decoding using iterative chunking: Plaintext recovery from the Classic McEliece
    hardware reference implementation. ASIACRYPT, pp. 881-910, 2020.

    - [57] P. L. Cayrel and P. Dusart. McEliece/Niederreiter PKC: Sensitivity to fault
    injection. Fut. Inf. Tech., pp. 1-6, 2010.

    - [58] P. L. Cayrel, B. Colombier, V. F. Drăgoi, A. Menu, and L. Bossuet. Message-recovery
    laser fault injection attack on the classic McEliece cryptosystem. EUROCRYPT,
    pp. 438-467, Springer, 2021.

    - [59] S. Pircher, J. Geier, J. Danner, D. Mueller-Gritschneder, and A. Wachter-Zeh.
    Key-recovery fault injection attack on the Classic McEliece KEM. Code-Based Cryptography
    Workshop, pp. 37-61, Springer, 2023.

    - [60] H. G. Molter, M. Stttinger, A. Shoufan, and F. Strenzke. A simple power
    analysis attack on a McEliece cryptoprocessor. Journal of Cryptographic Engineering
    vol. 1, pp. 29-36, 2011.

    - [61] Q. Guo, A. Johansson, and T. Johansson. A key-recovery side-channel attack
    on classic McEliece. ePrint, 2022.

    - [62] B. Colombier, V. F. Drăgoi, P. L. Cayrel, and V. Grosso. Profiled side-channel
    attack on cryptosystems based on the binary syndrome decoding problem. IEEE Trans.
    Information Forensics and Security, vol. 17, pp.3407-3420, 2022.

    - [63] M. Petrvalsky, T. Richmond, M. Drutarovsky, P. L. Cayrel, and V. Fischer.
    Countermeasure against the SPA attack on an embedded McEliece cryptosystem. RADIOELEKTRONIKA,
    pp. 462-466, 2015.

    - [64] A. Cintas-Canto, M. Mozaffari-Kermani, R. Azarderakhsh. Reliable CRC-based
    error detection constructions for finite field multipliers with applications in
    cryptography. IEEE Trans. VLSI Systems, vol. 29, no. 1, pp. 232-236, 2021.

    - [65] A. Cintas-Canto, M. Mozaffari-Kermani, and R. Azarderakhsh. Reliable architectures
    for finite field multipliers using cyclic codes on FPGA utilized in classic and
    post-quantum cryptography. IEEE Trans. VLSI Systems, vol. 1, no. 31, pp. 157-161,
    2023.

    - [66] A. Cintas-Canto, M. Mozaffari-Kermani, and R. Azarderakhsh. CRC-based error
    detection constructions for FLT and ITA finite field inversions over 𝐺𝐹 (2<sup>𝑚</sup>
    ). IEEE Trans. VLSI Systems, vol. 29, no. 5, pp. 1033-1037, 2021.

    - <span id="page-15-0"></span>[67] A. Cintas-Canto, M. Mozaffari-Kermani, and
    R. Azarderakhsh. Error detection constructions for ITA finite field inversions
    over 𝐺𝐹 (2<sup>𝑚</sup> ) on FPGA using CRC and hamming codes. IEEE Trans. Reliability,
    to appear 2023.

    - [68] A. Cintas-Canto, M. Mozaffari-Kermani, and R. Azarderakhsh. Reliable architectures
    for composite-field-oriented constructions of McEliece post-quantum cryptography
    on FPGA. IEEE Transactions on Computer-Aided Design Integr. Circuits Syst., vol.
    40, no. 5, pp. 999-1003, 2021.

    - [69] A. Cintas-Canto, M. Mozaffari-Kermani, and R. Azarderakhsh. Reliable constructions
    for the key generator of codebased post-quantum cryptosystems on FPGA. ACM Emerging
    Technologies in Computing Systems (special issue on CAD for Hardware Security),
    vol. 29, no. 1, pp. 5:1-5:20, 2023.

    - [70] S. Huang, R. Sim, C. Chuengsatiansup, Q. Guo, T. Johansson. Cache-timing
    attack against HQC. ePrint, 2023.

    - [71] T. Schamberger, J. Renner, G. Sigl, and A. Wachter-Zeh. A power side-channel
    attack on the CCA2-secure HQC KEM. CARDIS 2020, pp. 119-134, Springer, 2021.

    - [72] T. Schamberger, L. Holzbaur, J. Renner, A. Wachter-Zeh, and G. Sigl. A
    power side-channel attack on the reed-muller reed-solomon version of the HQC cryptosystem.
    PQCrypto, pp. 327-352, Springer, 2022.

    - [73] G. Goy, A. Loiseau, and P. Gaborit. A new key recovery side-channel attack
    on HQC with chosen ciphertext. PQCrypto 2022, pp. 353-371, Springer, 2022.'
  decisions:
    evaluation_prompt: 'Qualified. Reason: The paper contains a section titled "SCA
      AGAINST POST-QUANTUM ALGORITHMS AND COUNTERMEASURES" that evaluates various
      side-channel attacks (SCAs) and countermeasures on post-quantum cryptographic
      algorithms. It includes tables, figures, and references to empirical studies
      and experiments, demonstrating structured evaluation and analysis.'
    related_work_prompt: 'Qualified. Reason: The paper meaningfully engages with prior
      research throughout its content. It includes numerous academic citations, discusses
      previous work, and compares its methods and findings to existing research in
      the field of post-quantum cryptography and side-channel attacks.'
    novelty_prompt: 'Qualified. Reason: The paper provides a comprehensive survey
      on emerging security concerns in the post-quantum era, specifically focusing
      on implementation attacks and side-channel attacks (SCAs) against post-quantum
      cryptography (PQC) algorithms. It offers insights into the vulnerabilities of
      these algorithms to SCAs and discusses various countermeasures. The paper claims
      to provide forward-looking insights and discussions that can be used to scrutinize
      new standards, which indicates a novel application of known techniques in the
      context of PQC.'
    review_only_prompt: 'Disqualified: review paper. Reason: The title contains the
      word "survey," and the main body primarily summarizes existing work on post-quantum
      cryptography and side-channel attacks without introducing new methods, datasets,
      experiments, or frameworks.'
- title: 'AI for Education (AI4EDU): Advancing Personalized Education with LLM and
    Adaptive Learning'
  abstract: Recent advanced AI technologies, especially large language models (LLMs)
    like GPTs, have significantly advanced the field of data mining and led to the
    development of various LLM-based applications. AI for education (AI4EDU) is a
    vibrant multi-disciplinary field of data mining, machine learning, and education,
    with increasing importance and extraordinary potential. In this field, LLM and
    adaptive learning-based models can be utilized as interfaces in human-in-the-loop
    education systems, where the model serves as a mediator among the teacher, students,
    and machine capabilities, including its own. This perspective has several benefits,
    including the ability to personalize interactions, allow unprecedented flexibility
    and adaptivity for human-AI collaboration and improve the user experience. However,
    several challenges still exist, including the need for more robust and efficient
    algorithms, designing effective user interfaces, and ensuring ethical considerations
    are addressed. This workshop aims to bring together researchers and practitioners
    from academia and industry to explore cutting-edge AI technologies for personalized
    education, especially the potential of LLMs and adaptive learning technologies.
  keywords: 'Education, Edtech, Adaptive Learning, LLM KDD ''24, August 25–29, 2024,
    Barcelona, Spain © 2024 Copyright held by the owner/author(s). ACM ISBN 979-8-4007-0490-1/24/08.
    <https://doi.org/10.1145/3637528.3671498> ACM Reference Format: Qingsong Wen,
    Jing Liang, Carles Sierra, Rose Luckin, Richard Tong, Zitao Liu, Peng Cui, and
    Jiliang Tang. 2024. AI for Education (AI4EDU): Advancing Personalized Education
    with LLM and Adaptive Learning. In Proceedings of the 30th ACM SIGKDD Conference
    on Knowledge Discovery and Data Mining (KDD ''24), August 25–29, 2024, Barcelona,
    Spain. ACM, New York, NY, USA, [2](#page-1-0) pages.<https://doi.org/10.1145/3637528.3671498>'
  document: '![](_page_0_Picture_0.jpeg)


    # AI for Education (AI4EDU): Advancing Personalized Education with LLM and Adaptive
    Learning


    Qingsong Wen Squirrel Ai Learning Bellevue, USA qingsongedu@gmail.com


    Rose Luckin University College London London, UK r.luckin@ucl.ac.uk


    Jing Liang Squirrel Ai Learning Shanghai, China joleenliang@squirrelai.com


    Richard Tong Squirrel Ai Learning Bellevue, USA richard.tong@ieee.org


    Peng Cui Tsinghua University Beijing, China cuip@tsinghua.edu.cn


    Carles Sierra IIIA of the Spanish National Research Council Barcelona, Spain sierra@iiia.csic.es


    > Zitao Liu Jinan University Guangzhou, China liuzitao@jnu.edu.cn


    Jiliang Tang Michigan State University East Lansing, USA tangjili@msu.edu


    #### ABSTRACT


    Recent advanced AI technologies, especially large language models (LLMs) like
    GPTs, have significantly advanced the field of data mining and led to the development
    of various LLM-based applications. AI for education (AI4EDU) is a vibrant multi-disciplinary
    field of data mining, machine learning, and education, with increasing importance
    and extraordinary potential. In this field, LLM and adaptive learning-based models
    can be utilized as interfaces in human-in-the-loop education systems, where the
    model serves as a mediator among the teacher, students, and machine capabilities,
    including its own. This perspective has several benefits, including the ability
    to personalize interactions, allow unprecedented flexibility and adaptivity for
    human-AI collaboration and improve the user experience. However, several challenges
    still exist, including the need for more robust and efficient algorithms, designing
    effective user interfaces, and ensuring ethical considerations are addressed.
    This workshop aims to bring together researchers and practitioners from academia
    and industry to explore cutting-edge AI technologies for personalized education,
    especially the potential of LLMs and adaptive learning technologies.


    ### CCS CONCEPTS


    • Applied computing → Education; • Human-centered computing→Human computer interaction
    (HCI);• Computing methodologies → Machine learning.


    # KEYWORDS


    Education, Edtech, Adaptive Learning, LLM


    KDD ''24, August 25–29, 2024, Barcelona, Spain


    © 2024 Copyright held by the owner/author(s).


    ACM ISBN 979-8-4007-0490-1/24/08. <https://doi.org/10.1145/3637528.3671498> ACM
    Reference Format: Qingsong Wen, Jing Liang, Carles Sierra, Rose Luckin, Richard
    Tong, Zitao Liu, Peng Cui, and Jiliang Tang. 2024. AI for Education (AI4EDU):
    Advancing Personalized Education with LLM and Adaptive Learning. In Proceedings
    of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD
    ''24), August 25–29, 2024, Barcelona, Spain. ACM, New York, NY, USA, [2](#page-1-0)
    pages.<https://doi.org/10.1145/3637528.3671498>


    #### 1 INTRODUCTION


    Following the success of the previous multiple AI4EDU workshops, which were co-organized
    by our co-organizers, we are looking forward to hosting the new AI4EDU workshop
    in KDD 2024. Different from those previous workshops, the AI4EDU workshop at KDD
    2024 will (1) provide a platform for both academia and industrial researchers
    from different fields, e.g., data mining, machine learning, artificial intelligence,
    education, etc, to exchange ideas and promote collaborations, and (2) focus on
    new emerging LLMs and adaptive learning in education. Specifically, this workshop
    aims to explore cutting-edge LLMs and adaptive learning technologies for personalized
    education. The objectives of the workshop are to: 1) Review the current state-of-the-art
    in LLM-based systems and their applications in education. 2) Discuss the state-of-the-art
    technologies of adaptive learning and mining that tailor education to the individual
    needs, learning styles, proficiency levels, and problem areas of each student,
    for personalized learning experience. 3) Identify challenges and opportunities
    in using LLMs as both communication and collaboration interfaces in adaptive learning
    systems, educational games and intelligent educational assistants. 4) Explore
    ethical considerations and standardization issues in the use of LLMs. 5) Introduce
    and design new approaches such as prompt engineering, local fine tuning, integrated
    reasoning, and delegation framework for dialog-based systems that not only generate
    content but also shape the behavior of the system.


    Permission to make digital or hard copies of part or all of this work for personal
    or classroom use is granted without fee provided that copies are not made or distributed
    for profit or commercial advantage and that copies bear this notice and the full
    citation on the first page. Copyrights for third-party components of this work
    must be honored. For all other uses, contact the owner/author(s).


    <span id="page-1-0"></span>KDD ''24, August 25–29, 2024, Barcelona, Spain Qingsong
    Wen, et al.


    ## 2 TOPICS OF INTEREST


    This workshop encourages submissions of innovative solutions for a broad range
    of AI for Education problems. Topics of interest include but are not limited to
    the following:


    - Mining multimodal data for comprehensive learning analytics in LLM-aided education.

    - Challenges and opportunities in integrating LLMs with existing adaptive learning
    systems.

    - Adaptive learning and mining systems and their applications in educational settings.

    - Predictive modeling in education using LLMs for student success and retention.

    - The potential of LLMs in education from both the theoretical and practical angles.

    - Ethical considerations in the use of LLMs as interfaces in educational settings,
    especially with AI standards committee.

    - Frameworks for standardization and benchmarking of LLMs in educational technology.

    - Data-driven approaches to curriculum development using LLM insights.

    - Data-driven approaches to curriculum development using LLM insights.

    - LLMs role in automated assessment and real-time feedback for students.

    - The future of LLMs in education: trends, potentials, and unforeseen consequences.


    # 3 PAPER SUBMISSION AND REVIEW PROCESS


    We invite high-quality paper submissions of theoretical and experimental nature
    on the broad AI4EDU topics. The workshop solicits 4-7 pages double-blind paper
    submissions from participants. Submissions of the following flavors will be sought:
    (1) research ideas, (2) case studies (or deployed projects), (3) review papers,
    (4) best practice papers, and (5) lessons learned. All submissions will be peer-reviewed.
    Some will be selected for spotlight talks, and some for the poster session.


    Each submitted paper will be evaluated by at least two reviewers, using the same
    criteria as SIGKDD Research Track papers: novelty, technical quality, potential
    impact, and clarity. As with Research Track papers, we will consider sufficiently
    innovative application-oriented papers, in addition to theoretical and methodological
    contributions. The program committee members and other researchers recommended
    by the program committee members will review the papers. Additional reviews may
    be solicited if the two reviews are not conclusive. Only papers that are deemed
    to be satisfactorily novel and technically sound by the program committee will
    be accepted.


    ### 4 WORKSHOP FORMAT


    The workshop will be held in person and will include interactive sessions and
    online resources to support ongoing collaboration. The workshop will consist of
    paper presentations, panel discussions, and group activities to facilitate the
    exchange of ideas and promote collaborative learning as follows:


    • Paper Presentations: 20 minutes for each paper.


    - Invited Talks: We intend to have 5-7 speakers to present their expert insights.

    - Panel Discussions: Panel discussion sessions are intended to explore various
    heated topics related to the implementation of AI in education, ongoing initiatives,
    and projects.

    - Poster Sessions: Optional for papers that could not fit into the main session
    - Allow breakout rooms.


    # 5 INTENDED AUDIENCE


    The workshop is intended for researchers and practitioners in the areas of data
    mining, NLP, HCI, machine learning, educational technology, and other related
    fields. Participants will benefit from the opportunity to learn about the latest
    research and developments in the use of LLMs and adaptive learning systems, as
    well as engage in a collaborative design and prototyping activity.


    # 6 EXPECTED OUTCOMES


    The expected outcomes of the workshop include a better understanding of the potential
    of LLMs and adaptive learning for personalized education systems, a review of
    the current state-of-the-art, identification of challenges and opportunities,
    and recommendations for future research and practice. Additionally, we expect
    to identify potential collaborations and partnerships that can lead to the development
    of more robust LLMs and adaptive learning systems, as well as prototype designs
    for new LLM-based systems in educational settings.


    # 7 WORKSHOP ORGANIZERS


    - Qingsong Wen, Head of AI Research & Chief Scientist at Squirrel Ai Learning.

    - Jing Liang, Co-Founder of Squirrel Ai Learning.

    - Carles Sierra, Professor and Director of the Artificial Intelligence Research
    Institute (IIIA) of the Spanish National Research Council (CSIC).

    - Rose Luckin, Professor of Learner Centred Design at the UCL Knowledge Lab.

    - Richard Tong, Chief Architect of Squirrel Ai Learning.

    - Zitao Liu, Dean of Guangdong Institute of Smart Education, Jinan University.

    - Peng Cui, Associate Professor with tenure in Tsinghua University.

    - Jiliang Tang, University Foundation Professor in the computer science and engineering
    department at Michigan State University.'
  decisions:
    evaluation_prompt: 'Disqualified: no evaluation. Reason: The paper does not contain
      any sections or content that indicate empirical, experimental, or quantitative
      evaluation. It primarily discusses the workshop''s objectives, topics of interest,
      and format without presenting any structured evaluation or results.'
    related_work_prompt: 'Disqualified: no related work. Reason: The paper does not
      include any meaningful engagement with prior research. It lacks academic citations
      and does not explain or compare its methods to previous work. The content focuses
      on workshop organization and objectives without discussing related research
      or situating its contributions within the existing body of knowledge.'
    novelty_prompt: 'Disqualified: no novelty. Reason: The paper primarily describes
      the organization and objectives of a workshop rather than presenting new research
      findings, methods, or applications. It does not make specific claims of novel
      contributions or propose new methods, algorithms, or insights in the field of
      AI for education.'
    review_only_prompt: 'Disqualified: review paper. Reason: The paper''s title contains
      the word "Advancing," which does not explicitly indicate a survey or review,
      but the content primarily summarizes existing work and discusses the state-of-the-art
      without introducing new methods, datasets, experiments, or frameworks. The focus
      is on reviewing current technologies and identifying challenges and opportunities,
      which aligns with the characteristics of a review paper without novel contributions.'
- title: '**1. Introduction**'
  abstract: ''
  keywords: ''
  document: "![](_page_0_Picture_0.jpeg)\n\n*Review*\n\n![](_page_0_Picture_1.jpeg)\n\
    \n**Kwame Nyako , Suman Devkota, Frank Li and Vamsi Borra [\\\\*](https://orcid.org/0000-0003-0348-2044)**\n\
    \nElectrical and Computer Engineering Program, Rayen School of Engineering, Youngstown\
    \ State University, Youngstown, OH 44555, USA\n\n**\\*** Correspondence: vsborra@ysu.edu\n\
    \n**Abstract:** The field of microelectronics has experienced extensive integration\
    \ into various aspects of our everyday lives, evident via its utilization across\
    \ a wide range of devices such as cellphones, airplanes, computers, wristwatches,\
    \ and other similar technologies. Microelectronics are vital to the healthcare\
    \ and defense industries, making them vulnerable to counterfeit products. Currently,\
    \ the complicated global microelectronics supply chain involves the production\
    \ of varied components in multiple places, resulting in tremendous risk. In this\
    \ scenario, it is possible for hostile or adversarial actors to exploit the situation\
    \ by intentionally introducing counterfeit components. This hostile be‑ havior\
    \ could steal data or use these components as remote kill switches. To address\
    \ these problems, enormous resources are being committed to research, innovation,\
    \ and development to build trust in microelectronics. This research study provides\
    \ a thorough analysis of the taxonomy associated with prominent attack, detection,\
    \ and avoidance models in the realm of counterfeit microelectronics. This research\
    \ aims to improve our understanding of dependable microelectronics. Prevention\
    \ strate‑ gies like Physical Unclonable Functions (PUFs) and machine learning\
    \ (ML), and detection methods like aging‑based fingerprints are reviewed in this\
    \ study. Finally, we underscore the significance of interdisciplinary cooperation,\
    \ commitment to norms, and proactive methods.\n\n**Keywords:** counterfeit; detection;\
    \ trust; microelectronics\n\n# **1. Introduction**\n\nCybersecurity plays a pivotal\
    \ and indispensable role in today's technological land‑ scape. Yet, cybercriminal\
    \ tactics continue to evolve, making their identification increas‑ ingly challenging.\
    \ Phishing, IoT hacks, and ransomware have resulted in substantial losses in the\
    \ tech industry. Thus, hardware security, which protects electronic gear throughout\
    \ production, has grown in popularity. Hardware security, akin to other security\
    \ domains, strives to shield hardware from threats that could compromise or obliterate\
    \ it [\\[1](#page-17-0)]. Ensur‑ ing 'Assurance' and 'Trust' in the context of\
    \ securing hardware systems translates to the confidence that electronic equipment\
    \ will perform as intended, free from the peril of com‑ promised components[[2\\\
    ]](#page-17-1).\n\nAs the global supply chain grows more intricate and the prevalence\
    \ of counterfeit components surges, it becomes paramount to verify the authenticity\
    \ of electrical chips. The infiltration of counterfeit components, potentially\
    \ finding their way into electronic equip‑ ment, raises concerns as workers contend\
    \ with mounting client demands[[3\\]](#page-17-2). National security, economic\
    \ stability, and individual privacy hang in the balance when hardware systems\
    \ lack adequate security. Reports from the Department of Defense reveal that over\
    \ a million components in military aviation and combat missiles have been identified\
    \ as coun‑ terfeit [\\[4](#page-17-3),[5\\]](#page-17-4).\n\nDuring the first\
    \ Iraq War in 1991, fighter planes were disabled by a secret activation code embedded\
    \ in the hardware [\\[6](#page-17-5)]. Experts believe that the presence of a\
    \ wicked electri‑ cal circuit that was remotely programmable and triggerable played\
    \ a part in aiding such\n\n![](_page_0_Picture_11.jpeg)\n\n**Citation:** Nyako,\
    \ K.; Devkota, S.; Li, F.; Borra, V. Building Trust in Microelectronics: A Comprehensive\
    \ Review of Current Techniques and Adoption Challenges. *Electronics* **2023**,\
    \ *12*, 4618. [https://doi.org/](https://doi.org/10.3390/electronics12224618)\
    \ [10.3390/electronics12224618](https://doi.org/10.3390/electronics12224618)\n\
    \nAcademic Editors: Wei Hu, Jiaji He and Haoqi Shan\n\nReceived: 13 October 2023\
    \ Revised: 7 November 2023 Accepted: 9 November 2023 [Published: 11 November 2023](https://creativecommons.org/)\n\
    \n![](_page_0_Picture_15.jpeg)\n\n**Copyright:** © 2023 by the authors. Licensee\
    \ MDPI, Basel, Switzerland. This article is an open access article distributed\
    \ under the terms and conditions of the Creative Commons Attribution (CC BY) license\
    \ [\\(https://](https://creativecommons.org/licenses/by/4.0/) [creativecommons.org/licenses/by/](https://creativecommons.org/licenses/by/4.0/)\
    \ 4.0/).\n\n![](_page_0_Picture_19.jpeg)\n\na catastrophic catastrophe. The Semiconductor\
    \ Industry Association (SIA) says that an‑ nual losses to manufacturers owing\
    \ to counterfeits total USD 7.5 billion [\\[7](#page-17-6)], amounting to around\
    \ 11,000 job losses in the United States[[8\\]](#page-17-7). Other sources assert\
    \ even higher losses, estimating annual sales losses of around USD 100 billion\
    \ to counterfeiting[[9,](#page-17-8)[10](#page-17-9)]. such a catastrophic catastrophe.\
    \ The Semiconductor Industry Association (SIA) says that annual losses to manufacturers\
    \ owing to counterfeits total USD 7.5 billion [7], amounting to around 11,000\
    \ job losses in the United States [8]. Other sources assert even higher losses,\
    \ estimating annual sales losses of around USD 100 billion to counterfeiting [9,10].\n\
    \nelectrical circuit that was remotely programmable and triggerable played a part\
    \ in aiding\n\n*Electronics* **2023**, *12*, x FOR PEER REVIEW 2 of 22\n\nTo combat\
    \ this menace, cutting‑edge strategies for detecting and preventing counter‑ feits\
    \ from infiltrating the market are of paramount importance [\\[11](#page-17-10)].\
    \ Figure [1](#page-1-0) illustrates the alarming increase in reported counterfeit\
    \ components between 2021 and 2022, a period during which worldwide semiconductor\
    \ sales remained relatively stable. To combat this menace, cutting-edge strategies\
    \ for detecting and preventing counterfeits from infiltrating the market are of\
    \ paramount importance [11]. Figure 1 illustrates the alarming increase in reported\
    \ counterfeit components between 2021 and 2022, a period during which worldwide\
    \ semiconductor sales remained relatively stable.\n\n<span id=\"page-1-0\"></span>![](_page_1_Figure_3.jpeg)\n\
    \n**Figure 1.** Reported counterfeits increased significantly between 2021 and\
    \ 2022 [12]. **Figure 1.** Reported counterfeits increased significantly between\
    \ 2021 and 2022 [\\[12](#page-17-11)].\n\nNeglecting hardware security and component\
    \ verification carries a spectrum of potential consequences, ranging from threats\
    \ to national security to severe economic repercussions, underscoring the criticality\
    \ of this facet of technology. The burgeoning presence of counterfeit components\
    \ in the global supply chain mandates substantial investments in advanced detection\
    \ technologies and concerted proactive initiatives. In this first section, we\
    \ adopt a review-style approach to investigate the intricacies between semiconductor\
    \ sales and the reporting of counterfeit parts in the industry. The aim is to\
    \ understand if an increasing trend in semiconductor sales correlates with the\
    \ rise in counterfeit parts. The objectives are to present the data, understand\
    \ the underlying patterns, and provide insights on the significance of these trends.\
    \ Neglecting hardware security and component verification carries a spectrum of\
    \ po‑ tential consequences, ranging from threats to national security to severe\
    \ economic reper‑ cussions, underscoring the criticality of this facet of technology.\
    \ The burgeoning presence of counterfeit components in the global supply chain\
    \ mandates substantial investments in advanced detection technologies and concerted\
    \ proactive initiatives. In this first section, we adopt a review‑style approach\
    \ to investigate the intricacies between semiconductor sales and the reporting\
    \ of counterfeit parts in the industry. The aim is to understand if an increasing\
    \ trend in semiconductor sales correlates with the rise in counterfeit parts.\
    \ The ob‑ jectives are to present the data, understand the underlying patterns,\
    \ and provide insights on the significance of these trends.\n\nBrief statistics\
    \ below underscore the issues. Figure 1 below indicates that while global semiconductor\
    \ sales remained steady from 2021 to 2022, reported counterfeit components surged\
    \ by 35 percent. Over the years, semiconductor sales have shown a definitive upward\
    \ trajectory. However, when juxtaposed with the total counterfeit parts reported,\
    \ the relationship is not immediately apparent. While there is a spike observed\
    \ between 2021 and 2022, a more substantial increase can be seen between 2010\
    \ and 2011. This suggests Brief statistics below underscore the issues. Figure\
    \ [1](#page-1-0) below indicates that while global semiconductor sales remained\
    \ steady from 2021 to 2022, reported counterfeit components surged by 35 percent.\
    \ Over the years, semiconductor sales have shown a definitive up‑ ward trajectory.\
    \ However, when juxtaposed with the total counterfeit parts reported, the relationship\
    \ is not immediately apparent. While there is a spike observed between 2021 and\
    \ 2022, a more substantial increase can be seen between 2010 and 2011. This suggests\
    \ that drawing conclusions based solely on the 2021–2022 data might be premature.\n\
    \nthat drawing conclusions based solely on the 2021–2022 data might be premature.\
    \ To offer a more comprehensive view, we calculated the Pearson's r correlation\
    \ between semiconductor sales and the total counterfeit parts reported. The results\
    \ indicate a Pearson's r of 0.01366, which shows a positive correlation between\
    \ semiconductor sales and counterfeit parts, albeit a weak one. The low correlation\
    \ can also be attributed to the To offer a more comprehensive view, we calculated\
    \ the Pearson's r correlation be‑ tween semiconductor sales and the total counterfeit\
    \ parts reported. The results indicate a Pearson's r of 0.01366, which shows a\
    \ positive correlation between semiconductor sales and counterfeit parts, albeit\
    \ a weak one. The low correlation can also be attributed to the fact that the\
    \ Pearson's r was computed from the average of yearly values. Other potential\
    \ drivers for this trend deviation include the following.\n\nThe initial impact\
    \ of the COVID‑19 pandemic led to many businesses downsizing or suspending their\
    \ operations, causing significant disruptions in global supply chains. However,\
    \ as the global economy slowly rebounds, businesses are returning to their pre‑\
    \ pandemic activities, resulting in a surge in demand for electrical components.\
    \ This height‑ ened demand could create opportunities for counterfeiters to exploit\
    \ weaknesses in the supply chain to meet the increased market needs. Additionally,\
    \ as pandemic‑related re‑ strictions ease, global supply networks are gradually\
    \ recovering and reopening, poten‑ tially enabling the cross‑border spread of\
    \ counterfeit parts. Moreover, the growing aware‑ ness of and reporting on counterfeit\
    \ component issues likely contribute to the observed rise in reported instances\
    \ of counterfeit electrical components infiltrating the market. To address the\
    \ risks associated with counterfeit components, stakeholders should invest in\
    \ ad‑ vanced detection and prevention technologies, establish industry standards,\
    \ and promote collaboration within the global supply chain. suspending their operations,\
    \ causing significant disruptions in global supply chains. However, as the global\
    \ economy slowly rebounds, businesses are returning to their prepandemic activities,\
    \ resulting in a surge in demand for electrical components. This heightened demand\
    \ could create opportunities for counterfeiters to exploit weaknesses in the supply\
    \ chain to meet the increased market needs. Additionally, as pandemic-related\
    \ restrictions ease, global supply networks are gradually recovering and reopening,\
    \ potentially enabling the cross-border spread of counterfeit parts. Moreover,\
    \ the growing awareness of and reporting on counterfeit component issues likely\
    \ contribute to the observed rise in reported instances of counterfeit electrical\
    \ components infiltrating the market. To address the risks associated with counterfeit\
    \ components, stakeholders should invest in advanced detection and prevention\
    \ technologies, establish industry standards, and promote collaboration within\
    \ the global supply chain. Figure 2 is a trend analysis of the most frequently\
    \ reported component types over the\n\nThe initial impact of the COVID-19 pandemic\
    \ led to many businesses downsizing or\n\n*Electronics* **2023**, *12*, x FOR\
    \ PEER REVIEW 3 of 22\n\ndrivers for this trend deviation include the following.\n\
    \nFigure [2](#page-2-0) is a trend analysis of the most frequently reported component\
    \ types over the past decade, which reveals interesting information about the\
    \ microelectronics market. One noteworthy tendency is the flattening of the capacitor\
    \ spike, which could indicate ei‑ ther an advance in capacitor dependability and\
    \ affordability or a shift in the counterfeiting community's focus. Since the\
    \ Electronics Research and Analysis Institute (ERAI) began tracking this data,\
    \ the demand for analog devices has expanded faster than any other type of component\
    \ in the last year. past decade, which reveals interesting information about the\
    \ microelectronics market. One noteworthy tendency is the flattening of the capacitor\
    \ spike, which could indicate either an advance in capacitor dependability and\
    \ affordability or a shift in the counterfeiting community's focus. Since the\
    \ Electronics Research and Analysis Institute (ERAI) began tracking this data,\
    \ the demand for analog devices has expanded faster than any other type of component\
    \ in the last year.\n\n<span id=\"page-2-0\"></span>![](_page_2_Figure_3.jpeg)\n\
    \n**Figure 2.** The most counterfeited semiconductors in 2022 compared with 10\
    \ and 5 years ago. **Figure 2.** The most counterfeited semiconductors in 2022\
    \ compared with 10 and 5 years ago.\n\nOther reasons for the recent rise of analog\
    \ devices are likely to include growing prices, improving technology, and even\
    \ sophisticated counterfeiting efforts. Stakeholders in the microelectronics sector\
    \ would do well to keep an eye on these trends and determine their root causes;\
    \ doing so would help in the creation of efficient methods for the identification,\
    \ prevention, and avoidance of counterfeit products. In addition, having an awareness\
    \ of these tendencies will aid in guaranteeing the security and dependability\
    \ of microelectronic components. Other reasons for the recent rise of analog devices\
    \ are likely to include growing prices, improving technology, and even sophisticated\
    \ counterfeiting efforts. Stakeholders in the microelectronics sector would do\
    \ well to keep an eye on these trends and determine their root causes; doing so\
    \ would help in the creation of efficient methods for the identification, prevention,\
    \ and avoidance of counterfeit products. In addition, having an awareness of these\
    \ tendencies will aid in guaranteeing the security and dependability of microelectronic\
    \ components.\n\nConsidering all the challenges above, we have adopted a review-style\
    \ methodology, to meticulously examine the literature and advancements in the\
    \ microelectronics domain. Additionally, we offer a thorough insight into the\
    \ challenges and ever-changing threats Considering all the challenges above, we\
    \ have adopted a review‑style methodology, to meticulously examine the literature\
    \ and advancements in the microelectronics domain. Additionally, we offer a thorough\
    \ insight into the challenges and ever‑changing threats and solutions concerning\
    \ trusted microelectronics. The research aims to provide an in‑ depth understanding\
    \ of the taxonomy of counterfeit attack, detection, and avoidance within the industry,\
    \ articulating the complexities and current developments. The objectives en‑\n\
    \ncompass tracing microelectronics' evolution and its modern relevance, understanding\
    \ ex‑ ternal impacts like the COVID‑19 pandemic on the sector's vulnerabilities,\
    \ emphasizing the escalating sophistication of counterfeit threats, addressing\
    \ ethical and security implica‑ tions from technology convergence, and forecasting\
    \ the future of microelectronics security with a focus on innovative solutions.\
    \ These objectives lay the groundwork for the subse‑ quent sections, ensuring\
    \ readers receive a coherent and insightful exploration of the topic. phasizing\
    \ the escalating sophistication of counterfeit threats, addressing ethical and\
    \ security implications from technology convergence, and forecasting the future\
    \ of microelectronics security with a focus on innovative solutions. These objectives\
    \ lay the groundwork for the subsequent sections, ensuring readers receive a coherent\
    \ and insightful exploration of the topic.\n\nand solutions concerning trusted\
    \ microelectronics. The research aims to provide an in-\n\ntives encompass tracing\
    \ microelectronics' evolution and its modern relevance, understanding external\
    \ impacts like the COVID-19 pandemic on the sector's vulnerabilities, em-\n\n\
    *Electronics* **2023**, *12*, x FOR PEER REVIEW 4 of 22\n\n#### <span id=\"page-3-1\"\
    ></span>**2. Counterfeit Attack Modes 2. Counterfeit Attack Modes**\n\nAs depicted\
    \ in Figure [3,](#page-3-0) counterfeit integrated circuits (ICs) are primarily\
    \ susceptible to four categories of attack mechanisms: software, hardware, network,\
    \ and information security. In the subsequent sections, we delve into these potential\
    \ attack techniques for counterfeit ICs, elaborating on the potential consequences\
    \ they may entail. As depicted in Figure 3, counterfeit integrated circuits (ICs)\
    \ are primarily susceptible to four categories of attack mechanisms: software,\
    \ hardware, network, and information security. In the subsequent sections, we\
    \ delve into these potential attack techniques for counterfeit ICs, elaborating\
    \ on the potential consequences they may entail.\n\n<span id=\"page-3-0\"></span>![](_page_3_Figure_4.jpeg)\n\
    \n**Figure 3.** Chart showing counterfeit attack modes and the potential consequences\
    \ of such attacks. **Figure 3.** Chart showing counterfeit attack modes and the\
    \ potential consequences of such attacks.\n\n#### *2.1. Software Security*\n\n\
    *2.1. Software Security*  As the significance of software security continues to\
    \ escalate, the role of trusted microelectronics in fortifying software applications\
    \ and ensuring their stability has gained paramount importance. Software security\
    \ revolves around the safeguarding of software applications against vulnerabilities\
    \ and attacks that could be exploited by counterfeit integrated circuits (ICs).\
    \ Counterfeit ICs provide malicious actors with the means to inject malicious\
    \ code, circumvent security protocols, or manipulate the functionality of software\
    \ applications. They can also facilitate software-based side-channel attacks and\
    \ privilege As the significance of software security continues to escalate, the\
    \ role of trusted mi‑ croelectronics in fortifying software applications and ensuring\
    \ their stability has gained paramount importance. Software security revolves\
    \ around the safeguarding of software applications against vulnerabilities and\
    \ attacks that could be exploited by counterfeit in‑ tegrated circuits (ICs).\
    \ Counterfeit ICs provide malicious actors with the means to inject malicious\
    \ code, circumvent security protocols, or manipulate the functionality of software\
    \ applications. They can also facilitate software‑based side‑channel attacks and\
    \ privilege escalation, thereby granting unauthorized access to sensitive data\
    \ or system resources.\n\nescalation, thereby granting unauthorized access to\
    \ sensitive data or system resources. Notably, the Plundervolt attack, elucidated\
    \ by [13], exploits the dynamic frequency and voltage scaling features of modern\
    \ CPUs, specifically targeting Intel SGX enclave operations. By manipulating the\
    \ processor's voltage, attackers can induce known faults in the processor package,\
    \ compromising security. This vulnerability can lead to the compromise of cryptographic\
    \ keys and the introduction of memory-safety vulnerabilities. The repercussions,\
    \ as outlined in [14], encompass unauthorized access to private data, system Notably,\
    \ the Plundervolt attack, elucidated by [\\[13](#page-17-12)], exploits the dynamic\
    \ frequency and voltage scaling features of modern CPUs, specifically targeting\
    \ Intel SGX enclave op‑ erations. By manipulating the processor's voltage, attackers\
    \ can induce known faults in the processor package, compromising security. This\
    \ vulnerability can lead to the compro‑ mise of cryptographic keys and the introduction\
    \ of memory‑safety vulnerabilities. The repercussions, as outlined in[[14\\]](#page-17-13),\
    \ encompass unauthorized access to private data, system instability, software\
    \ performance degradation, and reduced overall system security.\n\ninstability,\
    \ software performance degradation, and reduced overall system security. Furthermore,\
    \ speculative execution, a form of software security attack that occurs when the\
    \ CPU speculatively executes tasks it anticipates needing in the future without\
    \ explicit instruction [15], introduces potential risks. This approach eliminates\
    \ the need to Furthermore, speculative execution, a form of software security\
    \ attack that occurs when the CPU speculatively executes tasks it anticipates\
    \ needing in the future without explicit instruction[[15\\]](#page-17-14), introduces\
    \ potential risks. This approach eliminates the need to await the completion of\
    \ previous commands before executing new ones, thereby enhanc‑ ing speed by reducing\
    \ latency and increasing parallelism[[16\\]](#page-17-15). However, speculative\
    \ exe‑ cution can inadvertently execute potentially harmful programs, raising\
    \ security concerns.\n\nTo enhance software security and instill trust, Physically\
    \ Unclonable Functions (PUFs) have been proposed. PUFs are employed to generate\
    \ unique and unpredictable crypto‑ graphic keys for authentication and encryption,\
    \ constituting robust hardware‑based secu‑ rity mechanisms. Notable PUF projects\
    \ include the Arbiter PUF, which leverages differing data‑line delays [\\[17](#page-17-16)],\
    \ the Ring Oscillator PUF, which relies on variations in the frequencies of two‑ring\
    \ oscillators[[18\\]](#page-17-17), the SRAM PUF, exploiting idiosyncrasies in\
    \ SRAM‑cell startup behavior [\\[19](#page-17-18)], and the Memristor PUF, capitalizing\
    \ on the resistance‑changing properties of memristive devices [\\[20](#page-17-19)].\
    \ It is worth noting that PUFs have faced attacks, as elucidated in [\\[21](#page-17-20)],\
    \ where modeling attacks seek to emulate a PUF's behavior through mathematical\
    \ modeling. These attacks have been successfully executed with the aid of machine\
    \ learning tools such as Support Vector Machines (SVMs) and neural networks.\n\
    \n#### *2.2. Hardware Security*\n\nThe embedding of Hardware Trojans, backdoors,\
    \ and other malicious circuits within counterfeit integrated circuits (ICs) poses\
    \ a significant threat, endangering the security, confidentiality, and availability\
    \ of electronic systems [\\[22](#page-17-21)]. This underscores the critical need\
    \ for rigorous hardware security measures, including supply chain oversight, secure\
    \ manufacturing processes, and state‑of‑the‑art counterfeit detection technologies,\
    \ to fore‑ stall unauthorized access [\\[23](#page-17-22)], data breaches[[24\\\
    ]](#page-17-23), or system malfunctions[[25\\]](#page-17-24).\n\nHardware security\
    \ presents multifaceted challenges, encompassing vulnerabilities to a range of\
    \ attacks (e.g., side‑channel or Trojan attacks) at various layers (e.g., chip\
    \ or PCB), further complicating the landscape of hardware security. Concurrently,\
    \ hardware trust concerns stem from interactions with untrustworthy third parties\
    \ at any stage of a device's production and distribution, spanning from IP or\
    \ CAD tool providers to manufacturing facilities and warehouses.\n\nAmong common\
    \ hardware security breaches, Reverse Engineering Attacks, which aim to pilfer\
    \ a device's intellectual property and design details for illicit purposes such\
    \ as duplication or counterfeiting, are prominent[[26\\]](#page-18-0). These attacks\
    \ can be executed through methods like deprocessing, optical imaging, and circuit\
    \ extraction[[27\\]](#page-18-1). In contrast, fault injection attacks intentionally\
    \ induce system malfunctions to gain access to or control over the targeted system[[28\\\
    ]](#page-18-2), employing tools such as lasers, electromagnetic pulses, or temperature‑dependent\
    \ fault injections[[29\\]](#page-18-3).\n\nSide‑channel attacks focus on unintentional\
    \ data leakage from a device's physical im‑ plementation, encompassing aspects\
    \ like power consumption, electromagnetic radiation, or timing data[[30\\]](#page-18-4).\
    \ Techniques such as differential power analysis, simple power anal‑ ysis, and\
    \ correlation power analysis are employed to infer device behaviors and poten‑\
    \ tially extract sensitive information, such as encryption keys, from power consumption\
    \ pat‑ terns [\\[31](#page-18-5)].\n\nFurthermore, Hardware Trojans represent\
    \ malevolent hardware additions introduced during product assembly, serving as\
    \ latent security or functionality vulnerabilities that can be activated at a\
    \ later stage[[32\\]](#page-18-6).\n\n#### *2.3. Network Security*\n\nNetwork\
    \ attacks often manifest in the deployment of counterfeit network interface controllers\
    \ or routers, potentially leading to the theft of sensitive information, service\
    \ dis‑ ruptions, or the illicit takeover of networked devices via unauthorized\
    \ remote access [\\[33](#page-18-7)].\n\nIn safeguarding critical infrastructure,\
    \ the Internet of Things (IoT), and cloud‑based services, trusted microelectronics\
    \ play a central role [\\[34](#page-18-8)]. These components are instru‑ mental\
    \ in ensuring the privacy, integrity, and authenticity of stored data[[18\\]](#page-17-17),\
    \ commonly relying on cryptographic primitives and secure key storage.\n\nOne\
    \ particular area of scrutiny is spear‑phishing, an exceptionally targeted and\
    \ so‑ phisticated form of phishing attack that surpasses conventional phishing\
    \ attempts in terms of complexity and personalization. This issue is explored\
    \ extensively in a research pa‑ per authored by a single individual[[35\\]](#page-18-9).\
    \ The paper underscores the urgency for enter‑ prises to proactively counter the\
    \ escalating threat of spear‑phishing. To fortify themselves against sophisticated\
    \ cyberattacks, businesses are advised to prioritize user education, im‑ plement\
    \ robust security measures, and maintain a comprehensive and up‑to‑date incident\
    \ response plan.\n\n# *2.4. Information Security*\n\nIn addition to bypassing\
    \ security measures to gain unauthorized access to sensitive data, counterfeit\
    \ cryptographic integrated circuits also have the potential to disrupt encryp‑\
    \ tion or authentication methods. The advent of social media and cloud computing\
    \ has ne‑ cessitated a heavy investment by businesses in information security\
    \ in order to safeguard data. The Federal Communications Commission offers tips\
    \ to businesses for cybersecu‑ rity[[36\\]](#page-18-10). The CIA Triad, comprising\
    \ of Confidentiality, Integrity, and Availability, serves as a fundamental framework\
    \ within the field of information security. An all‑encompassing information security\
    \ strategy encompasses policies and security controls that effectively mitigate\
    \ risks to these three essential components.\n\nThe CIA triad serves as a comprehensive\
    \ framework for overseeing information secu‑ rity and is also valuable for effectively\
    \ managing research products and data.\n\n#### <span id=\"page-5-1\"></span>**3.\
    \ Counterfeit Detection Methods**\n\nNumerous previous research endeavors have\
    \ conducted comprehensive analyses and comparisons of both destructive and non‑destructive\
    \ techniques employed for the identi‑ fication of counterfeit integrated circuits\
    \ (ICs) [\\[37](#page-18-11)]. Destructive methods, including de‑ layering and\
    \ cross‑sectioning, offer profound insights into the internal structure of ICs,\
    \ uncovering potential anomalies or tampering. However, the use of these methodologies\
    \ often results in the degradation of the examined components. Conversely, non‑destructive\
    \ techniques such as X‑ray imaging, optical microscopy, and electrical testing\
    \ provide the means to scrutinize integrated circuits without causing any harm\
    \ to their structural in‑ tegrity. Consequently, these approaches are better suited\
    \ for conducting extensive screen‑ ings on a broader scale. This section underscores\
    \ the importance of integrating multiple detection techniques to enhance the accuracy\
    \ and effectiveness of counterfeit IC identifi‑ cation, thereby contributing to\
    \ the overall enhancement of security and reliability in elec‑ tronic systems.\
    \ A concise overview of the taxonomy of counterfeit detection strategies, along\
    \ with its subdivisions is provided. These are depicted in Figures [4](#page-5-0)\
    \ and [5](#page-6-0). *Electronics* **2023**, *12*, x FOR PEER REVIEW 7 of 22\n\
    \n<span id=\"page-5-0\"></span>![](_page_5_Figure_8.jpeg)\n\n**Figure 4.** Counterfeit\
    \ detection modes and subcategories [38]. **Figure 4.** Counterfeit detection\
    \ modes and subcategories[[38\\]](#page-18-12).\n\n**Figure 5.** Subdivisions\
    \ under physical inspection.\n\nTo identify imperfections, physical examinations\
    \ involve a meticulous assessment of the components' external attributes. These\
    \ examinations encompass both internal and external evaluations aimed at scrutinizing\
    \ the component's construction, packaging, and\n\n*3.1. Physical Inspections*\
    \ \n\n<span id=\"page-6-0\"></span>![](_page_6_Figure_2.jpeg)\n\n**Figure 4.**\
    \ Counterfeit detection modes and subcategories [38].\n\n**Figure 5.** Subdivisions\
    \ under physical inspection. **Figure 5.** Subdivisions under physical inspection.\n\
    \n## *3.1. Physical Inspections*\n\n*3.1. Physical Inspections*  To identify imperfections,\
    \ physical examinations involve a meticulous assessment of the components' external\
    \ attributes. These examinations encompass both internal and external evaluations\
    \ aimed at scrutinizing the component's construction, packaging, and To identify\
    \ imperfections, physical examinations involve a meticulous assessment of the\
    \ components' external attributes. These examinations encompass both internal\
    \ and external evaluations aimed at scrutinizing the component's construction,\
    \ packaging, and leads. External tests, such as low‑power visual inspection (LPVI)[[39\\\
    ]](#page-18-13), blacktop testing [\\[40](#page-18-14)[–42](#page-18-15)], microblast\
    \ analysis[[43–](#page-18-16)[45\\]](#page-18-17), hermiticity testing[[46–](#page-18-18)[48\\\
    ]](#page-18-19), scanning electron microscopy (SEM) [\\[49](#page-18-20)[–52](#page-19-0)],\
    \ and scanning acoustic microscopy (SAM) [\\[53](#page-19-1)[–55](#page-19-2)],\
    \ focus on as‑ sessing the component's exterior characteristics. The method of\
    \ low‑power visual examina‑ tion (LPVI) uses tools like microscopes, digital cameras,\
    \ or infrared light sources to inspect essential markings on package‑level electronics\
    \ and identify indications of previously used or recycled items, including marks\
    \ on the package or leftover solder on IC connectors. Fur‑ thermore, X‑ray visualization,\
    \ which is a non‑destructive testing technique, is applied to identify irregularities\
    \ within the internal components, dies, and connecting wires by com‑ paring them\
    \ to a standard component. Microblast testing is used to determine if markings\
    \ or scratches on reused or fake components have been intentionally erased using\
    \ a dry sand‑ blasting method. In contrast, internal assessments necessitate decapping\
    \ the component to expose its internal structure, which can then be subjected\
    \ to techniques like optical in‑ spection[[56–](#page-19-3)[58\\]](#page-19-4),\
    \ wire pull and die/ball shear[[59–](#page-19-5)[61\\]](#page-19-6). Essential\
    \ details about die markings, such as the company emblem, manufacturing date,\
    \ chip identification, and origin coun‑ try, among others, should be recorded.\
    \ Wire pull is used to check the bond's consistency with the die. If the component\
    \ has been used for an extended period, the bond between the die and bond wires\
    \ may weaken. By comparing the tension (or pulling strength) be‑ tween the standard\
    \ and examined components, one can ascertain if the component had prior usage.\
    \ The die shear method is employed to confirm the die attach's reliability, but\
    \ it is relevant only for sealed devices. The ball bond's robustness at the die\
    \ is assessed using a ball shear test. Scanning electron microscopy (SEM) captures\
    \ images of the die, package, or leads by scanning them with a concentrated electron\
    \ beam. This method is effective in detecting any irregularities present. With\
    \ a resolution that can reach a few nanome‑ ters, SEM allows for the detailed\
    \ analysis of the die, even down to its gate level. For an examination of the\
    \ material composition of the package, leads, and die, techniques such as X‑ray\
    \ fluorescence (XRF) [\\[62](#page-19-7)[–64](#page-19-8)], Fourier transform\
    \ infrared spectroscopy [\\[65](#page-19-9)[–67](#page-19-10)], and energy‑dispersive\
    \ spectroscopy[[68,](#page-19-11)[69](#page-19-12)] are employed. XRF Spectroscopy\
    \ is a non‑invasive technique used for material analysis. When a material is subjected\
    \ to intense X‑rays, its outer electrons are energized to higher, unstable orbits.\
    \ As these electrons revert to their original state, they emit radiation. This\
    \ emission is specific to each element, resulting in a distinctive spectral peak.\
    \ By using XRF, a unique signature from a component's package is obtained. The\
    \ component's authenticity is ascertained by comparing this signature to a reference\
    \ sample or, if accessible, the manufacturer's specifications. On the other hand,\
    \ Energy Dispersive Spectroscopy (EDS) is a technique that determines the chemical\
    \ prop‑ erties of a component by stimulating it with X‑rays. By directing a high‑powered\
    \ stream of charged particles onto the component's surface, X‑rays are emitted.\
    \ An X‑ray detector then captures this emission to produce the EDS spectrum. This\
    \ process yields a distinctive X‑ray signature based on the materials present\
    \ in the component's outer casing.\n\nLastly, Fourier Transform Infrared (FTIR)\
    \ Spectroscopy leverages the principles of infrared (IR) spectroscopy. When subjected\
    \ to IR radiation, a material will both absorb and transmit portions of it. The\
    \ captured IR radiation provides insights into molecular behaviors, both in terms\
    \ of absorption and transmission. Through this method, a specific molecular pattern\
    \ is derived, which can then be compared to a known reference or \"gold standard\"\
    \ for material verification. FTIR is versatile, suitable for examining both organic\
    \ and inorganic substances in a component. It involves validating a component's\
    \ specific ma‑ terials, such as polymers or coatings; spotting remnants from procedures\
    \ like sandblasting, which erase prior inscriptions; and detecting traces from\
    \ chemical methods. These meth‑ ods are commonly found in counterfeit parts, repurposed\
    \ from circuit boards or resulting from unsanctioned refurbishing processes.\n\
    \nA comprehensive physical inspection constitutes the initial step in thwarting\
    \ the infil‑ tration of counterfeit components. This systematic examination is\
    \ consistently applied to various categories of incoming components, regardless\
    \ of their condition, encompassing new, used, or aged components. The security\
    \ and reliability of electronic systems hinge upon this methodical approach to\
    \ detecting counterfeit parts.\n\n#### 3.1.1. Incoming Inspections\n\nFor counterfeit\
    \ integrated circuit (IC) detection, the physical inspection process ini‑ tiates\
    \ with inbound examinations. This procedure involves scrutinizing newly acquired\
    \ components to ensure their authenticity and quality before their integration\
    \ into electronic systems. Incoming inspections serve to identify anomalies, defects,\
    \ or potential signs of counterfeiting through a careful examination of the components'\
    \ physical attributes. Com‑ puter vision techniques play a pivotal role in addressing\
    \ hardware security challenges. Techniques like Keypoint Extraction using SIFT\
    \ and SURF, Image Segmentation, and Tem‑ plate Matching help in identifying and\
    \ analyzing various elements of printed circuit boards (PCBs) and integrated circuits.\
    \ With the evolution of deep learning and artificial neural networks (ANNs), feature\
    \ extraction has become more efficient, particularly with models like AlexNet,\
    \ ResNet, and Inception‑v3. Despite these advancements, computer vision‑ based\
    \ hardware security faces challenges, including the absence of large, labeled\
    \ datasets and the inherent noise and clutter in imagery, especially in high‑density\
    \ PCBs. To ad‑ dress these challenges, future research can consider multi‑modal\
    \ imaging, develop pub‑ licly available datasets, and apply deep learning earlier\
    \ in the computer vision pipeline. Collaborative efforts that combine hardware\
    \ design, imaging, computer vision, and ma‑ chine learning expertise are essential\
    \ for more holistic solutions. The complexity of con‑ temporary digital systems\
    \ presents challenges in verifying chip authenticity, prompting the authors Akter\
    \ et al. [\\[70](#page-19-13)] to advocate for the use of terahertz (THz) and\
    \ sub‑terahertz (sub‑THz) scanning combined with AI processing to detect counterfeit\
    \ Integrated Circuits (ICs) and assess their reliability. This technology, tested\
    \ on devices like the i7 microproces‑\n\nsor, uses unique THz signatures from\
    \ circuit pins to distinguish genuine from counterfeit chips. Using MATLAB‑based\
    \ software, the THz response data undergoes a multi‑step pro‑ cessing procedure,\
    \ with techniques like Hough transform applied for image classification. The research\
    \ suggests that this combined approach of THz scanning and AI processing can serve\
    \ as a significant tool for cybersecurity, ensuring the reliability and genuineness\
    \ of ICs in sectors vulnerable to counterfeit threats, such as defense and healthcare.\n\
    \nAnother use of machine learning in counterfeit IC detection proposed by Sukhwan\
    \ et al. [\\[71](#page-19-14)] uses simulated circuits to pinpoint temperatures\
    \ that best emphasize the dis‑ parities between genuine and counterfeit circuits.\
    \ By using RLC circuits, non‑inverting amplifier circuits, and the NSGA II algorithm,\
    \ the research establishes optimal testing con‑ ditions, notably in extreme temperatures,\
    \ that accentuate these differences. When tested on genuine Intel and counterfeit\
    \ Soviet clone circuits, the counterfeit circuits exhibited sig‑ nificant output\
    \ differences, especially in cold environments. This machine learning model is\
    \ adaptable for industrial‑grade counterfeit detection tools and offers a cost‑efficient\
    \ alter‑ native. In a study by Lu et al.[[67\\]](#page-19-10), the authors underscore\
    \ the potential of X‑ray imaging as a means to detect counterfeit and recycled\
    \ ICs. They suggest using a method based on deep learning to analyze X‑ray images\
    \ of integrated circuits in order to spot fakes. The au‑ thors describe Hardware\
    \ Trojans as malicious modifications in integrated circuits. These can include\
    \ simple changes like adding, removing, or altering circuit cells (like gates)\
    \ or their connections, as shown in Figure [6.](#page-8-0) When processing X‑ray\
    \ pictures, convolutional neural networks, also known as CNNs, are utilized, which\
    \ enables the automatic extrac‑ tion of distinguishing characteristics. *Electronics*\
    \ **2023**, *12*, x FOR PEER REVIEW 10 of 22\n\n<span id=\"page-8-0\"></span>![](_page_8_Figure_3.jpeg)\n\
    \n**Figure 6.** An SEM image of an IC layout showing **a2** being points of cell\
    \ insertion, **b2** being points of cell deletion, and **c2** being points of\
    \ cell replacement [67]. (Figure adopted with permission) **Figure 6.** An SEM\
    \ image of an IC layout showing **a2** being points of cell insertion, **b2**\
    \ being points of cell deletion, and **c2** being points of cell replacement[[67\\\
    ]](#page-19-10). (Figure adopted with permission).\n\nConsequently, these networks\
    \ categorize integrated circuits as either authentic or counterfeit/recycled.\
    \ The incorporation of deep learning in this technology holds the promise of surpassing\
    \ current manual inspection procedures in terms of accuracy, speed, and scalability.\
    \ Consequently, these networks categorize integrated circuits as either authentic\
    \ or counterfeit/recycled. The incorporation of deep learning in this technology\
    \ holds the promise of surpassing current manual inspection procedures in terms\
    \ of accuracy, speed, and scalability.\n\n#### 3.1.2. Exterior Tests 3.1.2. Exterior\
    \ Tests\n\nnents.\n\n3.1.3. Interior Tests\n\nBlacktop testing, as defined by\
    \ researchers in [38,72], involves inspecting the surface of the components for\
    \ discrepancies, such as the existence of a blacktop coating intended to disguise\
    \ remarking or other tampering, with the goal of discovering counterfeit ICs.\
    \ The longevity of the parts under scrutiny is determined by subjecting them to\
    \ a battery of different solvents. Hermeticity, as described in [73], necessitates\
    \ a special method of package assessment, especially for hermetically sealed components.\
    \ This evaluation ensures that the Hermetic Seal is intact and the product will\
    \ work as expected in the designated setting. When the circuit's performance is\
    \ at stake and great dependability is required, such as in the military or industry,\
    \ hermetic enclosures for integrated circuit packages are commonly used. Examining\
    \ a Fine Leak or a Gross Leak in a Hermetic Seal is a simple and low-cost approach\
    \ to check for seal failure. To analyze a Fine Leak Hermetic Seal, one can use\
    \ commercially available leak detection systems that use either helium or radioisotope\
    \ tracer gases. A vacuum is applied, the integrated circuit is pressurized for\
    \ a certain amount of time (allowing the gas to seep into the package cavity),\
    \ and then the released gas is detected. Gross Leak Hermetic Seal assessments,\
    \ on the other hand, may be readily carried out with just a bit of pressured air,\
    \ a vacuum system, a pressure chamber, and two Blacktop testing, as defined by\
    \ researchers in [\\[38](#page-18-12),[72\\]](#page-19-15), involves inspecting\
    \ the surface of the components for discrepancies, such as the existence of a\
    \ blacktop coating intended to disguise remarking or other tampering, with the\
    \ goal of discovering counterfeit ICs. The longevity of the parts under scrutiny\
    \ is determined by subjecting them to a battery of different solvents. Hermeticity,\
    \ as described in [\\[73](#page-19-16)], necessitates a special method of pack‑\
    \ age assessment, especially for hermetically sealed components. This evaluation\
    \ ensures that the Hermetic Seal is intact and the product will work as expected\
    \ in the designated setting. When the circuit's performance is at stake and great\
    \ dependability is required, such as in the military or industry, hermetic enclosures\
    \ for integrated circuit packages are commonly used. Examining a Fine Leak or\
    \ a Gross Leak in a Hermetic Seal is a simple and low‑cost approach to check for\
    \ seal failure. To analyze a Fine Leak Hermetic Seal, one can use commercially\
    \ available leak detection systems that use either helium or radioiso‑ tope tracer\
    \ gases. A vacuum is applied, the integrated circuit is pressurized for a certain\
    \ amount of time (allowing the gas to seep into the package cavity), and then\
    \ the released gas is detected. Gross Leak Hermetic Seal assessments, on the other\
    \ hand, may be read‑ ily carried out with just a bit of pressured air, a vacuum\
    \ system, a pressure chamber, and\n\nliquids that will not interfere with any\
    \ electronic devices [74–76]. Scanning electron microscopy uses a concentrated\
    \ electron beam rather than light to create a high-resolution picture. The process\
    \ begins when a beam of electrons is created by an electron cannon at the microscope's\
    \ focal point. The extensive test time of SEM, since it might take several hours\
    \ to analyze a single component, limits its applicability. However, SEM is particularly\
    \ beneficial for identifying various faults and abnormalities prevalent in counterfeit\
    \ compo-\n\nThe term \"interior tests\" describes the process of inspecting the\
    \ inner workings of a gadget or product to ensure its legitimacy. The component's\
    \ protective covering must be\n\nBump connections, which are used in modern chip\
    \ technologies instead of wire bonds, enhance the density and stress concentration\
    \ on the connecting part by a substantial amount [77]. Ball shear testing has\
    \ been created to examine the reliability of these bumps. To use this technique,\
    \ one places an implement next to the base and presses down on the ball until\
    \ it breaks. The idea behind both ball and die shear testing is quite similar.\
    \ These experiments provide a direct measure of the interaction's trustworthiness;\
    \ nonetheless, they call for the handling of the samples and a decapping procedure\
    \ [78]. The electronic connections between various IC layers are critical to the\
    \ reliability of the IC package as a whole. The quality and durability of bonding\
    \ in microelectronic applications may be evaluated with tests like wire-pull testing.\
    \ In this kind of testing, wires are subjected to an\n\nremoved so that its internal\
    \ structure may be examined for this test.\n\ntwo liquids that will not interfere\
    \ with any electronic devices [\\[74](#page-19-17)[–76](#page-19-18)]. Scanning\
    \ electron microscopy uses a concentrated electron beam rather than light to create\
    \ a high‑resolution picture. The process begins when a beam of electrons is created\
    \ by an electron cannon at the microscope's focal point. The extensive test time\
    \ of SEM, since it might take several hours to analyze a single component, limits\
    \ its applicability. However, SEM is particularly beneficial for identifying various\
    \ faults and abnormalities prevalent in counterfeit compo‑ nents.\n\n## 3.1.3.\
    \ Interior Tests\n\nThe term \"interior tests\" describes the process of inspecting\
    \ the inner workings of a gadget or product to ensure its legitimacy. The component's\
    \ protective covering must be removed so that its internal structure may be examined\
    \ for this test.\n\nBump connections, which are used in modern chip technologies\
    \ instead of wire bonds, enhance the density and stress concentration on the connecting\
    \ part by a substantial amount [\\[77](#page-20-0)]. Ball shear testing has been\
    \ created to examine the reliability of these bumps. To use this technique, one\
    \ places an implement next to the base and presses down on the ball until it breaks.\
    \ The idea behind both ball and die shear testing is quite similar. These experiments\
    \ provide a direct measure of the interaction's trustworthiness; nonetheless,\
    \ they call for the handling of the samples and a decapping procedure[[78\\]](#page-20-1).\
    \ The electronic connections between various IC layers are critical to the reliability\
    \ of the IC package as a whole. The quality and durability of bonding in microelectronic\
    \ applications may be evaluated with tests like wire‑pull testing. In this kind\
    \ of testing, wires are subjected to an upward force applied by a hook, which\
    \ is then used to draw the wire away from the substrate or die until the bond\
    \ fails or the wire breaks. A tiny hook is inserted beneath the wire and pulled\
    \ upwards to impart strain to the bond wire and determine its quality. In order\
    \ to pass the standard non‑destructive wire pull test used in the industry, all\
    \ bonds must remain intact despite the light loading tension used[[79\\]](#page-20-2).\
    \ The goals of wire pull test‑ ing are to assess the durability of the bond, investigate\
    \ the causes of bond failure, and guarantee that the specified bond strength criteria\
    \ are met. The die shear test is used in semiconductors and other microelectronic\
    \ devices as a quality control measure to evaluate the adhesion and bonded area\
    \ of bare die attached with media such as epoxy, solder, and sinter materials\
    \ to substrate materials such as metal lead frames, ceramic packages, and printed\
    \ circuit boards.\n\n#### 3.1.4. Material Analysis\n\nThe non‑destructive qualities,\
    \ rapidity, and compatibility of Raman spectroscopy with a diverse array of materials\
    \ render it exceptionally well suited for implementation in hard‑ ware security\
    \ applications [\\[80](#page-20-3)]. This spectroscopic technique harnesses the\
    \ scattering of light to provide valuable insights into the molecular composition\
    \ and structure of mate‑ rials. In the realm of hardware security, Raman‑active\
    \ compounds like nanotags play a pivotal role in the authentication and tracking\
    \ of components[[81\\]](#page-20-4). Nanotags, infused with Raman‑active materials\
    \ can be affixed to integrated circuits or other hardware components, allowing\
    \ for their secure identification and traceability. An exemplary illustration\
    \ of Ra‑ man spectroscopy's efficacy in hardware security can be found in the\
    \ work of Vaskova et al.[[82](#page-20-5)], where it was employed to scrutinize\
    \ the dielectric materials within electronic assemblies. The objective was to\
    \ uncover instances of counterfeit capacitors, a prevalent concern in the electronics\
    \ industry. By subjecting the components to Raman spectroscopic analysis, the\
    \ researchers could non‑destructively assess the molecular composition of the\
    \ dielectric materials. Any disparities or inconsistencies in the spectral signatures\
    \ could sig‑ nify the presence of counterfeit or substandard components, thus\
    \ enabling precise detec‑ tion and mitigation of potential security threats. Raman\
    \ spectroscopy's versatility and accuracy make it an invaluable tool in the ongoing\
    \ efforts to enhance the security and reli‑ ability of electronic systems.\n\n\
    ### *3.2. Electrical Inspections*\n\nParametric, Burn‑In, and Structural Tests\n\
    \nSinanoglu et al.[[83\\]](#page-20-6) introduced an innovative approach for detecting\
    \ counterfeit in‑ tegrated circuits (ICs) based on a two‑dimensional space of\
    \ parametric measurements. In their method, they employed a one‑class support\
    \ vector machine (SVM) trained using mea‑ surements obtained from a collection\
    \ of new devices sourced from reputable suppliers. These devices naturally exhibit\
    \ some degree of process variation. The one‑class SVM, act‑ ing as a machine‑learning\
    \ model, establishes a nonlinear boundary within the parametric measurement space.\
    \ This boundary effectively discriminates between genuine and coun‑ terfeit ICs.\n\
    \nThe conventional one‑class SVM, as described by Schölkopf[[84\\]](#page-20-7)\
    \ and colleagues, rep‑ resent an objective function as:\n\n$$\\frac{1}{2}|w|^2\
    \ - \\rho + \\mathcal{C}\\sum\\_{j} \\mathfrak{f}\\_j \\tag{1}$$\n\nUnder the\
    \ constraints, *w · ϕ*(*xj*) *≥ ρ − ξj and ξj ≥* 0. In this context, the equation\
    \ *w · ϕ*(*x*) = *ρ* identifies a hyperplane within the feature domain. The symbol\
    \ *|·|* is represen‑ tative of the Euclidean magnitude, while *ξj* are the slack\
    \ variables. A pre‑set parameter, *C*, determines the proportion of anomalies,\
    \ as discussed by Müller et al. and Schölkopf et al. [\\[84](#page-20-7),[85\\\
    ]](#page-20-8).\n\nAnother study by different authors[[86\\]](#page-20-9) employed\
    \ Support Vector Machines (SVMs) to detect counterfeit ICs, with a specific focus\
    \ on distinguishing previously used ICs from unused ones. They accomplished this\
    \ by training a one‑class SVM classifier on a set of new devices that exhibit\
    \ process variations. Notably, this approach obviated the need for prior knowledge\
    \ concerning how transistor degradation may affect IC functionality. The classifier\
    \ utilized straightforward parametric measurements and validation data from burn‑in\
    \ experiments simulating the aging process. This cost‑effective method eliminated\
    \ additional identification expenses and exhibited high effectiveness in identifying\
    \ counter‑ feit ICs falsely represented as new. By incorporating various parametric\
    \ measurements, this technique demonstrated exceptional precision in identifying\
    \ used components falsely marketed as brand‑new.\n\nA recent study using SVM was\
    \ performed by Kent et al. [\\[87\\]](#page-20-10) and utilized a linear support\
    \ vector machine (SVM), a supervised machine‑learning model, to classify distinct\
    \ categories. SVM works by creating a hyperplane that best separates data points\
    \ from dif‑ ferent categories, maximizing the margin between them. Its principle\
    \ lies in ensuring the hyperplane is positioned to maximize the distance from\
    \ the nearest data points of differ‑ ing categories. The application of SVM extends\
    \ beyond just this study; it has traditionally been employed for routine maintenance\
    \ tasks like fault detection in hardware and soft‑ ware systems. For instance,\
    \ SVM was applied to distinguish performance issues in heating ventilation air‑conditioning\
    \ and cooling chillers by categorizing the data into two classes: \"fault detected\"\
    \ and \"no fault detected\". While machine learning techniques have been ex‑ plored\
    \ to address sensor location challenges for daylight harvesting, this particular\
    \ study showcased SVM's distinct application in this context.\n\nFurthermore,\
    \ the impact of Negative Bias Temperature Instability (NBTI), a primary cause\
    \ of circuit performance deterioration, can be assessed through a structural test\
    \ to gauge the integrity of ICs. NBTI aging has been shown to influence the threshold\
    \ voltage in PMOS devices[[83](#page-20-6)[,88](#page-20-11)[–91](#page-20-12)].\
    \ As mathematically developed by Wang et al. [\\[92](#page-20-13)] Equation (1)\
    \ details the calculation for \"∆*Vth*\" as influenced by NBTI for a given time\
    \ \"*t*\". In this for‑ mula, \"*Kv*\" signifies the impact of the electric field,\
    \ temperature, and carrier concentration. The time exponential constant is denoted\
    \ as \"*n*\". The term \"*α*\" indicates the signal prob‑\n\n(2)\n\n(2)\n\nability,\
    \ representing the portion of time a transistor is under NBTI stress within a\
    \ given period. \"*T*\" is the temperature, derives continuous values capable\
    \ of generating unique chip identifiers. The wealth of available test vectors\
    \ enhances the diversity of challenge-response pairings, opening up new avenues\
    \ for IC monitoring and security protocols [93–95]. This innovative approach derives\
    \ continuous values capable of generating unique chip identifiers. The wealth\
    \ of available test vectors enhances the diversity of challenge-response pairings,\
    \ opening up new avenues for IC monitoring and security protocols [93–95]. This\
    \ innovative approach\n\nmajority of ICs produced with cutting-edge technology,\
    \ all without the need for additional chip components. Leveraging non-invasive\
    \ gate-level characterization, this method\n\n*Electronics* **2023**, *12*, x\
    \ FOR PEER REVIEW 12 of 22\n\nstudy showcased SVM's distinct application in this\
    \ context.\n\ngiven period. \"*T*\" is the temperature,\n\n∆ℎ <sup>=</sup> (〖√\n\
    \nstudy showcased SVM's distinct application in this context.\n\n<sup>2</sup>\
    \ × ×\n\n∆ℎ <sup>=</sup> (〖√\n\nIn the realm of IC verification through structural\
    \ tests, there is a noteworthy exploration of using ICs' distinctive timing path\
    \ signatures, stemming from inherent process variations, as a basis for creating\
    \ Physical Unclonable Functions (PUFs) for identification purposes. Structural\
    \ tests encompass assessments like leakage, timing, and dynamic\n\n<sup>2</sup>\
    \ × ×\n\nIn the realm of IC verification through structural tests, there is a\
    \ noteworthy exploration of using ICs' distinctive timing path signatures, stemming\
    \ from inherent process variations, as a basis for creating Physical Unclonable\
    \ Functions (PUFs) for identification purposes. Structural tests encompass assessments\
    \ like leakage, timing, and dynamic\n\n1− 1 2 )〗 2\n\n1− 1 2 )〗 2\n\ngiven period.\
    \ \"*T*\" is the temperature,\n\nmarketed as brand-new.\n\nmarketed as brand-new.\n\
    \nAnother study by different authors [86] employed Support Vector Machines (SVMs)\
    \ to detect counterfeit ICs, with a specific focus on distinguishing previously\
    \ used ICs from unused ones. They accomplished this by training a one-class SVM\
    \ classifier on a set of new devices that exhibit process variations. Notably,\
    \ this approach obviated the need for prior knowledge concerning how transistor\
    \ degradation may affect IC functionality. The classifier utilized straightforward\
    \ parametric measurements and validation data from burn-in experiments simulating\
    \ the aging process. This cost-effective method eliminated additional identification\
    \ expenses and exhibited high effectiveness in identifying counterfeit ICs falsely\
    \ represented as new. By incorporating various parametric measurements, this technique\
    \ demonstrated exceptional precision in identifying used components falsely\n\n\
    Another study by different authors [86] employed Support Vector Machines (SVMs)\
    \ to detect counterfeit ICs, with a specific focus on distinguishing previously\
    \ used ICs from unused ones. They accomplished this by training a one-class SVM\
    \ classifier on a set of new devices that exhibit process variations. Notably,\
    \ this approach obviated the need for prior knowledge concerning how transistor\
    \ degradation may affect IC functionality. The classifier utilized straightforward\
    \ parametric measurements and validation data from burn-in experiments simulating\
    \ the aging process. This cost-effective method eliminated additional identification\
    \ expenses and exhibited high effectiveness in identifying counterfeit ICs falsely\
    \ represented as new. By incorporating various parametric measurements, this technique\
    \ demonstrated exceptional precision in identifying used components falsely\n\n\
    A recent study using SVM was performed by Kent et al. [87] and utilized a linear\
    \ support vector machine (SVM), a supervised machine-learning model, to classify\
    \ distinct categories. SVM works by creating a hyperplane that best separates\
    \ data points from different categories, maximizing the margin between them. Its\
    \ principle lies in ensuring the hyperplane is positioned to maximize the distance\
    \ from the nearest data points of differing categories. The application of SVM\
    \ extends beyond just this study; it has traditionally been employed for routine\
    \ maintenance tasks like fault detection in hardware and software systems. For\
    \ instance, SVM was applied to distinguish performance issues in heating ventilation\
    \ air-conditioning and cooling chillers by categorizing the data into two classes:\
    \ \"fault detected\" and \"no fault detected.\" While machine learning techniques\
    \ have been explored to address sensor location challenges for daylight harvesting,\
    \ this particular\n\nFurthermore, the impact of Negative Bias Temperature Instability\
    \ (NBTI), a primary cause of circuit performance deterioration, can be assessed\
    \ through a structural test to gauge the integrity of ICs. NBTI aging has been\
    \ shown to influence the threshold voltage in PMOS devices [83,88–91]. As mathematically\
    \ developed by Wang et al. [92] equation (1) details the calculation for \"∆ℎ\"\
    \ as influenced by NBTI for a given time \"\". In this formula, \"\" signifies\
    \ the impact of the electric field, temperature, and carrier concentration. The\
    \ time exponential constant is denoted as \"\". The term \"\" indicates the signal\
    \ probability, representing the portion of time a transistor is under NBTI stress\
    \ within a\n\n*Electronics* **2023**, *12*, x FOR PEER REVIEW 12 of 22\n\nA recent\
    \ study using SVM was performed by Kent et al. [87] and utilized a linear support\
    \ vector machine (SVM), a supervised machine-learning model, to classify distinct\
    \ categories. SVM works by creating a hyperplane that best separates data points\
    \ from different categories, maximizing the margin between them. Its principle\
    \ lies in ensuring the hyperplane is positioned to maximize the distance from\
    \ the nearest data points of differing categories. The application of SVM extends\
    \ beyond just this study; it has traditionally been employed for routine maintenance\
    \ tasks like fault detection in hardware and software systems. For instance, SVM\
    \ was applied to distinguish performance issues in heating ventilation air-conditioning\
    \ and cooling chillers by categorizing the data into two classes: \"fault detected\"\
    \ and \"no fault detected.\" While machine learning techniques have been explored\
    \ to address sensor location challenges for daylight harvesting, this particular\n\
    \nFurthermore, the impact of Negative Bias Temperature Instability (NBTI), a primary\
    \ cause of circuit performance deterioration, can be assessed through a structural\
    \ test to gauge the integrity of ICs. NBTI aging has been shown to influence the\
    \ threshold voltage in PMOS devices [83,88–91]. As mathematically developed by\
    \ Wang et al. [92] equation (1) details the calculation for \"∆ℎ\" as influenced\
    \ by NBTI for a given time \"\". In this formula, \"\" signifies the impact of\
    \ the electric field, temperature, and carrier concentration. The time exponential\
    \ constant is denoted as \"\". The term \"\" indicates the signal probability,\
    \ representing the portion of time a transistor is under NBTI stress within a\n\
    \n$$\n\\Delta V\\_{th} = \\left( \\mathbb{E} \\sqrt{K\\_o^2 \\times T\\_{clk}\
    \ \\times \\frac{\\alpha}{1 - \\rho\\_t^{\\frac{1}{2n}}}} \\mathbb{I} \\right)^{2n}\
    \ \\tag{2}\n$$\n\nmajority of ICs produced with cutting-edge technology, all without\
    \ the need for additional chip components. Leveraging non-invasive gate-level\
    \ characterization, this method\n\nAging-based fingerprints are distinct characteristics\
    \ that develop in electronic devices, such as integrated circuits, over time due\
    \ to aging effects. These fingerprints offer valuable potential for enhancing\
    \ hardware security by enabling the development of Aging-based fingerprints are\
    \ distinct characteristics that develop in electronic devices, such as integrated\
    \ circuits, over time due to aging effects. These fingerprints offer valuable\
    \ potential for enhancing hardware security by enabling the development of In\
    \ the realm of IC verification through structural tests, there is a noteworthy\
    \ explo‑ ration of using ICs' distinctive timing path signatures, stemming from\
    \ inherent process variations, as a basis for creating Physical Unclonable Functions\
    \ (PUFs) for identification purposes. Structural tests encompass assessments like\
    \ leakage, timing, and dynamic power measurements. These evaluations have the\
    \ potential to uniquely identify the vast majority of ICs produced with cutting‑edge\
    \ technology, all without the need for additional chip components. Leveraging\
    \ non‑invasive gate‑level characterization, this method derives continuous values\
    \ capable of generating unique chip identifiers. The wealth of available test\
    \ vectors enhances the diversity of challenge‑response pairings, opening up new\
    \ av‑ enues for IC monitoring and security protocols[[93–](#page-20-14)[95\\]](#page-20-15).\
    \ This innovative approach holds promise for bolstering IC authentication and\
    \ security measures while maintaining cost‑ efficiency and scalability.\n\n####\
    \ *3.3. Aging‑Based Fingerprint Testing*\n\nAging‑based fingerprints are distinct\
    \ characteristics that develop in electronic devices, such as integrated circuits,\
    \ over time due to aging effects. These fingerprints offer valuable potential\
    \ for enhancing hardware security by enabling the development of identification\
    \ or authentication methods based on the natural wear and tear of these devices.\
    \ Various factors, including Negative Bias Temperature Instability, Hot Carrier\
    \ Injection, and Time‑ dependent Dielectric Breakdown, contribute to changes in\
    \ the performance of transistors and other components as electronic devices undergo\
    \ aging. These changes are unique to each device due to process variations and\
    \ patterns of usage, resulting in the creation of individualized aging‑based fingerprints[[72](#page-19-15)[,96](#page-20-16)].\n\
    \nIn the context of this paper[[97\\]](#page-20-17), a cost‑effective approach\
    \ is presented for safeguarding secret keys using Physical Unclonable Functions\
    \ (PUFs), leveraging the unique hardware identity of sensor nodes. Additionally,\
    \ a resource‑efficient fingerprint recognition system is introduced, designed\
    \ specifically for deployment in low‑cost sensor nodes. PUFs are also employed\
    \ for obfuscation to protect sensitive biometric data. The authors propose a two‑factor\
    \ authentication method to verify the source of collected data, relying on the\
    \ unique physical identity of the trusted sensor node and the physical presence\
    \ of an autho‑ rized individual overseeing data transfer. Experimental results\
    \ indicate the feasibility of implementing the proposed PUF‑based solution in\
    \ the SRAMs of commercially available Bluetooth Low‑energy chips within sensor\
    \ nodes. The fingerprint identification technol‑ ogy is based on \"QFingerMap16\"\
    , utilizing unique texture‑based features. The research further delves into the\
    \ resilience, security, and privacy aspects of the suggested sensor nodes, drawing\
    \ from experimental data involving PUFs and fingerprints sourced from public and\
    \ standardized databases. This multifaceted approach offers promising implica‑\
    \ tions for enhancing security and privacy in low‑cost sensor node applications.\n\
    \n#### **4. Counterfeit Avoidance Method**\n\n#### *4.1. PUF‑Based Avoidance Techniques*\n\
    \nThere are two main categories of Physical Unclonable Functions (PUFs): delay‑based\
    \ PUFs and memory‑based PUFs. Each of these utilize different aspects of the underlying\
    \ technology. These PUFs offer several advantages, including unpredictability,\
    \ resistance to tampering, cost‑effectiveness, and dynamic key generation. However,\
    \ they also present challenges such as sensitivity to environmental factors, low\
    \ entropy, and susceptibility to modeling attacks. Ongoing research and development\
    \ in PUF design, error correction, and countermeasures aim to address these issues,\
    \ making PUFs a promising solution for hardware security.\n\nOne notable implementation\
    \ is the Ring‑Oscillator PUF, mentioned in article[[98\\]](#page-20-18), which\
    \ uses an oscillator with an odd number of gates to generate distinct signatures\
    \ sen‑ sitive to manufacturing variations. However, delay‑based PUFs suffer from\
    \ spatial corre‑ lations in process parameters, limiting their uniqueness and\
    \ making them susceptible to side‑channel attacks.\n\nTo overcome these limitations,\
    \ the authors of paper[[22\\]](#page-17-21) introduce the Process and Environmental\
    \ (PE)‑PUF. This PUF design takes into account process and ambient vari‑ ables\
    \ like temperature, power supply noise, and crosstalk, enhancing the randomness\
    \ and uniqueness of the generated signatures. The study employs a 90 nm‑implemented\
    \ seven‑ inverter ring oscillator with nearby interconnects, simulated using HSPICE.\n\
    \nIn [\\[99](#page-20-19)], researchers explore the application of deep learning\
    \ techniques to model at‑ tacks on double arbiter PUFs. The results demonstrate\
    \ that deep learning methods out‑ perform conventional machine learning approaches\
    \ like logistic regression and support vector machines in terms of predictive\
    \ accuracy. The success rate in attacks against 3‑1 DAPUFs exceeds 86%, surpassing\
    \ the previous record of 76%. Similarly, the accuracy in attacks against 4‑1 DAPUFs\
    \ ranges from 71% to 81.5%, surpassing the prior high of 63%.\n\nFinally, in[[100\\\
    ]](#page-20-20), authors propose an innovative SRAM architecture that facilitates\
    \ cost‑effective and widespread key generation by integrating dynamic and multi‑bit\
    \ static entropy generation in memory. This design retains a commercial bitcell,\
    \ a pitch‑matched peripheral, and compatibility with memory compiler designs.\
    \ Additionally, it incorpo‑ rates a True Random Number Generator (TRNG) and a\
    \ physically unclonable function (PUF) to enhance security.\n\n#### *4.2. Machine\
    \ Learning and Artificial Intelligence*\n\nAI and machine learning (ML) approaches\
    \ are increasingly being integrated into hard‑ ware design processes, providing\
    \ a fresh approach to addressing various phases and lay‑ ers of abstraction. By\
    \ estimating hardware overhead[[101\\]](#page-20-21), optimizing logic[[102\\\
    ]](#page-21-0), rout‑ ing[[103\\]](#page-21-1), and introducing test points [\\\
    [104](#page-21-2)], these techniques address scalability difficulties and accelerate\
    \ design completion. Using AI and ML in hardware design enables better op‑ timization,\
    \ more efficiency, and shorter development cycles.\n\nThe authors of the study[[105\\\
    ]](#page-21-3) analyze the viability of repurposing an existing neural network\
    \ to construct a robust Physically Unclonable Function in order to ensure safety\
    \ and reliability in Internet of Things and smart sensor applications. The Multilayer\
    \ Perceptron is the primary subject of this work. It is a feed‑forward neural\
    \ network with multiple lay‑ ers of completely coupled neurons. They consider\
    \ several network designs, each with its unique hidden layer depth and synaptic\
    \ weight accuracy. PUF criteria such as uniformity, uniqueness, bit‑aliasing,\
    \ and reliability are used to assess the quality of the proposed solu‑ tion. Another\
    \ work[[106\\]](#page-21-4) introduces \"HW2VEC\", a free and open source graph‑learning\
    \ tool developed to let researchers investigate hardware security applications\
    \ using graph representations. HW2VEC is a tool that translates non‑Euclidean\
    \ hardware designs into an embedding in a Euclidean network and extracts graph\
    \ representations from hardware designs at various abstraction levels.\n\n####\
    \ *4.3. Hardware Metering*\n\nHardware metering, also referred to as integrated\
    \ circuit metering, serves as a crucial mechanism for monitoring and safeguarding\
    \ integrated circuits (ICs) once they have been manufactured. This becomes particularly\
    \ significant as many businesses choose to out‑ source their IC manufacturing\
    \ to companies located in different countries, exposing their designs to potential\
    \ theft or replication risks. To address this challenge, experts have devel‑ oped\
    \ various methods for monitoring and managing ICs, with passive and active metering\
    \ emerging as the two predominant approaches.\n\nIn passive metering systems,\
    \ individual chips are initially identified separately to de‑ tect any unauthorized\
    \ or counterfeit chips effectively. Active metering, on the other hand, provides\
    \ designers with the capability to control specific chip operations, enhancing\
    \ chip security. This article provides an overview of hardware metering, exploring\
    \ its key con‑ cepts and diverse methodologies.\n\nIt is worth noting that hardware\
    \ watermarking, while related, differs from hardware metering. While hardware\
    \ metering involves actively or passively tagging individual chips, hardware watermarking\
    \ embeds its mark within the design file rather than on the individ‑ ual chips.\
    \ Watermarking, however, has limitations in combatting counterfeiting as it can‑\
    \ not differentiate between chips of the same design. In contrast, hardware metering\
    \ offers a more effective solution by assigning a unique identity to each chip\
    \ or its functionality, enabling differentiation among chips with identical architectures.\n\
    \n#### Passive and Active IC Metering\n\nPassive metering represents a method\
    \ for the identification of counterfeit chips by monitoring and analyzing their\
    \ operational data. In essence, this approach aims to dis‑ tinguish genuine chips\
    \ from counterfeits that replicate the control behaviors of legitimate chips.\
    \ Passive metering proves particularly effective when dealing with a large number\
    \ of chips that can be coupled, allowing for the examination of their individual\
    \ control paths. This examination is achieved through techniques like XOR operations\
    \ and additional par‑ ity tests [\\[107](#page-21-5)].\n\nHowever, as noted in[[108\\\
    ]](#page-21-6), current passive metering methods suffer from various limitations,\
    \ including challenges in quantifying chip IDs accurately, high associated costs,\
    \ and issues related to scalability. To address these issues, the authors propose\
    \ two signif‑ icant changes as potential solutions. Firstly, they suggest utilizing\
    \ manifestation proper‑ ties to extract physical‑level characteristics, such as\
    \ gate threshold voltage, which remain independent of aging, temperature variations,\
    \ and supply voltage. Secondly, to reduce expenses, expedite time‑to‑market, and\
    \ enhance scalability, they advocate for IC segmen‑ tation. This segmentation\
    \ involves selecting only a subset of gates for detailed characteri‑ zation.\n\
    \nIn[[107\\]](#page-21-5), the authors delve into the horizontal semiconductor\
    \ business model, which exposes designers' intellectual property (IP) to piracy\
    \ and excessive production of inte‑ grated circuits due to the transparency prevalent\
    \ across the production chain. To com‑ bat these challenges and enable chip‑tracking\
    \ post production, they introduce the concept of active hardware metering. The\
    \ authors also discuss potential risks and countermea‑ sures while presenting\
    \ a low‑overhead hardware solution based on an autonomous syn‑ thesis method.\n\
    \nMoreover, Ref. [\\[109](#page-21-7)] introduces a novel approach to external\
    \ active IC metering that utilizes a PUF (Physically Unclonable Function) design\
    \ to generate keys. In contrast to tra‑ ditional encryption modules, they employ\
    \ a modified Finite State Machine (FSM) to pro‑ tect PUF‑based keys from unauthorized\
    \ access. By integrating the retrieval method within the high‑level design of\
    \ the FSM, they significantly reduce the time and effort required to securely\
    \ recover PUF‑based keys, especially when the original FSM is reused.\n\n### *4.4.\
    \ Secure Split Testing*\n\nThe \"Secure Split‑Test\" (SST) is a newly introduced\
    \ approach that restores testing au‑ thority to the owner of Intellectual Property\
    \ (IP). With SST, chips are securely locked during the evaluation phase. Only\
    \ the IP proprietor has the capability to decipher the locked test outcomes and\
    \ grant access to the chips that meet the set criteria. SST's main objective is\
    \ to halt the distribution of excess or flawed chips within the supply chain.\
    \ Compared to its predecessor, this method streamlines the dialogue between the\
    \ chip‑making foundry and the IP owner. Evidence suggests that SST not only bolsters\
    \ security but also mitigates communication obstacles. The researchers Contreras\
    \ et al.[[110\\]](#page-21-8) introduced a unique \"SST Structure\" to augment\
    \ the protection of integrated circuits. This design incorporates a\n\nlocking\
    \ mechanism known as the \"XORF mask\", which consists of three‑way XOR gates\
    \ situated in less crucial circuit routes. The XORF acts as a switch; it serves\
    \ as a conduit when two inputs match, and as a converter when they differ. Placing\
    \ these XORFs, es‑ pecially near scan flip‑flop entry points, can alter specific\
    \ circuit feedback. True Random Number Generators (TRNGs) are employed to add\
    \ an element of randomness, drawing from physical occurrences such as clock inconsistencies\
    \ and temperature variations for en‑ tropy. TRNG outputs are saved in a non‑reusable\
    \ memory for consistency. The design also incorporates RSA encryption to fortify\
    \ the IC's security, with a complex key system (TKEY and FKEY) governing the XORF\
    \ operations. An additional \"Scan‑Locking Block\", employing three‑way XOR gates\
    \ and key‑driven functions (KDFs), has been integrated to enhance defenses against\
    \ potential threats.\n\nIn the following sections, we present two comprehensive\
    \ tables that encapsulate the myriad of challenges encountered in the realm of\
    \ counterfeit electronics. Table [1](#page-14-0), titled \"Implementation Challenges\
    \ of Counterfeit Detection Methods\", delves into the obstacles faced when identifying\
    \ fake components through various detection strategies. It outlines the practical\
    \ difficulties and technical intricacies inherent to the current detection method‑\
    \ ologies. Following this, Table [2,](#page-14-1) \"Implementation Challenges\
    \ of Counterfeit Avoidance Methods\", shifts the focus to preventative strategies.\
    \ It scrutinizes the hurdles in imple‑ menting effective systems designed to thwart\
    \ the infiltration of counterfeit electronics into the supply chain, highlighting\
    \ the proactive measures necessary to safeguard against such threats. Together,\
    \ these tables provide a dual perspective on the fight against electronic counterfeiting,\
    \ offering insights into both reactive detection and proactive prevention.\n\n\
    #### <span id=\"page-14-0\"></span>**Table 1.** Implementation challenges of counterfeit\
    \ detection methods.\n\n| Detection Scheme                                   |\
    \ Dependability | Distinctiveness  | Tamper Proofing | Chip Area<br>Requirement\
    \ | Target Component           | Deployment Cost  |\n|----------------------------------------------------|---------------|------------------|-----------------|--------------------------|----------------------------|------------------|\n\
    | Incoming<br>Inspections                            | Varies        | Moderate\
    \         | Low             | Low                      | Digital/Analog/RF,<br>etc.\
    \ | Low              |\n| Exterior Tests                                     |\
    \ Moderate      | Moderate         | Moderate        | Low                   \
    \   | Digital/Analog/RF,<br>etc. | Moderate         |\n| Interior Tests      \
    \                               | High          | High             | High    \
    \        | High                     | Digital/Analog/RF,<br>etc. | High      \
    \       |\n| Material Analysis                                  | High       \
    \   | Moderate to High | High            | Very High                | Digital/Analog/RF,<br>etc.\
    \ | Very High        |\n| Parametric/Burn‑in<br>Test and Structural<br>Tests |\
    \ Very High     | High             | Very High       | Moderate              \
    \   | Digital ICs                | Moderate to High |\n\n<span id=\"page-14-1\"\
    ></span>**Table 2.** Implementation challenges of counterfeit avoidance methods.\n\
    \n| Avoidance Scheme                             | Dependability     | Distinctiveness\
    \  | Tamper Proofing | Chip Area<br>Requirement | Target Component | Deployment\
    \ Cost |\n|----------------------------------------------|-------------------|------------------|-----------------|--------------------------|------------------|-----------------|\n\
    | Physically<br>Unclonable<br>Functions (PUFs) | Moderate          | High    \
    \         | High            | Low                      | Digital ICs      | Moderate\
    \        |\n| Passive Hardware<br>Metering                 | Moderate to High\
    \  | High             | Moderate        | Low                      | Digital ICs\
    \      | Moderate        |\n| Active Hardware<br>Metering                  | High\
    \ to Very High | High             | Moderate        | Moderate               \
    \  | Digital ICs      | Moderate        |\n| Machine<br>Learning/Computer<br>Vision\
    \       | High              | Moderate to High | Low             | Varies    \
    \               | Digital ICs      | Low             |\n| Secure Split Test<br>(SST)\
    \                   | NA                | NA               | Moderate        |\
    \ Moderate                 | Digital ICs      | High            |\n\n- (a) **Dependability:**\
    \ Many of these methods grapple with the challenge of consistent per‑ formance.\
    \ For instance, a PUF's reaction should remain unchanged across different environmental\
    \ conditions, disturbances, and over time. Such issues do not plague active and\
    \ passive hardware metering, though its ability to prevent counterfeiting is still\
    \ under examination. Machine Learning, since the accuracy of its results depends\
    \ on vast dataset, has a high reliability. Incoming Tests ensure initial quality\
    \ but might vary in dependability based on the test's comprehensiveness.\n- (b)\
    \ **Distinctiveness:** This evaluates the dissimilarity between chip identifications.\
    \ Ide‑ ally, two identifiers should have a 50% probability of differing under\
    \ identical condi‑ tions. Strong distinctiveness hinders the ability of counterfeiters\
    \ to predict new IDs after obtaining a collection. PUFs and magnetic PUFs yield\
    \ almost perfect results in this aspect. Common programming languages can produce\
    \ truly random numbers, typically used for chip identification.\n- (c) **Tamper\
    \ Proofing:** This gauges the challenges counterfeiters face in trying to bypass\
    \ anti‑counterfeit measures. The locked results of SSTs offer an appreciably high\
    \ taper resistance to the chips. Material analysis imposes a high level of difficulty\
    \ in detection because counterfeiting happens at the material composition level.\
    \ Meanwhile, exte‑ rior tests detect tampering at the surface level. Machine Learning,\
    \ combined with Material Analysis, can detect counterfeit actions at a compositional\
    \ level.\n- (d) **Chip Area Requirement:** This represents the space required\
    \ on the chip that is needed for anti‑counterfeit tools. Machine Learning/Computer\
    \ Vision, on the other hand, might demand significant computational resources\
    \ but not necessarily chip space. In contrast, hardware metering, SST, and poly\
    \ fuse‑based sensors require more space.\n- (e) **Targeted Component Types:**\
    \ This details the component kinds these anti‑counterfeit tools are suited for.\
    \ Parametric/Burn‑in and Structural Tests are mostly targeted at digital components,\
    \ while Incoming Tests can apply to both. PUFs can be used in both analog and\
    \ digital parts while other tools are more suited for digital components.\n- (f)\
    \ **Deployment Cost:** Setting up a PUF involves maintaining a secure challenge‑response\
    \ database, alongside the space it occupies. For hardware metering and SST, extensive\
    \ communication between the designer and the manufacturer hikes up the price.\
    \ Tools like CDIR come with their own spatial costs. Verifying integrated circuits\
    \ demands affordable equipment, but the intricate verification for applied plant\
    \ DNA on the IC as an interior test is high.\n\n#### **5. Challenges Facing the\
    \ Microelectronics Industry in Adopting Trust**\n\nThe COVID‑19 pandemic has had\
    \ a profound impact on the electronics industry, sig‑ nificantly increasing the\
    \ prevalence and quality of counterfeit electronics. These attacks have grown\
    \ more sophisticated over time, necessitating equally complex countermeasures\
    \ in response. Traditional physical inspection countermeasures and confidence‑building\
    \ strategies are both expensive and risky, presenting substantial challenges.\
    \ The time‑consuming process of physically inspecting and testing counterfeit\
    \ electronics further exacerbates the problem. Additionally, as commercial and\
    \ military technologies converge, ethical concerns in the IT industry have arisen,\
    \ prompting businesses to evaluate how their products' capabilities and applications,\
    \ whether used by the Department of Defense or its adversaries, impact national\
    \ security.\n\nThe growing reliance on microelectronics across various industries\
    \ has heightened the demand for reliable and secure hardware solutions. In the\
    \ realm of hardware security, verifying the authenticity and integrity of microelectronic\
    \ components has become a daunt‑ ing task. The intricacy of modern supply chains\
    \ makes comprehensive monitoring from inception to final assembly challenging,\
    \ increasing the risk of electronic equipment being composed of subpar materials,\
    \ infected with malware, or subject to intellectual property (IP) theft.\n\nAnother\
    \ challenge in the domain of trusted microelectronics is the ever‑evolving land‑\
    \ scape of threats and attack vectors. Hackers continuously devise new methods\
    \ to exploit\n\nhardware systems, necessitating ongoing vigilance from security\
    \ researchers and design‑ ers. Side‑channel attacks, for instance, rely on extracting\
    \ sensitive data through the phys‑ ical implementation of a system. Given these\
    \ trends, microelectronics security remains a formidable challenge. As technology\
    \ advances, physical components become increasingly complex and interconnected,\
    \ making it challenging to defend against both existing and emerging threats.\
    \ Consequently, it is evident that addressing these evolving dangers re‑ quires\
    \ the integration of Physically Unclonable Functions (PUFs), robust design principles,\
    \ and machine learning‑based approaches to hardware security.\n\n#### **6. Conclusions**\n\
    \nThis comprehensive review underscores the significant challenges and threats\
    \ con fronting the microelectronics industry, particularly from counterfeit components.\
    \ As ex‑ plored in Section [2,](#page-3-1) \"Counterfeit Attack Modes\", the industry\
    \ is battling a range of so‑ phisticated methods employed by malicious entities\
    \ to introduce counterfeit components, undermining the integrity of both individual\
    \ electronic units and larger systems. The vul‑ nerabilities these attack modes\
    \ present are not just technical but also ripple into economic, ethical, and security\
    \ realms.\n\nIn response to these threats, Section [3,](#page-5-1) \"Counterfeit\
    \ Detection\", delves into the multi‑ faceted strategies and methods to identify\
    \ and mitigate the presence of counterfeit com‑ ponents. These detection mechanisms\
    \ are essential in ensuring the security, reliability, and efficiency of electronic\
    \ systems. However, the ever‑evolving nature of attack vectors demands ongoing\
    \ research, innovation, and refinement in these detection methodologies.\n\nBeyond\
    \ the direct threats of counterfeiting, broader challenges have surfaced, such\
    \ as the ethical dilemmas stemming from the overlap of commercial and military\
    \ technologies and the heightened risks brought on by the COVID‑19 pandemic. The\
    \ complex interplay of these challenges necessitates a cohesive, interdisciplinary\
    \ response, ranging from techno‑ logical solutions like Physically Unclonable\
    \ Functions (PUFs) and machine learning‑based approaches to policy interventions\
    \ and universally accepted industry standards.\n\nFurthermore, a comparison of\
    \ the implementation challenges involved in both the avoidance and detection techniques\
    \ have been explored under the headings of dependabil‑ ity, distinctiveness, tamper\
    \ proofing, chip area overhead and deployment costs. It must be noted, however,\
    \ that this provides a generalized perspective. The actual dependabil‑ ity, distinctiveness,\
    \ tamper proofing, chip area overhead, and ease of implementation may vary depending\
    \ on the specific methodologies and tools used within each scheme.\n\nIn summary,\
    \ the microelectronics industry is at a critical juncture. Trust and security\
    \ are non‑negotiable pillars for its sustained growth and evolution. By integrating\
    \ insights from various sections, it is evident that proactive measures, collaborative\
    \ efforts, and a commitment to continuous learning are vital to navigate the multifarious\
    \ challenges and ensure a resilient future for microelectronics.\n\n**Author Contributions:**\
    \ Conceptualization, K.N., S.D. and V.B.; writing—original draft preparation,\
    \ K.N.; writing—review and editing, V.B.; supervision, V.B.; funding acquisition,\
    \ F.L. and V.B. All authors have read and agreed to the published version of the\
    \ manuscript.\n\n**Funding:** This research was funded by the U.S. Air Force via\
    \ the Assured Digital Microelectronics Education and Training Ecosystem (ADMETE)\
    \ grant (FA8650‑20‑2‑1136).\n\n**Data Availability Statement:** The datasets generated\
    \ and/or analyzed during the current study are available in the \"ERAI\" repository\
    \ at <https://www.erai.com/> (accessed on 16 April 2022).\n\n**Conflicts of Interest:**\
    \ The authors declare no conflict of interest. Additionally, The funders had no\
    \ role in the design of the study; in the collection, analyses, or interpretation\
    \ of data; in the writing of the manuscript; or in the decision to publish the\
    \ results.\n\n# **References**\n\n- <span id=\"page-17-0\"></span>1. Bhunia, S.;\
    \ Tehranipoor, M. Chapter 1—Introduction to Hardware Security. In *Hardware Security*;\
    \ Bhunia, S., Tehranipoor, M., Eds.; Morgan Kaufmann: Burlington, MA, USA, 2019;\
    \ pp. 1–20.\n- <span id=\"page-17-1\"></span>2. Fazzari Booz, S.; Hamilton, A.;\
    \ Narumi, R. *New & Old Challenges for Trusted and Assured Microelectronics*;\
    \ Booz Allen Hamilton: Arlington, VA, USA, 2019.\n- <span id=\"page-17-2\"></span>3.\
    \ Shah, A. Europe, US Warn of Fake‑Chip Danger to National Security, Critical\
    \ Systems. The Register. 2022. Available online: [https://www.theregister.com/2022/03/18/eu\\\
    \\_us\\\\_counterfeit\\\\_chips/](https://www.theregister.com/2022/03/18/eu_us_counterfeit_chips/)\
    \ (accessed on 13 April 2023).\n- <span id=\"page-17-3\"></span>4. Zeljka, Z.\
    \ Supply Chain Compromise: Adding Undetectable Hardware Trojans to Integrated\
    \ Circuits. Help Net Security. 2018. Available online: [https://www.helpnetsecurity.com/2018/12/10/hardware‑trojans/](https://www.helpnetsecurity.com/2018/12/10/hardware-trojans/)\
    \ (accessed on 19 March 2022).\n- <span id=\"page-17-4\"></span>5. Uppal, R. Threats\
    \ to ICT Supply Chains including Counterfeit Electronic Components and Hardware\
    \ Trojans Present Crit‑ ical Risk to Military and Security Systems. International\
    \ Defense Security & Technology Inc. 2020. Available online: [https://idstch.com/threats/threats‑to‑ict‑supply‑chains‑including‑counterfeit‑electronic‑components‑and‑hardware‑trojans‑](https://idstch.com/threats/threats-to-ict-supply-chains-including-counterfeit-electronic-components-and-hardware-trojans-present-critical-risk-to-military-and-security-systems/)\
    \ [present‑critical‑risk‑to‑military‑and‑security‑systems/](https://idstch.com/threats/threats-to-ict-supply-chains-including-counterfeit-electronic-components-and-hardware-trojans-present-critical-risk-to-military-and-security-systems/)\
    \ (accessed on 19 March 2022).\n- <span id=\"page-17-5\"></span>6. Hambling, D.\
    \ Pentagon's \"Kill Switch\": Urban Myth? Wired. 2008. Available online: [https://www.wired.com/2008/05/kill‑](https://www.wired.com/2008/05/kill-switch-urb/)\
    \ [switch‑urb/](https://www.wired.com/2008/05/kill-switch-urb/) (accessed on 27\
    \ March 2023).\n- <span id=\"page-17-6\"></span>7. McKeefry, H. Counter the Counterfeiters.\
    \ DigiKey. 2021. Available online: [https://www.digikey.com/en/blog/counter‑the‑](https://www.digikey.com/en/blog/counter-the-counterfeiters)\
    \ [counterfeiters](https://www.digikey.com/en/blog/counter-the-counterfeiters)\
    \ (accessed on 18 April 2022).\n- <span id=\"page-17-7\"></span>8. Brett, D. Counterfeit\
    \ Electronic Parts: A Multibillion‑Dollar Black Market. Trenton Systems. 2020.\
    \ Available online: [https:](https://www.trentonsystems.com/blog/counterfeit-electronic-parts)\
    \ [//www.trentonsystems.com/blog/counterfeit‑electronic‑parts](https://www.trentonsystems.com/blog/counterfeit-electronic-parts)\
    \ (accessed on 19 March 2022).\n- <span id=\"page-17-8\"></span>9. The Threat\
    \ of Counterfeit Components to Electronic Supply Chains. Nanotech. Available online:\
    \ [https://www.nanosecurity.ca/](https://www.nanosecurity.ca/counterfeit-electronic-components/)\
    \ [counterfeit‑electronic‑components/](https://www.nanosecurity.ca/counterfeit-electronic-components/)\
    \ (accessed on 19 March 2022).\n- <span id=\"page-17-9\"></span>10. IEEE Transactions\
    \ on Components and Packaging Technologies Publication Information. *IEEE Trans.\
    \ Compon. Packag. Technol.* **2007**, *30*, C2. [\\[CrossRef\\]](https://doi.org/10.1109/TCAPT.2007.912781)\n\
    - <span id=\"page-17-10\"></span>11. Bastia, S. Next generation technologies to\
    \ combat counterfeiting of electronic components. *Compon. Packag. Technol. IEEE\
    \ Trans.* **2002**, *25*, 175–176.[[CrossRef](https://doi.org/10.1109/6144.991192)]\n\
    - <span id=\"page-17-11\"></span>12. Akhoundov, D. *2022 Annual Report*; ERAI,\
    \ Inc.: Naples, FL, USA, 2022.\n- <span id=\"page-17-12\"></span>13. Murdock,\
    \ K.; Oswald, D.; Garcia, F.D.; Van Bulck, J.; Gruss, D.; Piessens, F. Plundervolt:\
    \ Software‑Based Fault Injection Attacks against Intel SGX. In Proceedings of\
    \ the 2020 IEEE Symposium on Security and Privacy (SP), San Francisco, CA, USA,\
    \ 18–21 May 2020; pp. 1466–1482.\n- <span id=\"page-17-13\"></span>14. Tehranipoor,\
    \ M.; Koushanfar, F. A Survey of Hardware Trojan Taxonomy and Detection. *IEEE\
    \ Des. Test Comput.* **2010**, *27*, 10–25. [\\[CrossRef\\]](https://doi.org/10.1109/MDT.2010.7)\n\
    - <span id=\"page-17-14\"></span>15. Intel. Speculative Execution. 2018. Available\
    \ online: [https://www.intel.com/content/www/us/en/developer/articles/technical/](https://www.intel.com/content/www/us/en/developer/articles/technical/software-security-guidance/technical-documentation/introduction-speculative-side-channel-methods.html)\
    \ [software‑security‑guidance/technical‑documentation/introduction‑speculative‑side‑channel‑methods.html](https://www.intel.com/content/www/us/en/developer/articles/technical/software-security-guidance/technical-documentation/introduction-speculative-side-channel-methods.html)\
    \ (accessed on 16 March 2023).\n- <span id=\"page-17-15\"></span>16. Dewan, M.C.\
    \ Study of Speculative Execution and Branch Prediction. 2006. Available online:\
    \ [https://citeseerx.ist.psu.edu/](https://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=EBE980ABF71E4B8C0055F14D3DDAC3F2?doi=10.1.1.119.2934&rep=rep1&type=pdf)\
    \ [viewdoc/download;jsessionid=EBE980ABF71E4B8C0055F14D3DDAC3F2?doi=10.1.1.119.2934&rep=rep1&type=pdf](https://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=EBE980ABF71E4B8C0055F14D3DDAC3F2?doi=10.1.1.119.2934&rep=rep1&type=pdf)\
    \ (accessed on 16 March 2023).\n- <span id=\"page-17-16\"></span>17. Lee, J.W.;\
    \ Lim, D.; Gassend, B.; Suh, G.E.; Van Dijk, M.; Devadas, S. A Technique to Build\
    \ a Secret Key in Integrated Circuits for Identification and Authentication Applications.\
    \ In Proceedings of the 2004 Symposium on VLSI Circuits, Honolulu, HI, USA, 17–19\
    \ June 2004; Digest of Technical Papers (IEEE Cat. No.04CH37525). IEEE: Piscataway,\
    \ PJ, USA, 2004; pp. 176–179.\n- <span id=\"page-17-17\"></span>18. Suh, G.E.;\
    \ Devadas, S. Physical Unclonable Functions for Device Authentication and Secret\
    \ Key Generation. In Proceedings of the 2007 44th ACM/IEEE Design Automation Conference,\
    \ San Diego, CA, USA, 4–8 June 2007; pp. 9–14.\n- <span id=\"page-17-18\"></span>19.\
    \ Gassend, B.; Clarke, D.; Van Dijk, M.; Devadas, S. Silicon Physical Random Functions.\
    \ In Proceedings of the 9th ACM Conference on Computer and Communications Security,\
    \ Washington, DC, USA, 18–22 November 2002.\n- <span id=\"page-17-19\"></span>20.\
    \ Ranasinghe, C.; Engels, D.W.; Cole, P.H. Security and Privacy: Modest Proposals\
    \ for Low‑Cost RFID Systems. Available on‑ line: [https://www.semanticscholar.org/paper/Security‑and‑Privacy%3A‑Modest‑Proposals‑for‑Low‑Cost‑Ranasinghe‑Engels/](https://www.semanticscholar.org/paper/Security-and-Privacy%3A-Modest-Proposals-for-Low-Cost-Ranasinghe-Engels/4c755bb9751f148a769737addc3e0fb14de42341)\
    \ [4c755bb9751f148a769737addc3e0fb14de42341](https://www.semanticscholar.org/paper/Security-and-Privacy%3A-Modest-Proposals-for-Low-Cost-Ranasinghe-Engels/4c755bb9751f148a769737addc3e0fb14de42341)\
    \ (accessed on 27 September 2023).\n- <span id=\"page-17-20\"></span>21. Rührmair,\
    \ U.; Sehnke, F.; Sölter, J.; Dror, G.; Devadas, S.; Schmidhuber, J. Modeling\
    \ Attacks on Physical Unclonable Functions. In Proceedings of the 17th ACM Conference\
    \ on Computer and Communications Security, Chicago, IL, USA, 4–8 October 2010;\
    \ Association for Computing Machinery: New York, NY, USA, 2010; pp. 237–249.\n\
    - <span id=\"page-17-21\"></span>22. Wang, X.; Tehranipoor, M. Novel Physical\
    \ Unclonable Function with Process and Environmental Variations. In Proceedings\
    \ of the 2010 Design, Automation & Test in Europe Conference & Exhibition (DATE\
    \ 2010), Dresden, Germany, 8–12 March 2010; pp. 1065–1070.\n- <span id=\"page-17-22\"\
    ></span>23. Monjur, M.M.R.; Heacock, J.; Calzadillas, J.; Mahmud, M.; Roth, J.;\
    \ Mankodiya, K.; Sazonov, E.; Yu, Q. Hardware Security in Sensor and its Networks.\
    \ *Front. Sens.* **2022**, *3*, 850056.[[CrossRef\\]](https://doi.org/10.3389/fsens.2022.850056)\n\
    - <span id=\"page-17-23\"></span>24. Shivakumara, T.; Patil, R.M.; Muneshwara,\
    \ M.S. Review Paper on Dynamic Mechanisms of Data Leakage Detection and Preven‑\
    \ tion. *Int. J. Comput. Sci. Eng.* **2019**, *7*, 349–358.\n- <span id=\"page-17-24\"\
    ></span>25. Asadizanjani, N.; Rahman, M.T.; Tehranipoor, M. (Eds.) Package Security.\
    \ In *Physical Assurance: For Electronic Devices and Systems*; Springer International\
    \ Publishing: Cham, Switzerland, 2021; pp. 155–177.\n- <span id=\"page-18-0\"\
    ></span>26. Sharief, S.; Chahal, P.; Alocilja, E. Application of DNA sequences\
    \ in anti‑counterfeiting: Current progress and challenges. *Int. J. Pharm.* **2021**,\
    \ *602*, 120580. [\\[CrossRef\\]](https://doi.org/10.1016/j.ijpharm.2021.120580)\n\
    - <span id=\"page-18-1\"></span>27. Torrance, R.; James, D. The State‑of‑the‑Art\
    \ in IC Reverse Engineering. In *International Workshop on Cryptographic Hardware\
    \ and Embedded Systems*; Springer: Berlin/Heidelberg, Germany, 2009; pp. 363–381.\n\
    - <span id=\"page-18-2\"></span>28. Barenghi, A.; Breveglieri, L.; Koren, I.;\
    \ Naccache, D. Fault Injection Attacks on Cryptographic Devices: Theory, Practice,\
    \ and Countermeasures. *Proc. IEEE* **2012**, *100*, 3056–3076. [\\[CrossRef\\\
    ]](https://doi.org/10.1109/JPROC.2012.2188769)\n- <span id=\"page-18-3\"></span>29.\
    \ Balasch, J.; Gierlichs, B.; Verbauwhede, I. An In‑Depth and Black‑Box Characterization\
    \ of the Effects of Clock Glitches on 8‑Bit MCUs. In Proceedings of the 2011 Workshop\
    \ on Fault Diagnosis and Tolerance in Cryptography, Tokyo, Japan, 29 September\
    \ 2011; IEEE Computer Society: Washington, DC, USA, 2011; pp. 105–114.\n- <span\
    \ id=\"page-18-4\"></span>30. Kocher, P.; Jaffe, J.; Jun, B.; Rohatgi, P. Introduction\
    \ to differential power analysis. *J. Cryptogr. Eng.* **2011**, *1*, 5–27. [\\\
    [CrossRef\\]](https://doi.org/10.1007/s13389-011-0006-y)\n- <span id=\"page-18-5\"\
    ></span>31. Mangard, S.; Oswald, E.; Popp, T. *Power Analysis Attacks: Revealing\
    \ the Secrets of Smart Cards*; Springer: New York, NY, USA, 2007.\n- <span id=\"\
    page-18-6\"></span>32. Brier, E.; Clavier, C.; Olivier, F. Correlation Power Analysis\
    \ with a Leakage Model. In *Cryptographic Hardware and Embedded Systems—CHES 2004*;\
    \ Joye, M., Quisquater, J.‑J., Eds.; Springer: Berlin/Heidelberg, Germany, 2004;\
    \ pp. 16–29.\n- <span id=\"page-18-7\"></span>33. York, D. Chapter 3—Eavesdropping\
    \ and Modification. In *Seven Deadliest Unified Communications Attacks*; York,\
    \ D., Ed.; Syngress: Boston, MA, USA, 2010; pp. 41–69.\n- <span id=\"page-18-8\"\
    ></span>34. Alves, T.; Das, R.; Werth, A.; Morris, T. Virtualization of SCADA\
    \ Testbeds for Cybersecurity Research: A Modular Approach. *Comput. Secur.* **2018**,\
    \ *77*, 531–546.[[CrossRef\\]](https://doi.org/10.1016/j.cose.2018.05.002)\n-\
    \ <span id=\"page-18-9\"></span>35. Parmar, B. Protecting against spear‑phishing.\
    \ *Comput. Fraud. Secur.* **2012**, *2012*, 8–11.[[CrossRef\\]](https://doi.org/10.1016/S1361-3723(12)70007-6)\n\
    - <span id=\"page-18-10\"></span>36. Cybersecurity for Small Businesses. Federal\
    \ Communications Commission. Available online: <https://www.fcc.gov/communicat>\
    \ [ions‑business‑opportunities/cybersecurity‑small‑businesses](ions-business-opportunities/cybersecurity-small-businesses)\
    \ (accessed on 7 September 2023).\n- <span id=\"page-18-11\"></span>37. Subramanyan,\
    \ P.; Ray, S.; Malik, S. Evaluating the Security of Logic Encryption Algorithms.\
    \ In Proceedings of the 2015 IEEE International Symposium on Hardware Oriented\
    \ Security and Trust (HOST), Washington, DC, USA, 5–7 May 2015; pp. 137–143.\n\
    - <span id=\"page-18-12\"></span>38. Guin, U.; Huang, K.; DiMase, D.; Carulli,\
    \ J.M.; Tehranipoor, M.; Makris, Y. Counterfeit integrated circuits: A rising\
    \ threat in the global semiconductor supply chain. *Proc. IEEE* **2014**, *102*,\
    \ 1207–1228. [\\[CrossRef\\]](https://doi.org/10.1109/JPROC.2014.2332291)\n- <span\
    \ id=\"page-18-13\"></span>39. Baldini, G.; Steri, G.; Dimc, F.; Giuliani, R.;\
    \ Kamnik, R. Experimental Identification of Smartphones Using Fingerprints of\
    \ Built‑In Micro‑Electro Mechanical Systems (MEMS). *Sensors* **2016**, *16*,\
    \ 818. [\\[CrossRef\\]](https://doi.org/10.3390/s16060818) [\\[PubMed](https://www.ncbi.nlm.nih.gov/pubmed/27271630)]\n\
    - <span id=\"page-18-14\"></span>40. A Novel Technique for Effective Detection\
    \ of Recycled ICs Using Joint Parameter Analysis. IJARTET Journal—Academia.edu.\
    \ Available online: [https://www.academia.edu/9939115/A\\\\_Novel\\\\_Technique\\\
    \\_for\\\\_Effective\\\\_Detection\\\\_of\\\\_Recycled\\\\_ICs\\\\_Using\\\\_](https://www.academia.edu/9939115/A_Novel_Technique_for_Effective_Detection_of_Recycled_ICs_Using_Joint_Parameter_Analysis)\
    \ [Joint\\\\_Parameter\\\\_Analysis](https://www.academia.edu/9939115/A_Novel_Technique_for_Effective_Detection_of_Recycled_ICs_Using_Joint_Parameter_Analysis)\
    \ (accessed on 27 October 2023).\n- 41. Vosatka, J.; Stern, A.; Hossain, M.M.;\
    \ Rahman, F.; Allen, J.; Allen, M.; Farahmandi, F.; Tehranipoor, M. Tracking Cloned\
    \ Elec‑ tronic Components using a Consortium‑based Blockchain Infrastructure.\
    \ In Proceedings of the 2020 IEEE International Con‑ ference on Physical Assurance\
    \ and Inspection on Electronics, Washington, DC, USA, 28–29 July 2020; PAINE:\
    \ Durham, NH, USA, 2020.[[CrossRef](https://doi.org/10.1109/PAINE49178.2020.9337735)]\n\
    - <span id=\"page-18-15\"></span>42. Xiao, K. Techniques for Improving Security\
    \ and Trustworthiness of Integrated Circuits. Ph.D. Thesis, University of Connecticut,\
    \ Storrs, CT, USA, 2015.\n- <span id=\"page-18-16\"></span>43. Klocke, F.; Gorgels,\
    \ C.; Bouzakis, E.; Stuckenberg, A. Tool life increase of coated carbide tools\
    \ by micro blasting. *Prod. Eng.* **2009**, *3*, 453–459.[[CrossRef](https://doi.org/10.1007/s11740-009-0173-1)]\n\
    - 44. Melentiev, R.; Kang, C.; Shen, G.; Fang, F. Study on surface roughness generated\
    \ by micro‑blasting on Co‑Cr‑Mo bio‑implant. *Wear* **2019**, *428–429*, 111–126.[[CrossRef](https://doi.org/10.1016/j.wear.2019.03.005)]\n\
    - <span id=\"page-18-17\"></span>45. Gadge, M.; Lohar, G.; Chinchanikar, S. A\
    \ review on micro‑blasting as surface treatment technique for improved cutting\
    \ tool performance. *Mater. Today Proc.* **2022**, *64*, 725–730.[[CrossRef](https://doi.org/10.1016/j.matpr.2022.05.196)]\n\
    - <span id=\"page-18-18\"></span>46. Candler, R.N.; Park, W.T.; Hopcroft, M.;\
    \ Kim, B.; Kenny, T.W. Hydrogen diffusion and pressure control of encapsulated\
    \ mems resonators. In Proceedings of the International Conference on Solid State\
    \ Sensors and Actuators and Microsystems, Seoul, Re‑ public of Korea, 5–9 June\
    \ 2005; Digest of Technical Papers, TRANSDUCERS '05. IEEE: Piscataway, NJ, USA,\
    \ 2005; Volume 1, pp. 920–923. [\\[CrossRef\\]](https://doi.org/10.1109/SENSOR.2005.1496568)\n\
    - 47. Ding, C.; Soni, G.; Bozorgi, P.; Piorek, B.D.; Meinhart, C.D.; MacDonald,\
    \ N.C. A flat heat pipe architecture based on nanostruc‑ tured titania. *J. Microelectromech.\
    \ Syst.* **2010**, *19*, 878–884. [\\[CrossRef\\]](https://doi.org/10.1109/JMEMS.2010.2051019)\n\
    - <span id=\"page-18-19\"></span>48. Dandapat, N.; Ghosh, S. Interfacial and Cross‑sectional\
    \ Studies of Thermally Cycled Alumina‑Monel Brazed Joint. *Trans. Indian Ceram.\
    \ Soc.* **2020**, *79*, 152–157. [\\[CrossRef](https://doi.org/10.1080/0371750X.2020.1787865)]\n\
    - <span id=\"page-18-20\"></span>49. Rahman, M.T.; Asadizanjani, N. Failure Analysis\
    \ for Hardware Assurance and Security. *Electron. Device Fail. Anal.* **2019**,\
    \ *21*, 16–24. [\\[CrossRef](https://doi.org/10.31399/ASM.EDFA.2019-3.P016)]\n\
    - 50. Vashistha, N.; Lu, H.; Shi, Q.; Rahman, M.T.; Shen, H.; Woodard, D.L.; Asadizanjani,\
    \ N.; Tehranipoor, M. Trojan Scanner: Detecting Hardware Trojans with Rapid SEM\
    \ Imaging combined with Image Processing and Machine Learning. In *ISTFA 2018:\
    \ Proceedings from the 44th International Symposium for Testing and Failure Analysis,\
    \ Phoenix, AZ, USA, 28 October–1 November 2018*; ASM International. Available\
    \ online: [https://books.google.com/books?hl=en&lr=&id=Mx59DwAAQBAJ&oi=fnd&pg=PA256](https://books.google.com/books?hl=en&lr=&id=Mx59DwAAQBAJ&oi=fnd&pg=PA256&dq=SEM+hardware+security&ots=-ibwWTUyG4&sig=l7llYBLLFmyYdJ6SbK-socj3Tx0#v=onepage&q=SEM%20hardware%20security&f=false)\
    \ [&dq=SEM+hardware+security&ots=‑ibwWTUyG4&sig=l7llYBLLFmyYdJ6SbK‑socj3Tx0#v=onepage&q=SEM%20hardware%20](https://books.google.com/books?hl=en&lr=&id=Mx59DwAAQBAJ&oi=fnd&pg=PA256&dq=SEM+hardware+security&ots=-ibwWTUyG4&sig=l7llYBLLFmyYdJ6SbK-socj3Tx0#v=onepage&q=SEM%20hardware%20security&f=false)\
    \ [security&f=false](https://books.google.com/books?hl=en&lr=&id=Mx59DwAAQBAJ&oi=fnd&pg=PA256&dq=SEM+hardware+security&ots=-ibwWTUyG4&sig=l7llYBLLFmyYdJ6SbK-socj3Tx0#v=onepage&q=SEM%20hardware%20security&f=false)\
    \ (accessed on 27 October 2023).\n- 51. Courbon, F.; Loubet‑Moundi, P.; Fournier,\
    \ J.J.A.; Tria, A. A high efficiency Hardware Trojan detection technique based\
    \ on fast SEM imaging. In Proceedings of the 2015 Design, Automation and Test\
    \ in Europe Conference & Exhibition (DATE), Grenoble, France, 9–13 March 2015;\
    \ pp. 788–793. [\\[CrossRef](https://doi.org/10.7873/DATE.2015.1104)]\n- <span\
    \ id=\"page-19-0\"></span>52. Rahman, M.T.; Shi, Q.; Tajik, S.; Shen, H.; Woodard,\
    \ D.L.; Tehranipoor, M.; Asadizanjani, N. Physical inspection attacks: New frontier\
    \ in hardware security. In Proceedings of the 2018 IEEE 3rd International Verification\
    \ and Security Workshop, IVSW, Costa Brava, Spain, 2–4 July 2018; pp. 93–102.[[CrossRef](https://doi.org/10.1109/IVSW.2018.8494856)]\n\
    - <span id=\"page-19-1\"></span>53. Thomas‑Brans, F.; Heckmann, T.; Markantonakis,\
    \ K.; Sauveron, D. New Diagnostic Forensic Protocol for Damaged Secure Digital\
    \ Memory Cards. *IEEE Access* **2022**, *10*, 33742–33757. [\\[CrossRef\\]](https://doi.org/10.1109/ACCESS.2022.3158958)\n\
    - 54. Xi, C.; Khan, A.A.; Jessurun, N.; Vashisthan, N.; Tehranipoor, M.M.; Asadizanjani,\
    \ N. Physical Assurance for Heterogeneous Integration: Challenges and Opportunities.\
    \ In Proceedings of the International Symposium on the Physical and Failure Analysis\
    \ of Integrated Circuits, IPFA, Singapore, 18–20 July 2022. [\\[CrossRef](https://doi.org/10.1109/IPFA55383.2022.9915749)]\n\
    - <span id=\"page-19-2\"></span>55. Klima, S.J.; Baaklini, G.Y.; Abel, P.B. *Nondestructive\
    \ Evaluation of Structural Ceramics*; NASA: Washington, DC, USA, 1987.\n- <span\
    \ id=\"page-19-3\"></span>56. Asadizanjani, N.; Rahman, M.T.; Tehranipoor, M.\
    \ Optical Inspection and Attacks. In *Physical Assurance*; Springer: Cham, Switzer‑\
    \ land, 2021; pp. 133–153.[[CrossRef](https://doi.org/10.1007/978-3-030-62609-9_6)]\n\
    - 57. Kulkarni, A.; Xu, C. A Deep Learning Approach in Optical Inspection to Detect\
    \ Hidden Hardware Trojans and Secure Cyberse‑ curity in Electronics Manufacturing\
    \ Supply Chains. *Front. Mech. Eng.* **2021**, *7*, 709924.[[CrossRef](https://doi.org/10.3389/fmech.2021.709924)]\n\
    - <span id=\"page-19-4\"></span>58. Vashistha, N.; Rahman, M.T.; Shen, H.; Woodard,\
    \ D.L.; Asadizanjani, N.; Tehranipoor, M. Detecting Hardware Trojans Inserted\
    \ by Untrusted Foundry Using Physical Inspection and Advanced Image Processing.\
    \ *J. Hardw. Syst. Secur.* **2018**, *2*, 333–344. [\\[CrossRef\\]](https://doi.org/10.1007/s41635-018-0055-0)\n\
    - <span id=\"page-19-5\"></span>59. van Gils, M.A.; van der Sluis, O.; Zhang,\
    \ G.Q.; Janssen, J.H.; Voncken, R.M. Analysis of Cu/low‑k bond pad delamination\
    \ by using a novel failure index. In Proceedings of the 6th International Conference\
    \ on Thermal, Mechanical and Multi‑Physics Sim‑ ulation and Experiments in Micro‑Electronics\
    \ and Micro‑Systems, EuroSimE, Berlin, Germany, 18–20 April 2005; pp. 190–196.\
    \ [\\[CrossRef\\]](https://doi.org/10.1109/ESIME.2005.1502798)\n- 60. Viswanath,\
    \ A.G.; Fang, W.; Zhang, X.; Ganesh, V.P.; Lim, L.A. Numerical analysis by 3D\
    \ finite element wire bond simulation on Cu/low‑K structures. In Proceedings of\
    \ the 7th Electronics Packaging Technology Conference, EPTC, Singapore, 7–9 December\
    \ 2005; Volume 1, pp. 215–220.[[CrossRef\\]](https://doi.org/10.1109/EPTC.2005.1614396)\n\
    - <span id=\"page-19-6\"></span>61. Wang, C.; Sun, R. The Quality Test of Wire\
    \ Bonding. *Mod. Appl. Sci.* **2009**, *3*, 50–56. [\\[CrossRef\\]](https://doi.org/10.5539/mas.v3n12p50)\n\
    - <span id=\"page-19-7\"></span>62. Zamalloa Jara, M.A.; Luízar Obregón, C.; Araujo\
    \ Del Castillo, C. Exploratory analysis for the identification of false banknotes\
    \ using portable X‑ray Fluorescence spectrometer. *Appl. Radiat. Isot.* **2018**,\
    \ *135*, 212–218.[[CrossRef](https://doi.org/10.1016/j.apradiso.2018.01.043)]\
    \ [\\[PubMed](https://www.ncbi.nlm.nih.gov/pubmed/29427957)]\n- 63. Camp, D.C.\
    \ K‑Edge X‑ray Fluorescence Analysis for Actinide and Heavy Elements Solution\
    \ Concentration Measurements. *Adv. X‑ray Anal.* **1984**, *28*, 91–98. [\\[CrossRef\\\
    ]](https://doi.org/10.1154/S0376030800013823)\n- <span id=\"page-19-8\"></span>64.\
    \ Anceau, S.; Bleuet, P.; Clédière, J.; Maingault, L.; Rainard, J.L.; Tucoulou,\
    \ R. Nanofocused X‑ray beam to reprogram secure cir‑ cuits. In Proceedings of\
    \ the Cryptographic Hardware and Embedded Systems–CHES 2017: 19th International\
    \ Conference, Taipei, Taiwan, 25–28 September 2017; Lecture Notes in Computer\
    \ Science (including subseries Lecture Notes in Artificial Intelligence and Lecture\
    \ Notes in Bioinformatics) 10529 LNCS. pp. 175–188. [\\[CrossRef](https://doi.org/10.1007/978-3-319-66787-4_9)]\n\
    - <span id=\"page-19-9\"></span>65. Chan, K.L.A.; Kazarian, S.G. Detection of\
    \ trace materials with Fourier transform infrared spectroscopy using a multi‑channel\
    \ detector. *Analyst* **2006**, *131*, 126–131.[[CrossRef](https://doi.org/10.1039/B511243E)][[PubMed\\\
    ]](https://www.ncbi.nlm.nih.gov/pubmed/16365673)\n- 66. Chen, H.; Ferrari, C.;\
    \ Angiuli, M.; Yao, J.; Raspi, C.; Bramanti, E. Qualitative and quantitative analysis\
    \ of wood samples by Fourier transform infrared spectroscopy and multivariate\
    \ analysis. *Carbohydr. Polym.* **2010**, *82*, 772–778. [\\[CrossRef\\]](https://doi.org/10.1016/j.carbpol.2010.05.052)\n\
    - <span id=\"page-19-10\"></span>67. Lu, H.; Capecci, D.E.; Ghosh, P.; Forte,\
    \ D.; Woodard, D.L. Computer vision for hardware security. In *Emerging Topics\
    \ in Hardware Security*; Tehranipoor, M., Ed.; Springer International Publishing:\
    \ Cham, Switzerland, 2021; pp. 493–525.[[CrossRef\\]](https://doi.org/10.1007/978-3-030-64448-2_18)\n\
    - <span id=\"page-19-11\"></span>68. Huynh, N.; Cherian, H.; Ahn, E.C. Hardware\
    \ security of emerging non‑volatile memory devices under imaging attacks. In Proceedings\
    \ of the International Conference on Applied Electronics, Pilsen, Czech Republic,\
    \ 7–8 September 2021. [\\[CrossRef\\]](https://doi.org/10.23919/AE51540.2021.9542884)\n\
    - <span id=\"page-19-12\"></span>69. Hadjikhani, A.; Rodzinski, A.; Wang, P.;\
    \ Nagesetti, A.; Guduru, R.; Liang, P.; Runowicz, C.; Shahbazmohamadi, S.; Khizroev,\
    \ S. Biodistribution and clearance of magnetoelectric nanoparticles for nanomedical\
    \ applications using energy dispersive spec‑ troscopy. *Nanomedicine* **2017**,\
    \ *12*, 1801–1822.[[CrossRef](https://doi.org/10.2217/nnm-2017-0080)]\n- <span\
    \ id=\"page-19-13\"></span>70. Akter, N.; Karabiyik, M.; Shur, M.; Suarez, J.;\
    \ Pala, N. AI Powered THz VLSI Testing Technology. In Proceedings of the 29th\
    \ North Atlantic Test Workshop, NATW 2020, Albany, NY, USA, 17–24 June 2020. [\\\
    [CrossRef\\]](https://doi.org/10.1109/NATW49237.2020.9153077)\n- <span id=\"page-19-14\"\
    ></span>71. Ishibuchi, H.; Kwoh, C.K.; Tan, A.H.; Srinivasan, D.; Miao, C.; Trivedi,\
    \ A.; Crockett, K.; Institute of Electrical and Electron‑ ics Engineers. In Proceedings\
    \ of the 2022 IEEE Symposium Series on Computational Intelligence (SSCI 2022),\
    \ Singapore, 4–7 December 2022.\n- <span id=\"page-19-15\"></span>72. Xu, Z.;\
    \ Cui, A.; Qu, G. A New Aging Sensor for the Detection of Recycled ICs. In Proceedings\
    \ of the 2020 on Great Lakes Symposium on VLSI, Beijing, China, 8–11 September\
    \ 2020; pp. 223–228.\n- <span id=\"page-19-16\"></span>73. Guin, U.; DiMase, D.;\
    \ Tehranipoor, M. Counterfeit Integrated Circuits: Detection, Avoidance, and the\
    \ Challenges Ahead. *J. Electron. Test.* **2014**, *30*, 9–23.[[CrossRef](https://doi.org/10.1007/s10836-013-5430-8)]\n\
    - <span id=\"page-19-17\"></span>74. Doyle, E.J. *Morris Bill Failure Analysis\
    \ Techniques*; Rome Air Development Center: Oneida County, NY, USA, 1981.\n- 75.\
    \ Kim, B.; Park, W.‑T. MEMS Packaging. In *Encyclopedia of Nanotechnology*; Bhushan,\
    \ B., Ed.; Springer: Dordrecht, The Netherlands, 2012; pp. 1351–1359.\n- <span\
    \ id=\"page-19-18\"></span>76. Davy, J. Calculations for Leak Rates of Hermetic\
    \ Packages. *IEEE Trans. Parts Hybrids Packag.* **1975**, *11*, 177–189. [\\[CrossRef](https://doi.org/10.1109/TPHP.1975.1135069)]\n\
    - <span id=\"page-20-0\"></span>77. Tu, K.N. Reliability challenges in 3D IC packaging\
    \ technology. *Microelectron. Reliab.* **2011**, *51*, 517–523. [\\[CrossRef](https://doi.org/10.1016/j.microrel.2010.09.031)]\n\
    - <span id=\"page-20-1\"></span>78. Xi, C.; Jessurun, N.; Asadizanjani, N. A Framework\
    \ to Assess the Security of Advanced Integrated Circuit (IC) Packaging. In Pro‑\
    \ ceedings of the 2020 IEEE 8th Electronics System‑Integration Technology Conference\
    \ (ESTC), Tonsberg, Norway, 15–18 Septem‑ ber 2020; pp. 1–7.\n- <span id=\"page-20-2\"\
    ></span>79. Fang, K. 3—Encapsulation Process Technology. In *Encapsulation Technologies\
    \ for Electronic Applications*, 2nd ed.; Ardebili, H., Zhang, J., Pecht, M.G.,\
    \ Eds.; William Andrew Publishing: Norwich, NY, USA, 2019; pp. 123–181.\n- <span\
    \ id=\"page-20-3\"></span>80. Zumbusch, A.; Holtom, G.R.; Xie, X.S. Three‑Dimensional\
    \ Vibrational Imaging by Coherent Anti‑Stokes Raman Scattering. *Phys. Rev. Lett.*\
    \ **1999**, *82*, 4142–4145.[[CrossRef](https://doi.org/10.1103/PhysRevLett.82.4142)]\n\
    - <span id=\"page-20-4\"></span>81. Sánchez‑Purrà, M.; Roig‑Solvas, B.; Rodriguez‑Quijada,\
    \ C.; Leonardo, B.M.; Hamad‑Schifferli, K. Reporter Selection for Nano‑ tags in\
    \ Multiplexed Surface Enhanced Raman Spectroscopy Assays. *ACS Omega* **2018**,\
    \ *3*, 10733–10742. [\\[CrossRef\\]](https://doi.org/10.1021/acsomega.8b01499)\n\
    - <span id=\"page-20-5\"></span>82. Vaskova, H.; Neumann, P.; Kozubik, M.; Jelinek,\
    \ K. Raman Spectroscopic Study of Counterfeit Electronic Components. *WSEAS Trans.\
    \ Syst. Control* **2018**, *13*, 453–459.\n- <span id=\"page-20-6\"></span>83.\
    \ Sinanoglu, O.; Karimi, N.; Rajendran, J.; Karri, R.; Jin, Y.; Huang, K.; Makris,\
    \ Y. Reconciling the IC test and security dichotomy. In Proceedings of the 2013\
    \ 18th IEEE European Test Symposium (ETS), Avignon, France, 27–30 May 2013; pp.\
    \ 1–6.\n- <span id=\"page-20-7\"></span>84. Advances in Kernel Methods—Support\
    \ Vector Learning. Available online: [https://www.researchgate.net/publication/2346087\\\
    \\_](https://www.researchgate.net/publication/2346087_Advances_in_Kernel_Methods_-_Support_Vector_Learning)\
    \ [Advances\\\\_in\\\\_Kernel\\\\_Methods\\\\_‑\\\\_Support\\\\_Vector\\\\_Learning](https://www.researchgate.net/publication/2346087_Advances_in_Kernel_Methods_-_Support_Vector_Learning)\
    \ (accessed on 28 October 2023).\n- <span id=\"page-20-8\"></span>85. Müller,\
    \ K.R.; Mika, S.; Tsuda, K.; Schölkopf, K. An introduction to kernel‑based learning\
    \ algorithms. *IEEE Trans. Neural Netw.* **2001**, *12*, 181–201.[[CrossRef](https://doi.org/10.1109/72.914517)]\
    \ [\\[PubMed](https://www.ncbi.nlm.nih.gov/pubmed/18244377)]\n- <span id=\"page-20-9\"\
    ></span>86. Huang, K.; Carulli, J.M.; Makris, Y. Parametric counterfeit IC detection\
    \ via Support Vector Machines. In Proceedings of the 2012 IEEE International Symposium\
    \ on Defect and Fault Tolerance in VLSI and Nanotechnology Systems (DFT), Austin,\
    \ TX, USA, 3–5 October 2012; pp. 7–12.\n- <span id=\"page-20-10\"></span>87. Kent,\
    \ M.; Huynh, N.K.; Schiavon, S.; Selkowitz, S. Using support vector machine to\
    \ detect desk illuminance sensor blockage for closed‑loop daylight harvesting.\
    \ *Energy Build.* **2022**, *274*, 112443. [\\[CrossRef\\]](https://doi.org/10.1016/j.enbuild.2022.112443)\n\
    - <span id=\"page-20-11\"></span>88. Alam, M.A.; Mahapatra, S. A comprehensive\
    \ model of PMOS NBTI degradation. *Microelectron. Reliab.* **2005**, *45*, 71–81.\
    \ [\\[Cross‑](https://doi.org/10.1016/j.microrel.2004.03.019) [Ref\\]](https://doi.org/10.1016/j.microrel.2004.03.019)\n\
    - 89. Bhardwaj, S.; Wang, W.; Vattikonda, R.; Cao, Y.; Vrudhula, S. Predictive\
    \ modeling of the NBTI effect for reliable design. In Proceedings of the Custom\
    \ Integrated Circuits Conference, San Jose, CA, USA, 10–13 September 2006; pp.\
    \ 189–192. [\\[CrossRef\\]](https://doi.org/10.1109/CICC.2006.320885)\n- 90. Kumar,\
    \ S.V.; Kim, C.H.; Sapatnekar, S.S. An analytical model for negative bias temperature\
    \ instability. In Proceedings of the IEEE/ACM International Conference on Computer‑Aided\
    \ Design, Digest of Technical Papers, ICCAD, San Jose, CA, USA, 5–8 November 2006;\
    \ pp. 493–496.[[CrossRef](https://doi.org/10.1109/ICCAD.2006.320163)]\n- <span\
    \ id=\"page-20-12\"></span>91. Vattikonda, R.; Wang, W.; Cao, Y. Modeling and\
    \ minimization of PMOS NBTI effect for robust nanometer design. *Proc. Des. Autom.\
    \ Conf.* **2006**, 1047–1052.[[CrossRef](https://doi.org/10.1145/1146909.1147172)]\n\
    - <span id=\"page-20-13\"></span>92. Wang, W.; Wei, Z.; Yang, S.; Cao, Y. An efficient\
    \ method to identify critical gates under circuit aging. In Proceedings of the\
    \ IEEE/ACM International Conference on Computer‑Aided Design, Digest of Technical\
    \ Papers, ICCAD, San Jose, CA, USA, 4–8 November 2007; pp. 735–740.[[CrossRef](https://doi.org/10.1109/ICCAD.2007.4397353)]\n\
    - <span id=\"page-20-14\"></span>93. Rührmair, U.; Devadas, S.; Koushanfar, F.\
    \ Security Based on Physical Unclonability and Disorder. In *Introduction to Hardware\
    \ Security and Trust*; Springer: New York, NY, USA, 2012; pp. 65–102.\n- 94. Alkabani,\
    \ Y.; Koushanfar, F.; Kiyavash, N.; Potkonjak, M. Trusted Integrated Circuits:\
    \ A Nondestructive Hidden Characteristics Extraction Approach. In *Information\
    \ Hiding: 10th International Workshop, IH 2008, Santa Barbara, CA, USA, 19–21\
    \ May 2008*; Revised Selected Papers; Springer: Berlin/Heidelberg, Germany, 2008;\
    \ pp. 102–117.\n- <span id=\"page-20-15\"></span>95. Gassend, B.; Lim, D.; Clarke,\
    \ D.; Van Dijk, M.; Marten; Devadas, S. Identification and authentication of integrated\
    \ circuits. *Concurr. Comput.* **2004**, *16*, 1077–1098.[[CrossRef](https://doi.org/10.1002/cpe.805)]\n\
    - <span id=\"page-20-16\"></span>96. Zhang, X.; Xiao, K.; Tehranipoor, M. Path‑delay\
    \ fingerprinting for identification of recovered ICs. In Proceedings of the 2012\
    \ IEEE International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology\
    \ Systems (DFT), Austin, TX, USA, 3–5 October 2012.\n- <span id=\"page-20-17\"\
    ></span>97. Arjona, R.; Prada‑Delgado, M.A.; Arcenegui, J.; Baturone, I. A PUF‑\
    \ and Biometric‑Based Lightweight Hardware Solution to Increase Security at Sensor\
    \ Nodes. *Sensors* **2018**, *18*, 2429. [\\[CrossRef](https://doi.org/10.3390/s18082429)]\n\
    - <span id=\"page-20-18\"></span>98. Chakraborty, R.S.; Narasimhan, S.; Bhunia,\
    \ S. Hardware Trojan: Threats and emerging solutions. In Proceedings of the 2009\
    \ IEEE International High Level Design Validation and Test Workshop, San Francisco,\
    \ CA, USA, 4–6 November 2009; pp. 166–171.\n- <span id=\"page-20-19\"></span>99.\
    \ Khalafalla, M.; Gebotys, C. PUFs Deep Attacks: Enhanced modeling attacks using\
    \ deep learning techniques to break the security of double arbiter PUFs. In Proceedings\
    \ of the 2019 Design, Automation & Test in Europe Conference & Exhibition (DATE),\
    \ Florence, Italy, 25–29 March 2019; pp. 204–209.\n- <span id=\"page-20-20\"></span>100.\
    \ Taneja, S.; Rajanna, V.K.; Alioto, M. In‑Memory Unified TRNG and Multi‑Bit PUF\
    \ for Ubiquitous Hardware Security. *IEEE J. Solid‑State Circuits* **2022**, *57*,\
    \ 153–166. [\\[CrossRef\\]](https://doi.org/10.1109/JSSC.2021.3125255)\n- <span\
    \ id=\"page-20-21\"></span>101. Servadei, L.; Zennaro, E.; Devarajegowda, K.;\
    \ Manzinger, M.; Ecker, W.; Wille, R. Accurate Cost Estimation of Memory Systems\
    \ Inspired by Machine Learning for Computer Vision. In Proceedings of the 2019\
    \ Design, Automation & Test in Europe Conference & Exhibition (DATE), Florence,\
    \ Italy, 25–29 March 2019; pp. 1277–1280.\n- <span id=\"page-21-0\"></span>102.\
    \ Neto, W.L.; Austin, M.; Temple, S.; Amaru, L.; Tang, X.; Gaillardon, P.E. LSOracle:\
    \ A Logic Synthesis Framework Driven by Ar‑ tificial Intelligence: Invited Paper.\
    \ In Proceedings of the 2019 IEEE/ACM International Conference on Computer‑Aided\
    \ Design (ICCAD), Westminster, CO, USA, 4–7 November 2019; pp. 1–6.\n- <span id=\"\
    page-21-1\"></span>103. Xie, Z.; Huang, Y.H.; Fang, G.Q.; Ren, H.; Fang, S.Y.;\
    \ Chen, Y.; Hu, J. RouteNet: Routability prediction for Mixed‑Size Designs Using\
    \ Convolutional Neural Network. In Proceedings of the 2018 IEEE/ACM International\
    \ Conference on Computer‑Aided Design (ICCAD), San Diego, CA, USA, 5–8 November\
    \ 2018; pp. 1–8.\n- <span id=\"page-21-2\"></span>104. Ma, Y.; Ren, H.; Khailany,\
    \ B.; Sikka, H.; Luo, L.; Natarajan, K.; Yu, B. High Performance Graph Convolutional\
    \ Networks with Applications in Testability Analysis. In Proceedings of the 56th\
    \ Annual Design Automation Conference 2019, Las Vegas, NV, USA, 2–6 June 2019.\n\
    - <span id=\"page-21-3\"></span>105. Regazzoni, F.; Bhasin, S.; Pour, A.A.; Alshaer,\
    \ I.; Aydin, F.; Aysu, A.; Beroulle, V.; Di Natale, G.; Franzon, P.; Hely, D.;\
    \ et al. Machine Learning and Hardware Security: Challenges and Opportunities.\
    \ In Proceedings of the 39th International Conference on Computer‑Aided Design,\
    \ San Diego, CA, USA, 2–5 November 2020.\n- <span id=\"page-21-4\"></span>106.\
    \ Yu, S.Y.; Yasaei, R.; Zhou, Q.; Nguyen, T.; Al Faruque, M.A. HW2VEC: A Graph\
    \ Learning Tool for Automating Hardware Security. In Proceedings of the 2021 IEEE\
    \ International Symposium on Hardware Oriented Security and Trust (HOST), San\
    \ Jose, CA, USA, 13–14 December 2021; pp. 13–23.\n- <span id=\"page-21-5\"></span>107.\
    \ Koushanfar, F. Provably Secure Active IC Metering Techniques for Piracy Avoidance\
    \ and Digital Rights Management. *IEEE Trans. Inf. Forensics Secur.* **2012**,\
    \ *7*, 51–63. [\\[CrossRef\\]](https://doi.org/10.1109/TIFS.2011.2163307)\n- <span\
    \ id=\"page-21-6\"></span>108. Wei, S.; Nahapetian, A.; Potkonjak, M. Robust passive\
    \ hardware metering. In Proceedings of the 2011 IEEE/ACM International Conference\
    \ on Computer‑Aided Design (ICCAD), San Jose, CA, USA, 7–10 November 2011; pp.\
    \ 802–809.\n- <span id=\"page-21-7\"></span>109. Cui, A.; Yang, Y.; Qu, G.; Li,\
    \ H. A Secure and Low‑overhead Active IC Metering Scheme. In Proceedings of the\
    \ 2019 IEEE 37th VLSI Test Symposium (VTS), Monterey, CA, USA, 23–25 April 2019;\
    \ pp. 1–6.\n- <span id=\"page-21-8\"></span>110. Contreras, G.K.; Rahman, M.T.;\
    \ Tehranipoor, M. Secure Split‑Test for preventing IC piracy by untrusted foundry\
    \ and assembly. In Proceedings of the IEEE International Symposium on Defect and\
    \ Fault Tolerance in VLSI Systems 2013, New York, NY, USA, 2–4 October 2013; pp.\
    \ 196–203.[[CrossRef](https://doi.org/10.1109/DFT.2013.6653606)]\n\n**Disclaimer/Publisher's\
    \ Note:** The statements, opinions and data contained in all publications are\
    \ solely those of the individual au‑ thor(s) and contributor(s) and not of MDPI\
    \ and/or the editor(s). MDPI and/or the editor(s) disclaim responsibility for\
    \ any injury to people or property resulting from any ideas, methods, instructions\
    \ or products referred to in the content."
  decisions:
    evaluation_prompt: 'Qualified. Reason: All relevant sections passed.'
    related_work_prompt: 'Qualified. Reason: All relevant sections passed.'
    novelty_prompt: 'Disqualified: Chunk 3: Disqualified: no novelty. Reason: The
      section primarily discusses existing methods and applications of Support Vector
      Machines (SVMs) for detecting counterfeit integrated circuits (ICs) and does
      not introduce any new methods, algorithms, applications, or insights. The described
      approaches and studies are based on previously established techniques without
      any clear claims of novel contributions or applications in a new context.'
    review_only_prompt: 'Qualified. Reason: All relevant sections passed.'
- title: A Survey of Aging Monitors and Reconfiguration Techniques
  abstract: CMOS technology scaling makes aging effects an important concern for the
    design and fabrication of integrated circuits. Aging deterioration reduces the
    useful life of a circuit, making it fail earlier. This deterioration can affect
    all portions of a circuit and impacts its performance and reliability. Contemporary
    literature shows solutions to monitor and mitigate aging using hardware and software
    monitoring mechanisms and reconfiguration techniques. The goal of this review
    of the state-of-the-art is to identify existing monitoring and reconfiguration
    solutions for aging. This survey evaluates the aging research, focusing the years
    from 2012 to 2019, and proposes a classification for monitors and reconfiguration
    techniques. Results show that the most common monitor type used for aging detection
    is to monitor timing errors, and the most common reconfiguration technique used
    to deal with aging is voltage scaling. Furthermore, most of the literature contributions
    are in the digital field, using hardware solutions for monitoring aging in circuits.
    There are few literature contributions in the analog area, being the scope of
    this survey in the digital domain. By scrutinizing these solutions, this survey
    points directions for further research and development of aging monitors and reconfiguration
    techniques.
  keywords: Aging monitors, reconfiguration techniques, survey.
  document: '#### I. INTRODUCTION


    With the scaling of CMOS technology circuit reliability issues become increasingly
    relevant for the design of integrated circuits. Among these issues, circuit aging
    is getting critical, as it inevitably affects all circuits. The literature shows
    an increase in the number of papers related to aging between 2000 to 2020 [\[1\]](#page-15-0),
    [\[2\]](#page-15-1), [\[3\]](#page-15-2). This trend is due to the development
    of ultra-deep submicron technologies, where reliability became crucial [\[4\]](#page-15-3).


    Aging is the deterioration of circuit performance over time [\[5\]](#page-15-4),
    which can reduce the useful life of a circuit. This deterioration can increase
    circuit delay and affect all portions of a System-on-Chip (SoC), analog circuit,
    digital logic, and memory. One important factor that accelerates aging is power.
    The increase of power in modern circuits increases the temperature and makes these
    circuits susceptible to effects like bias temperature instability (BTI) and hot
    carrier injection (HCI) [\[6\]](#page-15-5).


    One solution to deal with aging effects is to add design safety margins to the
    circuit, such as clock margins. These margins ensure correct operation even in
    the presence of aging effects once they are designed according to worst-case conditions.
    However, these margins decrease performance, as they increase the clock period.
    The literature presents other solutions to mitigate aging, allowing to extend
    the lifetime of chips. These solutions monitor parameters that indicate aging
    effects. The monitored parameters include temperature, frequency variation, delay
    variation, among others. Decision methods, as threshold voltage analysis, evaluate
    whether the monitored parameters have an appropriate range of values. Activation
    mechanisms, such as voltage and frequency adaptations, bring the circuit back
    to the safe parameters if these do not meet predefined constraints.


    The *goal* of this review is to study existing solutions for monitoring aging
    effects in circuits and dealing with them. This study seeks to answer two questions:
    *(i)* what solutions the literature presents for aging monitoring? and *(ii)*
    what solutions the literature presents for circuit reconfiguration? This work
    surveys the literature from 2012 to 2019, while works [\[7\]](#page-15-6), [\[8\]](#page-15-7),
    [\[9\]](#page-15-8) map aging monitors since 1998. Thus, this survey fills the
    gap related to aging surveys, covering the most recent works.


    The literature review considered three main search terms:


    • *Integrated Circuits*: this category limits the search to the area of integrated
    circuits. The search string presents the terms used to reference this area, like
    VLSI, system, and architectures;


    - *Monitoring and Self-reconfigurable Circuits*: this category includes the monitoring
    area and the problems induced by aging, as Negative-Bias Temperature Instability
    (NBTI);

    - *Aging*: this category limits the research by aging problems.


    The Scopus abstract and citation database [\(https://www.scopus.com\)](https://www.scopus.com)
    was the start point of the research. After that, the review researched in IEEE
    [\(https://ieeexplore.ieee.org\)](https://ieeexplore.ieee.org) and ACM [\(https://www.acm.org\)](https://www.acm.org)
    databases. Finally, the research focused on Google Scholar [\(https://scholar.google.com\)](https://scholar.google.com)
    database. The review considered journals and conference papers published since
    2014.


    This survey is organized as follows. Section [II](#page-1-0) presents basic definitions
    to the understating of this work. Section [III](#page-1-1) presents a review of
    other surveys available in the literature. Section [IV](#page-2-0) presents the
    proposed classification for the reviewed papers. Section [V](#page-4-0) discusses
    comparatively the reviewed works. Section [VI](#page-6-0) presents in detail the
    literature survey. Section [VII](#page-14-0) concludes this survey.


    #### II. BASIC DEFINITIONS


    <span id="page-1-0"></span>This section provides definitions required for the
    understanding of this survey.


    <span id="page-1-9"></span>Definition 1. *Critical path*: is the purely combinational
    path with the most significant delay between any two registers or primary I/O
    ports in a design.


    <span id="page-1-8"></span>Definition 2. *Soft-errors*: errors that can occur
    in a circuit when it is exposed to radiation, like cosmic rays and neutrons particles.
    Single-event upset (SEU) is an example of soft-error, when the exposition to radiation
    can generate a change in the memory elements values, generating erroneous outputs
    [\[10\]](#page-15-9).


    Important effects are considered in the aging research: NBTI (Definition [3\)](#page-1-2),
    PBTI (Definition [4\)](#page-1-3), HCI (Definition [5\)](#page-1-4).


    <span id="page-1-2"></span>Definition 3. *NBTI* – Negative Bias Temperature Instability:
    increase in the threshold voltage and consequently decrease drain current and
    transconductance of a transistor [\[11\]](#page-15-10). It occurs in PMOS transistors
    and is caused by circuit aging.


    <span id="page-1-3"></span>Definition 4. *PBTI* – Positive Bias Temperature Instability:
    similar to NBTI, but in NMOS transistors. Since the introduction of the high-K
    gate dielectrics and metal gates transistors, the effect of PBTI becomes comparable
    to the NBTI one.


    <span id="page-1-4"></span>Definition 5. *HCI* – Hot-Carrier Injection: consists
    of a voltage drop that produces a large electric field in the region near to the
    drain of a transistor in saturation mode. It can result in the change of transistor
    characteristics such as the threshold voltage [\[12\]](#page-15-11). According
    to Novak et al., from Intel, [\[13\]](#page-16-0), tri-gate technologies as 14nm
    can help to mitigate HCI effects toghter with body bias adjust techniques.


    Classic test approaches are adopted for aging monitoring and reconfiguration techniques:
    DfT (Definition [6\)](#page-1-5), BIST (Definition [7\)](#page-1-6), ATPG (Definition
    [8\)](#page-1-7).


    <span id="page-1-5"></span>Definition 6. *DfT* – Design for Testability: a set
    of techniques used to improve circuit testability by increasing controllability
    and observability in the design [\[14\]](#page-16-1).


    <span id="page-1-6"></span>Definition 7. *BIST* – Built-in Self-Test: a mechanism
    that tests the circuit itself, verifying all or a portion of the internal functionality
    of the design [\[14\]](#page-16-1). The hardware and/or the software is built
    into integrated circuits allowing them to test their operation. The main advantage
    of BIST is the ability to test internal circuits having no direct connections
    to external pins or external testers. In addition, BIST allows testing in the
    field.


    <span id="page-1-7"></span>Definition 8. *ATPG* –Automatic Test Pattern Generation:
    a method that finds an input sequence (called test vectors) that enables automatic
    test equipment (ATE) to distinguish between the correct circuit behavior and the
    faulty circuit behavior caused by defects.


    #### III. PREVIOUS AGING SURVEYS


    <span id="page-1-1"></span>Rahimipour et al. [\[7\]](#page-15-6) review on-chip
    monitors for temperature, soft-errors (Definition [2\)](#page-1-8), and critical
    paths (Definition [1\)](#page-1-9), covering the period 1998-2011 (21 works).
    Figure [1\(](#page-2-1)a) presents their classification divided in: monitors for
    high temperature induced problems; monitors for soft-errors; monitors for critical
    paths; and collaborative monitors, which combines the previously mentioned class
    of monitors. Soft-errors detects change caused in memory elements due radiation.
    Thermal monitors identify problems induced by high temperatures. Critical path
    delay monitors detect changes in the critical path, as delay increases. Collaborative
    monitors are a combination of more than one class of monitors. Figure [1\(](#page-2-1)b)
    summarizes the monitor types and also informs cause, effect, and control action
    for each effect. Juracy *et al.*: A Survey of Aging Monitors and Reconfiguration
    Techniques


    ![](_page_2_Figure_1.jpeg)


    | Magnitude     | Cause                                              | Adverse
    Effect                         | Control Action       |

    |---------------|----------------------------------------------------|----------------------------------------|----------------------|

    |               | Localized                                          | Performance
    /                          | DVFS /               |

    | Temperature   | power                                              | Reliability                            |
    Clock                |

    |               | consumption                                        | loss                                   |
    throttling           |

    | Critical Path | Timing<br>uncertainties                            | Speed loss                             |
    DVFS                 |

    | Soft Error    | ncreasing in<br>system<br>operating<br>frequencies | Reliability<br>loss                    |
    Backward<br>recovery |

    | Aging         | Prolonged<br>Usage                                 | Speed<br>reduction/<br>Malfunction     |
    DVFS                 |

    |               |                                                    | (b) Monitor
    types and control actions. |                      |


    (a) Typical examples of monitors.


    <span id="page-2-1"></span>**FIGURE 1.** Monitors types and control actions. Adapted
    from [4]. Fig. 1. Monitors types and control actions. Adapted from [\[7\]](#page-15-6).


    (controlled resource wearout), or availability of expendable resources (spatial
    redundancy). **AGING ADAPTATION AND MITIGATION TECHNIQUES WORST-CASE DESIGN DESIGN
    TIME AGING-AWARE BALANCING DYNAMIC ADAPTATION TECHNIQUES ADAPTIVE RESOURCE MANAGEMENT
    VOLTAGE MARGIN GATE SIZING FREQUENCY MARGIN GATES PATHS INSTRUCTION PIPELINE STAGES
    VOLTAGE AND FREQUENCY SCALE COMPUTATIONAL SPRITING CONTROLLED RESOURCE WEAROUT
    ITL SCHEME SPATIAL REDUNDANCY** system clock and the same path controlled by a
    delayed clock [11]; • *Clock frequency*: clock frequency monitors measure the
    frequency variation of a clock circuit under aging. This type of monitor uses
    a reference frequency to identify a change in the circuit operating frequency;
    • *Workload*: workload monitors measure the workload of a circuit to identify
    the stress level. Similar to the CPU load measure. Khoshavi et al. [\[8\]](#page-15-7)
    review the period 2004-2015 (30 works). Their work analyzes aging monitors and
    also aging models and techniques for aging mitigation. Aging models are used to
    predict the degradation of the circuit due to aging. Mitigation techniques are
    used to deal with aging effects and ensure correct behavior of the circuit under
    these effects. Besides, their work proposes a taxonomy to classify the aging mitigation
    techniques, shown in Figure [2.](#page-3-0) Worst-case design techniques add safety
    margins to the circuit characteristics, like frequency and supply voltage, at
    design-time. Design time aging-aware balancing focuses on balancing circuit delay
    to reduce aging effects. Dynamic adaptation techniques are online approaches to
    tune the design under aging during circuit operation. Adaptive resource management
    techniques mitigate the aging effects either through the management of idle time
    (Idle-Time Leveraging schemes, also called ITL schemes), power management and
    task scheduling (controlled resource wearout), or availability of expendable resources
    (spatial redundancy).


    **FIGURE 2.** Taxonomy of aging mitigation techniques. Adapted from [5]. Kochte
    et al. [6] review the period 2007-2017 (14 works). Their work analyses self-test,
    self-checking, and self-diagnosis online techniques for self-awareness. Online
    • *Circuit state*: circuit state monitors consider the state of the entire system.
    For example, some techniques use the BIST circuit output to evaluate aging effects;
    • *Voltage*: Voltage monitors analyze the threshold voltage of the circuit. Aging
    effects as NBTI can change the threshold voltage of transistors. Kochte et al.
    [\[9\]](#page-15-8) review the period 2007-2017 (14 works). Their work analyses
    self-test, self-checking, and selfdiagnosis online techniques for self-awareness.
    Online techniques include aging monitors. Figure [3](#page-3-1) shows the classification
    for self-test and self-checking, which contains non-concurrent and concurrent
    approaches. Non-concurrent approaches regard self-testing methods, including classic
    methods, as BIST, and techniques like suspending the circuit operation to execute
    the test. Concurrent approaches are self-checking methods executed during the
    circuit operation, which includes aging monitors.


    #### techniques include aging monitors. Figure 3 shows the classification for
    self-test and self-checking, which contains non-Table 1 presents the aging monitors
    addressed in this IV. PROPOSED CLASSIFICATION OF AGING MONITORS AND RECONFIGURATION
    TECHNIQUES


    <span id="page-2-0"></span>concurrent and concurrent approaches. Non-concurrent
    approaches regard self-testing methods, including classic methods, as BIST, and
    techniques like suspending the circuit survey and compares with those covered
    by previous works. Note that the Table does not include survey [5] because it
    does not consider aging monitors. Our work addresses eight Our proposed classification
    extends the taxonomy of previous work [\[7\]](#page-15-6), [\[8\]](#page-15-7),
    [\[9\]](#page-15-8), considering parameters included in the state-of-the-art and
    features of the circuits monitored by them. Thus, this work proposes the following
    set of parameters for aging monitors classification:


    > operation to execute the test. Concurrent approaches are self-checking methods
    executed during the circuit operation,


    > **IV. PROPOSED CLASSIFICATION OF AGING MONITORS**


    Our proposed classification extends the taxonomy of previous work [4]–[6], considering
    parameters included in the state-of-the-art and features of the circuits monitored
    by them. Thus, this work proposes the following set of parame-


    • *Temperature*: a temperature monitor detects aging effects by measuring the
    variation in the temperature of the circuit. Temperature variations cause aging
    effects


    • *Critical path*: critical path monitors can be used to identify timing errors
    due to wrong transitions, SEU,


    which includes aging monitors.


    **AND RECONFIGURATION TECHNIQUES**


    ters for aging monitors classification:


    as NBTI and PBTI;


    **NON-CONCURRENT**


    **POWER-ON ON-DEMAND PERIODICAL**


    **SELF TEST MEMORY BIST**


    **SELF-TEST USING STORED DETERMINISTIC PATTERNS**


    **BIST**


    **SOFTWARE-BASED**


    works.


    uration techniques:


    VOLUME 4, 2016 3


    **ONLINE**


    **SELF-TESTING SELF-CHECKING**


    **FIGURE 3.** Self-test and self-checking circuits classification. Adapted from
    [6].


    monitors types, including monitors not covered by previous


    **TABLE 1.** Comparison among the reviewed surveys related to aging monitor types,
    and this survey coverage. Legend: "A": addressed, "NA": not addressed.


    Critical Path: Timing Errors NA A A


    Temperature AA A


    Workload NA A A Circuit State NA NA A Voltage NA NA A


    Critical Path: SEU AA A Critical Path: Delay A NA A Clock Frequency NA NA A


    This work adopts the following classification of reconfig-


    • *Dynamic voltage scaling*: Dynamic Voltage Scaling


    [4] [6] This Survey


    or delay increase on circuit paths. These errors are detectable by comparing a
    circuit path controlled by the


    **SELF-TEST AND SELF-CHECK METHODS**


    **CONCURRENT**


    **WATCHDOG**


    **ALGORITHM-BASED FAULT TOLERANCE**


    **NON-FUNCTIONAL MONITORS**


    **CONCURRENT BIST SELF CHECKING DESIGN / CONCURRENT ERROR DETECTION LOCKSTEP EXECUTION
    SYNTHESIZED ASSERTIONS**


    ![](_page_3_Figure_0.jpeg)


    <span id="page-3-0"></span>Fig. 2. Taxonomy of aging mitigation techniques. Adapted
    from [\[8\]](#page-15-7).


    ![](_page_3_Figure_2.jpeg)


    #### **SELF-TEST AND SELF-CHECK METHODS**


    <span id="page-3-1"></span>Fig. 3. Self-test and self-checking circuits classification.
    Adapted from [\[9\]](#page-15-8).


    - *Temperature*: a temperature monitor detects aging effects by measuring the
    variation in the temperature of the circuit. Temperature variations cause aging
    effects as NBTI and PBTI;

    - *Critical path*: critical path monitors can be used to identify timing errors
    due to wrong transitions, SEU, or delay increase on circuit paths. These errors
    are detectable by comparing a circuit path controlled by the system clock and
    the same path controlled by a delayed clock [\[15\]](#page-16-2);

    - *Clock frequency*: clock frequency monitors measure the frequency variation
    of a clock circuit under aging. This type of monitor uses a reference frequency
    to identify a change in the circuit operating frequency;

    - *Workload*: workload monitors measure the workload of a circuit to identify
    the stress level. Similar to the CPU load measure.

    - *Circuit state*: circuit state monitors consider the state of the entire system.
    For example, some techniques use the BIST circuit output to evaluate aging effects;

    - *Voltage*: Voltage monitors analyze the threshold voltage of the circuit. Aging
    effects as NBTI can change the threshold voltage of transistors.


    Table [I](#page-4-1) presents the aging monitors addressed in this survey and
    compares with those covered by previous works. Note that the Table does not include
    survey [\[8\]](#page-15-7) because it does not consider aging monitors. Our work
    addresses eight monitors types, including monitors not covered by previous works.


    This work adopts the following classification of reconfiguration techniques:


    • *Dynamic voltage scaling*: Dynamic Voltage Scaling (DVS) is a power management
    technique where the voltage used in a component increases or decreases, according
    to some criteria [\[16\]](#page-16-3). An example of an approach to manage power
    dissipation is the adoption of a closed-loop control technique where the voltage
    is a knob to


    <span id="page-4-1"></span>TABLE I COMPARISON AMONG THE REVIEWED SURVEYS RELATED
    TO AGING MONITOR TYPES, AND THIS SURVEY COVERAGE. LEGEND: "A": ADDRESSED, "NA":
    NOT ADDRESSED.


    |                              | [7] | [9] | This Survey |

    |------------------------------|-----|-----|-------------|

    | Temperature                  | A   | A   | A           |

    | Critical Path: Timing Errors | NA  | A   | A           |

    | Critical Path: SEU           | A   | A   | A           |

    | Critical Path: Delay         | A   | NA  | A           |

    | Clock Frequency              | NA  | NA  | A           |

    | Workload                     | NA  | A   | A           |

    | Circuit State                | NA  | NA  | A           |

    | Voltage                      | NA  | NA  | A           |


    meet the power goal [\[17\]](#page-16-4).


    - *Dynamic frequency scaling*: Dynamic frequency scaling (DFS) is a technique
    similar to DVS, but applied to the circuit frequency. Similarly, if the circuit
    needs a boost in performance, the frequency is increased. If the circuit or application
    can tolerate lower performance, the frequency may be decreased to allow power
    savings;

    - *Aging compensation*: Aging compensation is a technique that enables the circuit
    to alleviate aging effects. For example, some circuits activate extra devices,
    in parallel to the main circuit, to increase the driving strength of an output
    driver, compensating the degradation due to HCI and BTI effects [\[18\]](#page-16-5);

    - *Body-bias adaptive*: Body-bias adaptive (BBA) is a technique that allows tuning
    the transistor threshold voltage [\[19\]](#page-16-6). This technique helps to
    mitigate and compensate for the NBTI impact in the circuit;

    - *Workload reduction*: Workload reduction is a series of software approaches
    to reduce the workload system by introducing, for instance, no operation (NOP)
    instructions during the system operation.


    Table [II](#page-4-2) compares reconfiguration approaches covered by the previous
    works, and the ones addressed in this survey. The Table does not include survey
    [\[9\]](#page-15-8) because it does not address reconfiguration techniques. Also,
    note that this survey does not address three types of reconfiguration techniques
    (clock throttling, backward recovering and computational sprinting) that were
    covered in the previous surveys because these techniques were not adopted in the
    research papers from 2012 to 2019. Our work addresses five reconfiguration approaches,
    including two types not covered by previous works.


    <span id="page-4-2"></span>TABLE II COMPARISON AMONG THE REVIEWED SURVEYS RELATED
    TO RECONFIGURATION TECHNIQUES TYPES, AND THIS SURVEY COVERAGE. LEGEND: "A": ADDRESSED,
    "NA": NOT ADDRESSED.


    |                           | [7] | [8] | This Survey |

    |---------------------------|-----|-----|-------------|

    | Dynamic Voltage Scaling   | A   | A   | A           |

    | Dynamic Frequency Scaling | A   | A   | A           |

    | Aging Compensation        | NA  | A   | A           |

    | Body Bias Adaptive        | NA  | NA  | A           |

    | Workload Reduction        | NA  | NA  | A           |

    | Clock Throttling          | A   | NA  | NA          |

    | Backward Recovering       | A   | NA  | NA          |

    | Computational Sprinting   | NA  | A   | NA          |


    ### V. DISCUSSION RELATED TO THE STATE-OF-THE-ART


    <span id="page-4-0"></span>This Section brings a summary of the presented techniques,
    remarks, and insights about how to deal with aging. Also, this Section answers
    the research questions presented in the Introduction Section. The classified state-of-the-art
    works are described in Section [VI.](#page-6-0)


    About industry, most applications rely on sensors built in SoCs that allow measuring
    variations in such parameters as the circuit ages. These sensors are commonly
    distributed across the die and accessible through DfT infrastructure or as peripherals
    to CPUs. The most common sensor consists of a set of ring oscillators that control
    asynchronous counters. These counters provide an overview of how the overall speed
    of the circuit is being impacted by aging [\[20\]](#page-16-7).


    # *A. Summary and remarks of the literature review*


    Table [III](#page-6-1) summarizes the reviewed works. The "Overall Monitoring"
    column means monitoring the entire circuit, not just the critical paths using,
    for example, the voltage or the current. The "Monitor Insertion Strategy" column
    corresponds to approaches that use some strategy to insert the monitors, such
    as statistical methods, and not based only on critical paths. The "Structure Reuse"
    column shows designs that use structures available in the circuit for monitoring
    aging effects. In these cases, only DfT structures are reused. The "Metastability
    Concern" column contains works concerned with metastability issues.


    Circuits monitoring the overall system may present a low area overhead, once one
    mechanism can be applied for the entire design. This approach may be better in
    terms of area overhead when compared to solutions focusing on inserting monitors
    in all critical paths. However, designs that use methods to select paths to insert
    monitor are also promising in terms of area overhead reduction. The reuse of DfT
    structures is a promising strategy to choose paths, once test insertion overhead
    is already present in the circuit. This allows reducing the impact of aging monitors
    on area.


    A "*no*" in the first column (Overall Monitoring) means that only part of the
    system is monitored. This means that specialized mechanisms may be required for
    different parts of the system. Particularly, works with a "*no*" in the second
    and/or third columns in Table [III](#page-6-1) (Monitor Insertion Strategy and
    Structure Reuse) can present a significant overhead in the system. Nevertheless,
    these solutions may be useful for detecting aging and could be combined with path
    selection strategies to reduce the system overhead, making their use feasible.


    Metastability is a concern present in only two works. It is an important issue,
    once its effects may propagate through designs, reducing circuit reliability,
    making them fail even in the absence of aging effects. Metastability can also
    be an issue to systems with more than one clock domain, due to the clock synchronization
    between domains. Thus, these two works have an advantage compared to other approaches
    since they use the same circuitry to deal with both aging and metastability effects.


    A feature that can be observed is that voltage and frequency scaling are reconfiguration
    techniques associated mostly with critical path monitors, once it is possible
    to control the circuit speed by these two parameters. Similarly, body bias adjustment
    is associated with voltage monitors, once this reconfiguration technique changes
    the threshold voltage for compensating aging effects.


    #### *B. Remarks about aging monitors*


    Figure [4](#page-7-0) and Table [IV](#page-7-1) present the answer to the first
    research question of this survey, "What solutions the literature presents for
    aging monitoring?". The Figure shows the monitor types covered by this survey.
    The most common monitor type used for aging detection are timing error monitors,
    which is present in 36.58% of the reviewed papers. The second most common monitor
    type used for aging detection is temperature monitor, which is present in 27%
    of the papers.


    # *C. Remarks about reconfiguration techniques*


    This Section answers the second research question of this survey: "What solutions
    the literature presents for circuit reconfiguration?". Figure [5](#page-7-2) and
    Table [V](#page-7-3) present the reconfiguration techniques covered in this survey.
    According to the Table, voltage scaling is the most adopted reconfiguration technique,
    present in 50% of the papers about reconfiguration techniques. The second most
    common reconfiguration technique used for aging detection is frequency scaling,
    which is present in 28.57% of the papers.


    <span id="page-6-1"></span>


    |            | Overall<br>Monitoring | Monitor Insertion<br>Strategy | Structure<br>Reuse
    | Metastability<br>Concern |

    |------------|-----------------------|-------------------------------|--------------------|--------------------------|

    | [21], 2015 | yes                   | no                            | no                 |
    no                       |

    | [22], 2017 | yes                   | no                            | no                 |
    no                       |

    | [23], 2017 | yes                   | no                            | no                 |
    no                       |

    | [24], 2017 | yes                   | no                            | no                 |
    no                       |

    | [25], 2015 | yes                   | no                            | no                 |
    no                       |

    | [26], 2016 | yes                   | no                            | no                 |
    no                       |

    | [18], 2014 | yes                   | no                            | no                 |
    no                       |

    | [27], 2016 | yes                   | no                            | no                 |
    no                       |

    | [28], 2019 | yes                   | no                            | no                 |
    no                       |

    | [29], 2015 | no                    | no                            | yes                |
    no                       |

    | [30], 2017 | no                    | no                            | no                 |
    no                       |

    | [31], 2018 | no                    | no                            | no                 |
    yes                      |

    | [32], 2016 | no                    | no                            | no                 |
    no                       |

    | [33], 2015 | yes                   | no                            | no                 |
    no                       |

    | [34], 2017 | no                    | no                            | no                 |
    no                       |

    | [35], 2014 | no                    | no                            | no                 |
    no                       |

    | [36], 2017 | no                    | no                            | no                 |
    no                       |

    | [37], 2014 | no                    | yes                           | no                 |
    no                       |

    | [38], 2014 | no                    | yes                           | no                 |
    no                       |

    | [39], 2018 | no                    | no                            | no                 |
    no                       |

    | [40], 2017 | no                    | yes                           | no                 |
    no                       |

    | [41], 2015 | no                    | yes                           | no                 |
    no                       |

    | [42], 2019 | yes                   | no                            | no                 |
    no                       |

    | [43], 2019 | yes                   | yes                           | no                 |
    no                       |

    | [44], 2018 | no                    | no                            | no                 |
    no                       |

    | [45], 2012 | no                    | yes                           | no                 |
    no                       |

    | [46], 2014 | no                    | yes                           | no                 |
    no                       |

    | [47], 2014 | no                    | yes                           | no                 |
    no                       |

    | [48], 2015 | yes                   | no                            | no                 |
    no                       |

    | [49], 2016 | yes                   | no                            | no                 |
    no                       |

    | [50], 2014 | no                    | no                            | no                 |
    no                       |

    | [51], 2014 | no                    | yes                           | no                 |
    no                       |

    | [52], 2015 | yes                   | no                            | no                 |
    yes                      |

    | [53], 2017 | yes                   | no                            | no                 |
    no                       |

    | [54], 2015 | yes                   | no                            | yes                |
    no                       |

    | [55], 2015 | yes                   | no                            | yes                |
    no                       |

    | [56], 2019 | yes                   | no                            | no                 |
    no                       |

    | [57], 2017 | yes                   | no                            | yes                |
    no                       |

    | [58], 2015 | yes                   | no                            | no                 |
    no                       |

    | [59], 2015 | yes                   | no                            | no                 |
    no                       |

    | [60], 2018 | yes                   | no                            | no                 |
    no                       |


    TABLE III SUMMARY OF THE LITERATURE REVIEW.


    ## VI. LITERATURE REVIEW


    <span id="page-6-0"></span>This Section describes the papers related to aging
    monitors and reconfiguration techniques covering the years from 2012 to 2019.
    The subsections are grouped by monitoring approaches, according to the classification
    proposed in Section [IV](#page-2-0) for aging monitors. When a paper also presents
    a reconfiguration technique, it is described together, in the same paragraph.


    ![](_page_7_Figure_0.jpeg)


    <span id="page-7-1"></span><span id="page-7-0"></span>Fig. 4. Monitor types covered
    by the survey.


    TABLE IV CLASSIFICATION OF THE MONITORS'' WORKS ACCORDING TO THE PROPOSED CLASSIFICATION.


    | Types                             | Works |      |      |      |      |      |

    |-----------------------------------|-------|------|------|------|------|------|

    | Temperature                       | [21]  | [22] | [23] | [24] | [25] | [26]
    |

    |                                   | [18]  | [27] | [28] | [46] | [47] |      |

    | Critical path: timing errors      | [29]  | [30] | [31] | [32] | [33] | [34]
    |

    |                                   | [35]  | [36] | [37] | [38] | [39] | [40]
    |

    |                                   | [41]  | [42] | [43] |      |      |      |

    | Critical path: single event upset | [44]  |      |      |      |      |      |

    | Critical path: delay              | [45]  | [48] | [49] | [50] | [51] |      |

    | Clock frequency                   | [52]  | [53] |      |      |      |      |

    | Circuit state                     | [54]  | [55] | [56] | [57] |      |      |

    | Workload                          | [58]  |      |      |      |      |      |

    | Voltage                           | [59]  | [60] |      |      |      |      |


    ![](_page_7_Figure_4.jpeg)


    <span id="page-7-3"></span><span id="page-7-2"></span>Fig. 5. Reconfiguration
    techniques covered by the survey.


    TABLE V WORKS CLASSIFICATION REGARDING RECONFIGURATION TECHNIQUES.


    | Techiniques                                                                                          |                                      |              |              |
    Works        |      |      |      |

    |------------------------------------------------------------------------------------------------------|--------------------------------------|--------------|--------------|--------------|------|------|------|

    | Voltage scaling<br>Frequency scaling<br>Aging compensation<br>Body bias adjust<br>Workload
    reduction | [21]<br>[21]<br>[18]<br>[59]<br>[40] | [32]<br>[45] | [39]<br>[52]
    | [45]<br>[56] | [48] | [50] | [56] |


    #### *A. Temperature Monitors*


    NBTI, PBTI, and HCI are aging effects accelerated by temperature increase in chips.
    System workload affects power dissipation, which has a direct impact on the temperature.
    Thus, monitoring temperature helps to deal with these effects. Some sensors use
    ring-oscillators to capture the aging effects caused by temperature increase.
    This kind of sensor provides an indirect measurement of temperature, and can be
    considered a temperature monitor.


    Igarashi et al. [\[21\]](#page-16-8) propose an aging monitor implemented with
    ring-oscillator (RO) to measures BTI and AC hot-carrier-injection (AC-HCI). The
    monitor consists of a symmetric RO (SRO) and an asymmetric RO (ASRO). ASRO is
    an RO composed of standard cells of different drives, while SRO is implemented
    only by standard cells with the same driving strength. With these two types of
    RO, it is possible to separate NBTI and PBTI effects for analyses by observing
    them under DC stress conditions. Also, the speed degradation caused by AC-HCI
    can be detected because unbalanced delay with a long/short transition in ASRO
    has high sensitivity against AC-HCI under AC stress. A dynamic voltage and frequency
    scaling (DVFS) technique controlled by software is used to change the supply voltage
    and clock activity dynamically and reconfigure the circuit. A test chip, including
    both SRO and ASRO using NAND2 standard cells, was implemented in a 16 nm Fin-FET
    bulk CMOS technology. Results show that Vth shift due to PBTI measured from frequency
    degradation is 2mV, which is still 1/10 of NBTI in Fin-FET technology, and that
    is possible to reduce the BTI guard bands in 45% at the nominal frequency operation.


    Majerus et al. [\[22\]](#page-16-9) use ROs to measure changes in transistor and
    resistor parameters as a function of the stress caused by aging. The result is
    a data-driven aging model that provides information that can be used to ensure
    system reliability.


    Sengupta and Sapatnekar [\[23\]](#page-16-10) present two methods that use sensors
    implemented with ROs to detect the delay shifts in circuits as a result of BTI
    and HCI effects. The first method uses a pre-silicon analysis of the circuit to
    compute calibration factors that can translate the delay shifts in the ROs with
    a delay estimate of 1% of the real values. The second method uses an analysis
    where sensor measurements are combined with infrequent online delay measurements
    to reduce the circuit guard bands and allows 8% lower delay guard banding overheads
    compared to the conventional methods.


    Kim et al. [\[24\]](#page-16-11) propose a new test structure of RO that helps
    to measure the stress duty cycle (SDC) of the HCI. SDC is the ratio between the
    stress caused by the aging effect and the circuit cycle time [\[61\]](#page-17-17).
    The structure is composed of a NAND gate that has the function of enabling the
    oscillator mode and inverters. VDD and GND bias of the HCI stress inverter are
    set up in a complementary way during the stress, making the device not suffering
    from BTI aging. Also, a buffer is designed as a compensator for the signal falling
    by as much as Vth. Results demonstrated that HCI SDC increases with frequency,
    but the maximum duty cycle was much less than 2%.


    Shakya et al. [\[25\]](#page-16-12) propose an NBTI sensor that uses two ROs,
    one without circuit influence used as a reference and other to evaluate the degradation
    circuit under stress, and compare the output of both. This approach gives the
    manufacturer the exact control over the yield and accuracy of the sensors, which
    not occurs with ad hoc approaches that determine parameters such as the decision
    threshold.


    Miyake et al. [\[26\]](#page-16-13) propose an aging-tolerant monitor that analyzes
    frequencies of more than one RO. Thus, it is possible to derive the values for
    temperature and voltage from the frequencies using multiple regression analysis.
    Besides, three techniques to select the RO types are proposed to improve the accuracy
    of the measurement. The method was validated with simulations in 180 nm, 90 nm,
    and 45 nm CMOS technologies. In the 180 nm technology, temperature accuracy is
    about 0.99◦C, and voltage accuracy is about 4.17 mV. Also, the authors fabricated
    test chips with 180 nm CMOS technology to confirm its feasibility.


    Kumar [\[18\]](#page-16-5) presents an aging compensation technique for a CMOS
    transistor output driver. It contains an aging compensation cell which monitors
    the degradation in the ON current (ION ) of output driver due to the HCI and BTI
    effect. Based on this degradation, the aging compensation cell generates compensation
    codes for PMOS and NMOS transistors drivers. These aging compensation codes turn
    on devices in parallel to the main driver, increasing the drive strength of output,
    which compensates the degradation in NMOS and PMOS driver due to HCI and BTI effects.
    The design was implemented in 40 nm CMOS process by using 1.8V thick-oxide devices.
    Results show that by using the proposed aging compensation technique, the impact
    of aging on output driver reduces by 70% after ten years of operation.


    Ali et al. [\[27\]](#page-16-14) use IJTAG to manage temperature health monitors
    on the chip. The temperature health monitors are based on a Wheatstone bridge,
    which is composed of four resistors, one operational amplifier, one filter, and
    one analog to digital converter. Results show that the proposed solution can be
    used to manage and control instruments to ensure the reliable operation of the
    chip over its lifetime. According to the authors, the proposed method can reduce
    the overall time spent on the test, once there is no off-chip interface, and the
    system clock can be used instead of the test clock.


    Rathore et al. [\[28\]](#page-16-15) propose to use temperature and NBTI sensors
    to implement a task mapping strategy to manycore systems, called LifeGuard. LifeGuard
    considers performance and aging as parameters to perform task mapping, and is
    based on reinforcement learning. At each tile of the network-on-chip (NoC), an
    NBTI and a thermal sensor are added and used to perform the task mapping. As a
    benefit, LifeGuard prevents the rapid aging of cores that map a more significant
    number of tasks. Also, it improves the aggregate safe operating frequency of the
    system. Experimental results using a 256-core system showed that LifeGuard improved
    the health of the cores for 57% when compared to the HiMap strategy [\[62\]](#page-17-18),
    and 74% when compared to the Hayat [\[63\]](#page-17-19). Also, LifeGuard shows
    a better system performance.


    #### *B. Critical Path Monitors*


    Contemporary literature presents monitors that capture timing errors on the critical
    paths of circuits (Definition [1\)](#page-1-9). This technique contains extra
    components that capture the memory register output of the critical paths and its
    processed data. A comparison between these data is executed to identify if a timing
    error occurred.


    Savanur et al. [\[29\]](#page-16-16) present a BIST (Definition [7\)](#page-1-6)
    approach to detect aging effects on the circuit during test mode. The BIST circuitry
    uses two identical buffer chains and a logic block to compare the output of these
    chains. If there is a difference between the outputs of the chains, an error caused
    by aging is detected. The approach needs extra components, which are a D flip-flop,
    a NAND gate, an AND gate, and two buffers. HSPICE simulations on 45 nm and 65
    nm were performed to extract results. This paper focuses only on the NBTI aging
    factor, and results show that the solution can detect minimal stress levels in
    the presence of process variations and that the aging detection depends on the
    time that a path of the circuit keeps at logic level zero.


    Sai et al. [\[30\]](#page-16-17) present a Parity Check Circuit (PPC) for monitoring
    delay-faults and compare it with the Canary flipflop approach [\[64\]](#page-17-20).
    Unlike the Canary flip-flop approach, PPC can monitor more than one logic path
    simultaneously, which allows reducing the number of sensors. PPC is implemented
    using a multiple-input XOR gate, a delay element (DE), a matched delay element
    (MD), a flip-flop, a shadow flip-flop, and a 2-input XOR gate. The multiple-input
    XOR gate is responsible for computing the data parity, and the MD is responsible
    for adding a delay to the clock signal to compensate delay produced by the multiple-input
    XOR gate. The PPC was validated in a 32 bit MIPS processor using a 65 nm technology.
    Results indicate that the use of the circuit reduces area overhead by 66% and
    power by 33% when compared to the Canary flip-flop approach.


    Sai et al. [\[31\]](#page-16-18) propose a metastability-free aging sensor called
    Differential Multiple Error Detection Sensor (DMEDS). The sensor monitors multiple
    paths concurrently. It is composed of a Multiple Detection Unit (MDU) and a stability
    checker, which allows monitoring two or more critical paths simultaneously. Any
    transition in the data active the MDU output signal that is captured by the stability
    checker, signaling a delay fault. The stability checker checks the stability of
    the delayed signal while the clock is high. DMEDS was designed at transistor level
    using a 32 nm technology and applied to a 32-bit MIPS processor to monitor ten
    paths concurrently. Results show that using DMEDS for monitoring ten paths can
    save 197.1% and 97.1% in area overhead when compared to Razor [\[15\]](#page-16-2)
    and Canary [\[64\]](#page-17-20), respectively.


    Copetti et al. [\[32\]](#page-16-19) propose a hardware-based technique able to
    increase ICs lifetime. The technique is based on a sensor able to monitor IC aging
    and to adjust its power supply voltage to minimize NBTI effects, increasing the
    circuit lifetime. The approach is composed of: (i) an aging sensor, which contains
    a delay element and the stability checker; (ii) an actuator, which contains a
    counter and a decoder block; and (iii) a flip-flop inserted at the critical path
    output. The flip-flop output of the critical path passes through the delay element
    and the stability checker while the clock signal is high, analyzing data transitions.
    If a transition while the clock is high occurs, it means that the delay of the
    circuit increased, changing the output of the stability checker and indicating
    a timing violation. Also, the actuator receives the signal from the stability
    checker and increases its counter, allowing the decoder to adjust the power supply.
    Experimental results obtained by simulations demonstrate that the technique increases
    the circuit lifetime by 150%.


    Sadeghi-Kohan et al. [\[33\]](#page-16-20) propose a self-adjusting age monitoring
    method to pipeline circuits, which allows detecting progressive changes in the
    timing of a circuit. The output of the critical paths are captured using an age
    monitoring clock (that occurs before the system clock), and this captured data
    is compared with the same output but captured at the rising edge of the system
    clock. The circuit used to adjust the age monitoring clock has an age indicator
    counter that counts RO pulses to adjust the clock phase and is initialized with
    the core process characteristic. As the core ages, the age indicator counter is
    incremented, causing a more extended clock phase shift, and shorter slack time.
    The monitors are designed targeting low hardware overhead and accuracy in reported
    timing changes.


    In another work, Sadeghi-Kohan et al. [\[34\]](#page-16-21) use a similar strategy
    to monitor paths of a circuit and to detect its continuous age growth. This approach
    can provide the aging rate and the aging state of the circuit. The proposed strategy
    uses a clock generator to feed the register responsible for capturing the data
    before the system clock. Results show an area overhead of 2.13%, a power overhead
    of 0.69%, and a low-performance overhead. Yi et al. [\[35\]](#page-16-22) present
    a scan-based on-line monitoring that monitors aging during system operation and
    gives an alarm if the system detects aging effects. This work inserts an extra
    scan chain that captures early the functional data (at the opposite edge of the
    system clock) within a given guard-band interval during system operation. After
    that, the extra scan chain output is compared to the original scan chain output,
    which allows detecting violations. The scan-chain scheme contains two scan-chains,
    one with conventional scan cells (SC scan-chain) and the other one with the early
    capture scan cells (ECSC scan-chain). The SC flip-flops capture the data at the
    clock rising edge, while the ECSC flip-flops capture the data at the clock falling
    edge. The modified scan chain uses an XOR gate to compare the captured data.


    Jung [\[36\]](#page-16-23) presents an aging level estimating flip-flop that exploits
    the frequency guard band of a device to estimate the aging level with a small
    power overhead, called performance estimation flip-flop (PEFF). The PEFF has five
    elements: i) a scan flip-flop; ii) a shadow latch; iii) a sampling time indicator;
    iv) a logic block to controls the input of the performance result cell (PERC);
    v) the PERC. The shadow-latch is used to sample the data earlier than the functional
    flip-flop. Results show a reduction in monitoring time, and the power consumption
    is reduced by 50% when compared to the Yi et al. [\[35\]](#page-16-22).


    Vazquez-Hernandez [\[37\]](#page-16-24) proposes a solution for error prediction
    using an aging sensor based on the Error-Detection Sequential (EDS) circuit [\[65\]](#page-17-21).
    The EDS has a decoder module to monitors the critical paths. When one of the paths
    is activated, the decoder active the EDS to allow detect errors. The methodology
    for path selection uses statistical static timing analysis. Results show that
    the EDS can reduce power overhead form 102% to 6% and area overhead from 69% to
    22% when compared to [\[5\]](#page-15-4) and [\[35\]](#page-16-22), considering
    the circuit characteristics as the number of gates and buffers.


    Chandra [\[38\]](#page-16-25) proposes the SlackProbe monitor. This approach inserts
    timing monitors at endpoints and intermediate nodes of the circuit paths. If a
    monitor is inserted at an intermediate node, an AND gate is used as delay matching,
    and a transition detector is connected to the intermediate node with a minimum
    size inverter. If a signal transition at the intermediate node occurs, it arrives
    at the transition detector through the delay chain, and the signal is compared
    with the incoming clock edge. If the transition is close to its required arrival
    time, a corresponding signal transition arrives at the transition detector input
    after the clock edge. This transition triggers the transition detector and flags
    a signal indicating a delay failure. The monitor inserted at the intermediate
    node is capable of monitoring the delay of all critical paths passing through
    it, and its output can be used for mitigating failures due to aging (based on
    hardware or software). The results show that SlackProbe can achieve up to 16x
    reduction in the total number of monitors.


    Masuda and Hashimoto [\[39\]](#page-16-26) propose an error prediction adaptive
    voltage scaling (EP-AVS) and a mean time to failure aware (MTTF-aware) design
    methodology for EP-AVS circuits. The EP-AVS has a main circuit plus a timing error
    predictive flip-flop (TEP-FF) and a voltage control unit. The TEP-FF has a flip-flop,
    delay buffers, and a comparator implemented with an XOR gate. Also, TEP-FF works
    with the main flip-flop. When the timing margin is gradually decreasing, a timing
    error occurs at the TEP-FF before the main flip-flop captures a wrong value due
    to the delay buffer. This wrong value produces an error prediction signal, which
    allows the voltage control logic to provide a higher supply voltage and reduce
    the circuit delay. Evaluation results show that the proposed EP-AVS design methodology
    achieves a 20.8% voltage reduction while satisfying the target MTTF.


    Vijayan et al. [\[40\]](#page-16-27) propose an aging monitor based on hardware
    and software. The system is composed of representative flip-flops (RFF) that are
    selected in an offline phase and connected to the monitoring hardware. The aging
    effect consists of two phases: i) stress phase, where the transistor is under
    the aging effect; ii) recovery phase, where the transistor is recovering from
    the stress phase. A switching event in the RFF corresponds to the recovery phase
    of the corresponding flip-flop group, which is captured to report the recovery
    event to the software. The representative flip-flops are observed by a switching-event
    detector to perform the capture operation, which is composed of an XOR gate and
    a shadow flip-flop that generates a pulse at its output when a logic transition
    occurs in the corresponding flip-flop. The output of the switching-event detector
    is encoded using a priority encoder. In a determined clock cycle, the output of
    the priority encoder indicates the index of the flip-flop that switches its state
    in that particular clock cycle. If two representative flip-flops change their
    states at the same time, the priority encoder ensures a valid output. The critical-flag
    register (CFF) keeps the criticality word to represent the recovery/aging state
    of the corresponding representative flip-flop. This paper uses a software subroutine
    to mitigate aging by inserting NOPs instructions, which allows a relaxation on
    BTI stress, reducing the workload. Results show that area and power overheads
    imposed by the monitoring hardware are less than 0.25% for a Leon3 processor and
    Fabscalar processor.


    Saliva et al. [\[41\]](#page-16-28) propose monitors based on delay elements called
    pre-error flip-flops. The approaches are composed of a shadow flip-flop that stores
    delayed data, and is works in parallel to the regular flip-flop. The approach
    compares the two flip-flop outputs, and a pre-error signal is generated to predict
    the occurrence of timing errors. Each monitor uses different delay approaches.
    The first approach is the buffer delay, where buffers produce the delay. The second
    is the passive delay, where a resistor generates the delay. The last is the master
    delay, where master-slave latches replace the regular flip-flop, and the slave
    latch outputs feed the shadow flip-flop to generate the delay. Results show that
    the detection window of the in-situ monitors with passive delay is less deviant
    than the buffer and master delay ones with Vdd decrease. However, using a passive
    element in a digital circuit is not common. The in-situ monitor with buffer delay
    is a better choice because it uses standard cells in its implementation.


    Di Natale et al. [\[42\]](#page-16-29) propose a hidden-delay-fault sensor that
    can be used to detect small delay faults. The sensor allows the circuit to operate
    at the nominal frequency, and it is inserted in a critical path. The monitor works
    sampling a signal in both clock edges. After that, the monitor compares the two
    samples using an XOR gate and stores the result on the next falling edge of the
    clock suing a shadow flip-flop. Result extraction is performed using a classic
    scan chain. The authors propose that the sensor can be used during the lifetime
    of the circuit to identify timing violations in short paths caused by aging. Also,
    the authors mention that it is possible to use the sensor combined with reconfiguration
    techniques such as DVFS. The paper does not present results.


    Wang et al. [\[43\]](#page-16-30) uses a timing margin detector (TMD) to monitor
    aging and capture delay behavior. Also, the output detector is used in a machine
    learning engine based on a support vector machine (SVM) to predict aging. The
    TMD is used to capture late transitions. It is composed of two D flip-flops, and
    by an OR gate at the flipflops output. Results show that it is possible to obtain
    a 97.40% of accuracy in aging prediction, with 4.14% area overhead on average.


    Rohbani and Miremadi [\[44\]](#page-17-0) propose an aging sensor combined with
    the flip-flops of the design that monitors the critical path output before the
    rising edge of the clock signal. This signal follows the system clock by an adjusted
    delay of about 10% to 20% of the clock period. When the clock is at logic level
    one, the sensor is activated. Any change in the input signal during the period
    where the sensor clock is at logic level one and the system clock is at level
    logic level zero represents a delay extension of the critical path due to aging
    effects. Results show that the precision of the proposed sensor is about 2.7 higher,
    with almost 33% less area overhead compared with state-ofthe-art aging sensors.
    Furthermore, the presented sensor can detect and correct 50% of the Single Event
    Upsets (SEUs), which lead to a bit-flip in the flip-flops. Besides, the SEU detection
    circuitry can reduce Bias Temperature Instability (BTI) by balancing the duty
    cycle of the flip-flop with negligible extra overhead.


    Pachito et al. [\[45\]](#page-17-1) propose an aging-aware power supply or frequency
    reconfiguration approach that uses global and local sensors. Global sensors perform
    periodic or on-demand delay monitoring, while local sensors predict errors locally.
    Both allow adjusting frequency or power supply voltage. Results show that performance
    and power can be improved by, respectively, increasing the frequency and reducing
    the voltage while still preventing errors. In other work, Semio et al. [\[46\]](#page-17-2),
    [\[47\]](#page-17-3) propose improvements in the global and local sensors cited
    previously. The global sensor was improved to detect Negative-bias temperature
    instability (NBTI) and Positive-bias temperature instability (PBTI), while the
    local sensor was improved to tolerate delay-faults.


    Cho et al. [\[48\]](#page-17-4) examine the effectiveness of the aging-aware Adaptive
    Voltage Scaling (AVS) for logic circuit blocks using a Tunable Replica Circuit
    (TRC) aging monitors. The TRC is calibrated off-line, based on the critical paths
    and on-line monitoring of the operational conditions of the circuit, as temperature
    variations. The Power Management Unit (PMU) communicates with the TRC periodically.
    The PMU tunes the Voltage Regulator Module (VRM) when the TRC detects an aging
    delay degradation until the TRC detects the correct behavior based on the clock.
    Simulation results in a 22 nm High-K/Metal-Gate Tri-Gate CMOS process show a 7%
    power reduction with the removal of the guard-bands of a conventional fixed Vcc.


    Ding et al. [\[49\]](#page-17-5) propose a delay amplified digital (DAD) aging
    sensor circuit composed of a delay sensor and a signal amplification circuit.
    It uses a reference delay circuit designed according to the monitored combinational
    logic circuit. The delay sensor is used to detect aging effects, while a timing
    multiplier circuit eliminates the effects on the environment, improving the aging
    sensor data accuracy. A digital sample module uses nine T flip-flops to count
    the number of falling-edge during the amplified enable pulse. Using the parameters
    of TSMC 65 nm CMOS technology, the DAD sensor circuit is designed and simulated
    using SPECTRE.


    Li and Seok [\[50\]](#page-17-6) propose a technique to pipeline circuits that
    enables accurate of aging monitoring even under environmental variations. The
    technique scales the supply voltage for a temperature-insensitive delay and reconfigures
    the target paths into ring oscillators. The oscillation periods are measured and
    compared to pre-aging measurements to estimate the delay degradation caused by
    aging. Also, the technique presents a new register implementation, that has an
    area overhead of 12 transistors when compared to a standard flip-flop, and a relatively
    low delay overhead, once it adds a small amount of load between the path from
    input to output. The technique adds a feedback network between the input and output
    registers of target paths, which can present a small portion of the total oscillation
    period, making little impact on monitoring accuracy. The area overhead of feedback
    network can be minimized by sharing feedback paths among multiple target paths,
    as like the counter. The counter is used to measure the periods of the ring oscillator
    operation. Results show that the technique achieves highly-accurate monitoring
    with an error of 15.5% across the temperature variations in self-test phases from
    0◦C to 80◦C, exhibiting more than 30 times improvement in accuracy as compared
    to the conventional technique operating at the nominal supply voltage.


    Jang et al. [\[51\]](#page-17-7) propose a aging sensor that detects failures
    caused by BTI and HCI. This aging sensor is based on timing warning windows to
    detect a guardband violation of sequential circuits and generates a warning right
    before circuit failures occur. It monitors the moment when the critical path delays
    of the logic exceed a standard value, which guarantees a correct circuit operation.
    The aging sensor is composed by: i) a guardband generator; ii) a path delay monitor;
    iii) a hold circuit; iv) a signal that controls the aging sensor. The circuit
    was implemented in 110 nm, and results show that the aging sensor achieves a good
    aging failure prediction with low overhead.


    Table [VI](#page-13-0) summarizes the reviewed path delay monitors. Most of the
    monitors use delay elements and comparison mechanism to detect timing errors.
    Also, most of the approaches monitor just the critical paths without monitoring
    other system elements.


    #### *C. Clock Frequency Monitors*


    Aging can affect clock frequency and decreases system performance. Thus, clock
    frequency monitoring is a way to detect aging in a design.


    Wang et al. [\[52\]](#page-17-8) present a sensor for reliability analysis of
    digital circuits using standard-cells called Radic. The Authors also propose a
    low-cost built-in aging adaption system based on the Radic sensor to perform in-field
    aging adaption. Radic allows frequency, aging, and metastability measurements.
    Also, the sensor is designed to obtain the frequency difference between the waveform
    under test and a reference frequency by measuring how much clock cycles the wave
    under test is faster or slower than the reference frequency. A stable external
    source such as automatic test equipment, or a waveform generator, or an internal
    source such as a phase-locked loop (PLL) can generate the reference frequency.
    An m-bit timer stores the length of the measurement window by counting the number
    of clock cycles of the reference frequency. The Radic-based aging monitor system
    is inserted into a Freescale IP and an ITC''99 b19 benchmark. Results show that
    the system reduces the fixed aging guardband by 80%. A comparison between the
    original design and the design with the proposed adaption system shows an area
    reduction of about 1.02% to 3.16% in most cases. Power is also reduced, as the
    design can be synthesized using smaller drive strength.


    Kfloglu et al. [\[53\]](#page-17-9) propose an aging sensor based on RO that uses
    two identical aging paths. Both paths can be either equally sensitive to BTI or
    modulated to be more sensitive to aging effects. Using DC biased with opposite
    polarity inputs, both paths have the PBTI and NBTI effects stressed alternatively
    at every other stage. Unlike a conventional RO based aging sensor, a control loop
    logic links all stressed devices into one measuring RO loop which its output is
    the frequency degraded due to the aging. Also, the control loop logic links all
    non-stressed devices are linked into a second RO loop, wich the output is the
    reference frequency. The frequency delta between aging frequency and reference
    frequency is used to monitors aging.


    <span id="page-13-0"></span>


    | TABLE VI                                                                                     |  |

    |----------------------------------------------------------------------------------------------|--|

    | COMPARISON AMONG CRITICAL-PATH MONITORS PAPERS. LEGEND: "A": ADDRESSED, "NA":
    NOT ADDRESSED. |  |


    |            | System<br>monitoring | Extra<br>clock | Delay<br>element | Comparison<br>mechanism
    |

    |------------|----------------------|----------------|------------------|-------------------------|

    | [29], 2015 | NA                   | NA             | A                | A                       |

    | [30], 2017 | NA                   | NA             | A                | A                       |

    | [31], 2018 | NA                   | NA             | A                | A                       |

    | [32], 2016 | NA                   | NA             | A                | A                       |

    | [33], 2015 | NA                   | A              | NA               | A                       |

    | [34], 2017 | NA                   | A              | NA               | A                       |

    | [35], 2014 | NA                   | NA             | NA               | A                       |

    | [36], 2017 | NA                   | A              | NA               | A                       |

    | [37], 2014 | NA                   | NA             | NA               | A                       |

    | [38], 2014 | NA                   | NA             | A                | A                       |

    | [39], 2018 | NA                   | NA             | A                | A                       |

    | [40], 2017 | NA                   | NA             | NA               | A                       |

    | [41], 2015 | NA                   | NA             | A                | A                       |

    | [42], 2019 | NA                   | NA             | NA               | A                       |

    | [43], 2019 | NA                   | NA             | NA               | A                       |

    | [44], 2018 | NA                   | NA             | A                | NA                      |

    | [45], 2012 | A                    | NA             | A                | A                       |

    | [48], 2015 | NA                   | NA             | NA               | NA                      |

    | [49], 2016 | NA                   | NA             | NA               | A                       |

    | [50], 2014 | NA                   | NA             | NA               | NA                      |

    | [51], 2014 | NA                   | NA             | A                | A                       |


    #### *D. Circuit State and Workload Monitors*


    It is possible to detect aging by monitoring the whole system instead of just
    critical paths. The circuit state and its workload are metrics that can be monitored
    and provide insightful information. For example, they can indicate stress levels
    that will increase the aging effects impact.


    Koneru et al. [\[54\]](#page-17-10) reuse the design for testability (DfT – Definition
    [6\)](#page-1-5) infrastructure to perform a fine-grain workload-induced stress
    monitoring for accurate aging prediction. A multiple-input signature register
    (MISR) is used to capture the workload effect on the circuit. An aging prediction
    software, based on support vector machine (SVM) learning technique, performs aging
    mitigation. The DfT controller, implemented as a finite-state machine (FSM), periodically
    switches the circuit into scan mode to capture the circuit state. After capturing
    the state, the contents of the scan chains are then shifted out to the MISR. The
    scan-chains are modified to keep its value during the aging monitoring phase,
    which overwrites the state of the flip-flops and not allow the circuit to return
    to normal operation until completing the shift to MISR. The Authors conducted
    experiments on two open-source processor benchmarks, namely OpenRISC 1200 and
    Leon3, and on four ISCAS''89 benchmarks, to evaluate the accuracy of the proposed
    technique. Simulation results show that the proposed approach can accurately predict
    workloadinduced aging trends. In a similar work, Firouzi et al. [\[55\]](#page-17-11)
    reuse the BIST structure to predict the fine-grained circuit-delay degradation
    with minimal area and performance overhead and high accuracy.


    Khan and Kundu [\[56\]](#page-17-12) propose a system-level reliability management
    scheme (SRM) that dynamically adjusts the operating frequency and supply voltage
    according to the system aging. The proposal allows continuous runtime adjustments
    based on parameters such as actual room temperature and power supply tolerance.
    The SRM communicates with the voltage and frequency control registers to enable
    frequency and voltage reconfiguration. It is implemented in software and assumes
    a Virtual Machine Monitor (VMM) running underneath the OS software stack, which
    is primarily used to enter and exit the SRM. The SRM software enables carefully
    crafted functional stress tests or built-in self-test control to identify degradation
    at a component granularity and provides adjustments for sustained performance
    levels at the target reliability. The software allows the system to adapt to the
    aging effects and invokes aging device management at determined periods. The results
    show that the device can operate near peak frequency throughout product life.
    Also, the approach ensures protection against failure due to insufficient lifetime
    guardband and no system downtime or change.


    Sadi et al. [\[57\]](#page-17-13) presents a framework for designing lifetime-reliable
    system-on-chip (SoC) with reconfiguration capability to deal with aging effects.
    The proposed flow uses a BIST (Definition [7\)](#page-1-6), and a machine learning
    linear regression predictor software to activate aging countermeasures. The aging
    status of the chip is monitored at regular intervals by the BIST hardware. Based
    on the observations, proactive adaptation methods are taken to counteract the
    reliability degradation effect. The framework allows testing patterns from SoC''s
    existing BIST hardware, collect the response, and tune the linear regression software.
    A gate-overlap and path-delay-aware algorithm selects a minimum set of patterns,
    which activate the target paths used as features of the linear regression predictor.
    The seeds of the selected patterns are stored in on-chip memory and applied at
    the BIST hardware at multiple test clock frequencies when required. The corresponding
    responses of these patterns are collected in a separate response storage flipflop
    chain. The software-implemented machine learning classifier is trained with the
    collected multiple-frequency responses, and the trained predictor accurately predicts
    the state of aging degradation at runtime. The paths to be monitored by the BIST
    hardware are selected at the design time based on timing analysis. The adaptive
    methods used in this approach are frequency scaling, voltage scaling, and adaptive
    body biasing. Simulation results show that the proposed technique allows accurate
    and fine-grained in-field aging prediction, with a precision that can reach 94%.


    Baranowski et al. [\[58\]](#page-17-14) present a method for aging rate prediction,
    which is based on workload monitoring and linear regression machine learning technique.
    The monitoring technique enables the on-line prediction of the degradation rate
    caused by the currently running application. The degradation rate monitoring system
    is composed of a workload monitor and a temperature sensor. The linear regression
    machine learning technique is used to find the representative critical gates that
    are monitored. Results show that this method delivers sufficient accuracy at an
    area overhead of 4.2%, which decreases with the size of the monitored circuit.


    #### *E. Voltage Monitors*


    Circuit voltage can also be use to monitor aging effects. Similar to what happens
    in clock frequency variations, as the circuit ages, negative effects will be observed,
    such as timing errors and path delay extension.


    Narang and Srivastava [\[59\]](#page-17-15) propose an approach that uses an inverter
    chain and counter-based technique to detect the variation in the threshold voltage.
    A voltage sensing methodology is used to monitor the circuit''s voltage variation.
    This variation can be fed to an Adaptive Body Bias (ABB) circuit to mitigate the
    effects of NBTI. The approach uses a counter to determine the total path delay.
    The path delay feeds an inverter connected to an amplifier. The amplifier output
    pass trough a voltage to current converter, which feeds a logarithmic amplifier.
    The output of this logarithmic amplifier feds an exponential function generator
    that passes through a subtractor circuit that is used to detect a change in the
    threshold voltage due to the NBTI effect. The circuit was validated in a set of
    circuits such as 32-bit OR gate, 64-input OR gate, and 32-bit comparator in 32
    nm technology. The simulation results show that this methodology is efficient
    as it reduces the delay to a large extent with minimal increase in power.


    Xiaojin et al. [\[60\]](#page-17-16) propose a digital on-chip detector that uses
    the circuit output voltage phase to detect aging. The approach consists of duplicating
    the circuit, generating two circuits: a reference circuit and an aging stressed
    circuit. The output of both is compared using an XNOR gate. If a pulse occurs
    in the XNOR output, aging is detected. Also, the XNOR output pass trough time
    to digital converter to facilitate the circuit state analyses and verification.
    The authors claim that the aging detecting circuit can be applied in adaptive
    systems to mitigate the aging, but do not present a solution in this work. The
    validation was made by a chip implementation and by simulation. The chip demonstrates
    results close to the simulated regarding aging time.


    #### VII. CONCLUSION


    <span id="page-14-0"></span>This Section concludes the aging monitors and reconfiguration
    techniques survey, providing insights for future research and development. Table
    [VII](#page-15-12) presents the implementation methods.


    Most of the literature contributions are in the digital area, specifically using
    hardware solutions for monitoring aging in circuits. Few works use software approaches
    for aging monitoring. Most software applications act on reconfiguring the circuit
    after aging detection. We observed works using learning methods (software) for
    taking proactive actions, detecting events related to aging before they occur.
    These learning-based methods can point out


    | TABLE VII                                              |

    |--------------------------------------------------------|

    | CLASSIFICATION ACCORDING TO THE IMPLEMENTATION METHOD. |


    <span id="page-15-12"></span>


    | Classification                                                                       |
    Works                                                                                                                                                                  |

    |--------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------|

    | Digital, Hardware, Synchronous                                                       |
    [23] [24] [25] [26] [18] [28] [29]<br>[30] [31] [32] [33] [34] [35] [36]<br>[37]
    [38] [39] [42] [43] [44] [45]<br>[46] [47] [48] [49] [50] [51] [52]<br>[53] [55]
    [60] |

    | Digital, Hardware & Software, Synchronous<br>Analog & Digital, Hardware, Synchronous
    | [21] [40] [54] [56] [57] [58]<br>[22] [27] [41] [59]                                                                                                                   |


    a promising way to detect the effects of aging, as long as they are associated
    with a rich set of hardware monitors, such as temperature monitors. Also, few
    contributions combine analog and digital techniques to perform aging monitoring.


    As mentioned, the most common monitor used for aging detection is the timing error
    monitor. However, this technique is a function of the paths chosen to be monitored
    during design time. If this choice is executed incorrectly and the set of critical
    paths does not represent the critical paths, the aging counter-effects solutions
    are inefficient. With the CMOS scaling, the number of critical paths increases,
    which increases the number of components to monitor the aging effects. Thus, it
    is likely that the use of solutions focused on timing errors and path monitoring
    will decrease in the future or be limited to older technologies nodes.


    We believe that solutions based on system-wide monitoring parameters such as temperature,
    voltage, and frequency will be more prevalent once they do not depend on a specific
    parameter.


    Summarizing, current techniques heavily rely on timing error monitors for detecting
    aging and use voltage scaling to compensate the effects in integrated circuits.
    We believe that new solutions are required due to the fact that as technology
    nodes advance, it becomes harder to identify critical paths of a circuit. This
    limitation not only makes the task of defining where to place timing error monitors
    more challenging, but can also require an increase in the number of monitors,
    inducing larger area and power overheads. Furthermore, with the availability of
    different sensors, such as frequency and temperature, in industrial SoCs, we believe
    there is a gap to be filled in aging detection algorithms. Especially with emerging
    artificial intelligence capabilities, algorithms can analyze the data of the available
    sensors and configure the SoC to counter aging effects.


    #### REFERENCES


    - <span id="page-15-0"></span>[1] H. Kim, J. Kim, H. Amrouch, J. Henkel, A. Gerstlauer,
    K. Choi, and H. Park, "Aging compensation with dynamic computation approximation,"
    *IEEE Transactions on Circuits and Systems I: Regular Papers*, 2020.

    - <span id="page-15-1"></span>[2] G. Sai, M. Zwolinski, and B. Halak, "A cost-efficient
    aging sensor based on multiple paths delay fault," *Ageing of Integrated Circuits:
    Causes, Effects and Mitigation Techniques*, p. 211, 2020.

    - <span id="page-15-2"></span>[3] S. R. Sahoo and K. Mahapatra, "A novel area
    efficient on-chip ro-sensor for recycled ic detection," *Integration*, vol. 70,
    pp. 138–150, 2020.

    - <span id="page-15-3"></span>[4] Y. Lu, L. Shang, H. Zhou, H. Zhu, F. Yang, and
    X. Zeng, "Statistical Reliability Analysis under Process Variation and Aging Effects,"
    in *Design Automation Conference (DAC)*. IEEE, 2009, pp. 514–519.

    - <span id="page-15-4"></span>[5] M. Agarwal, V. Balakrishnan, A. Bhuyan, K. Kim,
    B. C. Paul, W. Wang, B. Yang, Y. Cao, and S. Mitra, "Optimized Circuit Failure
    Prediction for Aging: Practicality and Promise," in *International Test Conference
    (ITC)*. IEEE, 2008, pp. 1–10.

    - <span id="page-15-5"></span>[6] R. J. Baker, *CMOS: Circuit Design, Layout,
    and Simulation*. Wiley-IEEE press, 2019.

    - <span id="page-15-6"></span>[7] S. Rahimipour, W. N. Flayyih, I. El-Azhary,
    S. Shafie, and F. Z. Rokhani, "A survey of On-chip Monitors," in *International
    Conference on Circuits and Systems (ICCAS)*. IEEE, 2012, pp. 243–248.

    - <span id="page-15-7"></span>[8] N. Khoshavi, R. A. Ashraf, R. F. DeMara, S.
    Kiamehr, F. Oboril, and M. B. Tahoori, "Contemporary CMOS Aging Mitigation Techniques:
    Survey, Taxonomy, and Methods," *Integration, the VLSI Journal*, vol. 59, pp.
    10–22, 2017.

    - <span id="page-15-8"></span>[9] M. A. Kochte and H.-J. Wunderlich, "Self-Test
    and Diagnosis for Self-Aware Systems," *IEEE Design & Test*, vol. 35, no. 7, pp.
    7–18, 2018.

    - <span id="page-15-9"></span>[10] A. Jagirdar, R. Oliveira, and T. J. Chakraborty,
    "Efficient flip-flop designs for SET/SEU mitigation with tolerance to crosstalk
    induced signal delays," in *IEEE Silicon Errors Logic System Effects (SELSE)*,
    2007, pp. 1–6.

    - <span id="page-15-10"></span>[11] D. K. Schroder and J. A. Babcock, "Negative
    bias temperature instability: Road to cross in deep submicron silicon semiconductor
    manufacturing," *Journal of applied Physics*, vol. 94, no. 1, pp. 1–18, 2003.

    - <span id="page-15-11"></span>[12] E. Maricau and G. Gielen, "Transistor aging-induced
    degradation of analog circuits: Impact analysis and design guidelines," in *European
    Solid-State Device Research Conference (ESSCIRC)*. IEEE, 2011, pp. 243–246.

    - <span id="page-16-0"></span>[13] S. Novak, C. Parker, D. Becher, M. Liu, M.
    Agostinelli, M. Chahal, P. Packan, P. Nayak, S. Ramey, and S. Natarajan, "Transistor
    aging and reliability in 14nm tri-gate technology," in *2015 IEEE International
    Reliability Physics Symposium*. IEEE, 2015, pp. 2F–2.

    - <span id="page-16-1"></span>[14] M. Abramovici, M. A. Breuer, and A. D. Friedman,
    *Digital Systems Testing And Testable Design*, 1st ed. Wiley-IEEE Press, 1994.

    - <span id="page-16-2"></span>[15] D. Ernst, N. S. Kim, S. Das, S. Pant, R. Rao,
    T. Pham, C. Ziesler, D. Blaauw, T. Austin, K. Flautner *et al.*, "Razor: A Low-power
    Pipeline Based on Circuit-level Timing Speculation," in *International Symposium
    on Microarchitecture (MICRO)*. IEEE, 2003, pp. 7–18.

    - <span id="page-16-3"></span>[16] S. Mittal, "A survey of techniques for improving
    energy efficiency in embedded computing systems," *International Journal of Computer
    Aided Engineering and Technology*, vol. 6, no. 4, pp. 440–459, 2014.

    - <span id="page-16-4"></span>[17] A. L. D. M. Martins, A. H. L. da Silva, A.
    M. Rahmani, N. D. Dutt, and F. G. Moraes, "Hierarchical adaptive Multi-objective
    resource management for many-core systems," *Journal of Systems Architecture*,
    vol. 97, pp. 416–427, 2019.

    - <span id="page-16-5"></span>[18] V. Kumar, "On-chip Aging Compensation for Output
    Driver," in *International Reliability Physics Symposium (IRPS)*. IEEE, 2014,
    pp. CA.3.1–CA.3.5.

    - <span id="page-16-6"></span>[19] T. Chen and S. Naffziger, "Comparison of adaptive
    body bias (ABB) and Adaptive Supply Voltage (ASV) for Improving Delay and Leakage
    Under the Presence of Process Variation," *IEEE Transactions on Very Large Scale
    Integration (VLSI) Systems*, vol. 11, no. 5, pp. 888–899, 2003.

    - <span id="page-16-7"></span>[20] X. Wang, J. Keane, T. T.-H. Kim, P. Jain, Q.
    Tang, and C. H. Kim, "Silicon odometers: Compact in situ aging sensors for robust
    system design," *IEEE micro*, vol. 34, no. 6, pp. 74–85, 2014.

    - <span id="page-16-8"></span>[21] M. Igarashi, K. Takeuchi, T. Okagaki, K. Shibutani,
    H. Matsushita, and K. Nii, "An on-die digital aging monitor against HCI and xBTI
    in 16 nm Fin-FET bulk CMOS technology," in *European Solid-State Circuits Conference
    (ESSCIRC)*. IEEE, 2015, pp. 112–115.

    - <span id="page-16-9"></span>[22] S. Majerus, X. Tang, J. Liang, and S. Mandal,
    "Embedded silicon odometers for monitoring the aging of high-temperature integrated
    circuits," in *National Aerospace and Electronics Conference (NAECON)*. IEEE,
    2017, pp. 98–103.

    - <span id="page-16-10"></span>[23] D. Sengupta and S. S. Sapatnekar, "Estimating
    Circuit Aging due to BTI and HCI using Ring-Oscillator-Based Sensors," *IEEE Transactions
    on Computer-Aided Design of Integrated Circuits and Systems*, vol. 36, no. 10,
    pp. 1688–1701, 2017.

    - <span id="page-16-11"></span>[24] Y. Kim, H. Shim, M. Jin, J. Bae, C. Liu, and
    S. Pae, "Investigation of HCI effects in FinFET based ring oscillator circuits
    and IP blocks," in *International Reliability Physics Symposium (IRPS)*. IEEE,
    2017, pp. 4C–2.1–4C–2.4.

    - <span id="page-16-12"></span>[25] B. Shakya, U. Guin, M. Tehranipoor, and D.
    Forte, "Performance optimization for on-chip sensors to detect recycled ICs,"
    in *International Conference on Computer Design (ICCD)*. IEEE, 2015, pp. 289–295.

    - <span id="page-16-13"></span>[26] Y. Miyake, Y. Sato, S. Kajihara, and Y. Miura,
    "Temperature and Voltage Measurement for Field Test Using an Aging-Tolerant Monitor,"
    *IEEE Transactions on Very Large Scale Integration (VLSI) Systems*, vol. 24, no.
    11, pp. 3282–3295, 2016.

    - <span id="page-16-14"></span>[27] G. Ali, A. Badawy, and H. G. Kerkhoff, "Accessing
    on-chip temperature health monitors using the IEEE 1687 standard," in *International
    Conference on Electronics, Circuits and Systems (ICECS)*. IEEE, 2016, pp. 776–779.

    - <span id="page-16-15"></span>[28] V. Rathore, V. Chaturvedi, A. K. Singh, T.
    Srikanthan, and M. Shafique, "LifeGuard: A Reinforcement Learning-Based Task Mapping
    Strategy for Performance-Centric Aging Management," in *Design Automation Conference
    (DAC)*. ACM, 2019, p. 179.

    - <span id="page-16-16"></span>[29] P. R. Savanur, P. Alladi, and S. Tragoudas,
    "A BIST approach for counterfeit circuit detection based on NBTI degradation,"
    in *International Symposium on Defect and Fault Tolerance in VLSI and Nanotechnology
    Systems (DFTS)*. IEEE, 2015, pp. 123–126.

    - <span id="page-16-17"></span>[30] G. Sai, B. Halak, and M. Zwolinski, "A cost-efficient
    delay-fault monitor," in *International Symposium on Circuits and Systems (ISCAS)*.
    IEEE, 2017, pp. 1–4.

    - <span id="page-16-18"></span>[31] ——, "Multi-Path Aging Sensor for Cost-Efficient
    Delay Fault Prediction," *IEEE Transactions on Circuits and Systems II: Express
    Briefs*, vol. 65, no. 4, pp. 491–495, 2018.

    - <span id="page-16-19"></span>[32] T. Copetti, G. C. Medeiros, L. B. Poehls,
    and F. Vargas, "NBTI-Aware Design of Integrated Circuits: A Hardware-Based Approach
    for Increasing Circuits Life Time," *Journal of Electronic Testing*, vol. 32,
    no. 3, pp. 315–328, 2016.

    - <span id="page-16-20"></span>[33] S. Sadeghi-Kohan, M. Kamal, J. McNeil, P.
    Prinetto, and Z. Navabi, "Online self adjusting progressive age monitoring of
    timing variations," in *International Conference on Design Technology of Integrated
    Systems in Nanoscale Era (DTIS)*. IEEE, 2015, pp. 1–2.

    - <span id="page-16-21"></span>[34] S. Sadeghi-Kohan, M. Kamal, and Z. Navabi,
    "Self-Adjusting Monitor for Measuring Aging Rate and Advancement," *IEEE Transactions
    on Emerging Topics in Computing*, vol. (preprint), no. 1, pp. 1–1, 2017.

    - <span id="page-16-22"></span>[35] H. Yi, T. Yoneda, and M. Inoue, "A Scan-Based
    On-Line Aging Monitoring Scheme," *JSTS: Journal of Semiconductor Technology and
    Science*, vol. 14, no. 1, pp. 124–130, 2014.

    - <span id="page-16-23"></span>[36] J. Jung, M. A. Ansari, D. Kim, H. Yi, and
    S. Park, "On Diagnosing the Aging Level of Automotive Semiconductor Devices,"
    *IEEE Transactions on Circuits and Systems II: Express Briefs*, vol. 64, no. 7,
    pp. 822–826, 2017.

    - <span id="page-16-24"></span>[37] J. Vazquez-Hernandez, "Error prediction and
    detection methodologies for reliable circuit operation under NBTI," in *International
    Test Conference (ITC)*. IEEE, 2014, pp. 1–10.

    - <span id="page-16-25"></span>[38] V. Chandra, "Monitoring Reliability in Embedded
    Processors - A Multi-layer View," in *Design Automation Conference (DAC)*. ACM,
    2014, pp. 1–6.

    - <span id="page-16-26"></span>[39] Y. Masuda and M. Hashimoto, "MTTF-aware design
    methodology of error prediction based adaptively voltage-scaled circuits," in
    *Asia and South Pacific Design Automation Conference (ASP-DAC)*. IEEE, 2018, pp.
    159–165.

    - <span id="page-16-27"></span>[40] A. Vijayan, S. Kiamehr, F. Oboril, K. Chakrabarty,
    and M. B. Tahoori, "Workload-aware Static Aging Monitoring and Mitigation of Timing-critical
    Flip-flops," *IEEE Transactions on Computer-Aided Design of Integrated Circuits
    and Systems*, vol. 37, no. 10, pp. 2098–2110, 2017.

    - <span id="page-16-28"></span>[41] M. Saliva, F. Cacho, V. Huard, X. Federspiel,
    D. Angot, A. Benhassain, A. Bravaix, and L. Anghel, "Digital circuits reliability
    with in-situ monitors in 28nm fully depleted SOI," in *Design, Automation & Test
    in Europe Conference & Exhibition (DATE)*. IEEE, 2015, pp. 441–446.

    - <span id="page-16-29"></span>[42] G. Di Natale, E. I. Vatajelu, K. S. Kannan,
    and L. Anghel, "Hidden-Delay-Fault Sensor for Test, Reliability and Security,"
    in *Design, Automation & Test in Europe Conference & Exhibition (DATE)*. IEEE,
    2019, pp. 316–319.

    - <span id="page-16-30"></span>[43] Y.-T. Wang, K.-C. Wu, C.-H. Chou, and S.-C.
    Chang, "Aging-aware chip health prediction adopting an innovative monitoring strategy,"
    in *Asia and South Pacific Design Automation Conference (ASP-DAC)*. ACM, 2019,
    pp. 179–184.

    - <span id="page-17-1"></span><span id="page-17-0"></span>[45] J. Pachito, C.
    V. Martins, B. Jacinto, J. Semiao, J. C. Vazquez, V. Champac, M. B. Santos, I.
    C. Teixeira, and J. P. Teixeira, "Aging-aware ˜ power or frequency tuning with
    predictive fault detection," *IEEE Design & Test of Computers*, vol. 29, no. 5,
    pp. 27–36, 2012.

    - <span id="page-17-2"></span>[46] J. Semio, C. Leong, A. Romo, M. B. Santos,
    I. C. Teixeira, and J. P. Teixeira, "Aging-aware Dynamic Voltage or Frequency
    Scaling," in *Design of Circuits and Integrated Circuits (DCIS)*. IEEE, 2014,
    pp. 1–6.

    - <span id="page-17-3"></span>[47] J. Semio, D. Saraiva, C. Leong, A. Romo, M.
    B. Santos, I. C. Teixeira, and J. P. Teixeira, "Performance Sensor for Tolerance
    and Predictive Detection Of Delay-faults," in *Defect and Fault Tolerance in VLSI
    and Nanotechnology Systems (DFT)*. IEEE, 2014, pp. 110–115.

    - <span id="page-17-4"></span>[48] M. Cho, C. Tokunaga, M. M. Khellah, J. W. Tschanz,
    and V. De, "Aging-aware Adaptive Voltage Scaling in 22nm high-K/metal-gate tri-gate
    CMOS," in *Custom Integrated Circuits Conference (CICC)*. IEEE, 2015, pp. 1–4.

    - <span id="page-17-5"></span>[49] D. Ding, Y. Zhang, P. Wang, H. Qian, and G.
    Li, "Design a Delay Amplified Digital Aging Sensor Circuit in 65nm CMOS," in *International
    Conference on Solid-State and Integrated Circuit Technology (ICSICT)*. IEEE, 2016,
    pp. 1449–1451.

    - <span id="page-17-6"></span>[50] J. Li and M. Seok, "Robust and In-situ Self-testing
    Technique for Monitoring Device Aging Effects In Pipeline Circuits," in *Design
    Automation Conference (DAC)*. IEEE, 2014, pp. 1–6.

    - <span id="page-17-7"></span>[51] B. Jang, J. K. Lee, M. Choi, and K. K. Kim,
    "On-chip aging prediction circuit in nanometer digital circuits," in *International
    SoC Design Conference (ISOCC)*. IEEE, 2014, pp. 68–69.

    - <span id="page-17-8"></span>[52] X. Wang, L. Winemberg, D. Su, D. Tran, S. George,
    N. Ahmed, S. Palosh, A. Dobin, and M. Tehranipoor, "Aging adaption in integrated
    circuits using a novel built-in sensor," *IEEE Transactions on Computer-Aided
    Design of Integrated Circuits and Systems*, vol. 34, no. 1, pp. 109–121, 2015.

    - <span id="page-17-9"></span>[53] H. Kfloglu, M. Chen, S. Lu, A. Rabindranath,
    R. Kakoee, and S. Hu, "Thermally-aware sensor allocation for real-time monitoring
    and mitigation of FEOL aging in System-on-Chip (SoC) applications," in *International
    Reliability Physics Symposium (IRPS)*. IEEE, 2017, pp. 4C–6.1–4C–6.5.

    - <span id="page-17-10"></span>[54] A. Koneru, A. Vijayan, K. Chakrabarty, and
    M. B. Tahoori, "Fine-grained aging prediction based on the monitoring of run-time
    stress using DfT infrastructure," in *International Conference on Computer-Aided
    Design (ICCAD)*. IEEE, 2015, pp. 51–58.

    - <span id="page-17-11"></span>[55] F. Firouzi, F. Ye, A. Vijayan, A. Koneru,
    K. Chakrabarty, and M. B. Tahoori, "Re-using BIST for Circuit Aging Monitoring,"
    in *European Test Symposium (ETS)*. IEEE, 2015, pp. 1–2.

    - <span id="page-17-12"></span>[56] O. Khan and S. Kundu, "A self-adaptive system
    architecture to address transistor aging," in *Design, Automation & Test in Europe
    Conference & Exhibition (DATE)*. IEEE, 2009, pp. 81–86.

    - <span id="page-17-13"></span>[57] M. Sadi, G. K. Contreras, J. Chen, L. Winemberg,
    and M. Tehranipoor, "Design of Reliable SoCs With BIST Hardware and Machine Learning,"
    *IEEE Transactions on Very Large Scale Integration (VLSI) Systems*, vol. 25, no.
    11, pp. 3237–3250, 2017.

    - <span id="page-17-14"></span>[58] R. Baranowski, F. Firouzi, S. Kiamehr, C.
    Liu, M. Tahoori, and H.-J. Wunderlich, "On-line Prediction of NBTI-induced Aging
    Rates," in *Design, Automation & Test in Europe Conference & Exhibition (DATE)*.
    IEEE, 2015, pp. 589–592.

    - <span id="page-17-15"></span>[59] S. Narang and A. P. Srivastava, "NBTI detection
    methodology for building tolerance with respect to NBTI effects employing adaptive
    body bias," in *International Conference on Circuit, Power and Computing Technologies
    (ICCPCT)*. IEEE, 2015, pp. 1–7.

    - <span id="page-17-16"></span>[60] X. Li, J. Qing, Y. Sun, Y. Zeng, Y. Shi, and
    Y. Wang, "Linear and resolution adjusted on-chip aging detection of NBTI degradation,"
    *IEEE Transactions on Device and Materials Reliability*, vol. 18, no. 3, pp. 383–390,
    2018.

    - <span id="page-17-17"></span>[61] K. Hofmann, H. Reisinger, K. Ermisch, C. Schlnder,
    W. Gustin, T. Pompl, G. Georgakos, K. v. Arnim, J. Hatsch, T. Kodytek, T. Baumann,
    and C. Pacha, "Highly Accurate Product-level Aging Monitoring in 40nm CMOS," in
    *Symposium on VLSI Technology (VLSIT)*. IEEE, 2010, pp. 27–28.

    - <span id="page-17-18"></span>[62] V. Rathore, V. Chaturvedi, A. K. Singh, T.
    Srikanthan, R. Rohith, S.-K. Lam, and M. Shaflque, "HiMap: A hierarchical mapping
    approach for enhancing lifetime reliability of dark silicon manycore systems,"
    in *Design, Automation & Test in Europe Conference & Exhibition (DATE)*. IEEE,
    2018, pp. 991–996.

    - <span id="page-17-19"></span>[63] D. Gnad, M. Shafique, F. Kriebel, S. Rehman,
    D. Sun, and J. Henkel, "Hayat: Harnessing Dark Silicon and Variability for Aging
    Deceleration And Balancing," in *Design Automation Conference (DAC)*. IEEE, 2015,
    pp. 1–6.

    - <span id="page-17-20"></span>[64] H. Fuketa, M. Hashimoto, Y. Mitsuyama, and
    T. Onoye, "Adaptive performance compensation with in-situ timing error predictive
    sensors for subthreshold circuits," *IEEE Transactions on very large scale integration
    (VLSI) systems*, vol. 20, no. 2, pp. 333–343, 2012.

    - <span id="page-17-21"></span>[65] K. A. Bowman, J. W. Tschanz, S.-L. L. Lu,
    P. A. Aseron, M. M. Khellah, A. Raychowdhury, B. M. Geuskens, C. Tokunaga, C.
    B. Wilkerson, T. Karnik *et al.*, "A 45 nm Resilient Microprocessor Core for Dynamic
    Variation Tolerance," *IEEE Journal of Solid-State Circuits*, vol. 46, no. 1,
    pp. 194–208, 2011.


    #### ACKNOWLEDGMENTS


    Author Fernando Gehm Moraes is supported by FAPERGS (17/2551-0001196-1) and CNPq
    (302531/2016-5), Brazilian funding agencies. Leonardo Rezende Juracy was financed
    in part by the Coordenao de Aperfeioamento de Pessoal de Nivel Superior - Brasil
    (CAPES) - Finance Code 001.


    #### BIOGRAPHY


    Leonardo Rezende Juracy received a bachelor degree from the Pontifical Catholic
    University of Rio Grande do Sul (PUCRS), Brazil, in Computer Engineering in 2015,
    an M.Sc. degree from the PUCRS, Brazil, in Computer Science in 2018, and is currently
    an Ph.D. student at PUCRS. His research interests include design for testability,
    fault-tolerant designs, asynchronous designs, resilient designs, networks-on-chip
    and multi-processor systems-onchip.


    Matheus Trevisan Moreira received a B.S.E degree in Computer Engineering from
    Pontifcia Universidade Catlica do Rio Grande do Sul (PUCRS) in 2011. He also received
    a M.Sc. degree in Computer Science from the graduate program in Computer Science
    (PPGCC) at PUCRS in 2012. He has over 50 published articles, in conferences and
    journals. Also, his Thesis received an award from the Brazilian Society of Microelectronics
    (SBMICRO) and CEITEC S.A. as the best Ph.D. Thesis in Design, EDA and Test of
    Integrated Circuits in 2016. He is currently the Director of Technology at Chronos
    Tech, in San Diego, CA, USA. He has experience in different fields of microelectronics
    with emphasis on non-synchronous circuits design.


    Alexandre de Morais Amory received bachelor and master degrees in computer science
    from the PUCRS University, in 2001 and 2003, respectively. In 2007 he received
    the Ph.D. in computer science from UFRGS University, Porto Alegre, Brazil. His
    thesis received an Honorable Mention in the CAPES Thesis Award, in 2008. His professional
    experience include an internship at Philips Research Laboratories, The Netherlands,
    in 2005; as a lead verification engineer at CEITEC design house from 2007 to 2009;
    and as a postdoctoral fellow at PUCRS, from 2009 to 2012. Alexandre is currently
    a professor at PUCRS University. His research interest include design, test, fault-tolerance,
    and verification of digital systems, particularly MPSoCs and NoCs.


    Fernando Gehm Moraes (M''1997–SM''2002) received the Electrical Engineering and
    M.Sc. degrees from the Universidade Federal do Rio Grande do Sul (UFRGS), Porto
    Alegre, Brazil, in 1987 and 1990, respectively. In 1994 he received the Ph.D.
    degree from the Laboratoire dInformatique, Robotique et Microlectronique de Montpellier),
    France. He is currently at PUCRS, where he has been an Associate Professor from
    1996 to 2002, and Full Professor since 2002. He has authored and co-authored 37
    peer refereed journal articles in the field of VLSI design. His primary research
    interests include Microelectronics, FPGAs, reconfigurable architectures, NoCs
    and MPSoCs.'
  decisions:
    evaluation_prompt: 'Qualified. Reason: The paper contains structured evaluation
      with sections dedicated to empirical analysis, including tables and figures
      presenting quantifiable outcomes, and mentions of experiments and metrics used
      to assess performance.'
    related_work_prompt: 'Qualified. Reason: The paper meaningfully engages with prior
      research throughout its content. It includes numerous academic citations, discusses
      previous works in the introduction, and provides a detailed literature review.
      The paper also compares its findings and methods to existing research, particularly
      in the sections discussing aging monitors and reconfiguration techniques.'
    novelty_prompt: '- Qualified. Reason: The paper proposes a new classification
      for aging monitors and reconfiguration techniques, extending the taxonomy of
      previous works. It also claims to fill a gap by covering the most recent works
      from 2012 to 2019, which were not addressed in previous surveys.'
    review_only_prompt: 'Disqualified: review paper. Reason: The title contains the
      word "survey," and the main body primarily summarizes existing work without
      introducing new methods, datasets, experiments, or frameworks.'
